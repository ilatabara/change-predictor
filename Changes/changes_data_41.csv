id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fcharm-designate~stable%2Fussuri~I48a04ac619204ba109d87ca05de7cbe308592486,openstack/charm-designate,stable/ussuri,I48a04ac619204ba109d87ca05de7cbe308592486,Add check to expose internal endpoints,MERGED,2023-01-09 16:49:03.000000000,2023-01-30 23:25:36.000000000,2023-01-30 23:25:36.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-09 16:49:03.000000000', 'files': ['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/275a77acb68f1c0e5dd704e5a49c6ae4510e1b04', 'message': 'Add check to expose internal endpoints\n\nCurrently, the charm ignores the use-internal-endpoints config\noption that is being inherited from the Openstack Layer. This\npatch adds a check to ensure that the internal endpoint is exposed\nif this is set to True.\n\nCloses-bug: #1995188\nChange-Id: I48a04ac619204ba109d87ca05de7cbe308592486\n(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)\n(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)\n(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)\n(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)\n(cherry picked from commit 9caf724caae86fdf474edc56eb280307521a6049)\n(cherry picked from commit ace9be35cbb30a3f2bcd941496e7bb122e380af3)\n'}]",3,869462,275a77acb68f1c0e5dd704e5a49c6ae4510e1b04,11,4,1,14567,,,0,"Add check to expose internal endpoints

Currently, the charm ignores the use-internal-endpoints config
option that is being inherited from the Openstack Layer. This
patch adds a check to ensure that the internal endpoint is exposed
if this is set to True.

Closes-bug: #1995188
Change-Id: I48a04ac619204ba109d87ca05de7cbe308592486
(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)
(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)
(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)
(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)
(cherry picked from commit 9caf724caae86fdf474edc56eb280307521a6049)
(cherry picked from commit ace9be35cbb30a3f2bcd941496e7bb122e380af3)
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/62/869462/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py']",2,275a77acb68f1c0e5dd704e5a49c6ae4510e1b04,, if hookenv.config('use-internal-endpoints'): endpoint.expose_endpoint(instance.internal_url) else: endpoint.expose_endpoint(instance.public_url), endpoint.expose_endpoint(instance.public_url),11,2
openstack%2Fcharm-designate~master~Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a,openstack/charm-designate,master,Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a,Add apache2 to the list of managed services.,NEW,2023-01-26 19:01:06.000000000,2023-01-30 23:25:22.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 19:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/32542796676cbdf8a12a5bf0d966bf4d0a2b598c', 'message': 'Add apache2 to the list of managed services.\n\nThis charm installs and manages apache2, it needs to be registed in the\nlist of services to allow pause/resume actions to stop/start it\nrespectively.\n\nChange-Id: Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a\nCloses-Bug: #2003850\n'}, {'number': 2, 'created': '2023-01-27 13:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/3a0b508bc5008d0ca4bd7c0f44fde22c1e2fe803', 'message': 'Add apache2 to the list of managed services.\n\nThis charm installs and manages apache2, it needs to be registed in the\nlist of services to allow pause/resume actions to stop/start it\nrespectively.\n\nChange-Id: Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a\nCloses-Bug: #2003850\n'}, {'number': 3, 'created': '2023-01-30 20:42:37.000000000', 'files': ['src/lib/charm/openstack/designate.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/efe81258492dc59cb9dd1352ea2bafdc27636dbc', 'message': 'Add apache2 to the list of managed services.\n\nThis charm installs and manages apache2, it needs to be registed in the\nlist of services to allow pause/resume actions to stop/start it\nrespectively.\n\nChange-Id: Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a\nCloses-Bug: #2003850\n'}]",0,871841,efe81258492dc59cb9dd1352ea2bafdc27636dbc,9,2,3,2424,,,0,"Add apache2 to the list of managed services.

This charm installs and manages apache2, it needs to be registed in the
list of services to allow pause/resume actions to stop/start it
respectively.

Change-Id: Ie324c21d0a4fb89cdbac49aceb98226e7cf8496a
Closes-Bug: #2003850
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/41/871841/2 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/designate.py'],1,32542796676cbdf8a12a5bf0d966bf4d0a2b598c,bug/2003850," 'designate-api', 'apache2'] 'designate-api', 'apache2']", 'designate-api'] 'designate-api'],2,2
openstack%2Fcharm-magnum-dashboard~master~I8f4930312a04cf510d99fe86769497ad8a408914,openstack/charm-magnum-dashboard,master,I8f4930312a04cf510d99fe86769497ad8a408914,"Update bundles to use ""edge"" for mysql-* charms.",ABANDONED,2022-12-06 15:54:18.000000000,2023-01-30 23:22:24.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-06 15:54:18.000000000', 'files': ['src/tests/bundles/jammy-yoga.yaml', 'src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/5611b1c6e50b519a4105382eafe2450e7ff9f809', 'message': 'Update bundles to use ""edge"" for mysql-* charms.\n\nThis change drops the use of the ""8.0/edge"" track for the mysql-* charms\nin favor of just ""edge"" as a workaround of charmhub/juju issue that\nmakes ""--force"" not able of deploying those charms to a ""base"" that the\ncharm doesn\'t advertise as supported.\n\nAs part of this change also the \'source\' config option override is being\ndropped from mysql-innodb-cluster and rabbitmq-server.\n\nRelated-Bug: #1996794\nChange-Id: I8f4930312a04cf510d99fe86769497ad8a408914\n'}]",0,866755,5611b1c6e50b519a4105382eafe2450e7ff9f809,4,2,1,2424,,,0,"Update bundles to use ""edge"" for mysql-* charms.

This change drops the use of the ""8.0/edge"" track for the mysql-* charms
in favor of just ""edge"" as a workaround of charmhub/juju issue that
makes ""--force"" not able of deploying those charms to a ""base"" that the
charm doesn't advertise as supported.

As part of this change also the 'source' config option override is being
dropped from mysql-innodb-cluster and rabbitmq-server.

Related-Bug: #1996794
Change-Id: I8f4930312a04cf510d99fe86769497ad8a408914
",git fetch https://review.opendev.org/openstack/charm-magnum-dashboard refs/changes/55/866755/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/jammy-yoga.yaml', 'src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml']",3,5611b1c6e50b519a4105382eafe2450e7ff9f809,bug/1996794,comment: - 'machines section to decide order of deployment. database sooner = faster'applications: mysql-innodb-cluster: channel: edge '*mysql-router': channel: edge relations:, comment: - 'machines section to decide order of deployment. database sooner = faster' applications: relations: ,15,57
openstack%2Fcharm-designate~stable%2Fvictoria~I48a04ac619204ba109d87ca05de7cbe308592486,openstack/charm-designate,stable/victoria,I48a04ac619204ba109d87ca05de7cbe308592486,Add check to expose internal endpoints,MERGED,2023-01-09 16:48:36.000000000,2023-01-30 23:21:53.000000000,2023-01-30 23:21:53.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-09 16:48:36.000000000', 'files': ['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/ace9be35cbb30a3f2bcd941496e7bb122e380af3', 'message': 'Add check to expose internal endpoints\n\nCurrently, the charm ignores the use-internal-endpoints config\noption that is being inherited from the Openstack Layer. This\npatch adds a check to ensure that the internal endpoint is exposed\nif this is set to True.\n\nCloses-bug: #1995188\nChange-Id: I48a04ac619204ba109d87ca05de7cbe308592486\n(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)\n(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)\n(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)\n(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)\n(cherry picked from commit 9caf724caae86fdf474edc56eb280307521a6049)\n'}]",5,869461,ace9be35cbb30a3f2bcd941496e7bb122e380af3,16,4,1,14567,,,0,"Add check to expose internal endpoints

Currently, the charm ignores the use-internal-endpoints config
option that is being inherited from the Openstack Layer. This
patch adds a check to ensure that the internal endpoint is exposed
if this is set to True.

Closes-bug: #1995188
Change-Id: I48a04ac619204ba109d87ca05de7cbe308592486
(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)
(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)
(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)
(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)
(cherry picked from commit 9caf724caae86fdf474edc56eb280307521a6049)
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/61/869461/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py']",2,ace9be35cbb30a3f2bcd941496e7bb122e380af3,, if hookenv.config('use-internal-endpoints'): endpoint.expose_endpoint(instance.internal_url) else: endpoint.expose_endpoint(instance.public_url), endpoint.expose_endpoint(instance.public_url),11,2
openstack%2Fcharm-designate~stable%2Fwallaby~I48a04ac619204ba109d87ca05de7cbe308592486,openstack/charm-designate,stable/wallaby,I48a04ac619204ba109d87ca05de7cbe308592486,Add check to expose internal endpoints,MERGED,2022-12-07 13:02:05.000000000,2023-01-30 23:21:52.000000000,2023-01-30 23:21:52.000000000,"[{'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-07 13:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/0b4d1878d89c70a2b178e0c3310ae592494fd36e', 'message': 'Add check to expose internal endpoints\n\nCurrently, the charm ignores the use-internal-endpoints config\noption that is being inherited from the Openstack Layer. This\npatch adds a check to ensure that the internal endpoint is exposed\nif this is set to True.\n\nCloses-bug: #1995188\nChange-Id: I48a04ac619204ba109d87ca05de7cbe308592486\n(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)\n(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)\n(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)\n'}, {'number': 2, 'created': '2023-01-09 16:46:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/2a0ba167d6da73fb034e6ed7c2a982e4970a0605', 'message': 'Add check to expose internal endpoints\n\nCurrently, the charm ignores the use-internal-endpoints config\noption that is being inherited from the Openstack Layer. This\npatch adds a check to ensure that the internal endpoint is exposed\nif this is set to True.\n\nCloses-bug: #1995188\nChange-Id: I48a04ac619204ba109d87ca05de7cbe308592486\n(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)\n(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)\n(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)\n'}, {'number': 3, 'created': '2023-01-09 16:47:53.000000000', 'files': ['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/9caf724caae86fdf474edc56eb280307521a6049', 'message': 'Add check to expose internal endpoints\n\nCurrently, the charm ignores the use-internal-endpoints config\noption that is being inherited from the Openstack Layer. This\npatch adds a check to ensure that the internal endpoint is exposed\nif this is set to True.\n\nCloses-bug: #1995188\nChange-Id: I48a04ac619204ba109d87ca05de7cbe308592486\n(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)\n(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)\n(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)\n(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)\n'}]",2,866667,9caf724caae86fdf474edc56eb280307521a6049,14,4,3,14567,,,0,"Add check to expose internal endpoints

Currently, the charm ignores the use-internal-endpoints config
option that is being inherited from the Openstack Layer. This
patch adds a check to ensure that the internal endpoint is exposed
if this is set to True.

Closes-bug: #1995188
Change-Id: I48a04ac619204ba109d87ca05de7cbe308592486
(cherry picked from commit 8a4940bbb108124246ad3ae830964cf58dfc9ec3)
(cherry picked from commit 4d50f9ab40c8948771a7338949a84a3899c426d7)
(cherry picked from commit 1a0d3f4765ad359f6c9dd6d384377c859e7a36fe)
(cherry picked from commit 20381223c8a77cd021da74289af3a095da0de53f)
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/67/866667/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py']",2,0b4d1878d89c70a2b178e0c3310ae592494fd36e,, if hookenv.config('use-internal-endpoints'): endpoint.expose_endpoint(instance.internal_url) else: endpoint.expose_endpoint(instance.public_url), endpoint.expose_endpoint(instance.public_url),11,2
openstack%2Fopenstack-helm~master~Iccdfec9f30ef2cbe233beee1004a4cb1341f8b79,openstack/openstack-helm,master,Iccdfec9f30ef2cbe233beee1004a4cb1341f8b79,Imported Translations from Zanata,MERGED,2023-01-27 04:09:26.000000000,2023-01-30 23:08:12.000000000,2023-01-30 23:06:54.000000000,"[{'_account_id': 1004}, {'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 04:09:26.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1322aea8d0b6421cab148d42b0dab9c66528bea2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iccdfec9f30ef2cbe233beee1004a4cb1341f8b79\n'}]",0,871937,1322aea8d0b6421cab148d42b0dab9c66528bea2,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iccdfec9f30ef2cbe233beee1004a4cb1341f8b79
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/37/871937/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,1322aea8d0b6421cab148d42b0dab9c66528bea2,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-20 18:06+0000\n""""PO-Revision-Date: 2023-01-26 10:26+0000\n""msgid ""0.1.0-2249"" msgstr ""0.1.0-2249""msgid ""0.2.6 Remove default policy rules"" msgstr ""0.2.6 Remove default policy rules"" msgid ""0.2.7 Remove default policy rules"" msgstr ""0.2.7 Remove default policy rules"" msgid ""0.2.8 Add helm3 hook supports to allow things like terraform deploys"" msgstr ""0.2.8 Add helm3 hook supports to allow things like Terraform deploys"" msgid ""0.2.8 Remove default policy rules"" msgstr ""0.2.8 Remove default policy rules"" msgid ""0.3.0 Remove support for Train and Ussuri"" msgstr ""0.3.0 Remove support for Train and Ussuri"" msgid ""0.3.1 Added backoffLimit for bootstrap job"" msgstr ""0.3.1 Added backoffLimit for bootstrap job"" msgid ""0.3.1 Change ceph-config-helper image tag"" msgstr ""0.3.1 Change ceph-config-helper image tag"" msgid ""0.3.1 Fix container infra api version in values"" msgstr ""0.3.1 Fix container infra api version in values"" msgid ""0.3.1 Remove default policy rules"" msgstr ""0.3.1 Remove default policy rules"" msgid ""0.3.1 Remove support for Train and Ussuri"" msgstr ""0.3.1 Remove support for Train and Ussuri"" msgid ""0.3.2 Remove default policy rules"" msgstr ""0.3.2 Remove default policy rules"" msgid """" ""0.3.2 Use correct labels for ovs which uses one daemonset for ovs-db and ovs-"" ""vswitchd"" msgstr """" ""0.3.2 Use correct labels for ovs which uses one daemonset for ovs-db and ovs-"" ""vswitchd"" msgid ""0.3.3 Fix for creation endpoins and services when v1/v2 are disabled"" msgstr ""0.3.3 Fix for creation endpoins and services when v1/v2 are disabled"" msgid ""0.4.0 Remove support for Train and Ussuri"" msgstr ""0.4.0 Remove support for Train and Ussuri"" msgid ""0.4.1 Remove default policy rules"" msgstr ""0.4.1 Remove default policy rules"" ","""POT-Creation-Date: 2022-10-24 20:45+0000\n""""PO-Revision-Date: 2022-11-07 02:45+0000\n""msgid ""0.1.0-2236"" msgstr ""0.1.0-2236""",54,4
openstack%2Ftripleo-heat-templates~stable%2Ftrain~I1e21bf9cc1101f7ab2cfb4873470cfde63265023,openstack/tripleo-heat-templates,stable/train,I1e21bf9cc1101f7ab2cfb4873470cfde63265023,[Octavia] Set octavia *_log_targets params with tripleo-ansible,MERGED,2023-01-19 13:02:17.000000000,2023-01-30 23:05:21.000000000,2023-01-30 23:05:21.000000000,"[{'_account_id': 6681}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-19 13:02:17.000000000', 'files': ['deployment/octavia/octavia-base.yaml', 'deployment/octavia/octavia-deployment-config.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3fc2a25010d60b769f0e0a7132ef43b30e5e15f7', 'message': ""[Octavia] Set octavia *_log_targets params with tripleo-ansible\n\nDon't set admin_log_targets and tenant_log_targets through\npuppet-octavia.\nThese parameters are automatically computed by tripleo-ansible based on\nthe IP addresses of the controllers.\n\nOctaviaAdminLogTargets and OctaviaTenantLogTargets are now used by\ntripleo-ansible to create a rsyslog forwarder from the controllers to an\nexternal endpoint.\nThose params affect only the octavia-rsyslog container configuration and\nnot the octavia-worker config.\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/871084\n\nChange-Id: I1e21bf9cc1101f7ab2cfb4873470cfde63265023\n(cherry picked from commit 58dcc7b766c3a20c381b14df374e82828a663b79)\n(cherry picked from commit 31b84a821cdc4f671f789b74856544ccb80e4fa5)\n(cherry picked from commit 74d7800782415fcf7680180a3706c69939a0785b)\n""}]",1,871086,3fc2a25010d60b769f0e0a7132ef43b30e5e15f7,12,4,1,29244,,,0,"[Octavia] Set octavia *_log_targets params with tripleo-ansible

Don't set admin_log_targets and tenant_log_targets through
puppet-octavia.
These parameters are automatically computed by tripleo-ansible based on
the IP addresses of the controllers.

OctaviaAdminLogTargets and OctaviaTenantLogTargets are now used by
tripleo-ansible to create a rsyslog forwarder from the controllers to an
external endpoint.
Those params affect only the octavia-rsyslog container configuration and
not the octavia-worker config.

Depends-On: https://review.opendev.org/c/openstack/tripleo-ansible/+/871084

Change-Id: I1e21bf9cc1101f7ab2cfb4873470cfde63265023
(cherry picked from commit 58dcc7b766c3a20c381b14df374e82828a663b79)
(cherry picked from commit 31b84a821cdc4f671f789b74856544ccb80e4fa5)
(cherry picked from commit 74d7800782415fcf7680180a3706c69939a0785b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/871086/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/octavia/octavia-base.yaml', 'deployment/octavia/octavia-deployment-config.j2.yaml']",2,3fc2a25010d60b769f0e0a7132ef43b30e5e15f7,," OctaviaAdminLogTargets: default: [] description: List of syslog endpoints, host:port comma separated list, to receive administrative log messages. type: comma_delimited_list OctaviaTenantLogTargets: default: [] description: List of syslog endpoints, host:port comma separated list, to receive tenant traffic flow log messages. type: comma_delimited_list octavia_admin_log_targets: { get_param: OctaviaAdminLogTargets } octavia_tenant_log_targets: { get_param: OctaviaTenantLogTargets }",,12,12
openstack%2Fopenstack-helm-images~master~Ia1690386a17ba6ee697df59c861d4c9001a172c8,openstack/openstack-helm-images,master,Ia1690386a17ba6ee697df59c861d4c9001a172c8,[ceph-daemon] Add packages to the ceph-daemon image,MERGED,2023-01-26 20:42:58.000000000,2023-01-30 22:19:26.000000000,2023-01-30 22:18:27.000000000,"[{'_account_id': 3009}, {'_account_id': 8898}, {'_account_id': 21040}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 28372}, {'_account_id': 32190}, {'_account_id': 34520}]","[{'number': 1, 'created': '2023-01-26 20:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/20e1120d321496d5aa92888b844089ba9ee66d26', 'message': '[ceph-daemon] Add the lvm2 package to the ceph-daemon image\n\nLVM commands are required by the ceph-osd osd-init container and\nare not present in the latest Focal-based images. This change adds\nthe lvm2 package to the ceph-daemon image to make them available.\n\nChange-Id: Ia1690386a17ba6ee697df59c861d4c9001a172c8\n'}, {'number': 2, 'created': '2023-01-27 22:26:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f4de56b294312d1d07c42e8228ad30880fd9aec8', 'message': '[ceph-daemon] Add packages to the ceph-daemon image\n\nLVM commands and the ceph-volume command are required by the\nceph-osd osd-init container and are not present in the latest\nFocal-based images. This change adds the lvm2 and ceph-osd packages\nto the ceph-daemon image to make those commands available.\n\nChange-Id: Ia1690386a17ba6ee697df59c861d4c9001a172c8\n'}, {'number': 3, 'created': '2023-01-30 15:01:17.000000000', 'files': ['ceph-daemon/Dockerfile.ubuntu_focal'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/3b85ef600b8d49f7840081006fb625143dd56534', 'message': '[ceph-daemon] Add packages to the ceph-daemon image\n\nLVM commands and the ceph-volume command are required by the\nceph-osd osd-init container and are not present in the latest\nFocal-based images. This change adds the lvm2 and ceph-volume\npackages to the ceph-daemon image to make those commands available.\n\nChange-Id: Ia1690386a17ba6ee697df59c861d4c9001a172c8\n'}]",0,871852,3b85ef600b8d49f7840081006fb625143dd56534,18,8,3,29974,,,0,"[ceph-daemon] Add packages to the ceph-daemon image

LVM commands and the ceph-volume command are required by the
ceph-osd osd-init container and are not present in the latest
Focal-based images. This change adds the lvm2 and ceph-volume
packages to the ceph-daemon image to make those commands available.

Change-Id: Ia1690386a17ba6ee697df59c861d4c9001a172c8
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/52/871852/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_focal'],1,20e1120d321496d5aa92888b844089ba9ee66d26,871852, alien \ lvm2 ;\, alien ;\,2,1
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,openstack/tripleo-heat-templates,stable/train,Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,Support setting ovn-ofctrl-wait-before-clear,MERGED,2022-11-11 00:23:24.000000000,2023-01-30 22:15:52.000000000,2023-01-30 22:15:52.000000000,"[{'_account_id': 8297}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-11 00:23:24.000000000', 'files': ['deployment/ovn/ovn-controller-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/534efe0884c0e26a9aa1a34b13f923a1e4bc02a1', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\n Conflicts:\n\tdeployment/ovn/ovn-controller-container-puppet.yaml\n\nCo-Authored-By: David Hill <davidchill@hotmail.com>\nDepends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170\nChange-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7\n(cherry picked from commit ddaa270bd160f9cc7d8689a2470636eb25c14cb4)\n'}]",1,864239,534efe0884c0e26a9aa1a34b13f923a1e4bc02a1,9,4,1,5756,,,0,"Support setting ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

 Conflicts:
	deployment/ovn/ovn-controller-container-puppet.yaml

Co-Authored-By: David Hill <davidchill@hotmail.com>
Depends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170
Change-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7
(cherry picked from commit ddaa270bd160f9cc7d8689a2470636eb25c14cb4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/864239/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-controller-container-puppet.yaml'],1,534efe0884c0e26a9aa1a34b13f923a1e4bc02a1,ovn-ofctrl-wait-before-clear, OVNOfctrlWaitBeforeClear: description: > Sets the time ovn-controller will wait on startup before clearing all openflow rules and installing the new ones. type: number default: 8000 ovn::controller::ovn_ofctrl_wait_before_clear: {get_param: OVNOfctrlWaitBeforeClear},,7,0
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,openstack/tripleo-heat-templates,stable/wallaby,Ia2337e2f1802257f172ecf9e88995cd12ebc31d7,Support setting ovn-ofctrl-wait-before-clear,MERGED,2022-11-11 00:07:28.000000000,2023-01-30 22:15:48.000000000,2023-01-30 22:15:48.000000000,"[{'_account_id': 8297}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-11 00:07:28.000000000', 'files': ['deployment/ovn/ovn-controller-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fbaf55f23f3be600283681401302dbf864c61ba0', 'message': 'Support setting ovn-ofctrl-wait-before-clear\n\nSupport was added for this option [1] to avoid dataplane downtime\nduring ovn upgrades where schema changes have happened. This\nadds the ability for us to configure it.\n\n[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/\n\n Conflicts:\n\tdeployment/ovn/ovn-controller-container-puppet.yaml\n\nCo-Authored-By: David Hill <davidchill@hotmail.com>\nDepends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170\nChange-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7\n(cherry picked from commit ddaa270bd160f9cc7d8689a2470636eb25c14cb4)\n'}]",2,864237,fbaf55f23f3be600283681401302dbf864c61ba0,10,4,1,5756,,,0,"Support setting ovn-ofctrl-wait-before-clear

Support was added for this option [1] to avoid dataplane downtime
during ovn upgrades where schema changes have happened. This
adds the ability for us to configure it.

[1] https://patchwork.ozlabs.org/project/ovn/patch/20220808182845.2746916-2-mmichels@redhat.com/

 Conflicts:
	deployment/ovn/ovn-controller-container-puppet.yaml

Co-Authored-By: David Hill <davidchill@hotmail.com>
Depends-On: https://review.opendev.org/c/openstack/puppet-ovn/+/863170
Change-Id: Ia2337e2f1802257f172ecf9e88995cd12ebc31d7
(cherry picked from commit ddaa270bd160f9cc7d8689a2470636eb25c14cb4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/864237/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-controller-container-puppet.yaml'],1,fbaf55f23f3be600283681401302dbf864c61ba0,ovn-ofctrl-wait-before-clear, OVNOfctrlWaitBeforeClear: description: > Sets the time ovn-controller will wait on startup before clearing all openflow rules and installing the new ones. type: number default: 8000 ovn::controller::ovn_ofctrl_wait_before_clear: {get_param: OVNOfctrlWaitBeforeClear},,7,0
openstack%2Fcharm-guide~master~I3d4c5db75548a44072aa864f0bc3c97e4601997d,openstack/charm-guide,master,I3d4c5db75548a44072aa864f0bc3c97e4601997d,Add zed-jammy to charm delivery page,MERGED,2023-01-28 02:06:17.000000000,2023-01-30 22:06:54.000000000,2023-01-30 22:05:51.000000000,"[{'_account_id': 11805}, {'_account_id': 20870}, {'_account_id': 21107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-28 02:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/1b96b3a85a38d6e23049639cf114d046a2284619', 'message': 'Add zed-jammy to charm delivery page\n\nAdd zed track for jammy series on charm delivery page.\n\nNote that pacemaker-remote does not appear to have a\nstable revision on either focal or jammy.\n\nWe should probably not continue to state mulitple upstream\nversions just because they work but stick with a\nrecommended version (see OVN and Vault).\n\nChange-Id: I3d4c5db75548a44072aa864f0bc3c97e4601997d\n'}, {'number': 2, 'created': '2023-01-30 03:31:32.000000000', 'files': ['doc/source/project/charm-delivery.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/203c81abc66dbdfdb5a8e18c5420d4a76fff912a', 'message': 'Add zed-jammy to charm delivery page\n\nAdd zed track for jammy series on charm delivery page.\n\nNote that pacemaker-remote does not appear to have a\nstable revision on either focal or jammy.\n\nWe should probably not continue to state mulitple upstream\nversions just because they work but stick with a\nrecommended version (see OVN and Vault).\n\nChange-Id: I3d4c5db75548a44072aa864f0bc3c97e4601997d\n'}]",1,872057,203c81abc66dbdfdb5a8e18c5420d4a76fff912a,10,4,2,30561,,,0,"Add zed-jammy to charm delivery page

Add zed track for jammy series on charm delivery page.

Note that pacemaker-remote does not appear to have a
stable revision on either focal or jammy.

We should probably not continue to state mulitple upstream
versions just because they work but stick with a
recommended version (see OVN and Vault).

Change-Id: I3d4c5db75548a44072aa864f0bc3c97e4601997d
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/57/872057/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/project/charm-delivery.rst'],1,1b96b3a85a38d6e23049639cf114d046a2284619,add-zed-jammy-to-charm-delivery, - - ``zed`` - ``quincy`` - ``22.03`` - ``8.0`` - ``2.4`` - ``jammy`` - ``3.9`` - | ``1.7`` | ``1.8``,,10,0
openstack%2Fnova~master~I178700bf5ba172603593b1c9972520d05face849,openstack/nova,master,I178700bf5ba172603593b1c9972520d05face849,Persist existing node uuids locally,MERGED,2022-11-07 18:32:10.000000000,2023-01-30 22:03:03.000000000,2023-01-30 18:29:23.000000000,"[{'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78a3bc52f725eabfb9472332a15531ad881b69b3', 'message': 'WIP: Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 2, 'created': '2023-01-09 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83bdcee1064b9dc5f1b32cdc621b45ee35fd7b65', 'message': 'WIP: Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nThis is WIP because it needs more tests\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 3, 'created': '2023-01-10 18:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa35e72435c35efc270c983bfacdda780af666d7', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 4, 'created': '2023-01-10 18:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed6f44fa4ce212e39f7e7e58dc89bf6ddd04a975', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 5, 'created': '2023-01-10 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84170b9fe3155632bffe4f2f374f4bde6b097965', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 6, 'created': '2023-01-10 19:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8ceb5187992951f3723ad13259c048ca62079fc', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 7, 'created': '2023-01-11 20:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb9be8da05b5734d97d4814ae56a6fdfe3d3d262', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 8, 'created': '2023-01-11 20:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eb8d86f7f079b9afdd82a6c89d5b5946204a3ccf', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 9, 'created': '2023-01-12 21:20:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/70e7e4cf2362582b15b84581c65088d846384150', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 10, 'created': '2023-01-13 18:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a72ec13d1c1882a875e579923d58e3ebc0cce099', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 11, 'created': '2023-01-20 15:57:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa4ef3c27bf6a5cae182bd0bc9f75ca2f8fb2392', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}, {'number': 12, 'created': '2023-01-20 16:07:15.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/objects/service.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/53a925ff0f79fe822a96e1fadf552bb8d0f8e4b4', 'message': 'Persist existing node uuids locally\n\nIf we start up from an older service version, we need to look at the\ndatabase to determine what our node is and write it locally. This\nleap of faith will be the last time we need to look up our node based\non our hostname. Instead of relying on this, operators can (ideally)\npre-populate the compute node identities for maximum safety.\n\nChange-Id: I178700bf5ba172603593b1c9972520d05face849\n'}]",21,863918,53a925ff0f79fe822a96e1fadf552bb8d0f8e4b4,58,3,12,4393,,,0,"Persist existing node uuids locally

If we start up from an older service version, we need to look at the
database to determine what our node is and write it locally. This
leap of faith will be the last time we need to look up our node based
on our hostname. Instead of relying on this, operators can (ideally)
pre-populate the compute node identities for maximum safety.

Change-Id: I178700bf5ba172603593b1c9972520d05face849
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/863918/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/objects/service.py', 'nova/compute/manager.py']",3,78a3bc52f725eabfb9472332a15531ad881b69b3,bp/stable-compute-uuid,"from nova.objects import service as service_objimport nova.virt.node try: node_uuids = self.driver.get_available_node_uuids() ""service is starting on this host, then you can ignore "" ""this warning."") nodes = objects.ComputeNodeList.get_all_by_uuids(context, node_uuids) if not nodes: # NOTE(danms): This should only happen if the compute_id is # pre-provisioned on a host that has never started. LOG.warning('Compute nodes %s for host %s were not found in the ' 'database. If this is the first time this service is ' 'starting on this host, then you can ignore this ' 'warning.', node_uuids, self.host) return {} return {n.uuid: n for n in nodes} def _ensure_existing_node_identity(self, service_ref): """"""If we are upgrading from an older service version, we need to write our node identity uuid (if not already done) based on nodes assigned to us in the database. """""" if service_ref.version >= service_obj.NODE_IDENTITY_VERSION: # Already new enough, nothing to do here return if 'ironic' in CONF.compute_driver.lower(): # We do not persist a single local node identity for # ironic return if nova.virt.node.read_local_node_uuid(): # We already have a local node identity, no migration needed return context = nova.context.get_admin_context() db_nodes = objects.ComputeNodeList.get_all_by_host(context, self.host) if not db_nodes: # This means we have no nodes in the database (that we # know of) and thus have no need to record an existing # UUID. That is probably strange, so log a warning. raise exception.InvalidConfiguration( ('Upgrading from service version %i but found no ' 'nodes in the database for host %s to persist ' 'locally; Possible rename detected, ' 'refusing to start!') % ( service_ref.version, self.host)) return if len(db_nodes) > 1: # If this happens we can't do the right thing, so raise an # exception to abort host startup LOG.warning('Multiple nodes found in the database for host %s; ' 'unable to persist local node identity automatically') raise exception.InvalidConfiguration( 'Multiple nodes found in database, manual node uuid ' 'configuration required') nova.virt.node.write_local_node_uuid(db_nodes[0].uuid) if service_ref: # If we are an existing service, check to see if we need # to record a locally-persistent node identity because # we have upgraded from a previous version. self._ensure_existing_node_identity(service_ref) "," nodes_by_uuid = {} try: node_names = self.driver.get_available_nodes() ""service is starting on this host, then you can ignore this "" ""warning."") for node_name in node_names: try: node = objects.ComputeNode.get_by_host_and_nodename( context, self.host, node_name) nodes_by_uuid[node.uuid] = node except exception.ComputeHostNotFound: LOG.warning( ""Compute node %s not found in the database. If this is "" ""the first time this service is starting on this host, "" ""then you can ignore this warning."", node_name) return nodes_by_uuid",90,31
openstack%2Frally~master~Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011,openstack/rally,master,Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011,Pin SQLAlchemy to <2.0.0,MERGED,2023-01-27 14:24:03.000000000,2023-01-30 21:47:04.000000000,2023-01-30 21:47:04.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}, {'_account_id': 34437}]","[{'number': 1, 'created': '2023-01-27 14:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/05f1cf2fd5197c6a8919526eef07185dbe6747f0', 'message': ""Pin SQLAlchemy to <2.0.0\n\nRally code is not compatible with SQLAlchemy-2.0.0,\nuntil it's compatible let's pin it.\n\nRelated-Bug: #2004022\nChange-Id: Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011\n""}, {'number': 2, 'created': '2023-01-30 11:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/382de2d55a894184226c236c1266b37ebe8c4820', 'message': ""Pin SQLAlchemy to <2.0.0\n\nRally code is not compatible with SQLAlchemy-2.0.0,\nuntil it's compatible let's pin it.\n\nCI jobs are broken with multiple errors, so to get\nthis in also need following fixes:-\n- Remove python-dev from bindep to fix announce-release\n  and docs jobs\n- Update upper-constraints for testtools to 2.5.0 to fix\n  issues with python3.10+\n- Update tox.ini for tox4 compatibility\n- Ignore warnings introdueced with oslo.db-12.1.0,\n  SQLAlchemy-1.4.46\n\nRelated-Bug: #2004022\nChange-Id: Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011\n""}, {'number': 3, 'created': '2023-01-30 11:55:20.000000000', 'files': ['requirements.txt', 'bindep.txt', '.zuul.d/zuul.yaml', 'upper-constraints.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/rally/commit/14d449b2f1bc51416053d1e6bdd1a5cd915e527a', 'message': ""Pin SQLAlchemy to <2.0.0\n\nRally code is not compatible with SQLAlchemy-2.0.0,\nuntil it's compatible let's pin it.\n\nCI jobs are broken with multiple errors, so to get\nthis in also need following fixes:-\n- Remove python-dev from bindep to fix announce-release\n  and docs jobs\n- Update upper-constraints for testtools to 2.5.0 to fix\n  issues with python3.10+\n- Update tox.ini for tox4 compatibility\n- Ignore warnings introdueced with oslo.db-12.1.0,\n  SQLAlchemy-1.4.46\n- Make tox-cover job non-voting as to get it passing\n  coverage report need to succeed for previous commit,\n  which will not succeed without the required changes\n  in this patch. It will be made voting again in follow\n  up patch.\n\nRelated-Bug: #2004022\nChange-Id: Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011\n""}]",3,872021,14d449b2f1bc51416053d1e6bdd1a5cd915e527a,12,3,3,13861,,,0,"Pin SQLAlchemy to <2.0.0

Rally code is not compatible with SQLAlchemy-2.0.0,
until it's compatible let's pin it.

CI jobs are broken with multiple errors, so to get
this in also need following fixes:-
- Remove python-dev from bindep to fix announce-release
  and docs jobs
- Update upper-constraints for testtools to 2.5.0 to fix
  issues with python3.10+
- Update tox.ini for tox4 compatibility
- Ignore warnings introdueced with oslo.db-12.1.0,
  SQLAlchemy-1.4.46
- Make tox-cover job non-voting as to get it passing
  coverage report need to succeed for previous commit,
  which will not succeed without the required changes
  in this patch. It will be made voting again in follow
  up patch.

Related-Bug: #2004022
Change-Id: Ifcffd11e300e1485fdbfa54b23bcdcaa6ad61011
",git fetch https://review.opendev.org/openstack/rally refs/changes/21/872021/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,05f1cf2fd5197c6a8919526eef07185dbe6747f0,bug/2004022,"SQLAlchemy!=1.1.5,!=1.1.6,!=1.1.7,!=1.1.8,<2.0.0 # MIT","SQLAlchemy!=1.1.5,!=1.1.6,!=1.1.7,!=1.1.8 # MIT",1,1
openstack%2Fswift~stable%2Fyoga~I4786371314daa3f37e33f97defed43d1cec887ba,openstack/swift,stable/yoga,I4786371314daa3f37e33f97defed43d1cec887ba,Authors/ChangeLog for 2.29.2,ABANDONED,2023-01-30 21:34:03.000000000,2023-01-30 21:41:31.000000000,,[],"[{'number': 1, 'created': '2023-01-30 21:34:03.000000000', 'files': ['CHANGELOG', 'releasenotes/notes/2_29_2_release-de619e50f10cc413.yaml', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/d1aba58d3b668231abae5875eb4c05a536ce8b46', 'message': 'Authors/ChangeLog for 2.29.2\n\nChange-Id: I4786371314daa3f37e33f97defed43d1cec887ba\n'}]",2,872221,d1aba58d3b668231abae5875eb4c05a536ce8b46,3,0,1,15343,,,0,"Authors/ChangeLog for 2.29.2

Change-Id: I4786371314daa3f37e33f97defed43d1cec887ba
",git fetch https://review.opendev.org/openstack/swift refs/changes/21/872221/1 && git format-patch -1 --stdout FETCH_HEAD,"['CHANGELOG', 'releasenotes/notes/2_29_2_release-de619e50f10cc413.yaml', 'AUTHORS']",3,d1aba58d3b668231abae5875eb4c05a536ce8b46,,Thibault Person (thibault.person@ovhcloud.com),,24,0
openstack%2Fmanila~master~Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d,openstack/manila,master,Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d,"db: Migrate ""quota usage"" APIs to enginefacade",MERGED,2022-09-06 14:59:10.000000000,2023-01-30 21:33:52.000000000,2023-01-30 21:31:36.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-09-06 14:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9e4c9b9e877cfdee052a4a2837102280785654e6', 'message': 'db: Migrate ""quota usage"" APIs to enginefacade\n\nMigrate quota usage-related APIs from the legacy enginefacade to the\nmodern context-based enginefacade.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d\n'}, {'number': 2, 'created': '2022-09-07 23:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/4cb47d7ce88219df622a0059e2a71d480e09796f', 'message': 'db: Migrate ""quota usage"" APIs to enginefacade\n\nMigrate quota usage-related APIs from the legacy enginefacade to the\nmodern context-based enginefacade.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d\n'}, {'number': 3, 'created': '2022-09-08 10:50:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/20ae0039b7693cc1750bbbd6b76563bc79e99161', 'message': 'db: Migrate ""quota usage"" APIs to enginefacade\n\nMigrate quota usage-related APIs from the legacy enginefacade to the\nmodern context-based enginefacade.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d\n'}, {'number': 4, 'created': '2022-12-21 12:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cc280fef0d52f9981261df0e24cdc183895492a3', 'message': 'db: Migrate ""quota usage"" APIs to enginefacade\n\nMigrate quota usage-related APIs from the legacy enginefacade to the\nmodern context-based enginefacade.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d\n'}, {'number': 5, 'created': '2023-01-30 11:59:52.000000000', 'files': ['manila/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/4042d7027385210a7c734d9f9eca519e7ccb2bfa', 'message': 'db: Migrate ""quota usage"" APIs to enginefacade\n\nMigrate quota usage-related APIs from the legacy enginefacade to the\nmodern context-based enginefacade.\n\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\nChange-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d\n'}]",236,856147,4042d7027385210a7c734d9f9eca519e7ccb2bfa,39,3,5,15334,,,0,"db: Migrate ""quota usage"" APIs to enginefacade

Migrate quota usage-related APIs from the legacy enginefacade to the
modern context-based enginefacade.

Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
Change-Id: Ib7f5402b4a9c94290e14ebc9b76700cbf517de4d
",git fetch https://review.opendev.org/openstack/manila refs/changes/47/856147/4 && git format-patch -1 --stdout FETCH_HEAD,['manila/db/sqlalchemy/api.py'],1,9e4c9b9e877cfdee052a4a2837102280785654e6,sqlalchemy-20,"@context_manager.reader@context_manager.reader@context_manager.reader@context_manager.reader# TODO(stephenfin): Remove session argument once all callers have been # converted@context_manager.writer context, project_id, user_id, resource, in_use, reserved, until_refresh, share_type_id=share_type_id, session=context.session, )@context_manager.writer"," session = get_session() context, project_id, user_id, resource, in_use, reserved, until_refresh, share_type_id=share_type_id, session=session)",18,3
openstack%2Fcharm-designate~master~I0d4fea182da1316c0c30c143e64fcd2ca682afff,openstack/charm-designate,master,I0d4fea182da1316c0c30c143e64fcd2ca682afff,Prevent update-status to run unrequired handlers,MERGED,2023-01-30 10:45:22.000000000,2023-01-30 20:55:58.000000000,2023-01-30 20:55:58.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 10:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/ff7cee2ea6622dd8a8daab56f9f3b81d19595c38', 'message': 'Prevent update-status to run unrequired handlers\n\nBefore, the update-status hook would run many handlers\nthat would have been normally done only during\nconfiguration changes.\nConsequently it creates an impact on the service and\napply changes every time the hook is triggered, which is\nin most deployments every 5 minutes.\nThis prevents the DNS zones managed by Designate to be\nupdated constantly and potentially avoid race conditions\nwithin designate components.\n\nCloses-bug: #2003528\nChange-Id: I0d4fea182da1316c0c30c143e64fcd2ca682afff\n'}, {'number': 2, 'created': '2023-01-30 11:19:04.000000000', 'files': ['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/f84cee2634e6d9605fd154be40f2c04426eba01e', 'message': 'Prevent update-status to run unrequired handlers\n\nBefore, the update-status hook would run many handlers\nthat would have been normally done only during\nconfiguration changes.\nConsequently it creates an impact on the service and\napply changes every time the hook is triggered, which is\nin most deployments every 5 minutes.\nThis prevents the DNS zones managed by Designate to be\nupdated constantly and potentially avoid race conditions\nwithin designate components.\n\nCloses-bug: #2003528\nChange-Id: I0d4fea182da1316c0c30c143e64fcd2ca682afff\n'}]",2,872151,f84cee2634e6d9605fd154be40f2c04426eba01e,11,3,2,34232,,,0,"Prevent update-status to run unrequired handlers

Before, the update-status hook would run many handlers
that would have been normally done only during
configuration changes.
Consequently it creates an impact on the service and
apply changes every time the hook is triggered, which is
in most deployments every 5 minutes.
This prevents the DNS zones managed by Designate to be
updated constantly and potentially avoid race conditions
within designate components.

Closes-bug: #2003528
Change-Id: I0d4fea182da1316c0c30c143e64fcd2ca682afff
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/51/872151/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_designate_handlers.py', 'src/reactive/designate_handlers.py']",2,ff7cee2ea6622dd8a8daab56f9f3b81d19595c38,reactive-update-status,@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook')@reactive.when_not('is-update-status-hook'),,16,1
openstack%2Fcharm-designate~master~I6dba64157cc7ad9468d15921f259b045a735341d,openstack/charm-designate,master,I6dba64157cc7ad9468d15921f259b045a735341d,Fix charm for tox4 compatibility,MERGED,2023-01-17 09:33:04.000000000,2023-01-30 20:55:57.000000000,2023-01-30 20:55:57.000000000,"[{'_account_id': 2424}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 09:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/9489f60ef016c4d868a8678783eb1cd3f723f15f', 'message': 'Fix charm for tox4 compatibility\n\nRelated-Bug: 2002788\nChange-Id: I6dba64157cc7ad9468d15921f259b045a735341d\n'}, {'number': 2, 'created': '2023-01-17 14:56:07.000000000', 'files': ['osci.yaml', 'src/tests/bundles/jammy-yoga.yaml', 'build-requirements.txt', 'src/tox.ini', 'pip.sh', 'charmcraft.yaml', 'src/test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/ea0c1da551e6be7ee4944adff91330e459da5da7', 'message': 'Fix charm for tox4 compatibility\n\nRelated-Bug: 2002788\nChange-Id: I6dba64157cc7ad9468d15921f259b045a735341d\n'}]",6,870753,ea0c1da551e6be7ee4944adff91330e459da5da7,17,3,2,12549,,,0,"Fix charm for tox4 compatibility

Related-Bug: 2002788
Change-Id: I6dba64157cc7ad9468d15921f259b045a735341d
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/53/870753/2 && git format-patch -1 --stdout FETCH_HEAD,"['osci.yaml', 'src/tests/bundles/jammy-yoga.yaml', 'build-requirements.txt', 'src/tox.ini', 'pip.sh', 'charmcraft.yaml', 'src/test-requirements.txt', 'tox.ini']",8,9489f60ef016c4d868a8678783eb1cd3f723f15f,tox4-compat,"# We use tox mainly for virtual environment management for test requirements # and do not install the charm code as a Python package into that environment. # Ref: https://tox.wiki/en/latest/config.html#skip_install skip_install = True CHARM_LAYERS_DIR={toxinidir}/layers CHARM_INTERFACES_DIR={toxinidir}/interfacespassenv = no_proxy http_proxy https_proxy CHARM_INTERFACES_DIR CHARM_LAYERS_DIR JUJU_REPOSITORY rename.sh# charmcraft clean is done to ensure that # `tox -e build` always performs a clean, repeatable build. # For faster rebuilds during development, # directly run `charmcraft -v pack && ./rename.sh`. {toxinidir}/rename.sh charmcraft clean","skipsdist = True# NOTE: https://wiki.canonical.com/engineering/OpenStack/InstallLatestToxOnOsci minversion = 3.18.0 passenv = no_proxy http_proxy https_proxy JUJU_REPOSITORY # We can stop using pip.sh when charmcraft snap includes new version of git: # https://github.com/canonical/charmcraft/issues/875 install_command = {toxinidir}/pip.sh install {opts} {packages}deps = -r{toxinidir}/build-requirements.txt[testenv:func-target] # Hack to get functional tests working in the charmcraft # world. We should fix this. basepython = python3 passenv = HOME TERM CS_* OS_* TEST_* deps = -r{toxinidir}/src/test-requirements.txt changedir = {toxinidir}/src commands = bash -c ""if [ ! -f ../*.charm ]; then echo 'Charm does not exist. Run tox -e build'; exit 1; fi"" tox --version tox -e func-target {posargs} ",39,88
openstack%2Fcharm-magnum-dashboard~stable%2Fzed~I8a81c09ce804b7cd70c645f2e32834dbff9a90d5,openstack/charm-magnum-dashboard,stable/zed,I8a81c09ce804b7cd70c645f2e32834dbff9a90d5,Updates for zed stable branch creation,MERGED,2022-10-14 16:06:48.000000000,2023-01-30 20:00:05.000000000,2023-01-30 20:00:05.000000000,"[{'_account_id': 935}, {'_account_id': 2424}, {'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-14 16:06:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/0e4c2159898fa9cf970933c28ade3ef4a756fb0d', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 2, 'created': '2022-10-21 02:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/744dd5d96e71e24f5f9f4ab3008825050a387a10', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 3, 'created': '2022-10-26 18:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/e45dff754cea46a7a45069cf71fe54cf9a38cbd3', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 4, 'created': '2022-10-26 18:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/c334f9b01de2a66086cc4c49383a36d8c8a3b6fd', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 5, 'created': '2022-10-27 01:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/a098fae300d69af2096d2195d7e997bbfa4a7eda', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 6, 'created': '2023-01-17 20:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/e38e77b2a9d5076d963996bdc3557a183d040481', 'message': 'Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n'}, {'number': 7, 'created': '2023-01-18 17:12:50.000000000', 'files': ['src/tests/bundles/jammy-yoga.yaml', '.gitreview', 'test-requirements.txt', 'src/wheelhouse.txt', 'charmcraft.yaml', 'src/test-requirements.txt', 'src/build.lock', 'src/tests/bundles/jammy-zed.yaml', 'tox.ini', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-magnum-dashboard/commit/09d8f05fc6c5394f9af91dc07824fe8ceb4006a6', 'message': ""Updates for zed stable branch creation\n\n- Set default branch for git review/gerrit to stable/zed\n- Switch tests to stable.\n- Switch to using stable charm-helpers branch.\n- Switch to using stable charm.openstack branch.\n- Switch to using stable zaza, zaza-openstack-tests\n  branch\n- (reactive charms) Add build.lock file\n- (classic charms) make sync\n- (reactive: not reactive plugin): lock charm-tools < 3.1\n- (reactive: with reactive plugin): lock charm snap to 3.x/stable\n- pin tox < 4.0.0 (more below)\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nChange-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5\n""}]",9,861430,09d8f05fc6c5394f9af91dc07824fe8ceb4006a6,38,6,7,20870,,,0,"Updates for zed stable branch creation

- Set default branch for git review/gerrit to stable/zed
- Switch tests to stable.
- Switch to using stable charm-helpers branch.
- Switch to using stable charm.openstack branch.
- Switch to using stable zaza, zaza-openstack-tests
  branch
- (reactive charms) Add build.lock file
- (classic charms) make sync
- (reactive: not reactive plugin): lock charm-tools < 3.1
- (reactive: with reactive plugin): lock charm snap to 3.x/stable
- pin tox < 4.0.0 (more below)

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Change-Id: I8a81c09ce804b7cd70c645f2e32834dbff9a90d5
",git fetch https://review.opendev.org/openstack/charm-magnum-dashboard refs/changes/30/861430/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/jammy-yoga.yaml', '.gitreview', 'test-requirements.txt', 'src/wheelhouse.txt', 'charmcraft.yaml', 'src/test-requirements.txt', 'src/build.lock', 'src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml']",9,0e4c2159898fa9cf970933c28ade3ef4a756fb0d,pin-tox, channel: 3.9/edge channel: zed/edge channel: zed/edge channel: zed/edge, channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge,196,18
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Ib49223709e20931abcec4d16301db9882c64c06f,openstack/tripleo-heat-templates,stable/wallaby,Ib49223709e20931abcec4d16301db9882c64c06f,Replace qdrouterd backend with rabbitmq in Sc03,MERGED,2023-01-24 14:22:19.000000000,2023-01-30 19:55:06.000000000,2023-01-30 19:55:06.000000000,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2023-01-24 14:22:19.000000000', 'files': ['ci/environments/scenario003-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c75349244c37863e85ecb0b9d99347bd5cceffae', 'message': ""Replace qdrouterd backend with rabbitmq in Sc03\n\nqdrouterd for RPC is not a supported backend in RHOSP,\nupdating sc03 to test rabbitmq which is a supported\nbackend for RPC communication.\n\nTrying to run with qdrouterd backend in downstream fails\nbecause python-pyngus is not added as dependency downstream[1]\npython-pyngus available since RHOSP13 but is not added as dep\nfor oslo-messaging rpm with reasoning[2].\n\n~~~\n ModuleNotFoundError: No module named 'pyngus'\n~~~\n\nSc03 provides desginate testing coverage, This change will\nallow us to run standalone sc03 in downstream pipelines keeping\nsc03 env files in sync in upstream and downstream.\n\nThis patch will be backported to wallaby.\n\n[1] https://github.com/rdo-packages/oslo-messaging-distgit/blob/wallaby-rdo/python-oslo-messaging.spec#L89-L91\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=1791364#c13\n\nChange-Id: Ib49223709e20931abcec4d16301db9882c64c06f\n(cherry picked from commit 9962b52a0a2ff93d57e9d1dff8a03d70991df1a8)\n(cherry picked from commit 382e76fe9d52ec0c22cfb5f90ec26e8936303c0b)\n""}]",5,871555,c75349244c37863e85ecb0b9d99347bd5cceffae,14,5,1,29775,,,0,"Replace qdrouterd backend with rabbitmq in Sc03

qdrouterd for RPC is not a supported backend in RHOSP,
updating sc03 to test rabbitmq which is a supported
backend for RPC communication.

Trying to run with qdrouterd backend in downstream fails
because python-pyngus is not added as dependency downstream[1]
python-pyngus available since RHOSP13 but is not added as dep
for oslo-messaging rpm with reasoning[2].

~~~
 ModuleNotFoundError: No module named 'pyngus'
~~~

Sc03 provides desginate testing coverage, This change will
allow us to run standalone sc03 in downstream pipelines keeping
sc03 env files in sync in upstream and downstream.

This patch will be backported to wallaby.

[1] https://github.com/rdo-packages/oslo-messaging-distgit/blob/wallaby-rdo/python-oslo-messaging.spec#L89-L91
[2] https://bugzilla.redhat.com/show_bug.cgi?id=1791364#c13

Change-Id: Ib49223709e20931abcec4d16301db9882c64c06f
(cherry picked from commit 9962b52a0a2ff93d57e9d1dff8a03d70991df1a8)
(cherry picked from commit 382e76fe9d52ec0c22cfb5f90ec26e8936303c0b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/55/871555/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario003-standalone.yaml'],1,c75349244c37863e85ecb0b9d99347bd5cceffae,, OS::TripleO::Services::OsloMessagingRpc: ../../deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml, OS::TripleO::Services::OsloMessagingRpc: ../../deployment/messaging/rpc-qdrouterd-container-puppet.yaml RpcPort: 31459,1,2
openstack%2Fkolla~stable%2Fyoga~I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0,openstack/kolla,stable/yoga,I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0,influxdb: Update gpg key,MERGED,2023-01-30 16:19:55.000000000,2023-01-30 19:25:53.000000000,2023-01-30 19:24:58.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2023-01-30 16:19:55.000000000', 'files': ['docker/base/Dockerfile.j2', 'docker/base/influxdb.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/f3234d17d655e48208284369a169a9788eda50d4', 'message': 'influxdb: Update gpg key\n\nInflux repo gpg key has been rotated as of of 2023-01-26 [1].\n\n[1]: https://www.influxdata.com/blog/linux-package-signing-key-rotation/\n\nDepends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/871821\n\nChange-Id: I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0\n(cherry picked from commit ab70c7618b3b7e025759fe38c8692f66ef420b15)\n'}]",0,872120,f3234d17d655e48208284369a169a9788eda50d4,9,3,1,22629,,,0,"influxdb: Update gpg key

Influx repo gpg key has been rotated as of of 2023-01-26 [1].

[1]: https://www.influxdata.com/blog/linux-package-signing-key-rotation/

Depends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/871821

Change-Id: I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0
(cherry picked from commit ab70c7618b3b7e025759fe38c8692f66ef420b15)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/20/872120/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'docker/base/influxdb.repo']",2,f3234d17d655e48208284369a169a9788eda50d4,,gpgkey = https://repos.influxdata.com/influxdata-archive_compat.key,gpgkey = https://repos.influxdata.com/influxdb.key,2,2
openstack%2Ftripleo-ansible~master~I9eda195d4ff862a4b7a2b9c536afbd977ecfc632,openstack/tripleo-ansible,master,I9eda195d4ff862a4b7a2b9c536afbd977ecfc632,Add missing neutron vars for tripleo-standalone-vars,MERGED,2023-01-18 11:47:58.000000000,2023-01-30 18:51:30.000000000,2023-01-30 18:51:30.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-18 11:47:58.000000000', 'files': ['scripts/tripleo-standalone-vars'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6cb8206479e1d8249550aa719f2228501b652f79', 'message': 'Add missing neutron vars for tripleo-standalone-vars\n\nIt adds the controlplane missing vars which are needed\nfor configuring the ovn part.\n\nChange-Id: I9eda195d4ff862a4b7a2b9c536afbd977ecfc632\n'}]",0,870001,6cb8206479e1d8249550aa719f2228501b652f79,9,3,1,34118,,,0,"Add missing neutron vars for tripleo-standalone-vars

It adds the controlplane missing vars which are needed
for configuring the ovn part.

Change-Id: I9eda195d4ff862a4b7a2b9c536afbd977ecfc632
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/01/870001/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo-standalone-vars'],1,6cb8206479e1d8249550aa719f2228501b652f79,standalone-roles," 'tripleo_ovn_metadata_agent_DEFAULT_transport_url': { 'template': 'rabbit://' '{% for node in oslo_messaging_rpc_node_names %}' '{% if not loop.first %},{% endif %}' '{{oslo_messaging_rpc_user_name}}:{{oslo_messaging_rpc_password}}' '@{{node}}:5672' '{% endfor %}' '/?ssl={% if oslo_messaging_rpc_use_ssl==""True"" %}1' '{% else %}0{% endif %}', 'section': 'DEFAULT', 'option': 'transport_url' }, 'tripleo_ovn_metadata_agent_oslo_messaging_notifications_transport_url': { 'template': 'rabbit://' '{% for node in oslo_messaging_rpc_node_names %}' '{% if not loop.first %},{% endif %}' '{{oslo_messaging_rpc_user_name}}:{{oslo_messaging_rpc_password}}' '@{{node}}:5672' '{% endfor %}' '/?ssl={% if oslo_messaging_rpc_use_ssl==""True"" %}1' '{% else %}0{% endif %}', 'section': 'oslo_messaging_notifications', 'option': 'transport_url' }, 'tripleo_ovn_metadata_agent_database_connection': { 'template': '{{ neutron_database_connection }}', 'section': 'database', 'option': 'connection' }, 'tripleo_ovn_metadata_agent_keystone_www_authenticate_uri': { 'template': '{{ neutron_keystone_auth_uri }}', 'section': 'keystone_authtoken', 'option': 'www_authenticate_uri' }, 'tripleo_ovn_metadata_agent_keystone_auth_url': { 'template': '{{ neutron_keystone_auth_url }}', 'section': 'keystone_authtoken', 'option': 'auth_url' }, 'tripleo_ovn_metadata_agent_keystone_password': { 'template': '{{ neutron_keystone_password }}', 'section': 'keystone_authtoken', 'option': 'password' }, 'tripleo_ovn_metadata_agent_placement_password': { 'template': '{{ neutron_placement_password }}', 'section': 'placement', 'option': 'password' }, 'tripleo_ovn_metadata_agent_nova_auth_url': { 'template': '{{ neutron_nova_auth_url }}', 'section': 'nova', 'option': 'auth_url' }, 'tripleo_ovn_metadata_agent_nova_password': { 'template': '{{ neutron_nova_password }}', 'section': 'nova', 'option': 'password' }, 'tripleo_ovn_metadata_agent_placement_auth_url': { 'template': '{{ neutron_placement_auth_url }}', 'section': 'placement', 'option': 'auth_url' }, 'tripleo_ovn_metadata_agent_metadata_agent_DEFAULT_nova_metadata_host': { 'template': '{{ neutron_metadata_host }}', 'section': 'DEFAULT', 'option': 'nova_metadata_host' }, 'tripleo_ovn_metadata_agent_metadata_agent_DEFAULT_metadata_proxy_shared_secret': { 'template': '{{ neutron_metadata_shared_secret }}', 'section': 'DEFAULT', 'option': 'metadata_proxy_shared_secret' }, 'placement_region_name': { 'file': 'group_vars/{role}', 'key': 'service_configs.nova::placement::region_name' }, 'neutron_database_connection': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::db::database_connection' }, 'neutron_keystone_auth_uri': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::keystone::authtoken::www_authenticate_uri' }, #'neutron_keystone_memcached_servers': { # 'file': 'group_vars/{role}', # 'key': 'service_configs.neutron::keystone::authtoken::memc' #}, 'neutron_keystone_auth_url': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::keystone::authtoken::auth_url' }, 'neutron_keystone_password': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::keystone::authtoken::password' }, 'neutron_placement_password': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::server::placement::password' }, 'neutron_placement_auth_url': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::server::placement::auth_url' }, 'neutron_nova_password': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::server::notifications::nova::password' }, 'neutron_nova_auth_url': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::server::notifications::nova::auth_url' }, 'neutron_metadata_host': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::agents::ovn_metadata::metadata_host' }, 'neutron_metadata_shared_secret': { 'file': 'group_vars/{role}', 'key': 'service_configs.neutron::agents::ovn_metadata::shared_secret' },"," 'placement_region_name': { 'file': 'group_vars/{role}', 'key': 'service_configs.nova::placement::region_name' },",125,4
openstack%2Ftripleo-ansible~stable%2Fwallaby~I994bd597d0425a4cd5988f7570eaacc300b6b2e4,openstack/tripleo-ansible,stable/wallaby,I994bd597d0425a4cd5988f7570eaacc300b6b2e4,[Octavia] Create a rsyslog forward when *_log_targets params are set,MERGED,2023-01-17 14:17:50.000000000,2023-01-30 18:51:27.000000000,2023-01-30 18:51:27.000000000,"[{'_account_id': 6681}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-17 14:17:50.000000000', 'files': ['tripleo_ansible/playbooks/octavia-files.yaml', 'tripleo_ansible/roles/octavia_controller_post_config/templates/10-octavia.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/925268f2602c8caf8f2ed2b12ee604a357b19a83', 'message': '[Octavia] Create a rsyslog forward when *_log_targets params are set\n\nIf a user sets the OctaviaAdminLogTargets param or the\nOctaviaTenantLogTargets param (from [0]), the\noctavia_controller_post_config role now creates a rsyslog forwarder on\nthe controllers, that redirects messages to those targets.\n\n[0] I1e21bf9cc1101f7ab2cfb4873470cfde63265023\n\nChange-Id: I994bd597d0425a4cd5988f7570eaacc300b6b2e4\n(cherry picked from commit 5fd009c5a669e043a5fd727122fffb8fd948f4e8)\n(cherry picked from commit 2075001834c8f1308c006c5186e0acf40fcb3787)\n'}]",1,870814,925268f2602c8caf8f2ed2b12ee604a357b19a83,12,4,1,29244,,,0,"[Octavia] Create a rsyslog forward when *_log_targets params are set

If a user sets the OctaviaAdminLogTargets param or the
OctaviaTenantLogTargets param (from [0]), the
octavia_controller_post_config role now creates a rsyslog forwarder on
the controllers, that redirects messages to those targets.

[0] I1e21bf9cc1101f7ab2cfb4873470cfde63265023

Change-Id: I994bd597d0425a4cd5988f7570eaacc300b6b2e4
(cherry picked from commit 5fd009c5a669e043a5fd727122fffb8fd948f4e8)
(cherry picked from commit 2075001834c8f1308c006c5186e0acf40fcb3787)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/14/870814/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/playbooks/octavia-files.yaml', 'tripleo_ansible/roles/octavia_controller_post_config/templates/10-octavia.conf.j2']",2,925268f2602c8caf8f2ed2b12ee604a357b19a83,,"{% macro forwarder(type, log_targets) %} {% if (log_targets|length) > 0 %} ruleset(name=""{{ type }}_forwarding"" queue.type=""linkedList"" queue.size=""10000"") { {% for target in log_targets %} action(type=""omfwd"" {%- set host, port = target.split(':') -%} target=""{{ host }}"" port=""{{ port }}"" protocol=""{{ log_offload_protocol }}"" action.resumeRetryCount=""5"" action.resumeInterval=""2"" {% if not loop.first %}action.execOnlyWhenPreviousIsSuspended=""on""{%- endif %} ) {% endfor %} } {% endif %} {% endmacro %} {{ forwarder('tenant', tenant_log_targets) }} {{ forwarder('admin', admin_log_targets) }} {% if (tenant_log_targets|length) > 0 %} call tenant_forwarding {% endif %}{% if (admin_log_targets|length) > 0 %} call admin_forwarding {% endif %}",,29,0
openstack%2Fcinder~master~I49ac061011293900b04a7a5b90ff5b840521993d,openstack/cinder,master,I49ac061011293900b04a7a5b90ff5b840521993d,Hitachi and OEM: Support multi pool,MERGED,2022-06-22 11:39:05.000000000,2023-01-30 18:48:13.000000000,2023-01-27 14:38:20.000000000,"[{'_account_id': 5314}, {'_account_id': 14806}, {'_account_id': 22348}, {'_account_id': 22879}, {'_account_id': 27615}, {'_account_id': 28403}]","[{'number': 1, 'created': '2022-06-22 11:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e205e008d3f1754d9da2920f3b7a0aa245c59a95', 'message': 'Hitachi and OEM: Support multi pool\n\nThis patch support multi pool for Hitachi VSP driver and NEC V driver.\n\nImplements: blueprint hitachi-vsp-add-multi-pool\nChange-Id: I49ac061011293900b04a7a5b90ff5b840521993d\n'}, {'number': 2, 'created': '2022-10-17 02:32:32.000000000', 'files': ['cinder/volume/drivers/nec/v/nec_v_rest.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_fc.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_iscsi.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_iscsi.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_iscsi.py', 'releasenotes/notes/hitachi-vsp-add-multi-pool-4c4589b93399e641.yaml', 'cinder/volume/drivers/hitachi/hbsd_utils.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_rest.py', 'cinder/volume/drivers/hitachi/hbsd_common.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/e9482b7f64930624ffcf07ee6581480dbd877ac0', 'message': 'Hitachi and OEM: Support multi pool\n\nThis patch support multi pool feature for Hitachi VSP driver\nand NEC V driver.\n\nImplements: blueprint hitachi-vsp-add-multi-pool\nChange-Id: I49ac061011293900b04a7a5b90ff5b840521993d\n'}]",12,846977,e9482b7f64930624ffcf07ee6581480dbd877ac0,81,6,2,33473,,,0,"Hitachi and OEM: Support multi pool

This patch support multi pool feature for Hitachi VSP driver
and NEC V driver.

Implements: blueprint hitachi-vsp-add-multi-pool
Change-Id: I49ac061011293900b04a7a5b90ff5b840521993d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/846977/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/nec/v/nec_v_rest.py', 'cinder/volume/drivers/hitachi/hbsd_fc.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_fc.py', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_iscsi.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_iscsi.py', 'cinder/tests/unit/volume/drivers/nec/v/test_internal_nec_rest_iscsi.py', 'releasenotes/notes/hitachi-vsp-add-multi-pool-4c4589b93399e641.yaml', 'cinder/tests/unit/volume/drivers/hitachi/test_hitachi_hbsd_rest_fc.py', 'cinder/volume/drivers/hitachi/hbsd_rest.py', 'cinder/volume/drivers/hitachi/hbsd_common.py', 'cinder/tests/unit/volume/drivers/nec/v/test_nec_rest_iscsi.py']",12,e205e008d3f1754d9da2920f3b7a0aa245c59a95,bp/hitachi-vsp-add-multi-pool," self.configuration.nec_v_pool = [""30""] self.driver.common._stats = {} self.driver.common._stats['pools'] = [ {'location_info': {'pool_id': 30}}]"," self.configuration.nec_v_pool = ""30""",2365,113
openstack%2Fopenstack-helm-images~master~I9774fe81c1dafea6768224082bf3684e9b122149,openstack/openstack-helm-images,master,I9774fe81c1dafea6768224082bf3684e9b122149,WIP - Test re-enabling Yoga images,ABANDONED,2022-11-23 04:22:27.000000000,2023-01-30 18:40:44.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-11-23 04:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f2013c9c21f25b5887eecbc10ba90b80540d13c1', 'message': 'WIP - Test re-enabling Yoga images\n\nChange-Id: I9774fe81c1dafea6768224082bf3684e9b122149\n'}, {'number': 2, 'created': '2022-12-12 22:50:05.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/e9b278697aa24f06d496900844c47144900faf1e', 'message': 'WIP - Test re-enabling Yoga images\n\nChange-Id: I9774fe81c1dafea6768224082bf3684e9b122149\n'}]",0,865370,e9b278697aa24f06d496900844c47144900faf1e,5,1,2,21420,,,0,"WIP - Test re-enabling Yoga images

Change-Id: I9774fe81c1dafea6768224082bf3684e9b122149
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/70/865370/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,f2013c9c21f25b5887eecbc10ba90b80540d13c1,yoga-images, - openstack-helm-images-compute-kit-yoga-ubuntu_focal - openstack-helm-images-cinder-yoga-ubuntu_focal - openstack-helm-images-compute-kit-yoga-ubuntu_focal - openstack-helm-images-cinder-yoga-ubuntu_focal - openstack-helm-images-compute-kit-yoga-ubuntu_focal - openstack-helm-images-cinder-yoga-ubuntu_focal - name: openstack-helm-images-build-openstack-loci-yoga-ubuntu_focal soft: true - name: openstack-helm-images-build-openstack-loci-yoga-ubuntu_focal soft: true, # TODO(gagehugo): Fix the yoga job failure and uncomment # - openstack-helm-images-compute-kit-yoga-ubuntu_focal # - openstack-helm-images-cinder-yoga-ubuntu_focal # - openstack-helm-images-compute-kit-yoga-ubuntu_focal # - openstack-helm-images-cinder-yoga-ubuntu_focal # - openstack-helm-images-compute-kit-yoga-ubuntu_focal # - openstack-helm-images-cinder-yoga-ubuntu_focal #- name: openstack-helm-images-build-openstack-loci-yoga-ubuntu_focal # soft: true #- name: openstack-helm-images-build-openstack-loci-yoga-ubuntu_focal # soft: true,10,11
openstack%2Fopenstack-helm~master~I3c1da4cd99c19d3243e31fc65063c4409cd64781,openstack/openstack-helm,master,I3c1da4cd99c19d3243e31fc65063c4409cd64781,Create a directory for ebtables lock,ABANDONED,2022-11-16 16:35:15.000000000,2023-01-30 18:40:43.000000000,,"[{'_account_id': 8898}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-16 16:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0d0ba4785cbf10d97151925d9adbfe30e02a6c40', 'message': 'Create a directory for ebtables lock\n\nDefault user neutron is unable to create /var/lib/ebtabls dir for\nlock file /var/lib/ebtables/lock.\nThis commit creates it using emptyDir.\n\nChange-Id: I3c1da4cd99c19d3243e31fc65063c4409cd64781\n'}, {'number': 2, 'created': '2022-11-16 16:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2110a68ee8872f7a5960be2293df73305d37d26e', 'message': 'Create a directory for ebtables lock\n\nDefault user neutron is unable to create /var/lib/ebtabls dir for\nlock file /var/lib/ebtables/lock.\nThis commit creates it using emptyDir.\n\nChange-Id: I3c1da4cd99c19d3243e31fc65063c4409cd64781\n'}, {'number': 3, 'created': '2022-12-02 16:53:04.000000000', 'files': ['neutron/templates/daemonset-lb-agent.yaml', 'neutron/Chart.yaml', 'releasenotes/notes/neutron.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a729bdd14233cdca04fbfd295a701b3a79fee0bf', 'message': 'Create a directory for ebtables lock\n\nDefault user neutron is unable to create /var/lib/ebtables dir for\nlock file /var/lib/ebtables/lock.\nThis commit creates it using emptyDir.\n\nChange-Id: I3c1da4cd99c19d3243e31fc65063c4409cd64781\n'}]",6,864763,a729bdd14233cdca04fbfd295a701b3a79fee0bf,10,2,3,34293,,,0,"Create a directory for ebtables lock

Default user neutron is unable to create /var/lib/ebtables dir for
lock file /var/lib/ebtables/lock.
This commit creates it using emptyDir.

Change-Id: I3c1da4cd99c19d3243e31fc65063c4409cd64781
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/63/864763/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/templates/daemonset-lb-agent.yaml'],1,0d0ba4785cbf10d97151925d9adbfe30e02a6c40,864763, - name: pod-ebtables mountPath: /var/lib/ebtables - name: pod-ebtables emptyDir: {},,4,0
openstack%2Fopenstack-helm~master~I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80,openstack/openstack-helm,master,I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80,Migrate nova to wsgi,ABANDONED,2022-10-13 00:50:12.000000000,2023-01-30 18:40:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-10-13 00:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b033c9a0e9e7202b62c9b302c1213ac063866ff3', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 2, 'created': '2022-10-13 02:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/55875bc6b10792032b60aca53603e1034c026650', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 3, 'created': '2022-10-16 20:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/a3452fed0dfbeb631530b86d757782600208cc48', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 4, 'created': '2022-10-19 02:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ebb60082707beb34004bb1300b3ffb725be5c36f', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 5, 'created': '2022-10-19 04:22:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/899ca23af337321c7ea851704025052ada748ff2', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 6, 'created': '2022-10-19 15:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/9cf10dc6170d88d4768d797b3b1c18cf235ef5f9', 'message': 'WIP - Migrate nova to wsgi\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 7, 'created': '2022-10-20 04:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/4bb848386f9bf863c89bdc9d5ae3887d66c11f57', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 8, 'created': '2022-10-20 04:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/caa9c1d1398da5c6ac9d9fa6afcd40fb25db8569', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 9, 'created': '2022-10-25 16:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/12a2908c99061cf0a97ff27d2efa6b35d207c89f', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 10, 'created': '2022-10-26 20:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/cea45b65ecd4559ff1148f5393672928832e95ac', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 11, 'created': '2022-11-10 00:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/58d97517c7764b504a7b91178fd2b4b114d96126', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 12, 'created': '2022-11-10 00:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/13dcfdc10e84329d935b45cc9b60a7b7c85d6877', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 13, 'created': '2022-11-10 00:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/dca33a00f3e8a9e6383fdcaee62ec433cee6f07d', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 14, 'created': '2022-11-18 17:48:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bf848e895d153e42cb2679dc529e024c3723e631', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 15, 'created': '2022-11-18 17:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bef5088ffeca0cf5ed7105c20e05b2f527552f27', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 16, 'created': '2022-11-18 17:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/043abfecc0aec23443b2c6169366c8ff48a6ba18', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 17, 'created': '2022-11-18 17:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/2d4431c22836b155a7f0c66abfe1fefe7f0fdc8e', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 18, 'created': '2022-11-18 17:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/95ed442530c8816e71a6b14d96c7428c5f80cfcd', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}, {'number': 19, 'created': '2022-12-12 22:50:43.000000000', 'files': ['nova/templates/bin/_nova-api.sh.tpl', 'nova/templates/bin/_nova-api-metadata.sh.tpl', 'nova/templates/configmap-etc.yaml', 'nova/values.yaml', 'nova/templates/deployment-api-osapi.yaml', 'releasenotes/notes/nova.yaml', 'nova/templates/deployment-api-metadata.yaml', 'nova/Chart.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5f3bfb505e0759a9320a476c61bdcf3f503373a6', 'message': 'Migrate nova to wsgi\n\nRunning nova via eventlet has been deprecated for quite\nsome time now. To avoid any future issues, this change\nmigrates nova to be ran via apache2 like other openstack\nservices.\n\nChange-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80\n'}]",3,861123,5f3bfb505e0759a9320a476c61bdcf3f503373a6,41,1,19,21420,,,0,"Migrate nova to wsgi

Running nova via eventlet has been deprecated for quite
some time now. To avoid any future issues, this change
migrates nova to be ran via apache2 like other openstack
services.

Change-Id: I2ac7ee94776c35e8e2c7abbe2639ab5d49a48c80
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/23/861123/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/templates/bin/_nova-api.sh.tpl', 'nova/templates/bin/_nova-api-metadata.sh.tpl', 'nova/values.yaml', 'zuul.d/project.yaml', 'releasenotes/notes/nova.yaml', 'nova/Chart.yaml']",6,b033c9a0e9e7202b62c9b302c1213ac063866ff3,nova-wsgi,version: 0.3.0,version: 0.2.47,60,26
openstack%2Fnova~master~Ibd8b555c4d6a70cd221b12821d6e9d88cf132a4a,openstack/nova,master,Ibd8b555c4d6a70cd221b12821d6e9d88cf132a4a,Fix huge-page doc,MERGED,2023-01-10 12:26:43.000000000,2023-01-30 18:31:46.000000000,2023-01-30 18:29:33.000000000,"[{'_account_id': 4690}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-10 12:26:43.000000000', 'files': ['doc/source/admin/huge-pages.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/0826ee1c686bc1880d9933d1bcc56e4925e71cdc', 'message': 'Fix huge-page doc\n\nThis change updates the echo command as per description [1],\nto append huge-page specific paramters instead of overwriting.\n\n[1] https://docs.openstack.org/nova/zed/admin/huge-pages.html\n\nCloses-Bug: #2002317\n\nChange-Id: Ibd8b555c4d6a70cd221b12821d6e9d88cf132a4a\n'}]",2,869689,0826ee1c686bc1880d9933d1bcc56e4925e71cdc,10,6,1,20733,,,0,"Fix huge-page doc

This change updates the echo command as per description [1],
to append huge-page specific paramters instead of overwriting.

[1] https://docs.openstack.org/nova/zed/admin/huge-pages.html

Closes-Bug: #2002317

Change-Id: Ibd8b555c4d6a70cd221b12821d6e9d88cf132a4a
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/869689/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/huge-pages.rst'],1,0826ee1c686bc1880d9933d1bcc56e4925e71cdc,doc-fix," # echo 'GRUB_CMDLINE_LINUX=""$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never""' >> /etc/default/grub"," # echo 'GRUB_CMDLINE_LINUX=""$GRUB_CMDLINE_LINUX hugepagesz=2M hugepages=2048 transparent_hugepage=never""' > /etc/default/grub",1,1
openstack%2Fopenstacksdk~master~I34d68d2d22d0a5a221d976713ec7a0db4745b299,openstack/openstacksdk,master,I34d68d2d22d0a5a221d976713ec7a0db4745b299,Prepare release note for R1.0,MERGED,2023-01-27 17:11:30.000000000,2023-01-30 18:30:50.000000000,2023-01-30 18:29:29.000000000,"[{'_account_id': 15334}, {'_account_id': 16708}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-27 17:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/30e30e3bba1469df7a38ae8d677e4ccaa9c2e4e0', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}, {'number': 2, 'created': '2023-01-27 17:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/364d1701ef13629cd5691c09df29979fa188ca05', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}, {'number': 3, 'created': '2023-01-29 12:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d55832d9e5bed9eade8fd66314192a0e609a8997', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}, {'number': 4, 'created': '2023-01-30 11:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3ef12194118f668bc4a24a33590b1d2eff4850db', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}, {'number': 5, 'created': '2023-01-30 11:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/248582feb1b3636740a75e45c448f4f2a8d50f76', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}, {'number': 6, 'created': '2023-01-30 15:35:17.000000000', 'files': ['releasenotes/notes/r1-d4efe289ebf0cbcd.yaml'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9ea832d660fe2ae52b8756ae499b23171cb61048', 'message': 'Prepare release note for R1.0\n\nWe made a technical problem releasing lot of breaking changes in 0.99,\nbut that was necessary due to inability to build RC. In order to log\nthings properly create an explanational releasenote describing issues\nand repeating major stuff.\n\nChange-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299\n'}]",31,872030,9ea832d660fe2ae52b8756ae499b23171cb61048,23,4,6,27900,,,0,"Prepare release note for R1.0

We made a technical problem releasing lot of breaking changes in 0.99,
but that was necessary due to inability to build RC. In order to log
things properly create an explanational releasenote describing issues
and repeating major stuff.

Change-Id: I34d68d2d22d0a5a221d976713ec7a0db4745b299
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/30/872030/3 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/r1-d4efe289ebf0cbcd.yaml'],1,30e30e3bba1469df7a38ae8d677e4ccaa9c2e4e0,sdk_r1,"--- prelude: > This is a final R1.0 release of the OpenStackSDK. A few technical issues caused us not to reach this milestone cleanly, therefore we decided to one more time explicitly log everything what should be considered as R1.0. For detailed list of changes please see individual release notes from 0.99.0 to 0.103.0. Most important changes are explicitly repeated here. There were issues with maintainability of multiple available access interfaces, what forced us to consider what we are able to maintain in the long run and what not. That means that certain things were dropped, which is why we are releasing this as a major release. R1.0 is considered as a first major release with corresponding promise regarding backward compatibility. features: - | Cloud layer is now consistenly returning Resource class objects. Previously it was not always the case. - | API response caching is implemented deep inside the code which should allow to save some roundtips. - | Majority of services were verified and adapted to the latest state of the API. - | Certain code reorganization to further help in code reduction has been made (metadata, tag and quota support moved to standalone common classes). upgrade: - | Cloud layer methods are returning Resource class objects and not Munch objects anymore. In some cases this cause renaming of the attributes. Resource class is Munch compatible and allows both dictionary and attribute base access. deprecations: - | Some historical methods, which were never properly tested wer List deprecations notes here, or remove this section. All of the list items in this section are combined when the release notes are rendered, so the text needs to be worded so that it does not depend on any information only available in another section, such as the prelude. This may mean repeating some details. - | Munch is dropped as a dependency. The project has no releases since multiple years and is causing huge performance impact already during import. This has directly no negative imapct to SDK users (it now starts faster), but in the code we copied used Munch pieces. They are going to be consistently eliminated in next releases. ",,45,0
openstack%2Foslo.utils~stable%2Fxena~I8729cf180f92f43519c942e22f3b285377a5612f,openstack/oslo.utils,stable/xena,I8729cf180f92f43519c942e22f3b285377a5612f,[imageutils] Fix __str__ for QemuImgInfo,MERGED,2023-01-30 09:50:29.000000000,2023-01-30 17:27:02.000000000,2023-01-30 17:26:01.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 09:50:29.000000000', 'files': ['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/3ae82df28d7882dc4d13e9332b273a1b42fa82ce', 'message': ""[imageutils] Fix __str__ for QemuImgInfo\n\nCode is calling 'appened' on a list; correct this to 'append'.\n\nCloses-bug: #1996426\nChange-Id: I8729cf180f92f43519c942e22f3b285377a5612f\n(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)\n""}]",0,872112,3ae82df28d7882dc4d13e9332b273a1b42fa82ce,9,2,1,28522,,,0,"[imageutils] Fix __str__ for QemuImgInfo

Code is calling 'appened' on a list; correct this to 'append'.

Closes-bug: #1996426
Change-Id: I8729cf180f92f43519c942e22f3b285377a5612f
(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/12/872112/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py']",2,3ae82df28d7882dc4d13e9332b273a1b42fa82ce,bug-1996426," # test for Bug #1996426 expected_str = ""format_specific: {'data': {'foo': 'bar'}}"" self.assertIn(expected_str, str(image_info))",,4,1
openstack%2Foslo.utils~stable%2Fyoga~I8729cf180f92f43519c942e22f3b285377a5612f,openstack/oslo.utils,stable/yoga,I8729cf180f92f43519c942e22f3b285377a5612f,[imageutils] Fix __str__ for QemuImgInfo,MERGED,2023-01-30 09:50:09.000000000,2023-01-30 17:22:37.000000000,2023-01-30 17:21:36.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 09:50:09.000000000', 'files': ['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/92d0c17a62d4f4e2ac65d85ee6d6a2c02a75739a', 'message': ""[imageutils] Fix __str__ for QemuImgInfo\n\nCode is calling 'appened' on a list; correct this to 'append'.\n\nCloses-bug: #1996426\nChange-Id: I8729cf180f92f43519c942e22f3b285377a5612f\n(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)\n""}]",0,872111,92d0c17a62d4f4e2ac65d85ee6d6a2c02a75739a,9,2,1,28522,,,0,"[imageutils] Fix __str__ for QemuImgInfo

Code is calling 'appened' on a list; correct this to 'append'.

Closes-bug: #1996426
Change-Id: I8729cf180f92f43519c942e22f3b285377a5612f
(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/11/872111/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py']",2,92d0c17a62d4f4e2ac65d85ee6d6a2c02a75739a,bug-1996426," # test for Bug #1996426 expected_str = ""format_specific: {'data': {'foo': 'bar'}}"" self.assertIn(expected_str, str(image_info))",,4,1
openstack%2Foslo.utils~stable%2Fzed~I8729cf180f92f43519c942e22f3b285377a5612f,openstack/oslo.utils,stable/zed,I8729cf180f92f43519c942e22f3b285377a5612f,[imageutils] Fix __str__ for QemuImgInfo,MERGED,2023-01-30 09:49:33.000000000,2023-01-30 17:17:29.000000000,2023-01-30 17:16:26.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 09:49:33.000000000', 'files': ['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/716c2e2b8e3ec640be2db6df93a611b0dbe06bc1', 'message': ""[imageutils] Fix __str__ for QemuImgInfo\n\nCode is calling 'appened' on a list; correct this to 'append'.\n\nCloses-bug: #1996426\nChange-Id: I8729cf180f92f43519c942e22f3b285377a5612f\n(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)\n""}]",0,872110,716c2e2b8e3ec640be2db6df93a611b0dbe06bc1,9,2,1,28522,,,0,"[imageutils] Fix __str__ for QemuImgInfo

Code is calling 'appened' on a list; correct this to 'append'.

Closes-bug: #1996426
Change-Id: I8729cf180f92f43519c942e22f3b285377a5612f
(cherry picked from commit d49d5944824f15d00e04e1b9c7f8c3b03b440c95)
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/10/872110/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_utils/imageutils.py', 'oslo_utils/tests/test_imageutils.py']",2,716c2e2b8e3ec640be2db6df93a611b0dbe06bc1,bug-1996426," # test for Bug #1996426 expected_str = ""format_specific: {'data': {'foo': 'bar'}}"" self.assertIn(expected_str, str(image_info))",,4,1
openstack%2Fkolla~master~I46945f994c2e4d86989b35836604140329267e84,openstack/kolla,master,I46945f994c2e4d86989b35836604140329267e84,CI: add ubuntu opensearch experimental job,MERGED,2023-01-23 07:39:41.000000000,2023-01-30 17:13:37.000000000,2023-01-30 17:10:54.000000000,"[{'_account_id': 22348}, {'_account_id': 23084}, {'_account_id': 24072}]","[{'number': 1, 'created': '2023-01-23 07:39:41.000000000', 'files': ['.zuul.d/ubuntu.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1a9c1e81071d6a9541442103d373951cac2dc3a3', 'message': 'CI: add ubuntu opensearch experimental job\n\nChange-Id: I46945f994c2e4d86989b35836604140329267e84\n'}]",1,871447,1a9c1e81071d6a9541442103d373951cac2dc3a3,11,3,1,22629,,,0,"CI: add ubuntu opensearch experimental job

Change-Id: I46945f994c2e4d86989b35836604140329267e84
",git fetch https://review.opendev.org/openstack/kolla refs/changes/47/871447/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/ubuntu.yaml'],1,1a9c1e81071d6a9541442103d373951cac2dc3a3,, - kolla-ansible-ubuntu-prometheus-opensearch: files: ^docker/(base|opensearch|fluentd|grafana|prometheus)/,,2,0
openstack%2Fkolla~master~I8882484b32a3a3fbde52f58c1209e8c127ea9931,openstack/kolla,master,I8882484b32a3a3fbde52f58c1209e8c127ea9931,Switch trove-api to wsgi running under apache.,MERGED,2022-08-26 07:10:15.000000000,2023-01-30 17:12:42.000000000,2023-01-30 17:10:52.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 27339}]","[{'number': 1, 'created': '2022-08-26 07:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/78ee76b79cd6d7e863b66b6686e113c2d1aab417', 'message': ""Switch trove-api to wsgi running under apache.\n\nDrop 'USER trove' from trove-api, trove-api runs under\napache needs run as root\n\nChange-Id: I8882484b32a3a3fbde52f58c1209e8c127ea9931\n""}, {'number': 2, 'created': '2023-01-05 14:48:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a7ccbe114c84360b351cbe4ff370b16dc924ecbb', 'message': ""Switch trove-api to wsgi running under apache.\n\nDrop 'USER trove' from trove-api, trove-api runs under\napache needs run as root\n\nChange-Id: I8882484b32a3a3fbde52f58c1209e8c127ea9931\n""}, {'number': 3, 'created': '2023-01-30 13:34:49.000000000', 'files': ['releasenotes/notes/run-trove-api-under-apache-928103ee6b879de2.yaml', 'docker/trove/trove-api/extend_start.sh', 'docker/trove/trove-api/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1bb082d35a03579d7b762d9691aef86c5b428534', 'message': ""Switch trove-api to wsgi running under apache.\n\nDrop 'USER trove' from trove-api, trove-api runs under\napache needs run as root\n\nChange-Id: I8882484b32a3a3fbde52f58c1209e8c127ea9931\n""}]",6,854744,1bb082d35a03579d7b762d9691aef86c5b428534,23,4,3,26285,,,0,"Switch trove-api to wsgi running under apache.

Drop 'USER trove' from trove-api, trove-api runs under
apache needs run as root

Change-Id: I8882484b32a3a3fbde52f58c1209e8c127ea9931
",git fetch https://review.opendev.org/openstack/kolla refs/changes/44/854744/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/trove/trove-api/extend_start.sh', 'docker/trove/trove-api/Dockerfile.j2']",2,78ee76b79cd6d7e863b66b6686e113c2d1aab417,trove-api,, USER trove,2,2
openstack%2Ftripleo-common~stable%2Fwallaby~I0134be5ec7fbe035edf9fdc31fcc6cf0b37d07d6,openstack/tripleo-common,stable/wallaby,I0134be5ec7fbe035edf9fdc31fcc6cf0b37d07d6,checking purpose,ABANDONED,2023-01-30 14:32:13.000000000,2023-01-30 17:04:20.000000000,,[],"[{'number': 1, 'created': '2023-01-30 14:32:13.000000000', 'files': ['tripleo_common/image/kolla_builder.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/86f0df8429835ef44ecab4af60f321a66611c4e1', 'message': 'checking purpose\n\nChange-Id: I0134be5ec7fbe035edf9fdc31fcc6cf0b37d07d6\n'}]",0,872177,86f0df8429835ef44ecab4af60f321a66611c4e1,3,0,1,22954,,,0,"checking purpose

Change-Id: I0134be5ec7fbe035edf9fdc31fcc6cf0b37d07d6
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/77/872177/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/kolla_builder.py', 'tripleo_common/image/image_uploader.py']",2,86f0df8429835ef44ecab4af60f321a66611c4e1,test_purpose," LOG.info(""starting values: conf:{} mirrors:{} cleanup:{} registry:{} multi:{} lock:{}"".format(config_files,mirrors,cleanup,registry_credentials,multi_arch,lock)) LOG.info(""updated conf:{} mirrors:{} cleanup:{} registry:{} multi:{} lock:{}"".format(self.config_files, ""mirrors"", self.cleanup, ""reg"",self.multi_arch ,""lock"")) LOG.info(""pull_source:{}"".format(task.pull_source)) LOG.info(""image_name:"".format(task.image_name)) LOG.info(""push_destination:{}"".format(task.push_destination)) LOG.info(""Upload Done"")",,8,0
openstack%2Ftap-as-a-service~master~Ia9048ef2dbc602ecd571da502ac2131b575f59ac,openstack/tap-as-a-service,master,Ia9048ef2dbc602ecd571da502ac2131b575f59ac,Add pylint to pep8 and adopt code to the results,MERGED,2022-11-21 19:03:40.000000000,2023-01-30 16:45:46.000000000,2023-01-30 16:45:46.000000000,"[{'_account_id': 1131}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-21 19:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/b337964162b04891f09102a7425f1e5ba282b4cf', 'message': 'Add pylint to pep8 and adopt code to the results\n\nChange-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac\n'}, {'number': 2, 'created': '2022-11-22 08:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/0da26d3f5a1ad988e29c17b45f000f7b4c70795c', 'message': 'Add pylint to pep8 and adopt code to the results\n\nChange-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac\n'}, {'number': 3, 'created': '2022-11-22 14:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/b809fbe75d5d4f326ca2253a4117dfe94ebf4f5b', 'message': 'Add pylint to pep8 and adopt code to the results\n\nChange-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac\n'}, {'number': 4, 'created': '2022-11-23 09:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/44259dff53126382834cb64844c42fe0a8bc0081', 'message': 'Add pylint to pep8 and adopt code to the results\n\nChange-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac\n'}, {'number': 5, 'created': '2023-01-30 12:40:16.000000000', 'files': ['neutron_taas/services/taas/agents/common/taas_agent.py', 'neutron_taas/services/taas/service_drivers/service_driver_context.py', '.pylintrc', 'neutron_taas/services/taas/drivers/linux/sriov_nic_exceptions.py', 'neutron_taas/common/utils.py', 'neutron_taas/services/taas/drivers/linux/sriov_nic_utils.py', 'test-requirements.txt', 'neutron_taas/services/taas/agents/taas_agent_api.py', 'neutron_taas/services/taas/agents/extensions/taas.py', 'neutron_taas/services/taas/drivers/linux/ovs_utils.py', 'neutron_taas/taas_client/osc/tap_flow.py', 'neutron_taas/services/taas/drivers/linux/ovs_taas.py', 'neutron_taas/db/migration/alembic_migration/env.py', 'neutron_taas/services/taas/drivers/linux/sriov_nic_taas.py', 'neutron_taas/services/taas/taas_plugin.py', 'neutron_taas/services/taas/service_drivers/taas_agent_api.py', 'neutron_taas/taas_client/osc/tap_service.py', 'neutron_taas/services/taas/service_drivers/taas_rpc.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/1ef9316e92bfa2c41748538e44e10d28467eec16', 'message': 'Add pylint to pep8 and adopt code to the results\n\nChange-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac\n'}]",2,865187,1ef9316e92bfa2c41748538e44e10d28467eec16,18,3,5,8313,,,0,"Add pylint to pep8 and adopt code to the results

Change-Id: Ia9048ef2dbc602ecd571da502ac2131b575f59ac
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/87/865187/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_taas/services/taas/agents/common/taas_agent.py', 'neutron_taas/services/taas/drivers/linux/sriov_nic_exceptions.py', 'neutron_taas/common/utils.py', 'neutron_taas/services/taas/drivers/linux/sriov_nic_utils.py', 'neutron_taas/services/taas/agents/taas_agent_api.py', 'neutron_taas/services/taas/drivers/linux/ovs_utils.py', 'neutron_taas/services/taas/drivers/linux/ovs_taas.py', 'neutron_taas/services/taas/drivers/linux/sriov_nic_taas.py', 'neutron_taas/services/taas/taas_plugin.py', 'neutron_taas/services/taas/service_drivers/taas_agent_api.py', 'neutron_taas/services/taas/service_drivers/taas_rpc.py', 'tox.ini']",12,b337964162b04891f09102a7425f1e5ba282b4cf,pylint_for_taas, pylint --version pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_taas},,32,74
openstack%2Fpython-openstackclient~stable%2Fwallaby~I2d9c68db5bf891ffa25fd5a7fc9e8953e44b73ab,openstack/python-openstackclient,stable/wallaby,I2d9c68db5bf891ffa25fd5a7fc9e8953e44b73ab,volume: Allow more versions,MERGED,2023-01-11 17:45:09.000000000,2023-01-30 16:37:06.000000000,2023-01-30 16:35:55.000000000,"[{'_account_id': 15334}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-11 17:45:09.000000000', 'files': ['openstackclient/volume/client.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e1872e01bfcb2edc5cbd6e6f44a1cfa6443dea18', 'message': ""volume: Allow more versions\n\nCopy the API version checks from the 'openstackclient.compute.client'\nmodule. These will only be necessary until we migrate everything to SDK\nbut it's very helpful until then.\n\nChange-Id: I2d9c68db5bf891ffa25fd5a7fc9e8953e44b73ab\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n(cherry picked from commit 0f28588e48c1e296f834e8684f293c2cdf4afc33)\n""}]",0,869832,e1872e01bfcb2edc5cbd6e6f44a1cfa6443dea18,9,4,1,6816,,,0,"volume: Allow more versions

Copy the API version checks from the 'openstackclient.compute.client'
module. These will only be necessary until we migrate everything to SDK
but it's very helpful until then.

Change-Id: I2d9c68db5bf891ffa25fd5a7fc9e8953e44b73ab
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
(cherry picked from commit 0f28588e48c1e296f834e8684f293c2cdf4afc33)
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/32/869832/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/volume/client.py'],1,e1872e01bfcb2edc5cbd6e6f44a1cfa6443dea18,cinder-gaps-stable/wallaby,"from osc_lib import exceptions} # Save the microversion if in use _volume_api_version = None if _volume_api_version is not None: version = _volume_api_version else: version = instance._api_version[API_NAME] from cinderclient import api_versions # convert to APIVersion object version = api_versions.get_api_version(version) def check_api_version(check_version): """"""Validate version supplied by user Returns: * True if version is OK * False if the version has not been checked and the previous plugin check should be performed * throws an exception if the version is no good """""" # Defer client imports until we actually need them from cinderclient import api_versions global _volume_api_version # Copy some logic from novaclient 3.3.0 for basic version detection # NOTE(dtroyer): This is only enough to resume operations using API # version 3.0 or any valid version supplied by the user. _volume_api_version = api_versions.get_api_version(check_version) # Bypass X.latest format microversion if not _volume_api_version.is_latest(): if _volume_api_version > api_versions.APIVersion(""3.0""): if not _volume_api_version.matches( api_versions.MIN_VERSION, api_versions.MAX_VERSION, ): msg = _(""versions supported by client: %(min)s - %(max)s"") % { ""min"": api_versions.MIN_VERSION, ""max"": api_versions.MAX_VERSION, } raise exceptions.CommandError(msg) return True return False"," ""3.42"": ""cinderclient.v3.client.Client"", } version = instance._api_version[API_NAME] from cinderclient import api_versions # convert to APIVersion object version = api_versions.get_api_version(version)",50,5
openstack%2Fovn-bgp-agent~master~Iacbcc2ef094858f82166273d5b23c81f10324726,openstack/ovn-bgp-agent,master,Iacbcc2ef094858f82166273d5b23c81f10324726,Support for AddressScopes as an API of what to expose,MERGED,2023-01-27 13:42:37.000000000,2023-01-30 16:27:15.000000000,2023-01-30 16:27:15.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 23804}]","[{'number': 1, 'created': '2023-01-27 13:42:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/2dbd0b31b38dd38deee2b5401f2797a522e3547c', 'message': 'Support for AddressScopes as an API of what to expose\n\nThis patch adds the option to filter the tenant subnets to\nbe exposed depending on them belonging or not to an\naddress_scope (i.e., to a subnet pool associated to an\naddress_scope).\n\nChange-Id: Iacbcc2ef094858f82166273d5b23c81f10324726\n'}, {'number': 2, 'created': '2023-01-30 08:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/2cff86ad7fcba044297d4d02fcfefda4fcb5bb9b', 'message': 'Support for AddressScopes as an API of what to expose\n\nThis patch adds the option to filter the tenant subnets to\nbe exposed depending on them belonging or not to an\naddress_scope (i.e., to a subnet pool associated to an\naddress_scope).\n\nChange-Id: Iacbcc2ef094858f82166273d5b23c81f10324726\n'}, {'number': 3, 'created': '2023-01-30 12:25:07.000000000', 'files': ['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/utils/driver_utils.py', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_ovn_stretched_l2_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/ovn_stretched_l2_bgp_driver.py', 'doc/source/contributor/bgp_mode_design.rst', 'ovn_bgp_agent/tests/unit/drivers/openstack/test_ovn_bgp_driver.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/19bd3e0fb9c7c2b9977acdfd1fce4bac058aa1c3', 'message': 'Support for AddressScopes as an API of what to expose\n\nThis patch adds the option to filter the tenant subnets to\nbe exposed depending on them belonging or not to an\naddress_scope (i.e., to a subnet pool associated to an\naddress_scope).\n\nChange-Id: Iacbcc2ef094858f82166273d5b23c81f10324726\n'}]",3,871264,19bd3e0fb9c7c2b9977acdfd1fce4bac058aa1c3,14,4,3,23567,,,0,"Support for AddressScopes as an API of what to expose

This patch adds the option to filter the tenant subnets to
be exposed depending on them belonging or not to an
address_scope (i.e., to a subnet pool associated to an
address_scope).

Change-Id: Iacbcc2ef094858f82166273d5b23c81f10324726
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/64/871264/1 && git format-patch -1 --stdout FETCH_HEAD,"['ovn_bgp_agent/drivers/openstack/ovn_bgp_driver.py', 'ovn_bgp_agent/drivers/openstack/utils/driver_utils.py', 'ovn_bgp_agent/drivers/openstack/ovn_stretched_l2_bgp_driver.py']",3,2dbd0b31b38dd38deee2b5401f2797a522e3547c,address-scopes-api,from ovn_bgp_agent.drivers.openstack.utils import driver_utils address_scopes = driver_utils.get_addr_scopes(port) address_scopes = driver_utils.get_addr_scopes(port) address_scopes = driver_utils.get_addr_scopes(port)," def _get_addr_scopes(self, port): return { constants.IP_VERSION_4: port.external_ids.get( constants.SUBNET_POOL_ADDR_SCOPE4 ), constants.IP_VERSION_6: port.external_ids.get( constants.SUBNET_POOL_ADDR_SCOPE6 ), } address_scopes = self._get_addr_scopes(port) address_scopes = self._get_addr_scopes(port) address_scopes = self._get_addr_scopes(port)",78,27
openstack%2Fkolla~master~I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0,openstack/kolla,master,I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0,influxdb: Update gpg key,MERGED,2023-01-30 10:30:00.000000000,2023-01-30 16:16:20.000000000,2023-01-30 16:14:57.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-01-30 10:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2384b0c5941499111fc300458672fa801de39926', 'message': 'influxdb: Update gpg key\n\nInflux repo gpg key has been rotated as of of 2023-01-26 [1].\n\n[1]: https://www.influxdata.com/blog/linux-package-signing-key-rotation/\n\nChange-Id: I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0\n'}, {'number': 2, 'created': '2023-01-30 13:10:27.000000000', 'files': ['docker/base/Dockerfile.j2', 'docker/base/influxdb.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ab70c7618b3b7e025759fe38c8692f66ef420b15', 'message': 'influxdb: Update gpg key\n\nInflux repo gpg key has been rotated as of of 2023-01-26 [1].\n\n[1]: https://www.influxdata.com/blog/linux-package-signing-key-rotation/\n\nDepends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/871821\n\nChange-Id: I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0\n'}]",2,872107,ab70c7618b3b7e025759fe38c8692f66ef420b15,14,4,2,22629,,,0,"influxdb: Update gpg key

Influx repo gpg key has been rotated as of of 2023-01-26 [1].

[1]: https://www.influxdata.com/blog/linux-package-signing-key-rotation/

Depends-On: https://review.opendev.org/c/openstack/kolla-ansible/+/871821

Change-Id: I76b35bb20ddc0130ca15ff03942e1a97f5d36ff0
",git fetch https://review.opendev.org/openstack/kolla refs/changes/07/872107/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/Dockerfile.j2', 'docker/base/influxdb.repo']",2,2384b0c5941499111fc300458672fa801de39926,,gpgkey = https://repos.influxdata.com/influxdata-archive_compat.key,gpgkey = https://repos.influxdata.com/influxdb.key,2,2
openstack%2Fgrenade~master~I36a3bfe31c77451b3c34838c05d13d00187cc0cd,openstack/grenade,master,I36a3bfe31c77451b3c34838c05d13d00187cc0cd,WIP: use ensure-rust,NEW,2023-01-30 14:27:40.000000000,2023-01-30 16:16:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-30 14:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/d65f9f4bbce94e4b03c8ddcd5ecdf1d6c068c1ce', 'message': 'WIP: use ensure-rust\n\nChange-Id: I36a3bfe31c77451b3c34838c05d13d00187cc0cd\n'}, {'number': 2, 'created': '2023-01-30 14:35:24.000000000', 'files': ['playbooks/multinode-pre.yaml'], 'web_link': 'https://opendev.org/openstack/grenade/commit/c00c987311e5583edb92a8c62eca8ea6bfe8ad84', 'message': 'WIP: use ensure-rust\n\nChange-Id: I36a3bfe31c77451b3c34838c05d13d00187cc0cd\n'}]",1,872174,c00c987311e5583edb92a8c62eca8ea6bfe8ad84,4,1,2,17685,,,0,"WIP: use ensure-rust

Change-Id: I36a3bfe31c77451b3c34838c05d13d00187cc0cd
",git fetch https://review.opendev.org/openstack/grenade refs/changes/74/872174/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d65f9f4bbce94e4b03c8ddcd5ecdf1d6c068c1ce,ensure-rust-cryptography, name: grenade-multinode description: | Basic multinode grenade job parent: grenade roles: - ensure-rust branches: - ussuri nodeset: openstack-two-node-focal pre-run: playbooks/multinode-pre.yaml - job:,,12,0
openstack%2Fkolla~master~I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe,openstack/kolla,master,I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe,Update kafka v1.0.1 to v2.1.1,ABANDONED,2018-07-31 03:30:03.000000000,2023-01-30 16:02:12.000000000,,"[{'_account_id': 13039}, {'_account_id': 17669}, {'_account_id': 19316}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23717}, {'_account_id': 26285}, {'_account_id': 28654}]","[{'number': 1, 'created': '2018-07-31 03:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/05eef1e4fcbd6ea26e52d00e3d00d0bc5ac04de8', 'message': 'update docker-kafka-Dockerfile-version\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}, {'number': 2, 'created': '2018-07-31 03:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/267538c4bde2204c692f3bc5761664343f3f769a', 'message': 'update kafka v1.0.1 to v2.0.0\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}, {'number': 3, 'created': '2018-08-02 02:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9fd27bcd1ad2666a6353f048c080bff5484676b9', 'message': 'Update kafka v1.0.1 to v2.0.0\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}, {'number': 4, 'created': '2018-09-27 16:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d8d63e1729a9a0ffb350732ebe8a75a86dfa753e', 'message': 'Update kafka v1.0.1 to v2.0.0\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}, {'number': 5, 'created': '2019-02-28 05:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/50d136737b6228eff5e43bb7ef848c1ebee78291', 'message': 'Update kafka v1.0.1 to v2.0.0\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}, {'number': 6, 'created': '2019-02-28 05:50:49.000000000', 'files': ['docker/kafka/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6c64d150f56b686a408e7905f8a56ce4c20671d9', 'message': 'Update kafka v1.0.1 to v2.1.1\n\nChange-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe\n'}]",1,587274,6c64d150f56b686a408e7905f8a56ce4c20671d9,41,9,6,28654,,,0,"Update kafka v1.0.1 to v2.1.1

Change-Id: I7d71aa732757cea5a7f7420d52d0fa482f0b0cbe
",git fetch https://review.opendev.org/openstack/kolla refs/changes/74/587274/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/kafka/Dockerfile.j2'],1,05eef1e4fcbd6ea26e52d00e3d00d0bc5ac04de8,kolla-docker-kafka-Dockerfile-version,ENV kafka_version=2.0.0,ENV kafka_version=1.0.1,1,1
openstack%2Ftripleo-ansible~stable%2Ftrain~I994bd597d0425a4cd5988f7570eaacc300b6b2e4,openstack/tripleo-ansible,stable/train,I994bd597d0425a4cd5988f7570eaacc300b6b2e4,[Octavia] Create a rsyslog forward when *_log_targets params are set,MERGED,2023-01-19 13:02:05.000000000,2023-01-30 15:41:40.000000000,2023-01-30 15:41:40.000000000,"[{'_account_id': 6681}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29244}]","[{'number': 1, 'created': '2023-01-19 13:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cf1b31156be57fc55c4e900e3d9e0f93fbbe2bde', 'message': '[Octavia] Create a rsyslog forward when *_log_targets params are set\n\nIf a user sets the OctaviaAdminLogTargets param or the\nOctaviaTenantLogTargets param (from [0]), the\noctavia_controller_post_config role now creates a rsyslog forwarder on\nthe controllers, that redirects messages to those targets.\n\n[0] I1e21bf9cc1101f7ab2cfb4873470cfde63265023\n\nConflict:\n    tripleo_ansible/roles/octavia-controller-post-config/templates/10-octavia.conf.j2\n\nChange-Id: I994bd597d0425a4cd5988f7570eaacc300b6b2e4\n(cherry picked from commit 5fd009c5a669e043a5fd727122fffb8fd948f4e8)\n(cherry picked from commit 2075001834c8f1308c006c5186e0acf40fcb3787)\n'}, {'number': 2, 'created': '2023-01-30 08:02:53.000000000', 'files': ['tripleo_ansible/playbooks/octavia-files.yaml', 'tripleo_ansible/roles/octavia-controller-post-config/templates/10-octavia.conf.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/dac5d602eeccdd52ff54f2be4d0bb03709f6275e', 'message': '[Octavia] Create a rsyslog forward when *_log_targets params are set\n\nIf a user sets the OctaviaAdminLogTargets param or the\nOctaviaTenantLogTargets param (from [0]), the\noctavia_controller_post_config role now creates a rsyslog forwarder on\nthe controllers, that redirects messages to those targets.\n\n[0] I1e21bf9cc1101f7ab2cfb4873470cfde63265023\n\nConflict:\n    tripleo_ansible/roles/octavia-controller-post-config/templates/10-octavia.conf.j2\n\nChange-Id: I994bd597d0425a4cd5988f7570eaacc300b6b2e4\n(cherry picked from commit 5fd009c5a669e043a5fd727122fffb8fd948f4e8)\n(cherry picked from commit 2075001834c8f1308c006c5186e0acf40fcb3787)\n(cherry picked from commit 925268f2602c8caf8f2ed2b12ee604a357b19a83)\n'}]",2,871084,dac5d602eeccdd52ff54f2be4d0bb03709f6275e,12,5,2,29244,,,0,"[Octavia] Create a rsyslog forward when *_log_targets params are set

If a user sets the OctaviaAdminLogTargets param or the
OctaviaTenantLogTargets param (from [0]), the
octavia_controller_post_config role now creates a rsyslog forwarder on
the controllers, that redirects messages to those targets.

[0] I1e21bf9cc1101f7ab2cfb4873470cfde63265023

Conflict:
    tripleo_ansible/roles/octavia-controller-post-config/templates/10-octavia.conf.j2

Change-Id: I994bd597d0425a4cd5988f7570eaacc300b6b2e4
(cherry picked from commit 5fd009c5a669e043a5fd727122fffb8fd948f4e8)
(cherry picked from commit 2075001834c8f1308c006c5186e0acf40fcb3787)
(cherry picked from commit 925268f2602c8caf8f2ed2b12ee604a357b19a83)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/84/871084/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/playbooks/octavia-files.yaml', 'tripleo_ansible/roles/octavia-controller-post-config/templates/10-octavia.conf.j2']",2,cf1b31156be57fc55c4e900e3d9e0f93fbbe2bde,,"{% macro forwarder(type, log_targets) %} {% if (log_targets|length) > 0 %} ruleset(name=""{{ type }}_forwarding"" queue.type=""linkedList"" queue.size=""10000"") { {% for target in log_targets %} action(type=""omfwd"" {%- set host, port = target.split(':') -%} target=""{{ host }}"" port=""{{ port }}"" protocol=""udp"" action.resumeRetryCount=""5"" action.resumeInterval=""2"" {% if not loop.first %}action.execOnlyWhenPreviousIsSuspended=""on""{%- endif %} ) {% endfor %} } {% endif %} {% endmacro %} {{ forwarder('tenant', tenant_log_targets) }} {{ forwarder('admin', admin_log_targets) }} {% if (tenant_log_targets|length) > 0 %} call tenant_forwarding {% endif %}{% if (admin_log_targets|length) > 0 %} call admin_forwarding {% endif %}",,29,0
openstack%2Ftripleo-ansible~stable%2Ftrain~Iefe861f91cefe2a9cf773cae98b2440566ae8b5e,openstack/tripleo-ansible,stable/train,Iefe861f91cefe2a9cf773cae98b2440566ae8b5e,Wrap stopping podman -t with systemd timeouts (squash),MERGED,2022-05-05 13:08:20.000000000,2023-01-30 15:22:34.000000000,2022-05-10 23:03:29.000000000,"[{'_account_id': 7144}, {'_account_id': 7353}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-05-05 13:08:20.000000000', 'files': ['tripleo_ansible/roles/tripleo-container-manage/templates/systemd-service.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8417892f0c8f0250192ef56aeb595e7b46eef32f', 'message': 'Wrap stopping podman -t with systemd timeouts (squash)\n\n1) Currently with KillMode=none, if podman -t hangs, the command repeats\nleaving the process and its cgroup around.\nBut if a stop/start command hangs, we should not start another one.\n\nInstead time it out properly via TimeoutStopSec set to the 2x of\nthe timeout given to the managed podman action. Then if it expires,\nkill its cgroup all the way (KillMode=control-group is a default)\nbefore rerunning the same operation. Also note that using KilMode\nprocess is not recommended by systemd man pages.\n\nIncrease the grace stop timeout defaults 10->42s to align it with:\nhttps://github.com/containers/podman/pull/8889\n\n2) Make KillMode configurable for service units\n\nLibvirt container is a special beast that needs custom\nkillmode value for its tripleo-manager service unit.\nAdd kill_mode for the container values that defaults to\ncontrol-group.\n\n3) Fix TimeoutStopSec to integer convertion\n\nRelated: rhbz#2010135\nCloses-bug: #1945791\nChange-Id: Iefe861f91cefe2a9cf773cae98b2440566ae8b5e\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit badd5a3c10f0af9e1c69a9b88064e743a36d4f53)\n'}]",4,840663,8417892f0c8f0250192ef56aeb595e7b46eef32f,11,5,1,6926,,,0,"Wrap stopping podman -t with systemd timeouts (squash)

1) Currently with KillMode=none, if podman -t hangs, the command repeats
leaving the process and its cgroup around.
But if a stop/start command hangs, we should not start another one.

Instead time it out properly via TimeoutStopSec set to the 2x of
the timeout given to the managed podman action. Then if it expires,
kill its cgroup all the way (KillMode=control-group is a default)
before rerunning the same operation. Also note that using KilMode
process is not recommended by systemd man pages.

Increase the grace stop timeout defaults 10->42s to align it with:
https://github.com/containers/podman/pull/8889

2) Make KillMode configurable for service units

Libvirt container is a special beast that needs custom
killmode value for its tripleo-manager service unit.
Add kill_mode for the container values that defaults to
control-group.

3) Fix TimeoutStopSec to integer convertion

Related: rhbz#2010135
Closes-bug: #1945791
Change-Id: Iefe861f91cefe2a9cf773cae98b2440566ae8b5e
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit badd5a3c10f0af9e1c69a9b88064e743a36d4f53)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/63/840663/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo-container-manage/templates/systemd-service.j2'],1,8417892f0c8f0250192ef56aeb595e7b46eef32f,,"ExecStop=/usr/bin/podman stop -t {{ lookup('dict', container_data).value.stop_grace_period | default(42) | int }} {{ lookup('dict', container_data).key }} ExecStopPost=/usr/bin/podman stop -t {{ lookup('dict', container_data).value.stop_grace_period | default(42) | int }} {{ lookup('dict', container_data).key }}TimeoutStopSec={{ 2*(lookup('dict', container_data).value.stop_grace_period | default(42) | int) }} KillMode={{ lookup('dict', container_data).value.kill_mode | default('control-group') }}","ExecStop=/usr/bin/podman stop -t {{ lookup('dict', container_data).value.stop_grace_period | default(10) | int }} {{ lookup('dict', container_data).key }} ExecStopPost=/usr/bin/podman stop -t {{ lookup('dict', container_data).value.stop_grace_period | default(10) | int }} {{ lookup('dict', container_data).key }}KillMode=none",4,3
openstack%2Fnova~stable%2Fussuri~Ia7ad1322b5a15d1407140c77fe0edb179f66ec7a,openstack/nova,stable/ussuri,Ia7ad1322b5a15d1407140c77fe0edb179f66ec7a,Neutron fixture: don't clobber profile and vif_details if empty,ABANDONED,2023-01-19 15:08:19.000000000,2023-01-30 15:04:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 15:08:19.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/886f406d2f7b5eb209507320e5a63ecb11a4fb91', 'message': ""Neutron fixture: don't clobber profile and vif_details if empty\n\nPreviously, the way Neutron fixture's update_port method was coded\nwould cause the binding:profile and binding:vid_details fields to get\nclobbered if they were not passed to the update. This was because if\nnothing was passed, a default of {} was used. This is not how the real\nNeutron API behaves. If nothing is passed, the previous values remain\nand are not replaced with {}. This patches fixes this in the Neutron\nfixture.\n\nChange-Id: Ia7ad1322b5a15d1407140c77fe0edb179f66ec7a\n(cherry picked from commit 62868aaac70d908ade6ff80c8ced54afa0435a76)\n(cherry picked from commit 83ca8b3563c2a293bc0ec153932bdee75aaab8ce)\n""}]",0,871049,886f406d2f7b5eb209507320e5a63ecb11a4fb91,3,1,1,19234,,,0,"Neutron fixture: don't clobber profile and vif_details if empty

Previously, the way Neutron fixture's update_port method was coded
would cause the binding:profile and binding:vid_details fields to get
clobbered if they were not passed to the update. This was because if
nothing was passed, a default of {} was used. This is not how the real
Neutron API behaves. If nothing is passed, the previous values remain
and are not replaced with {}. This patches fixes this in the Neutron
fixture.

Change-Id: Ia7ad1322b5a15d1407140c77fe0edb179f66ec7a
(cherry picked from commit 62868aaac70d908ade6ff80c8ced54afa0435a76)
(cherry picked from commit 83ca8b3563c2a293bc0ec153932bdee75aaab8ce)
",git fetch https://review.opendev.org/openstack/nova refs/changes/49/871049/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,886f406d2f7b5eb209507320e5a63ecb11a4fb91,bug/1851545-stable/ussuri, update = { if body['port'].get('binding:profile'): update['profile'] = copy.deepcopy( body['port']['binding:profile']) if body['port'].get('binding:vif_details'): update['vif_details'] = copy.deepcopy( body['port']['binding:vif_details']) self._port_bindings[port_id][host] = update," self._port_bindings[port_id][host] = { 'profile': copy.deepcopy( body['port'].get('binding:profile') or {}, ), 'vif_details': port.get('binding:vif_details') or {},",8,5
openstack%2Fnova~stable%2Fussuri~I8a040f148427cdee7b8a4983efe2b586d73be88d,openstack/nova,stable/ussuri,I8a040f148427cdee7b8a4983efe2b586d73be88d,fixtures: Handle binding of first port,ABANDONED,2023-01-19 15:06:51.000000000,2023-01-30 15:04:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 15:06:51.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f7a61ff60003cbc4d0a7362fd0becbc3cc2f3d33', 'message': 'fixtures: Handle binding of first port\n\nResolve some TODOs. This is necessary to prove out SR-IOV live\nmigration.\n\nChange-Id: I8a040f148427cdee7b8a4983efe2b586d73be88d\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n(cherry picked from commit 4861eebc91a25056f445a4dc55a87cbb381fea05)\n'}]",0,871048,f7a61ff60003cbc4d0a7362fd0becbc3cc2f3d33,3,1,1,19234,,,0,"fixtures: Handle binding of first port

Resolve some TODOs. This is necessary to prove out SR-IOV live
migration.

Change-Id: I8a040f148427cdee7b8a4983efe2b586d73be88d
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
(cherry picked from commit 4861eebc91a25056f445a4dc55a87cbb381fea05)
",git fetch https://review.opendev.org/openstack/nova refs/changes/48/871048/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,f7a61ff60003cbc4d0a7362fd0becbc3cc2f3d33,bug/1851545-stable/ussuri," port = self._ports[port_id] binding = copy.deepcopy(data['binding']) # NOTE(stephenfin): We don't allow changing of backend binding['vif_type'] = port['binding:vif_type'] binding['vif_details'] = port['binding:vif_details'] binding['vnic_type'] = port['binding:vnic_type'] # the first binding is active by default if not self._port_bindings[port_id]: binding['status'] = 'ACTIVE' else: binding['status'] = 'INACTIVE' self._port_bindings[port_id][binding['host']] = binding return fake_requests.FakeResponse( 200, content=jsonutils.dumps({'binding': binding}), ) def _activate_port_binding(self, port_id, host): def activate_port_binding(self, context, client, port_id, host): failure = self._get_failure_response_if_port_or_binding_not_exists( port_id, host) if failure is not None: return failure self._activate_port_binding(port_id, host) return host, copy.deepcopy(binding) return None, {} _, binding = self._get_active_binding(port['id']) # update port binding if ( 'binding:host_id' in body['port'] and body['port']['binding:host_id'] is None ): # if the host_id is explicitly set to None, delete the binding host, _ = self._get_active_binding(port_id) del self._port_bindings[port_id][host] else: # else it's an update if 'binding:host_id' in body['port']: # if the host ID is present, update that specific binding host = body['port']['binding:host_id'] else: # else update the active one host, _ = self._get_active_binding(port_id) self._port_bindings[port_id][host] = { 'host': host, 'status': 'ACTIVE', 'profile': copy.deepcopy( body['port'].get('binding:profile') or {}, ), 'vif_details': port.get('binding:vif_details') or {}, 'vif_type': port['binding:vif_type'], 'vnic_type': port['binding:vnic_type'], } # mark any other active bindings as inactive self._activate_port_binding(port_id, host) "," host = data['binding']['host'] # We assume that every binding that is created is inactive. # This is only true from the current nova code perspective where # explicit binding creation only happen for migration where the port # is already actively bound to the source host. # TODO(gibi): enhance update_port to detect if the port is bound by # the update and create a binding internally in _port_bindings. Then # we can change the logic here to mimic neutron better by making the # first binding active by default. data['binding']['status'] = 'INACTIVE' self._port_bindings[port_id][host] = copy.deepcopy(data['binding']) return fake_requests.FakeResponse(200, content=jsonutils.dumps(data)) def activate_port_binding(self, context, client, port_id, host): failure = self._get_failure_response_if_port_or_binding_not_exists( port_id, host) if failure is not None: return failure return binding binding = self._get_active_binding(port['id']) or {} # TODO(gibi): check if the port update binds the port and update the # internal _port_bindings dict accordingly. Such a binding always # becomes and active port binding of the port.",64,23
openstack%2Fnova~master~Iff162767a330e47f0f81db07d4200fa1ccb9a084,openstack/nova,master,Iff162767a330e47f0f81db07d4200fa1ccb9a084,DNM: CI test,ABANDONED,2023-01-30 14:38:32.000000000,2023-01-30 14:56:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-30 14:38:32.000000000', 'files': ['nova/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/122431489f70abda1883a37b3dc42f8308b2cd3c', 'message': 'DNM: CI test\n\nDepends-On: https://review.opendev.org/872174\nChange-Id: Iff162767a330e47f0f81db07d4200fa1ccb9a084\n'}]",0,872178,122431489f70abda1883a37b3dc42f8308b2cd3c,7,1,1,17685,,,0,"DNM: CI test

Depends-On: https://review.opendev.org/872174
Change-Id: Iff162767a330e47f0f81db07d4200fa1ccb9a084
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/872178/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/__init__.py'],1,122431489f70abda1883a37b3dc42f8308b2cd3c,ensure-rust-cryptography, #dummy change,,2,0
openstack%2Ftap-as-a-service~master~I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6,openstack/tap-as-a-service,master,I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6,Switch away from Mock auto_spec=True,MERGED,2021-12-10 19:40:21.000000000,2023-01-30 14:56:18.000000000,2023-01-30 14:56:18.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-12-10 19:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/34c1cbc9f64298a1430b7ffddc4ebae1e61317ab', 'message': 'Switch away from Mock auto_spec=True\n\nIn Python 3.10, Mock spec arguments are no longer allowed.\nMore details are available at: https://bugs.python.org/issue43478\n\nCloses-Bug: #1954476\nChange-Id: I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6\n'}, {'number': 2, 'created': '2022-05-31 10:09:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/3fdbc9c5d8787b911a847d457d4bebb2dbcc5d4b', 'message': 'Switch away from Mock auto_spec=True\n\nIn Python 3.10, Mock spec arguments are no longer allowed.\nMore details are available at: https://bugs.python.org/issue43478\n\nCloses-Bug: #1954476\nChange-Id: I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6\n'}, {'number': 3, 'created': '2023-01-30 12:28:06.000000000', 'files': ['neutron_taas/tests/unit/services/taas/test_taas_plugin.py'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/7eaf7dfebb428544056877bfe5aaaab6c582f5ca', 'message': 'Switch away from Mock auto_spec=True\n\nIn Python 3.10, Mock spec arguments are no longer allowed.\nMore details are available at: https://bugs.python.org/issue43478\n\nCloses-Bug: #1954476\nChange-Id: I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6\n'}]",3,821445,7eaf7dfebb428544056877bfe5aaaab6c582f5ca,14,4,3,11805,,,0,"Switch away from Mock auto_spec=True

In Python 3.10, Mock spec arguments are no longer allowed.
More details are available at: https://bugs.python.org/issue43478

Closes-Bug: #1954476
Change-Id: I98c3d6d67ba518f9c6c3455e9c5b0e2ea669a2f6
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/45/821445/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_taas/tests/unit/services/taas/test_taas_plugin.py'],1,34c1cbc9f64298a1430b7ffddc4ebae1e61317ab,," mock.patch.object(n_rpc, 'Connection', spec=object).start() 'TaasAgentApi', spec=object).start()"," mock.patch.object(n_rpc, 'Connection', auto_spec=True).start() 'TaasAgentApi', auto_spec=True).start()",2,2
openstack%2Fkolla-ansible~master~Icaef4b25458490e46f623b055658abc678d2f1c6,openstack/kolla-ansible,master,Icaef4b25458490e46f623b055658abc678d2f1c6,Remove support for Ubuntu Focal 20.04 hosts,MERGED,2023-01-26 13:27:21.000000000,2023-01-30 14:53:01.000000000,2023-01-30 14:50:57.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 26285}, {'_account_id': 27339}]","[{'number': 1, 'created': '2023-01-26 13:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8559162c7cedc68b18e081d8319e85a29a5a049f', 'message': 'Remove support for Ubuntu Focal 20.04 hosts\n\nUsers running on a Focal host will now fail in prechecks.\n\nChange-Id: Icaef4b25458490e46f623b055658abc678d2f1c6\n'}, {'number': 2, 'created': '2023-01-26 14:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bf1b586c7ec0f800c8067586abdf3f400b7790ea', 'message': 'Remove support for Ubuntu Focal 20.04 hosts\n\nUsers running on a Focal host will now fail in prechecks.\n\nChange-Id: Icaef4b25458490e46f623b055658abc678d2f1c6\n'}, {'number': 3, 'created': '2023-01-29 14:29:38.000000000', 'files': ['zuul.d/nodesets.yaml', 'doc/source/user/operating-kolla.rst', 'zuul.d/jobs.yaml', 'ansible/roles/prechecks/vars/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6db6bc0a9f62aa97922aaf6c9d12078d180e2d8a', 'message': 'Remove support for Ubuntu Focal 20.04 hosts\n\nUsers running on a Focal host will now fail in prechecks.\n\nChange-Id: Icaef4b25458490e46f623b055658abc678d2f1c6\n'}]",4,871821,6db6bc0a9f62aa97922aaf6c9d12078d180e2d8a,19,4,3,23084,,,0,"Remove support for Ubuntu Focal 20.04 hosts

Users running on a Focal host will now fail in prechecks.

Change-Id: Icaef4b25458490e46f623b055658abc678d2f1c6
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/21/871821/3 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/nodesets.yaml', 'doc/source/user/operating-kolla.rst', 'zuul.d/jobs.yaml', 'ansible/roles/prechecks/vars/main.yml']",4,8559162c7cedc68b18e081d8319e85a29a5a049f,,," - ""focal""",11,37
openstack%2Fnova~master~Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,openstack/nova,master,Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1,Fix rescue volume-based instance,MERGED,2022-08-10 12:58:44.000000000,2023-01-30 14:04:39.000000000,2023-01-30 11:16:59.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 34860}]","[{'number': 1, 'created': '2022-08-10 12:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0855da8ef121c485f01bfd951ba7f6fcb2686528', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 2, 'created': '2022-08-11 04:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d6d4a548acf40abe14436c8a4dd0b2a8a338f30', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 3, 'created': '2022-08-22 08:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6ed77124635d3077bd7b6380cec6da5aa911761', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 4, 'created': '2022-08-22 11:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c08d2001b4c6914982ce20c472211a941ce1e647', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 5, 'created': '2022-08-22 12:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36b2e2c778243db7a6485830e281016cb45d4c48', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 6, 'created': '2022-08-22 16:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7d91e89a7eaa034930e67e53f04c66760b488621', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nCloses-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 7, 'created': '2022-08-25 13:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/651f33b4aa871c29868dde92f93dbadad309efa4', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 8, 'created': '2022-08-25 16:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b3945a6bba595feb33fe08d7d714ce8293f4ab7', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 9, 'created': '2022-08-26 06:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fdc87ed81884ba64bb105b78dfd81246f4b371e', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}, {'number': 10, 'created': '2022-08-26 06:59:18.000000000', 'files': ['releasenotes/notes/rescue-volume-based-instance-c6e3fba236d90be7.yaml', 'nova/tests/functional/test_server_rescue.py', 'nova/compute/api.py', 'nova/tests/unit/compute/test_api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b', 'message': 'Fix rescue volume-based instance\n\nAs of now, when attempting to rescue a volume-based instance\nusing an image without the hw_rescue_device and/or hw_rescue_bus\nproperties set, the rescue api call fails (as non-stable rescue\nfor volume-based instances are not supported) leaving the instance\nin error state.\n\nThis change checks for hw_rescue_device/hw_rescue_bus image\nproperties before attempting to rescue and if the property\nis not set, then fail with proper error message, without changing\ninstance state.\n\nRelated-Bug: #1978958\nCloses-Bug: #1926601\nChange-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1\n'}]",16,852737,6eed55bf55469f4ceaa7d4d4eb1be635e14bc73b,74,6,10,20733,,,0,"Fix rescue volume-based instance

As of now, when attempting to rescue a volume-based instance
using an image without the hw_rescue_device and/or hw_rescue_bus
properties set, the rescue api call fails (as non-stable rescue
for volume-based instances are not supported) leaving the instance
in error state.

This change checks for hw_rescue_device/hw_rescue_bus image
properties before attempting to rescue and if the property
is not set, then fail with proper error message, without changing
instance state.

Related-Bug: #1978958
Closes-Bug: #1926601
Change-Id: Id4c8c5f3b32985ac7d3d7c833b82e0876f7367c1
",git fetch https://review.opendev.org/openstack/nova refs/changes/37/852737/10 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,0855da8ef121c485f01bfd951ba7f6fcb2686528,lp_1978958, hw_rescue_meta_set = ((image_meta.properties.get( 'hw_rescue_device') is not None) or image_meta.properties.get( 'hw_rescue_bus') is not None) if volume_backed and allow_bfv_rescue and hw_rescue_meta_set:, if volume_backed and allow_bfv_rescue:,5,1
openstack%2Ftripleo-ansible~stable%2Ftrain~If825271ec82f4906cf9ad433a3e4b848f7f2e685,openstack/tripleo-ansible,stable/train,If825271ec82f4906cf9ad433a3e4b848f7f2e685,Cleanup Keystone services that are not required,MERGED,2023-01-10 11:10:06.000000000,2023-01-30 13:54:22.000000000,2023-01-30 13:53:25.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-10 11:10:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/c96dde587d61a6401d9c181a8a10a71a479e29aa', 'message': 'Cleanup Keystone services that are not required\n\nOccassionally, services are disabled by the user. This\ncan happen during upgrades on the undercloud. But it can\nalso be invoked by a user who is removing a service.\n\nThis change introduces a block to cleanup keystone services\nthat are no longer required.\n\nResolves: rhbz#2080199\nChange-Id: If825271ec82f4906cf9ad433a3e4b848f7f2e685\n(cherry picked from commit 1d9093bbefa0433b974a2d104b4e7aeffb600f9b)\n(cherry picked from commit 258cf821e6058480739bc26ecb9054ffbbcf8174)\n'}, {'number': 2, 'created': '2023-01-10 11:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/4b2938799d4d2b7c53cdd6be590f075c11bf66f4', 'message': 'Cleanup Keystone services that are not required\n\nOccassionally, services are disabled by the user. This\ncan happen during upgrades on the undercloud. But it can\nalso be invoked by a user who is removing a service.\n\nThis change introduces a block to cleanup keystone services\nthat are no longer required.\n\nResolves: rhbz#2080199\nChange-Id: If825271ec82f4906cf9ad433a3e4b848f7f2e685\n(cherry picked from commit 1d9093bbefa0433b974a2d104b4e7aeffb600f9b)\n(cherry picked from commit 258cf821e6058480739bc26ecb9054ffbbcf8174)\n'}, {'number': 3, 'created': '2023-01-10 11:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/219cf745c87d3198cfd1d3ace7773ae853a108bf', 'message': 'Cleanup Keystone services that are not required\n\nOccassionally, services are disabled by the user. This\ncan happen during upgrades on the undercloud. But it can\nalso be invoked by a user who is removing a service.\n\nThis change introduces a block to cleanup keystone services\nthat are no longer required.\n\nResolves: rhbz#2080199\nChange-Id: If825271ec82f4906cf9ad433a3e4b848f7f2e685\n(cherry picked from commit 1d9093bbefa0433b974a2d104b4e7aeffb600f9b)\n(cherry picked from commit 258cf821e6058480739bc26ecb9054ffbbcf8174)\n'}, {'number': 4, 'created': '2023-01-16 06:57:35.000000000', 'files': ['tripleo_ansible/roles/tripleo-keystone-resources/tasks/cleanup.yml', 'tripleo_ansible/roles/tripleo-keystone-resources/tasks/main.yml', 'releasenotes/notes/clean-endpoints-cca5478129f0506d.yaml', 'tripleo_ansible/roles/tripleo-keystone-resources/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2728b2fd486c4196014fd4d33870541f3d40e6ce', 'message': 'Cleanup Keystone services that are not required\n\nOccassionally, services are disabled by the user. This\ncan happen during upgrades on the undercloud. But it can\nalso be invoked by a user who is removing a service.\n\nThis change introduces a block to cleanup keystone services\nthat are no longer required.\n\nResolves: rhbz#1876045\nChange-Id: If825271ec82f4906cf9ad433a3e4b848f7f2e685\n(cherry picked from commit 1d9093bbefa0433b974a2d104b4e7aeffb600f9b)\n(cherry picked from commit 258cf821e6058480739bc26ecb9054ffbbcf8174)\n'}]",2,869635,2728b2fd486c4196014fd4d33870541f3d40e6ce,17,5,4,32240,,,0,"Cleanup Keystone services that are not required

Occassionally, services are disabled by the user. This
can happen during upgrades on the undercloud. But it can
also be invoked by a user who is removing a service.

This change introduces a block to cleanup keystone services
that are no longer required.

Resolves: rhbz#1876045
Change-Id: If825271ec82f4906cf9ad433a3e4b848f7f2e685
(cherry picked from commit 1d9093bbefa0433b974a2d104b4e7aeffb600f9b)
(cherry picked from commit 258cf821e6058480739bc26ecb9054ffbbcf8174)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/35/869635/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_keystone_resources/tasks/cleanup.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/tasks/main.yml', 'tripleo_ansible/roles/tripleo_keystone_resources/defaults/main.yml', 'releasenotes/notes/clean-endpoints-cca5478129f0506d.yaml']",4,c96dde587d61a6401d9c181a8a10a71a479e29aa,cleanup-endpoints-stable/wallaby-stable/train,--- features: - | Add a new playbook to allow for the removal of old Keystone services. This playbook will remove any services that exist but have since been disabled. This cleanup task is tunable using `tripleo_keystone_resources_cleanup` which by default is set to True. ,,176,0
openstack%2Fcharm-mysql-innodb-cluster~stable%2Fjammy~If5e5beda90a918e8ff48f1d47fc91d90d79d27fe,openstack/charm-mysql-innodb-cluster,stable/jammy,If5e5beda90a918e8ff48f1d47fc91d90d79d27fe,Pin tox to < 4.0.0,MERGED,2023-01-20 20:11:27.000000000,2023-01-30 13:46:47.000000000,2023-01-30 13:46:47.000000000,"[{'_account_id': 2424}, {'_account_id': 10366}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 20:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/91b4ff14ef285f6ae696c51906934719a2c336c3', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: If5e5beda90a918e8ff48f1d47fc91d90d79d27fe\n""}, {'number': 2, 'created': '2023-01-23 01:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/d4dc670758dca51bdebea872e1bc9dfbbc80bc46', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAlso, accommodate the following changes from origin/master by hand:\n- bindep.txt\n\nRelated-Bug: #2002788\nChange-Id: If5e5beda90a918e8ff48f1d47fc91d90d79d27fe\n""}, {'number': 3, 'created': '2023-01-24 17:23:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/f67ce7c4f2b55814bbb1880c17cc725dc378dbb5', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes include:\n- Add bindep.txt changes from origin/master by hand.\n- Switch charm-tools to 2.8.4 to remove ruamel requirement that\n  doesn't work on Python 3.10.\n\nRelated-Bug: #2002788\nChange-Id: If5e5beda90a918e8ff48f1d47fc91d90d79d27fe\n""}, {'number': 4, 'created': '2023-01-24 19:51:46.000000000', 'files': ['requirements.txt', 'bindep.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/0a3bb225c1a653767f542e1f9023ad27735a5bc5', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nAdditional changes include:\n- Add bindep.txt changes from origin/master by hand.\n- Switch charm-tools to 2.8.4 to remove ruamel requirement that\n  doesn't work on Python 3.10.\n\nRelated-Bug: #2002788\nChange-Id: If5e5beda90a918e8ff48f1d47fc91d90d79d27fe\n""}]",11,871369,0a3bb225c1a653767f542e1f9023ad27735a5bc5,31,5,4,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Additional changes include:
- Add bindep.txt changes from origin/master by hand.
- Switch charm-tools to 2.8.4 to remove ruamel requirement that
  doesn't work on Python 3.10.

Related-Bug: #2002788
Change-Id: If5e5beda90a918e8ff48f1d47fc91d90d79d27fe
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/69/871369/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,91b4ff14ef285f6ae696c51906934719a2c336c3,pin-tox-jammy, tox < 4.0.0,,1,0
openstack%2Fkolla-ansible~master~I0adbe0a6c39e11d7c9542569085fc5d580f26c9d,openstack/kolla-ansible,master,I0adbe0a6c39e11d7c9542569085fc5d580f26c9d,Remove system scope token to access services,MERGED,2023-01-18 03:22:14.000000000,2023-01-30 13:04:24.000000000,2023-01-30 13:03:12.000000000,"[{'_account_id': 8556}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-01-18 03:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b75214e98d8daa648e874e15100e1e685744e367', 'message': 'Remove system scope token to access services\n\nAs per the RBAC new direction in Zed cycle, we have dropped the\nsystem scope from API policies and all the policies are hardcoded\nto project scoped so that any user accessing APIs using system scope\nwill get 403 error. It is dropped from all the OpenStack services\nexcept for the Ironic service which will have system scope and to\nsupport ironic only deployment, we are keeping system as well as project\nscope in Keystone.\n\nComplete discussion and direction can be found in the below gerrit\nchange and TC goal direction:\n\n- https://review.opendev.org/c/openstack/governance/+/847418\n- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept\n\nAs phase-2 of RBAC goal, services will start enabling the new\ndefaults and project scope by default. For example: Nova did in\n- https://review.opendev.org/c/openstack/nova/+/866218\n\nKolla who start accessing the services using system scope token\n- https://review.opendev.org/c/openstack/kolla-ansible/+/692179\n\nThis commit partially revert the above change except keeping\nsystem scope usage for Keystone and Ironic. Rest all services are changed\nto use the project scope token.\n\nChange-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d\n'}, {'number': 2, 'created': '2023-01-18 03:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/817dc339f79d84dbd6191140775b621dfe057156', 'message': 'Remove system scope token to access services\n\nAs per the RBAC new direction in Zed cycle, we have dropped the\nsystem scope from API policies and all the policies are hardcoded\nto project scoped so that any user accessing APIs using system scope\nwill get 403 error. It is dropped from all the OpenStack services\nexcept for the Ironic service which will have system scope and to\nsupport ironic only deployment, we are keeping system as well as project\nscope in Keystone.\n\nComplete discussion and direction can be found in the below gerrit\nchange and TC goal direction:\n\n- https://review.opendev.org/c/openstack/governance/+/847418\n- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept\n\nAs phase-2 of RBAC goal, services will start enabling the new\ndefaults and project scope by default. For example: Nova did in\n- https://review.opendev.org/c/openstack/nova/+/866218\n\nKolla who start accessing the services using system scope token\n- https://review.opendev.org/c/openstack/kolla-ansible/+/692179\n\nThis commit partially revert the above change except keeping\nsystem scope usage for Keystone and Ironic. Rest all services are changed\nto use the project scope token.\n\nAnd enable the scope and new defaults for Nova which was disabled\nby https://review.opendev.org/c/openstack/kolla-ansible/+/870804\n\nChange-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d\n'}, {'number': 3, 'created': '2023-01-18 15:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b04c0524f8548f097a03e453938c76d9be45dfb4', 'message': 'Remove system scope token to access services\n\nAs per the RBAC new direction in Zed cycle, we have dropped the\nsystem scope from API policies and all the policies are hardcoded\nto project scoped so that any user accessing APIs using system scope\nwill get 403 error. It is dropped from all the OpenStack services\nexcept for the Ironic service which will have system scope and to\nsupport ironic only deployment, we are keeping system as well as project\nscope in Keystone.\n\nComplete discussion and direction can be found in the below gerrit\nchange and TC goal direction:\n\n- https://review.opendev.org/c/openstack/governance/+/847418\n- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept\n\nAs phase-2 of RBAC goal, services will start enabling the new\ndefaults and project scope by default. For example: Nova did in\n- https://review.opendev.org/c/openstack/nova/+/866218\n\nKolla who start accessing the services using system scope token\n- https://review.opendev.org/c/openstack/kolla-ansible/+/692179\n\nThis commit partially revert the above change except keeping\nsystem scope usage for Keystone and Ironic. Rest all services are changed\nto use the project scope token.\n\nAnd enable the scope and new defaults for Nova which was disabled\nby https://review.opendev.org/c/openstack/kolla-ansible/+/870804\n\nChange-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d\n'}, {'number': 4, 'created': '2023-01-19 10:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e88520b4e50b73c323d790442dc24a2b3aa38ffc', 'message': 'Remove system scope token to access services\n\nAs per the RBAC new direction in Zed cycle, we have dropped the\nsystem scope from API policies and all the policies are hardcoded\nto project scoped so that any user accessing APIs using system scope\nwill get 403 error. It is dropped from all the OpenStack services\nexcept for the Ironic service which will have system scope and to\nsupport ironic only deployment, we are keeping system as well as project\nscope in Keystone.\n\nComplete discussion and direction can be found in the below gerrit\nchange and TC goal direction:\n\n- https://review.opendev.org/c/openstack/governance/+/847418\n- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept\n\nAs phase-2 of RBAC goal, services will start enabling the new\ndefaults and project scope by default. For example: Nova did in\n- https://review.opendev.org/c/openstack/nova/+/866218\n\nKolla who start accessing the services using system scope token\n- https://review.opendev.org/c/openstack/kolla-ansible/+/692179\n\nThis commit partially revert the above change except keeping\nsystem scope usage for Keystone and Ironic. Rest all services are changed\nto use the project scope token.\n\nAnd enable the scope and new defaults for Nova which was disabled\nby https://review.opendev.org/c/openstack/kolla-ansible/+/870804\n\nChange-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d\n'}, {'number': 5, 'created': '2023-01-26 23:52:13.000000000', 'files': ['ansible/roles/freezer/templates/freezer.conf.j2', 'doc/source/user/multi-regions.rst', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/keystone/tasks/register_identity_providers.yml', 'ansible/roles/ironic/tasks/upgrade.yml', 'ansible/roles/murano/tasks/import_library_packages.yml', 'ansible/roles/nova/templates/nova.conf.j2', 'releasenotes/notes/stop-using-system-scope-token-328a64927dc0fb2e.yaml', 'ansible/roles/nova-cell/tasks/wait_discover_computes.yml', 'ansible/roles/heat/tasks/bootstrap_service.yml', 'ansible/roles/keystone/tasks/register.yml', 'ansible/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/283fa242caffe058ec770941da7889e6e1fbff5b', 'message': 'Remove system scope token to access services\n\nAs per the RBAC new direction in Zed cycle, we have dropped the\nsystem scope from API policies and all the policies are hardcoded\nto project scoped so that any user accessing APIs using system scope\nwill get 403 error. It is dropped from all the OpenStack services\nexcept for the Ironic service which will have system scope and to\nsupport ironic only deployment, we are keeping system as well as project\nscope in Keystone.\n\nComplete discussion and direction can be found in the below gerrit\nchange and TC goal direction:\n\n- https://review.opendev.org/c/openstack/governance/+/847418\n- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept\n\nAs phase-2 of RBAC goal, services will start enabling the new\ndefaults and project scope by default. For example: Nova did in\n- https://review.opendev.org/c/openstack/nova/+/866218\n\nKolla who start accessing the services using system scope token\n- https://review.opendev.org/c/openstack/kolla-ansible/+/692179\n\nThis commit partially revert the above change except keeping\nsystem scope usage for Keystone and Ironic. Rest all services are changed\nto use the project scope token.\n\nAnd enable the scope and new defaults for Nova which was disabled\nby https://review.opendev.org/c/openstack/kolla-ansible/+/870804\n\nChange-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d\n'}]",14,870879,283fa242caffe058ec770941da7889e6e1fbff5b,29,4,5,8556,,,0,"Remove system scope token to access services

As per the RBAC new direction in Zed cycle, we have dropped the
system scope from API policies and all the policies are hardcoded
to project scoped so that any user accessing APIs using system scope
will get 403 error. It is dropped from all the OpenStack services
except for the Ironic service which will have system scope and to
support ironic only deployment, we are keeping system as well as project
scope in Keystone.

Complete discussion and direction can be found in the below gerrit
change and TC goal direction:

- https://review.opendev.org/c/openstack/governance/+/847418
- https://governance.openstack.org/tc/goals/selected/consistent-and-secure-rbac.html#the-issues-we-are-facing-with-scope-concept

As phase-2 of RBAC goal, services will start enabling the new
defaults and project scope by default. For example: Nova did in
- https://review.opendev.org/c/openstack/nova/+/866218

Kolla who start accessing the services using system scope token
- https://review.opendev.org/c/openstack/kolla-ansible/+/692179

This commit partially revert the above change except keeping
system scope usage for Keystone and Ironic. Rest all services are changed
to use the project scope token.

And enable the scope and new defaults for Nova which was disabled
by https://review.opendev.org/c/openstack/kolla-ansible/+/870804

Change-Id: I0adbe0a6c39e11d7c9542569085fc5d580f26c9d
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/79/870879/3 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/skydive/templates/skydive-agent.conf.j2', 'ansible/roles/skydive/defaults/main.yml', 'ansible/roles/freezer/templates/freezer.conf.j2', 'doc/source/user/multi-regions.rst', 'ansible/roles/skydive/templates/skydive-analyzer.conf.j2', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/keystone/tasks/register_identity_providers.yml', 'ansible/roles/ironic/tasks/upgrade.yml', 'ansible/roles/murano/tasks/import_library_packages.yml', 'ansible/roles/nova-cell/tasks/wait_discover_computes.yml', 'ansible/roles/heat/tasks/bootstrap_service.yml', 'ansible/roles/keystone/tasks/register.yml', 'ansible/group_vars/all.yml']",13,b75214e98d8daa648e874e15100e1e685744e367,secure-rbac," project_name: ""{{ keystone_admin_project }}"" domain_name: ""default"""," system_scope: ""all""",37,26
openstack%2Fmagnum-specs~master~I0750ec7440c1fa329104a524cf6779203e842c7c,openstack/magnum-specs,master,I0750ec7440c1fa329104a524cf6779203e842c7c,Add Cluster API Kubernetes COE driver,MERGED,2022-01-12 21:48:29.000000000,2023-01-30 12:35:51.000000000,2023-01-30 12:34:46.000000000,"[{'_account_id': 782}, {'_account_id': 1004}, {'_account_id': 8064}, {'_account_id': 16137}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 33467}]","[{'number': 1, 'created': '2022-01-12 21:48:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/6659b2a0f819b54c2871c4dac98398df2a219391', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI as a common standard.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 2, 'created': '2022-01-26 12:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/1f3877159e5531ba3c2bffcd59f04dfca6609d8a', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI as a common standard.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 3, 'created': '2022-10-17 15:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/2169d3b9020851b8885ec8e819fb956926b6eff8', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 4, 'created': '2022-10-17 16:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/0f3bb9932c57540fe12af6819dfa7a87f5047034', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 5, 'created': '2022-10-18 11:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/d4f010eee2de055f9fe4baaf26b803a513daaf2c', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 6, 'created': '2022-10-18 15:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/3a6acd08771d3fa5889b54ed7a25978a85cc85e4', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 7, 'created': '2022-11-14 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/5990a7eeaaad4941331947841b52f5710b184036', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 8, 'created': '2023-01-30 12:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/27ddaafb4a1f2f62f9fe6a5aa7d6344b80656453', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}, {'number': 9, 'created': '2023-01-30 12:23:47.000000000', 'files': ['doc/source/index.rst', 'specs/bobcat/clusterapi-driver.rst'], 'web_link': 'https://opendev.org/openstack/magnum-specs/commit/042d55a322c52b3495d534d13f8b800a5c274bf8', 'message': 'Add Cluster API Kubernetes COE driver\n\nThis spec proposes a new driver class that implements Kubernetes\ncluster orchestration using Cluster API. The intention of this\nproposal is to create a simplified Kubernetes driver that takes\nadvantage of a broader cross-infrastructure community using Cluster\nAPI.\n\nstory: 2009780\nChange-Id: I0750ec7440c1fa329104a524cf6779203e842c7c\n'}]",79,824488,042d55a322c52b3495d534d13f8b800a5c274bf8,41,8,9,10910,,,0,"Add Cluster API Kubernetes COE driver

This spec proposes a new driver class that implements Kubernetes
cluster orchestration using Cluster API. The intention of this
proposal is to create a simplified Kubernetes driver that takes
advantage of a broader cross-infrastructure community using Cluster
API.

story: 2009780
Change-Id: I0750ec7440c1fa329104a524cf6779203e842c7c
",git fetch https://review.opendev.org/openstack/magnum-specs refs/changes/88/824488/8 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/yoga/clusterapi-driver.rst']",2,6659b2a0f819b54c2871c4dac98398df2a219391,clusterapi-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/magnum/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================== Cluster API driver ================== https://storyboard.openstack.org/#!/story/2009780 Problem description =================== Generally Magnum works best when you treat your Kubernetes clusters as a single-purpose and disposable. If there is a problem, you simply replace your cluster. This can make running production web apps quite hard (although support for sharing Octavia load balancers between multiple clusters could help). However, some use cases require longer-lived clusters that are not disposable. Upgrades in Magnum ------------------ Magnum supports rolling upgrades in some drivers [#]_, although experience suggests this process is not always reliable. The scripts used to implement rolling upgrades have proven hard to maintain and test. Driving Innovation ------------------ The pace of development of the Magnum project has suffered, potentially due to the ongoing effort for sustaining the model used in current drivers. A driver in which most of the core was outsourced to an active external project should reduce maintenance burden. Proposed change =============== All current Magnum COE drivers are built on a common Heat-based driver class. This spec proposes a new driver class that implements Kubernetes cluster orchestration using Cluster API [#]_. The intention of this proposal is to create a simplified Kubernetes driver that takes advantage of a broader cross-infrastructure community using Cluster API as a common standard. Cluster API is not a drop-in replacement for a Magnum COE driver, and some further work will be needed to ensure it has the resources it requires in order to function. Cluster API provisions and operates Kubernetes clusters from an external management cluster, which requires access to OpenStack APIs and provisioned infrastructure. A feature comparison shows that Cluster API has much in common with Magnum, but introduces some innovations that would be beneficial to Magnum. +--------------------------+----------------------+---------------------------+ | Feature | Magnum | Cluster-API | +==========================+======================+===========================+ | Cloud Provider OpenStack | Installed by default | Installed via Helm charts | +--------------------------+----------------------+---------------------------+ | Host OS support | FCOS 33 supported, | Typically Ubuntu 20.04 | | | 34 and beyond WIP | LTS, various choices | | | (due to cgroups v2) | supported by the image | | | | builder [#]_. | | | *NOTE: no security | | | | updates for FCOS 33 | | | | any more?* | | +--------------------------+----------------------+---------------------------+ | External dependencies | Heat, Keystone, | External Kubernetes, | | | others. | Keystone, others. | +--------------------------+----------------------+---------------------------+ | Supported CNIs | Flannel, Calico. | Further options available,| | | | eg Cilium. | +--------------------------+----------------------+---------------------------+ | Cinder CSI | Default from Victoria| Installed via Helm charts.| +--------------------------+----------------------+---------------------------+ | Prometheus monitoring | Installed by default.| Installed via Helm charts.| +--------------------------+----------------------+---------------------------+ | Ingress controllers | Octavia, Traefik, | Nginx installed via Helm. | | | Nginx. | | +--------------------------+----------------------+---------------------------+ | Horizon dashboard | Supported. | Not supported. | +--------------------------+----------------------+---------------------------+ | Delegated authorisation | Keystone trust. | Application credential. | +--------------------------+----------------------+---------------------------+ | Kubernetes CRD API | None. | Helm, flux, argo, etc. | +--------------------------+----------------------+---------------------------+ | In-place upgrades | Partial - depends on | Various supported | | | driver. | strategies, build in | | | | infrastrucutre agnostic | | | | code. Defaults to rolling | | | | upgrade (like Magnum). | +--------------------------+----------------------+---------------------------+ | Self-healing | Partial / uncertain. | Supported with | | | | infrastrcuture agnostic | | | | code via reconciliation | | | | loop. | +--------------------------+----------------------+---------------------------+ | Auto-scaling | Supported for | Supported with | | | default node group. | infrastructure agnositc | | | | code. | +--------------------------+----------------------+---------------------------+ | Multiple node groups | Supported. | Supported, with no default| | | | group. | +--------------------------+----------------------+---------------------------+ | Additional networks | Supported (review | Supported | | | pending) | | +--------------------------+----------------------+---------------------------+ | New Kubernetes versions | Test burden on Magnum| Test burden split between | | | entirely. | Cluster API for | | | | Kubernetes, Magnum for | | | | infrastructure provision. | +--------------------------+----------------------+---------------------------+ The intention for the new driver is to make it compatible with the Magnum REST API. No changes to the REST API are anticipated. Bootstrapping and managing the external management cluster and the Cluster API service is out of scope. This driver would depend on a Cluster API service being installed in a similar way to expecting Heat API to be installed. Alternatives ------------ A roadmap securing ongoing Magnum development is important for the project. Alternatives would include doing something similar outside of Magnum. Implementation ============== Implementation, deployment and operation of the Cluster API service is beyond the scope of this proposal. However, we expect to integrate into devstack a method that uses k3s to provide a simple management cluster that can be used to test this driver. A k3s based Cluster API can itself be used to bootstrap an HA management cluster. Assignee(s) ----------- Primary assignee: * *TBD* Lead at StackHPC With support from: * *TBD* Lead at CERN * *TBD* Lead at VexxHost Milestones ---------- *TBD* Work Items ---------- *TBD* A stubbed-out Cluster API driver framework was proposed here [#]_. Dependencies ============ - The proposed Cluster API driver would integrate particularly well with the Helm-based approach to Kubernetes cluster deployment and configuration. - Introducing a new driver with significant differences in implementation will expose any leaks of abstraction in the class hierarchy. Additional CI tests will be required to increase functional coverage and catch any regressions. Security Impact =============== A new driver built upon Cluster API has the potential to improve security for Magnum, due to wider scrutiny of the open source implementation, a smaller code base for the Magnum team to maintain and a larger community focussing on the security of Cluster API's managed clusters. References ========== .. [#] https://docs.openstack.org/magnum/latest/user/#rolling-upgrade .. [#] https://cluster-api.sigs.k8s.io .. [#] https://github.com/kubernetes-sigs/image-builder/tree/master/images/capi/packer/qemu .. [#] https://review.opendev.org/c/openstack/magnum/+/815521 ",,211,0
openstack%2Fcloudkitty-specs~master~Ie965ad1621c984e6eaa9ae6c85fa0f637f078391,openstack/cloudkitty-specs,master,Ie965ad1621c984e6eaa9ae6c85fa0f637f078391,Fix docs build error,MERGED,2023-01-27 18:42:20.000000000,2023-01-30 12:12:29.000000000,2023-01-30 12:11:07.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 25277}, {'_account_id': 28356}, {'_account_id': 30695}]","[{'number': 1, 'created': '2023-01-27 18:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-specs/commit/7f59c63a2be575f0ca1937cd0684ec278e7b2d8f', 'message': 'Fix docs build error\n\nThis patch fixes docs build errors such as the ones seen in https://review.opendev.org/c/openstack/cloudkitty-specs/+/866198\n\nChange-Id: Ie965ad1621c984e6eaa9ae6c85fa0f637f078391\n'}, {'number': 2, 'created': '2023-01-30 11:47:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty-specs/commit/d5261f48a3da9e60760b731cd26248d187e0fbac', 'message': 'Fix docs build error\n\nThis patch fixes docs build errors such as the ones seen in\nhttps://review.opendev.org/c/openstack/cloudkitty-specs/+/866198\n\nChange-Id: Ie965ad1621c984e6eaa9ae6c85fa0f637f078391\n'}]",7,872041,d5261f48a3da9e60760b731cd26248d187e0fbac,14,5,2,28356,,,0,"Fix docs build error

This patch fixes docs build errors such as the ones seen in
https://review.opendev.org/c/openstack/cloudkitty-specs/+/866198

Change-Id: Ie965ad1621c984e6eaa9ae6c85fa0f637f078391
",git fetch https://review.opendev.org/openstack/cloudkitty-specs refs/changes/41/872041/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7f59c63a2be575f0ca1937cd0684ec278e7b2d8f,fix_docs-pdf-build,allowlist_externals = makeallowlist_externals =,whitelist_externals =,3,1
openstack%2Fneutron~stable%2Fzed~I7a4056680d8453b2ef2dcc853437a0ec4b3e8044,openstack/neutron,stable/zed,I7a4056680d8453b2ef2dcc853437a0ec4b3e8044,Support L3 agent cleanup on shutdown,ABANDONED,2023-01-30 11:54:52.000000000,2023-01-30 12:02:21.000000000,,[],"[{'number': 1, 'created': '2023-01-30 11:54:52.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/conf/agent/l3/config.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ea8c670078cfd6db69976d08ba0bb92e48dfd9dd', 'message': 'Support L3 agent cleanup on shutdown\n\nAdd an option to delete all routers on agent shutdown.\n\nCloses-Bug: #1851609\nChange-Id: I7a4056680d8453b2ef2dcc853437a0ec4b3e8044\n(cherry picked from commit 566351761318aa1f33650ba4d78b55cc6a4f8f7b)\n'}]",0,872114,ea8c670078cfd6db69976d08ba0bb92e48dfd9dd,3,0,1,14826,,,0,"Support L3 agent cleanup on shutdown

Add an option to delete all routers on agent shutdown.

Closes-Bug: #1851609
Change-Id: I7a4056680d8453b2ef2dcc853437a0ec4b3e8044
(cherry picked from commit 566351761318aa1f33650ba4d78b55cc6a4f8f7b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/872114/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/agent.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/conf/agent/l3/config.py']",3,ea8c670078cfd6db69976d08ba0bb92e48dfd9dd,bug/1851609-stable/zed,<<<<<<< HEAD (931f0a Never raise an exception in notify())======= >>>>>>> CHANGE (566351 Support L3 agent cleanup on shutdown),,33,0
openstack%2Ftripleo-ansible~stable%2Fwallaby~I4c1090f6d335509051c63f1a1788abd1606cfa4f,openstack/tripleo-ansible,stable/wallaby,I4c1090f6d335509051c63f1a1788abd1606cfa4f,Adding modules for retrieval of overcloud role info,MERGED,2023-01-03 10:13:26.000000000,2023-01-30 11:58:10.000000000,2023-01-30 11:57:16.000000000,"[{'_account_id': 9816}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}]","[{'number': 1, 'created': '2023-01-03 10:13:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2112da7c1e7ece216f20164f6dc5e27e3b171da7', 'message': 'Adding modules for retrieval of overcloud role info\n\nDocumentation included.\n\nResolves: rhbz#2136519\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f\n(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)\n(cherry picked from commit 7a318433b6205693bfefd3f58230f60dbf19c71c)\n'}, {'number': 2, 'created': '2023-01-23 13:29:39.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_show.py', 'doc/source/modules/modules-tripleo-overcloud_role_show.rst', 'doc/source/modules/modules-tripleo_overcloud_role_list.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_list.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/61d9e8be5ef184dd00194fe50a839585b5c63b88', 'message': 'Adding modules for retrieval of overcloud role info\n\nDocumentation included.\n\nBackport note:\nThis backport includes change I2b31100c7a547f10ff9f445811c0bf4084fec3cd\nwhich fixed several problems with the original change.\n\nResolves: rhbz#2136519\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f\n(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)\n(cherry picked from commit 156bf5f696f9502b892f7d818ea7741e005b83e3)\n'}]",1,869066,61d9e8be5ef184dd00194fe50a839585b5c63b88,15,5,2,32926,,,0,"Adding modules for retrieval of overcloud role info

Documentation included.

Backport note:
This backport includes change I2b31100c7a547f10ff9f445811c0bf4084fec3cd
which fixed several problems with the original change.

Resolves: rhbz#2136519

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f
(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)
(cherry picked from commit 156bf5f696f9502b892f7d818ea7741e005b83e3)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/66/869066/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_show.py', 'doc/source/modules/modules-tripleo-overcloud_role_show.rst', 'doc/source/modules/modules-tripleo_overcloud_role_list.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_list.py']",4,2112da7c1e7ece216f20164f6dc5e27e3b171da7,,"#!/usr/bin/python # -*- coding: utf-8 -*- # Copyright (c) 2022 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import yaml from ansible.module_utils.basic import AnsibleModule from ansible_collections.openstack.cloud.plugins.module_utils.openstack import openstack_full_argument_spec from ansible_collections.openstack.cloud.plugins.module_utils.openstack import openstack_module_kwargs from tripleo_common.utils import roles as rolesutils ROLES_PATH_DEFAULT = ""/usr/share/openstack-tripleo-heat-templates/roles"" ANSIBLE_METADATA = { 'metadata_version': '1.1', 'status': ['preview'], 'supported_by': 'community' } DOCUMENTATION = f''' --- module: tripleo_overcloud_role_list short_description: Retrieve list of overcloud roles version_added: ""4.2"" description: - ""Retrieve list of overcloud roles"" options: roles_path: description: - Path to the tripleo heat templates roles directory default: {ROLES_PATH_DEFAULT} author: - Jiri Podivin <jpodivin@redhat.com> ''' RETURN = ''' role_list: description: Overcloud roles list returned: always type: list elements: string sample: [ ""BlockStorage"", ""CellController"", ""CephAll"", ""NetworkerSriov"", ""NovaManager"", ""Novacontrol"", ""ObjectStorage"", ""Standalone"", ""Telemetry"", ""Undercloud"" ] ''' EXAMPLES = ''' - name: Get Overcloud roles list tripleo_overcloud_role_list: register: overcloud_role_list - name: Write data to output file copy: content: ""{{ overcloud_role_list.role_list | to_yaml }}"" dest: /path/exported-overcloud_role_list.yaml ''' def run_module(): result = dict( success=False, changed=False, error="""", role_list=list() ) argument_spec = openstack_full_argument_spec( **yaml.safe_load(DOCUMENTATION)['options'] ) module = AnsibleModule( argument_spec, supports_check_mode=True, **openstack_module_kwargs() ) try: roles_path = module.params[ROLES_PATH_DEFAULT] result['role_list'] = rolesutils.get_roles_list_from_directory(roles_path) result['changed'] = bool(result['role_list']) module.exit_json(**result) except Exception as err: result['error'] = str(err) result['msg'] = (""Error getting role list: %{error}"".format(error=err)) module.fail_json(**result) def main(): run_module() if __name__ == '__main__': main() ",,337,0
openstack%2Fci-log-processing~master~I7b8f19ed650c6c4b3694423855f17ec3bdb8b785,openstack/ci-log-processing,master,I7b8f19ed650c6c4b3694423855f17ec3bdb8b785,Add Elasticsearch Exporter ansible role,NEW,2022-09-05 12:09:18.000000000,2023-01-30 11:23:43.000000000,,"[{'_account_id': 6889}, {'_account_id': 9311}, {'_account_id': 18551}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-05 12:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ci-log-processing/commit/f852dccf8f722a54bf472b64f43d3771f2c48a53', 'message': 'DNM Add Elasticsearch Exporter ansible role\n\nThe Elasticsearch Exporter would provide interesting metrics\nto monitor Opensearch host.\n\nChange-Id: I7b8f19ed650c6c4b3694423855f17ec3bdb8b785\n'}, {'number': 2, 'created': '2022-09-06 07:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ci-log-processing/commit/90f31cfb564e38c9441073571c590a6cf04598eb', 'message': 'Add Elasticsearch Exporter ansible role\n\nThe Elasticsearch Exporter would provide interesting metrics\nto monitor Opensearch host.\n\nChange-Id: I7b8f19ed650c6c4b3694423855f17ec3bdb8b785\n'}, {'number': 3, 'created': '2022-09-29 12:32:05.000000000', 'files': ['ansible/playbooks/deploy-services.yml', 'ansible/roles/check-services/tasks/download.yml', 'ansible/roles/elasticsearch-exporter/templates/elasticsearch-exporter.sh.j2', 'ansible/playbooks/check-services-sender.yml', 'ansible/roles/elasticsearch-exporter/README.rst', 'ansible/roles/elasticsearch-exporter/tasks/main.yml', 'ansible/roles/elasticsearch-exporter/templates/elasticsearch-exporter.service.j2', 'ansible/roles/elasticsearch-exporter/tasks/service.yml', 'ansible/roles/elasticsearch-exporter/meta/main.yml', 'ansible/roles/check-services/tasks/main.yml', 'ansible/roles/elasticsearch-exporter/defaults/main.yml', 'ansible/playbooks/check-services.yml'], 'web_link': 'https://opendev.org/openstack/ci-log-processing/commit/4ea257f816f07b4a122f64560fd621dbdea32ca1', 'message': 'Add Elasticsearch Exporter ansible role\n\nThe Elasticsearch Exporter would provide interesting metrics\nto monitor Opensearch host.\n\nChange-Id: I7b8f19ed650c6c4b3694423855f17ec3bdb8b785\n'}]",0,855875,4ea257f816f07b4a122f64560fd621dbdea32ca1,8,4,3,20676,,,0,"Add Elasticsearch Exporter ansible role

The Elasticsearch Exporter would provide interesting metrics
to monitor Opensearch host.

Change-Id: I7b8f19ed650c6c4b3694423855f17ec3bdb8b785
",git fetch https://review.opendev.org/openstack/ci-log-processing refs/changes/75/855875/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/playbooks/deploy-services.yml', 'ansible/roles/check-services/tasks/download.yml', 'ansible/roles/elasticsearch-exporter/templates/elasticsearch-exporter.sh.j2', 'ansible/playbooks/check-services-sender.yml', 'ansible/roles/elasticsearch-exporter/README.rst', 'ansible/roles/elasticsearch-exporter/tasks/main.yml', 'ansible/roles/elasticsearch-exporter/tasks/service.yml', 'ansible/roles/elasticsearch-exporter/templates/elasticsearch-exporter.j2', 'ansible/roles/elasticsearch-exporter/meta/main.yml', 'ansible/roles/check-services/tasks/main.yml', 'ansible/roles/elasticsearch-exporter/defaults/main.yml', 'ansible/playbooks/check-services.yml']",12,f852dccf8f722a54bf472b64f43d3771f2c48a53,, opensearch_url: https://admin:admin@localhost:9200,,207,0
openstack%2Fovn-bgp-agent~master~I4e59fabd66aa9e67d59937762ff9eadca8fe33fd,openstack/ovn-bgp-agent,master,I4e59fabd66aa9e67d59937762ff9eadca8fe33fd,Publish docs to readthedocs,MERGED,2023-01-27 17:36:36.000000000,2023-01-30 11:21:05.000000000,2023-01-30 06:45:15.000000000,"[{'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-01-27 17:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/edbbb2fe1b438875bd2f66ef4ce6074394a8b7f8', 'message': 'Publish docs to readthedocs\n\nDocs should be published at https://ovn-bgp-agent.readthedocs.io/\n\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: I4e59fabd66aa9e67d59937762ff9eadca8fe33fd\n'}, {'number': 2, 'created': '2023-01-27 17:55:13.000000000', 'files': ['zuul.d/project.yaml', 'doc/source/contributor/bgp_mode_design.rst'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/1efb875df1894753c28c56eb9d281d61b10cd94e', 'message': 'Publish docs to readthedocs\n\nDocs should be published at https://ovn-bgp-agent.readthedocs.io/\n\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: I4e59fabd66aa9e67d59937762ff9eadca8fe33fd\n'}]",2,872032,1efb875df1894753c28c56eb9d281d61b10cd94e,9,2,2,6773,,,0,"Publish docs to readthedocs

Docs should be published at https://ovn-bgp-agent.readthedocs.io/

Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Change-Id: I4e59fabd66aa9e67d59937762ff9eadca8fe33fd
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/32/872032/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,edbbb2fe1b438875bd2f66ef4ce6074394a8b7f8,readthedocs, - docs-on-readthedocs vars: rtd_webhook_id: '224878',,3,0
openstack%2Fneutron~stable%2Fwallaby~I5f703d82175d71a222c76df37a82b5ccad890d14,openstack/neutron,stable/wallaby,I5f703d82175d71a222c76df37a82b5ccad890d14,Never raise an exception in notify(),MERGED,2023-01-27 11:27:21.000000000,2023-01-30 11:18:24.000000000,2023-01-30 11:17:06.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 11:27:21.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/848787785eb1140ee7d0eac72f3967b39345e625', 'message': 'Never raise an exception in notify()\n\nnotify() is called from python-ovs code which is not built to\nrecover from an exception in this user-overriden code. If there\nis an exception (e.g. the DB server is down when we process\nthe hash ring), this exception can cause an unrecoverable error\nin processing OVSDB messages, rendering the neutron worker useless.\n\nChange-Id: I5f703d82175d71a222c76df37a82b5ccad890d14\n(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)\n'}]",4,871991,848787785eb1140ee7d0eac72f3967b39345e625,21,5,1,13861,,,0,"Never raise an exception in notify()

notify() is called from python-ovs code which is not built to
recover from an exception in this user-overriden code. If there
is an exception (e.g. the DB server is down when we process
the hash ring), this exception can cause an unrecoverable error
in processing OVSDB messages, rendering the neutron worker useless.

Change-Id: I5f703d82175d71a222c76df37a82b5ccad890d14
(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/871991/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,848787785eb1140ee7d0eac72f3967b39345e625,," try: self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) except Exception as e: LOG.exception(e)"," self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates)",34,30
openstack%2Fironic~master~Ic09d2611553534416d94343c16fbd5b5168be883,openstack/ironic,master,Ic09d2611553534416d94343c16fbd5b5168be883,Imported Translations from Zanata,MERGED,2023-01-28 04:19:23.000000000,2023-01-30 11:12:36.000000000,2023-01-30 11:11:19.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-28 04:19:23.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4e8705dc9f6219b0af8d6d2769fb5aa554f458c5', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic09d2611553534416d94343c16fbd5b5168be883\n'}]",0,872060,4e8705dc9f6219b0af8d6d2769fb5aa554f458c5,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ic09d2611553534416d94343c16fbd5b5168be883
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/872060/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,4e8705dc9f6219b0af8d6d2769fb5aa554f458c5,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-27 22:13+0000\n""""PO-Revision-Date: 2023-01-26 10:06+0000\n""msgid ""13.0.7-29"" msgstr ""13.0.7-29""msgid ""17.1.0-5"" msgstr ""17.1.0-5"" msgid ""18.2.2"" msgstr ""18.2.2""msgid ""20.1.1"" msgstr ""20.1.1"" msgid ""20.1.1-4"" msgstr ""20.1.1-4""msgid ""21.2.0"" msgstr ""21.2.0""msgid """" ""Drivers using the \""agent\"" deploy mechanism do not support \""rebuild --"" ""preserve-ephemeral\"""" msgstr """" ""Drivers using the \""agent\"" deploy mechanism do not support \""rebuild --"" ""preserve-ephemeral\"""" msgid """" ""IPMI Passwords are now obfuscated in REST API responses. This may be "" ""disabled by changing API policy settings."" msgstr """" ""IPMI Passwords are now obfuscated in REST API responses. This may be "" ""disabled by changing API policy settings."" ""The \""agent\"" class of drivers now support both whole-disk and partition "" ""based images."" msgstr """" ""The \""agent\"" class of drivers now support both whole-disk and partition "" ""based images."" msgid """"msgid """" ""While Ironic does include a ClusteredComputeManager, which allows running "" ""more than one nova-compute process with Ironic, it should be considered "" ""experimental and has many known problems."" msgstr """" ""While Ironic does include a ClusteredComputeManager, which allows running "" ""more than one nova-compute process with Ironic, it should be considered "" ""experimental and has many known problems."" ","""POT-Creation-Date: 2022-11-04 18:03+0000\n""""PO-Revision-Date: 2022-11-04 10:34+0000\n""msgid ""11.0.0"" msgstr ""11.0.0"" msgid ""12.0.0"" msgstr ""12.0.0"" msgid ""12.2.0"" msgstr ""12.2.0"" msgid ""13.0.7-28"" msgstr ""13.0.7-28""msgid ""15.0.2-22"" msgstr ""15.0.2-22"" msgid ""16.0.5-9"" msgstr ""16.0.5-9"" msgid ""18.2.1-31"" msgstr ""18.2.1-31""msgid ""20.1.0-29"" msgstr ""20.1.0-29""msgid ""21.1.0-25"" msgstr ""21.1.0-25""""default_boot_mode`` from \""bios\"" to \""uefi\"". It is recommended to set an "" ""explicit value for this option. For hardware types which don't support "" ""setting boot mode, a future release will assume boot mode is set to UEFI if "" ""no boot mode is set to node's capabilities. It is also recommended to set "" ""``boot_mode`` into ``properties/capabilities`` of a node."" msgstr """" ""A future release will change the default value of ``[deploy]/"" ""default_boot_mode`` from \""bios\"" to \""uefi\"". It is recommended to set an "" ""explicit value for this option. For hardware types which don't support "" ""setting boot mode, a future release will assume boot mode is set to UEFI if "" ""no boot mode is set to node's capabilities. It is also recommended to set "" ""``boot_mode`` into ``properties/capabilities`` of a node."" msgid """" ""A future release will change the default value of ``[deploy]/""msgid ""A warning is logged for any changes to immutable configuration options."" msgstr """" ""A warning is logged for any changes to immutable configuration options."" ""API version 1.57 adds a REST API endpoint for updating an existing "" ""allocation. Only ``name`` and ``extra`` fields are allowed to be updated."" msgstr """" ""API version 1.57 adds a REST API endpoint for updating an existing "" ""allocation. Only ``name`` and ``extra`` fields are allowed to be updated."" msgid """" ""API version 1.58 allows backfilling allocations for existing deployed nodes "" ""by providing ``node`` to ``POST /v1/allocations``."" msgstr """" ""API version 1.58 allows backfilling allocations for existing deployed nodes "" ""by providing ``node`` to ``POST /v1/allocations``."" msgid """"""Add ``?detail=`` boolean query to the API list endpoints to provide a more "" ""RESTful alternative to the existing ``/nodes/detail`` and similar endpoints. "" ""The default is False. Now these API requests are possible:"" msgstr """" ""Add ``?detail=`` boolean query to the API list endpoints to provide a more "" ""RESTful alternative to the existing ``/nodes/detail`` and similar endpoints. "" ""The default is False. Now these API requests are possible:"" msgid """"msgid """" ""Adds SNMPv3 message authentication and encryption features to ironic "" ""``snmp`` hardware type. To enable these features, the following parameters "" ""should be used in the node's ``driver_info``:"" msgstr """" ""Adds SNMPv3 message authentication and encryption features to ironic "" ""``snmp`` hardware type. To enable these features, the following parameters "" ""should be used in the node's ``driver_info``:"" msgid ""Adds ``bios`` interface to the ``redfish`` hardware type."" msgstr ""Adds ``bios`` interface to the ``redfish`` hardware type."" ""Adds ``command_timeout`` and ``max_command_attempts`` configuration options "" ""to IPA, so when connection errors occur the command will be executed again. "" ""The options are located in the ``[agent]`` section."" msgstr """" ""Adds ``command_timeout`` and ``max_command_attempts`` configuration options "" ""to IPA, so when connection errors occur the command will be executed again. "" ""The options are located in the ``[agent]`` section."" msgid """"""Adds ``external`` storage interface which is short for \""externally managed"" ""\"". This adds logic to allow the Bare Metal service to identify when a BFV "" ""scenario is being requested based upon the configuration set for ``volume "" ""targets``."" msgstr """" ""Adds ``external`` storage interface which is short for \""externally managed"" ""\"". This adds logic to allow the Bare Metal service to identify when a BFV "" ""scenario is being requested based upon the configuration set for ``volume "" ""targets``."" msgid """" ""Adds ``get_boot_mode``, ``set_boot_mode`` and ``get_supported_boot_modes`` "" ""methods to driver management interface. Drivers can override these methods "" ""implementing boot mode management calls to the BMC of the baremetal nodes "" ""being managed."" msgstr """" ""Adds ``get_boot_mode``, ``set_boot_mode`` and ``get_supported_boot_modes`` "" ""methods to driver management interface. Drivers can override these methods "" ""implementing boot mode management calls to the BMC of the baremetal nodes "" ""being managed."" msgid """"msgid """" ""Adds ``reset_idrac`` and ``known_good_state`` cleaning steps to hardware "" ""type ``idrac``. ``reset_idrac`` actually resets the iDRAC; "" ""``known_good_state`` also resets the iDRAC and clears the Lifecycle "" ""Controller job queue to make sure the iDRAC is in good state."" msgstr """" ""Adds ``reset_idrac`` and ``known_good_state`` cleaning steps to hardware "" ""type ``idrac``. ``reset_idrac`` actually resets the iDRAC; "" ""``known_good_state`` also resets the iDRAC and clears the Lifecycle "" ""Controller job queue to make sure the iDRAC is in good state."" ""Adds a ``[conductor]send_sensor_data_for_undeployed_nodes`` option to enable "" ""ironic to collect and transmit sensor data for all nodes for which sensor "" ""data collection is available. By default, this option is not enabled which "" ""aligns with the prior behavior of sensor data collection and transmission "" ""where such data was only collected if an ``instance_uuid`` was present to "" ""signify that the node has been or is being deployed. With this option set to "" ""``True``, operators may be able to identify hardware in a faulty state "" ""through the sensor data and take action before an instance workload is "" ""deployed."" msgstr """" ""Adds a ``[conductor]send_sensor_data_for_undeployed_nodes`` option to enable "" ""ironic to collect and transmit sensor data for all nodes for which sensor "" ""data collection is available. By default, this option is not enabled which "" ""aligns with the prior behaviour of sensor data collection and transmission "" ""where such data was only collected if an ``instance_uuid`` was present to "" ""signify that the node has been or is being deployed. With this option set to "" ""``True``, operators may be able to identify hardware in a faulty state "" ""through the sensor data and take action before an instance workload is "" ""deployed."" msgid """"""Adds a configuration option ``[deploy]disk_erasure_concurrency`` to define "" ""the target pool size used by Ironic Python Agent ramdisk to erase disk "" ""devices. The number of threads created by IPA to erase disk devices is the "" ""minimum value of target pool size and the number of disks to be erased. This "" ""feature can greatly reduce the operation time for baremetals with multiple "" ""disks. For the backwards compatibility, the default value is 1."" msgstr """" ""Adds a configuration option ``[deploy]disk_erasure_concurrency`` to define "" ""the target pool size used by Ironic Python Agent ramdisk to erase disk "" ""devices. The number of threads created by IPA to erase disk devices is the "" ""minimum value of target pool size and the number of disks to be erased. This "" ""feature can greatly reduce the operation time for baremetals with multiple "" ""disks. For the backwards compatibility, the default value is 1."" msgid """" ""Adds a configuration option ``[ipmi]disable_boot_timeout`` which is used to "" ""set the default behavior whether ironic should send a raw IPMI command to "" ""disable timeout. This configuration option can be overidden by the per-node "" ""option ``ipmi_disable_boot_timeout`` in node's ``driver_info`` field. See "" ""`story 2004266 <https://storyboard.openstack.org/#!/story/2004266>`_ and "" ""`Story 2002977 <https://storyboard.openstack.org/#!/story/2002977>`_ for "" ""additional information."" msgstr """" ""Adds a configuration option ``[ipmi]disable_boot_timeout`` which is used to "" ""set the default behaviour whether ironic should send a raw IPMI command to "" ""disable timeout. This configuration option can be overridden by the per-node "" ""option ``ipmi_disable_boot_timeout`` in node's ``driver_info`` field. See "" ""`story 2004266 <https://storyboard.openstack.org/#!/story/2004266>`_ and "" ""`Story 2002977 <https://storyboard.openstack.org/#!/story/2002977>`_ for "" ""additional information."" msgid """"""Adds a new configuration option ``[disk_utils]partprobe_attempts`` which "" ""defaults to 10. This is the maximum number of times to try to read a "" ""partition (if creating a config drive) via a ``partprobe`` command. "" ""Previously, no retries were done which caused failures. This addresses `bug "" ""1756760 <https://storyboard.openstack.org/#!/story/1756760>`_."" msgstr """" ""Adds a new configuration option ``[disk_utils]partprobe_attempts`` which "" ""defaults to 10. This is the maximum number of times to try to read a "" ""partition (if creating a config drive) via a ``partprobe`` command. "" ""Previously, no retries were done which caused failures. This addresses `bug "" ""1756760 <https://storyboard.openstack.org/#!/story/1756760>`_."" msgid """" ""Adds a new configuration option ``[disk_utils]partprobe_attempts`` which "" ""defaults to 10. This is the maximum number of times to try to read a "" ""partition (if creating a config drive) via a ``partprobe`` command. Set it "" ""to 1 if you want the previous behavior, where no retries were done."" msgstr """" ""Adds a new configuration option ``[disk_utils]partprobe_attempts`` which "" ""defaults to 10. This is the maximum number of times to try to read a "" ""partition (if creating a config drive) via a ``partprobe`` command. Set it "" ""to 1 if you want the previous behaviour, where no retries were done."" msgid """"""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. Caution should be taken due to the timeout monitoring is "" ""shifted from ``inspecting`` to ``inspect wait``, please stop all running "" ""asynchronous hardware inspection or wait until it is finished before "" ""upgrading to the Rocky release. Otherwise nodes in asynchronous inspection "" ""will be left at ``inspecting`` state forever unless the database is manually "" ""updated."" msgstr """" ""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. Caution should be taken due to the timeout monitoring is "" ""shifted from ``inspecting`` to ``inspect wait``, please stop all running "" ""asynchronous hardware inspection or wait until it is finished before "" ""upgrading to the Rocky release. Otherwise nodes in asynchronous inspection "" ""will be left at ``inspecting`` state forever unless the database is manually "" ""updated."" msgid """" ""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. Returning ``INSPECTING`` from the ``inspect_hardware`` method "" ""of inspect interface is deprecated, ``INSPECTWAIT`` should be returned "" ""instead."" msgstr """" ""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. Returning ``INSPECTING`` from the ``inspect_hardware`` method "" ""of inspect interface is deprecated, ``INSPECTWAIT`` should be returned "" ""instead."" msgid """" ""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. The ``[conductor]inspect_timeout`` configuration option is "" ""deprecated for removal, please use ``[conductor]inspect_wait_timeout`` "" ""instead to specify the timeout of inspection process."" msgstr """" ""Adds an ``inspect wait`` state to handle asynchronous hardware "" ""introspection. The ``[conductor]inspect_timeout`` configuration option is "" ""deprecated for removal, please use ``[conductor]inspect_wait_timeout`` "" ""instead to specify the timeout of inspection process."" msgid """"",47,237
openstack%2Fopenstacksdk~master~I01772710e637a4a9cb969677ec815c5350c16632,openstack/openstacksdk,master,I01772710e637a4a9cb969677ec815c5350c16632,Allow to disable prometheus metrics collection,NEW,2023-01-28 18:51:42.000000000,2023-01-30 11:02:54.000000000,,"[{'_account_id': 9542}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-28 18:51:42.000000000', 'files': ['openstack/config/cloud_region.py', 'openstack/config/loader.py', 'openstack/tests/unit/config/test_config.py', 'doc/source/user/guides/stats.rst', 'openstack/proxy.py', 'openstack/tests/unit/config/base.py', 'releasenotes/notes/allow-disable-prometheus-metrics-6cc7c633bed5da6e.yaml'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a57140b3b1c4f1fe62e9f0491596e84167f87f65', 'message': 'Allow to disable prometheus metrics collection\n\nThe patch allows to disable prometheus metrics collection via\nclouds config.\n\nStory: 2010556\nTask: 47230\n\nChange-Id: I01772710e637a4a9cb969677ec815c5350c16632\n'}]",1,872067,a57140b3b1c4f1fe62e9f0491596e84167f87f65,4,3,1,14525,,,0,"Allow to disable prometheus metrics collection

The patch allows to disable prometheus metrics collection via
clouds config.

Story: 2010556
Task: 47230

Change-Id: I01772710e637a4a9cb969677ec815c5350c16632
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/67/872067/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/config/cloud_region.py', 'openstack/config/loader.py', 'openstack/tests/unit/config/test_config.py', 'doc/source/user/guides/stats.rst', 'openstack/proxy.py', 'openstack/tests/unit/config/base.py', 'releasenotes/notes/allow-disable-prometheus-metrics-6cc7c633bed5da6e.yaml']",7,a57140b3b1c4f1fe62e9f0491596e84167f87f65,,--- features: - | Add possibility to disable prometheus metrics collection.. ,,55,2
openstack%2Fneutron~master~I403d73a1f35cb6314c814f25628a83d3e111e0fe,openstack/neutron,master,I403d73a1f35cb6314c814f25628a83d3e111e0fe,Honor debug mode in keepalived-state-change script logs,MERGED,2023-01-20 12:33:12.000000000,2023-01-30 10:50:53.000000000,2023-01-30 10:49:28.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 34050}]","[{'number': 1, 'created': '2023-01-20 12:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68623a045ac39110e13764dea39eb30478d7e49c', 'message': 'Honor debug mode in keepalived-state-change script logs\n\nThis patch removes the config option ""debug"" override done\nduring the script initialization.\n\nCloses-Bug: #2003534\nChange-Id: I403d73a1f35cb6314c814f25628a83d3e111e0fe\n'}, {'number': 2, 'created': '2023-01-25 17:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/05ae89a4c7cff8be421cf1e8587db3beeaf308db', 'message': 'Honor debug mode in keepalived-state-change script logs\n\nThis patch removes the config option ""debug"" override done\nduring the script initialization.\n\nCloses-Bug: #2003534\nChange-Id: I403d73a1f35cb6314c814f25628a83d3e111e0fe\n'}, {'number': 3, 'created': '2023-01-25 17:07:57.000000000', 'files': ['neutron/tests/functional/agent/l3/test_keepalived_state_change.py', 'neutron/agent/l3/keepalived_state_change.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a3bdff18abef093c0633bd39187f5a0e582535f', 'message': 'Honor debug mode in keepalived-state-change script logs\n\nThis patch removes the config option ""debug"" override done\nduring the script initialization.\n\nCloses-Bug: #2003534\nChange-Id: I403d73a1f35cb6314c814f25628a83d3e111e0fe\n'}]",4,871274,1a3bdff18abef093c0633bd39187f5a0e582535f,19,6,3,16688,,,0,"Honor debug mode in keepalived-state-change script logs

This patch removes the config option ""debug"" override done
during the script initialization.

Closes-Bug: #2003534
Change-Id: I403d73a1f35cb6314c814f25628a83d3e111e0fe
",git fetch https://review.opendev.org/openstack/neutron refs/changes/74/871274/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/keepalived_state_change.py'],1,68623a045ac39110e13764dea39eb30478d7e49c,bug/2003534,," conf.set_override('debug', True)",0,1
openstack%2Ftripleo-ansible~master~Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089,openstack/tripleo-ansible,master,Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089,Delete keystone users of disabled services,ABANDONED,2023-01-10 06:29:25.000000000,2023-01-30 10:50:51.000000000,,"[{'_account_id': 7294}, {'_account_id': 9816}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-10 06:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/87f69c3366746195849a95e00ff65d94105e2926', 'message': ""Delete keystone users of disabled services\n\nRemoving a service from cloud makes it's user in keystone obsolete.\n\nThis change deletes the corresponding users of the disabled services\nwhose endpoints were cleaned up.\n\nChange-Id: Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089\n""}, {'number': 2, 'created': '2023-01-12 04:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/1d1cdbfe9bc7a43c1206b4521c9bb33274f83f47', 'message': ""Delete keystone users of disabled services\n\nRemoving a service from cloud makes it's user in keystone obsolete.\n\nThis change deletes the corresponding users of the disabled services\nwhose endpoints were cleaned up.\n\nThis change is wallaby-backport-potential.\n\nChange-Id: Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089\n""}, {'number': 3, 'created': '2023-01-16 06:58:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/490a392262e66b5ec3e8ea78d37f0e65de602598', 'message': ""Delete keystone users of disabled services\n\nRemoving a service from cloud makes it's user in keystone obsolete.\n\nThis change deletes the corresponding users of the disabled services\nwhose endpoints were cleaned up.\n\nThis change is wallaby-backport-potential.\n\nResolves: rhbz#1876045\n\nChange-Id: Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089\n""}, {'number': 4, 'created': '2023-01-20 04:44:00.000000000', 'files': ['tripleo_ansible/roles/tripleo_keystone_resources/tasks/cleanup.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a825a397f6f0a892f99e163cb84c55102734b958', 'message': ""Delete keystone users of disabled services\n\nRemoving a service from cloud makes it's user in keystone obsolete.\nAfter the endpoints of the disabled services are cleaned up, this change deletes the corresponding users of those disabled services.\n\nThis change is wallaby-backport-potential.\n\nResolves: rhbz#1876045\n\nChange-Id: Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089\n""}]",2,869651,a825a397f6f0a892f99e163cb84c55102734b958,19,7,4,32240,,,0,"Delete keystone users of disabled services

Removing a service from cloud makes it's user in keystone obsolete.
After the endpoints of the disabled services are cleaned up, this change deletes the corresponding users of those disabled services.

This change is wallaby-backport-potential.

Resolves: rhbz#1876045

Change-Id: Id5ccbe1dc7f348a987a4eee142df96b9f6dcf089
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/51/869651/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/roles/tripleo_keystone_resources/tasks/cleanup.yml'],1,87f69c3366746195849a95e00ff65d94105e2926,," - name: Delete keystone users of disabled services openstack.cloud.identity_user: cloud: ""{{ tripleo_keystone_resources_cloud_name }}"" name: ""{{ item.key }}"" state: absent loop: ""{{ tripleo_keystone_removed_services | dict2items }}"" register: cleanup_users_result",,8,0
openstack%2Fcharm-ops-sunbeam~main~Ia263c0691849bb0d7382562693e96c806cf793ea,openstack/charm-ops-sunbeam,main,Ia263c0691849bb0d7382562693e96c806cf793ea,Make test_utils compatible with ops 2.0,MERGED,2023-01-30 03:57:47.000000000,2023-01-30 10:22:13.000000000,2023-01-30 10:22:13.000000000,"[{'_account_id': 12549}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-30 03:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ops-sunbeam/commit/d0226be882fda21f7692d6b2d8b990687bb2c39d', 'message': 'Remove SIMULATE_CAN_CONNECT\n\nSIMULATE_CAN_CONNECT is removed from ops 2.0\ntesting and is enabled by default.\n\nRemove SIMULATE_CAN_CONNECT from test_utils.\nResync get_pebble function from ops/testing.py\n\nChange-Id: Ia263c0691849bb0d7382562693e96c806cf793ea\n'}, {'number': 2, 'created': '2023-01-30 04:03:32.000000000', 'files': ['ops_sunbeam/test_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-ops-sunbeam/commit/f597a3168ac7a8a79285f5c4670c836ea808d7c1', 'message': 'Make test_utils compatible with ops 2.0\n\nSIMULATE_CAN_CONNECT is removed from ops 2.0\ntesting and is enabled by default [1].\n\nRemove SIMULATE_CAN_CONNECT from test_utils.\nResync get_pebble function from ops/testing.py\n\n[1] https://juju.is/docs/sdk/testing#heading--simulate-can-connect\n\nChange-Id: Ia263c0691849bb0d7382562693e96c806cf793ea\n'}]",0,872086,f597a3168ac7a8a79285f5c4670c836ea808d7c1,7,2,2,10366,,,0,"Make test_utils compatible with ops 2.0

SIMULATE_CAN_CONNECT is removed from ops 2.0
testing and is enabled by default [1].

Remove SIMULATE_CAN_CONNECT from test_utils.
Resync get_pebble function from ops/testing.py

[1] https://juju.is/docs/sdk/testing#heading--simulate-can-connect

Change-Id: Ia263c0691849bb0d7382562693e96c806cf793ea
",git fetch https://review.opendev.org/openstack/charm-ops-sunbeam refs/changes/86/872086/2 && git format-patch -1 --stdout FETCH_HEAD,['ops_sunbeam/test_utils.py'],1,d0226be882fda21f7692d6b2d8b990687bb2c39d,ops2_changes,"# SIMULATE_CAN_CONNECT, container = socket_path.split('/')[3] # /charm/containers/<container_name>/pebble.socket client = self._pebble_clients.get(container, None) if client is None: # Below three lines are changes from parent class method # Add container name to the pebble client client.container_name = container self._pebble_clients[container] = client # we need to know which container a new pebble client belongs to # so we can figure out which storage mounts must be simulated on # this pebble client's mock file systems when storage is # attached/detached later. self._pebble_clients[container] = client self._pebble_clients_can_connect[client] = False"," SIMULATE_CAN_CONNECT, client = self._pebble_clients.get(socket_path, None) if client is None: # Extract container name from: # /charm/containers/placement-api/pebble.socket client.container_name = socket_path.split(""/"")[3] self._pebble_clients[socket_path] = client self._pebble_clients_can_connect[client] = not SIMULATE_CAN_CONNECT",16,7
openstack%2Fpython-aodhclient~stable%2Fussuri~Ia11f25fa8c36c6051a44994f2545e2b64a665593,openstack/python-aodhclient,stable/ussuri,Ia11f25fa8c36c6051a44994f2545e2b64a665593,Change aggregation method to mean and don't use */* in accept header,MERGED,2022-12-20 10:08:31.000000000,2023-01-30 10:17:00.000000000,2023-01-30 10:16:02.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-20 10:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/19c35534d00186dbc45af291f4f8e0db19f7bc73', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence""\nattribute because of change[1] in pyparsing module. Adjust to\nthis change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 2, 'created': '2022-12-21 06:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/0ba23a115951b86d9639091d082e7591142c228c', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence""\nattribute because of change[1] in pyparsing module. Adjust to\nthis change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 3, 'created': '2022-12-21 09:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/6a248152e8c4ebf5538fb085b1e6550bca1639bf', 'message': 'Change aggregation method to mean\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence""\nattribute because of change[1] in pyparsing module. Adjust to\nthis change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 4, 'created': '2022-12-21 13:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/24e1adbe0985195845913bd3fc8b3e59901a76af', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nCommit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\nignoring gnocchi api error when metric is not created.\nHowever there are functional test failures when the\naggregation method is set to last for alarm type\ngnocchi_aggregation_by_resources_threshold,\n\nThis fix changes the aggregration method to mean for\nany create/update of alarm type\ngnocchi_aggregation_by_resources_threshold.\n\nopenstack-tox-py* jobs fail due to missing ""operatorPrecedence""\nattribute because of change[1] in pyparsing module. Adjust to\nthis change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\nThis change also combines changes from [2]\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n[2] https://review.opendev.org/c/openstack/python-aodhclient/+/747722\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 5, 'created': '2022-12-22 07:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/216f69f79472d7a8723b38c8da3fd3fe5bd4d66a', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    ""importlib-metadata"" released v5.0.0, it removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 6, 'created': '2023-01-30 08:25:15.000000000', 'files': ['aodhclient/tests/functional/test_alarm.py', 'aodhclient/utils.py', 'requirements.txt', 'aodhclient/v2/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/d9b6d1f08d208d5769e243f2227921ee53c0f0d2', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    ""importlib-metadata"" released v5.0.0, it removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}]",3,868175,d9b6d1f08d208d5769e243f2227921ee53c0f0d2,24,2,6,32240,,,0,"Change aggregation method to mean and don't use */* in accept header

This commit combines the following changes

* Change aggregation method to mean

     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles
     ignoring gnocchi api error when metric is not created.
     However there are functional test failures when the
     aggregation method is set to last for alarm type
     gnocchi_aggregation_by_resources_threshold,

     This fix changes the aggregration method to mean for
     any create/update of alarm type
     gnocchi_aggregation_by_resources_threshold.

     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""
     attribute because of change[1] in pyparsing module. Adjust to
     this change by using ""infixNotation"" in place of ""operatorPrecedence"".

* Don't use */* in accept header

    The response is returned as text/plain in case of exception.
    Pecan 1.4 uses accept header to decide the response content type.

    This also affected gnocciclient and has been fixed there.
    https://github.com/gnocchixyz/python-gnocchiclient/pull/110

    https://review.opendev.org/747722 (master)
    Co-authored-by: Dan Radez <dradez@redhat.com>

* Set upper-constraint for import-metadata

    py37 job fails with error
    ```
    'EntryPoints' object has no attribute 'get'
    ```

    ""importlib-metadata"" released v5.0.0, it removed the
    deprecated endpoint. So use the version <5.0 and do not
    install the latest version.

Depends-On: https://review.opendev.org/868173
Depends-On: https://review.opendev.org/868174

[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4

Change-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593
Closes-Bug: #1974682
(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)
(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)
(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)
(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/75/868175/6 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/tests/functional/test_alarm.py', 'aodhclient/utils.py', 'tox.ini']",3,19c35534d00186dbc45af291f4f8e0db19f7bc73,," PYTHONWARNINGS=ignore:DEPRECATION::pip._internal.cli.base_command,ignore::UserWarning http://tarballs.openstack.org/aodh/aodh-stable-wallaby.tar.gz#egg=aodh[mysql]", http://tarballs.openstack.org/aodh/aodh-master.tar.gz#egg=aodh[mysql],13,12
openstack%2Fpuppet-neutron~master~I4abc42cd1e6fb728c3f9056133c54ac94e25c62b,openstack/puppet-neutron,master,I4abc42cd1e6fb728c3f9056133c54ac94e25c62b,"Revert ""Disable unit tests incompatible with Ubuntu Focal""",NEW,2022-12-14 06:47:05.000000000,2023-01-30 09:47:09.000000000,,"[{'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-14 06:47:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/317c4728e6ed932e2cdd4f759b91b1fb58c19727', 'message': 'Revert ""Disable unit tests incompatible with Ubuntu Focal""\n\nThis reverts commit cc5d0cf049785bd14b4a982172812cea5527bbfd.\n\nReason for revert:\nWIP\n\nChange-Id: I4abc42cd1e6fb728c3f9056133c54ac94e25c62b\n'}, {'number': 2, 'created': '2023-01-17 09:07:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/9d30616b4a286f0c820edac864b81e4bbe416a2b', 'message': 'Revert ""Disable unit tests incompatible with Ubuntu Focal""\n\nThis reverts commit cc5d0cf049785bd14b4a982172812cea5527bbfd.\n\nReason for revert:\nWIP\n\nChange-Id: I4abc42cd1e6fb728c3f9056133c54ac94e25c62b\n'}, {'number': 3, 'created': '2023-01-30 06:16:36.000000000', 'files': ['spec/classes/neutron_plugins_ovs_opendaylight_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5e8f254e8d61068345b901bee493252f507928ea', 'message': 'Revert ""Disable unit tests incompatible with Ubuntu Focal""\n\nThis reverts commit cc5d0cf049785bd14b4a982172812cea5527bbfd.\n\nReason for revert:\nWIP\n\nChange-Id: I4abc42cd1e6fb728c3f9056133c54ac94e25c62b\n'}]",0,867606,5e8f254e8d61068345b901bee493252f507928ea,7,2,3,9816,,,0,"Revert ""Disable unit tests incompatible with Ubuntu Focal""

This reverts commit cc5d0cf049785bd14b4a982172812cea5527bbfd.

Reason for revert:
WIP

Change-Id: I4abc42cd1e6fb728c3f9056133c54ac94e25c62b
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/06/867606/2 && git format-patch -1 --stdout FETCH_HEAD,['spec/classes/neutron_plugins_ovs_opendaylight_spec.rb'],1,317c4728e6ed932e2cdd4f759b91b1fb58c19727,bug/2004135," context 'with TLS and no CA cert' do before do File.stubs(:file?).returns(true) File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) params.merge!({ :enable_tls => true, :tls_key_file => 'dummy.pem', :tls_cert_file => 'dummy.crt'}) end it_behaves_like 'with TLS enabled' it {should contain_vs_ssl('system').with( 'ensure' => 'present', 'key_file' => 'dummy.pem', 'cert_file' => 'dummy.crt', 'bootstrap' => true, 'before' => 'Exec[Set OVS Manager to OpenDaylight]' )} end context 'with TLS and CA cert' do before do File.stubs(:file?).returns(true) File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) params.merge!({ :enable_tls => true, :tls_key_file => 'dummy.pem', :tls_cert_file => 'dummy.crt', :tls_ca_cert_file => 'ca.crt'}) end it_behaves_like 'with TLS enabled' it {should contain_vs_ssl('system').with( 'ensure' => 'present', 'key_file' => 'dummy.pem', 'cert_file' => 'dummy.crt', 'ca_file' => 'ca.crt', 'before' => 'Exec[Set OVS Manager to OpenDaylight]' )} end context 'with TLS and multiple ODLs' do before do File.stubs(:file?).returns(true) File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) params.merge!({ :enable_tls => true, :tls_key_file => 'dummy.pem', :tls_cert_file => 'dummy.crt', :odl_ovsdb_iface => 'ssl:127.0.0.1:6640 ssl:172.0.0.1:6640'}) end it_behaves_like 'with TLS and ODL HA' it {should contain_vs_ssl('system').with( 'ensure' => 'present', 'key_file' => 'dummy.pem', 'cert_file' => 'dummy.crt', 'bootstrap' => true, 'before' => 'Exec[Set OVS Manager to OpenDaylight]' )} end"," # TODO(tkajinam): The following test cases are now disabled to avoid # failures on Focal. # https://bugs.launchpad.net/puppet-neutron/+bug/1921450 # context 'with TLS and no CA cert' do # before do # File.stubs(:file?).returns(true) # File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) # params.merge!({ # :enable_tls => true, # :tls_key_file => 'dummy.pem', # :tls_cert_file => 'dummy.crt'}) # end # it_behaves_like 'with TLS enabled' # it {should contain_vs_ssl('system').with( # 'ensure' => 'present', # 'key_file' => 'dummy.pem', # 'cert_file' => 'dummy.crt', # 'bootstrap' => true, # 'before' => 'Exec[Set OVS Manager to OpenDaylight]' # )} # end # context 'with TLS and CA cert' do # before do # File.stubs(:file?).returns(true) # File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) # params.merge!({ # :enable_tls => true, # :tls_key_file => 'dummy.pem', # :tls_cert_file => 'dummy.crt', # :tls_ca_cert_file => 'ca.crt'}) # end # it_behaves_like 'with TLS enabled' # it {should contain_vs_ssl('system').with( # 'ensure' => 'present', # 'key_file' => 'dummy.pem', # 'cert_file' => 'dummy.crt', # 'ca_file' => 'ca.crt', # 'before' => 'Exec[Set OVS Manager to OpenDaylight]' # )} # end # context 'with TLS and multiple ODLs' do # before do # File.stubs(:file?).returns(true) # File.stubs(:readlines).returns([""MIIFGjCCBAKgAwIBAgICA""]) # params.merge!({ # :enable_tls => true, # :tls_key_file => 'dummy.pem', # :tls_cert_file => 'dummy.crt', # :odl_ovsdb_iface => 'ssl:127.0.0.1:6640 ssl:172.0.0.1:6640'}) # end # # it_behaves_like 'with TLS and ODL HA' # it {should contain_vs_ssl('system').with( # 'ensure' => 'present', # 'key_file' => 'dummy.pem', # 'cert_file' => 'dummy.crt', # 'bootstrap' => true, # 'before' => 'Exec[Set OVS Manager to OpenDaylight]' # )} # end",57,60
openstack%2Fpuppet-murano~master~I7f83a7fe7ffee3ec6066c132f3fa46f720e3d615,openstack/puppet-murano,master,I7f83a7fe7ffee3ec6066c132f3fa46f720e3d615,Add api version in [keystone_authtoken] www_authenticate_uri,ABANDONED,2023-01-30 09:17:31.000000000,2023-01-30 09:19:47.000000000,,[],"[{'number': 1, 'created': '2023-01-30 09:17:31.000000000', 'files': ['spec/classes/murano_keystone_authtoken_spec.rb', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/80d4cd9e3133f0c4f1e89a650705d6f97e0ca027', 'message': 'Add api version in [keystone_authtoken] www_authenticate_uri\n\nThis fixes the regression caused by [1] and ensures api version is\nincluded in the www_authenticate_uri option. This is required so that\nmurano can decide the identity api version properly.\n\n[1] 183e14ab35c7cf379546b235ea98983c1c9d0259\n\nRelated-Bug: #1754203\nChange-Id: I7f83a7fe7ffee3ec6066c132f3fa46f720e3d615\n'}]",0,872101,80d4cd9e3133f0c4f1e89a650705d6f97e0ca027,2,0,1,9816,,,0,"Add api version in [keystone_authtoken] www_authenticate_uri

This fixes the regression caused by [1] and ensures api version is
included in the www_authenticate_uri option. This is required so that
murano can decide the identity api version properly.

[1] 183e14ab35c7cf379546b235ea98983c1c9d0259

Related-Bug: #1754203
Change-Id: I7f83a7fe7ffee3ec6066c132f3fa46f720e3d615
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/01/872101/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/murano_keystone_authtoken_spec.rb', 'manifests/keystone/authtoken.pp']",2,80d4cd9e3133f0c4f1e89a650705d6f97e0ca027,," $www_authenticate_uri = 'http://localhost:5000/v3',"," $www_authenticate_uri = 'http://localhost:5000',",2,2
openstack%2Fswift~master~Ie28dfffac8a511f30e7b753beb487e5b30849ae7,openstack/swift,master,Ie28dfffac8a511f30e7b753beb487e5b30849ae7,sq: fix probe test,ABANDONED,2022-12-12 13:58:30.000000000,2023-01-30 09:05:35.000000000,,"[{'_account_id': 7847}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-12 13:58:30.000000000', 'files': ['test/probe/test_sharder.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c661c083bb6a38144dcf76cacab192809b1396b4', 'message': 'sq: fix probe test\n\nChange-Id: Ie28dfffac8a511f30e7b753beb487e5b30849ae7\n'}]",7,867225,c661c083bb6a38144dcf76cacab192809b1396b4,5,2,1,7847,,,0,"sq: fix probe test

Change-Id: Ie28dfffac8a511f30e7b753beb487e5b30849ae7
",git fetch https://review.opendev.org/openstack/swift refs/changes/25/867225/1 && git format-patch -1 --stdout FETCH_HEAD,['test/probe/test_sharder.py'],1,c661c083bb6a38144dcf76cacab192809b1396b4,test_probe," c_shard_ranges = self.get_container_shard_ranges() c_shard_brokers = [self.get_shard_broker(c_shard_ranges[0], node_index=i) c_shard_brokers[0].db_file, child_shard_part, c_shard_nodes = self.brain.ring.get_nodes( c_shard_ranges[0].account, c_shard_ranges[0].container) for node in c_shard_nodes: node, 'unsharded', 2, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part) # run sharder on only 2 of the child replicas devs = [node['device'] for node in self.brain.ring.devs if node['device'] != c_shard_nodes[2]['device']] devs_arg = ','.join(devs) self.sharders_once(additional_args=[ '--partitions=%s' % child_shard_part, '--devices=%s' % devs_arg]) for node in c_shard_nodes[:2]: node, 'sharded', 2, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part) # so one child shard remains unsharded self.assert_container_state( c_shard_nodes[2], 'unsharded', 2, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part) # get updates done... self.sharders_once(additional_args=['--devices=%s' % devs_arg]) gc_shard_ranges = self.get_container_shard_ranges( account=c_shard_ranges[0].account, container=c_shard_ranges[0].container) shard_brokers = [self.get_shard_broker(gc_shard_ranges[0], node_index=i) grandchild_shard_part, gc_shard_nodes = self.brain.ring.get_nodes( gc_shard_ranges[0].account, gc_shard_ranges[0].container) self.sharders_once(additional_args=[ '--partitions=%s' % grandchild_shard_part, '--devices=%s' % devs_arg]) self.sharders_once(additional_args=['--devices=%s' % devs_arg]) self.sharders_once(additional_args=['--devices=%s' % devs_arg]) self.container_replicators.once( additional_args='--partitions=%s' % child_shard_part) # the 2 child shards that sharded earlier still have their original # grand-child shards because they stopped updating form root once # sharded for node in c_shard_nodes[:2]: node, 'sharded', 2, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part) # the child shard that did not shard earlier has not been touched by # the sharder since, so still has two grand-child shards c_shard_nodes[2], 'unsharded', 2, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part) # now, finally, run the sharder on the child that is still waiting to # shard # ...it will get 2 great-grandchild ranges from root to replace deleted # grandchild self.sharders_once(additional_args=['--partitions=%s' % child_shard_part, '--devices=%s' % c_shard_nodes[2]['device']]) # batch size is 2 but this replicas has 3 shard ranges so we need two # runs of the sharder self.sharders_once(additional_args=['--partitions=%s' % child_shard_part, '--devices=%s' % c_shard_nodes[2]['device']]) self.assert_container_state( c_shard_nodes[2], 'sharded', 3, account=c_shard_ranges[0].account, container=c_shard_ranges[0].container, part=child_shard_part)"," shard_ranges = self.get_container_shard_ranges() shard_brokers = [self.get_shard_broker(shard_ranges[0], node_index=i) shard_brokers[0].db_file, child_shard_part, shard_nodes = self.brain.ring.get_nodes( shard_ranges[0].account, shard_ranges[0].container) for node in shard_nodes: node, 'unsharded', 2, account=shard_ranges[0].account, container=shard_ranges[0].container, part=child_shard_part) # stop the child shard nodes 0 container. container_node_to_stop = shard_nodes[0] container_to_stop = shard_ranges[0].container self.stop_container_servers_by_ids( [container_node_to_stop.get(""id"") + 1]) self.sharders_once(additional_args='--partitions=%s' % child_shard_part) # get shards to update state from parent... self.sharders_once() for node in shard_nodes[1::]: node, 'sharded', 2, account=shard_ranges[0].account, container=shard_ranges[0].container, part=child_shard_part) shard_ranges = self.get_container_shard_ranges() shard_brokers = [self.get_shard_broker(shard_ranges[0], node_index=i) grandchild_shard_part, shard_nodes = self.brain.ring.get_nodes( shard_ranges[0].account, shard_ranges[0].container) self.sharders_once(additional_args='--partitions=%s' % grandchild_shard_part) self.sharders_once() for node in exclude_nodes(shard_nodes, container_node_to_stop): node, 'sharded', 2, account=shard_ranges[0].account, container=shard_ranges[0].container, part=grandchild_shard_part) self.sharders_once(additional_args='--partitions=%s' % child_shard_part) # get shards to update state from parent... self.sharders_once() self.container_replicators.once( additional_args='--partitions=%s' % child_shard_part) # restart child shard nodes 0 container self.brain.servers.start(number=(container_node_to_stop.get(""id"") + 1)) self.container_replicators.once( additional_args='--partitions=%s' % child_shard_part) self.sharders_once(additional_args='--partitions=%s' % child_shard_part) container_node_to_stop, 'sharded', 2, account=shard_ranges[0].account, container=container_to_stop, part=child_shard_part)",63,48
openstack%2Fdiskimage-builder~master~Id9f816c98977e93aee989523c52c452c9a9d60b2,openstack/diskimage-builder,master,Id9f816c98977e93aee989523c52c452c9a9d60b2,Map curl to curl-minimal for rocky 9,NEW,2023-01-06 04:08:06.000000000,2023-01-30 08:06:49.000000000,,"[{'_account_id': 4571}, {'_account_id': 7118}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 34411}]","[{'number': 1, 'created': '2023-01-06 04:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/f69fe50457e48748ef241399e48e8f4a4d483319', 'message': 'Map curl to curl-minimal for rocky 9\n\nCurl-minimal is included in the base rocky 9 images but conflicts\nwith the curl package that cache-url tries to install. To make sure\nwe always have curl installed a pkg-map seems to be the best fix.\n\nCloses-Bug: #2002066\nChange-Id: Id9f816c98977e93aee989523c52c452c9a9d60b2\n'}, {'number': 2, 'created': '2023-01-10 13:59:21.000000000', 'files': ['diskimage_builder/elements/cache-url/pkg-map'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/51adbcceff05d7a909b23be7974d14b3f6e2f0fd', 'message': 'Map curl to curl-minimal for rocky 9\n\nCurl-minimal is included in the base rocky 9 images but conflicts\nwith the curl package that cache-url tries to install. To make sure\nwe always have curl installed a pkg-map seems to be the best fix.\n\nCloses-Bug: #2002066\nChange-Id: Id9f816c98977e93aee989523c52c452c9a9d60b2\n'}]",10,869424,51adbcceff05d7a909b23be7974d14b3f6e2f0fd,17,5,2,28297,,,0,"Map curl to curl-minimal for rocky 9

Curl-minimal is included in the base rocky 9 images but conflicts
with the curl package that cache-url tries to install. To make sure
we always have curl installed a pkg-map seems to be the best fix.

Closes-Bug: #2002066
Change-Id: Id9f816c98977e93aee989523c52c452c9a9d60b2
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/24/869424/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/cache-url/pkg-map'],1,f69fe50457e48748ef241399e48e8f4a4d483319,fix_rocky," }, ""release"": { ""rocky"": { ""9"": { ""curl"": ""curl-minimal"" } }",,7,0
openstack%2Fmanila-tempest-plugin~master~I76175e33f506e35112ab9e86724caa3aea8f546d,openstack/manila-tempest-plugin,master,I76175e33f506e35112ab9e86724caa3aea8f546d,Add tests replica create with 'share-network' option.,MERGED,2021-08-15 19:57:33.000000000,2023-01-30 07:56:44.000000000,2023-01-30 07:56:44.000000000,"[{'_account_id': 6413}, {'_account_id': 16643}, {'_account_id': 19262}, {'_account_id': 20104}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30025}, {'_account_id': 30407}, {'_account_id': 32594}]","[{'number': 1, 'created': '2021-08-15 19:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/5b9873f9dd277151d81fd2f25a942cb10ee33a70', 'message': 'Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 2, 'created': '2021-08-16 14:11:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/618cec02a4237bd92ec5ec552aef0997bcd3e195', 'message': 'Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 3, 'created': '2021-08-16 16:07:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/69440c2c65a91667211b50309b66abbac0c093a3', 'message': 'Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 4, 'created': '2021-09-25 15:49:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/bb7f32c753215a22071ad2028bb6c89c97a5aee3', 'message': 'Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 5, 'created': '2021-09-25 20:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/dfe8e2a55621946a2ccf767f810aa877d487d139', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 6, 'created': '2021-09-26 07:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/7d4c10c788c6650b9fa594db25944ee2bbb5e137', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 7, 'created': '2021-09-26 10:04:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/2ca3f859f48699135c6830e2397f07a510a3e9bc', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 8, 'created': '2021-09-26 17:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/3ab022b7b40b2fe6c3136b525aa7c4eb2e64889c', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 9, 'created': '2022-03-17 14:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/a610ed908b35f592fa61e737f4c40e845e328d4b', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 10, 'created': '2022-03-17 17:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/ea24b6d56f565efb12a5236062e8f3895ee64608', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 11, 'created': '2022-03-17 20:17:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/b6165cd6cb72e63d4949c4e7085321bacfb092b9', 'message': '[WIP]Update tests for share replica create\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n'}, {'number': 12, 'created': '2022-04-06 12:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/883fe52f5fe1ddbab9a092d9b33ccbe3fb8a269c', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 13, 'created': '2022-05-07 14:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/bc321d361d3dd2bbdbed1fe2a67bd3f9c10f741d', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 14, 'created': '2022-09-01 07:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/54fd5b77702ac9690979af3d160f9a94a1b8429c', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 15, 'created': '2022-09-05 08:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/433fbcfdbcacbff2a0f4b796022da1f786dc24c0', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 16, 'created': '2022-09-05 08:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/466c5cb6ab9595d53e178c9d9297952fd29905be', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 17, 'created': '2022-09-21 09:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/69591886b419fa8f3419e972cb099607426a863b', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 18, 'created': '2022-09-23 07:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/b8d8c60421295dc44d6d9351964b1a8b78e63a26', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 19, 'created': '2022-11-16 14:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/6c515ed9f3e841a00e4cdbac3aa03ed2957e8403', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 20, 'created': '2023-01-20 12:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/bfe28c0ede91dfe9670c69d58622271fb652e802', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 21, 'created': '2023-01-23 09:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/0802d753ea1ef164550cb1dc8c32946a5d862447', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 22, 'created': '2023-01-23 12:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/b2803182e1d3e246096284cfc339facd4418e5d4', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 23, 'created': '2023-01-24 08:10:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/6d3e918cc5d9152160a9dd271e34fe5c68cc9bf4', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 24, 'created': '2023-01-26 16:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/77ea838fcb1afcdd40a53c2bb008359195cba2eb', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}, {'number': 25, 'created': '2023-01-27 08:37:35.000000000', 'files': ['manila_tempest_tests/tests/api/base.py', 'manila_tempest_tests/tests/api/test_replication.py', 'manila_tempest_tests/common/constants.py', 'manila_tempest_tests/tests/api/admin/test_replication.py', 'manila_tempest_tests/services/share/v2/json/shares_client.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/2521fbf86a2aa001e5c82dc9fd36d39646b37a3b', 'message': ""Add tests replica create with 'share-network' option.\n\nThis patch update positive and negative tests using the\nshare replica create API. For version >= 2.72.\n\nPartial-Bug: #1925486\nDepends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3\nChange-Id: I76175e33f506e35112ab9e86724caa3aea8f546d\n""}]",41,804589,2521fbf86a2aa001e5c82dc9fd36d39646b37a3b,93,9,25,32919,,,0,"Add tests replica create with 'share-network' option.

This patch update positive and negative tests using the
share replica create API. For version >= 2.72.

Partial-Bug: #1925486
Depends-On: I9049dcd418fbb16d663ab8ed27b90c765fafc5d3
Change-Id: I76175e33f506e35112ab9e86724caa3aea8f546d
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/89/804589/5 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/api/base.py', 'manila_tempest_tests/config.py', 'manila_tempest_tests/tests/api/test_replication_export_locations.py', 'manila_tempest_tests/tests/api/test_replication_snapshots.py', 'manila_tempest_tests/tests/api/admin/test_quotas_negative.py', 'manila_tempest_tests/services/share/v2/json/shares_client.py', 'manila_tempest_tests/tests/api/test_replication.py', 'manila_tempest_tests/common/constants.py', 'manila_tempest_tests/tests/api/test_replication_export_locations_negative.py', 'manila_tempest_tests/tests/api/admin/test_replication.py', 'manila_tempest_tests/tests/api/test_replication_negative.py', 'manila_tempest_tests/tests/api/admin/test_replication_actions.py']",12,5b9873f9dd277151d81fd2f25a942cb10ee33a70,bug/1925486," self.sn_id, cleanup=True, client=self.admin_client) self.sn_id, cleanup=True, client=self.admin_client) self.sn_id, cleanup=True, client=self.admin_client) self.sn_id, cleanup=True, client=self.admin_client)"," cleanup=True, client=self.admin_client) cleanup=True, client=self.admin_client) cleanup=True, client=self.admin_client) cleanup=True, client=self.admin_client)",55,17
openstack%2Freleases~master~I1caf2098287250be33827441ec06e07a48ae575a,openstack/releases,master,I1caf2098287250be33827441ec06e07a48ae575a,EOL Kolla Ussuri and Victoria,MERGED,2023-01-09 14:42:41.000000000,2023-01-30 07:00:51.000000000,2023-01-30 07:00:51.000000000,"[{'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-09 14:42:41.000000000', 'files': ['deliverables/ussuri/kayobe.yaml', 'deliverables/victoria/kayobe.yaml', 'deliverables/ussuri/kolla-ansible.yaml', 'deliverables/victoria/kolla-ansible.yaml', 'deliverables/victoria/kolla.yaml', 'deliverables/ussuri/kolla.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5be3c1fe2952427fd73e2a8da9ceb02e0ba36dc0', 'message': 'EOL Kolla Ussuri and Victoria\n\nChange-Id: I1caf2098287250be33827441ec06e07a48ae575a\n'}]",4,869569,5be3c1fe2952427fd73e2a8da9ceb02e0ba36dc0,12,6,1,23084,,,0,"EOL Kolla Ussuri and Victoria

Change-Id: I1caf2098287250be33827441ec06e07a48ae575a
",git fetch https://review.opendev.org/openstack/releases refs/changes/69/869569/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ussuri/kayobe.yaml', 'deliverables/victoria/kayobe.yaml', 'deliverables/ussuri/kolla-ansible.yaml', 'deliverables/victoria/kolla-ansible.yaml', 'deliverables/victoria/kolla.yaml', 'deliverables/ussuri/kolla.yaml']",6,5be3c1fe2952427fd73e2a8da9ceb02e0ba36dc0,, - version: ussuri-eol projects: - repo: openstack/kolla hash: 9107c5f9ed360176909cc7322faf2d3a9464c675,,32,0
openstack%2Freleases~master~Ic1a4fe3ee7c43764b6a31f9cb70a48a99c5d29a2,openstack/releases,master,Ic1a4fe3ee7c43764b6a31f9cb70a48a99c5d29a2,WIP: Move keystoneauth to independent,ABANDONED,2022-03-04 13:58:06.000000000,2023-01-30 06:43:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-03-04 13:58:06.000000000', 'files': ['deliverables/_independent/keystoneauth.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/13e762118f3b56752baa4175090d5b0d1cf64bf2', 'message': ""WIP: Move keystoneauth to independent\n\nIn Yoga cycle keystoneauth had no functional code change, thus it seems\nthe time has come to transition its release model to 'independent',\nwhich means the team is not required to release changes at milestones.\n\nChange-Id: Ic1a4fe3ee7c43764b6a31f9cb70a48a99c5d29a2\n""}]",0,831943,13e762118f3b56752baa4175090d5b0d1cf64bf2,3,1,1,17685,,,0,"WIP: Move keystoneauth to independent

In Yoga cycle keystoneauth had no functional code change, thus it seems
the time has come to transition its release model to 'independent',
which means the team is not required to release changes at milestones.

Change-Id: Ic1a4fe3ee7c43764b6a31f9cb70a48a99c5d29a2
",git fetch https://review.opendev.org/openstack/releases refs/changes/43/831943/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/keystoneauth.yaml'],1,13e762118f3b56752baa4175090d5b0d1cf64bf2,,--- include-pypi-link: true launchpad: keystoneauth team: keystone type: library repository-settings: openstack/keystoneauth: tarball-base: keystoneauth1 ,,8,0
openstack%2Freleases~master~Ied73a19d6c733f32de397d8c2ad0b4d5547cb379,openstack/releases,master,Ied73a19d6c733f32de397d8c2ad0b4d5547cb379,Remove mistral deliverables from 2023.1 Antelope,ABANDONED,2022-11-24 15:50:49.000000000,2023-01-30 06:29:16.000000000,,"[{'_account_id': 308}, {'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 35600}]","[{'number': 1, 'created': '2022-11-24 15:50:49.000000000', 'files': ['deliverables/antelope/mistral-tempest-plugin.yaml', 'deliverables/antelope/mistral-lib.yaml', 'deliverables/antelope/python-mistralclient.yaml', 'deliverables/antelope/mistral-extra.yaml', 'deliverables/antelope/mistral.yaml', 'deliverables/antelope/mistral-dashboard.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/cb8b2bcea7f7e401ca5389ff3afbab7457fe211d', 'message': 'Remove mistral deliverables from 2023.1 Antelope\n\nMistral deliverables are not actively maintained, thus in release\nmanagement team we tend to have probelms with them at release\ndeadlines. I propose to remove these deliverables from official\n2023.1 Antelope release.\n\nChange-Id: Ied73a19d6c733f32de397d8c2ad0b4d5547cb379\n'}]",1,865577,cb8b2bcea7f7e401ca5389ff3afbab7457fe211d,4,6,1,17685,,,0,"Remove mistral deliverables from 2023.1 Antelope

Mistral deliverables are not actively maintained, thus in release
management team we tend to have probelms with them at release
deadlines. I propose to remove these deliverables from official
2023.1 Antelope release.

Change-Id: Ied73a19d6c733f32de397d8c2ad0b4d5547cb379
",git fetch https://review.opendev.org/openstack/releases refs/changes/77/865577/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/mistral-tempest-plugin.yaml', 'deliverables/antelope/mistral-lib.yaml', 'deliverables/antelope/python-mistralclient.yaml', 'deliverables/antelope/mistral-extra.yaml', 'deliverables/antelope/mistral.yaml', 'deliverables/antelope/mistral-dashboard.yaml']",6,cb8b2bcea7f7e401ca5389ff3afbab7457fe211d,,,--- include-pypi-link: true launchpad: mistral release-model: cycle-with-rc team: mistral type: horizon-plugin repository-settings: openstack/mistral-dashboard: {} ,0,51
openstack%2Freleases~master~I86f8b268d8d94f89f4a807ca24ad81b315280938,openstack/releases,master,I86f8b268d8d94f89f4a807ca24ad81b315280938,Release mistral-extra for Antelope-1 milestone,ABANDONED,2022-11-15 12:56:54.000000000,2023-01-30 06:27:06.000000000,,"[{'_account_id': 8731}, {'_account_id': 15895}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 35600}]","[{'number': 1, 'created': '2022-11-15 12:56:54.000000000', 'files': ['deliverables/antelope/mistral-extra.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/2168653a1a31c5cd8c5c1a40e2cb3e28fd1e888a', 'message': 'Release mistral-extra for Antelope-1 milestone\n\nThis is a library release for mistral-extra for the Antelope-1\nmilestone. This repository contains commits that have not been releases\nfor this cycle yet.\n\nIf the team is ready to process with this release, please leave a +1\nto indicate we should go ahead with the release.\n\nIf the team needs more time for things about to merge, or if there is\nsome other reason a release should not be done at this time, please\nleave a -1 with a comment indicating the status. Then update the patch\nwith the new commit hash to use once the team is ready to do the\nrelease.\n\n$ git log --oneline --no-merges 12.0.1..fbfc343\nc721ecc Drop bay and baymodel\nd631ce5 Update master for stable/zed\n64fdbe5 remove unicode prefix from code\n\nSigned-off-by: Herv Beraud <hberaud@redhat.com>\nChange-Id: I86f8b268d8d94f89f4a807ca24ad81b315280938\n'}]",3,864524,2168653a1a31c5cd8c5c1a40e2cb3e28fd1e888a,6,5,1,28522,,,0,"Release mistral-extra for Antelope-1 milestone

This is a library release for mistral-extra for the Antelope-1
milestone. This repository contains commits that have not been releases
for this cycle yet.

If the team is ready to process with this release, please leave a +1
to indicate we should go ahead with the release.

If the team needs more time for things about to merge, or if there is
some other reason a release should not be done at this time, please
leave a -1 with a comment indicating the status. Then update the patch
with the new commit hash to use once the team is ready to do the
release.

$ git log --oneline --no-merges 12.0.1..fbfc343
c721ecc Drop bay and baymodel
d631ce5 Update master for stable/zed
64fdbe5 remove unicode prefix from code

Signed-off-by: Herv Beraud <hberaud@redhat.com>
Change-Id: I86f8b268d8d94f89f4a807ca24ad81b315280938
",git fetch https://review.opendev.org/openstack/releases refs/changes/24/864524/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/antelope/mistral-extra.yaml'],1,2168653a1a31c5cd8c5c1a40e2cb3e28fd1e888a,antelope-milestone-1,releases: - version: 13.0.0 projects: - repo: openstack/mistral-extra hash: fbfc343f39eaf493beaa723beceea83af41288a9,,5,0
openstack%2Fpython-designateclient~master~I0080c028466d809f4f5118fec05d9e46b2dfce84,openstack/python-designateclient,master,I0080c028466d809f4f5118fec05d9e46b2dfce84,Provide option for delete zonefiles on zone delete,MERGED,2022-03-25 20:19:38.000000000,2023-01-30 06:05:49.000000000,2023-01-30 06:04:47.000000000,"[{'_account_id': 5572}, {'_account_id': 11628}, {'_account_id': 19298}, {'_account_id': 20104}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 29759}, {'_account_id': 32919}]","[{'number': 1, 'created': '2022-03-25 20:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/9996b69fc6a0c976508300156f76c8985ae4b492', 'message': 'Provide option for clean-zonefiles to zone delete\n\nWe do not delete the zone-files on the back-end (Bind) when the zone is\ndeleted in Designate. This results in tens of thousand leftover zone\nfiles on Bind.\n\nThis commit provides an option clean-zonefile for deletion of backend\nzonefile for BIND zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 2, 'created': '2022-06-27 17:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/e9d87aa6fe24b69fe55a98cbbcfa68f4337515b2', 'message': 'Provide option for clean-zonefiles to zone delete\n\nWe do not delete the zone-files on the back-end (Bind) when the zone is\ndeleted in Designate. This results in tens of thousand leftover zone\nfiles on Bind.\n\nThis commit provides an option clean-zonefile for deletion of backend\nzonefile for BIND zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 3, 'created': '2022-10-03 08:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/b779efe1ec7b8b15a4aeb6717b84ec1929b1f488', 'message': 'Provide option for clean-zonefiles to zone delete\n\nWe do not delete the zone-files on the back-end (Bind) when the zone is\ndeleted in Designate. This results in tens of thousand leftover zone\nfiles on Bind.\n\nThis commit provides an option clean-zonefile for deletion of backend\nzonefile for BIND zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 4, 'created': '2022-10-06 13:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/fdaf3d99343648e6f6d25b6af012aaa82ec4542e', 'message': 'Provide option for delete zonefiles on zone delete\n\nThis commit provides an header option (soft-delete) for deletion of\nzonefiles on backend as part of zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 5, 'created': '2022-10-19 19:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/175f5ecec9d37cd9cfb5741e5666689bae7f69d9', 'message': 'Provide option for delete zonefiles on zone delete\n\nThis commit provides an header option (hard-delete) for deletion of\nzonefiles on backend as part of zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 6, 'created': '2022-10-19 20:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/8bfdfbaa2470792d95c336371d5576d9b140949f', 'message': 'Provide option for delete zonefiles on zone delete\n\nThis commit provides an header option (hard-delete) for deletion of\nzonefiles on backend as part of zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 7, 'created': '2023-01-30 01:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/a9c368da29af82979c8c393be104daafcb9fb972', 'message': 'Provide option for delete zonefiles on zone delete\n\nThis commit provides an header option (hard-delete) for deletion of\nzonefiles on backend as part of zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}, {'number': 8, 'created': '2023-01-30 03:44:37.000000000', 'files': ['designateclient/v2/cli/zones.py', 'designateclient/v2/client.py', 'designateclient/v2/cli/common.py', 'releasenotes/notes/add-hard-delete-option-for-zone-delete-e16652c8e72fc023.yaml'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/483e0d16c6b357a610634ad5f7db9ab61b41d353', 'message': 'Provide option for delete zonefiles on zone delete\n\nThis commit provides an header option (hard-delete) for deletion of\nzonefiles on backend as part of zone delete API.\n\nMain patch (in Designate) is:\nhttps://review.opendev.org/c/openstack/designate/+/835317\n\nChange-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84\n'}]",16,835318,483e0d16c6b357a610634ad5f7db9ab61b41d353,42,8,8,34181,,,0,"Provide option for delete zonefiles on zone delete

This commit provides an header option (hard-delete) for deletion of
zonefiles on backend as part of zone delete API.

Main patch (in Designate) is:
https://review.opendev.org/c/openstack/designate/+/835317

Change-Id: I0080c028466d809f4f5118fec05d9e46b2dfce84
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/18/835318/8 && git format-patch -1 --stdout FETCH_HEAD,"['designateclient/v2/cli/zones.py', 'designateclient/client.py', 'designateclient/v2/zones.py']",3,9996b69fc6a0c976508300156f76c8985ae4b492,bug/1966517," def delete(self, zone, clean_zonefile=False): data = { ""clean_zonefile"": clean_zonefile } return self._delete(url, data=data)"," def delete(self, zone): return self._delete(url)",20,3
openstack%2Fpython-designateclient~master~Iad13eb46c2cd89169c1aa9c39492ef7a29c83161,openstack/python-designateclient,master,Iad13eb46c2cd89169c1aa9c39492ef7a29c83161,Update tox.ini for tox4,MERGED,2023-01-30 01:23:42.000000000,2023-01-30 05:34:46.000000000,2023-01-30 05:33:42.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-01-30 01:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/477aa5b6751178edd9ea3a4262abd022bf8f004e', 'message': 'Update tox.ini for tox4\n\nWith tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace.\n\nChange-Id: Iad13eb46c2cd89169c1aa9c39492ef7a29c83161\n'}, {'number': 2, 'created': '2023-01-30 03:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/481ab07155f9a1d62666494e2c82d6836352f111', 'message': 'Update tox.ini for tox4\n\nWith tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace.\n\nChange-Id: Iad13eb46c2cd89169c1aa9c39492ef7a29c83161\n'}, {'number': 3, 'created': '2023-01-30 03:36:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/a4f67bc736ae6c0a53c2d945ff585a3761cb94c3', 'message': 'Update tox.ini for tox4\n\nWith tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace. The skipdist setting also breaks the runs.\n\nChange-Id: Iad13eb46c2cd89169c1aa9c39492ef7a29c83161\n'}]",2,872081,a4f67bc736ae6c0a53c2d945ff585a3761cb94c3,12,3,3,11628,,,0,"Update tox.ini for tox4

With tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace. The skipdist setting also breaks the runs.

Change-Id: Iad13eb46c2cd89169c1aa9c39492ef7a29c83161
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/81/872081/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,477aa5b6751178edd9ea3a4262abd022bf8f004e,,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,7,1
openstack%2Fcyborg-tempest-plugin~master~I123947207791f4388f892c3082aebcc37f48d252,openstack/cyborg-tempest-plugin,master,I123947207791f4388f892c3082aebcc37f48d252,add list devices filter testcase for non exist hostname,MERGED,2023-01-09 08:08:10.000000000,2023-01-30 03:38:29.000000000,2023-01-30 03:38:29.000000000,"[{'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 31412}]","[{'number': 1, 'created': '2023-01-09 08:08:10.000000000', 'files': ['cyborg_tempest_plugin/tests/api/test_device.py'], 'web_link': 'https://opendev.org/openstack/cyborg-tempest-plugin/commit/3601860fb5866419d68f565e9f865754992fddd6', 'message': 'add list devices filter testcase for non exist hostname\n\nadd list devices filter testcase for non exist hostname\n\nChange-Id: I123947207791f4388f892c3082aebcc37f48d252\n'}]",1,869300,3601860fb5866419d68f565e9f865754992fddd6,7,3,1,30409,,,0,"add list devices filter testcase for non exist hostname

add list devices filter testcase for non exist hostname

Change-Id: I123947207791f4388f892c3082aebcc37f48d252
",git fetch https://review.opendev.org/openstack/cyborg-tempest-plugin refs/changes/00/869300/1 && git format-patch -1 --stdout FETCH_HEAD,['cyborg_tempest_plugin/tests/api/test_device.py'],1,3601860fb5866419d68f565e9f865754992fddd6,master15," def test_list_devices_filter_by_non_exist_hostname(self): # list devices filter by non exist hostname params = {""hostname"": ""fake_hostname""} response = self.os_admin.cyborg_client.list_devices(params=params) self.assertEmpty(response['devices']) ",,6,0
openstack%2Fpuppet-openstack_spec_helper~stable%2Ftrain~Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,openstack/puppet-openstack_spec_helper,stable/train,Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,Pin concurrent-ruby,MERGED,2023-01-27 07:50:18.000000000,2023-01-30 01:47:15.000000000,2023-01-30 01:47:15.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 07:50:18.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/fb28e804e21a3b59f269bc7f971a736bf8379776', 'message': ""Pin concurrent-ruby\n\nconcurrent-ruby 1.2.0 dropped the implementation which puppet still\nrelies on. Let's pin it to the older version to fix the broken tests\nwith old and current puppet versions.\n\nBackport note:\nBackport does not require disabling the puppet jobs because the failure\nis caused by the change which is present only in master atm.\n\nConflicts:\n\tpuppet-openstack_spec_helper.gemspec\n\nCloses-Bug: #2003761\nChange-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568\n(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)\n(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)\n(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)\n(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)\n(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)\n(cherry picked from commit 90d78b53cd7bf643687c4a0a88bdb6e98e353a5d)\n(cherry picked from commit 077a22880032aaa41633a19168d23c7684107e66)\n""}]",0,871905,fb28e804e21a3b59f269bc7f971a736bf8379776,9,3,1,9816,,,0,"Pin concurrent-ruby

concurrent-ruby 1.2.0 dropped the implementation which puppet still
relies on. Let's pin it to the older version to fix the broken tests
with old and current puppet versions.

Backport note:
Backport does not require disabling the puppet jobs because the failure
is caused by the change which is present only in master atm.

Conflicts:
	puppet-openstack_spec_helper.gemspec

Closes-Bug: #2003761
Change-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568
(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)
(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)
(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)
(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)
(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)
(cherry picked from commit 90d78b53cd7bf643687c4a0a88bdb6e98e353a5d)
(cherry picked from commit 077a22880032aaa41633a19168d23c7684107e66)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/05/871905/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,fb28e804e21a3b59f269bc7f971a736bf8379776,bug/2003761," # NOTE(tkajinam): concurrent-ruby 1.2.0 dropped RubyThreadLocalVar, which is # still used by puppet as of 7.21.0. spec.add_dependency 'concurrent-ruby', ['< 1.2.0'] ",,4,0
openstack%2Fpuppet-openstack_spec_helper~stable%2Fussuri~Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,openstack/puppet-openstack_spec_helper,stable/ussuri,Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,Pin concurrent-ruby,MERGED,2023-01-27 07:01:12.000000000,2023-01-30 01:47:14.000000000,2023-01-30 01:47:14.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 07:01:12.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/077a22880032aaa41633a19168d23c7684107e66', 'message': ""Pin concurrent-ruby\n\nconcurrent-ruby 1.2.0 dropped the implementation which puppet still\nrelies on. Let's pin it to the older version to fix the broken tests\nwith old and current puppet versions.\n\nBackport note:\nBackport does not require disabling the puppet jobs because the failure\nis caused by the change which is present only in master atm.\n\nConflicts:\n\tpuppet-openstack_spec_helper.gemspec\n\nCloses-Bug: #2003761\nChange-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568\n(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)\n(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)\n(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)\n(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)\n(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)\n(cherry picked from commit 90d78b53cd7bf643687c4a0a88bdb6e98e353a5d)\n""}]",0,871959,077a22880032aaa41633a19168d23c7684107e66,7,3,1,9816,,,0,"Pin concurrent-ruby

concurrent-ruby 1.2.0 dropped the implementation which puppet still
relies on. Let's pin it to the older version to fix the broken tests
with old and current puppet versions.

Backport note:
Backport does not require disabling the puppet jobs because the failure
is caused by the change which is present only in master atm.

Conflicts:
	puppet-openstack_spec_helper.gemspec

Closes-Bug: #2003761
Change-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568
(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)
(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)
(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)
(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)
(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)
(cherry picked from commit 90d78b53cd7bf643687c4a0a88bdb6e98e353a5d)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/59/871959/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,077a22880032aaa41633a19168d23c7684107e66,bug/2003761," # NOTE(tkajinam): concurrent-ruby 1.2.0 dropped RubyThreadLocalVar, which is # still used by puppet as of 7.21.0. spec.add_dependency 'concurrent-ruby', ['< 1.2.0'] ",,4,0
openstack%2Fpuppet-openstack_spec_helper~stable%2Fvictoria~Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,openstack/puppet-openstack_spec_helper,stable/victoria,Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,Pin concurrent-ruby,MERGED,2023-01-25 01:57:54.000000000,2023-01-30 01:44:16.000000000,2023-01-30 01:44:16.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 01:57:54.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/90d78b53cd7bf643687c4a0a88bdb6e98e353a5d', 'message': ""Pin concurrent-ruby\n\nconcurrent-ruby 1.2.0 dropped the implementation which puppet still\nrelies on. Let's pin it to the older version to fix the broken tests\nwith old and current puppet versions.\n\nBackport note:\nBackport does not require disabling the puppet jobs because the failure\nis caused by the change which is present only in master atm.\n\nCloses-Bug: #2003761\nChange-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568\n(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)\n(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)\n(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)\n(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)\n(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)\n""}]",2,871561,90d78b53cd7bf643687c4a0a88bdb6e98e353a5d,11,3,1,9816,,,0,"Pin concurrent-ruby

concurrent-ruby 1.2.0 dropped the implementation which puppet still
relies on. Let's pin it to the older version to fix the broken tests
with old and current puppet versions.

Backport note:
Backport does not require disabling the puppet jobs because the failure
is caused by the change which is present only in master atm.

Closes-Bug: #2003761
Change-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568
(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)
(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)
(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)
(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)
(cherry picked from commit effb21c271abb4adbbdd097419c567fd9aca3440)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/61/871561/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,90d78b53cd7bf643687c4a0a88bdb6e98e353a5d,bug/2003761," # NOTE(tkajinam): concurrent-ruby 1.2.0 dropped RubyThreadLocalVar, which is # still used by puppet as of 7.21.0. spec.add_dependency 'concurrent-ruby', ['< 1.2.0'] ",,4,0
openstack%2Fopenstack-manuals~master~I668ae073b55661e13bdd1f02ef419d6b1d8c8787,openstack/openstack-manuals,master,I668ae073b55661e13bdd1f02ef419d6b1d8c8787,Enable CloudKitty API ref,MERGED,2022-12-13 12:18:22.000000000,2023-01-29 16:46:05.000000000,2023-01-29 16:16:43.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 28356}]","[{'number': 1, 'created': '2022-12-13 12:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7dd2bd5a87f743ffe7860cae257170f24d90c483', 'message': 'Enable CloudKitty API ref\n\nThe API reference for the CLoudKitty project [1] has been moved to a\ndedicated ""api-ref"" directory and this change adds it to the landing\npage for API refs.\n\n[1] https://opendev.org/openstack/cloudkitty\n\nChange-Id: I668ae073b55661e13bdd1f02ef419d6b1d8c8787\n'}, {'number': 2, 'created': '2022-12-13 12:21:02.000000000', 'files': ['www/project-data/latest.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/698453974595eeb647569a09a7f9bd0233156f9d', 'message': 'Enable CloudKitty API ref\n\nThe API reference for the CloudKitty project [1] has been moved to a\ndedicated ""api-ref"" directory and this change adds it to the landing\npage for API refs.\n\n[1] https://opendev.org/openstack/cloudkitty\n\nChange-Id: I668ae073b55661e13bdd1f02ef419d6b1d8c8787\n'}]",17,867357,698453974595eeb647569a09a7f9bd0233156f9d,29,3,2,25277,,,0,"Enable CloudKitty API ref

The API reference for the CloudKitty project [1] has been moved to a
dedicated ""api-ref"" directory and this change adds it to the landing
page for API refs.

[1] https://opendev.org/openstack/cloudkitty

Change-Id: I668ae073b55661e13bdd1f02ef419d6b1d8c8787
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/57/867357/2 && git format-patch -1 --stdout FETCH_HEAD,['www/project-data/latest.yaml'],1,7dd2bd5a87f743ffe7860cae257170f24d90c483,cloudkitty-api-ref, has_api_ref: true,,1,0
openstack%2Fmanila-tempest-plugin~master~I94d614a6cca9cd493f2789af1a9ba539844ce787,openstack/manila-tempest-plugin,master,I94d614a6cca9cd493f2789af1a9ba539844ce787,Create a file by vi command instead of touch command,ABANDONED,2023-01-25 16:10:02.000000000,2023-01-29 14:01:14.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 30025}]","[{'number': 1, 'created': '2023-01-25 16:10:02.000000000', 'files': ['manila_tempest_tests/tests/scenario/test_share_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/302cf20c611d478eda8b18cfff9ae6c6309d5028', 'message': ""Create a file by vi command instead of touch command\n\nWe noticed that file3 isn't listed when it's created by touch\ncommand, however, by using vi command this problem doesn't exist.\nWe encountered this strange behavior when the backend is\nCephFS NFS backend and the instance based on RHEL 8.6 image.\nSo let's use the vi command to prevent this test from failing\nespecially since it's not a Manila issue.\n\nChange-Id: I94d614a6cca9cd493f2789af1a9ba539844ce787\n""}]",4,871740,302cf20c611d478eda8b18cfff9ae6c6309d5028,8,4,1,19262,,,0,"Create a file by vi command instead of touch command

We noticed that file3 isn't listed when it's created by touch
command, however, by using vi command this problem doesn't exist.
We encountered this strange behavior when the backend is
CephFS NFS backend and the instance based on RHEL 8.6 image.
So let's use the vi command to prevent this test from failing
especially since it's not a Manila issue.

Change-Id: I94d614a6cca9cd493f2789af1a9ba539844ce787
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/40/871740/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/scenario/test_share_basic_ops.py'],1,302cf20c611d478eda8b18cfff9ae6c6309d5028,use_vi_cmd," # We noticed that file3 isn't listed when it's created by touch # command, however, by using vi command this problem doesn't exist. # We encountered this strange behavior when the backend is # CephFS NFS backend and the instance based on RHEL 8.6 image. # So let's use the vi command to prevent this test from failing # especially since it's not a Manila issue. remote_client.exec_command( ""sudo vi %s/file3 +g/^/m0 +wq"" % child_share_dir)"," remote_client.exec_command(""sudo touch %s/file3"" % child_share_dir)",8,1
openstack%2Fopenstacksdk~master~I6612278ae798d48b296239e3359026584efb8a70,openstack/openstacksdk,master,I6612278ae798d48b296239e3359026584efb8a70,Drop munch dependency,MERGED,2022-11-18 16:52:20.000000000,2023-01-29 12:02:05.000000000,2023-01-29 12:00:56.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-18 16:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eda5aa989b51ae4c9c53e31a7918aa77bb361e12', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 2, 'created': '2022-12-05 11:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3f61cbdcaca8619e044b1f4ea17767be6a4080e6', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 3, 'created': '2023-01-03 12:52:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2b52f3ad4b22a2357e4a81e9401e112eee7abde3', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 4, 'created': '2023-01-11 07:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6de2dd621fd28b6dded3d3f5d99f652e444b64e3', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 5, 'created': '2023-01-13 18:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c77e498e4d2f2aaa7a294fea6b2ce7b381db1caf', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 6, 'created': '2023-01-27 16:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/be098ea3170f58e18217150198d6c794acd40244', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 7, 'created': '2023-01-27 17:47:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/33ca1debe74b7ec1501ba1982c58d59fca368070', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 8, 'created': '2023-01-27 20:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bf158845f12a5a0fd6ca666106f60833297e3d00', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 9, 'created': '2023-01-28 12:19:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/df9a9d2af3242d0596b77e5e0051a01df4b4eae5', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}, {'number': 10, 'created': '2023-01-29 08:03:00.000000000', 'files': ['openstack/cloud/_coe.py', 'openstack/tests/unit/cloud/test_floating_ip_neutron.py', 'openstack/cloud/openstackcloud.py', 'openstack/cloud/_baremetal.py', 'openstack/proxy.py', 'openstack/tests/unit/test_proxy.py', 'openstack/utils.py', 'openstack/tests/base.py', 'openstack/tests/unit/cloud/test_create_server.py', 'requirements.txt', 'openstack/tests/unit/test_resource.py', 'openstack/resource.py', 'openstack/cloud/_orchestration.py', 'openstack/cloud/_compute.py', 'openstack/cloud/_security_group.py', 'openstack/cloud/_floating_ip.py', 'openstack/cloud/meta.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6e5f34dba55365805033694b7a01ea39e0072c99', 'message': 'Drop munch dependency\n\nImporting munch inside of SDK is taking around 0.3 second. Itself it is\nnot a big problem, but it hurts on the openstackclient front. In\naddition to that munch project does not seem to be actively maintained\nand had no releases since 2 years.\nDropping this dependency at once is requiring quite a big rework so\ninstead copy a heavily stripped version of what we really require from\nit. This helps us to gain performance improvement while giving time to\nrework our code to come up with a decicion on how to deal with it.\n\nChange-Id: I6612278ae798d48b296239e3359026584efb8a70\n'}]",3,865045,6e5f34dba55365805033694b7a01ea39e0072c99,30,3,10,27900,,,0,"Drop munch dependency

Importing munch inside of SDK is taking around 0.3 second. Itself it is
not a big problem, but it hurts on the openstackclient front. In
addition to that munch project does not seem to be actively maintained
and had no releases since 2 years.
Dropping this dependency at once is requiring quite a big rework so
instead copy a heavily stripped version of what we really require from
it. This helps us to gain performance improvement while giving time to
rework our code to come up with a decicion on how to deal with it.

Change-Id: I6612278ae798d48b296239e3359026584efb8a70
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/45/865045/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cloud/_coe.py', 'openstack/tests/unit/cloud/test_floating_ip_neutron.py', 'openstack/cloud/openstackcloud.py', 'openstack/tests/unit/cloud/test_cluster_templates.py', 'openstack/tests/unit/cloud/test_coe_clusters_certificate.py', 'openstack/tests/unit/test_proxy.py', 'openstack/utils.py', 'openstack/tests/base.py', 'openstack/tests/unit/cloud/test_coe_clusters.py', 'requirements.txt', 'openstack/tests/unit/test_resource.py', 'openstack/resource.py', 'openstack/cloud/_security_group.py', 'openstack/cloud/meta.py']",14,eda5aa989b51ae4c9c53e31a7918aa77bb361e12,sdk_r1," elif isinstance(obj, utils.Munch) or hasattr(obj, 'mock_add_spec'): instance = utils.Munch(obj) else: instance = utils.Munch() # some attributes can be defined as a @property, so we can't assure","import munch elif isinstance(obj, munch.Munch) or hasattr(obj, 'mock_add_spec'): instance = munch.Munch(obj) else: instance = munch.Munch() # some attributes can be defined as a @propierty, so we can't assure",231,53
openstack%2Fskyline-console~master~Ibd81bc6331fa09a3c70fcfc6f1f72ccc3e6f9c37,openstack/skyline-console,master,Ibd81bc6331fa09a3c70fcfc6f1f72ccc3e6f9c37,feat: add attributes to the ModalAction,MERGED,2023-01-29 08:46:35.000000000,2023-01-29 11:59:10.000000000,2023-01-29 11:58:15.000000000,"[{'_account_id': 22348}, {'_account_id': 28706}]","[{'number': 1, 'created': '2023-01-29 08:46:35.000000000', 'files': ['src/components/Tables/Base/ActionButton/index.jsx'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/2ebb26942a6e1e92de8d5d890cc4f3dfe0b40df4', 'message': 'feat: add attributes to the ModalAction\n\nAdd the onFinishAction and onCancelAction which are from the ListPage component to the ModalAction, add the modalProps to the ModalAction, these attritubes will make custom operations in the ModalAction to easily control the ListPage\n\nChange-Id: Ibd81bc6331fa09a3c70fcfc6f1f72ccc3e6f9c37\n'}]",0,872073,2ebb26942a6e1e92de8d5d890cc4f3dfe0b40df4,7,2,1,30434,,,0,"feat: add attributes to the ModalAction

Add the onFinishAction and onCancelAction which are from the ListPage component to the ModalAction, add the modalProps to the ModalAction, these attritubes will make custom operations in the ModalAction to easily control the ListPage

Change-Id: Ibd81bc6331fa09a3c70fcfc6f1f72ccc3e6f9c37
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/73/872073/1 && git format-patch -1 --stdout FETCH_HEAD,['src/components/Tables/Base/ActionButton/index.jsx'],1,2ebb26942a6e1e92de8d5d890cc4f3dfe0b40df4,modal-action," const { title, action, item, containerProps, items, onFinishAction, onCancelAction, } = this.props; onFinishAction={onFinishAction} onCancelAction={onCancelAction} modalProps={modalProps}"," const { title, action, item, containerProps, items } = this.props;",12,1
openstack%2Fdevstack~stable%2Fyoga~I5e938139b47f443a4c358415d0d4dcf6549cd085,openstack/devstack,stable/yoga,I5e938139b47f443a4c358415d0d4dcf6549cd085,Fix setting the tempest virtual env constraints env var,MERGED,2023-01-27 04:40:02.000000000,2023-01-29 11:43:49.000000000,2023-01-29 11:42:49.000000000,"[{'_account_id': 7166}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-27 04:40:02.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/febdb122e46ad22b5481c03c33fcd4130593d116', 'message': ""Fix setting the tempest virtual env constraints env var\n\nDevstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE\nwhich are used to use the constraints during Tempest virtual env installation.\nThose env var are set to non-master constraint when we need to use non-master\nconstraints but when we need to use the master constraints we do not set/reset\nthem point to master constraints. This create the issue when running the grenade\njob where we run Tempest on the old devstack as well as in the new devstack.\nWhen tempest is installed on old devstack then old tempest is used and it sets\nthese env var to stable/<branch> constraints (this is the case when old devstack\n(the stable branch is in EM phase) uses the old tempest not the master tempest),\nall good till now. But the problem comes when in the same grenade script run\nupgrade-tempest install the master tempest (when new devstack branches are in\nthe 'supported' phase and use the master tempest means) and are supposed to use\nthe master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env\nvar set by old tempest is used by the tempest and due to a mismatch in constraints\nit fails.\n\nThis happened when we tried to pin the stable/wallaby with Tempest 29.0.0\n- https://review.opendev.org/c/openstack/devstack/+/871782\n\nand table/xena grenade job failed (stable/xena use master tempest and supposed\nto use master constraints)\n- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641\n\nWe should set/reset those constraint env var to master constraints if configuration\ntell devstack to use the master constraints.\n\n[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124\n\nCloses-Bug: #2003993\nChange-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085\n(cherry picked from commit 7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d)\n(cherry picked from commit 30a7d790b6bf45bbcc6333008621b093c84055d1)\n""}]",2,871944,febdb122e46ad22b5481c03c33fcd4130593d116,9,3,1,8556,,,0,"Fix setting the tempest virtual env constraints env var

Devstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE
which are used to use the constraints during Tempest virtual env installation.
Those env var are set to non-master constraint when we need to use non-master
constraints but when we need to use the master constraints we do not set/reset
them point to master constraints. This create the issue when running the grenade
job where we run Tempest on the old devstack as well as in the new devstack.
When tempest is installed on old devstack then old tempest is used and it sets
these env var to stable/<branch> constraints (this is the case when old devstack
(the stable branch is in EM phase) uses the old tempest not the master tempest),
all good till now. But the problem comes when in the same grenade script run
upgrade-tempest install the master tempest (when new devstack branches are in
the 'supported' phase and use the master tempest means) and are supposed to use
the master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env
var set by old tempest is used by the tempest and due to a mismatch in constraints
it fails.

This happened when we tried to pin the stable/wallaby with Tempest 29.0.0
- https://review.opendev.org/c/openstack/devstack/+/871782

and table/xena grenade job failed (stable/xena use master tempest and supposed
to use master constraints)
- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641

We should set/reset those constraint env var to master constraints if configuration
tell devstack to use the master constraints.

[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124

Closes-Bug: #2003993
Change-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085
(cherry picked from commit 7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d)
(cherry picked from commit 30a7d790b6bf45bbcc6333008621b093c84055d1)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/44/871944/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,febdb122e46ad22b5481c03c33fcd4130593d116,bug/2003993," # NOTE(gmann): we need to set the below env var pointing to master # constraints even that is what default in tox.ini. Otherwise it can # create the issue for grenade run where old and new devstack can have # different tempest (old and master) to install. For detail problem, # refer to the https://bugs.launchpad.net/devstack/+bug/2003993 export UPPER_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master export TOX_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master",,7,0
openstack%2Fzaqar~master~Iae33d7c725274be9de1aa66ad73b2d610c36e061,openstack/zaqar,master,Iae33d7c725274be9de1aa66ad73b2d610c36e061,Update deprecated zuul syntax,MERGED,2022-10-13 14:08:00.000000000,2023-01-29 10:55:55.000000000,2023-01-29 10:54:22.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-13 14:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d646512a7f05bfb29401e379a48b902980b7bf64', 'message': 'Update deprecated zuul syntax\n\nQueues are now declared at the project level\n\nhttps: //lists.openstack.org/pipermail/openstack-discuss/2021-November/025797.html\nChange-Id: Iae33d7c725274be9de1aa66ad73b2d610c36e061\n'}, {'number': 2, 'created': '2023-01-21 20:15:20.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/56f0110b1ef7a98dac206c92cc65b2a2c519922a', 'message': 'Update deprecated zuul syntax\n\nQueues are now declared at the project level\n\nhttps: //lists.openstack.org/pipermail/openstack-discuss/2021-November/025797.html\nChange-Id: Iae33d7c725274be9de1aa66ad73b2d610c36e061\n'}]",4,861188,56f0110b1ef7a98dac206c92cc65b2a2c519922a,27,2,2,16465,,,0,"Update deprecated zuul syntax

Queues are now declared at the project level

https: //lists.openstack.org/pipermail/openstack-discuss/2021-November/025797.html
Change-Id: Iae33d7c725274be9de1aa66ad73b2d610c36e061
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/88/861188/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d646512a7f05bfb29401e379a48b902980b7bf64,fix/zuul, queue: zaqar, queue: zaqar,1,1
openstack%2Fskyline-console~master~I6849fab3933cef82e1293f7bbe0f3006e19b6b38,openstack/skyline-console,master,I6849fab3933cef82e1293f7bbe0f3006e19b6b38,feat: support textarea in the KeyValueInput component,MERGED,2023-01-28 06:31:55.000000000,2023-01-29 10:28:44.000000000,2023-01-29 10:27:45.000000000,"[{'_account_id': 22348}, {'_account_id': 28706}]","[{'number': 1, 'created': '2023-01-28 06:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/216d8ea4a4231af962b7b86ada8296de01b4bd48', 'message': 'feat: support textarea in the KeyValueInput component\n\nProvide textrea in the KeyValueInput component, to input more content, and provide the textareaRows property to set the default rows of the textarea to display.\n\nChange-Id: I6849fab3933cef82e1293f7bbe0f3006e19b6b38\n'}, {'number': 2, 'created': '2023-01-28 09:23:47.000000000', 'files': ['src/components/FormItem/KeyValueInput/index.jsx'], 'web_link': 'https://opendev.org/openstack/skyline-console/commit/417e729e0d9bb999b5db1517fcfbc5a37d6aa15a', 'message': 'feat: support textarea in the KeyValueInput component\n\nProvide textrea in the KeyValueInput component, to input more content, and provide the textareaRows property to set the default rows of the textarea to display.\n\nChange-Id: I6849fab3933cef82e1293f7bbe0f3006e19b6b38\n'}]",0,872061,417e729e0d9bb999b5db1517fcfbc5a37d6aa15a,9,2,2,30434,,,0,"feat: support textarea in the KeyValueInput component

Provide textrea in the KeyValueInput component, to input more content, and provide the textareaRows property to set the default rows of the textarea to display.

Change-Id: I6849fab3933cef82e1293f7bbe0f3006e19b6b38
",git fetch https://review.opendev.org/openstack/skyline-console refs/changes/61/872061/1 && git format-patch -1 --stdout FETCH_HEAD,['src/components/FormItem/KeyValueInput/index.jsx'],1,216d8ea4a4231af962b7b86ada8296de01b4bd48,key-value-input," isTextarea: PropTypes.bool, textareaRows: PropTypes.number, isTextarea: false, textareaRows: 2, renderInput(value, placeholder, readOnly) { const { isTextarea = false, textareaRows } = this.props; const props = { value, placeholder, onChange: this.onValueChange, readOnly, required: true, }; if (isTextarea) { props.rows = textareaRows; return <Input.TextArea {...props} />; } } {this.renderInput(value, valuePlaceholder, valueReadonly)}", <Input value={value} placeholder={valuePlaceholder} onChange={this.onValueChange} readOnly={valueReadonly} required />,20,7
openstack%2Fironic~master~I352429065eedb1dcbbfa803ec2814c3e870c3be9,openstack/ironic,master,I352429065eedb1dcbbfa803ec2814c3e870c3be9,Delete resource provider after node deletion.,NEW,2022-02-01 14:11:34.000000000,2023-01-29 09:48:33.000000000,,"[{'_account_id': 782}, {'_account_id': 4571}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-02-01 14:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e9f90cda40c045f5a3b75e61f79a5b03613b2b01', 'message': ""Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option 'report_interval'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nwhich causes error behavior.\nThe patch removes resource provider in placement after node deletion.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n""}, {'number': 2, 'created': '2022-02-03 15:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8389d656e2cea1d31584a43d6a6825c7996d1428', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 3, 'created': '2022-02-03 18:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/856348e8a45c532c853deef0f4934f211189b21f', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 4, 'created': '2022-02-08 20:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d8180358b454731a89b91613079932239f65e7df', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 5, 'created': '2022-02-08 20:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/df42897c5b3c04177bdfcddbe010f169aa6ec2b4', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 6, 'created': '2022-03-21 10:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/50c23a77e51b7c51fd8b5f0dd9dfb4cef74c600f', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 7, 'created': '2022-03-21 10:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d497ac59c6e5c7ec68d40c71e6045725644bbfc6', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 8, 'created': '2022-03-23 10:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4902ecbadd22438c21d8f68ddd48cca7a65dada2', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 9, 'created': '2022-03-23 14:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1d24c382ba2e19fb66edf01ddf978f48e974a977', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 10, 'created': '2022-03-23 14:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/424b7126297839023c8036b0c7f7236ae1878558', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 11, 'created': '2022-05-04 07:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a47063ebb94c6c095a4b836880ced0e97ebec73c', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 12, 'created': '2022-05-04 07:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/df2c98328bbd576fc30343e58eac280d5e3c22ab', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 13, 'created': '2022-09-16 11:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e8107371f14c97bcae295354171e5f168f129e23', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some time.\nTime gap can long minutes.\nNove scheduler can schedule on deleted node,\nwhich causes error behavior.\nTime gap depends on nova option \'report_interval\'.\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\nThe patch removes resource provider in placement after node deletion.\nIt doesn\'t solve the problem of nova and ironic synchronization,\nbut it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 14, 'created': '2023-01-27 21:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d40f0726d9bc2bc19e7106a1d272833b2ae14586', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some\ntime due to the reconcile time lag of the nova-compute\nservice.\n\nTime gap can last minutes, to potentially hours in.\n\nPlacement can schedule upon a deleted baremetal node,\nwhich causes error behavior. Time gap depends on nova\noption \'report_interval\' as well as the general overhead\nof interaction dependent upon the size of a deployment.\n\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\n\nThe patch removes resource provider in placement after\nnode deletion. It doesn\'t solve the problem of nova and\nironic synchronization, but it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}, {'number': 15, 'created': '2023-01-27 21:13:25.000000000', 'files': ['requirements.txt', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'ironic/conf/__init__.py', 'releasenotes/notes/bug-1248022-71a6f5e04f30775e.yaml', 'ironic/conf/placement.py', 'ironic/common/placement.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d39d6832fad6f76c15b0bfbbfee9b1b9e4a8b660', 'message': 'Delete resource provider after node deletion.\n\nAfter node deletion resource provider exists for some\ntime due to the reconcile time lag of the nova-compute\nservice.\n\nTime gap can last minutes, to potentially hours in.\n\nPlacement can schedule upon a deleted baremetal node,\nwhich causes error behavior. Time gap depends on nova\noption \'report_interval\' as well as the general overhead\nof interaction dependent upon the size of a deployment.\n\nIf we decrease the value the gap is less.\nBut it increases load in deployment,\nespecially in high-loaded one.\nSo the option is not a cure.\n\nThe patch removes resource provider in placement after\nnode deletion. It doesn\'t solve the problem of nova and\nironic synchronization, but it\'s ""nice thing"" which helps.\n\nStory: #1248022\nTask: #9332\nChange-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9\n'}]",56,827295,d39d6832fad6f76c15b0bfbbfee9b1b9e4a8b660,79,6,15,32927,,,0,"Delete resource provider after node deletion.

After node deletion resource provider exists for some
time due to the reconcile time lag of the nova-compute
service.

Time gap can last minutes, to potentially hours in.

Placement can schedule upon a deleted baremetal node,
which causes error behavior. Time gap depends on nova
option 'report_interval' as well as the general overhead
of interaction dependent upon the size of a deployment.

If we decrease the value the gap is less.
But it increases load in deployment,
especially in high-loaded one.
So the option is not a cure.

The patch removes resource provider in placement after
node deletion. It doesn't solve the problem of nova and
ironic synchronization, but it's ""nice thing"" which helps.

Story: #1248022
Task: #9332
Change-Id: I352429065eedb1dcbbfa803ec2814c3e870c3be9
",git fetch https://review.opendev.org/openstack/ironic refs/changes/95/827295/8 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ironic/conductor/manager.py', 'ironic/tests/unit/conductor/test_manager.py', 'lower-constraints.txt', 'ironic/common/placement.py']",5,e9f90cda40c045f5a3b75e61f79a5b03613b2b01,story/1248022,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import openstack from ironic.common import keystone _PLACEMENT_SESSION = None def _get_placement_session(): global _PLACEMENT_SESSION if not _PLACEMENT_SESSION: service_auth = keystone.get_auth('service_catalog') _PLACEMENT_SESSION = keystone.get_session('service_catalog', auth=service_auth) return _PLACEMENT_SESSION def get_client(context): """"""Retrieve a placement client connection. :returns: A placement client. """""" cached_session = _get_placement_session() connection = openstack.connection.Connection(session=cached_session) return connection.global_request(context.global_id).placement def delete_resource_provider(context, resource_provider): """"""Delete a resource provider :param context: request context :param resource_provider: The value can be either the ID of a resource provider or an ResourceProvider, instance. """""" get_client(context).delete_resource_provider(resource_provider) ",,54,2
openstack%2Ftrove~stable%2Fzed~Icf7c1e874923d0270bab4f76e14d5d4bfa22d6da,openstack/trove,stable/zed,Icf7c1e874923d0270bab4f76e14d5d4bfa22d6da,Adapt bindep ubuntu-jammy,ABANDONED,2022-11-29 11:23:54.000000000,2023-01-29 08:53:46.000000000,,[{'_account_id': 26285}],"[{'number': 1, 'created': '2022-11-29 11:23:54.000000000', 'files': ['bindep.txt'], 'web_link': 'https://opendev.org/openstack/trove/commit/7c15befae1647936b61a94ca9bb53c34e4d1a7dd', 'message': 'Adapt bindep ubuntu-jammy\n\nThis patch changes the following items.\n\n* Remove python-dev in bindep.txt\n\n  This is needed to make openstack-tox-py310 job\n  to install deps properly.\n\n* Make python3 and python3-devel installed\n  on CentOS 8 and Fedora\n\nChange-Id: Icf7c1e874923d0270bab4f76e14d5d4bfa22d6da\nSigned-off-by: Takashi Natsume <takanattie@gmail.com>\n(cherry picked from commit bc80e2c524a889b12591c77cff32c0f137ab860e)\n'}]",3,865990,7c15befae1647936b61a94ca9bb53c34e4d1a7dd,6,1,1,26285,,,0,"Adapt bindep ubuntu-jammy

This patch changes the following items.

* Remove python-dev in bindep.txt

  This is needed to make openstack-tox-py310 job
  to install deps properly.

* Make python3 and python3-devel installed
  on CentOS 8 and Fedora

Change-Id: Icf7c1e874923d0270bab4f76e14d5d4bfa22d6da
Signed-off-by: Takashi Natsume <takanattie@gmail.com>
(cherry picked from commit bc80e2c524a889b12591c77cff32c0f137ab860e)
",git fetch https://review.opendev.org/openstack/trove refs/changes/90/865990/1 && git format-patch -1 --stdout FETCH_HEAD,['bindep.txt'],1,7c15befae1647936b61a94ca9bb53c34e4d1a7dd,adapt_py310-stable/zed,python3-all [platform:dpkg] python3-all-dev [platform:dpkg] python3 [platform:rpm test] python3-devel [platform:rpm test],python-dev [platform:dpkg test] python-devel [platform:rpm test] python3-all [platform:dpkg !platform:ubuntu-precise] python3-all-dev [platform:dpkg !platform:ubuntu-precise] python3-devel [platform:fedora] python34-devel [platform:centos],4,6
openstack%2Ftrove~stable%2Fzed~If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4,openstack/trove,stable/zed,If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4,Change settings for stable/zed,MERGED,2022-11-28 15:13:56.000000000,2023-01-29 08:46:59.000000000,2023-01-29 08:45:18.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-11-28 15:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d79f39b2c8bed2475ae271b95ce13e2a2ca99ab3', 'message': 'Change settings for stable/zed\n\nChange-Id: If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4\n'}, {'number': 2, 'created': '2022-11-28 15:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/066949ae0faf4899136a9d91fb0e8a95bd590317', 'message': 'Change settings for stable/zed\n\nChange-Id: If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4\n'}, {'number': 3, 'created': '2023-01-06 13:28:12.000000000', 'files': ['bindep.txt', 'integration/scripts/files/elements/guest-agent/source-repository-guest-agent', 'integration/scripts/trovestack', 'trove/common/cfg.py', 'integration/scripts/trovestack.rc', 'trove/guestagent/api.py', 'zuul.d/projects.yaml', 'zuul.d/jobs.yaml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/trove/commit/d99811a31f0130039046dca5fc60d379f2e56476', 'message': 'Change settings for stable/zed\n\nChange-Id: If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4\n'}]",1,865862,d99811a31f0130039046dca5fc60d379f2e56476,13,2,3,26285,,,0,"Change settings for stable/zed

Change-Id: If6ae91bea5594195d8c8dc7fe2a2500ec96d71d4
",git fetch https://review.opendev.org/openstack/trove refs/changes/62/865862/3 && git format-patch -1 --stdout FETCH_HEAD,"['integration/scripts/files/elements/guest-agent/source-repository-guest-agent', 'integration/scripts/trovestack', 'trove/common/cfg.py', 'integration/scripts/trovestack.rc', 'trove/guestagent/api.py', 'zuul.d/jobs.yaml', 'devstack/settings']",7,d79f39b2c8bed2475ae271b95ce13e2a2ca99ab3,,TROVE_BRANCH=${TROVE_BRANCH:-stable/zed}TROVE_CLIENT_BRANCH=${TROVE_CLIENT_BRANCH:-${TROVECLIENT_BRANCH:-stable/zed}}TROVE_DASHBOARD_BRANCH=${TROVE_DASHBOARD_BRANCH:-stable/zed}TRIPLEO_IMAGES_BRANCH=${TRIPLEO_IMAGES_BRANCH:-stable/zed},TROVE_BRANCH=${TROVE_BRANCH:-master}TROVE_CLIENT_BRANCH=${TROVE_CLIENT_BRANCH:-${TROVECLIENT_BRANCH:-master}}TROVE_DASHBOARD_BRANCH=${TROVE_DASHBOARD_BRANCH:-master}TRIPLEO_IMAGES_BRANCH=${TRIPLEO_IMAGES_BRANCH:-master},16,15
openstack%2Fvenus~master~I6246550999065c04c28562361c80754d651f613c,openstack/venus,master,I6246550999065c04c28562361c80754d651f613c,all index output to log,MERGED,2023-01-29 07:49:42.000000000,2023-01-29 08:31:59.000000000,2023-01-29 08:30:54.000000000,"[{'_account_id': 22348}, {'_account_id': 30562}]","[{'number': 1, 'created': '2023-01-29 07:49:42.000000000', 'files': ['venus/task/core/delete_es_index_task.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/78d18716c424f9fc2e64b7fd8c88075a276bd000', 'message': 'all index output to log\n\nChange-Id: I6246550999065c04c28562361c80754d651f613c\n'}]",0,872072,78d18716c424f9fc2e64b7fd8c88075a276bd000,7,2,1,30455,,,0,"all index output to log

Change-Id: I6246550999065c04c28562361c80754d651f613c
",git fetch https://review.opendev.org/openstack/venus refs/changes/72/872072/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/task/core/delete_es_index_task.py'],1,78d18716c424f9fc2e64b7fd8c88075a276bd000,," else: LOG.info(""no delete index {}, diff_day {}"" .format(index_name, diff_day)) except Exception as e: LOG.error(""try delete es inidex error"" + str(e)) "," except Exception as e: LOG.error(""delete es inidex error"" + str(e)) ",6,1
openstack%2Fvenus~master~I355b9b062f0424292e371817c82c02f19f3ebe5e,openstack/venus,master,I355b9b062f0424292e371817c82c02f19f3ebe5e,log output after judge it,MERGED,2023-01-29 07:12:32.000000000,2023-01-29 07:46:56.000000000,2023-01-29 07:46:02.000000000,"[{'_account_id': 22348}, {'_account_id': 30562}]","[{'number': 1, 'created': '2023-01-29 07:12:32.000000000', 'files': ['venus/task/core/delete_es_index_task.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/bf49e2878a2645a5e7ccbfa8f5cc1dd7ed622bc3', 'message': 'log output after judge it\n\nChange-Id: I355b9b062f0424292e371817c82c02f19f3ebe5e\n'}]",0,872071,bf49e2878a2645a5e7ccbfa8f5cc1dd7ed622bc3,7,2,1,30455,,,0,"log output after judge it

Change-Id: I355b9b062f0424292e371817c82c02f19f3ebe5e
",git fetch https://review.opendev.org/openstack/venus refs/changes/71/872071/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/task/core/delete_es_index_task.py'],1,bf49e2878a2645a5e7ccbfa8f5cc1dd7ed622bc3,," LOG.info(""the elasticsearch indexes keep days {}"".format(len_d)) "," LOG.info(""the elasticsearch indexes keep days {}"".format(len_d)) ",1,1
openstack%2Ftrove-tempest-plugin~master~Iea25327386a3c4e91ebe98aa8954b6353a51c4c6,openstack/trove-tempest-plugin,master,Iea25327386a3c4e91ebe98aa8954b6353a51c4c6,Fixing tests with tox 4.2.6,MERGED,2023-01-28 06:47:29.000000000,2023-01-29 07:34:19.000000000,2023-01-29 07:32:40.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2023-01-28 06:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/9388702b4567ecf0a442c1b6d8bb0e5f98cf994b', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 2, 'created': '2023-01-28 12:35:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/cb78cd77a452a69a18a8018aad35b9d59f993f8e', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 3, 'created': '2023-01-28 12:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/dd824665cb24fdfb46e21c771c473dc65eb64ca8', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 4, 'created': '2023-01-28 12:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/cffd3b8adb4addb5084eccb833d95297503a1421', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 5, 'created': '2023-01-28 12:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/ce160201d2b0f2d012dbff4a380cfa859077503b', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 6, 'created': '2023-01-28 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/d788fd40c52b2cf686a6969e3e330ebf452dbac5', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 7, 'created': '2023-01-28 14:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/ae558878d4abe61ec1be5bed4901f3b5e6ecafb4', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 8, 'created': '2023-01-28 14:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/e724f1b22ceb4f5828ff6bb7779cbca3622e2a26', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 9, 'created': '2023-01-28 14:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/f93c70361ea9165c17a4fd2264406e1291af7c1c', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 10, 'created': '2023-01-28 14:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/5889ab7a8aaedd1ff4cbb80d31a5f86a7760de5d', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 11, 'created': '2023-01-28 14:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/fffa7446b355142684830223878548f117268ef7', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 12, 'created': '2023-01-28 14:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/88e7d77eece4fdf574ddbd97b2864fdac15f3372', 'message': 'WIP: Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}, {'number': 13, 'created': '2023-01-29 02:29:32.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/00b4ef0991236e1ad19832698e5358f76781af46', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\nRemove pypy testenv\n\nChange-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6\n'}]",2,872063,00b4ef0991236e1ad19832698e5358f76781af46,23,2,13,26285,,,0,"Fixing tests with tox 4.2.6

Remove basepython from testenv
Remove pypy testenv

Change-Id: Iea25327386a3c4e91ebe98aa8954b6353a51c4c6
",git fetch https://review.opendev.org/openstack/trove-tempest-plugin refs/changes/63/872063/4 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9388702b4567ecf0a442c1b6d8bb0e5f98cf994b,,"envlist = py39,pep8","envlist = py39,pypy,pep8basepython = python3",1,2
openstack%2Ftrove~master~Ief3d3b98b55c02e185edb2294b9c723843e62086,openstack/trove,master,Ief3d3b98b55c02e185edb2294b9c723843e62086,Updates the backup document,MERGED,2022-10-24 04:47:16.000000000,2023-01-29 07:34:15.000000000,2023-01-29 07:32:44.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-10-24 04:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3dd78f97ba67da8575e522c01ca248e0a2718ca5', 'message': 'Updates the backup document\n\nThis PR updates the backup document[1]. The page contains wrong descriptions\nsince we have many updates for years.\n\n[1]: https://docs.openstack.org/trove/latest/user/backup-db.html#create-incremental-backups\n\nStory: 2010323\nTask: 46430\nChange-Id: Ief3d3b98b55c02e185edb2294b9c723843e62086\n'}, {'number': 2, 'created': '2023-01-28 13:27:48.000000000', 'files': ['doc/source/user/backup-db.rst'], 'web_link': 'https://opendev.org/openstack/trove/commit/3a27069307e57e163ae27b50cf515eda203b0433', 'message': 'Updates the backup document\n\nThis PR updates the backup document[1]. The page contains wrong descriptions\nsince we have many updates for years.\n\n[1]: https://docs.openstack.org/trove/latest/user/backup-db.html#create-incremental-backups\n\nStory: 2010323\nTask: 46430\nChange-Id: Ief3d3b98b55c02e185edb2294b9c723843e62086\n'}]",8,862454,3a27069307e57e163ae27b50cf515eda203b0433,14,2,2,31737,,,0,"Updates the backup document

This PR updates the backup document[1]. The page contains wrong descriptions
since we have many updates for years.

[1]: https://docs.openstack.org/trove/latest/user/backup-db.html#create-incremental-backups

Story: 2010323
Task: 46430
Change-Id: Ief3d3b98b55c02e185edb2294b9c723843e62086
",git fetch https://review.opendev.org/openstack/trove refs/changes/54/862454/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/backup-db.rst'],1,3dd78f97ba67da8575e522c01ca248e0a2718ca5,story/2010323," +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+-------------------------------------------------------------------------------------------------+-----------+------+------+ | ID | Name | Datastore | Datastore Version | Status | Operating Status | Public | Addresses | Flavor ID | Size | Role | +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+-------------------------------------------------------------------------------------------------+-----------+------+------+ | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | mysql1 | mysql | 8.0.29 | ACTIVE | HEALTHY | False | [{'address': '10.0.0.9', 'type': 'private', 'network': '33f3a589-b806-4212-9a59-8e058cac0699'}] | d2 | 1 | | +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+-------------------------------------------------------------------------------------------------+-----------+------+------+ $ openstack database backup strategy create --instance-id 78e338e3-d1c4-4189-8ea7-bfc1fab5011f --swift-container my-trove-backups | instance_id | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | | project_id | fc51186c63df417ea63cec6c65a2d564 | $ openstack database backup create mysql-backup-name1 --instance mysql1 --swift-container 'my-trove-backups' +----------------------+--------------------------------------+ | Field | Value | +----------------------+--------------------------------------+ | created | 2022-10-24T01:46:38 | | datastore | mysql | | datastore_version | 8.0.29 | | datastore_version_id | 324f2bdf-6099-4754-a5f9-82abee026a19 | | description | None | | id | 1ecd0a75-e4aa-400b-b0c8-cb738944fd43 | | instance_id | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | | locationRef | None | | name | mysql-backup-name1 | | parent_id | None | | project_id | fc51186c63df417ea63cec6c65a2d564 | | size | None | | status | NEW | | updated | 2022-10-24T01:46:38 | +----------------------+--------------------------------------+ +--------------------------------------+--------------------------------------+------------------------------+-----------+--------------------------------------+---------------------+----------------------------------+ | ID | Instance ID | Name | Status | Parent ID | Updated | Project ID | +--------------------------------------+--------------------------------------+------------------------------+-----------+--------------------------------------+---------------------+----------------------------------+ | 1ecd0a75-e4aa-400b-b0c8-cb738944fd43 | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | mysql-backup-name1 | COMPLETED | None | 2022-10-24T01:46:55 | fc51186c63df417ea63cec6c65a2d564 | +--------------------------------------+--------------------------------------+------------------------------+-----------+--------------------------------------+---------------------+----------------------------------+ $ openstack database backup show 1ecd0a75-e4aa-400b-b0c8-cb738944fd43 +----------------------+---------------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------------+ | created | 2022-10-24T01:46:38 | | datastore | mysql | | datastore_version | 8.0.29 | | datastore_version_id | 324f2bdf-6099-4754-a5f9-82abee026a19 | | description | None | | id | 1ecd0a75-e4aa-400b-b0c8-cb738944fd43 | | instance_id | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | | locationRef | http://172.../my-trove-backups/1ecd0a75-e4aa-400b-b0c8-cb738944fd43.xbstream.gz | | name | mysql-backup-name1 | | parent_id | None | | project_id | fc51186c63df417ea63cec6c65a2d564 | | size | 0.19 | | status | COMPLETED | | updated | 2022-10-24T01:46:55 | +----------------------+---------------------------------------------------------------------------------+ | 1ecd0a75-e4aa-400b-b0c8-cb738944fd43.xbstream.gz | Now assume that the ``mysql1`` database instance is damaged and you command to create a new database instance called ``mysql2``. - Specify that the new ``mysql2`` instance has the same flavor (``d2``) and the same root volume size (``d1`) as the original ``mysql1`` instance. ``1ecd0a75-e4aa-400b-b0c8-cb738944fd43``. $ openstack database instance create mysql2 --flavor d2 \ --nic net-id=$(openstack network list -f value -c ID --name private) \ --datastore mysql --datastore-version 8.0.29 --datastore-version-number 8.0.29 --size 1 \ --backup $(openstack database backup show mysql-backup-name1 -f value -c id) +--------------------------+--------------------------------------+ | Field | Value | +--------------------------+--------------------------------------+ | allowed_cidrs | [] | | created | 2022-10-24T01:56:55 | | datastore | mysql | | datastore_version | 8.0.29 | | datastore_version_number | 8.0.29 | | encrypted_rpc_messaging | True | | flavor | d2 | | id | 62f0f152-8cd5-42b3-9cd6-91bda651a4c0 | | name | mysql2 | | operating_status | | | public | False | | region | RegionOne | | server_id | None | | service_status_updated | 2022-10-24T01:56:55 | | status | BUILD | | tenant_id | fc51186c63df417ea63cec6c65a2d564 | | updated | 2022-10-24T01:56:55 | | volume | 1 | | volume_id | None | +--------------------------+--------------------------------------+ Now check that the new ``mysql2`` instance has the same characteristics as the original ``mysql1`` instance. Start by getting the ID of the new ``mysql2`` instance. +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+--------------------------------------------------------------------------------------------------+-----------+------+------+ | ID | Name | Datastore | Datastore Version | Status | Operating Status | Public | Addresses | Flavor ID | Size | Role | +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+--------------------------------------------------------------------------------------------------+-----------+------+------+ | 6eef378d-1d9c-4e48-b206-b3db130d750d | mysql2 | mysql | 8.0.29 | ACTIVE | HEALTHY | False | [{'address': '10.0.0.8', 'type': 'private', 'network': '33f3a589-b806-4212-9a59-8e058cac0699'}] | d2 | 1 | | | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | mysql1 | mysql | 8.0.29 | ACTIVE | HEALTHY | False | [{'address': '10.0.0.18', 'type': 'private', 'network': '33f3a589-b806-4212-9a59-8e058cac0699'}] | d2 | 1 | | +--------------------------------------+--------+-----------+-------------------+--------+------------------+--------+--------------------------------------------------------------------------------------------------+-----------+------+------+ mysql2 instance. Pass in mysql2's ``INSTANCE_ID``, which is ``6eef378d-1d9c-4e48-b206-b3db130d750d``. $ openstack database instance show mysql2 +--------------------------+-------------------------------------------------------------------------------------------------+ | Field | Value | +--------------------------+-------------------------------------------------------------------------------------------------+ | addresses | [{'address': '10.0.0.8', 'type': 'private', 'network': '33f3a589-b806-4212-9a59-8e058cac0699'}] | | allowed_cidrs | [] | | created | 2022-10-24T01:58:51 | | datastore | mysql | | datastore_version | 8.0.29 | | datastore_version_number | 8.0.29 | | encrypted_rpc_messaging | True | | flavor | d2 | | id | 6eef378d-1d9c-4e48-b206-b3db130d750d | | ip | 10.0.0.8 | | name | mysql2 | | operating_status | HEALTHY | | public | False | | region | RegionOne | | server_id | 7a8cd089-bd1c-4230-aedd-ced4e945ad46 | | service_status_updated | 2022-10-24T02:12:35 | | status | ACTIVE | | tenant_id | fc51186c63df417ea63cec6c65a2d564 | | updated | 2022-10-24T02:05:03 | | volume | 1 | | volume_id | 7080954f-e22f-4442-8f40-e26aaa080c9d | | volume_used | 0.19 | +--------------------------+-------------------------------------------------------------------------------------------------+ values as in the original ``mysql1`` instance. Tell the users who were accessing the now-disabled ``mysql1`` database instance that they can now access ``mysql2``. Provide them with ``mysql2``'s name, IP address, and any other information they At this point, you might want to delete the disabled ``mysql1`` $ openstack database backup create mysql-backup-name1.1 --instance mysql1 --swift-container 'my-trove-backups' \ --parent $(openstack database backup show mysql-backup-name1 -f value -c id) +----------------------+--------------------------------------+ | Field | Value | +----------------------+--------------------------------------+ | created | 2022-10-24T02:38:41 | | datastore | mysql | | datastore_version | 8.0.29 | | datastore_version_id | 324f2bdf-6099-4754-a5f9-82abee026a19 | | description | None | | id | e15ae06a-3afb-4794-8890-7059317b2218 | | instance_id | 78e338e3-d1c4-4189-8ea7-bfc1fab5011f | | locationRef | None | | name | mysql-backup-name1.1 | | parent_id | 1ecd0a75-e4aa-400b-b0c8-cb738944fd43 | | project_id | fc51186c63df417ea63cec6c65a2d564 | | size | None | | status | NEW | | updated | 2022-10-24T02:38:41 | +----------------------+--------------------------------------+To avoid this issue in the future, you can set up a cron job to create (incremental) backups regularly. "," +--------------------------------------+--------+-----------+-------------------+--------+-----------+------+ | id | name | datastore | datastore_version | status | flavor_id | size | +--------------------------------------+--------+-----------+-------------------+--------+-----------+------+ | 97b4b853-80f6-414f-ba6f-c6f455a79ae6 | guest1 | mysql | mysql-5.5 | ACTIVE | 10 | 2 | +--------------------------------------+--------+-----------+-------------------+--------+-----------+------+ $ openstack database backup strategy create --instance-id 97b4b853-80f6-414f-ba6f-c6f455a79ae6 --swift-container my-trove-backups | instance_id | 97b4b853-80f6-414f-ba6f-c6f455a79ae6 | | project_id | 922b47766bcb448f83a760358337f2b4 | $ openstack database backup create 97b4b853-80f6-414f-ba6f-c6f455a79ae6 backup1 +-------------+--------------------------------------+ | Property | Value | +-------------+--------------------------------------+ | created | 2014-03-18T17:09:07 | | description | None | | id | 8af30763-61fd-4aab-8fe8-57d528911138 | | instance_id | 97b4b853-80f6-414f-ba6f-c6f455a79ae6 | | locationRef | None | | name | backup1 | | parent_id | None | | size | None | | status | NEW | | updated | 2014-03-18T17:09:07 | +-------------+--------------------------------------+ +--------------------------------------+--------------------------------------+---------+-----------+-----------+---------------------+ | id | instance_id | name | status | parent_id | updated | +--------------------------------------+--------------------------------------+---------+-----------+-----------+---------------------+ | 8af30763-61fd-4aab-8fe8-57d528911138 | 97b4b853-80f6-414f-ba6f-c6f455a79ae6 | backup1 | COMPLETED | None | 2014-03-18T17:09:11 | +--------------------------------------+--------------------------------------+---------+-----------+-----------+---------------------+ $ openstack database backup show 8af30763-61fd-4aab-8fe8-57d528911138 +-------------+----------------------------------------------------+ | Property | Value | +-------------+----------------------------------------------------+ | created | 2014-03-18T17:09:07 | | description | None | | id | 8af...138 | | instance_id | 97b...ae6 | | locationRef | http://10.0.0.1:.../.../8af...138.xbstream.gz.enc | | name | backup1 | | parent_id | None | | size | 0.17 | | status | COMPLETED | | updated | 2014-03-18T17:09:11 | +-------------+----------------------------------------------------+ | 8af30763-61fd-4aab-8fe8-57d528911138.xbstream.gz | Now assume that the ``guest1`` database instance is damaged and you command to create a new database instance called ``guest2``. - Specify that the new ``guest2`` instance has the same flavor (``10``) and the same root volume size (``2``) as the original ``guest1`` instance. ``8af30763-61fd-4aab-8fe8-57d528911138``. $ openstack database instance create guest2 --flavor 10 --size 2 --nic net-id=$network_id --backup BACKUP_ID +-------------------+----------------------------------------------+ | Property | Value | +-------------------+----------------------------------------------+ | created | 2014-03-18T17:12:03 | | datastore | {u'version': u'mysql-5.5', u'type': u'mysql'}| |datastore_version | mysql-5.5 | | flavor | {u'id': u'10', u'links': [{u'href': ...]} | | id | ac7a2b35-a9b4-4ff6-beac-a1bcee86d04b | | name | guest2 | | status | BUILD | | updated | 2014-03-18T17:12:03 | | volume | {u'size': 2} | +-------------------+----------------------------------------------+ Now check that the new ``guest2`` instance has the same characteristics as the original ``guest1`` instance. Start by getting the ID of the new ``guest2`` instance. +-----------+--------+-----------+-------------------+--------+-----------+------+ | id | name | datastore | datastore_version | status | flavor_id | size | +-----------+--------+-----------+-------------------+--------+-----------+------+ | 97b...ae6 | guest1 | mysql | mysql-5.5 | ACTIVE | 10 | 2 | | ac7...04b | guest2 | mysql | mysql-5.5 | ACTIVE | 10 | 2 | +-----------+--------+-----------+-------------------+--------+-----------+------+ guest2 instance. Pass in guest2's ``INSTANCE_ID``, which is ``ac7a2b35-a9b4-4ff6-beac-a1bcee86d04b``. $ openstack database instance show INSTANCE_ID +-------------------+--------------------------------------+ | Property | Value | +-------------------+--------------------------------------+ | created | 2014-03-18T17:12:03 | | datastore | mysql | | datastore_version | mysql-5.5 | | flavor | 10 | | id | ac7a2b35-a9b4-4ff6-beac-a1bcee86d04b | | ip | 10.0.0.3 | | name | guest2 | | status | ACTIVE | | updated | 2014-03-18T17:12:06 | | volume | 2 | | volume_used | 0.18 | +-------------------+--------------------------------------+ values as in the original ``guest1`` instance. Tell the users who were accessing the now-disabled ``guest1`` database instance that they can now access ``guest2``. Provide them with ``guest2``'s name, IP address, and any other information they At this point, you might want to delete the disabled ``guest1`` $ openstack database backup create INSTANCE_ID backup1.1 --parent BACKUP_ID +-------------+--------------------------------------+ | Property | Value | +-------------+--------------------------------------+ | created | 2014-03-19T14:09:13 | | description | None | | id | 1d474981-a006-4f62-b25f-43d7b8a7097e | | instance_id | 792a6a56-278f-4a01-9997-d997fa126370 | | locationRef | None | | name | backup1.1 | | parent_id | 6dc3a9b7-1f3e-4954-8582-3f2e4942cddd | | size | None | | status | NEW | | updated | 2014-03-19T14:09:13 | +-------------+--------------------------------------+To avoid this issue in the future, you can set up a cron job to create (incremental) backups regularly.",149,113
openstack%2Fzaqar~master~I5bb488f33d1c24298bb96e2702d2c98415db6cf4,openstack/zaqar,master,I5bb488f33d1c24298bb96e2702d2c98415db6cf4,Optimize devstack plugin,MERGED,2023-01-28 03:13:31.000000000,2023-01-29 04:27:26.000000000,2023-01-29 04:26:24.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-28 03:13:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/296cb3b561698305cc5b2e7c88eace9e710b8c29', 'message': 'Optimize devstack plugin\n\nFor fixing the issue that mongodb in not in ubuntu 22.04 release, we need\nto give a work-around way to install mongodb successfully in 22.04.\n\nChange-Id: I5bb488f33d1c24298bb96e2702d2c98415db6cf4\n'}, {'number': 2, 'created': '2023-01-28 06:18:36.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6b34431779243cd274c9d4a71bb544cae980ef52', 'message': 'Optimize devstack plugin\n\nFor fixing the issue that mongodb in not in ubuntu 22.04 release, we need\nto give a work-around way to install mongodb successfully in 22.04.\n\nChange-Id: I5bb488f33d1c24298bb96e2702d2c98415db6cf4\n'}]",1,871265,6b34431779243cd274c9d4a71bb544cae980ef52,16,2,2,8846,,,0,"Optimize devstack plugin

For fixing the issue that mongodb in not in ubuntu 22.04 release, we need
to give a work-around way to install mongodb successfully in 22.04.

Change-Id: I5bb488f33d1c24298bb96e2702d2c98415db6cf4
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/65/871265/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,296cb3b561698305cc5b2e7c88eace9e710b8c29,optimize-plugin-shell," ubuntu_version=`cat /etc/issue | cut -d "" "" -f2` if [[ $ubuntu_version > '22' ]]; then wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add - echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list sudo apt update curl -LO http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1-1ubuntu2.1~18.04.20_amd64.deb sudo dpkg -i ./libssl1.1_1.1.1-1ubuntu2.1~18.04.20_amd64.deb install_package mongodb-org restart_service mongod else install_package mongodb-server restart_service mongodb"," wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add - echo ""deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse"" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list sudo apt update curl -LO http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1-1ubuntu2.1~18.04.20_amd64.deb sudo dpkg -i ./libssl1.1_1.1.1-1ubuntu2.1~18.04.20_amd64.deb install_package mongodb-org restart_service mongod",12,8
openstack%2Fvenus~master~I892b7954bd220c862972d975cd57700654664610,openstack/venus,master,I892b7954bd220c862972d975cd57700654664610,set check delete es index time as 120s,MERGED,2023-01-29 02:10:57.000000000,2023-01-29 03:45:32.000000000,2023-01-29 03:44:22.000000000,"[{'_account_id': 22348}, {'_account_id': 30455}, {'_account_id': 30562}]","[{'number': 1, 'created': '2023-01-29 02:10:57.000000000', 'files': ['venus/task/timer.py'], 'web_link': 'https://opendev.org/openstack/venus/commit/36b3e3469ca904a1ae230f4fe0c18d160151e5ee', 'message': 'set check delete es index time as 120s\n\nChange-Id: I892b7954bd220c862972d975cd57700654664610\n'}]",1,872070,36b3e3469ca904a1ae230f4fe0c18d160151e5ee,11,3,1,30455,,,0,"set check delete es index time as 120s

Change-Id: I892b7954bd220c862972d975cd57700654664610
",git fetch https://review.opendev.org/openstack/venus refs/changes/70/872070/1 && git format-patch -1 --stdout FETCH_HEAD,['venus/task/timer.py'],1,36b3e3469ca904a1ae230f4fe0c18d160151e5ee,," seconds=120, id='delete_es_index_job') "," seconds=60, id='delete_es_index_job') ",1,1
openstack%2Fironic~stable%2Fwallaby~I5449cab1b25d2543df397dd1bb086c84db16ea25,openstack/ironic,stable/wallaby,I5449cab1b25d2543df397dd1bb086c84db16ea25,DNM: testing tempest pin for stable/wallaby,ABANDONED,2023-01-27 19:21:32.000000000,2023-01-29 02:57:13.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 19:21:32.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/dc0b86e549f87d238782ad2f723864e9f51d6288', 'message': 'DNM: testing tempest pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nChange-Id: I5449cab1b25d2543df397dd1bb086c84db16ea25\n'}]",0,872045,dc0b86e549f87d238782ad2f723864e9f51d6288,4,1,1,8556,,,0,"DNM: testing tempest pin for stable/wallaby

Depends-On: https://review.opendev.org/c/openstack/devstack/+/871782
Change-Id: I5449cab1b25d2543df397dd1bb086c84db16ea25
",git fetch https://review.opendev.org/openstack/ironic refs/changes/45/872045/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,dc0b86e549f87d238782ad2f723864e9f51d6288,wallaby-pin-tempest,#test,,1,0
openstack%2Fnova~stable%2Fxena~If01acbb8a110b8580ad0701ce92abb7491020382,openstack/nova,stable/xena,If01acbb8a110b8580ad0701ce92abb7491020382,DNM: testing tempest pin for stable/wallaby,ABANDONED,2023-01-25 22:00:00.000000000,2023-01-29 02:57:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-25 22:00:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1fb17a6f49153a63f6ffe662a1cc8b40e81e7774', 'message': 'DNM: testing tempest pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nChange-Id: If01acbb8a110b8580ad0701ce92abb7491020382\n'}, {'number': 2, 'created': '2023-01-27 04:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/40b2fb066c512faff61827a2cc1edfdd67ac9fd1', 'message': 'DNM: testing tempest pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871945\n\nChange-Id: If01acbb8a110b8580ad0701ce92abb7491020382\n'}, {'number': 3, 'created': '2023-01-27 05:58:00.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/ef77d3f2476ef6106857d3624dfacf0bdf38a9ac', 'message': 'DNM: testing tempest pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871945\nDepends-On: https://review.opendev.org/c/openstack/grenade/+/871949\nDepends-On: https://review.opendev.org/c/openstack/grenade/+/871955\n\nChange-Id: If01acbb8a110b8580ad0701ce92abb7491020382\n'}]",7,871800,ef77d3f2476ef6106857d3624dfacf0bdf38a9ac,26,1,3,8556,,,0,"DNM: testing tempest pin for stable/wallaby

Depends-On: https://review.opendev.org/c/openstack/devstack/+/871782
Depends-On: https://review.opendev.org/c/openstack/devstack/+/871945
Depends-On: https://review.opendev.org/c/openstack/grenade/+/871949
Depends-On: https://review.opendev.org/c/openstack/grenade/+/871955

Change-Id: If01acbb8a110b8580ad0701ce92abb7491020382
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/871800/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1fb17a6f49153a63f6ffe662a1cc8b40e81e7774,wallaby-pin-tempest,# See https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3,# See https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3,1,1
openstack%2Foctavia~master~I48695be8868f9b4845bfebc3be3b628eda55c628,openstack/octavia,master,I48695be8868f9b4845bfebc3be3b628eda55c628,DNM: testing tempest pin for stable/wallaby,ABANDONED,2023-01-27 02:06:10.000000000,2023-01-29 02:56:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 02:06:10.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/1abc9598d5f5b72da488ee105e28e9e61c588b65', 'message': 'DNM: testing tempest pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/devstack/+/871782\nChange-Id: I48695be8868f9b4845bfebc3be3b628eda55c628\n'}]",0,871915,1abc9598d5f5b72da488ee105e28e9e61c588b65,3,1,1,8556,,,0,"DNM: testing tempest pin for stable/wallaby

Depends-On: https://review.opendev.org/c/openstack/devstack/+/871782
Change-Id: I48695be8868f9b4845bfebc3be3b628eda55c628
",git fetch https://review.opendev.org/openstack/octavia refs/changes/15/871915/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,1abc9598d5f5b72da488ee105e28e9e61c588b65,wallaby-pin-tempest,# Note: Some official OpenStack wide jobs are still defined in the,# Note: Some official OpenStack wide jobs are still defined in the,1,1
openstack%2Fneutron~master~I956e33d1300be7fa732ac7c3c87087744b93fe42,openstack/neutron,master,I956e33d1300be7fa732ac7c3c87087744b93fe42,DNM: testing tempest/plugin pin for stable/wallaby,ABANDONED,2023-01-25 21:53:04.000000000,2023-01-29 02:55:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-25 21:53:04.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f9e44a80084337366b0974e2adf0e97abb4b4420', 'message': 'DNM: testing tempest/plugin pin for stable/wallaby\n\nDepends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/871793\nChange-Id: I956e33d1300be7fa732ac7c3c87087744b93fe42\n'}]",3,871795,f9e44a80084337366b0974e2adf0e97abb4b4420,8,1,1,8556,,,0,"DNM: testing tempest/plugin pin for stable/wallaby

Depends-On: https://review.opendev.org/c/openstack/neutron-tempest-plugin/+/871793
Change-Id: I956e33d1300be7fa732ac7c3c87087744b93fe42
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/871795/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,f9e44a80084337366b0974e2adf0e97abb4b4420,wallaby-pin-tempest,# NOTE: In doc/source/contributor/testing/ci_scenario_jobs.rst file there is,# NOTE: In doc/source/contributor/testing/ci_scenario_jobs.rst file there is,1,1
openstack%2Fnova~master~Id568d342de24ff1c6da87cd5e2ad9f04541ad43a,openstack/nova,master,Id568d342de24ff1c6da87cd5e2ad9f04541ad43a,Remove mdev when delete vm,ABANDONED,2022-06-05 07:35:55.000000000,2023-01-29 02:51:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-06-05 07:35:55.000000000', 'files': ['nova/privsep/libvirt.py', 'nova/compute/manager.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3918fa106035bb8a7485d0132a9305196fb53c5b', 'message': 'Remove mdev when delete vm\n\nChange-Id: Id568d342de24ff1c6da87cd5e2ad9f04541ad43a\n'}]",4,844739,3918fa106035bb8a7485d0132a9305196fb53c5b,8,1,1,31412,,,0,"Remove mdev when delete vm

Change-Id: Id568d342de24ff1c6da87cd5e2ad9f04541ad43a
",git fetch https://review.opendev.org/openstack/nova refs/changes/39/844739/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/privsep/libvirt.py', 'nova/compute/manager.py', 'nova/compute/utils.py']",3,3918fa106035bb8a7485d0132a9305196fb53c5b,,"import nova.privsep.libvirt def delete_mdevs(instance): guest = self._host.get_guest(instance) cfg = guest.get_config() for device in cfg.devices: if isinstance(device, vconfig.LibvirtConfigGuestHostdevMDEV): nova.privsep.libvirt.remove_mdev( pci_addr, dev_supported_type, device.uuid)",,21,0
openstack%2Fcinder~master~I5e065a3c16d438df604a169deca9fb1852f13d6b,openstack/cinder,master,I5e065a3c16d438df604a169deca9fb1852f13d6b,Infinidat: add storage assisted volume migration,MERGED,2022-11-15 10:26:36.000000000,2023-01-29 00:09:40.000000000,2023-01-28 20:49:40.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5948}, {'_account_id': 13425}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-15 10:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2168a473df0831e3f251a6d2cdf1e2ef4e946d3a', 'message': 'Infinidat: add storage assisted volume migration\n\nAdding support for storage assisted volume migration\nin Infinidat driver. This patch implements:\n* migrate_volume()\n* unit tests to cover new code\n\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\nChange-Id: I5e065a3c16d438df604a169deca9fb1852f13d6b\n'}, {'number': 2, 'created': '2022-11-24 20:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2c0cde10780bef11db3d3a115fd7d449dc5b9f8f', 'message': 'Infinidat: add storage assisted volume migration\n\nAdding support for storage assisted volume migration\nin Infinidat driver. This patch implements:\n* migrate_volume()\n* unit tests to cover new code\n\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\nChange-Id: I5e065a3c16d438df604a169deca9fb1852f13d6b\n'}, {'number': 3, 'created': '2022-12-19 13:46:56.000000000', 'files': ['releasenotes/notes/infinidat-add-storage-assisted-migration-4e12f24ee297ef65.yaml', 'doc/source/configuration/block-storage/drivers/infinidat-volume-driver.rst', 'cinder/tests/unit/volume/drivers/test_infinidat.py', 'cinder/volume/drivers/infinidat.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7d442e5b5bf990d54385dfb43fe6de5ac5625b7f', 'message': 'Infinidat: add storage assisted volume migration\n\nAdding support for storage assisted volume migration\nin Infinidat driver. This patch implements:\n* migrate_volume()\n* unit tests to cover new code\n\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\nChange-Id: I5e065a3c16d438df604a169deca9fb1852f13d6b\n'}]",10,864287,7d442e5b5bf990d54385dfb43fe6de5ac5625b7f,84,6,3,35075,,,0,"Infinidat: add storage assisted volume migration

Adding support for storage assisted volume migration
in Infinidat driver. This patch implements:
* migrate_volume()
* unit tests to cover new code

Signed-off-by: Alexander Deiter <adeiter@infinidat.com>
Change-Id: I5e065a3c16d438df604a169deca9fb1852f13d6b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/864287/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/infinidat-add-storage-assisted-migration-4e12f24ee297ef65.yaml', 'doc/source/configuration/block-storage/drivers/infinidat-volume-driver.rst', 'cinder/tests/unit/volume/drivers/test_infinidat.py', 'cinder/volume/drivers/infinidat.py']",4,2168a473df0831e3f251a6d2cdf1e2ef4e946d3a,infinidat-add-local-volume-migration," 1.14 - added storage assisted volume migration VERSION = '1.14' location_info = '%(driver)s:%(serial)s:%(pool)s' % { 'driver': self.__class__.__name__, 'serial': self._system.get_serial(), 'pool': self.configuration.infinidat_pool_name} location_info=location_info, @infinisdk_to_cinder_exceptions def migrate_volume(self, ctxt, volume, host): """"""Migrate a volume within the same InfiniBox system."""""" LOG.debug('Starting volume migration for volume %s to host %s', volume.name, host) if not (host and 'capabilities' in host): LOG.error('No capabilities found for host %s', host) return False, None capabilities = host['capabilities'] if not (capabilities and 'location_info' in capabilities): LOG.error('No location info found for host %s', host) return False, None location = capabilities['location_info'] try: driver, serial, pool = location.split(':') serial = int(serial) except (AttributeError, ValueError) as error: LOG.error('Invalid location info %s found for host %s: %s', location, host, error) return False, None if driver != self.__class__.__name__: LOG.debug('Unsupported storage driver %s found for host %s', driver, host) return False, None if serial != self._system.get_serial(): LOG.error('Unable to migrate volume %s to remote host %s', volume.name, host) return False, None infinidat_volume = self._get_infinidat_volume(volume) if pool == infinidat_volume.get_pool_name(): LOG.debug('Volume %s already migrated to pool %s', volume.name, pool) return True, None infinidat_pool = self._system.pools.safe_get(name=pool) if infinidat_pool is None: LOG.error('Destination pool %s not found on host %s', pool, host) return False, None infinidat_volume.move_pool(infinidat_pool) LOG.debug('Migrated volume %s to pool %s', volume.name, pool) return True, None", VERSION = '1.13',131,7
openstack%2Fcinder~master~Ic583131b46d928ef7669fa47e697cce65e7632bc,openstack/cinder,master,Ic583131b46d928ef7669fa47e697cce65e7632bc,NetApp: Add NVMe/TCP driver,MERGED,2023-01-18 14:07:29.000000000,2023-01-28 23:30:19.000000000,2023-01-27 14:22:56.000000000,"[{'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 33648}, {'_account_id': 34853}]","[{'number': 1, 'created': '2023-01-18 14:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/683e4190f3739e5297033e429ada179aadfceaaf', 'message': 'NetApp: Add NVMe/TCP driver\n\nAdd NVMe/TCP cinder volume driver for the NetApp ONTAP Cluster.\n\nImplements: blueprint netapp-volume-driver\n\nChange-Id: Ic583131b46d928ef7669fa47e697cce65e7632bc\n'}, {'number': 2, 'created': '2023-01-18 14:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e5d49372477a37d82b7c97769bcf050f46ac640', 'message': 'NetApp: Add NVMe/TCP driver\n\nAdd NVMe/TCP cinder volume driver for the NetApp ONTAP Cluster.\n\nImplements: blueprint netapp-volume-driver\n\nChange-Id: Ic583131b46d928ef7669fa47e697cce65e7632bc\n'}, {'number': 3, 'created': '2023-01-26 00:29:51.000000000', 'files': ['cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/volume/drivers/netapp/dataontap/client/api.py', 'cinder/volume/drivers/netapp/dataontap/nvme_library.py', 'doc/source/configuration/tables/cinder-netapp_cdot_iscsi.inc', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode_rest.py', 'cinder/volume/drivers/netapp/options.py', 'doc/source/reference/support-matrix.ini', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode_rest.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nvme_library.py', 'cinder/volume/drivers/netapp/dataontap/utils/utils.py', 'releasenotes/notes/add_nvme_tcp_driver-558ff80aa2029e2b.yaml', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nvme_cmode.py', 'doc/source/configuration/block-storage/drivers/netapp-volume-driver.rst', 'cinder/volume/drivers/netapp/dataontap/nvme_cmode.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3141da1442e9f6ec18194feefc7173ab7798a193', 'message': 'NetApp: Add NVMe/TCP driver\n\nAdd NVMe/TCP cinder volume driver for the NetApp ONTAP Cluster.\n\nImplements: blueprint netapp-volume-driver\n\nChange-Id: Ic583131b46d928ef7669fa47e697cce65e7632bc\n'}]",24,870004,3141da1442e9f6ec18194feefc7173ab7798a193,82,5,3,31721,,,0,"NetApp: Add NVMe/TCP driver

Add NVMe/TCP cinder volume driver for the NetApp ONTAP Cluster.

Implements: blueprint netapp-volume-driver

Change-Id: Ic583131b46d928ef7669fa47e697cce65e7632bc
",git fetch https://review.opendev.org/openstack/cinder refs/changes/04/870004/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/volume/drivers/netapp/dataontap/client/api.py', 'cinder/volume/drivers/netapp/dataontap/nvme_library.py', 'doc/source/configuration/tables/cinder-netapp_cdot_iscsi.inc', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode_rest.py', 'cinder/volume/drivers/netapp/options.py', 'doc/source/reference/support-matrix.ini', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode_rest.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nvme_library.py', 'cinder/volume/drivers/netapp/dataontap/utils/utils.py', 'cinder/volume/drivers/netapp/common.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nvme_cmode.py', 'doc/source/configuration/block-storage/drivers/netapp-volume-driver.rst', 'cinder/volume/drivers/netapp/dataontap/nvme_cmode.py']",15,683e4190f3739e5297033e429ada179aadfceaaf,bp/netapp-volume-driver,"# Copyright (c) 2023 NetApp, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Volume driver for NetApp Data ONTAP NVMe storage systems. """""" from cinder import interface from cinder.volume import driver from cinder.volume.drivers.netapp.dataontap import nvme_library from cinder.volume.drivers.netapp import options as na_opts @interface.volumedriver class NetAppCmodeNVMeDriver(driver.BaseVD): """"""NetApp C-mode NVMe volume driver. Version history: .. code-block:: none 1.0.0 - Initial driver """""" VERSION = ""1.0.0"" DRIVER_NAME = 'NetApp_NVMe_Cluster_direct' # ThirdPartySystems wiki page CI_WIKI_NAME = ""NetApp_CI"" def __init__(self, *args, **kwargs): super(NetAppCmodeNVMeDriver, self).__init__(*args, **kwargs) self.library = nvme_library.NetAppNVMeStorageLibrary( self.DRIVER_NAME, 'NVMe', **kwargs) @staticmethod def get_driver_options(): return na_opts.netapp_cluster_opts def do_setup(self, context): self.library.do_setup(context) def check_for_setup_error(self): self.library.check_for_setup_error() def create_volume(self, volume): return self.library.create_volume(volume) def create_volume_from_snapshot(self, volume, snapshot): return self.library.create_volume_from_snapshot(volume, snapshot) def create_cloned_volume(self, volume, src_vref): return self.library.create_cloned_volume(volume, src_vref) def delete_volume(self, volume): self.library.delete_volume(volume) def create_snapshot(self, snapshot): self.library.create_snapshot(snapshot) def delete_snapshot(self, snapshot): self.library.delete_snapshot(snapshot) def get_volume_stats(self, refresh=False): return self.library.get_volume_stats(refresh, self.get_filter_function(), self.get_goodness_function()) def get_default_filter_function(self): return self.library.get_default_filter_function() def get_default_goodness_function(self): return self.library.get_default_goodness_function() def extend_volume(self, volume, new_size): self.library.extend_volume(volume, new_size) def ensure_export(self, context, volume): return self.library.ensure_export(context, volume) def create_export(self, context, volume, connector): return self.library.create_export(context, volume) def remove_export(self, context, volume): self.library.remove_export(context, volume) def initialize_connection(self, volume, connector): conn_info = self.library.initialize_connection(volume, connector) return conn_info def terminate_connection(self, volume, connector, **kwargs): conn_info = self.library.terminate_connection(volume, connector, **kwargs) return conn_info def get_pool(self, volume): return self.library.get_pool(volume) ",,2769,8
openstack%2Fopenstacksdk~master~I7532d03ad26785dccdcc37b19165c19246ebd6e1,openstack/openstacksdk,master,I7532d03ad26785dccdcc37b19165c19246ebd6e1,Finish Magnum rework,MERGED,2023-01-27 11:35:54.000000000,2023-01-28 20:49:40.000000000,2023-01-28 20:48:35.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-27 11:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a1f152e90d60de806f1379d322adfea889607ed5', 'message': 'Finish Magnum rework\n\n- add coe service resource and proxy methods\n- add coe cluster certificates resource and methods\n- switch remaining cloud methods to use proxy\n- add coe docs\n\nChange-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1\n'}, {'number': 2, 'created': '2023-01-27 17:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ee366f1234b8dddb6913a10a3756e10b1d06b654', 'message': 'Finish Magnum rework\n\n- add coe service resource and proxy methods\n- add coe cluster certificates resource and methods\n- switch remaining cloud methods to use proxy\n- add coe docs\n\nChange-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1\n'}, {'number': 3, 'created': '2023-01-27 17:47:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9665f07d815ba6252ea6ee7c52edf4b9f9d49cd9', 'message': 'Finish Magnum rework\n\n- add coe service resource and proxy methods\n- add coe cluster certificates resource and methods\n- switch remaining cloud methods to use proxy\n- add coe docs\n\nChange-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1\n'}, {'number': 4, 'created': '2023-01-27 20:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ddfdd660edb502eecda2c780a9ca7171733c49e8', 'message': 'Finish Magnum rework\n\n- add coe service resource and proxy methods\n- add coe cluster certificates resource and methods\n- switch remaining cloud methods to use proxy\n- add coe docs\n\nChange-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1\n'}, {'number': 5, 'created': '2023-01-28 10:40:31.000000000', 'files': ['openstack/cloud/_coe.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_service.py', 'doc/source/user/index.rst', 'openstack/tests/unit/cloud/test_coe_clusters_certificate.py', 'releasenotes/notes/switch-coe-to-proxy-c18789ed27cc1d95.yaml', 'doc/source/user/resources/container_infrastructure_management/index.rst', 'doc/source/user/resources/container_infrastructure_management/cluster_template.rst', 'openstack/container_infrastructure_management/v1/cluster_certificate.py', 'openstack/container_infrastructure_management/v1/service.py', 'doc/source/user/resources/container_infrastructure_management/service.rst', 'doc/source/user/proxies/container_infrastructure_management.rst', 'openstack/tests/unit/container_infrastructure_management/v1/test_cluster_certificate.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_proxy.py', 'doc/source/user/resources/container_infrastructure_management/cluster_certificate.rst', 'doc/source/user/resources/container_infrastructure_management/cluster.rst', 'openstack/container_infrastructure_management/v1/_proxy.py', 'openstack/tests/unit/cloud/test_magnum_services.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a27619cbf430fc99fb16e4adae0bb2cbda1e4507', 'message': 'Finish Magnum rework\n\n- add coe service resource and proxy methods\n- add coe cluster certificates resource and methods\n- switch remaining cloud methods to use proxy\n- add coe docs\n\nChange-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1\n'}]",1,871987,a27619cbf430fc99fb16e4adae0bb2cbda1e4507,15,2,5,27900,,,0,"Finish Magnum rework

- add coe service resource and proxy methods
- add coe cluster certificates resource and methods
- switch remaining cloud methods to use proxy
- add coe docs

Change-Id: I7532d03ad26785dccdcc37b19165c19246ebd6e1
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/87/871987/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cloud/_coe.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_service.py', 'doc/source/user/index.rst', 'openstack/tests/unit/cloud/test_coe_clusters_certificate.py', 'releasenotes/notes/switch-coe-to-proxy-c18789ed27cc1d95.yaml', 'doc/source/user/resources/container_infrastructure_management/index.rst', 'doc/source/user/resources/container_infrastructure_management/cluster_template.rst', 'openstack/container_infrastructure_management/v1/cluster_certificate.py', 'openstack/container_infrastructure_management/v1/service.py', 'doc/source/user/resources/container_infrastructure_management/service.rst', 'doc/source/user/proxies/container_infrastructure_management.rst', 'openstack/tests/unit/container_infrastructure_management/v1/test_cluster_certificate.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_proxy.py', 'doc/source/user/resources/container_infrastructure_management/cluster_certificate.rst', 'doc/source/user/resources/container_infrastructure_management/cluster.rst', 'openstack/container_infrastructure_management/v1/_proxy.py']",16,a1f152e90d60de806f1379d322adfea889607ed5,coe-gaps," cluster_certificate as _cluster_cert ) from openstack.container_infrastructure_management.v1 import (from openstack.container_infrastructure_management.v1 import ( service as _service ) ""service"": _service.Service # ============== Cluster Certificates ============== def create_cluster_certificate(self, **attrs): """"""Create a new cluster_certificate from CSR :param dict attrs: Keyword arguments which will be used to create a :class:`~openstack.container_infrastructure_management.v1.cluster_certificate.ClusterCertificate`, comprised of the properties on the ClusterCertificate class. :returns: The results of cluster_certificate creation :rtype: :class:`~openstack.container_infrastructure_management.v1.cluster_certificate.ClusterCertificate` """""" return self._create(_cluster_cert.ClusterCertificate, **attrs) def get_cluster_certificate(self, cluster_certificate): """"""Get a single cluster_certificate :param cluster_certificate: The value can be the ID of a cluster_certificate or a :class:`~openstack.container_infrastructure_management.v1.cluster_certificate.ClusterCertificate` instance. :returns: One :class:`~openstack.container_infrastructure_management.v1.cluster_certificate.ClusterCertificate` :raises: :class:`~openstack.exceptions.ResourceNotFound` when no resource can be found. """""" return self._get(_cluster_cert.ClusterCertificate, cluster_certificate) # ============== Services ============== def services(self): """"""Return a generator of services :returns: A generator of service objects :rtype: :class:`~openstack.container_infrastructure_management.v1.service.Service` """""" return self._list(_service.Service)",,361,186
openstack%2Fopenstacksdk~master~I8a7198231fd60abf5ac2dd44985961c8c47db657,openstack/openstacksdk,master,I8a7198231fd60abf5ac2dd44985961c8c47db657,Add magnum cluster templates resource,MERGED,2023-01-24 17:37:40.000000000,2023-01-28 20:45:33.000000000,2023-01-28 20:44:18.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-24 17:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/539fc12e5520dcccb04bf76937b9bb4fa818d438', 'message': 'WIP: add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 2, 'created': '2023-01-24 18:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/505ef239ee3fbc8da9821e243bb25c8b3a01761d', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 3, 'created': '2023-01-25 19:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/32e4f9976f30cae87f909c84e8d31eba1ae23d3e', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 4, 'created': '2023-01-25 19:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a8fe4451940c63decafb02daa1b23893b19469a4', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 5, 'created': '2023-01-26 08:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ae6f1089896e938af8e3cb602fe523f93a1916b0', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 6, 'created': '2023-01-26 12:32:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f50f6ac4933c9a7137ee17648b595528622153e6', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 7, 'created': '2023-01-27 16:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f7147e396a571451d92a59a0d9925561de0ecded', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}, {'number': 8, 'created': '2023-01-27 18:39:40.000000000', 'files': ['openstack/cloud/_coe.py', 'openstack/tests/unit/cloud/test_cluster_templates.py', 'openstack/tests/functional/cloud/test_cluster_templates.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_cluster.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_cluster_template.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_proxy.py', 'openstack/container_infrastructure_management/v1/_proxy.py', 'openstack/container_infrastructure_management/v1/cluster.py', 'openstack/container_infrastructure_management/v1/cluster_template.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b66c6cc847bc0bfd9ffdbc25bfb74a0bf568d6e3', 'message': 'Add magnum cluster templates resource\n\nImplement support for magnum clustertemplate.\n\n- drop support for bays. Those were never tested properly in SDK and are\n  deprecated since Newton.\n\nChange-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657\n'}]",1,871648,b66c6cc847bc0bfd9ffdbc25bfb74a0bf568d6e3,19,2,8,27900,,,0,"Add magnum cluster templates resource

Implement support for magnum clustertemplate.

- drop support for bays. Those were never tested properly in SDK and are
  deprecated since Newton.

Change-Id: I8a7198231fd60abf5ac2dd44985961c8c47db657
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/48/871648/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/container_infrastructure_management/v1/test_cluster_template.py', 'openstack/container_infrastructure_management/v1/cluster_template.py']",2,539fc12e5520dcccb04bf76937b9bb4fa818d438,coe-gaps,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack import resource class ClusterTemplate(resource.Resource): resources_key = 'clustertemplates' base_path = '/clustertemplates' # capabilities allow_create = True allow_fetch = True allow_commit = True allow_delete = True allow_list = True allow_patch = True commit_method = 'PATCH' commit_jsonpatch = True #: The exposed port of COE API server. apiserver_port = resource.Body('apiserver_port', type=int) #: Display the attribute os_distro defined as appropriate metadata in image #: for the bay/cluster driver. cluster_distro = resource.Body('cluster_distro') #: Specify the Container Orchestration Engine to use. Supported COEs #: include kubernetes, swarm, mesos. coe = resource.Body('coe') #: The date and time when the resource was created. created_at = resource.Body('created_at') #: The name of a driver to manage the storage for the images and the #: containers writable layer. docker_storage_driver = resource.Body('docker_storage_driver') #: The size in GB for the local storage on each server for the Docker #: daemon to cache the images and host the containers. docker_volume_size = resource.Body('docker_volume_size', type=int) #: The DNS nameserver for the servers and containers in the bay/cluster to #: use. dns_nameserver = resource.Body('dns_nameserver') #: The name or network ID of a Neutron network to provide connectivity to #: the external internet for the bay/cluster. external_network_id = resource.Body('external_network_id') #: The name or network ID of a Neutron network to provide connectivity to #: the internal network for the bay/cluster. fixed_network = resource.Body('fixed_network') #: Fixed subnet that are using to allocate network address for nodes in #: bay/cluster. fixed_subnet = resource.Body('fixed_subnet') #: The nova flavor ID or name for booting the node servers. flavor_id = resource.Body('flavor_id') #: The IP address for a proxy to use when direct http access #: from the servers to sites on the external internet is blocked. #: This may happen in certain countries or enterprises, and the #: proxy allows the servers and containers to access these sites. #: The format is a URL including a port number. The default is #: None. http_proxy = resource.Body('http_proxy') #: The IP address for a proxy to use when direct https access from the #: servers to sites on the external internet is blocked. https_proxy = resource.Body('https_proxy') #: The name or UUID of the base image in Glance to boot the servers for the #: bay/cluster. image_id = resource.Body('image_id') #: The URL pointing to userss own private insecure docker #: registry to deploy and run docker containers. insecure_registry = resource.Body('insecure_registry') #: Whether enable or not using the floating IP of cloud provider. is_floating_ip_enabled = resource.Body('floating_ip_enabled') #: Indicates whether the ClusterTemplate is hidden or not. is_hidden = resource.Body('hidden', type=bool) #: this option can be set to false to create a bay/cluster without the load #: balancer. is_master_lb_enabled = resource.Body('master_lb_enabled', type=bool) #: Specifying this parameter will disable TLS so that users can access the #: COE endpoints without a certificate. is_tls_disabled = resource.Body('tls_disabled', type=bool) #: Setting this flag makes the baymodel/cluster template public and #: accessible by other users. is_public = resource.Body('public', type=bool) #: This option provides an alternative registry based on the Registry V2 is_registry_enabled = resource.Body('registry_enabled', type=bool) #: The name of the SSH keypair to configure in the bay/cluster servers for #: ssh access. keypair_id = resource.Body('keypair_id') #: The flavor of the master node for this baymodel/cluster template. master_flavor_id = resource.Body('master_flavor_id') #: The name of a network driver for providing the networks for the #: containers. network_driver = resource.Body('network_driver') #: When a proxy server is used, some sites should not go through the proxy #: and should be accessed normally. no_proxy = resource.Body('no_proxy') #: The servers in the bay/cluster can be vm or baremetal. server_type = resource.Body('server_type') #: The date and time when the resource was updated. updated_at = resource.Body('updated_at') #: The UUID of the cluster template. uuid = resource.Body('uuid', alternate_id=True) #: The name of a volume driver for managing the persistent storage for the #: containers. volume_driver = resource.Body('volume_driver') ",,209,0
openstack%2Fdevstack~stable%2Fzed~I5e938139b47f443a4c358415d0d4dcf6549cd085,openstack/devstack,stable/zed,I5e938139b47f443a4c358415d0d4dcf6549cd085,Fix setting the tempest virtual env constraints env var,MERGED,2023-01-27 04:38:47.000000000,2023-01-28 20:24:27.000000000,2023-01-28 20:23:26.000000000,"[{'_account_id': 7166}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-27 04:38:47.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/30a7d790b6bf45bbcc6333008621b093c84055d1', 'message': ""Fix setting the tempest virtual env constraints env var\n\nDevstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE\nwhich are used to use the constraints during Tempest virtual env installation.\nThose env var are set to non-master constraint when we need to use non-master\nconstraints but when we need to use the master constraints we do not set/reset\nthem point to master constraints. This create the issue when running the grenade\njob where we run Tempest on the old devstack as well as in the new devstack.\nWhen tempest is installed on old devstack then old tempest is used and it sets\nthese env var to stable/<branch> constraints (this is the case when old devstack\n(the stable branch is in EM phase) uses the old tempest not the master tempest),\nall good till now. But the problem comes when in the same grenade script run\nupgrade-tempest install the master tempest (when new devstack branches are in\nthe 'supported' phase and use the master tempest means) and are supposed to use\nthe master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env\nvar set by old tempest is used by the tempest and due to a mismatch in constraints\nit fails.\n\nThis happened when we tried to pin the stable/wallaby with Tempest 29.0.0\n- https://review.opendev.org/c/openstack/devstack/+/871782\n\nand table/xena grenade job failed (stable/xena use master tempest and supposed\nto use master constraints)\n- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641\n\nWe should set/reset those constraint env var to master constraints if configuration\ntell devstack to use the master constraints.\n\n[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124\n\nCloses-Bug: #2003993\nChange-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085\n(cherry picked from commit 7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d)\n""}]",1,871943,30a7d790b6bf45bbcc6333008621b093c84055d1,9,3,1,8556,,,0,"Fix setting the tempest virtual env constraints env var

Devstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE
which are used to use the constraints during Tempest virtual env installation.
Those env var are set to non-master constraint when we need to use non-master
constraints but when we need to use the master constraints we do not set/reset
them point to master constraints. This create the issue when running the grenade
job where we run Tempest on the old devstack as well as in the new devstack.
When tempest is installed on old devstack then old tempest is used and it sets
these env var to stable/<branch> constraints (this is the case when old devstack
(the stable branch is in EM phase) uses the old tempest not the master tempest),
all good till now. But the problem comes when in the same grenade script run
upgrade-tempest install the master tempest (when new devstack branches are in
the 'supported' phase and use the master tempest means) and are supposed to use
the master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env
var set by old tempest is used by the tempest and due to a mismatch in constraints
it fails.

This happened when we tried to pin the stable/wallaby with Tempest 29.0.0
- https://review.opendev.org/c/openstack/devstack/+/871782

and table/xena grenade job failed (stable/xena use master tempest and supposed
to use master constraints)
- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641

We should set/reset those constraint env var to master constraints if configuration
tell devstack to use the master constraints.

[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124

Closes-Bug: #2003993
Change-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085
(cherry picked from commit 7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/43/871943/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,30a7d790b6bf45bbcc6333008621b093c84055d1,bug/2003993," # NOTE(gmann): we need to set the below env var pointing to master # constraints even that is what default in tox.ini. Otherwise it can # create the issue for grenade run where old and new devstack can have # different tempest (old and master) to install. For detail problem, # refer to the https://bugs.launchpad.net/devstack/+bug/2003993 export UPPER_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master export TOX_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master",,7,0
openstack%2Fansible-collections-openstack~master~Ib677862c049b70f39630d56a147bd5537b12fb2b,openstack/ansible-collections-openstack,master,Ib677862c049b70f39630d56a147bd5537b12fb2b,"Dropped unmaintained, obsolete and broken inventory script",MERGED,2023-01-27 13:39:26.000000000,2023-01-28 18:48:35.000000000,2023-01-28 18:48:35.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-27 13:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3a68c886fe10ce8245d19764dda206354c8f07cd', 'message': 'Dropped unmaintained, obsolete and broken inventory script\n\nThis removes the old inventory script only. For a proper replacement,\nplease use inventory plugin openstack.cloud.openstack.\n\nChange-Id: Ib677862c049b70f39630d56a147bd5537b12fb2b\n'}, {'number': 2, 'created': '2023-01-27 17:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e9c39d743d83bbe7b84fbab9890bf1ae22393d31', 'message': 'Dropped unmaintained, obsolete and broken inventory script\n\nThis removes the old inventory script only. For a proper replacement,\nplease use inventory plugin openstack.cloud.openstack.\n\nChange-Id: Ib677862c049b70f39630d56a147bd5537b12fb2b\n'}, {'number': 3, 'created': '2023-01-28 13:18:27.000000000', 'files': ['tools/run-ansible-sanity.sh', 'scripts/inventory/openstack_inventory.py', 'scripts/inventory/openstack.yml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/34017d511bea42c56a387a30dd2acb67f5e31de8', 'message': 'Dropped unmaintained, obsolete and broken inventory script\n\nThis removes the old inventory script only. For a proper replacement,\nplease use inventory plugin openstack.cloud.openstack.\n\nChange-Id: Ib677862c049b70f39630d56a147bd5537b12fb2b\n'}]",0,872017,34017d511bea42c56a387a30dd2acb67f5e31de8,12,4,3,32962,,,0,"Dropped unmaintained, obsolete and broken inventory script

This removes the old inventory script only. For a proper replacement,
please use inventory plugin openstack.cloud.openstack.

Change-Id: Ib677862c049b70f39630d56a147bd5537b12fb2b
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/17/872017/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/run-ansible-sanity.sh', 'scripts/inventory/openstack_inventory.py', 'scripts/inventory/openstack.yml', 'setup.cfg']",4,3a68c886fe10ce8245d19764dda206354c8f07cd,scripts,, share/ansible/collections/ansible_collections/openstack/cloud/scripts/ = scripts/*,2,309
openstack%2Fopenstacksdk~master~I631379e4711148a5a470a91b069d8b58019c0eef,openstack/openstacksdk,master,I631379e4711148a5a470a91b069d8b58019c0eef,Add Tap Services and Flows to SDK,MERGED,2023-01-20 15:22:42.000000000,2023-01-28 16:39:24.000000000,2023-01-28 16:38:16.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-20 15:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9849a64636b877a289de27bc4290c478d74a15dd', 'message': 'Add Tap Services and Flows to SDK\n\nTODO:\n* tests\n* Docs\n\nChange-Id: I631379e4711148a5a470a91b069d8b58019c0eef\nRelated-Bug: #1999774\n'}, {'number': 2, 'created': '2023-01-25 10:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/5eabce1eb5e1f7a3fef8b7ad23208bab39020332', 'message': 'Add Tap Services and Flows to SDK\n\nChange-Id: I631379e4711148a5a470a91b069d8b58019c0eef\nRelated-Bug: #1999774\n'}, {'number': 3, 'created': '2023-01-25 13:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/75d0d18a6c56bb56fff368a4c74425ea76e488ce', 'message': 'Add Tap Services and Flows to SDK\n\nChange-Id: I631379e4711148a5a470a91b069d8b58019c0eef\nRelated-Bug: #1999774\n'}, {'number': 4, 'created': '2023-01-28 13:21:20.000000000', 'files': ['doc/source/user/resources/network/v2/tap_service.rst', 'openstack/network/v2/tap_flow.py', 'doc/source/user/resources/network/index.rst', 'doc/source/user/resources/network/v2/tap_flow.rst', 'openstack/network/v2/_proxy.py', 'doc/source/user/proxies/network.rst', 'openstack/tests/unit/network/v2/test_tap_service.py', 'openstack/tests/functional/network/v2/test_taas.py', 'releasenotes/notes/network_add_taas_resources-86a947265e11ce84.yaml', 'openstack/tests/unit/network/v2/test_tap_flow.py', 'openstack/network/v2/tap_service.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/71dcfba0cadcc371b95b3fb2b97743018b14fce4', 'message': 'Add Tap Services and Flows to SDK\n\nChange-Id: I631379e4711148a5a470a91b069d8b58019c0eef\nRelated-Bug: #1999774\n'}]",0,871287,71dcfba0cadcc371b95b3fb2b97743018b14fce4,16,2,4,8313,,,0,"Add Tap Services and Flows to SDK

Change-Id: I631379e4711148a5a470a91b069d8b58019c0eef
Related-Bug: #1999774
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/87/871287/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/tap_flow.py', 'openstack/network/v2/_proxy.py', 'openstack/network/v2/tap_service.py']",3,9849a64636b877a289de27bc4290c478d74a15dd,bug/1999774,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack import resource class TapService(resource.Resource): """"""Tap Service"""""" resource_key = 'tap_service' resources_key = 'tap_services' base_path = '/taas/tap_services' # capabilities allow_create = True allow_fetch = True allow_commit = True allow_delete = True allow_list = True _allow_unknown_attrs_in_body = True _query_mapping = resource.QueryParameters( ""sort_key"", ""sort_dir"", 'name', 'project_id' ) # Properties #: The ID of the tap service. id = resource.Body('id') #: The tap service name. name = resource.Body('name') #: The tap service description. description = resource.Body('description') #: The ID of the project that owns the tap service. project_id = resource.Body('project_id', alias='tenant_id') #: Tenant_id (deprecated attribute). tenant_id = resource.Body('tenant_id', deprecated=True) #: The id of the port the tap service is associated with port_id = resource.Body('port_id') #: The status for the tap service. status = resource.Body('status') ",,162,0
openstack%2Fansible-collections-openstack~master~I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5,openstack/ansible-collections-openstack,master,I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5,Refactored inventory script,MERGED,2023-01-26 12:36:50.000000000,2023-01-28 15:35:30.000000000,2023-01-28 15:35:30.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-26 12:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0f017e67e7d4cee1013756e9c0f87b28258b81ee', 'message': 'Refactored inventory script\n\nChange-Id: I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5\n'}, {'number': 2, 'created': '2023-01-27 13:34:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/11d2c6c1078241da4c9ac778220e32070c87422e', 'message': 'Refactored inventory script\n\nChange-Id: I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5\n'}, {'number': 3, 'created': '2023-01-27 17:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7df6df4dfc97c88c00d754a80e0bdeadd8ca02b2', 'message': 'Refactored inventory script\n\nChange-Id: I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5\n'}, {'number': 4, 'created': '2023-01-28 13:17:47.000000000', 'files': ['ci/roles/inventory/tasks/main.yml', 'ci/roles/inventory/templates/openstack.yaml.j2', 'ci/run-collection.yml', 'ci/roles/inventory/files/ansible.cfg', 'plugins/inventory/openstack.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/70c029fa50e6a7dccb0a43f3c11fd2237b239ee6', 'message': 'Refactored inventory script\n\nChange-Id: I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5\n'}]",16,871815,70c029fa50e6a7dccb0a43f3c11fd2237b239ee6,19,4,4,32962,,,0,"Refactored inventory script

Change-Id: I78dbee41071bbfa8040ee13d662c1ba0fbdc10a5
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/15/871815/4 && git format-patch -1 --stdout FETCH_HEAD,['plugins/inventory/openstack.py'],1,0f017e67e7d4cee1013756e9c0f87b28258b81ee,inventory,"DOCUMENTATION = r''' - Gather servers from OpenStack clouds and add them as Ansible hosts to your inventory. - Use YAML configuration file C(openstack.{yaml,yml}) to configure this inventory plugin. - Consumes cloud credentials from standard YAML configuration files C(clouds{,-public}.yaml). options: all_projects: description: - Lists servers from all projects type: bool default: false clouds_yaml_path: description: - Override path to C(clouds.yaml) file. - If this value is given it will be searched first. - Search paths for cloud credentials are complemented with files C(/etc/ansible/openstack.{yaml,yml}). - Default search paths are documented in U(https://docs.openstack.org/os-client-config/latest/user/configuration.html#config-files). type: list elements: str env: - name: OS_CLIENT_CONFIG_FILE compose: description: - Create variables from Jinja2 expressions. type: dict default: {} expand_hostvars: description: - Enrich server facts with additional queries to OpenStack services. This includes requests to Cinder and Neutron which can be time-consuming for clouds with many servers. - Default value of I(expand_hostvars) is opposite of the default value for option C(expand_hostvars) in legacy openstack.py inventory script. type: bool default: false fail_on_errors: description: - Whether the inventory script fails, returning no hosts, when connection to a cloud failed, for example due to bad credentials or connectivity issues. - When I(fail_on_errors) is C(false) this inventory script will return all hosts it could fetch from clouds on a best effort basis. - Default value of I(fail_on_errors) is opposite of the default value for option C(fail_on_errors) in legacy openstack.py inventory script. type: bool default: false groups: description: - Add hosts to group based on Jinja2 conditionals. type: dict default: {} inventory_hostname: description: - What to register as inventory hostname. - When set to C(uuid) the uuid of a server will be used and a group will be created for a server name. - When set to C(name) the name of a server will be used. When multiple servers share the same name, then the servers uuids will be used. - Default value of I(inventory_hostname) is opposite of the default value for option C(use_hostnames) in legacy openstack.py inventory script. type: string choices: ['name', 'uuid'] default: 'name' legacy_groups: description: - Automatically create groups from host variables. type: bool default: true only_clouds: description: - List of clouds in C(clouds.yaml) which will be contacted to use instead of using all clouds. type: list elements: str default: [] plugin: description: - Token which marks a given YAML configuration file as a valid input file for this inventory plugin. required: true choices: ['openstack', 'openstack.cloud.openstack'] private: description: - Use private interfaces of servers, if available, when determining ip addresses for Ansible hosts. - Using I(private) helps when running Ansible from a server in the cloud and one wants to ensure that servers communicate over private networks only. type: bool default: false show_all: description: - Whether all servers should be listed or not. - When I(show_all) is C(false) then only servers with a valid ip address, regardless it is private or public, will be listed. type: bool default: false use_names: description: - Use server name instead of its ip address for C(ansible_host) and C(ansible_ssh_host) facts. - This helps when using jump or bastion hosts and each server name is actually a server's FQDN. type: bool default: false - inventory_cache - constructedEXAMPLES = r''' # Name this file either openstack.yaml or openstack.ymlexpand_hostvars: true fail_on_errors: true all_projects: truetry: import openstack super(InventoryModule, self).parse(inventory, loader, path, cache=cache) if not HAS_SDK: raise AnsibleParserError( 'Could not import Python library openstacksdk') try: ensure_compatibility(openstack.version.__version__) except ImportError as e: raise AnsibleParserError( 'Incompatible openstacksdk library found: {0}'.format(e)) # Redict logging to stderr so it does not mix with output, in # particular JSON output of ansible-inventory. # TODO: Integrate openstack's logging with Ansible's logging. if self.display.verbosity > 3: openstack.enable_logging(debug=True, stream=sys.stderr) else: openstack.enable_logging(stream=sys.stderr) config = self._read_config_data(path) if not config: raise AnsibleParserError( 'Empty OpenStack inventory configuration file found.') if 'plugin' in config and config['plugin'] not in (self.NAME, 'openstack'): raise AnsibleParserError( ""Incompatible OpenStack inventory configuration file found,"" "" plugin is '{0}'."".format(config['plugin'])) if 'plugin' not in config and 'clouds' not in config: raise AnsibleParserError( ""Invalid OpenStack inventory configuration file found,"" "" missing 'plugin' and 'clouds' keys."") # TODO: It it wise to disregard a potential user configuration error? if 'clouds' in config: 'Found clouds config file instead of plugin config.' ' Using default configuration.') config = {} servers = self._fetch_servers(config, path, cache) self._build_inventory(config, servers) def _fetch_servers(self, config, path, cache): cache_key = self._get_cache_prefix(path) user_cache_setting = self.get_option('cache') attempt_to_read_cache = user_cache_setting and cache cache_needs_update = not cache and user_cache_setting servers = None if attempt_to_read_cache: self.display.vvvv('Reading OpenStack inventory cache key {0}' .format(cache_key)) try: servers = self._cache[cache_key] except KeyError: self.display.vvvv(""OpenStack inventory cache not found"") if not attempt_to_read_cache or cache_needs_update: self.display.vvvv('Retrieving servers from Openstack clouds') clouds_yaml_path = config.get('clouds_yaml_path') config_files = ( openstack.config.loader.CONFIG_FILES + ([clouds_yaml_path] if clouds_yaml_path else [])) config = openstack.config.loader.OpenStackConfig( config_files=config_files) only_clouds = config.get('only_clouds', []) if only_clouds: if not isinstance(only_clouds, list): raise AnsibleParserError( 'Option only_clouds in OpenStack inventory' ' configuration is not a list') cloud_regions = [config.get_one(cloud=cloud) for cloud in only_clouds] else: cloud_regions = config.get_all() clouds = [openstack.connection.Connection(config=cloud_region) for cloud_region in cloud_regions] if config.get('private', False): for cloud in self.clouds: cloud.private = True self.display.vvvv( 'Found {0} OpenStack cloud(s)' .format(len(clouds))) self.display.vvvv( 'Using {0} OpenStack cloud(s)' .format(len(clouds))) expand_hostvars = config.get('expand_hostvars', False) all_projects = config.get('all_projects', False) servers = [] def _expand_server(server, volumes): if not expand_hostvars: return server # calling openstacksdk's compute.servers() with # details=True already fetched most facts server['volumes'] = [v for v in volumes if any(a['server_id'] == server['id'] for a in v['attachments'])] return server for cloud in clouds: if expand_hostvars: volumes = [v.to_dict(computed=False) for v in cloud.block_storage.volumes()] else: volumes = [] try: for server in [ # convert to dict before expanding servers # to allow us to attach attributes _expand_server(server.to_dict(computed=False), volumes) for server in cloud.compute.servers( all_projects=all_projects, # details are required because 'addresses' # attribute must be populated details=True) ]: servers.append(server) except openstack.exceptions.OpenStackCloudException as e: self.display.warning( 'Fetching servers for cloud {0} failed with: {1}' .format(cloud.name, str(e))) if config.get('fail_on_errors', False): raise if cache_needs_update: self._cache[cache_key] = servers return servers def _floating_ips(self, server): # aka public ips return dict( (network_name, [address for address in addresses if address['OS-EXT-IPS:type'] == 'floating']) for network_name, addresses in (server['addresses'] or {}).items()) def _fixed_ips(self, server): # aka private ips return dict( (network_name, [address for address in addresses if address['OS-EXT-IPS:type'] == 'fixed']) for network_name, addresses in (server['addresses'] or {}).items()) def _build_inventory(self, config, servers): use_server_name = ( config.get('inventory_hostname', 'name') == 'name') show_all = config.get('show_all', False) for server in servers: use_names = config.get('use_names', False) for name, servers in firstpass.items(): if len(servers) == 1 and use_server_name: self._append_hostvars(hostvars, groups, name, servers[0], use_names=use_names) if len(server_ids) == 1 and use_server_name: self._append_hostvars(hostvars, groups, name, servers[0], use_names=use_names) namegroup=True, use_names=use_names) self._set_variables(config, hostvars, groups) def _set_variables(self, config, hostvars, groups): config.get('compose'), self.inventory.get_host(host).get_vars(), host, strict) config.get('groups'), hostvars[host], host, strict) config.get('keyed_groups'), hostvars[host], host, strict) self.display.vvvv( ""Same name for host %s and group %s"" % (host, gname)) server, namegroup=False, use_names=False): if use_names: hostvars[current_host] = dict( ansible_ssh_host=server['name'], ansible_host=server['name'], openstack=server, ) else: # not use_names for group in self._get_groups_from_server(server, namegroup=namegroup): self.display.vvvv( 'OpenStack inventory configuration file found:' ' {0}'.format(maybe))"," DOCUMENTATION = ''' --- - Get inventory hosts from OpenStack clouds - Uses openstack.(yml|yaml) YAML configuration file to configure the inventory plugin - Uses standard clouds.yaml YAML configuration file to configure cloud credentials options: plugin: description: token that ensures this is a source file for the 'openstack' plugin. required: True choices: ['openstack', 'openstack.cloud.openstack'] show_all: description: toggles showing all vms vs only those with a working IP type: bool default: false inventory_hostname: description: | What to register as the inventory hostname. If set to 'uuid' the uuid of the server will be used and a group will be created for the server name. If set to 'name' the name of the server will be used unless there are more than one server with the same name in which case the 'uuid' logic will be used. Default is to do 'name', which is the opposite of the old openstack.py inventory script's option use_hostnames) type: string choices: - name - uuid default: ""name"" use_names: description: | Use the host's 'name' instead of 'interface_ip' for the 'ansible_host' and 'ansible_ssh_host' facts. This might be desired when using jump or bastion hosts and the name is the FQDN of the host. type: bool default: false expand_hostvars: description: | Run extra commands on each host to fill in additional information about the host. May interrogate cinder and neutron and can be expensive for people with many hosts. (Note, the default value of this is opposite from the default old openstack.py inventory script's option expand_hostvars) type: bool default: false private: description: | Use the private interface of each server, if it has one, as the host's IP in the inventory. This can be useful if you are running ansible inside a server in the cloud and would rather communicate to your servers over the private network. type: bool default: false only_clouds: description: | List of clouds from clouds.yaml to use, instead of using the whole list. type: list elements: str default: [] fail_on_errors: description: | Causes the inventory to fail and return no hosts if one cloud has failed (for example, bad credentials or being offline). When set to False, the inventory will return as many hosts as it can from as many clouds as it can contact. (Note, the default value of this is opposite from the old openstack.py inventory script's option fail_on_errors) type: bool default: false all_projects: description: | Lists servers from all projects type: bool default: false clouds_yaml_path: description: | Override path to clouds.yaml file. If this value is given it will be searched first. The default path for the ansible inventory adds /etc/ansible/openstack.yaml and /etc/ansible/openstack.yml to the regular locations documented at https://docs.openstack.org/os-client-config/latest/user/configuration.html#config-files type: list elements: str env: - name: OS_CLIENT_CONFIG_FILE compose: description: Create vars from jinja2 expressions. type: dictionary default: {} groups: description: Add hosts to group based on Jinja2 conditionals. type: dictionary default: {} legacy_groups: description: Automatically create groups from host variables. type: bool default: true- inventory_cache - constructed EXAMPLES = ''' # file must be named openstack.yaml or openstack.yml # Make the plugin behave like the default behavior of the old scriptexpand_hostvars: yes fail_on_errors: yes all_projects: yesimport loggingdisplay = Display() os_logger = logging.getLogger(""openstack"") try: # Due to the name shadowing we should import other way import importlib sdk = importlib.import_module('openstack') sdk_inventory = importlib.import_module('openstack.cloud.inventory') client_config = importlib.import_module('openstack.config.loader') sdk_exceptions = importlib.import_module(""openstack.exceptions"") display.vvvv(""Couldn't import Openstack SDK modules"") ''' Host inventory provider for ansible using OpenStack clouds. ''' super(InventoryModule, self).parse(inventory, loader, path) cache_key = self._get_cache_prefix(path) # file is config file self._config_data = self._read_config_data(path) msg = '' if not self._config_data: msg = 'File empty. this is not my config file' elif 'plugin' in self._config_data and self._config_data['plugin'] not in (self.NAME, 'openstack'): msg = 'plugin config file, but not for us: %s' % self._config_data['plugin'] elif 'plugin' not in self._config_data and 'clouds' not in self._config_data: msg = ""it's not a plugin configuration nor a clouds.yaml file"" elif not HAS_SDK: msg = ""openstacksdk is required for the OpenStack inventory plugin. OpenStack inventory sources will be skipped."" if not msg: try: ensure_compatibility(sdk.version.__version__) except ImportError as e: msg = (""Incompatible openstacksdk library found: {error}."" .format(error=str(e))) if msg: display.vvvv(msg) raise AnsibleParserError(msg) if 'clouds' in self._config_data: ""Found clouds config file instead of plugin config. "" ""Using default configuration."" ) self._config_data = {} # update cache if the user has caching enabled and the cache is being refreshed # will update variable below in the case of an expired cache cache_needs_update = not cache and self.get_option('cache') if cache: cache = self.get_option('cache') source_data = None if cache: self.display.vvvv(""Reading inventory data from cache: %s"" % cache_key) try: source_data = self._cache[cache_key] except KeyError: # cache expired or doesn't exist yet display.vvvv(""Inventory data cache not found"") if not source_data: self.display.vvvv(""Getting hosts from Openstack clouds"") clouds_yaml_path = self._config_data.get('clouds_yaml_path') if clouds_yaml_path: config_files = ( clouds_yaml_path + client_config.CONFIG_FILES ) else: config_files = None # Redict logging to stderr so it does not mix with output # particular ansible-inventory JSON output # TODO(mordred) Integrate openstack's logging with ansible's logging if self.display.verbosity > 3: sdk.enable_logging(debug=True, stream=sys.stderr) else: sdk.enable_logging(stream=sys.stderr) cloud_inventory = sdk_inventory.OpenStackInventory( config_files=config_files, private=self._config_data.get('private', False)) self.display.vvvv(""Found %d cloud(s) in Openstack"" % len(cloud_inventory.clouds)) only_clouds = self._config_data.get('only_clouds', []) if only_clouds and not isinstance(only_clouds, list): raise ValueError( 'OpenStack Inventory Config Error: only_clouds must be' ' a list') if only_clouds: new_clouds = [] for cloud in cloud_inventory.clouds: self.display.vvvv(""Looking at cloud : %s"" % cloud.name) if cloud.name in only_clouds: self.display.vvvv(""Selecting cloud : %s"" % cloud.name) new_clouds.append(cloud) cloud_inventory.clouds = new_clouds self.display.vvvv(""Selected %d cloud(s)"" % len(cloud_inventory.clouds)) expand_hostvars = self._config_data.get('expand_hostvars', False) fail_on_errors = self._config_data.get('fail_on_errors', False) all_projects = self._config_data.get('all_projects', False) self.use_names = self._config_data.get('use_names', False) source_data = [] try: source_data = cloud_inventory.list_hosts( expand=expand_hostvars, fail_on_cloud_config=fail_on_errors, all_projects=all_projects) except Exception as e: self.display.warning(""Couldn't list Openstack hosts. "" ""See logs for details"") os_logger.error(e.message) finally: if cache_needs_update: self._cache[cache_key] = source_data self._populate_from_source(source_data) def _populate_from_source(self, source_data): use_server_id = ( self._config_data.get('inventory_hostname', 'name') != 'name') show_all = self._config_data.get('show_all', False) for server in source_data: for name, servers in firstpass.items(): if len(servers) == 1 and not use_server_id: self._append_hostvars(hostvars, groups, name, servers[0]) if len(server_ids) == 1 and not use_server_id: self._append_hostvars(hostvars, groups, name, servers[0]) namegroup=True) self._set_variables(hostvars, groups) def _set_variables(self, hostvars, groups): self._config_data.get('compose'), self.inventory.get_host(host).get_vars(), host, strict) self._config_data.get('groups'), hostvars[host], host, strict) self._config_data.get('keyed_groups'), hostvars[host], host, strict) display.vvvv(""Same name for host %s and group %s"" % (host, gname)) server, namegroup=False): if not self.use_names: if self.use_names: hostvars[current_host] = dict( ansible_ssh_host=server['name'], ansible_host=server['name'], openstack=server, ) for group in self._get_groups_from_server(server, namegroup=namegroup): self.display.vvvv(""Valid plugin config file found"")",294,238
openstack%2Frpm-packaging~master~Id919a84397187f5dc010deaa2edda54ac8045992,openstack/rpm-packaging,master,Id919a84397187f5dc010deaa2edda54ac8045992,[antelope] oslo.config 9.1.0,MERGED,2023-01-05 13:29:07.000000000,2023-01-28 13:37:18.000000000,2023-01-28 13:37:18.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-05 13:29:07.000000000', 'files': ['openstack/oslo.config/oslo.config.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/495e226f3e826b46717e48dc0666b8887b7245ce', 'message': '[antelope] oslo.config 9.1.0\n\nChange-Id: Id919a84397187f5dc010deaa2edda54ac8045992\n'}]",0,869367,495e226f3e826b46717e48dc0666b8887b7245ce,8,4,1,28522,,,0,"[antelope] oslo.config 9.1.0

Change-Id: Id919a84397187f5dc010deaa2edda54ac8045992
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/67/869367/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.config/oslo.config.spec.j2'],1,495e226f3e826b46717e48dc0666b8887b7245ce,antelope,{% set upstream_version = upstream_version('9.1.0') %},{% set upstream_version = upstream_version('9.0.0') %},1,1
openstack%2Frpm-packaging~master~Id85fc8a78588bc0e17d3d6891fec8830c608ede6,openstack/rpm-packaging,master,Id85fc8a78588bc0e17d3d6891fec8830c608ede6,[antelope] oslo.messaging 14.1.0,MERGED,2023-01-05 13:25:21.000000000,2023-01-28 13:37:16.000000000,2023-01-28 13:37:16.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-05 13:25:21.000000000', 'files': ['openstack/oslo.messaging/oslo.messaging.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/7138fba38d20ea97b6e18d94d9011a62ed65f78a', 'message': '[antelope] oslo.messaging 14.1.0\n\nChange-Id: Id85fc8a78588bc0e17d3d6891fec8830c608ede6\n'}]",0,869363,7138fba38d20ea97b6e18d94d9011a62ed65f78a,8,4,1,28522,,,0,"[antelope] oslo.messaging 14.1.0

Change-Id: Id85fc8a78588bc0e17d3d6891fec8830c608ede6
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/63/869363/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/oslo.messaging/oslo.messaging.spec.j2'],1,7138fba38d20ea97b6e18d94d9011a62ed65f78a,antelope,{% set upstream_version = upstream_version('14.1.0') %},{% set upstream_version = upstream_version('14.0.0') %},1,1
openstack%2Frpm-packaging~master~Ie741ddbfc9d52f7b0c1f036dc198ed8a5809efaa,openstack/rpm-packaging,master,Ie741ddbfc9d52f7b0c1f036dc198ed8a5809efaa,[antelope] python-neutronclient 8.2.1,MERGED,2023-01-05 13:30:58.000000000,2023-01-28 13:37:14.000000000,2023-01-28 13:37:14.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-05 13:30:58.000000000', 'files': ['openstack/python-neutronclient/python-neutronclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/36168de67f67cd051f4b4129e3d33af6d1309988', 'message': '[antelope] python-neutronclient 8.2.1\n\nChange-Id: Ie741ddbfc9d52f7b0c1f036dc198ed8a5809efaa\n'}]",0,869368,36168de67f67cd051f4b4129e3d33af6d1309988,8,4,1,28522,,,0,"[antelope] python-neutronclient 8.2.1

Change-Id: Ie741ddbfc9d52f7b0c1f036dc198ed8a5809efaa
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/68/869368/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-neutronclient/python-neutronclient.spec.j2'],1,36168de67f67cd051f4b4129e3d33af6d1309988,antelope,{% set upstream_version = upstream_version('8.2.1') %},{% set upstream_version = upstream_version('8.2.0') %},1,1
openstack%2Frpm-packaging~master~If4b30b3d59d14cae7c6f6df16a053fff52251116,openstack/rpm-packaging,master,If4b30b3d59d14cae7c6f6df16a053fff52251116,[antelope] os-ken 2.6.0,MERGED,2023-01-05 13:31:52.000000000,2023-01-28 13:37:12.000000000,2023-01-28 13:37:12.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-05 13:31:52.000000000', 'files': ['openstack/os-ken/os-ken.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/87ab886e264aa596547e8db5806efa93456b820f', 'message': '[antelope] os-ken 2.6.0\n\nChange-Id: If4b30b3d59d14cae7c6f6df16a053fff52251116\n'}]",0,869369,87ab886e264aa596547e8db5806efa93456b820f,8,4,1,28522,,,0,"[antelope] os-ken 2.6.0

Change-Id: If4b30b3d59d14cae7c6f6df16a053fff52251116
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/69/869369/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-ken/os-ken.spec.j2'],1,87ab886e264aa596547e8db5806efa93456b820f,antelope,{% set upstream_version = upstream_version('2.6.0') %},{% set upstream_version = upstream_version('2.5.0') %},1,1
openstack%2Frpm-packaging~master~I70c8145e65ea89dc4c59009b9e79092ac34ce05a,openstack/rpm-packaging,master,I70c8145e65ea89dc4c59009b9e79092ac34ce05a,[antelope] kuryr-tempest-plugin 0.14.0,MERGED,2023-01-09 09:31:22.000000000,2023-01-28 13:37:10.000000000,2023-01-28 13:37:10.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-09 09:31:22.000000000', 'files': ['openstack/kuryr-tempest-plugin/kuryr-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c0d3e715ea11cb15075a3b7af42fcb25a2b972b8', 'message': '[antelope] kuryr-tempest-plugin 0.14.0\n\nChange-Id: I70c8145e65ea89dc4c59009b9e79092ac34ce05a\n'}]",0,869543,c0d3e715ea11cb15075a3b7af42fcb25a2b972b8,8,4,1,28522,,,0,"[antelope] kuryr-tempest-plugin 0.14.0

Change-Id: I70c8145e65ea89dc4c59009b9e79092ac34ce05a
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/43/869543/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/kuryr-tempest-plugin/kuryr-tempest-plugin.spec.j2'],1,c0d3e715ea11cb15075a3b7af42fcb25a2b972b8,antelope,{% set upstream_version = upstream_version('0.14.0') %},{% set upstream_version = upstream_version('0.9.0') %},1,1
openstack%2Frpm-packaging~stable%2Fxena~I8b53594e1055aadad28b2d5563826d4ca3eddacd,openstack/rpm-packaging,stable/xena,I8b53594e1055aadad28b2d5563826d4ca3eddacd,[xena] sushy 3.12.6,MERGED,2023-01-19 10:09:44.000000000,2023-01-28 13:35:52.000000000,2023-01-28 13:35:52.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-19 10:09:44.000000000', 'files': ['openstack/sushy/sushy.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1d88c2ef2508788107fbafcd3669dc01e69d6753', 'message': '[xena] sushy 3.12.6\n\nChange-Id: I8b53594e1055aadad28b2d5563826d4ca3eddacd\n'}]",1,871071,1d88c2ef2508788107fbafcd3669dc01e69d6753,9,5,1,28522,,,0,"[xena] sushy 3.12.6

Change-Id: I8b53594e1055aadad28b2d5563826d4ca3eddacd
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/71/871071/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/sushy/sushy.spec.j2'],1,1d88c2ef2508788107fbafcd3669dc01e69d6753,xena,{% set upstream_version = upstream_version('3.12.6') %},{% set upstream_version = upstream_version('3.12.4') %},1,1
openstack%2Frpm-packaging~stable%2Fxena~I3d70fb38a1e8446603995d5dcb1bc66e9ef9ee7b,openstack/rpm-packaging,stable/xena,I3d70fb38a1e8446603995d5dcb1bc66e9ef9ee7b,[xena] os-ken 2.1.1,MERGED,2023-01-19 10:08:40.000000000,2023-01-28 13:35:51.000000000,2023-01-28 13:35:51.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-19 10:08:40.000000000', 'files': ['openstack/os-ken/os-ken.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9a6241ad544acd4ee4e32ecbb3b9ae27bbbb630a', 'message': '[xena] os-ken 2.1.1\n\nChange-Id: I3d70fb38a1e8446603995d5dcb1bc66e9ef9ee7b\n'}]",0,871070,9a6241ad544acd4ee4e32ecbb3b9ae27bbbb630a,8,4,1,28522,,,0,"[xena] os-ken 2.1.1

Change-Id: I3d70fb38a1e8446603995d5dcb1bc66e9ef9ee7b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/70/871070/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/os-ken/os-ken.spec.j2'],1,9a6241ad544acd4ee4e32ecbb3b9ae27bbbb630a,xena,{% set upstream_version = upstream_version('2.1.1') %},{% set upstream_version = upstream_version('2.1.0') %},1,1
openstack%2Frpm-packaging~master~Ic715ec1eb7913428e7657220c944f41c9b6c4cc0,openstack/rpm-packaging,master,Ic715ec1eb7913428e7657220c944f41c9b6c4cc0,[antelope] python-tripleoclient 20.0.0,MERGED,2022-12-13 10:20:08.000000000,2023-01-28 13:35:49.000000000,2023-01-28 13:35:49.000000000,"[{'_account_id': 6593}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-12-13 10:20:08.000000000', 'files': ['openstack/python-tripleoclient/python-tripleoclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0e6acc7f150251c3f8f123acceb4a7ff6818747b', 'message': '[antelope] python-tripleoclient 20.0.0\n\nChange-Id: Ic715ec1eb7913428e7657220c944f41c9b6c4cc0\n'}]",0,867326,0e6acc7f150251c3f8f123acceb4a7ff6818747b,7,3,1,28522,,,0,"[antelope] python-tripleoclient 20.0.0

Change-Id: Ic715ec1eb7913428e7657220c944f41c9b6c4cc0
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/26/867326/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-tripleoclient/python-tripleoclient.spec.j2'],1,0e6acc7f150251c3f8f123acceb4a7ff6818747b,antelope,{% set upstream_version = upstream_version('20.0.0') %},{% set upstream_version = upstream_version('16.4.0') %},1,1
openstack%2Frpm-packaging~stable%2Fxena~I683a18c21956bf117041cc01721c34bfd06aef41,openstack/rpm-packaging,stable/xena,I683a18c21956bf117041cc01721c34bfd06aef41,[xena] neutron-lib 2.15.3,MERGED,2023-01-19 10:06:35.000000000,2023-01-28 13:33:18.000000000,2023-01-28 13:33:18.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-19 10:06:35.000000000', 'files': ['openstack/neutron-lib/neutron-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/5a40417cea1fb5841071c0170b6407b3f1234809', 'message': '[xena] neutron-lib 2.15.3\n\nDowngrading the version number as the official version for xena is the\nversion 2.15.3\n\nhttps://review.opendev.org/c/openstack/releases/+/870617\nhttps://review.opendev.org/c/openstack/requirements/+/870927\n\nChange-Id: I683a18c21956bf117041cc01721c34bfd06aef41\n'}]",0,871068,5a40417cea1fb5841071c0170b6407b3f1234809,9,4,1,28522,,,0,"[xena] neutron-lib 2.15.3

Downgrading the version number as the official version for xena is the
version 2.15.3

https://review.opendev.org/c/openstack/releases/+/870617
https://review.opendev.org/c/openstack/requirements/+/870927

Change-Id: I683a18c21956bf117041cc01721c34bfd06aef41
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/68/871068/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/neutron-lib/neutron-lib.spec.j2'],1,5a40417cea1fb5841071c0170b6407b3f1234809,xena,{% set upstream_version = upstream_version('2.15.3') %},{% set upstream_version = upstream_version('2.20.0') %},1,1
openstack%2Frpm-packaging~master~Ibb5907747c1cdb55d561bd9f89b6035bee252073,openstack/rpm-packaging,master,Ibb5907747c1cdb55d561bd9f89b6035bee252073,[antelope] python-zaqarclient 2.5.0,MERGED,2023-01-23 10:16:14.000000000,2023-01-28 13:33:16.000000000,2023-01-28 13:33:16.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-23 10:16:14.000000000', 'files': ['openstack/python-zaqarclient/python-zaqarclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/3878440c45008b8a7bba114587e8cc9a8593cf5c', 'message': '[antelope] python-zaqarclient 2.5.0\n\nChange-Id: Ibb5907747c1cdb55d561bd9f89b6035bee252073\n'}]",0,871457,3878440c45008b8a7bba114587e8cc9a8593cf5c,8,4,1,28522,,,0,"[antelope] python-zaqarclient 2.5.0

Change-Id: Ibb5907747c1cdb55d561bd9f89b6035bee252073
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/57/871457/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-zaqarclient/python-zaqarclient.spec.j2'],1,3878440c45008b8a7bba114587e8cc9a8593cf5c,antelope,{% set upstream_version = upstream_version('2.5.0') %},{% set upstream_version = upstream_version('2.3.0') %},1,1
openstack%2Frpm-packaging~master~Ia4586764af066c9cc5d0341046e077219a4309fb,openstack/rpm-packaging,master,Ia4586764af066c9cc5d0341046e077219a4309fb,[antelope] glance_store 4.2.0,NEW,2023-01-05 13:26:26.000000000,2023-01-28 13:31:15.000000000,,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-05 13:26:26.000000000', 'files': ['openstack/glance_store/glance_store.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/4ee3a01ab470e743d908d10aaed5aad671f0c37d', 'message': '[antelope] glance_store 4.2.0\n\nChange-Id: Ia4586764af066c9cc5d0341046e077219a4309fb\n'}]",1,869364,4ee3a01ab470e743d908d10aaed5aad671f0c37d,5,4,1,28522,,,0,"[antelope] glance_store 4.2.0

Change-Id: Ia4586764af066c9cc5d0341046e077219a4309fb
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/64/869364/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/glance_store/glance_store.spec.j2'],1,4ee3a01ab470e743d908d10aaed5aad671f0c37d,antelope,{% set upstream_version = upstream_version('4.2.0') %},{% set upstream_version = upstream_version('2.4.0') %},1,1
openstack%2Frpm-packaging~master~Iafdd331cead56dfe3a9fff5e64ae75acc8b757a5,openstack/rpm-packaging,master,Iafdd331cead56dfe3a9fff5e64ae75acc8b757a5,[antelope] python-mistralclient 5.0.0,MERGED,2023-01-23 12:31:13.000000000,2023-01-28 13:29:08.000000000,2023-01-28 13:29:08.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-23 12:31:13.000000000', 'files': ['openstack/python-mistralclient/python-mistralclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2d893fb7f16ceea90202856fb226576ed8601564', 'message': '[antelope] python-mistralclient 5.0.0\n\nChange-Id: Iafdd331cead56dfe3a9fff5e64ae75acc8b757a5\n'}]",0,871466,2d893fb7f16ceea90202856fb226576ed8601564,8,4,1,28522,,,0,"[antelope] python-mistralclient 5.0.0

Change-Id: Iafdd331cead56dfe3a9fff5e64ae75acc8b757a5
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/66/871466/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-mistralclient/python-mistralclient.spec.j2'],1,2d893fb7f16ceea90202856fb226576ed8601564,antelope,{% set upstream_version = upstream_version('5.0.0') %},{% set upstream_version = upstream_version('4.4.0') %},1,1
openstack%2Frpm-packaging~master~If0818b6bf9abab69270a5f01b06ceffc907aec55,openstack/rpm-packaging,master,If0818b6bf9abab69270a5f01b06ceffc907aec55,[antelope] mistral-lib 2.8.0,MERGED,2023-01-23 12:32:04.000000000,2023-01-28 13:28:15.000000000,2023-01-28 13:28:15.000000000,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-23 12:32:04.000000000', 'files': ['openstack/mistral-lib/mistral-lib.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/cc4d562cddf4e63fb651624346a8904a7a38da20', 'message': '[antelope] mistral-lib 2.8.0\n\nChange-Id: If0818b6bf9abab69270a5f01b06ceffc907aec55\n'}]",0,871467,cc4d562cddf4e63fb651624346a8904a7a38da20,8,4,1,28522,,,0,"[antelope] mistral-lib 2.8.0

Change-Id: If0818b6bf9abab69270a5f01b06ceffc907aec55
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/67/871467/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/mistral-lib/mistral-lib.spec.j2'],1,cc4d562cddf4e63fb651624346a8904a7a38da20,antelope,{% set upstream_version = upstream_version('2.8.0') %},{% set upstream_version = upstream_version('2.6.0') %},1,1
openstack%2Frpm-packaging~stable%2Fxena~Ic83405e9e7f215b96aa9e9b92132ebfdbe6ec9fe,openstack/rpm-packaging,stable/xena,Ic83405e9e7f215b96aa9e9b92132ebfdbe6ec9fe,[xena] sushy 4.8.2,NEW,2023-01-19 10:10:57.000000000,2023-01-28 13:28:10.000000000,,"[{'_account_id': 6593}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-19 10:10:57.000000000', 'files': ['openstack/python-ironicclient/python-ironicclient.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1f7ad92e3d95412d574a3355617804948154b62c', 'message': '[xena] sushy 4.8.2\n\nChange-Id: Ic83405e9e7f215b96aa9e9b92132ebfdbe6ec9fe\n'}]",2,871073,1f7ad92e3d95412d574a3355617804948154b62c,6,5,1,28522,,,0,"[xena] sushy 4.8.2

Change-Id: Ic83405e9e7f215b96aa9e9b92132ebfdbe6ec9fe
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/73/871073/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/python-ironicclient/python-ironicclient.spec.j2'],1,1f7ad92e3d95412d574a3355617804948154b62c,xena,{% set upstream_version = upstream_version('4.8.2') %},{% set upstream_version = upstream_version('4.8.1') %},1,1
openstack%2Fopenstacksdk~master~Id6927a7f1e213634a2845b6ac0708c13759a19dc,openstack/openstacksdk,master,Id6927a7f1e213634a2845b6ac0708c13759a19dc,image: Prevent passing conflicts args to stage_image,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:27:49.000000000,2023-01-28 13:26:01.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c6d6aa55840d1dfb297601ca11061a344fad59fd', 'message': 'image: Prevent passing conflicts args to stage_image\n\nChange-Id: Id6927a7f1e213634a2845b6ac0708c13759a19dc\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8a8189ad947940b3f8e691781af0467692f7a3c8', 'message': 'image: Prevent passing conflicts args to stage_image\n\nChange-Id: Id6927a7f1e213634a2845b6ac0708c13759a19dc\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,867045,8a8189ad947940b3f8e691781af0467692f7a3c8,9,2,2,15334,,,0,"image: Prevent passing conflicts args to stage_image

Change-Id: Id6927a7f1e213634a2845b6ac0708c13759a19dc
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/45/867045/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py']",2,c6d6aa55840d1dfb297601ca11061a344fad59fd,glance-gaps, if filename and data: raise exceptions.SDKException( 'filename and data are mutually exclusive' ) if filename and data: raise exceptions.SDKException( 'filename and data are mutually exclusive' ) # use of any of these imply use_import=True if stores or all_stores or all_stores_must_succeed: use_import = True , if data and filename: raise exceptions.SDKException( 'Passing filename and data simultaneously is not supported' ) if stores or all_stores or all_stores_must_succeed: use_import = True,41,12
openstack%2Fopenstacksdk~master~I3b09deddbc3914d3bd43888465fe6948f88a36ff,openstack/openstacksdk,master,I3b09deddbc3914d3bd43888465fe6948f88a36ff,image: Remove unnecessary abstractions,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:27:00.000000000,2023-01-28 13:25:52.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/cbc4e6b67e66ce1f694e40101f42372926e7a2e9', 'message': 'image: Remove unnecessary abstractions\n\nChange-Id: I3b09deddbc3914d3bd43888465fe6948f88a36ff\n'}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d99fc11214f732bafdc07a9800fabfd5d1624ff3', 'message': 'image: Remove unnecessary abstractions\n\nChange-Id: I3b09deddbc3914d3bd43888465fe6948f88a36ff\n'}]",0,867042,d99fc11214f732bafdc07a9800fabfd5d1624ff3,11,3,2,15334,,,0,"image: Remove unnecessary abstractions

Change-Id: I3b09deddbc3914d3bd43888465fe6948f88a36ff
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/42/867042/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py']",3,cbc4e6b67e66ce1f694e40101f42372926e7a2e9,glance-gaps," image = self._create(_image.Image, **image_kwargs) self, container_format=None, disk_format=None, data=None, **attrs, self, image, stream=False, output=None, chunk_size=1024, def update_image_properties( self, image=None, meta=None, **kwargs, ): """"""Update the properties of an existing image :param image: The value can be the ID of a image or a :class:`~openstack.image.v2.image.Image` instance. :param meta: A dict of key/value pairs to use for metadata that bypasses automatic type conversion. Additional kwargs will be passed to the image creation as additional metadata for the image and will have all values converted to string except for min_disk, min_ram, size and virtual_size which will be converted to int. """""" image = self._get_resource(_image.Image, image) if not meta: meta = {} properties = {} for k, v in iter(kwargs.items()): if v and k in ['ramdisk', 'kernel']: v = self._connection.get_image_id(v) k = '{0}_id'.format(k) properties[k] = v "," image = self._create_image(**image_kwargs) def _create_image(self, **kwargs): """"""Create image resource from attributes"""""" return self._create(_image.Image, **kwargs) self, container_format=None, disk_format=None, data=None, **attrs self, image, stream=False, output=None, chunk_size=1024 def _update_image_properties(self, image, meta, properties): if not isinstance(image, _image.Image): # If we come here with a dict (cloud) - convert dict to real object # to properly consume all properties (to calculate the diff). # This currently happens from unittests. image = _image.Image.existing(**image) def update_image_properties( self, image=None, meta=None, **kwargs, ): """""" Update the properties of an existing image. :param image: Name or id of an image or an Image object. :param meta: A dict of key/value pairs to use for metadata that bypasses automatic type conversion. Additional kwargs will be passed to the image creation as additional metadata for the image and will have all values converted to string except for min_disk, min_ram, size and virtual_size which will be converted to int. """""" if isinstance(image, str): image = self._connection.get_image(image) if not meta: meta = {} img_props = {} for k, v in iter(kwargs.items()): if v and k in ['ramdisk', 'kernel']: v = self._connection.get_image_id(v) k = '{0}_id'.format(k) img_props[k] = v return self._update_image_properties(image, meta, img_props) ",66,70
openstack%2Fopenstacksdk~master~I65da2e6795d7fd417dd2ab46c272b36e4ae83b69,openstack/openstacksdk,master,I65da2e6795d7fd417dd2ab46c272b36e4ae83b69,image: Remove unsupported parameters from v1 proxy,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:25:58.000000000,2023-01-28 13:25:58.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/99b41c8733524759822f95f5571acae18ace1403', 'message': ""image: Remove unsupported parameters from v1 proxy\n\nThere was an idea to provide the exact same method signature for\n'create_image' in the v1 and v2 Image proxy APIs. This was a bad idea as\nit limits how the v2 version of this method can evolve. Stop doing it.\nOr rather, try. In reality, nothing really changes and all we're doing\nis removing the documentation for these unsupported options and\nreworking the exception logic.\n\nThe docstring for the 'create_image' function is reworked.\n\nChange-Id: I65da2e6795d7fd417dd2ab46c272b36e4ae83b69\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/image/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6baa435a0409d4d6b5b00303f2308cd4412f46ad', 'message': ""image: Remove unsupported parameters from v1 proxy\n\nThere was an idea to provide the exact same method signature for\n'create_image' in the v1 and v2 Image proxy APIs. This was a bad idea as\nit limits how the v2 version of this method can evolve. Stop doing it.\nOr rather, try. In reality, nothing really changes and all we're doing\nis removing the documentation for these unsupported options and\nreworking the exception logic.\n\nThe docstring for the 'create_image' function is reworked.\n\nChange-Id: I65da2e6795d7fd417dd2ab46c272b36e4ae83b69\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,867044,6baa435a0409d4d6b5b00303f2308cd4412f46ad,8,2,2,15334,,,0,"image: Remove unsupported parameters from v1 proxy

There was an idea to provide the exact same method signature for
'create_image' in the v1 and v2 Image proxy APIs. This was a bad idea as
it limits how the v2 version of this method can evolve. Stop doing it.
Or rather, try. In reality, nothing really changes and all we're doing
is removing the documentation for these unsupported options and
reworking the exception logic.

The docstring for the 'create_image' function is reworked.

Change-Id: I65da2e6795d7fd417dd2ab46c272b36e4ae83b69
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/44/867044/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/image/v1/_proxy.py'],1,99b41c8733524759822f95f5571acae18ace1403,glance-gaps," """"""Create an image and optionally upload data. Create a new image. If ``filename`` or ``data`` are provided, it will also upload data to this image. :param str name: Name of the image to create. If it is a path name :returns: The results of image creation :rtype: :class:`~openstack.image.v1.image.Image` # these were previously provided for API (method) compatibility; that # was a bad idea if ( 'use_import' in kwargs or 'stores' in kwargs or 'all_stores' in kwargs or 'all_stores_must_succeed' in kwargs ): raise exceptions.InvalidRequest( ""Glance v1 does not support stores or image import"" ) # silently ignore these; they were never supported and were only given # for API (method) compatibility kwargs.pop('wait') kwargs.pop('timeout') image = self._create(_image.Image, name=name, **kwargs)"," wait=False, timeout=3600, use_import=False, stores=None, all_stores=None, all_stores_must_succeed=None, """"""Upload an image. :param str name: Name of the image to create. If it is a pathname :param bool wait: If true, waits for image to be created. Defaults to true - however, be aware that one of the upload methods is always synchronous. :param timeout: Seconds to wait for image creation. None is forever. :param bool use_import: Use the interoperable image import mechanism to import the image. This defaults to false because it is harder on the target cloud so should only be used when needed, such as when the user needs the cloud to transform image format. If the cloud has disabled direct uploads, this will default to true. :param stores: List of stores to be used when enabled_backends is activated in glance. List values can be the id of a store or a :class:`~openstack.image.v2.service_info.Store` instance. Implies ``use_import`` equals ``True``. :param all_stores: Upload to all available stores. Mutually exclusive with ``store`` and ``stores``. Implies ``use_import`` equals ``True``. :param all_stores_must_succeed: When set to True, if an error occurs during the upload in at least one store, the worfklow fails, the data is deleted from stores where copying is done (not staging), and the state of the image is unchanged. When set to False, the workflow will fail (data deleted from stores, ) only if the import fails on all stores specified by the user. In case of a partial success, the locations added to the image will be the stores where the data has been correctly uploaded. Default is True. Implies ``use_import`` equals ``True``. :returns: A ``munch.Munch`` of the Image object wait=wait, timeout=timeout, use_import=use_import, stores=stores, all_stores=stores, all_stores_must_succeed=stores, image_kwargs['name'] = name image = self._create(_image.Image, **kwargs) wait, timeout, use_import=False, stores=None, all_stores=None, all_stores_must_succeed=None, if use_import: raise exceptions.InvalidRequest( ""Glance v1 does not support image import"" ) if stores or all_stores or all_stores_must_succeed: raise exceptions.InvalidRequest( ""Glance v1 does not support stores"" ) # NOTE(mordred) wait and timeout parameters are unused, but # are present for ease at calling site.",25,62
openstack%2Fopenstacksdk~master~If38f900a8386833559474270154b913bbc9a5e87,openstack/openstacksdk,master,If38f900a8386833559474270154b913bbc9a5e87,image: Modify signatures of various image methods,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:25:55.000000000,2023-01-28 13:25:55.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6a80d37efa8dd477186da13f96656db1821153f4', 'message': 'image: Modify signatures of various image methods\n\nWe also update the docstrings to clarify some methods.\n\nChange-Id: If38f900a8386833559474270154b913bbc9a5e87\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e2e5042d383b0a95dbea3d7072c8f935958f2fa4', 'message': 'image: Modify signatures of various image methods\n\nWe also update the docstrings to clarify some methods.\n\nChange-Id: If38f900a8386833559474270154b913bbc9a5e87\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",0,867043,e2e5042d383b0a95dbea3d7072c8f935958f2fa4,8,2,2,15334,,,0,"image: Modify signatures of various image methods

We also update the docstrings to clarify some methods.

Change-Id: If38f900a8386833559474270154b913bbc9a5e87
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/43/867043/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/unit/image/v2/test_proxy.py', 'openstack/image/v2/_proxy.py']",2,6a80d37efa8dd477186da13f96656db1821153f4,glance-gaps," *, data=None, tags=None, """"""Create an image and optionally upload data Create a new image. If ``filename`` or ``data`` are provided, it will also upload data to this image. Note that uploading image data is actually quite a complicated procedure. There are three ways to upload an image: * Image upload * Image import * Image tasks If the image tasks API is enabled, this must be used. However, this API is deprecated since the Image service's Mitaka (12.0.0) release and is now admin-only. Assuming this API is not enabled, you may choose between image upload or image import. Image import is more powerful and allows you to upload data from multiple sources including other glance instances. It should be preferred on all services that support it. :param bool use_import: Use the 'glance-direct' method of the interoperable image import mechanism to import the image. This defaults to false because it is harder on the target cloud so should only be used when needed, such as when the user needs the cloud to transform image format. If the cloud has disabled direct uploads, this will default to true. If you wish to use other import methods, use the ``import_image`` method instead. :returns: The results of image creation :rtype: :class:`~openstack.image.v2.image.Image` def stage_image(self, image, *, filename=None, data=None): *, *,"," data=None, tags=None, """"""Upload an image. :param bool use_import: Use the interoperable image import mechanism to import the image. This defaults to false because it is harder on the target cloud so should only be used when needed, such as when the user needs the cloud to transform image format. If the cloud has disabled direct uploads, this will default to true. :returns: A ``munch.Munch`` of the Image object def stage_image(self, image, filename=None, data=None):",34,11
openstack%2Fmasakari~master~I334af06ef526bf11dfe5030e8cba210b98f1ceea,openstack/masakari,master,I334af06ef526bf11dfe5030e8cba210b98f1ceea,vm moves for host notification,MERGED,2022-12-26 14:48:43.000000000,2023-01-28 13:20:41.000000000,2023-01-28 13:19:42.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2022-12-26 14:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/4a7d18e97e1048225a344492a9e406ea42478d70', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}, {'number': 2, 'created': '2022-12-27 00:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/01094b4346e63444e0395e931dfd4bf1c3b5a2fd', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}, {'number': 3, 'created': '2023-01-11 08:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/aba6025c72694bd14bc4c4257f5fb9f4d7f9aa9d', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}, {'number': 4, 'created': '2023-01-18 08:30:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/d4228c585347dae7463a2da8a792dcec1c43afd9', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}, {'number': 5, 'created': '2023-01-28 02:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari/commit/70ef7557be85b2356e3f66b486a4f20b383166b8', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}, {'number': 6, 'created': '2023-01-28 11:01:25.000000000', 'files': ['masakari/tests/unit/fakes.py', 'masakari/tests/unit/objects/test_objects.py', 'masakari/policies/vmoves.py', 'masakari/tests/unit/objects/test_vmoves.py', 'masakari/tests/unit/db/test_migrations.py', 'masakari/exception.py', 'masakari/policies/__init__.py', 'masakari/tests/unit/api/openstack/ha/test_vmoves.py', 'masakari/engine/drivers/taskflow/host_failure.py', 'masakari/objects/__init__.py', 'masakari/api/openstack/ha/vmoves.py', 'masakari/ha/api.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py', 'masakari/db/sqlalchemy/api.py', 'masakari/db/api.py', 'masakari/objects/fields.py', 'masakari/tests/unit/ha/test_api.py', 'masakari/db/sqlalchemy/migrate_repo/versions/008_add_vm_moves_table.py', 'masakari/objects/vmove.py', 'masakari/tests/unit/db/test_db_api.py', 'masakari/db/sqlalchemy/models.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/masakari/commit/23c6c31409b9d27a6a528954cc9fd5df28a12d97', 'message': ""vm moves for host notification\n\nThis feature is mainly to persist vm moves information of one host\nnotification into the database. It also provides a new 'VMove' api,\nwhich could help users to insight the process or result of the host\nrecovery workflow, such as which vms evacuated succeed or failed, and\nwhich ones are still evacuating.\n\nImplements: BP vm-evacuations-for-host-recovery\nChange-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea\n""}]",37,868602,23c6c31409b9d27a6a528954cc9fd5df28a12d97,28,2,6,30623,,,0,"vm moves for host notification

This feature is mainly to persist vm moves information of one host
notification into the database. It also provides a new 'VMove' api,
which could help users to insight the process or result of the host
recovery workflow, such as which vms evacuated succeed or failed, and
which ones are still evacuating.

Implements: BP vm-evacuations-for-host-recovery
Change-Id: I334af06ef526bf11dfe5030e8cba210b98f1ceea
",git fetch https://review.opendev.org/openstack/masakari refs/changes/02/868602/1 && git format-patch -1 --stdout FETCH_HEAD,"['masakari/tests/unit/fakes.py', 'masakari/tests/unit/objects/test_objects.py', 'masakari/policies/vmoves.py', 'masakari/tests/unit/objects/test_vmoves.py', 'masakari/tests/unit/db/test_migrations.py', 'masakari/exception.py', 'masakari/policies/__init__.py', 'masakari/tests/unit/api/openstack/ha/test_vmoves.py', 'masakari/engine/drivers/taskflow/host_failure.py', 'masakari/objects/__init__.py', 'masakari/api/openstack/ha/vmoves.py', 'masakari/ha/api.py', 'masakari/tests/unit/engine/drivers/taskflow/test_host_failure_flow.py', 'masakari/db/sqlalchemy/api.py', 'masakari/db/api.py', 'masakari/objects/fields.py', 'masakari/tests/unit/ha/test_api.py', 'masakari/db/sqlalchemy/migrate_repo/versions/008_add_vm_moves_table.py', 'masakari/objects/vmove.py', 'masakari/tests/unit/db/test_db_api.py', 'masakari/db/sqlalchemy/models.py', 'setup.cfg']",22,4a7d18e97e1048225a344492a9e406ea42478d70,BP/vm-evacuations-for-host-recovery, vmoves = masakari.api.openstack.ha.vmoves:VMoves,,1387,144
openstack%2Fopenstacksdk~master~Ic20dc90be983c03a3166debeabe4af4587341723,openstack/openstacksdk,master,Ic20dc90be983c03a3166debeabe4af4587341723,image: Remove _base_proxy module,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:19:37.000000000,2023-01-28 13:17:43.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4511d7b06ed79a60acdcaa6c49f1a8ae366b6f90', 'message': ""image: Remove _base_proxy module\n\nThese have diverged so significantly that there isn't really any benefit\nin keeping them together any longer.\n\nThis change is purely code motion: a future change will remove the now\nunnecessary abstractions.\n\nChange-Id: Ic20dc90be983c03a3166debeabe4af4587341723\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/image/_base_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6462005c7b9678ec3e960a34ec44cbe5ab91394c', 'message': ""image: Remove _base_proxy module\n\nThese have diverged so significantly that there isn't really any benefit\nin keeping them together any longer.\n\nThis change is purely code motion: a future change will remove the now\nunnecessary abstractions.\n\nChange-Id: Ic20dc90be983c03a3166debeabe4af4587341723\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,867041,6462005c7b9678ec3e960a34ec44cbe5ab91394c,10,2,2,15334,,,0,"image: Remove _base_proxy module

These have diverged so significantly that there isn't really any benefit
in keeping them together any longer.

This change is purely code motion: a future change will remove the now
unnecessary abstractions.

Change-Id: Ic20dc90be983c03a3166debeabe4af4587341723
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/41/867041/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/image/_base_proxy.py', 'openstack/image/v2/_proxy.py']",3,4511d7b06ed79a60acdcaa6c49f1a8ae366b6f90,glance-gaps,"import osfrom openstack import proxydef _get_name_and_filename(name, image_format): # See if name points to an existing file if os.path.exists(name): # Neat. Easy enough return os.path.splitext(os.path.basename(name))[0], name # Try appending the disk format name_with_ext = '.'.join((name, image_format)) if os.path.exists(name_with_ext): return os.path.basename(name), name_with_ext return name, None class Proxy(proxy.Proxy): retriable_status_codes = [503] _IMAGE_MD5_KEY = 'owner_specified.openstack.md5' _IMAGE_SHA256_KEY = 'owner_specified.openstack.sha256' _IMAGE_OBJECT_KEY = 'owner_specified.openstack.object' # NOTE(shade) shade keys were owner_specified.shade.md5 - we need to add # those to freshness checks so that a shade->sdk transition # doesn't result in a re-upload _SHADE_IMAGE_MD5_KEY = 'owner_specified.shade.md5' _SHADE_IMAGE_SHA256_KEY = 'owner_specified.shade.sha256' _SHADE_IMAGE_OBJECT_KEY = 'owner_specified.shade.object' def create_image( self, name, filename=None, container=None, md5=None, sha256=None, disk_format=None, container_format=None, disable_vendor_agent=True, allow_duplicates=False, meta=None, wait=False, timeout=3600, data=None, validate_checksum=False, use_import=False, stores=None, tags=None, all_stores=None, all_stores_must_succeed=None, **kwargs, ): """"""Upload an image. :param str name: Name of the image to create. If it is a pathname of an image, the name will be constructed from the extensionless basename of the path. :param str filename: The path to the file to upload, if needed. (optional, defaults to None) :param data: Image data (string or file-like object). It is mutually exclusive with filename :param str container: Name of the container in swift where images should be uploaded for import if the cloud requires such a thing. (optional, defaults to 'images') :param str md5: md5 sum of the image file. If not given, an md5 will be calculated. :param str sha256: sha256 sum of the image file. If not given, an md5 will be calculated. :param str disk_format: The disk format the image is in. (optional, defaults to the os-client-config config value for this cloud) :param str container_format: The container format the image is in. (optional, defaults to the os-client-config config value for this cloud) :param list tags: List of tags for this image. Each tag is a string of at most 255 chars. :param bool disable_vendor_agent: Whether or not to append metadata flags to the image to inform the cloud in question to not expect a vendor agent to be runing. (optional, defaults to True) :param allow_duplicates: If true, skips checks that enforce unique image name. (optional, defaults to False) :param meta: A dict of key/value pairs to use for metadata that bypasses automatic type conversion. :param bool wait: If true, waits for image to be created. Defaults to true - however, be aware that one of the upload methods is always synchronous. :param timeout: Seconds to wait for image creation. None is forever. :param bool validate_checksum: If true and cloud returns checksum, compares return value with the one calculated or passed into this call. If value does not match - raises exception. Default is 'false' :param bool use_import: Use the interoperable image import mechanism to import the image. This defaults to false because it is harder on the target cloud so should only be used when needed, such as when the user needs the cloud to transform image format. If the cloud has disabled direct uploads, this will default to true. :param stores: List of stores to be used when enabled_backends is activated in glance. List values can be the id of a store or a :class:`~openstack.image.v2.service_info.Store` instance. Implies ``use_import`` equals ``True``. :param all_stores: Upload to all available stores. Mutually exclusive with ``store`` and ``stores``. Implies ``use_import`` equals ``True``. :param all_stores_must_succeed: When set to True, if an error occurs during the upload in at least one store, the worfklow fails, the data is deleted from stores where copying is done (not staging), and the state of the image is unchanged. When set to False, the workflow will fail (data deleted from stores, ) only if the import fails on all stores specified by the user. In case of a partial success, the locations added to the image will be the stores where the data has been correctly uploaded. Default is True. Implies ``use_import`` equals ``True``. Additional kwargs will be passed to the image creation as additional metadata for the image and will have all values converted to string except for min_disk, min_ram, size and virtual_size which will be converted to int. If you are sure you have all of your data types correct or have an advanced need to be explicit, use meta. If you are just a normal consumer, using kwargs is likely the right choice. If a value is in meta and kwargs, meta wins. :returns: A ``munch.Munch`` of the Image object :raises: SDKException if there are problems uploading """""" if container is None: container = self._connection._OBJECT_AUTOCREATE_CONTAINER if not meta: meta = {} if not disk_format: disk_format = self._connection.config.config['image_format'] if not container_format: # https://docs.openstack.org/image-guide/image-formats.html container_format = 'bare' if data and filename: raise exceptions.SDKException( 'Passing filename and data simultaneously is not supported' ) # If there is no filename, see if name is actually the filename if not filename and not data: name, filename = _get_name_and_filename( name, self._connection.config.config['image_format'], ) if validate_checksum and data and not isinstance(data, bytes): raise exceptions.SDKException( 'Validating checksum is not possible when data is not a ' 'direct binary object' ) if not (md5 or sha256) and validate_checksum: if filename: md5, sha256 = utils._get_file_hashes(filename) elif data and isinstance(data, bytes): md5, sha256 = utils._calculate_data_hashes(data) if allow_duplicates: current_image = None else: current_image = self.find_image(name) if current_image: # NOTE(pas-ha) 'properties' may be absent or be None props = current_image.get('properties') or {} md5_key = props.get( self._IMAGE_MD5_KEY, props.get(self._SHADE_IMAGE_MD5_KEY, ''), ) sha256_key = props.get( self._IMAGE_SHA256_KEY, props.get(self._SHADE_IMAGE_SHA256_KEY, ''), ) up_to_date = utils._hashes_up_to_date( md5=md5, sha256=sha256, md5_key=md5_key, sha256_key=sha256_key, ) if up_to_date: self.log.debug( ""image %(name)s exists and is up to date"", {'name': name}, ) return current_image else: self.log.debug( ""image %(name)s exists, but contains different "" ""checksums. Updating."", {'name': name}, ) if disable_vendor_agent: kwargs.update( self._connection.config.config['disable_vendor_agent'] ) # If a user used the v1 calling format, they will have # passed a dict called properties along properties = kwargs.pop('properties', {}) properties[self._IMAGE_MD5_KEY] = md5 or '' properties[self._IMAGE_SHA256_KEY] = sha256 or '' properties[self._IMAGE_OBJECT_KEY] = '/'.join([container, name]) kwargs.update(properties) image_kwargs = {'properties': kwargs} if disk_format: image_kwargs['disk_format'] = disk_format if container_format: image_kwargs['container_format'] = container_format if tags: image_kwargs['tags'] = tags if filename or data: image = self._upload_image( name, filename=filename, data=data, meta=meta, wait=wait, timeout=timeout, validate_checksum=validate_checksum, use_import=use_import, stores=stores, all_stores=stores, all_stores_must_succeed=stores, **image_kwargs, ) else: image_kwargs['name'] = name image = self._create_image(**image_kwargs) self._connection._get_cache(None).invalidate() return image def _update_image_properties(self, image, meta, properties): if not isinstance(image, _image.Image): # If we come here with a dict (cloud) - convert dict to real object # to properly consume all properties (to calculate the diff). # This currently happens from unittests. image = _image.Image.existing(**image) img_props = image.properties.copy() for k, v in iter(self._make_v2_image_params(meta, properties).items()): if image.get(k, None) != v: img_props[k] = v if not img_props: return False self.update_image(image, **img_props) self._connection.list_images.invalidate(self._connection) return True def update_image_properties( self, image=None, meta=None, **kwargs, ): """""" Update the properties of an existing image. :param image: Name or id of an image or an Image object. :param meta: A dict of key/value pairs to use for metadata that bypasses automatic type conversion. Additional kwargs will be passed to the image creation as additional metadata for the image and will have all values converted to string except for min_disk, min_ram, size and virtual_size which will be converted to int. """""" if isinstance(image, str): image = self._connection.get_image(image) if not meta: meta = {} img_props = {} for k, v in iter(kwargs.items()): if v and k in ['ramdisk', 'kernel']: v = self._connection.get_image_id(v) k = '{0}_id'.format(k) img_props[k] = v return self._update_image_properties(image, meta, img_props) ","from openstack.image import _base_proxyclass Proxy(_base_proxy.BaseImageProxy): def _update_image_properties(self, image, meta, properties): if not isinstance(image, _image.Image): # If we come here with a dict (cloud) - convert dict to real object # to properly consume all properties (to calculate the diff). # This currently happens from unittests. image = _image.Image.existing(**image) img_props = image.properties.copy() for k, v in iter(self._make_v2_image_params(meta, properties).items()): if image.get(k, None) != v: img_props[k] = v if not img_props: return False self.update_image(image, **img_props) self._connection.list_images.invalidate(self._connection) return True ",590,356
openstack%2Fansible-collections-openstack~master~I6ec79eb203d0f68661b54bc89a194c366b3574c6,openstack/ansible-collections-openstack,master,I6ec79eb203d0f68661b54bc89a194c366b3574c6,"Refactored {group,role}_assignment modules",MERGED,2023-01-16 20:10:12.000000000,2023-01-28 13:19:29.000000000,2023-01-28 13:19:29.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-16 20:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3ffbd386c401c347e9bcfada8077f037c851304e', 'message': 'Refactored {group,role}_assignment modules\n\nChange-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6\n'}, {'number': 2, 'created': '2023-01-16 20:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5ff19a59268165b712c4d49bca377dc318fa044f', 'message': 'Refactored {group,role}_assignment modules\n\nChange-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6\n'}, {'number': 3, 'created': '2023-01-17 16:39:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d3f3935b75133f54f2b26f46471a48bf8a575f77', 'message': 'Refactored {group,role}_assignment modules\n\nChange-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6\n'}, {'number': 4, 'created': '2023-01-19 19:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bd16529850b0e348921d7478d6693bcd2aed6750', 'message': 'Refactored {group,role}_assignment modules\n\nChange-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6\n'}, {'number': 5, 'created': '2023-01-26 12:36:36.000000000', 'files': ['ci/roles/user_group/tasks/main.yml', 'ci/roles/user_role/tasks/main.yaml', 'ci/roles/role_assignment/tasks/main.yml', 'ci/roles/user_role/defaults/main.yaml', 'plugins/modules/group_assignment.py', 'plugins/modules/role_assignment.py', 'ci/roles/group_assignment/tasks/main.yml', 'ci/run-collection.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d5ab2bf33f9dc3441b61063e6024eb8b15325882', 'message': 'Refactored {group,role}_assignment modules\n\nChange-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6\n'}]",0,870671,d5ab2bf33f9dc3441b61063e6024eb8b15325882,15,3,5,32962,,,0,"Refactored {group,role}_assignment modules

Change-Id: I6ec79eb203d0f68661b54bc89a194c366b3574c6
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/71/870671/5 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/user_group/tasks/main.yml', 'ci/roles/user_role/tasks/main.yaml', 'ci/roles/role_assignment/tasks/main.yml', 'ci/roles/group_assignment/tasks/main.yml', 'ci/roles/user_role/defaults/main.yaml', 'plugins/modules/group_assignment.py', 'plugins/modules/role_assignment.py', 'ci/run-collection.yml']",8,3ffbd386c401c347e9bcfada8077f037c851304e,user-group-assignments," - { role: group_assignment, tags: group_assignment }"," - { role: user_group, tags: user_group } - { role: user_role, tags: user_role }",382,327
openstack%2Fansible-collections-openstack~master~I95e0bcc2715493a5a3d27411957faf53b2394d52,openstack/ansible-collections-openstack,master,I95e0bcc2715493a5a3d27411957faf53b2394d52,Sorted Ansible roles with ci integration tests,MERGED,2023-01-16 11:12:07.000000000,2023-01-28 13:19:27.000000000,2023-01-28 13:19:27.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-16 11:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/44ca8b27947c06a142e9532b6aa982c6e5918a28', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 2, 'created': '2023-01-16 13:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ba973efb67da74f5752423c174bd9e86a9881f5e', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 3, 'created': '2023-01-16 18:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d0d7284069caee5c4b9f665b36a1cd64412c3998', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 4, 'created': '2023-01-16 20:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/528f8f84ebbe06ea53d458d6af3f7b196b1f8913', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 5, 'created': '2023-01-17 16:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/9d5bce364cd189a037dbe8e7e80270228df5baf3', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 6, 'created': '2023-01-19 19:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/9fab485813ee8cf86c38b916c814e31fec7eba93', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}, {'number': 7, 'created': '2023-01-26 12:36:24.000000000', 'files': ['ci/run-collection.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/754ae5e50dac9a0baa62ca99c3733db29247c2d0', 'message': 'Sorted Ansible roles with ci integration tests\n\nChange-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52\n'}]",1,870532,754ae5e50dac9a0baa62ca99c3733db29247c2d0,22,4,7,32962,,,0,"Sorted Ansible roles with ci integration tests

Change-Id: I95e0bcc2715493a5a3d27411957faf53b2394d52
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/32/870532/4 && git format-patch -1 --stdout FETCH_HEAD,['ci/run-collection.yml'],1,44ca8b27947c06a142e9532b6aa982c6e5918a28,ci-integration-tests," - { role: identity_user, tags: identity_user } - { role: keystone_idp, tags: keystone_idp } - { role: loadbalancer, tags: loadbalancer } - { role: quota, tags: quota }"," - { role: identity_user, tags: identity_user } - { role: keystone_idp, tags: keystone_idp } - role: loadbalancer tags: loadbalancer - { role: quota, tags: quota }",4,5
openstack%2Fansible-collections-openstack~master~I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159,openstack/ansible-collections-openstack,master,I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159,"Refactored tests for keystone_federation_protocol{,_info} modules",MERGED,2023-01-16 11:08:47.000000000,2023-01-28 13:19:26.000000000,2023-01-28 13:19:26.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-16 11:08:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2ed52ed0869cd082f304caff8dbc38e046c323a7', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 2, 'created': '2023-01-16 13:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3a9966aaf7ccbc2269ece37dc2a166fb4f15b889', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 3, 'created': '2023-01-16 18:53:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2e368f1e6ea9fe4542652dab2233b42e1ef3cf15', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 4, 'created': '2023-01-16 20:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/54f77044d1de1b6f9300c657be0aaa646d35d555', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 5, 'created': '2023-01-17 16:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2b2c94ac7f6a78de029b546ea3f6b5cd4fc7e77e', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 6, 'created': '2023-01-19 19:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/89a911bcf1d7fae9ff30d296617214c4a14c3392', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}, {'number': 7, 'created': '2023-01-26 12:36:10.000000000', 'files': ['ci/roles/keystone_federation_protocol/defaults/main.yml', 'ci/run-collection.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/546f24940f85cc3b2c067cfa989ba88905748400', 'message': 'Refactored tests for keystone_federation_protocol{,_info} modules\n\nChange-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159\n'}]",1,870531,546f24940f85cc3b2c067cfa989ba88905748400,21,3,7,32962,,,0,"Refactored tests for keystone_federation_protocol{,_info} modules

Change-Id: I9665f04e6c0d5a84d6c20a73ef7b0dfdc7bd8159
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/31/870531/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/keystone_federation_protocol/defaults/main.yml', 'ci/run-collection.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml']",3,2ed52ed0869cd082f304caff8dbc38e046c323a7,keystone_federation_protocol," idp_id: ansible_idp idp_id: ansible_idp - name: Create test Domain openstack.cloud.identity_domain: name: ansible_domain register: domain - name: Create test Identity Provider openstack.cloud.federation_idp: state: present name: ansible_idp domain_id: '{{ domain.domain.id }}' - name: Create test mapping (1) openstack.cloud.federation_mapping: state: present name: ansible_mapping1 rules: - local: - group: domain: name: example_domain name: example-group remote: - type: HTTP_OIDC_GROUPS any_one_of: - group1 - group2 - name: Create test mapping (2) openstack.cloud.federation_mapping: state: present name: ansible_mapping2 rules: - local: - group: domain: name: example_domain name: example_group remote: - type: HTTP_OIDC_GROUPS any_one_of: - group1 - name: Ensure Protocol does not exist to start openstack.cloud.keystone_federation_protocol: state: absent name: ansible_protocol1 - name: Create protocol - CHECK MODE state: present name: ansible_protocol1 mapping_id: ansible_mapping1 register: protocol - protocol is changed - name: Fetch Protocol info (should be absent) openstack.cloud.keystone_federation_protocol_info: name: ansible_protocol1 register: protocols - protocols.protocols | length == 0 - name: Create protocol openstack.cloud.keystone_federation_protocol: state: present name: ansible_protocol1 mapping_id: ansible_mapping1 register: protocol - protocol is changed - protocol.protocol.id == 'ansible_protocol1' - protocol.protocol.name == 'ansible_protocol1' - protocol.protocol.mapping_id == 'ansible_mapping1' - expected_fields|difference(protocol.protocol.keys())|length == 0 - name: Create protocol (retry - no change) - CHECK MODE state: present name: ansible_protocol1 mapping_id: ansible_mapping1 register: protocol - protocol is not changed - name: Create protocol (retry - no change) openstack.cloud.keystone_federation_protocol: state: present name: ansible_protocol1 mapping_id: ansible_mapping1 register: protocol - protocol is not changed - protocol.protocol.id == 'ansible_protocol1' - protocol.protocol.name == 'ansible_protocol1' - protocol.protocol.mapping_id == 'ansible_mapping1' - name: Update protocol - CHECK MODE state: present name: ansible_protocol1 mapping_id: ansible_mapping2 register: protocol - protocol is changed - name: Update protocol openstack.cloud.keystone_federation_protocol: state: present name: ansible_protocol1 mapping_id: ansible_mapping2 register: protocol - protocol is changed - protocol.protocol.id == 'ansible_protocol1' - protocol.protocol.name == 'ansible_protocol1' - protocol.protocol.mapping_id == 'ansible_mapping2' - name: Update protocol (retry - no change) - CHECK MODE state: present name: ansible_protocol1 mapping_id: ansible_mapping2 register: protocol - protocol is not changed - name: Update protocol (retry - no change) openstack.cloud.keystone_federation_protocol: state: present name: ansible_protocol1 mapping_id: ansible_mapping2 register: protocol - protocol is not changed - protocol.protocol.id == 'ansible_protocol1' - protocol.protocol.name == 'ansible_protocol1' - protocol.protocol.mapping_id == 'ansible_mapping2' - name: Create protocol (2) openstack.cloud.keystone_federation_protocol: state: present name: ansible_protocol2 mapping_id: ansible_mapping1 register: protocol - protocol is changed - protocol.protocol.id == 'ansible_protocol2' - protocol.protocol.name == 'ansible_protocol2' - protocol.protocol.mapping_id == 'ansible_mapping1' - name: Fetch Protocol info (a specific protocol) openstack.cloud.keystone_federation_protocol_info: name: ansible_protocol1 register: protocols - protocols.protocols|length > 0 - expected_fields|difference(protocols.protocols[0].keys())|length == 0 - protocols.protocols[0].id == 'ansible_protocol1' - protocols.protocols[0].name == 'ansible_protocol1' - protocols.protocols[0].mapping_id == 'ansible_mapping2' - name: Fetch Protocol info (all protocols on our test IDP) register: protocols # We created the IDP, and we're going to delete it: # we should be able to trust what's attached to it - protocols.protocols | length == 2 - ""'ansible_protocol1' in (protocols.protocols | map(attribute='id'))"" - ""'ansible_protocol1' in (protocols.protocols | map(attribute='id'))"" - ""'ansible_protocol2' in (protocols.protocols | map(attribute='name'))"" - ""'ansible_protocol2' in (protocols.protocols | map(attribute='name'))"" - ""'ansible_mapping1' in (protocols.protocols | map(attribute='mapping_id'))"" - ""'ansible_mapping2' in (protocols.protocols | map(attribute='mapping_id'))"" - name: Delete protocol - CHECK MODE state: absent name: ansible_protocol1 register: protocol - protocol is changed - name: Delete protocol openstack.cloud.keystone_federation_protocol: state: absent name: ansible_protocol1 register: protocol - protocol is changed - name: Delete protocol (retry - no change) - CHECK MODE state: absent name: ansible_protocol1 register: protocol - protocol is not changed - name: Delete protocol (retry - no change) openstack.cloud.keystone_federation_protocol: state: absent name: ansible_protocol1 register: protocol - protocol is not changed - name: Delete protocol openstack.cloud.keystone_federation_protocol: state: absent name: ansible_protocol1 idp_id: ansible_idp - name: Delete protocol (2) openstack.cloud.keystone_federation_protocol: state: absent name: ansible_protocol2 idp_id: ansible_idp - name: Delete mapping 1 openstack.cloud.federation_mapping: state: absent name: ansible_mapping1 - name: Delete mapping 2 openstack.cloud.federation_mapping: state: absent name: ansible_mapping2 - name: Delete idp openstack.cloud.federation_idp: state: absent name: ansible_idp - name: Delete domain openstack.cloud.identity_domain: state: absent name: ansible_domain"," idp_id: ""{{ idp_name }}"" idp_id: ""{{ idp_name }}"" - name: 'Create test Domain' openstack.cloud.identity_domain: name: '{{ domain_name }}' register: create_domain - name: 'Create test Identity Provider' openstack.cloud.federation_idp: state: 'present' name: '{{ idp_name }}' domain_id: '{{ create_domain.domain.id }}' - name: 'Create test mapping (1)' openstack.cloud.federation_mapping: state: 'present' name: '{{ mapping_name_1 }}' rules: '{{ mapping_rules_1 }}' - name: 'Create test mapping (2)' openstack.cloud.federation_mapping: state: 'present' name: '{{ mapping_name_2 }}' rules: '{{ mapping_rules_2 }}' - name: ""Ensure Protocol doesn't exist to start"" openstack.cloud.keystone_federation_protocol: state: 'absent' name: '{{ protocol_name }}' - name: 'Create protocol - CHECK MODE' state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_1 }}' register: create_protocol - create_protocol is changed - name: 'Fetch Protocol info (should be absent)' openstack.cloud.keystone_federation_protocol_info: name: '{{ protocol_name }}' register: protocol_info - protocol_info.protocols | length == 0 - name: 'Create protocol' openstack.cloud.keystone_federation_protocol: state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_1 }}' register: create_protocol - create_protocol is changed - create_protocol.protocol.id == protocol_name - create_protocol.protocol.name == protocol_name - create_protocol.protocol.mapping_id == mapping_name_1 - expected_fields|difference(create_protocol.protocol.keys())|length == 0 - name: 'Create protocol (retry - no change) - CHECK MODE' state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_1 }}' register: create_protocol - create_protocol is not changed - name: 'Create protocol (retry - no change)' openstack.cloud.keystone_federation_protocol: state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_1 }}' register: create_protocol - create_protocol is not changed - create_protocol.protocol.id == protocol_name - create_protocol.protocol.name == protocol_name - create_protocol.protocol.mapping_id == mapping_name_1 - name: 'Update protocol - CHECK MODE' state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_2 }}' register: update_protocol - update_protocol is changed - name: 'Update protocol' openstack.cloud.keystone_federation_protocol: state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_2 }}' register: update_protocol - update_protocol is changed - update_protocol.protocol.id == protocol_name - update_protocol.protocol.name == protocol_name - update_protocol.protocol.mapping_id == mapping_name_2 - name: 'Update protocol (retry - no change) - CHECK MODE' state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_2 }}' register: update_protocol - update_protocol is not changed - name: 'Update protocol (retry - no change)' openstack.cloud.keystone_federation_protocol: state: 'present' name: '{{ protocol_name }}' mapping_id: '{{ mapping_name_2 }}' register: update_protocol - update_protocol is not changed - update_protocol.protocol.id == protocol_name - update_protocol.protocol.name == protocol_name - update_protocol.protocol.mapping_id == mapping_name_2 - name: 'Create protocol (2)' openstack.cloud.keystone_federation_protocol: state: 'present' name: '{{ protocol_name_2 }}' mapping_id: '{{ mapping_name_1 }}' register: create_protocol_2 - create_protocol_2 is changed - create_protocol_2.protocol.id == protocol_name_2 - create_protocol_2.protocol.name == protocol_name_2 - create_protocol_2.protocol.mapping_id == mapping_name_1 - name: 'Fetch Protocol info (a specific protocol)' openstack.cloud.keystone_federation_protocol_info: name: '{{ protocol_name }}' register: protocol_info - protocol_info.protocols|length > 0 - expected_fields|difference(protocol_info.protocols[0].keys())|length == 0 - protocol_info.protocols[0].id == protocol_name - protocol_info.protocols[0].name == protocol_name - protocol_info.protocols[0].mapping_id == mapping_name_2 - name: 'Fetch Protocol info (all protocols on our test IDP)' register: protocol_info # We created the IDP, and we're going to delete it: # we should be able to trust what's attached to it - protocol_info.protocols | length == 2 - protocol_name in (protocol_info.protocols | map(attribute='id')) - protocol_name in (protocol_info.protocols | map(attribute='id')) - protocol_name_2 in (protocol_info.protocols | map(attribute='name')) - protocol_name_2 in (protocol_info.protocols | map(attribute='name')) - mapping_name_1 in (protocol_info.protocols | map(attribute='mapping_id')) - mapping_name_2 in (protocol_info.protocols | map(attribute='mapping_id')) vars: protocol_1: '{{ protocol_info.protocols[0] }}' protocol_2: '{{ protocol_info.protocols[1] }}' - name: 'Delete protocol - CHECK MODE' state: 'absent' name: '{{ protocol_name }}' register: update_protocol - update_protocol is changed - name: 'Delete protocol' openstack.cloud.keystone_federation_protocol: state: 'absent' name: '{{ protocol_name }}' register: update_protocol - update_protocol is changed - name: 'Delete protocol (retry - no change) - CHECK MODE' state: 'absent' name: '{{ protocol_name }}' register: update_protocol - update_protocol is not changed - name: 'Delete protocol (retry - no change)' openstack.cloud.keystone_federation_protocol: state: 'absent' name: '{{ protocol_name }}' register: update_protocol - update_protocol is not changed - name: 'Delete protocol' openstack.cloud.keystone_federation_protocol: state: 'absent' name: '{{ protocol_name }}' idp_id: '{{ idp_name }}' - name: 'Delete protocol (2)' openstack.cloud.keystone_federation_protocol: state: 'absent' name: '{{ protocol_name_2 }}' idp_id: '{{ idp_name }}' - name: 'Delete mapping 1' openstack.cloud.federation_mapping: state: 'absent' name: '{{ mapping_name_1 }}' - name: 'Delete mapping 2' openstack.cloud.federation_mapping: state: 'absent' name: '{{ mapping_name_2 }}' - name: 'Delete idp' openstack.cloud.federation_idp: state: 'absent' name: '{{ idp_name }}' - name: 'Delete domain' openstack.cloud.identity_domain: state: 'absent' name: '{{ domain_name }}'",175,195
openstack%2Fansible-collections-openstack~master~Iebcd45d0eae79ab3911fd97c63d17b42d238f875,openstack/ansible-collections-openstack,master,Iebcd45d0eae79ab3911fd97c63d17b42d238f875,"Pivoted docs to generic resource{,s} modules and StateMachine class",MERGED,2023-01-16 10:38:55.000000000,2023-01-28 13:19:24.000000000,2023-01-28 13:19:24.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-16 10:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/edd94026a41145d2125c1f4bde383d33aa4560b5', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 2, 'created': '2023-01-16 13:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/41028b54062d2260a7e048728fe01bb67691b55c', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 3, 'created': '2023-01-16 18:52:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/af078673eea1569214d101d8e45c58e8ece77693', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 4, 'created': '2023-01-16 20:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/cdb6043e892a9e9963f45fd927047c509296d4d9', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 5, 'created': '2023-01-17 16:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5f8bc2b79bb224df3a48e8bf9b652b95f532b21e', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 6, 'created': '2023-01-19 19:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/fae57226b6be14c85a85c28669ca824db08b6fd0', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}, {'number': 7, 'created': '2023-01-26 12:35:53.000000000', 'files': ['docs/contributing.md', 'README.md'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f507465c9e515ccf12906ef55ae1b22912a80069', 'message': 'Pivoted docs to generic resource{,s} modules and StateMachine class\n\nChange-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875\n'}]",0,870529,f507465c9e515ccf12906ef55ae1b22912a80069,19,3,7,32962,,,0,"Pivoted docs to generic resource{,s} modules and StateMachine class

Change-Id: Iebcd45d0eae79ab3911fd97c63d17b42d238f875
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/29/870529/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/contributing.md', 'README.md']",2,edd94026a41145d2125c1f4bde383d33aa4560b5,docs-fixed,"To use a module from the Ansible OpenStack collection, call them by their Fully Qualified Collection Name (FQCN), composed of their namespace, collection name and module name:- hosts: localhost tasks: - name: Create server in an OpenStack cloud openstack.cloud.server:- hosts: localhost - name: Create server in an OpenStack cloud server_volume:For powerful generic [CRUD][crud]-style resource management use Ansible module [`openstack.cloud.resource`](plugins/modules/resource.py): ```yaml --- - hosts: localhost tasks: - name: Create security group openstack.cloud.resource: cloud: openstack service: network type: security_group attributes: name: ansible_security_group description: 'ansible security group' - name: Update security group description openstack.cloud.resource: cloud: openstack service: network type: security_group attributes: name: ansible_security_group description: 'ansible neutron security group' - name: Delete security group openstack.cloud.resource: cloud: openstack service: network type: security_group attributes: name: ansible_security_group state: absent ``` For generic resource listing use Ansible module [`openstack.cloud.resources`](plugins/modules/resources.py): ```yaml --- - hosts: localhost tasks: - name: List images openstack.cloud.resources: cloud: openstack service: image type: image - name: List compute flavors openstack.cloud.resources: cloud: openstack service: compute type: flavor - name: List networks with name 'public' openstack.cloud.resources: cloud: openstack service: network type: network parameters: name: public ``` [crud]: https://en.wikipedia.org/wiki/CRUD","To use a module from the OpenStack Cloud collection, please reference the full namespace, collection name, and module name that you want to use:- name: Using OpenStack Cloud collection hosts: localhost tasks: - openstack.cloud.server:- name: Using the Ansible OpenStack Collection hosts: localhost - server_volume:",79,14
openstack%2Fansible-collections-openstack~master~Icbff6c799a9c33f1104633f7d9521f02228217a5,openstack/ansible-collections-openstack,master,Icbff6c799a9c33f1104633f7d9521f02228217a5,"Refactored federation_idp{,_info} modules",MERGED,2023-01-13 20:16:17.000000000,2023-01-28 13:19:23.000000000,2023-01-28 13:19:23.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-13 20:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3bcaefb5e978f53f5d37e53276bb7d880a20d751', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 2, 'created': '2023-01-14 08:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/82cf862c89d3209c9d18a6869583c5f92a454835', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 3, 'created': '2023-01-16 10:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/412d4206687e2ea6fc0efa0a6bd08a5625910097', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 4, 'created': '2023-01-16 13:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/89063fc48e38a0483154651f7b7c729ba8eeeeab', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 5, 'created': '2023-01-16 18:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5f65e383db4eccf7a84f2c62398044aa97a5bc80', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 6, 'created': '2023-01-16 20:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/23eb446b8382b0864e844e003c85e1ed424b3f79', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 7, 'created': '2023-01-17 16:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ea7597d630f8d148d07e818e9dbbf79c8b781c7f', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 8, 'created': '2023-01-19 19:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/78bda83f43e7aba7fe6842af773aa253b1b2e0cf', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}, {'number': 9, 'created': '2023-01-26 12:35:35.000000000', 'files': ['ci/roles/keystone_idp/tasks/main.yml', 'plugins/modules/federation_idp_info.py', 'ci/run-collection.yml', 'ci/roles/keystone_idp/defaults/main.yml', 'plugins/modules/federation_idp.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/90b110794f8ee9905c48ce7c524bcbb46e53ec74', 'message': 'Refactored federation_idp{,_info} modules\n\nChange-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5\n'}]",4,870313,90b110794f8ee9905c48ce7c524bcbb46e53ec74,25,4,9,32962,,,0,"Refactored federation_idp{,_info} modules

Change-Id: Icbff6c799a9c33f1104633f7d9521f02228217a5
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/13/870313/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/keystone_idp/tasks/main.yml', 'plugins/modules/federation_idp_info.py', 'ci/run-collection.yml', 'ci/roles/keystone_idp/defaults/main.yml', 'plugins/modules/federation_idp.py']",5,3bcaefb5e978f53f5d37e53276bb7d880a20d751,identity_provider,"DOCUMENTATION = r'''short_description: Manage an identity provider in a OpenStack cloud - Create, update or delete an identity provider of the OpenStack identity (Keystone) service. options: - The description of the identity provider. - The ID of a domain that is associated with the identity provider. - Federated users that authenticate with the identity provider will be - Required when creating a new identity provider. id: description: - The ID (and name) of the identity provider. type: str required: true aliases: ['name'] is_enabled: description: - Whether the identity provider is enabled or not. - Will default to C(false) when creating a new identity provider. aliases: ['enabled'] - ""List of the unique identity provider's remote IDs."" - Will default to an empty list when creating a new identity provider. state: description: - Whether the identity provider should be C(present) or C(absent). choices: ['present', 'absent'] default: present type: str - ""openstacksdk""EXAMPLES = r''' - 'https://auth.example.com/auth/realms/ExampleRealm'RETURN = r''' identity_provider: description: Dictionary describing the identity providers returned: On success when I(state) is C(present). type: dict contains: description: description: Identity provider description type: str sample: ""demodescription"" domain_id: description: Domain to which the identity provider belongs type: str sample: ""default"" id: description: Identity provider ID type: str sample: ""test-idp"" is_enabled: description: Indicates whether the identity provider is enabled type: bool name: description: Name of the identity provider, equals its ID. type: str sample: ""test-idp"" remote_ids: description: Remote IDs associated with the identity provider type: listfrom ansible_collections.openstack.cloud.plugins.module_utils.resource import StateMachine class IdentityProviderModule(OpenStackModule): id=dict(required=True, aliases=['name']), is_enabled=dict(type='bool', aliases=['enabled']), state=dict(default='present', choices=['absent', 'present']), def run(self): crud_functions = StateMachine.default_crud_functions( self.conn, 'identity', 'identity_provider') sm = StateMachine(connection=self.conn, crud_functions=crud_functions, service_name='identity', type_name='identity_provider', sdk=self.sdk) kwargs = dict((k, self.params[k]) for k in ['state', 'timeout'] if self.params[k] is not None) kwargs['attributes'] = \ dict((k, self.params[k]) for k in ['description', 'domain_id', 'id', 'is_enabled', 'remote_ids'] if self.params[k] is not None) identity_provider, is_changed = \ sm(check_mode=self.ansible.check_mode, updateable_attributes=None, non_updateable_attributes=['domain_id'], wait=False, **kwargs) if identity_provider is None: self.exit_json(changed=is_changed) else: self.exit_json( changed=is_changed, identity_provider=identity_provider.to_dict(computed=False)) module = IdentityProviderModule()","DOCUMENTATION = ''' ---short_description: manage a federation Identity Provider - Manage a federation Identity Provider. options: name: description: - The name of the Identity Provider. type: str required: true aliases: ['id'] state: description: - Whether the Identity Provider should be C(present) or C(absent). choices: ['present', 'absent'] default: present type: str - The description of the Identity Provider. - The ID of a domain that is associated with the Identity Provider. Federated users that authenticate with the Identity Provider will be - Required when creating a new Identity Provider. enabled: description: - Whether the Identity Provider is enabled or not. - Will default to C(true) when creating a new Identity Provider. aliases: ['is_enabled'] - ""List of the unique Identity Provider's remote IDs."" - Will default to an empty list when creating a new Identity Provider. - ""openstacksdk >= 0.44""EXAMPLES = ''' - 'https://auth.example.com/auth/realms/ExampleRealm'RETURN = ''' identity_provider: description: Dictionary describing the identity providers returned: On success when I(state) is 'present' type: dict elements: dict contains: description: description: Identity provider description type: str sample: ""demodescription"" domain_id: description: Domain to which the identity provider belongs type: str sample: ""default"" id: description: Identity provider ID type: str sample: ""test-idp"" is_enabled: description: Indicates whether the identity provider is enabled type: bool name: description: Name of the identity provider, equals its ID. type: str sample: ""test-idp"" remote_ids: description: Remote IDs associated with the identity provider type: list class IdentityFederationIdpModule(OpenStackModule): name=dict(required=True, aliases=['id']), state=dict(default='present', choices=['absent', 'present']), enabled=dict(type='bool', aliases=['is_enabled']), def delete_identity_provider(self, idp): """""" Delete an existing Identity Provider returns: the ""Changed"" state """""" if idp is None: return False if self.ansible.check_mode: return True self.conn.identity.delete_identity_provider(idp) return True def create_identity_provider(self, name): """""" Create a new Identity Provider returns: the ""Changed"" state and the new identity provider """""" if self.ansible.check_mode: return True, None description = self.params.get('description') enabled = self.params.get('enabled') domain_id = self.params.get('domain_id') remote_ids = self.params.get('remote_ids') if enabled is None: enabled = True if remote_ids is None: remote_ids = [] attributes = { 'domain_id': domain_id, 'enabled': enabled, 'remote_ids': remote_ids, } if description is not None: attributes['description'] = description idp = self.conn.identity.create_identity_provider(id=name, **attributes) return (True, idp.to_dict(computed=False)) def update_identity_provider(self, idp): """""" Update an existing Identity Provider returns: the ""Changed"" state and the new identity provider """""" description = self.params.get('description') enabled = self.params.get('enabled') domain_id = self.params.get('domain_id') remote_ids = self.params.get('remote_ids') attributes = {} if (description is not None) and (description != idp.description): attributes['description'] = description if (enabled is not None) and (enabled != idp.is_enabled): attributes['enabled'] = enabled if (domain_id is not None) and (domain_id != idp.domain_id): attributes['domain_id'] = domain_id if (remote_ids is not None) and (remote_ids != idp.remote_ids): attributes['remote_ids'] = remote_ids if not attributes: return False, idp.to_dict(computed=False) if self.ansible.check_mode: return True, None new_idp = self.conn.identity.update_identity_provider(idp, **attributes) return (True, new_idp.to_dict(computed=False)) def run(self): """""" Module entry point """""" name = self.params.get('name') state = self.params.get('state') changed = False idp = self.conn.identity.find_identity_provider(name) if state == 'absent': if idp is not None: changed = self.delete_identity_provider(idp) self.exit_json(changed=changed) # state == 'present' else: if idp is None: if self.params.get('domain_id') is None: self.fail_json(msg='A domain_id must be passed when creating' ' an identity provider') (changed, idp) = self.create_identity_provider(name) self.exit_json(changed=changed, identity_provider=idp) (changed, new_idp) = self.update_identity_provider(idp) self.exit_json(changed=changed, identity_provider=new_idp) module = IdentityFederationIdpModule()",498,592
openstack%2Fansible-collections-openstack~master~Iae52d1a86f8f78790290be3966681f2277b9701d,openstack/ansible-collections-openstack,master,Iae52d1a86f8f78790290be3966681f2277b9701d,"Refactored identity_user{,_info} modules",MERGED,2023-01-13 12:47:41.000000000,2023-01-28 13:19:22.000000000,2023-01-28 13:19:22.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-13 12:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/9c039740bfcc0617a1cddc2ae38abd7d91f40651', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 2, 'created': '2023-01-13 20:15:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/db9042db95a7cf374f8c52d7bbdbacf6bbad94c3', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 3, 'created': '2023-01-14 08:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/40259222f64bb6b0d51092a6776d70b25232028f', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 4, 'created': '2023-01-16 10:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3ae82977d0626db695676e6cdc6f9fc20ffc64e0', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 5, 'created': '2023-01-16 13:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5ede7dcd35c51ee9fa03e740fdf1064d1f80bf40', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 6, 'created': '2023-01-16 18:49:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5c804ed07a177d2eeb2384eea7337644d9743e2b', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 7, 'created': '2023-01-16 20:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e4c7a3eb42168644acc4104e3f591a2ea45b4ee5', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 8, 'created': '2023-01-17 16:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b649675109983770ad9a362dffc1afc33e9fcc45', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 9, 'created': '2023-01-19 19:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/187229e5daaf4aee25a5599b4c9839ed4b251492', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}, {'number': 10, 'created': '2023-01-26 12:35:16.000000000', 'files': ['plugins/modules/identity_user.py', 'ci/roles/identity_user/tasks/main.yml', 'ci/roles/identity_user/defaults/main.yml', 'ci/roles/identity_user_info/tasks/main.yml', 'ci/run-collection.yml', 'ci/roles/identity_user_info/defaults/main.yml', 'plugins/modules/identity_user_info.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c9afdbfd73d788450d0e9f28ffc6893e350c0460', 'message': 'Refactored identity_user{,_info} modules\n\nChange-Id: Iae52d1a86f8f78790290be3966681f2277b9701d\n'}]",1,870087,c9afdbfd73d788450d0e9f28ffc6893e350c0460,29,4,10,32962,,,0,"Refactored identity_user{,_info} modules

Change-Id: Iae52d1a86f8f78790290be3966681f2277b9701d
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/87/870087/4 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/identity_user.py', 'ci/roles/identity_user/tasks/main.yml', 'ci/roles/identity_user/defaults/main.yml', 'ci/roles/identity_user_info/tasks/main.yml', 'ci/roles/identity_user_info/defaults/main.yml', 'ci/run-collection.yml', 'plugins/modules/identity_user_info.py']",7,9c039740bfcc0617a1cddc2ae38abd7d91f40651,identity_user,"DOCUMENTATION = r'''short_description: Fetch OpenStack identity (Keystone) users - Fetch OpenStack identity (Keystone) users. options: domain: description: - Name or ID of the domain containing the user. type: str filters: description: - A dictionary of meta data to use for further filtering. Elements of this dictionary may be additional dictionaries. type: dict name: description: - Name or ID of the user. type: str requirements: - ""python >= 3.6"" - ""openstacksdk"" extends_documentation_fragment: - openstack.cloud.openstackEXAMPLES = r''' - name: Gather previously created users openstack.cloud.identity_user_info: - name: Gather previously created user by name openstack.cloud.identity_user_info: - name: Gather previously created user in a specific domain openstack.cloud.identity_user_info: - name: Gather previously created user with filters openstack.cloud.identity_user_info: is_enabled: FalseRETURN = r''' users: description: Dictionary describing all matching identity users. returned: always type: list elements: dict contains: id: description: Unique UUID. type: str name: description: Username of the user. type: str default_project_id: description: Default project ID of the user type: str description: description: The description of this user type: str domain_id: description: Domain ID containing the user type: str email: description: Email of the user type: str is_enabled: description: Flag to indicate if the user is enabled type: bool links: description: The links for the user resource type: dict password: description: The default form of credential used during authentication. type: str password_expires_at: description: The date and time when the password expires. The time zone is UTC. A Null value means the password never expires. type: str username: description: Username with Identity API v2 (OpenStack Pike or earlier) else Null. type: str filters=dict(type='dict'), name=dict(), filters = self.params['filters'] or {} kwargs = {} domain_name_or_id = self.params['domain'] if domain_name_or_id: domain = self.conn.identity.find_domain(domain_name_or_id) if domain is None: self.exit_json(changed=False, groups=[]) kwargs['domain_id'] = domain['id'] self.exit_json(changed=False, users=[u.to_dict(computed=False) for u in self.conn.search_users(name, filters, **kwargs)])","DOCUMENTATION = '''short_description: Retrieve information about one or more OpenStack users - Retrieve information about a one or more OpenStack users options: name: description: - Name or ID of the user type: str domain: description: - Name or ID of the domain containing the user if the cloud supports domains type: str filters: description: - A dictionary of meta data to use for further filtering. Elements of this dictionary may be additional dictionaries. type: dict default: {} requirements: - ""python >= 3.6"" - ""openstacksdk"" extends_documentation_fragment: - openstack.cloud.openstackEXAMPLES = ''' # Gather information about previously created users - openstack.cloud.identity_user_info: register: result - debug: msg: ""{{ result.users }}"" # Gather information about a previously created user by name - openstack.cloud.identity_user_info: register: result - debug: msg: ""{{ result.users }}"" # Gather information about a previously created user in a specific domain - openstack.cloud.identity_user_info: register: result - debug: msg: ""{{ result.users }}"" # Gather information about a previously created user in a specific domain with filter - openstack.cloud.identity_user_info: enabled: False register: result - debug: msg: ""{{ result.users }}"" RETURN = ''' users: description: has all the OpenStack information about users returned: always type: list elements: dict contains: id: description: Unique UUID. returned: success type: str name: description: Username of the user. returned: success type: str default_project_id: description: Default project ID of the user returned: success type: str description: description: The description of this user returned: success type: str domain_id: description: Domain ID containing the user returned: success type: str email: description: Email of the user returned: success type: str is_enabled: description: Flag to indicate if the user is enabled returned: success type: bool links: description: The links for the user resource returned: success type: complex contains: self: description: Link to this user resource returned: success type: str password: description: The default form of credential used during authentication. returned: success type: str password_expires_at: description: The date and time when the password expires. The time zone is UTC. A Null value means the password never expires. returned: success type: str username: description: Username with Identity API v2 (OpenStack Pike or earlier) else Null returned: success type: str name=dict(), filters=dict(type='dict', default={}), domain = self.params['domain'] filters = self.params['filters'] args = {} if domain: dom_obj = self.conn.identity.find_domain(domain) if dom_obj is None: self.fail_json( msg=""Domain name or ID '{0}' does not exist"".format(domain)) args['domain_id'] = dom_obj.id users = [user.to_dict(computed=False) for user in self.conn.search_users(name, filters, **args)] self.exit_json(changed=False, users=users)",452,559
openstack%2Fansible-collections-openstack~master~If8230eb8b41b5461e1eaa470569030e8a888015b,openstack/ansible-collections-openstack,master,If8230eb8b41b5461e1eaa470569030e8a888015b,"Refactored identity_role{,_info} modules",MERGED,2023-01-13 10:19:17.000000000,2023-01-28 13:19:20.000000000,2023-01-28 13:19:20.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-13 10:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/bedf55afbb4d4a955c6a7590a33f32b726cfd01b', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 2, 'created': '2023-01-13 10:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/1129b277042d0657ac08dca5a125f9a25570f5ae', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 3, 'created': '2023-01-13 12:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6665ce4c51be1499add50cabad14825d8215b61b', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 4, 'created': '2023-01-13 20:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/220bc944328de24de8a983dae415485fa0a8207f', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 5, 'created': '2023-01-14 08:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/5feb2dfb7da180a71fc3d5d044822fd6c89124d4', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 6, 'created': '2023-01-16 10:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/71446421df8e4ca318660a783c0901825fd4feb4', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 7, 'created': '2023-01-16 13:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3deae3e1d560efe23149fd24f9ccc3b3546f7138', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 8, 'created': '2023-01-16 18:48:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8591fda74ea41827d2bd6a998487e8218f5872ac', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 9, 'created': '2023-01-16 20:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e531f63fbb61700197ed21d1540924b3fdbc515c', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 10, 'created': '2023-01-17 16:37:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4a316dd4cc93011184b1b980ced91c937550409f', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 11, 'created': '2023-01-19 19:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6340253db9848aecdd510815f24fdf9b83e4c9eb', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}, {'number': 12, 'created': '2023-01-26 12:34:59.000000000', 'files': ['ci/roles/identity_role/tasks/main.yml', 'ci/roles/identity_role_info/tasks/main.yml', 'ci/roles/identity_role/defaults/main.yml', 'plugins/modules/identity_role_info.py', 'ci/run-collection.yml', 'plugins/modules/identity_role.py'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4a27306440fc489a7c39f326919777b5276acd2a', 'message': 'Refactored identity_role{,_info} modules\n\nChange-Id: If8230eb8b41b5461e1eaa470569030e8a888015b\n'}]",0,870072,4a27306440fc489a7c39f326919777b5276acd2a,31,4,12,32962,,,0,"Refactored identity_role{,_info} modules

Change-Id: If8230eb8b41b5461e1eaa470569030e8a888015b
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/72/870072/4 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/identity_role/tasks/main.yml', 'ci/roles/identity_role_info/tasks/main.yml', 'ci/roles/identity_role/defaults/main.yml', 'plugins/modules/identity_role_info.py', 'ci/run-collection.yml', 'plugins/modules/identity_role.py']",6,bedf55afbb4d4a955c6a7590a33f32b726cfd01b,identity_role,"DOCUMENTATION = r'''short_description: Manage a OpenStack identity (Keystone) role - Create, update or delete a OpenStack identity (Keystone) role. options: description: description: - Role description. type: str domain_id: description: - Domain id to create the role in. type: str name: description: - Role name. required: true type: str state: description: - Should the resource be present or absent. choices: ['present', 'absent'] default: present type: str requirements: - ""python >= 3.6"" - ""openstacksdk"" extends_documentation_fragment: - openstack.cloud.openstackEXAMPLES = r''' - name: Create a role named demo openstack.cloud.identity_role:- name: Delete the role named demo openstack.cloud.identity_role:RETURN = r''' role: description: Dictionary describing the identity role. returned: On success when I(state) is C(present). type: dict contains: description: description: Description of the role resource type: str sample: role description domain_id: description: Domain to which the role belongs type: str sample: default id: description: Unique role ID. type: str sample: ""677bfab34c844a01b88a217aa12ec4c2"" links: description: Links for the role resource type: list name: description: Role name. type: str sample: ""demo""from ansible_collections.openstack.cloud.plugins.module_utils.resource import StateMachine description=dict(), domain_id=dict(), class _StateMachine(StateMachine): def _find(self, attributes, **kwargs): kwargs = dict((k, attributes[k]) for k in ['domain_id'] if k in attributes and attributes[k] is not None) return self.find_function(attributes['name'], **kwargs) crud_functions = StateMachine.default_crud_functions( self.conn, 'identity', 'role') sm = self._StateMachine(connection=self.conn, crud_functions=crud_functions, service_name='identity', type_name='role', sdk=self.sdk) kwargs = dict((k, self.params[k]) for k in ['state', 'timeout'] if self.params[k] is not None) kwargs['attributes'] = \ dict((k, self.params[k]) for k in ['description', 'domain_id', 'name'] if self.params[k] is not None) role, is_changed = sm(check_mode=self.ansible.check_mode, updateable_attributes=None, non_updateable_attributes=['domain_id'], wait=False, **kwargs) if role is None: self.exit_json(changed=is_changed) else: self.exit_json(changed=is_changed, role=role.to_dict(computed=False))","DOCUMENTATION = '''short_description: Manage OpenStack Identity Roles - Manage OpenStack Identity Roles. options: name: description: - Role Name required: true type: str state: description: - Should the resource be present or absent. choices: [present, absent] default: present type: str requirements: - ""python >= 3.6"" - ""openstacksdk"" extends_documentation_fragment: - openstack.cloud.openstackEXAMPLES = ''' # Create a role named ""demo"" - openstack.cloud.identity_role:# Delete the role named ""demo"" - openstack.cloud.identity_role:RETURN = ''' role: description: Dictionary describing the role. returned: On success when I(state) is 'present'. type: dict contains: description: description: Description of the role resource type: str sample: role description domain_id: description: Domain to which the role belongs type: str sample: default id: description: Unique role ID. type: str sample: ""677bfab34c844a01b88a217aa12ec4c2"" links: description: Links for the role resource type: list name: description: Role name. type: str sample: ""demo"" def _system_state_change(self, state, role): if state == 'present' and not role: return True if state == 'absent' and role: return True return False name = self.params.get('name') state = self.params.get('state') role = self.conn.identity.find_role(name) if self.ansible.check_mode: self.exit_json(changed=self._system_state_change(state, role)) changed = False if state == 'present': if role is None: role = self.conn.identity.create_role(name=name) changed = True role = role.to_dict(computed=False) self.exit_json(changed=changed, role=role) elif state == 'absent' and role is not None: self.conn.identity.delete_role(role['id']) changed = True self.exit_json(changed=changed)",203,248
openstack%2Fopenstacksdk~master~Iec490c844efe735f01f6a9f6cc12876f2913b98c,openstack/openstacksdk,master,Iec490c844efe735f01f6a9f6cc12876f2913b98c,image: Reformat proxy modules,MERGED,2022-12-08 18:46:19.000000000,2023-01-28 13:18:46.000000000,2023-01-28 13:17:41.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/df013d31935ec92bf323e894bfd4b67f58e68307', 'message': ""image: Reformat proxy modules\n\nWe're going to be conducting surgery on these shortly. Clean them up\nbefore that happens.\n\nChange-Id: Iec490c844efe735f01f6a9f6cc12876f2913b98c\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/image/_base_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/121911feecbbc92920f67235454c692faff43c2e', 'message': ""image: Reformat proxy modules\n\nWe're going to be conducting surgery on these shortly. Clean them up\nbefore that happens.\n\nChange-Id: Iec490c844efe735f01f6a9f6cc12876f2913b98c\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",0,867040,121911feecbbc92920f67235454c692faff43c2e,11,3,2,15334,,,0,"image: Reformat proxy modules

We're going to be conducting surgery on these shortly. Clean them up
before that happens.

Change-Id: Iec490c844efe735f01f6a9f6cc12876f2913b98c
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/40/867040/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/image/_base_proxy.py', 'openstack/image/v2/_proxy.py']",3,df013d31935ec92bf323e894bfd4b67f58e68307,glance-gaps," ""task"": _task.Task, """"""Create image resource from attributes"""""" :param image: The value can be the ID of a image or a :param method: Method to use for importing the image. Not all deployments support all methods. One of: ``glance-direct`` (default), ``web-download``, ``glance-download``, or ``copy-image``. Use of ``glance-direct`` requires the image be first staged. :param uri: Required only if using the ``web-download`` import method. :param remote_region: The remote glance region to download the image from when using glance-direct. :param remote_image_id: The ID of the image of to import from the remote glance when using glance-direct. :param remote_service_interface: The remote glance service interface to use when uding glance-download :param store: Used when enabled_backends is activated in glance. The value can be the id of a store or a :param stores: List of stores to be used when enabled_backends is activated in glance. List values can be the id of a store or a :param all_stores: Upload to all available stores. Mutually exclusive with ``store`` and ``stores``. :param all_stores_must_succeed: When set to True, if an error occurs during the upload in at least one store, the worfklow fails, the data is deleted from stores where copying is done (not staging), and the state of the image is unchanged. When set to False, the ""all_stores is mutually exclusive with store and stores"" raise exceptions.SDKException( 'Image stage is only possible for images in the queued state. ' 'Current state is {status}'.format(status=image.status) ) def upload_image( self, container_format=None, disk_format=None, data=None, **attrs ): This method is deprecated - and also doesn't work very well. Please stop using it immediately and switch to `create_image`. ""Both container_format and disk_format are required"" ) img = self._create( _image.Image, disk_format=disk_format, container_format=container_format, **attrs, ) self, name, filename=None, data=None, meta=None, wait=False, timeout=None, validate_checksum=True, **kwargs, ""The Glance Task API and Import API are mutually "" ""exclusive. Either disable image_api_use_tasks in "" ""config, or do not request using import"" ) name, filename, data=data, meta=meta, wait=wait, timeout=timeout, **kwargs, ) name, filename, data=data, meta=meta, **kwargs, ) ""Image creation failed: {message}"".format(message=str(e)) ) self, name, filename, data, meta, validate_checksum, use_import=False, ""Importing image was requested but the cloud does not "" ""support the image import method."" ) valid = checksum == md5 or checksum == sha256 self.log.debug(""Deleting failed upload of image %s"", name) self, name, filename, data, wait, timeout, meta, **image_kwargs, ): ""The cloud {cloud} is configured to use tasks for image "" ""upload, but no object-store service is available. "" ""Aborting."".format(cloud=self._connection.config.name) ) container, name, filename, md5=md5, sha256=sha256, **{ 'content-type': 'application/octet-stream', 'x-delete-after': str(24 * 60 * 60), }, ) task_args = { 'type': 'import', 'input': { 'import_from': f'{container}/{name}', 'image_properties': {'name': name}, }, } task=glance_task, status='success', wait=timeout ) glance_task.id, image_id, (time.time() - start), ) message=e.message ), extra_data=glance_task, ) def download_image( self, image, stream=False, output=None, chunk_size=1024 ): instance allowing you to iterate over the response data stream instead of storing its entire contents in memory. See :meth:`requests.Response.iter_content` for more details. *NOTE*: If you do not consume the entirety of the response you must explicitly call :meth:`requests.Response.close` or otherwise risk inefficiencies with the ``requests`` library's handling of connections. When ``False``, return the entire contents of the response. self, stream=stream, output=output, chunk_size=chunk_size, ) return self._find( _image.Image, name_or_id, ignore_missing=ignore_missing, ) self._delete( _member.Member, member_id=member_id, image_id=image_id, ignore_missing=ignore_missing, ) return self._find( _member.Member, name_or_id, image_id=image_id, ignore_missing=ignore_missing, ) return self._get( _member.Member, member_id=member_id, image_id=image_id ) return self._update( _member.Member, member_id=member_id, image_id=image_id, **attrs, ) def create_metadef_resource_type_association( self, metadef_namespace, **attrs, ): **attrs, ) def delete_metadef_resource_type_association( self, metadef_resource_type, metadef_namespace, ignore_missing=True, ): **query, ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/images', ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/image', ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/members', ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/member', ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/tasks', ) return self._get( _schema.Schema, requires_id=False, base_path='/schemas/task', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/namespace', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/namespaces', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/resource_type', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/resource_types', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/object', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/objects', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/property', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/properties', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/tag', ) return self._get( _metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/tags', ) def wait_for_task( self, task, status='success', failures=None, interval=2, wait=120, ): name=name, status=status ) timeout=wait, message=msg, wait=interval ): name=name, status=status ) ) task_args = {'input': task.input, 'type': task.type} name=name, status=new_status ) ) self.log.debug( 'Still waiting for resource %s to reach state %s, ' 'current state is %s', name, status, new_status, )"," ""task"": _task.Task """"""Create image resource from attributes """""" :param image: The value can be the ID of a image or a :param method: Method to use for importing the image. Not all deployments support all methods. One of: ``glance-direct`` (default), ``web-download``, ``glance-download``, or ``copy-image``. Use of ``glance-direct`` requires the image be first staged. :param uri: Required only if using the web-download import method. :param remote_region: The remote glance region to download the image from when using glance-direct. :param remote_image_id: The ID of the image of to import from the remote glance when using glance-direct. :param remote_service_interface: The remote glance service interface to use when uding glance-download :param store: Used when enabled_backends is activated in glance. The value can be the id of a store or a :param stores: List of stores to be used when enabled_backends is activated in glance. List values can be the id of a store or a :param all_stores: Upload to all available stores. Mutually exclusive with ``store`` and ``stores``. :param all_stores_must_succeed: When set to True, if an error occurs during the upload in at least one store, the worfklow fails, the data is deleted from stores where copying is done (not staging), and the state of the image is unchanged. When set to False, the ""all_stores is mutually exclusive with "" ""store and stores"" raise exceptions.SDKException('Image stage is only possible for ' 'images in the queued state.' ' Current state is {status}' .format(status=image.status)) def upload_image(self, container_format=None, disk_format=None, data=None, **attrs): This method is deprecated - and also doesn't work very well. Please stop using it immediately and switch to `create_image`. ""Both container_format and disk_format are required"") img = self._create(_image.Image, disk_format=disk_format, container_format=container_format, **attrs) self, name, filename=None, data=None, meta=None, wait=False, timeout=None, validate_checksum=True, **kwargs ""The Glance Task API and Import API are"" "" mutually exclusive. Either disable"" "" image_api_use_tasks in config, or"" "" do not request using import"") name, filename, data=data, meta=meta, wait=wait, timeout=timeout, **kwargs) name, filename, data=data, meta=meta, **kwargs) ""Image creation failed: {message}"".format(message=str(e))) self, name, filename, data, meta, validate_checksum, use_import=False, ""Importing image was requested but the cloud does not"" "" support the image import method."") valid = (checksum == md5 or checksum == sha256) self.log.debug( ""Deleting failed upload of image %s"", name) self, name, filename, data, wait, timeout, meta, **image_kwargs): ""The cloud {cloud} is configured to use tasks for image"" "" upload, but no object-store service is available."" "" Aborting."".format(cloud=self._connection.config.name)) container, name, filename, md5=md5, sha256=sha256, **{'content-type': 'application/octet-stream', 'x-delete-after': str(24 * 60 * 60)}) task_args = dict( type='import', input=dict( import_from='{container}/{name}'.format( container=container, name=name), image_properties=dict(name=name))) task=glance_task, status='success', wait=timeout) glance_task.id, image_id, (time.time() - start)) message=e.message), extra_data=glance_task) def download_image(self, image, stream=False, output=None, chunk_size=1024): instance allowing you to iterate over the response data stream instead of storing its entire contents in memory. See :meth:`requests.Response.iter_content` for more details. *NOTE*: If you do not consume the entirety of the response you must explicitly call :meth:`requests.Response.close` or otherwise risk inefficiencies with the ``requests`` library's handling of connections. When ``False``, return the entire contents of the response. self, stream=stream, output=output, chunk_size=chunk_size) return self._find(_image.Image, name_or_id, ignore_missing=ignore_missing) self._delete(_member.Member, member_id=member_id, image_id=image_id, ignore_missing=ignore_missing) return self._find(_member.Member, name_or_id, image_id=image_id, ignore_missing=ignore_missing) return self._get(_member.Member, member_id=member_id, image_id=image_id) return self._update(_member.Member, member_id=member_id, image_id=image_id, **attrs) def create_metadef_resource_type_association(self, metadef_namespace, **attrs): **attrs) def delete_metadef_resource_type_association(self, metadef_resource_type, metadef_namespace, ignore_missing=True): **query) return self._get(_schema.Schema, requires_id=False, base_path='/schemas/images') return self._get(_schema.Schema, requires_id=False, base_path='/schemas/image') return self._get(_schema.Schema, requires_id=False, base_path='/schemas/members') return self._get(_schema.Schema, requires_id=False, base_path='/schemas/member') return self._get(_schema.Schema, requires_id=False, base_path='/schemas/tasks') return self._get(_schema.Schema, requires_id=False, base_path='/schemas/task') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/namespace') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/namespaces') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/resource_type') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/resource_types') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/object') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/objects') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/property') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/properties') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/tag') return self._get(_metadef_schema.MetadefSchema, requires_id=False, base_path='/schemas/metadefs/tags') def wait_for_task(self, task, status='success', failures=None, interval=2, wait=120): name=name, status=status) timeout=wait, message=msg, wait=interval): name=name, status=status)) task_args = dict(input=task.input, type=task.type) name=name, status=new_status)) self.log.debug('Still waiting for resource %s to reach state %s, ' 'current state is %s', name, status, new_status)",427,252
openstack%2Fopenstacksdk~master~If03254bf43652690fe3bbb106baa1da396247050,openstack/openstacksdk,master,If03254bf43652690fe3bbb106baa1da396247050,Add BGP Speakers and Peers to SDK,MERGED,2023-01-06 16:29:07.000000000,2023-01-28 13:16:26.000000000,2023-01-28 13:15:09.000000000,"[{'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2023-01-06 16:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/77d84839da2e05dd34f79d18d891e5428deb9e1c', 'message': 'Add BGP Speakers and Peers to SDK\n\nTODO: unit & functional tests\n\nChange-Id: If03254bf43652690fe3bbb106baa1da396247050\nRelated-Bug: #1999774\n'}, {'number': 2, 'created': '2023-01-10 19:08:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b41386c458371a450e12701e491823ec7b3e60ba', 'message': 'Add BGP Speakers and Peers to SDK\n\nTODO: unit & functional tests\n\nChange-Id: If03254bf43652690fe3bbb106baa1da396247050\nRelated-Bug: #1999774\n'}, {'number': 3, 'created': '2023-01-18 09:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/572e5e649373cb939cf65907f3ccac441bfc9813', 'message': 'Add BGP Speakers and Peers to SDK\n\nTODO: unit & functional tests\n\nChange-Id: If03254bf43652690fe3bbb106baa1da396247050\nRelated-Bug: #1999774\n'}, {'number': 4, 'created': '2023-01-19 13:51:06.000000000', 'files': ['doc/source/user/resources/network/index.rst', 'openstack/tests/unit/network/v2/test_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/tests/unit/network/v2/test_agent.py', 'openstack/tests/unit/network/v2/test_bgp_peer.py', 'openstack/network/v2/agent.py', 'doc/source/user/resources/network/v2/bgp_speaker.rst', 'doc/source/user/resources/network/v2/bgp_peer.rst', 'openstack/tests/unit/network/v2/test_bgp_speaker.py', 'doc/source/user/proxies/network.rst', 'openstack/network/v2/bgp_speaker.py', 'releasenotes/notes/network_add_bgp_resources-c182dc2873d6db18.yaml', 'openstack/network/v2/bgp_peer.py', 'openstack/tests/functional/network/v2/test_bgp.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b8038e6535d9c2f483829ea3a3213fe3559b6f97', 'message': 'Add BGP Speakers and Peers to SDK\n\nChange-Id: If03254bf43652690fe3bbb106baa1da396247050\nRelated-Bug: #1999774\n'}]",8,869485,b8038e6535d9c2f483829ea3a3213fe3559b6f97,21,5,4,8313,,,0,"Add BGP Speakers and Peers to SDK

Change-Id: If03254bf43652690fe3bbb106baa1da396247050
Related-Bug: #1999774
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/85/869485/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/network/v2/_proxy.py', 'openstack/network/v2/bgp_speaker.py', 'openstack/network/v2/bgp_peer.py']",3,77d84839da2e05dd34f79d18d891e5428deb9e1c,bug/1999774,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from openstack import resource class BgpPeer(resource.Resource): resource_key = 'bgp-peer' resources_key = 'bgp-peers' base_path = '/bgp-peers' _allow_unknown_attrs_in_body = True # capabilities allow_create = True allow_fetch = True allow_commit = True allow_delete = True allow_list = True # Properties #: The Id of the BGP Peer id = resource.Body('id') #: The BGP Peer's name. name = resource.Body('name') #: The ID of the project that owns the BGP Peer project_id = resource.Body('project_id', alias='tenant_id') #: Tenant_id (deprecated attribute). tenant_id = resource.Body('tenant_id', deprecated=True) #: The authentication type for the BGP Peer, can be none or md5. #: none by default. auth_type = resource.Body('auth_type') #: The remote Autonomous System number of the BGP Peer. remote_as = resource.Body('remote_as') #: The ip address of the Peer. peer_ip = resource.Body('peer_ip') ",,273,0
openstack%2Fansible-collections-openstack~master~I72dce1278a7623d4f68cabcceafcdfefda900195,openstack/ansible-collections-openstack,master,I72dce1278a7623d4f68cabcceafcdfefda900195,"Refactored identity_group{,_info} modules",MERGED,2023-01-13 09:56:44.000000000,2023-01-28 13:12:59.000000000,2023-01-28 13:12:59.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-13 09:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e13ef4ce0b7812b7fe444f7e7419e4485128ca24', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 2, 'created': '2023-01-13 10:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b9703c6f95245a731ab835e425c8a8c19e050fab', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 3, 'created': '2023-01-13 12:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/20b4a7156371b265a1c394f3f77e0392208f883d', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 4, 'created': '2023-01-13 20:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0c1dd66c2426379a837b014fe04c5dea99474ce2', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 5, 'created': '2023-01-14 08:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/86f0571cf156418315f9bb31d87036459ce28a19', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 6, 'created': '2023-01-16 10:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6a380d88b480771481f748af0eed3b3ea256f0f4', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 7, 'created': '2023-01-16 13:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d26e36f367acaa6eecc7478483f1a33c4b4e47ad', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 8, 'created': '2023-01-16 18:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b78df51272bf40aedfcded839e96f9e10d51872d', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 9, 'created': '2023-01-16 20:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4bc1e10943928445afcc2c379b6a7b9eb45644d6', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 10, 'created': '2023-01-17 16:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/42443c4e0f174da2f94a4318f3b908b25f9cf39d', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 11, 'created': '2023-01-19 19:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/f3c7a9a2110a003809f4b50662dcb844b9cf28e5', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}, {'number': 12, 'created': '2023-01-26 12:34:42.000000000', 'files': ['ci/roles/identity_group_info/tasks/main.yml', 'plugins/modules/identity_group.py', 'ci/roles/identity_group/tasks/main.yml', 'plugins/modules/identity_group_info.py', 'ci/run-collection.yml', 'ci/roles/identity_group/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/85349908408afd155cfc66024920ba1b2c271665', 'message': 'Refactored identity_group{,_info} modules\n\nChange-Id: I72dce1278a7623d4f68cabcceafcdfefda900195\n'}]",1,870070,85349908408afd155cfc66024920ba1b2c271665,31,3,12,32962,,,0,"Refactored identity_group{,_info} modules

Change-Id: I72dce1278a7623d4f68cabcceafcdfefda900195
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/70/870070/12 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/identity_group_info/tasks/main.yml', 'plugins/modules/identity_group.py', 'ci/roles/identity_group/tasks/main.yml', 'plugins/modules/identity_group_info.py', 'ci/roles/identity_group/defaults/main.yml', 'ci/run-collection.yml']",6,e13ef4ce0b7812b7fe444f7e7419e4485128ca24,identity_group,," - { role: identity_group_info, tags: identity_group_info }",325,363
openstack%2Fansible-collections-openstack~master~Idf48f10e66a5651fa4693774eecd2c8683703082,openstack/ansible-collections-openstack,master,Idf48f10e66a5651fa4693774eecd2c8683703082,"Refactored identity_domain{,_info} modules",MERGED,2023-01-13 08:47:14.000000000,2023-01-28 13:12:58.000000000,2023-01-28 13:12:58.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-13 08:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4415aaabde8924df98d4943b262a7884baa91750', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 2, 'created': '2023-01-13 09:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/3aaf9dfb20bcc9e82950a7f21adc9bbc8a295a9f', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 3, 'created': '2023-01-13 09:25:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a00354c1e02475dd998b5cfe1c4adac463dbbc4b', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 4, 'created': '2023-01-13 11:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/d12c489f2fe07dd2c3971b4374fbf8cbb08a39b0', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 5, 'created': '2023-01-13 12:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4a63d4537d811f9010d964286126b78abeac2f0d', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 6, 'created': '2023-01-13 20:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/13348dc2eb4e2b97d12d72a70dbf2830ac926a48', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 7, 'created': '2023-01-14 08:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/98fde23c51231526762e3305054a9f49b298f973', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 8, 'created': '2023-01-16 10:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a4bb66f57cab50a89f078e9ccc04e274669140f1', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 9, 'created': '2023-01-16 12:59:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/6710f4b0b837bbaf7d053ce613d280d7d7042297', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 10, 'created': '2023-01-16 18:47:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0246f6d8bc923cb0fb6c15d20aae57b7fdf6b552', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 11, 'created': '2023-01-16 20:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/7868c587c2f64ea36a5d3cc8a420ca32e025bc3d', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 12, 'created': '2023-01-17 16:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8550ab3fdcb2c455d7a11ad210433eef99c89c52', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 13, 'created': '2023-01-19 19:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4cd67cb513aa88b1f9dc5a5b4273144298cf312c', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}, {'number': 14, 'created': '2023-01-26 12:34:13.000000000', 'files': ['ci/roles/keystone_idp/tasks/main.yml', 'ci/roles/identity_domain/tasks/main.yml', 'ci/roles/user_role/tasks/main.yaml', 'plugins/modules/identity_domain.py', 'ci/roles/keystone_domain/tasks/main.yml', 'ci/roles/keystone_domain/defaults/main.yml', 'ci/run-collection.yml', 'ci/roles/keystone_federation_protocol/tasks/main.yml', 'ci/roles/identity_domain_info/defaults/main.yml', 'ci/roles/identity_domain_info/tasks/main.yml', 'plugins/modules/identity_domain_info.py', 'ci/roles/identity_group/tasks/main.yml', 'ci/roles/identity_domain/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/16a8a9e5d4444278ca5c81be091de55e30f4ad81', 'message': 'Refactored identity_domain{,_info} modules\n\nChange-Id: Idf48f10e66a5651fa4693774eecd2c8683703082\n'}]",12,870047,16a8a9e5d4444278ca5c81be091de55e30f4ad81,36,5,14,32962,,,0,"Refactored identity_domain{,_info} modules

Change-Id: Idf48f10e66a5651fa4693774eecd2c8683703082
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/47/870047/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci/roles/identity_domain/tasks/main.yml', 'plugins/modules/identity_domain.py', 'ci/roles/keystone_domain/tasks/main.yml', 'ci/roles/identity_domain_info/defaults/main.yml', 'ci/roles/identity_domain_info/tasks/main.yml', 'plugins/modules/identity_domain_info.py', 'ci/roles/keystone_domain/defaults/main.yml', 'ci/run-collection.yml', 'ci/roles/identity_domain/defaults/main.yml']",9,4415aaabde8924df98d4943b262a7884baa91750,identity_domain,expected_fields: - description - id - is_enabled - name - links ,,283,326
openstack%2Fpython-troveclient~master~Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd,openstack/python-troveclient,master,Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd,Switch to 2023.1 Python3 unit tests and generic template name,MERGED,2022-09-09 15:15:31.000000000,2023-01-28 09:34:02.000000000,2023-01-28 09:32:29.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-09-09 15:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/63f75586d9061491c15ec79d8da3328f2f404862', 'message': 'Add Python3 antelope unit tests\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd\n'}, {'number': 2, 'created': '2022-09-14 09:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/35d1ffccd7e4382b242d4acd1e8c886f2b25865c', 'message': 'Switch to 2023.1 Python3 unit tests and generic template name\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope. Also,\nupdating the template name to generic one.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd\n'}, {'number': 3, 'created': '2023-01-28 09:14:29.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/5a20908cd0852a98fdbf5355902366780ed4961f', 'message': 'Switch to 2023.1 Python3 unit tests and generic template name\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope. Also,\nupdating the template name to generic one.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd\n'}]",1,856818,5a20908cd0852a98fdbf5355902366780ed4961f,16,3,3,22816,,,0,"Switch to 2023.1 Python3 unit tests and generic template name

This is an automatically generated patch to ensure unit testing
is in place for all the of the tested runtimes for antelope. Also,
updating the template name to generic one.

See also the PTI in governance [1].

[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html

Change-Id: Ied8fb9f8decc7322cd3ecea3a9e875e98bf63bcd
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/18/856818/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,63f75586d9061491c15ec79d8da3328f2f404862,add-antelope-python-jobtemplates, - openstack-python3-antelope-jobs, - openstack-python3-zed-jobs,1,1
openstack%2Fpython-troveclient~master~Idb2a9d9dcc5a73e15e5cbab165b2b629a8b26afe,openstack/python-troveclient,master,Idb2a9d9dcc5a73e15e5cbab165b2b629a8b26afe,Fixing tests with tox 4.2.6,MERGED,2023-01-28 06:37:53.000000000,2023-01-28 08:33:12.000000000,2023-01-28 08:31:10.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2023-01-28 06:37:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/c96a2af8b0d99f89364184569bf44325e823c9e8', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\n\nChange-Id: Idb2a9d9dcc5a73e15e5cbab165b2b629a8b26afe\n'}, {'number': 2, 'created': '2023-01-28 07:54:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/c715b66b53506d499db3b266b4407a580548153b', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\n\nChange-Id: Idb2a9d9dcc5a73e15e5cbab165b2b629a8b26afe\n'}]",0,872062,c715b66b53506d499db3b266b4407a580548153b,9,2,2,26285,,,0,"Fixing tests with tox 4.2.6

Remove basepython from testenv

Change-Id: Idb2a9d9dcc5a73e15e5cbab165b2b629a8b26afe
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/62/872062/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c96a2af8b0d99f89364184569bf44325e823c9e8,,,basepython = python3,0,1
openstack%2Ftrove-dashboard~master~I140fc14944522000a808fa6292baa5c726b2dccd,openstack/trove-dashboard,master,I140fc14944522000a808fa6292baa5c726b2dccd,Fixing tests with tox 4.2.6,MERGED,2023-01-28 06:51:02.000000000,2023-01-28 08:27:36.000000000,2023-01-28 08:25:44.000000000,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2023-01-28 06:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/a6117607c2da2f3de510acfe9d76783b23ec2fde', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\n\nChange-Id: I140fc14944522000a808fa6292baa5c726b2dccd\n'}, {'number': 2, 'created': '2023-01-28 07:57:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/e1418f22949f44a650655b5f803431ac35968642', 'message': 'Fixing tests with tox 4.2.6\n\nRemove basepython from testenv\n\nChange-Id: I140fc14944522000a808fa6292baa5c726b2dccd\n'}]",0,872064,e1418f22949f44a650655b5f803431ac35968642,9,2,2,26285,,,0,"Fixing tests with tox 4.2.6

Remove basepython from testenv

Change-Id: I140fc14944522000a808fa6292baa5c726b2dccd
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/64/872064/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a6117607c2da2f3de510acfe9d76783b23ec2fde,,,basepython = python3,0,1
openstack%2Fcinder~master~Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d,openstack/cinder,master,Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d,cinder-backup: use the same backup backend host for incremental backups,MERGED,2022-10-17 04:47:38.000000000,2023-01-28 05:05:45.000000000,2023-01-27 16:04:44.000000000,"[{'_account_id': 7}, {'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 5997}, {'_account_id': 9236}, {'_account_id': 13671}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 31779}, {'_account_id': 35075}]","[{'number': 1, 'created': '2022-10-17 04:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3eda6512f6c83d9fd1d81ed35d589261c63a52e', 'message': 'cinder-backup: use the same backup backend host for incremental backups\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n'}, {'number': 2, 'created': '2022-10-17 17:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/13a35655f11bd8254618a67388e46ba9c049e153', 'message': 'cinder-backup: use the same backup backend host for incremental backups\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n'}, {'number': 3, 'created': '2022-10-20 05:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f65cd82d7ec9275fe0b4c53e45e963d48687ee9', 'message': 'cinder-backup: use the same backup backend host for incremental backups\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n'}, {'number': 4, 'created': '2022-10-21 20:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3caa8c4308e38435cb6f8cff949c68f0e9a73d2a', 'message': 'cinder-backup: use the same backup backend host for incremental backups\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n'}, {'number': 5, 'created': '2022-10-22 04:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ffffd61306e4143861953d8f38ff705403e3cc88', 'message': 'cinder-backup: use the same backup backend host for incremental backups\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n'}, {'number': 6, 'created': '2023-01-23 15:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e872235778998c93f2646637efec2d548e0ebb14', 'message': ""cinder-backup: use the same backup backend host for incremental backups\n\nIncremental backups only work if there's a previous backup to base it on. With\nWith the posix driver, this means there needs to be a previous backup on the\nsame host where the incremental backup is created.\n\nThis patch ensures that an incremental backup is scheduled on the host that\nthat contains the base backup being used for the increment. Previously we\nwere relying on luck for this and much of the time an incremental backup would\nfail due for want of a base backup.\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n""}, {'number': 7, 'created': '2023-01-23 15:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14cef94b21c7a959bbe048ea9c0e632d4032f8ac', 'message': ""cinder-backup: use the same backup backend host for incremental backups\n\nIncremental backups only work if there's a previous backup to base\nit on. With the posix driver, this means there needs to be a previous\nbackup on the same host where the incremental backup is created.\n\nThis patch ensures that an incremental backup is scheduled on the\nhost that that contains the base backup being used for the increment.\nPreviously we were relying on luck for this and much of the time an\nincremental backup would fail due for want of a base backup.\n\nBug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n""}, {'number': 8, 'created': '2023-01-23 19:31:04.000000000', 'files': ['cinder/tests/unit/api/contrib/test_backups.py', 'cinder/tests/unit/backup/test_backup_messages.py', 'cinder/backup/api.py', 'releasenotes/notes/bug-1952805-cinder-schedules-incremental-backups-on-the-wrong-node-b20b0c137f33ef03.yaml', 'cinder/scheduler/manager.py', 'cinder/tests/unit/api/v2/fakes.py', 'cinder/tests/unit/scheduler/test_scheduler.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/73c0d73aba1855edb774d69ae940a1b53dc975e0', 'message': ""cinder-backup: use the same backup backend host for incremental backups\n\nIncremental backups only work if there's a previous backup to base\nit on. With the posix driver, this means there needs to be a previous\nbackup on the same host where the incremental backup is created.\n\nThis patch ensures that an incremental backup is scheduled on the\nhost that that contains the base backup being used for the increment.\nPreviously we were relying on luck for this and much of the time an\nincremental backup would fail due for want of a base backup.\n\nCloses-bug: 1952805\nChange-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d\n""}]",30,861566,73c0d73aba1855edb774d69ae940a1b53dc975e0,172,10,8,12932,,,0,"cinder-backup: use the same backup backend host for incremental backups

Incremental backups only work if there's a previous backup to base
it on. With the posix driver, this means there needs to be a previous
backup on the same host where the incremental backup is created.

This patch ensures that an incremental backup is scheduled on the
host that that contains the base backup being used for the increment.
Previously we were relying on luck for this and much of the time an
incremental backup would fail due for want of a base backup.

Closes-bug: 1952805
Change-Id: Id239b4150b1c8e9f4bf32f2ef867fdffbe84f96d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/861566/7 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/backup/api.py', 'cinder/scheduler/manager.py', 'cinder/tests/unit/backup/test_backup.py']",3,d3eda6512f6c83d9fd1d81ed35d589261c63a52e,twonodebackup," def test_create_backup_set_parent_host(self, mock_isdir, mock_open, mock_chown, mock_backup_device, mock_brick): vol_size = 1 vol_id = self._create_volume_db_entry(size=vol_size) backup = self._create_backup_db_entry(volume_id=vol_id) parent_backup = self._create_backup_db_entry(size=vol_size) parent_backup.host = 'parenthost' self.override_config('backup_driver', 'cinder.backup.drivers.posix.PosixBackupDriver') with mock.patch.object(self.backup_mgr, 'service') as \ mock_service: mock_service.return_value.backup.return_value = ( {'parent_id': parent_backup.id}) with mock.patch.object(self.backup_mgr, '_detach_device'): device_path = '/fake/disk/path/' attach_info = {'device': {'path': device_path}} mock_attach_device = self.mock_object(self.backup_mgr, '_attach_device') mock_attach_device.return_value = attach_info properties = {} mock_brick.return_value = properties mock_open.return_value = open('/dev/null', 'rb') mock_brick.return_value = properties self.backup_mgr.create_backup(self.ctxt, backup) self.backup_mgr.continue_backup(self.ctxt, backup, mock_backup_device) backup = db.backup_get(self.ctxt, backup.id) self.assertEqual(fields.BackupStatus.AVAILABLE, backup.status) self.assertEqual(vol_size, backup.size) self.assertEqual(parent_backup.host, backup.host) @mock.patch('cinder.volume.volume_utils.brick_get_connector_properties') @mock.patch('cinder.volume.rpcapi.VolumeAPI.get_backup_device') @mock.patch('cinder.utils.temporary_chown') @mock.patch('builtins.open') @mock.patch.object(os.path, 'isdir', return_value=True) parent_backup.host = 'parenthost' self.assertIsNone(backup.host)",,58,3
openstack%2Ftripleo-ci~master~I89ce291546a68606c1eab1bb9379a21836773c70,openstack/tripleo-ci,master,I89ce291546a68606c1eab1bb9379a21836773c70,Allow to call the discover-latest-image role,MERGED,2023-01-25 12:56:48.000000000,2023-01-28 04:37:41.000000000,2023-01-28 04:37:41.000000000,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 14611}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 12:56:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/30e4f0850c3ad750145a8fd6146628ca40bebe60', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 2, 'created': '2023-01-25 13:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/867819fa45b978381c3c9e6b696de8e86438ddc4', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 3, 'created': '2023-01-25 23:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fa1c03abec61b757f808bacf3802ed47ef6402c5', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 4, 'created': '2023-01-26 02:12:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7792599ce7257d47fcdab96d11445cd91c8657ef', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 5, 'created': '2023-01-26 09:38:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/74fd8ec10bdb9790b215705c56c4670053eb220f', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 6, 'created': '2023-01-26 11:00:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7009ed42089a9ffc7ef049b2d7db60a0540d8824', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 7, 'created': '2023-01-26 12:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d211ff7e60d07df7fbf78786f3dd8286a1364e9f', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 8, 'created': '2023-01-26 13:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ab0b66d70dbff88803a656e152fea3efd1e0e104', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nIt adds 3 new parameters:\n+tripleo_ci_discover_latest (boolean): whether or not discover latest\nimage\n+tripleo_ci_discover_base_url: base_url passed down to the role\n+tripleo_ci_discover_qcow_prefix: qcow_prefix passed down to the role\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 9, 'created': '2023-01-26 15:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f9322109b5169e87192fc76f990d242b1d0381e5', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nIt adds 3 new parameters:\n+tripleo_ci_discover_latest (boolean): whether or not discover latest\nimage\n+tripleo_ci_discover_base_url: base_url passed down to the role\n+tripleo_ci_discover_qcow_prefix: qcow_prefix passed down to the role\n\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}, {'number': 10, 'created': '2023-01-26 16:27:14.000000000', 'files': ['roles/oooci-build-images/tasks/main.yaml', 'roles/oooci-build-images/defaults/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6df518c8a98bfb73d585c6f6e238f1c2ad9053f1', 'message': 'Allow to call the discover-latest-image role\n\nIt comes from oooq-extras:\nhttps://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image\n\nCalling it will allow to correct some issues we may face when the image\nchanges on a daily basis.\n\nIt adds 3 new parameters:\n+tripleo_ci_discover_latest (boolean): whether or not discover latest\nimage\n+tripleo_ci_discover_base_url: base_url passed down to the role\n+tripleo_ci_discover_qcow_prefix: qcow_prefix passed down to the role\n\nDepends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/871833\nChange-Id: I89ce291546a68606c1eab1bb9379a21836773c70\n'}]",4,871712,6df518c8a98bfb73d585c6f6e238f1c2ad9053f1,26,4,10,28223,,,0,"Allow to call the discover-latest-image role

It comes from oooq-extras:
https://opendev.org/openstack/tripleo-quickstart-extras/src/branch/master/roles/discover-latest-image

Calling it will allow to correct some issues we may face when the image
changes on a daily basis.

It adds 3 new parameters:
+tripleo_ci_discover_latest (boolean): whether or not discover latest
image
+tripleo_ci_discover_base_url: base_url passed down to the role
+tripleo_ci_discover_qcow_prefix: qcow_prefix passed down to the role

Depends-On: https://review.opendev.org/c/openstack/tripleo-quickstart-extras/+/871833
Change-Id: I89ce291546a68606c1eab1bb9379a21836773c70
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/12/871712/9 && git format-patch -1 --stdout FETCH_HEAD,['roles/oooci-build-images/tasks/main.yaml'],1,30e4f0850c3ad750145a8fd6146628ca40bebe60,discover-image,"- name: Get the latest image on demand when: - get_latest_image| default(false) | bool block: - name: Find latest image name import_role: name: discover-latest-image - name: Set needed facts set_fact: cacheable: true tripleo_image_source: ""{{ discovered_image_url }}"" ",,12,0
openstack%2Ftripleo-quickstart-extras~master~I264bad88b2f7bbc8f0b6cc295ca92498fe6e3d49,openstack/tripleo-quickstart-extras,master,I264bad88b2f7bbc8f0b6cc295ca92498fe6e3d49,Correct how the image is matched on the httpd index,MERGED,2023-01-26 16:25:17.000000000,2023-01-28 04:37:39.000000000,2023-01-28 04:37:39.000000000,"[{'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 14611}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 16:25:17.000000000', 'files': ['roles/discover-latest-image/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4f6efc3da905d7bac67c9e7f91773025fd1aaaf1', 'message': 'Correct how the image is matched on the httpd index\n\nUntil now, the regexp was trying to match content from the link text,\nnot href. This may lead to issue depending on the remote httpd\nconfiguration, since it may truncate the link text. Matching the link\nhref is therefore safer.\n\nChange-Id: I264bad88b2f7bbc8f0b6cc295ca92498fe6e3d49\n'}]",5,871833,4f6efc3da905d7bac67c9e7f91773025fd1aaaf1,14,5,1,28223,,,0,"Correct how the image is matched on the httpd index

Until now, the regexp was trying to match content from the link text,
not href. This may lead to issue depending on the remote httpd
configuration, since it may truncate the link text. Matching the link
href is therefore safer.

Change-Id: I264bad88b2f7bbc8f0b6cc295ca92498fe6e3d49
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/33/871833/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/discover-latest-image/tasks/main.yaml'],1,4f6efc3da905d7bac67c9e7f91773025fd1aaaf1,discover-latest-image/correct-sed," sed -n ""/qcow2/ s/.*href=\""\({{ qcow_prefix }}.*.qcow2\)\"">.*/\1/p"" {{ tempfile.path }} | tail -1"," sed -n ""/qcow2/ s/.*\({{ qcow_prefix }}.*.qcow2\)<\/a>.*/\1/p"" {{ tempfile.path }} | tail -1",1,1
openstack%2Fdesignate~master~I167c204b6a0f537ceb5b3b28e32dfbc7c617cff2,openstack/designate,master,I167c204b6a0f537ceb5b3b28e32dfbc7c617cff2,Imported Translations from Zanata,MERGED,2023-01-27 04:09:25.000000000,2023-01-28 03:23:37.000000000,2023-01-28 03:22:28.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-01-27 04:09:25.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/designate/commit/a9cf887da11f18dbda7c6c1332d430680a9edc14', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I167c204b6a0f537ceb5b3b28e32dfbc7c617cff2\n'}]",0,871936,a9cf887da11f18dbda7c6c1332d430680a9edc14,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I167c204b6a0f537ceb5b3b28e32dfbc7c617cff2
",git fetch https://review.opendev.org/openstack/designate refs/changes/36/871936/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,a9cf887da11f18dbda7c6c1332d430680a9edc14,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-22 00:07+0000\n""""PO-Revision-Date: 2023-01-26 09:59+0000\n""msgid ""13.0.2"" msgstr ""13.0.2""msgid ""15.0.0.0rc1-31"" msgstr ""15.0.0.0rc1-31""""Designate has increased the minimum version of dnspython to 2.2.1 for the "" ""antelope (2023.1) release to reflect support for python 3.10."" msgstr """" ""Designate has increased the minimum version of dnspython to 2.2.1 for the "" ""Antelope (2023.1) release to reflect support for Python 3.10."" msgid """"msgid """" ""Workaround the use of an unassigned opcode(14) by Designate that fails "" ""validation when used with dnspython >= 2.3.0."" msgstr """" ""Workaround the use of an unassigned opcode(14) by Designate that fails "" ""validation when used with dnspython >= 2.3.0."" msgid ""`LP#2002950 <https://launchpad.net/bugs/2002950>`__"" msgstr ""`LP#2002950 <https://launchpad.net/bugs/2002950>`__"" ","""POT-Creation-Date: 2022-11-23 06:38+0000\n""""PO-Revision-Date: 2022-12-10 04:35+0000\n""msgid ""13.0.1-5"" msgstr ""13.0.1-5""msgid ""15.0.0.0rc1-23"" msgstr ""15.0.0.0rc1-23""",24,6
openstack%2Fzaqar~master~If6204796a34031551817191d0ea602011f60de9a,openstack/zaqar,master,If6204796a34031551817191d0ea602011f60de9a,Replace abc.abstractproperty with property and abc.abstractmethod,MERGED,2022-08-03 12:53:25.000000000,2023-01-28 03:12:11.000000000,2023-01-28 03:10:58.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-08-03 12:53:25.000000000', 'files': ['zaqar/storage/base.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c9c8a0e71713a52366e139eb6bce5c4ffbbc5195', 'message': 'Replace abc.abstractproperty with property and abc.abstractmethod\n\nReplace abc.abstractproperty with property and abc.abstractmethod,\nas abc.abstractproperty has been deprecated since python3.3[1]\n\n[1]https://docs.python.org/3.8/whatsnew/3.3.html?highlight=deprecated#abc\n\nChange-Id: If6204796a34031551817191d0ea602011f60de9a\n'}]",3,852018,c9c8a0e71713a52366e139eb6bce5c4ffbbc5195,12,2,1,28743,,,0,"Replace abc.abstractproperty with property and abc.abstractmethod

Replace abc.abstractproperty with property and abc.abstractmethod,
as abc.abstractproperty has been deprecated since python3.3[1]

[1]https://docs.python.org/3.8/whatsnew/3.3.html?highlight=deprecated#abc

Change-Id: If6204796a34031551817191d0ea602011f60de9a
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/18/852018/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/storage/base.py'],1,c9c8a0e71713a52366e139eb6bce5c4ffbbc5195,, @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod @property @abc.abstractmethod, @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty @abc.abstractproperty,18,9
openstack%2Fnova~master~Ibe14d2b223c737d82c217a74bc94e41603271a9d,openstack/nova,master,Ibe14d2b223c737d82c217a74bc94e41603271a9d,Add get_available_node_uuids() to virt driver,MERGED,2022-11-07 18:32:10.000000000,2023-01-28 03:06:45.000000000,2023-01-27 19:53:51.000000000,"[{'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eaba744be32112951a3e42c573c8d8c64e4c0f57', 'message': 'WIP Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nNOTE: This currently fails a test for a good(ish) reason. The test\ndeletes and re-creates a service and expects the node to be\nre-created with a new UUID. However, because we\'re returning a\nstable node uuid now, we fail to re-create the node with the same\nuuid in the database.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 2, 'created': '2023-01-09 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9992ffb96c9db316dc31b3c1be1fe955e422440', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 3, 'created': '2023-01-10 18:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9b36abca8425c90acc90821a858b2efae8c6a4c2', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 4, 'created': '2023-01-10 18:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf82ed768896232fc99e8f2b8b67977d0e661fab', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 5, 'created': '2023-01-10 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0716f395282e772d85c43dce16099fcdd4696971', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 6, 'created': '2023-01-10 19:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/813e328b2171e03e117f0a10c7ea2bf4d014e942', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 7, 'created': '2023-01-11 20:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e0c9ad47f1e1a6f9535848bf7965839ea310474', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}, {'number': 8, 'created': '2023-01-20 15:57:55.000000000', 'files': ['nova/tests/functional/libvirt/test_evacuate.py', 'nova/virt/ironic/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/virt/libvirt/host.py', 'nova/tests/functional/libvirt/base.py', 'nova/test.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/compute/test_resource_tracker.py', 'nova/virt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0caf24f308e754884b53b244f5b6228c9c2e4147', 'message': 'Add get_available_node_uuids() to virt driver\n\nThis adds a get_available_node_uuids() method to the virt driver\ninterface. This aims to eventually replace the nodename-based\ninterface, but currently provides an implementation that will work\nfor most drivers. Any driver that does not override this method\nwill get the locally-persistent UUID from nova.virt.node.\n\nIronic obviously needs to override this (which is easy), as well as\nthe fake driver because it supports multiple nodes for testing. The\nlibvirt driver overrides it only because we test multiple libvirt\ndriver instances on a single host and we need each instantiation\nof it to ""capture"" the UUID we have mocked out at the time it is\nstarted.\n\nChange-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d\n'}]",20,863917,0caf24f308e754884b53b244f5b6228c9c2e4147,41,3,8,4393,,,0,"Add get_available_node_uuids() to virt driver

This adds a get_available_node_uuids() method to the virt driver
interface. This aims to eventually replace the nodename-based
interface, but currently provides an implementation that will work
for most drivers. Any driver that does not override this method
will get the locally-persistent UUID from nova.virt.node.

Ironic obviously needs to override this (which is easy), as well as
the fake driver because it supports multiple nodes for testing. The
libvirt driver overrides it only because we test multiple libvirt
driver instances on a single host and we need each instantiation
of it to ""capture"" the UUID we have mocked out at the time it is
started.

Change-Id: Ibe14d2b223c737d82c217a74bc94e41603271a9d
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/863917/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_evacuate.py', 'nova/virt/ironic/driver.py', 'nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/tests/functional/libvirt/base.py', 'nova/virt/libvirt/host.py', 'nova/test.py', 'nova/tests/functional/libvirt/test_vpmem.py', 'nova/tests/functional/compute/test_resource_tracker.py', 'nova/virt/driver.py']",10,eaba744be32112951a3e42c573c8d8c64e4c0f57,bp/stable-compute-uuid,"import nova.virt.node def get_available_node_uuids(self, refresh=False): return [nova.virt.node.get_local_node_uuid()] ",,44,6
openstack%2Fgovernance~master~I7cbf8467920a1de0369bcd0f2fe9d432cb28775d,openstack/governance,master,I7cbf8467920a1de0369bcd0f2fe9d432cb28775d,Add Axel to Mistral project DPL list,MERGED,2023-01-20 16:23:53.000000000,2023-01-28 01:55:50.000000000,2023-01-28 01:54:51.000000000,"[{'_account_id': 5314}, {'_account_id': 8556}, {'_account_id': 10342}, {'_account_id': 11292}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 35600}]","[{'number': 1, 'created': '2023-01-20 16:23:53.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/61e96461a9f8155b83d3972c53f7eb75b2cf5c52', 'message': ""Add Axel to Mistral project DPL list\n\nBased on Axel's mail [1] let's add him to the DPL list of Mistral, so\nthat Release Management tools recognise him.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-December/031417.html\n\nChange-Id: I7cbf8467920a1de0369bcd0f2fe9d432cb28775d\n""}]",1,871302,61e96461a9f8155b83d3972c53f7eb75b2cf5c52,15,8,1,17685,,,0,"Add Axel to Mistral project DPL list

Based on Axel's mail [1] let's add him to the DPL list of Mistral, so
that Release Management tools recognise him.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-December/031417.html

Change-Id: I7cbf8467920a1de0369bcd0f2fe9d432cb28775d
",git fetch https://review.opendev.org/openstack/governance refs/changes/02/871302/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,61e96461a9f8155b83d3972c53f7eb75b2cf5c52,formal-vote, - name: Axel Vanzaghi irc: avanzaghi email: axel.vanzaghi@axellink.fr,,3,0
openstack%2Fpython-zaqarclient~master~I113bb6dd90efe0f9b272a76939947bd913fe707f,openstack/python-zaqarclient,master,I113bb6dd90efe0f9b272a76939947bd913fe707f,Fix tox4 error,MERGED,2023-01-24 06:12:25.000000000,2023-01-28 01:52:25.000000000,2023-01-28 01:51:23.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-01-24 06:12:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/d78bf91ebcd73336f2cd47e38779a85921eebf49', 'message': 'Fix tox4 error\n\ntox.ini started failing with Tox4 which had some\nincompatible changes. One of them is changing\nwhitelist to allowlist. Other failure is due to\nthe skipsdist = True.\n\nFixing tox.ini for tox4 changes.\n\nChange-Id: I113bb6dd90efe0f9b272a76939947bd913fe707f\n'}]",1,871549,d78bf91ebcd73336f2cd47e38779a85921eebf49,10,3,1,8556,,,0,"Fix tox4 error

tox.ini started failing with Tox4 which had some
incompatible changes. One of them is changing
whitelist to allowlist. Other failure is due to
the skipsdist = True.

Fixing tox.ini for tox4 changes.

Change-Id: I113bb6dd90efe0f9b272a76939947bd913fe707f
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/49/871549/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d78bf91ebcd73336f2cd47e38779a85921eebf49,zaqar-gate-fix,Allowlist_externals = find,skipsdist = Truewhitelist_externals = find,1,2
openstack%2Fzaqar-ui~master~I49523d1e35c85ab34f17c85e873bbe3744629c64,openstack/zaqar-ui,master,I49523d1e35c85ab34f17c85e873bbe3744629c64,Fix tox4 error,MERGED,2023-01-24 06:10:18.000000000,2023-01-28 01:48:16.000000000,2023-01-28 01:47:12.000000000,"[{'_account_id': 8846}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-01-24 06:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/9876e5dbca653c4084baa1411d8cd06e486930e8', 'message': 'Fix tox4 error\n\ntox.ini started failing with Tox4 which had some\nincompatible changes. One of them is changing\nwhitelist to allowlist. Other failure is due to\nthe skipsdist = True.\n\nFixing tox.ini for tox4 changes.\n\nChange-Id: I49523d1e35c85ab34f17c85e873bbe3744629c64\n'}, {'number': 2, 'created': '2023-01-24 06:25:03.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/zaqar-ui/commit/c10a993d571ca034f6647c0ed9551f91268034fa', 'message': 'Fix tox4 error\n\ntox.ini started failing with Tox4 which had some\nincompatible changes. One of them is changing\nwhitelist to allowlist. Other failure is due to\nthe skipsdist = True.\n\nAlso, remove basepython definition from tox.ini. Tox 4.2.6\nfailing as testenv:functional{,-py38,-py39,-py310}] format\nis leads to missing interpreter error.\n\nChange-Id: I49523d1e35c85ab34f17c85e873bbe3744629c64\n'}]",0,871548,c10a993d571ca034f6647c0ed9551f91268034fa,13,4,2,8556,,,0,"Fix tox4 error

tox.ini started failing with Tox4 which had some
incompatible changes. One of them is changing
whitelist to allowlist. Other failure is due to
the skipsdist = True.

Also, remove basepython definition from tox.ini. Tox 4.2.6
failing as testenv:functional{,-py38,-py39,-py310}] format
is leads to missing interpreter error.

Change-Id: I49523d1e35c85ab34f17c85e873bbe3744629c64
",git fetch https://review.opendev.org/openstack/zaqar-ui refs/changes/48/871548/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9876e5dbca653c4084baa1411d8cd06e486930e8,zaqar-gate-fix,Allowlist_externals =Allowlist_externals =Allowlist_externals =,skipsdist = Truewhitelist_externals =whitelist_externals =whitelist_externals =,3,4
openstack%2Fswift~master~Iefea826ed3ae766163ba0bccb9ace521ada0ae0b,openstack/swift,master,Iefea826ed3ae766163ba0bccb9ace521ada0ae0b,Add swift-ring-info utility,NEW,2022-09-12 20:57:05.000000000,2023-01-28 01:36:04.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-12 20:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d6dcd189a048dec5854a5aa395cc560391e605cc', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 2, 'created': '2022-09-14 18:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8cc6632a3d7ef3f7ac0c1406a1a483bf3c83fd1c', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 3, 'created': '2022-09-14 20:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8f0f5beccbfe3fc59b1a068c837520186acf85ad', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 4, 'created': '2022-09-26 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/05ac31d5e47e8748828bbf01c95dd0edbec46443', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 5, 'created': '2022-10-21 05:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c79a2d613f15af5582a48c8400153a8d82906772', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 6, 'created': '2022-11-11 00:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2536f846daeebf15cba37eeeb03f398b67b69978', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 7, 'created': '2022-11-23 01:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/93b38b8a3c8940012727af6bd0bd33f40751accd', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}, {'number': 8, 'created': '2022-12-01 00:11:29.000000000', 'files': ['swift/common/ring/io.py', 'swift/cli/ring_info.py', 'setup.cfg', 'test/unit/common/ring/test_io.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/9427b96d81e7fa3b58ebba37ffeb084c62a6b3b0', 'message': 'Add swift-ring-info utility\n\nChange-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b\n'}]",4,857234,9427b96d81e7fa3b58ebba37ffeb084c62a6b3b0,26,2,8,15343,,,0,"Add swift-ring-info utility

Change-Id: Iefea826ed3ae766163ba0bccb9ace521ada0ae0b
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/857234/8 && git format-patch -1 --stdout FETCH_HEAD,"['swift/cli/ring_info.py', 'setup.cfg']",2,d6dcd189a048dec5854a5aa395cc560391e605cc,ring-v2, swift-ring-info = swift.cli.ring_info:main,,61,0
openstack%2Fopenstack-ansible~stable%2Fyoga~Icdc4fe78bd7bfda34a5f28874242c22f2f441f59,openstack/openstack-ansible,stable/yoga,Icdc4fe78bd7bfda34a5f28874242c22f2f441f59,Bump OSA for stable/yoga to cover CVE-2022-47951,MERGED,2023-01-26 16:41:37.000000000,2023-01-28 00:44:35.000000000,2023-01-28 00:43:21.000000000,"[{'_account_id': 13095}, {'_account_id': 16011}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 16:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7e2e52064ed60acf1cc1bcbaa14f2808cffa8761', 'message': ' Bump OSA for stable/yoga to cover CVE-2022-47951\n\nChange-Id: Icdc4fe78bd7bfda34a5f28874242c22f2f441f59\n'}, {'number': 2, 'created': '2023-01-27 08:32:47.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/erlang_cve_37026-bdf6304e7772cf29.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/ossa-2023-002-ac8462ef3a5702ad.yaml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/97fd09387f9d2e6f9ae6111f3730fe64d4f22b3a', 'message': 'Bump OSA for stable/yoga to cover CVE-2022-47951\n\nChange-Id: Icdc4fe78bd7bfda34a5f28874242c22f2f441f59\n'}]",2,871834,97fd09387f9d2e6f9ae6111f3730fe64d4f22b3a,15,3,2,28619,,,0,"Bump OSA for stable/yoga to cover CVE-2022-47951

Change-Id: Icdc4fe78bd7bfda34a5f28874242c22f2f441f59
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/871834/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/erlang_cve_37026-bdf6304e7772cf29.yaml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/ossa-2023-002-ac8462ef3a5702ad.yaml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml']",7,7e2e52064ed60acf1cc1bcbaa14f2808cffa8761,bump_osa, version: dffbf793ee0aa19ffc266a16ed0c7ce1f062f1d1 shallow_since: '2023-01-20' version: 5c5813f88f651ee64e507458f39cb67ecaf640cc shallow_since: '2023-01-24', version: 0a692b02f8e4e408991f24a2424b8018af3c23d2 shallow_since: '2022-12-27' version: 9aecc1b24dbb0f3c1caa3bf9746aa5cd07edafbc shallow_since: '2022-12-27',29,19
openstack%2Fswift~master~Ia8218b16bdee1d3d42dcc06053dbcda82fb10433,openstack/swift,master,Ia8218b16bdee1d3d42dcc06053dbcda82fb10433,Test py2 fix.,ABANDONED,2023-01-27 19:41:08.000000000,2023-01-28 00:36:14.000000000,,"[{'_account_id': 597}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 19:41:08.000000000', 'files': ['swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f6173854238dfe510647f2d576ee214fce161cd5', 'message': 'Test py2 fix.\n\nChange-Id: Ia8218b16bdee1d3d42dcc06053dbcda82fb10433\n'}]",4,872046,f6173854238dfe510647f2d576ee214fce161cd5,7,2,1,34930,,,0,"Test py2 fix.

Change-Id: Ia8218b16bdee1d3d42dcc06053dbcda82fb10433
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/872046/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/proxy/controllers/obj.py'],1,f6173854238dfe510647f2d576ee214fce161cd5,sr_cache," if namespaces: if six.PY2: namespaces = [ [lower.encode('utf-8'), name.encode('utf-8')] for lower, name in namespaces] namespace_list = NamespaceBoundList(namespaces) else: namespace_list = None", namespace_list = NamespaceBoundList(namespaces) if namespaces else None,15,1
openstack%2Fdevstack~master~I5e938139b47f443a4c358415d0d4dcf6549cd085,openstack/devstack,master,I5e938139b47f443a4c358415d0d4dcf6549cd085,Fix setting the tempest virtual env constraints env var,MERGED,2023-01-27 04:32:50.000000000,2023-01-27 23:16:56.000000000,2023-01-27 23:15:59.000000000,"[{'_account_id': 7166}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-27 04:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/355b8c8e27b7c65c6c176d165afb18b624ff3d7d', 'message': ""Fix setting the tempest virtual env constraints env var\n\nDevstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE\nwhich are used to use the constraints during Tempest virtual env installation.\nThose env var are set to non-master constraint when we need to use non-master\nconstraints but when we need to use the master constraints we do not set/reset\nthem point to master constraints. This create the issue when running the grenade\njob where we run Tempest on the old devstack as well as in the new devstack.\nWhen tempest is installed on old devstack then old tempest is used and it sets\nthese env var to stable/<branch> constraints (this is the case when old devstack\n(the stable branch is in EM phase) uses the old tempest not the master tempest),\nall good till now. But the problem comes when in the same grenade script run\nupgrade-tempest install the master tempest (when new devstack branches are in\nthe 'supported' phase and use the master tempest means) and are supposed to use\nthe master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env\nvar set by old tempest is used by the tempest and due to a mismatch in constraints\nit fails.\n\nThis happened when we tried to pin the stable/wallaby with Tempest 29.0.0\n- https://review.opendev.org/c/openstack/devstack/+/871782\n\nand table/xena grenade job failed (stable/xena use master tempest and supposed\nto use master constraints)\n- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641\n\nWe should set/reset those constraint env var to master constraints if configuration\ntell devstack to use the master constraints.\n\n[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124\n\nCloses-Bug: #2003993\nChange-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085\n""}, {'number': 2, 'created': '2023-01-27 04:37:07.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d', 'message': ""Fix setting the tempest virtual env constraints env var\n\nDevstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE\nwhich are used to use the constraints during Tempest virtual env installation.\nThose env var are set to non-master constraint when we need to use non-master\nconstraints but when we need to use the master constraints we do not set/reset\nthem point to master constraints. This create the issue when running the grenade\njob where we run Tempest on the old devstack as well as in the new devstack.\nWhen tempest is installed on old devstack then old tempest is used and it sets\nthese env var to stable/<branch> constraints (this is the case when old devstack\n(the stable branch is in EM phase) uses the old tempest not the master tempest),\nall good till now. But the problem comes when in the same grenade script run\nupgrade-tempest install the master tempest (when new devstack branches are in\nthe 'supported' phase and use the master tempest means) and are supposed to use\nthe master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env\nvar set by old tempest is used by the tempest and due to a mismatch in constraints\nit fails.\n\nThis happened when we tried to pin the stable/wallaby with Tempest 29.0.0\n- https://review.opendev.org/c/openstack/devstack/+/871782\n\nand table/xena grenade job failed (stable/xena use master tempest and supposed\nto use master constraints)\n- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641\n\nWe should set/reset those constraint env var to master constraints if configuration\ntell devstack to use the master constraints.\n\n[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124\n\nCloses-Bug: #2003993\nChange-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085\n""}]",3,871942,7fe998109bda8cdd5cb5ba4a0e02c6c83cb0566d,12,3,2,8556,,,0,"Fix setting the tempest virtual env constraints env var

Devstack set the env var TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE
which are used to use the constraints during Tempest virtual env installation.
Those env var are set to non-master constraint when we need to use non-master
constraints but when we need to use the master constraints we do not set/reset
them point to master constraints. This create the issue when running the grenade
job where we run Tempest on the old devstack as well as in the new devstack.
When tempest is installed on old devstack then old tempest is used and it sets
these env var to stable/<branch> constraints (this is the case when old devstack
(the stable branch is in EM phase) uses the old tempest not the master tempest),
all good till now. But the problem comes when in the same grenade script run
upgrade-tempest install the master tempest (when new devstack branches are in
the 'supported' phase and use the master tempest means) and are supposed to use
the master constraints. But the TOX_CONSTRAINTS_FILE/UPPER_CONSTRAINTS_FILE env
var set by old tempest is used by the tempest and due to a mismatch in constraints
it fails.

This happened when we tried to pin the stable/wallaby with Tempest 29.0.0
- https://review.opendev.org/c/openstack/devstack/+/871782

and table/xena grenade job failed (stable/xena use master tempest and supposed
to use master constraints)
- https://zuul.opendev.org/t/openstack/build/fb7b2a8b562c42bab4c741819f5e9732/log/controller/logs/grenade.sh_log.txt#16641

We should set/reset those constraint env var to master constraints if configuration
tell devstack to use the master constraints.

[1] https://github.com/openstack/devstack/blob/71c3c40c269a50303247855319d1d3a5d30f6773/lib/tempest#L124

Closes-Bug: #2003993
Change-Id: I5e938139b47f443a4c358415d0d4dcf6549cd085
",git fetch https://review.opendev.org/openstack/devstack refs/changes/42/871942/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,355b8c8e27b7c65c6c176d165afb18b624ff3d7d,bug/2003993," # NOTE(gmann): we need to set the below env var pointing to master # constraints even that is what default in tox.ini. Otherwise it can # create the issue for grenade run where old and new devstack can have # different tempest (old and master) to install. For detail problem, # refer to the https://bugs.launchpad.net/devstack/+bug/2003993 export UPPER_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master export TOX_CONSTRAINTS_FILE=https://releases.openstack.org/constraints/upper/master",,7,0
openstack%2Fironic~bugfix%2F20.2~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,bugfix/20.2,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:38:40.000000000,2023-01-27 22:56:45.000000000,2023-01-27 21:43:18.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:38:40.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/46abb61705ae8d4c7c353c7e02331383ae43ef46', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,871996,46abb61705ae8d4c7c353c7e02331383ae43ef46,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/871996/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,46abb61705ae8d4c7c353c7e02331383ae43ef46,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fkolla~master~I88e8e86ca35ee1b6b6b5551c3ca8698f0ed814cb,openstack/kolla,master,I88e8e86ca35ee1b6b6b5551c3ca8698f0ed814cb,CentOS: move gpg keys to repo files,MERGED,2023-01-02 12:47:28.000000000,2023-01-27 22:49:17.000000000,2023-01-03 19:48:50.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-01-02 12:47:28.000000000', 'files': ['docker/base/mariadb.repo', 'docker/base/Dockerfile.j2', 'docker/base/rabbitmq_rabbitmq-server.repo', 'docker/base/rabbitmq_rabbitmq-erlang.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/d73dc618aa6b20727ca7d1fc1e9dc5905201869c', 'message': 'CentOS: move gpg keys to repo files\n\nDefinition of 3rdparty repo can contain also url to gnupg key used to\nsign files there.\n\nDNF knows how to handle that so we do not need to import keys in base\nimage anymore.\n\nFunctionality stays as people may use own repos with own keys.\n\nChange-Id: I88e8e86ca35ee1b6b6b5551c3ca8698f0ed814cb\n'}]",0,869002,d73dc618aa6b20727ca7d1fc1e9dc5905201869c,10,3,1,24072,,,0,"CentOS: move gpg keys to repo files

Definition of 3rdparty repo can contain also url to gnupg key used to
sign files there.

DNF knows how to handle that so we do not need to import keys in base
image anymore.

Functionality stays as people may use own repos with own keys.

Change-Id: I88e8e86ca35ee1b6b6b5551c3ca8698f0ed814cb
",git fetch https://review.opendev.org/openstack/kolla refs/changes/02/869002/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/base/mariadb.repo', 'docker/base/Dockerfile.j2', 'docker/base/rabbitmq_rabbitmq-server.repo', 'docker/base/rabbitmq_rabbitmq-erlang.repo']",4,d73dc618aa6b20727ca7d1fc1e9dc5905201869c,,gpgkey = https://github.com/rabbitmq/signing-keys/releases/download/2.0/rabbitmq-release-signing-key.asc,,3,4
openstack%2Fironic~stable%2Fyoga~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/yoga,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:38:51.000000000,2023-01-27 22:48:21.000000000,2023-01-27 22:47:17.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:38:51.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e5267b58e15d4f7b2fd2538ed6621256072b861e', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,871997,e5267b58e15d4f7b2fd2538ed6621256072b861e,9,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/97/871997/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,e5267b58e15d4f7b2fd2538ed6621256072b861e,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~stable%2Fwallaby~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/wallaby,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:42:43.000000000,2023-01-27 22:37:18.000000000,2023-01-27 22:35:57.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:42:43.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/37b4b207f851f62176fafe1097a15e17b7b6648a', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,872001,37b4b207f851f62176fafe1097a15e17b7b6648a,9,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/01/872001/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,37b4b207f851f62176fafe1097a15e17b7b6648a,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~stable%2Fzed~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/zed,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:36:36.000000000,2023-01-27 22:37:06.000000000,2023-01-27 22:35:54.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:36:36.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b91d174eb0499b0b6430b5037fbc1b72f25cb26d', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,872040,b91d174eb0499b0b6430b5037fbc1b72f25cb26d,9,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/40/872040/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,b91d174eb0499b0b6430b5037fbc1b72f25cb26d,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~stable%2Fxena~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/xena,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:41:45.000000000,2023-01-27 22:10:42.000000000,2023-01-27 22:09:11.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:41:45.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/68efd7970d8db84d9127284294dda895c3b382ad', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,871999,68efd7970d8db84d9127284294dda895c3b382ad,9,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/99/871999/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,68efd7970d8db84d9127284294dda895c3b382ad,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~master~Id6723e92efb62f8ca03099f15c90580cec887ddd,openstack/ironic,master,Id6723e92efb62f8ca03099f15c90580cec887ddd,Fix grub config path default,MERGED,2023-01-04 00:42:07.000000000,2023-01-27 22:10:33.000000000,2023-01-27 22:09:15.000000000,"[{'_account_id': 6618}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-04 00:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ca8031f4f00c2638fc5497228fbc4480f129611d', 'message': ""Fix grub config path default\n\nGrub2 looks for files in different paths depending on the boot mode\nof the binary. Previously the grub_config_path setting was defaulted\nto the path used exclusively for BIOS booting, which meant anyone\nusing it had to override the setting. Now, we've set the default\nto the default for UEFI booting, and the world should be a happier,\nand less override filled place.\n\nChange-Id: Id6723e92efb62f8ca03099f15c90580cec887ddd\n""}, {'number': 2, 'created': '2023-01-04 15:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c233bed5086eb694f1376432c08dd78ded35a4e3', 'message': ""Fix grub config path default\n\nGrub2 looks for files in different paths depending on the boot mode\nof the binary. Previously the grub_config_path setting was defaulted\nto the path used exclusively for BIOS booting, which meant anyone\nusing it had to override the setting. Now, we've set the default\nto the default for UEFI booting, and the world should be a happier,\nand less override filled place.\n\nChange-Id: Id6723e92efb62f8ca03099f15c90580cec887ddd\n""}, {'number': 3, 'created': '2023-01-11 15:18:32.000000000', 'files': ['releasenotes/notes/fix-grub2-uefi-config-path-f1b4c5083cc97ee5.yaml', 'ironic/conf/default.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/2f4a156d2995387f944942bd769d17eca623d36a', 'message': ""Fix grub config path default\n\nGrub2 looks for files in different paths depending on the boot mode\nof the binary. Previously the grub_config_path setting was defaulted\nto the path used exclusively for BIOS booting, which meant anyone\nusing it had to override the setting. Now, we've set the default\nto the default for UEFI booting, and the world should be a happier,\nand less override filled place.\n\nChange-Id: Id6723e92efb62f8ca03099f15c90580cec887ddd\n""}]",12,869134,2f4a156d2995387f944942bd769d17eca623d36a,33,4,3,11655,,,0,"Fix grub config path default

Grub2 looks for files in different paths depending on the boot mode
of the binary. Previously the grub_config_path setting was defaulted
to the path used exclusively for BIOS booting, which meant anyone
using it had to override the setting. Now, we've set the default
to the default for UEFI booting, and the world should be a happier,
and less override filled place.

Change-Id: Id6723e92efb62f8ca03099f15c90580cec887ddd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/34/869134/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-grub2-uefi-config-path-f1b4c5083cc97ee5.yaml', 'ironic/conf/default.py']",2,ca8031f4f00c2638fc5497228fbc4480f129611d,," default='EFI/BOOT/grub.cfg',"," default='/boot/grub/grub.cfg',",7,1
openstack%2Fironic~bugfix%2F18.1~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,bugfix/18.1,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:42:28.000000000,2023-01-27 21:58:36.000000000,2023-01-27 21:57:17.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:42:28.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7db9a4a288e598ce66344675dc67f3638bb66ddc', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,872000,7db9a4a288e598ce66344675dc67f3638bb66ddc,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/00/872000/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,7db9a4a288e598ce66344675dc67f3638bb66ddc,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~bugfix%2F19.0~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,bugfix/19.0,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:41:34.000000000,2023-01-27 21:58:33.000000000,2023-01-27 21:57:15.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:41:34.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5cb5fc7e8e2a37f48bd99c7f358ce5d069a6c4c6', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,871998,5cb5fc7e8e2a37f48bd99c7f358ce5d069a6c4c6,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/871998/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,5cb5fc7e8e2a37f48bd99c7f358ce5d069a6c4c6,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic~stable%2Fvictoria~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/victoria,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:42:55.000000000,2023-01-27 21:55:10.000000000,2023-01-27 21:42:25.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:42:55.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/54d8711530a09b0d5dc59546157aed38de363f6d', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,872002,54d8711530a09b0d5dc59546157aed38de363f6d,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/02/872002/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,54d8711530a09b0d5dc59546157aed38de363f6d,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic-inspector~stable%2Fyoga~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/yoga,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:17:55.000000000,2023-01-27 21:44:21.000000000,2023-01-27 21:43:21.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:17:55.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/561fed27c7959b72aa74a46026a62fc1f941139b', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",1,871881,561fed27c7959b72aa74a46026a62fc1f941139b,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/81/871881/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,561fed27c7959b72aa74a46026a62fc1f941139b,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~stable%2Fwallaby~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/wallaby,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:19:42.000000000,2023-01-27 21:43:27.000000000,2023-01-27 21:42:27.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:19:42.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/9fef41df61ed133b5f162190ef690f413a6ccda1', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",1,871885,9fef41df61ed133b5f162190ef690f413a6ccda1,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/85/871885/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,9fef41df61ed133b5f162190ef690f413a6ccda1,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic~stable%2Fussuri~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,stable/ussuri,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:43:10.000000000,2023-01-27 21:41:34.000000000,2023-01-27 21:40:11.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:43:10.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/859e51c8b4b8344827b5bba1f9a0b737ffbc1ebc', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,872003,859e51c8b4b8344827b5bba1f9a0b737ffbc1ebc,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/03/872003/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,859e51c8b4b8344827b5bba1f9a0b737ffbc1ebc,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fironic-inspector~stable%2Fussuri~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/ussuri,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:20:03.000000000,2023-01-27 21:41:23.000000000,2023-01-27 21:40:14.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:20:03.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/44c4b4e39c32e70c9101905491ba7743b597e468', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",1,871887,44c4b4e39c32e70c9101905491ba7743b597e468,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/87/871887/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,44c4b4e39c32e70c9101905491ba7743b597e468,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~stable%2Fxena~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/xena,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:18:25.000000000,2023-01-27 20:27:34.000000000,2023-01-27 20:26:27.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:18:25.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/c582157e86cc05a42290db280efe5a0e36f186eb', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",1,871883,c582157e86cc05a42290db280efe5a0e36f186eb,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/83/871883/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,c582157e86cc05a42290db280efe5a0e36f186eb,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fkeystone-tempest-plugin~master~I28117a37a41ac76ba5561a285e417882c2d6a5a1,openstack/keystone-tempest-plugin,master,I28117a37a41ac76ba5561a285e417882c2d6a5a1,Update stable jobs on master gate,MERGED,2022-10-16 04:03:42.000000000,2023-01-27 20:19:37.000000000,2023-01-27 20:19:37.000000000,"[{'_account_id': 7973}, {'_account_id': 14250}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-16 04:03:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/3e6d6144211e4720a96b714977ec44ba16c83232', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I28117a37a41ac76ba5561a285e417882c2d6a5a1\n'}, {'number': 2, 'created': '2023-01-27 00:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/99ac176500944c5bca86010ed5a204f296bf76bd', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I28117a37a41ac76ba5561a285e417882c2d6a5a1\n'}, {'number': 3, 'created': '2023-01-27 01:38:05.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/0506e1c6d9018ad5bf0de4a24c603f594efdd9d6', 'message': 'Update stable jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nAlso, removing the stable/wallaby job as that is in EM\nstate.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I28117a37a41ac76ba5561a285e417882c2d6a5a1\n'}]",2,861526,0506e1c6d9018ad5bf0de4a24c603f594efdd9d6,17,4,3,8556,,,0,"Update stable jobs on master gate

As zed is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Also, removing the stable/wallaby job as that is in EM
state.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: I28117a37a41ac76ba5561a285e417882c2d6a5a1
",git fetch https://review.opendev.org/openstack/keystone-tempest-plugin refs/changes/26/861526/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3e6d6144211e4720a96b714977ec44ba16c83232,wallaby-last, - keystone-dsvm-py3-functional-zed name: keystone-dsvm-py3-functional-zed parent: keystone-dsvm-py3-functional nodeset: openstack-single-node-focal override-checkout: stable/zed - job:,,7,0
openstack%2Fironic-python-agent~stable%2Ftrain~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/train,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:25:12.000000000,2023-01-27 20:17:46.000000000,2023-01-27 20:16:11.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:25:12.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8330df949bab9f4d836085ff2c08d83ecd58311c', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",1,871898,8330df949bab9f4d836085ff2c08d83ecd58311c,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/98/871898/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,8330df949bab9f4d836085ff2c08d83ecd58311c,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~bugfix%2F8.6~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,bugfix/8.6,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:20:42.000000000,2023-01-27 20:17:41.000000000,2023-01-27 20:16:08.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:20:42.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/40a1dfd487c2190240a2e6dce6506a05fe594fdf', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",1,871890,40a1dfd487c2190240a2e6dce6506a05fe594fdf,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/90/871890/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,40a1dfd487c2190240a2e6dce6506a05fe594fdf,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fwallaby~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/wallaby,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:24:40.000000000,2023-01-27 20:17:41.000000000,2023-01-27 20:16:07.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:24:40.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/9619ceb46f31892ffdbb5273189089fdf3cb9341', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",0,871895,9619ceb46f31892ffdbb5273189089fdf3cb9341,12,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/95/871895/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,9619ceb46f31892ffdbb5273189089fdf3cb9341,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fussuri~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/ussuri,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:25:01.000000000,2023-01-27 20:17:36.000000000,2023-01-27 20:16:10.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:25:01.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/15de2b2d68be0b47e4a8c4f33ac5b394fd19cdd8', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",0,871897,15de2b2d68be0b47e4a8c4f33ac5b394fd19cdd8,12,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/97/871897/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,15de2b2d68be0b47e4a8c4f33ac5b394fd19cdd8,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fxena~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/xena,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:24:16.000000000,2023-01-27 20:17:27.000000000,2023-01-27 20:16:04.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:24:16.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/6aa917d4b45c83bf8b6600b1138492d7e23dbaf5', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",1,871893,6aa917d4b45c83bf8b6600b1138492d7e23dbaf5,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/93/871893/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,6aa917d4b45c83bf8b6600b1138492d7e23dbaf5,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fvictoria~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/victoria,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:24:49.000000000,2023-01-27 20:17:25.000000000,2023-01-27 20:16:05.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:24:49.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c5e06744f9fc071e7cd8361077f4f6e37fffb76d', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",1,871896,c5e06744f9fc071e7cd8361077f4f6e37fffb76d,13,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/96/871896/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,c5e06744f9fc071e7cd8361077f4f6e37fffb76d,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~stable%2Ftrain~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/train,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:20:11.000000000,2023-01-27 20:10:43.000000000,2023-01-27 20:09:27.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:20:11.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/3542e3ee184fa162c96cbcfa08b0157aa3634629', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",1,871888,3542e3ee184fa162c96cbcfa08b0157aa3634629,10,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/88/871888/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,3542e3ee184fa162c96cbcfa08b0157aa3634629,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fyoga~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/yoga,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:21:04.000000000,2023-01-27 19:59:39.000000000,2023-01-27 19:58:36.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:21:04.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8e77848c901e8a70295a41a355cb2b44a4793d06', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",0,871891,8e77848c901e8a70295a41a355cb2b44a4793d06,9,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/91/871891/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,8e77848c901e8a70295a41a355cb2b44a4793d06,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic~bugfix%2F21.0~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,bugfix/21.0,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-27 18:38:12.000000000,2023-01-27 19:56:33.000000000,2023-01-27 19:55:13.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 18:38:12.000000000', 'files': ['releasenotes/config.yaml', 'reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c8a035411c333beb5e520d676256bbddf832f3bc', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)\n'}]",0,871995,c8a035411c333beb5e520d676256bbddf832f3bc,8,2,1,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
(cherry picked from commit fbe22b23bc3f1c89822e17417747378c9449ebeb)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/95/871995/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/config.yaml', 'reno.yaml']",2,c8a035411c333beb5e520d676256bbddf832f3bc,,,"--- # Ignore the kilo-eol tag because that branch does not work with reno # and contains no release notes. closed_branch_tag_re: ""(.+)(?<!kilo)-eol"" ",5,4
openstack%2Fopenstack-ansible~stable%2Fxena~I0148592d13258e9107e16229572a6ad569b35bc4,openstack/openstack-ansible,stable/xena,I0148592d13258e9107e16229572a6ad569b35bc4,Bump OSA for stable/xena to cover CVE-2022-47951,MERGED,2023-01-26 17:47:57.000000000,2023-01-27 19:26:40.000000000,2023-01-27 19:24:23.000000000,"[{'_account_id': 13095}, {'_account_id': 16011}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 17:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e3e5de8cfc184435fceb3ed2f38c56cf02b002f5', 'message': 'Bump OSA for stable/zed to cover CVE-2022-47951\n\nChange-Id: I0148592d13258e9107e16229572a6ad569b35bc4\n'}, {'number': 2, 'created': '2023-01-26 17:48:43.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/ossa-2023-002-054d135e3066cca8.yaml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ea543967f973b606c68e5728431fa6bb841f44db', 'message': 'Bump OSA for stable/xena to cover CVE-2022-47951\n\nChange-Id: I0148592d13258e9107e16229572a6ad569b35bc4\n'}]",0,871839,ea543967f973b606c68e5728431fa6bb841f44db,9,3,2,28619,,,0,"Bump OSA for stable/xena to cover CVE-2022-47951

Change-Id: I0148592d13258e9107e16229572a6ad569b35bc4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/39/871839/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'releasenotes/notes/ossa-2023-002-054d135e3066cca8.yaml', 'ansible-role-requirements.yml']",5,e3e5de8cfc184435fceb3ed2f38c56cf02b002f5,bump_osa,### HEAD as of 26.01.2023 ### version: abe9b6d9c5a78583b6b1283e5226f7079aa50d02 shallow_since: '2023-01-12' version: 5c1f645e08ae4461c1c068eca38babdc72a2c93b shallow_since: '2023-01-17' version: d3071d3a0f776634e74b673d1abfc7690c20e875 shallow_since: '2023-01-15' version: 9850f00be4d8ce9bdd8f280e4f433fb9a9617667 shallow_since: '2023-01-11' version: bbeca7f60c3c36c7baf36b2940a59f834f6aad8e shallow_since: '2023-01-12',### HEAD as of 11.01.2023 ### version: 577dfa9450ad52854533e189a78111f1ba93a9b4 shallow_since: '2022-05-17' version: 788a3d86688eb85edc0f3e9d5a3a1842755fc079 shallow_since: '2022-12-27' version: fb6098fa7c6dd97193607b8a624f14b88862cdf3 shallow_since: '2022-12-14' version: 3d346f4c5d8918ad11f7d75ec87050fbd8b9974b shallow_since: '2022-12-28' version: 4023023c50a02a94bd37d1bde918329c40a49c16 shallow_since: '2022-12-28',32,27
openstack%2Fhorizon~stable%2Fzed~Ie31307d67cf3857e3bb80c124e92c81e0c6a2982,openstack/horizon,stable/zed,Ie31307d67cf3857e3bb80c124e92c81e0c6a2982,Fix flavor id auto generation,MERGED,2022-12-08 15:03:02.000000000,2023-01-27 19:00:52.000000000,2023-01-27 18:59:41.000000000,"[{'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-12-08 15:03:02.000000000', 'files': ['openstack_dashboard/dashboards/admin/flavors/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6acabc4f39dcd08756b7b43b5182d78bf6a54d51', 'message': 'Fix flavor id auto generation\n\nCurrently the flavor creation form always check for the uniqueness\nof the UUID field, even when it is set to ""auto"". That means that if\nwe create a flavor with UUID value of ""auto"", the check will fail.\n\nThis patch disable the check when UUID is automatically generated.\n\nChange-Id: Ie31307d67cf3857e3bb80c124e92c81e0c6a2982\n(cherry picked from commit af7e6c4f75299b9e47db059dc7ddbaf2e0b1a3fc)\n'}]",10,866908,6acabc4f39dcd08756b7b43b5182d78bf6a54d51,32,3,1,6914,,,0,"Fix flavor id auto generation

Currently the flavor creation form always check for the uniqueness
of the UUID field, even when it is set to ""auto"". That means that if
we create a flavor with UUID value of ""auto"", the check will fail.

This patch disable the check when UUID is automatically generated.

Change-Id: Ie31307d67cf3857e3bb80c124e92c81e0c6a2982
(cherry picked from commit af7e6c4f75299b9e47db059dc7ddbaf2e0b1a3fc)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/08/866908/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/flavors/workflows.py'],1,6acabc4f39dcd08756b7b43b5182d78bf6a54d51,flavor_id_auto-stable/zed," ""spaces. Use 'auto' to automatically generate id"") if (flavor.id != 'auto') and (flavor.id == flavor_id):"," ""spaces."") if flavor.id == flavor_id:",2,2
openstack%2Fironic~bugfix%2F21.0~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,bugfix/21.0,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:13:24.000000000,2023-01-27 18:53:16.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:13:24.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9496a4fe52945d8408da9d9037ec23b7ca880e5b', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871769,9496a4fe52945d8408da9d9037ec23b7ca880e5b,8,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/69/871769/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,9496a4fe52945d8408da9d9037ec23b7ca880e5b,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~bugfix%2F18.1~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,bugfix/18.1,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:15:21.000000000,2023-01-27 18:52:13.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:15:21.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d72c93f51fd8e10e6db8c6a635a1dde158f42c14', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871874,d72c93f51fd8e10e6db8c6a635a1dde158f42c14,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/74/871874/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,d72c93f51fd8e10e6db8c6a635a1dde158f42c14,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fussuri~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/ussuri,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:15:52.000000000,2023-01-27 18:51:58.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:15:52.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a4db9984aeffbec4c47fef4b25e7f000387ba88d', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871877,a4db9984aeffbec4c47fef4b25e7f000387ba88d,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/77/871877/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,a4db9984aeffbec4c47fef4b25e7f000387ba88d,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~bugfix%2F19.0~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,bugfix/19.0,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:14:54.000000000,2023-01-27 18:51:49.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:14:54.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/af6b0bc58b0c29b5093b34d3eb7fff2ff9c5b8e1', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871872,af6b0bc58b0c29b5093b34d3eb7fff2ff9c5b8e1,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/72/871872/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,af6b0bc58b0c29b5093b34d3eb7fff2ff9c5b8e1,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~bugfix%2F20.2~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,bugfix/20.2,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:14:13.000000000,2023-01-27 18:51:40.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:14:13.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fae34cc5fdd878f35253e8f83b83fcd99004e560', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871870,fae34cc5fdd878f35253e8f83b83fcd99004e560,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/70/871870/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,fae34cc5fdd878f35253e8f83b83fcd99004e560,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fvictoria~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/victoria,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:15:42.000000000,2023-01-27 18:51:30.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:15:42.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/616c03d0479b379fb7e351028449fb64f88a2aaa', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871876,616c03d0479b379fb7e351028449fb64f88a2aaa,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/76/871876/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,616c03d0479b379fb7e351028449fb64f88a2aaa,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fzed~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/zed,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:08:34.000000000,2023-01-27 18:49:26.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:08:34.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/88daf0b95508e8082ea056ed7e8d0f5f0db51edc', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871765,88daf0b95508e8082ea056ed7e8d0f5f0db51edc,7,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/65/871765/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,88daf0b95508e8082ea056ed7e8d0f5f0db51edc,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~bugfix%2F21.2~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,bugfix/21.2,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:13:10.000000000,2023-01-27 18:49:18.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:13:10.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ead5f040062c495c71fa432304c4aec164e3caf', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871768,1ead5f040062c495c71fa432304c4aec164e3caf,8,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/68/871768/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,1ead5f040062c495c71fa432304c4aec164e3caf,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fwallaby~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/wallaby,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:15:32.000000000,2023-01-27 18:47:51.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:15:32.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0b167e25793536e9e95bab42a4c87d2ecdad1bd', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871875,b0b167e25793536e9e95bab42a4c87d2ecdad1bd,7,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/75/871875/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,b0b167e25793536e9e95bab42a4c87d2ecdad1bd,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fxena~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/xena,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:15:05.000000000,2023-01-27 18:47:40.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:15:05.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/56e5f4ee25a8a58f26b4aa4b04afa37902f46fea', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871873,56e5f4ee25a8a58f26b4aa4b04afa37902f46fea,7,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/73/871873/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,56e5f4ee25a8a58f26b4aa4b04afa37902f46fea,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Fyoga~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/yoga,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:14:29.000000000,2023-01-27 18:47:30.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:14:29.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/be65971ea0e755fb2f0d32dbcc7f1745fa99082f', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871871,be65971ea0e755fb2f0d32dbcc7f1745fa99082f,7,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/71/871871/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,be65971ea0e755fb2f0d32dbcc7f1745fa99082f,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fironic~stable%2Ftrain~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,stable/train,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,ABANDONED,2023-01-26 23:16:03.000000000,2023-01-27 18:45:04.000000000,,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:16:03.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e060ea059a14f00c17067f457902600aedc4b1ea', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)\n""}]",1,871878,e060ea059a14f00c17067f457902600aedc4b1ea,6,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
(cherry picked from commit b63d15ccdb7202af1700ce4f35b892c989356d7a)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/871878/1 && git format-patch -1 --stdout FETCH_HEAD,['reno.yaml'],1,e060ea059a14f00c17067f457902600aedc4b1ea,,"# Ignore bugfix tags because their releasenotes are covered under stabl closed_branch_tag_re: ""(?!^(kilo|bugfix-)).+-eol$""","closed_branch_tag_re: ""(.+)(?<!kilo)-eol""",2,1
openstack%2Fswift~master~Ib05f615ec3afcd6a1d9e25239cc009fb5cf62cce,openstack/swift,master,Ib05f615ec3afcd6a1d9e25239cc009fb5cf62cce,maybe squash? use a NamespaceBoundList class,ABANDONED,2023-01-25 16:44:57.000000000,2023-01-27 18:44:46.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-25 16:44:57.000000000', 'files': ['swift/common/utils.py', 'swift/proxy/controllers/obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/07053cfcea17d31de111185fc71258223efba07f', 'message': 'maybe squash? use a NamespaceBoundList class\n\nChange-Id: Ib05f615ec3afcd6a1d9e25239cc009fb5cf62cce\n'}]",0,871742,07053cfcea17d31de111185fc71258223efba07f,4,1,1,7847,,,0,"maybe squash? use a NamespaceBoundList class

Change-Id: Ib05f615ec3afcd6a1d9e25239cc009fb5cf62cce
",git fetch https://review.opendev.org/openstack/swift refs/changes/42/871742/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'swift/proxy/controllers/obj.py']",2,07053cfcea17d31de111185fc71258223efba07f,sr_cache," ShardRange, find_shard_range, cache_from_env, NamespaceBoundList) :return: an instance of NamespaceBoundList namespace_list = infocache.get(cache_key) if namespace_list: return namespace_list, 'infocache_hit' return None, 'disabled' return None, 'skip' namespaces = None namespace_list = NamespaceBoundList(namespaces) if namespaces else None return namespace_list, cache_state infocache[cache_key] = cached_namespaces namespace = cached_namespaces.get_namespace(obj) cached_namespaces = NamespaceBoundList.from_namespaces( shard_ranges) infocache[cache_key] = cached_namespaces cache_key, cached_namespaces.bounds,"," ShardRange, find_shard_range, cache_from_env, find_namespace) :return: a tuple of (list of lowerbounds, cache state), each lowerbound is in the format [lower_str, name_str] namespaces = infocache.get(cache_key) if namespaces: return namespaces, 'infocache_hit' return [], 'disabled' return [], 'skip' return namespaces or [], cache_state infocache[cache_key] = tuple(cached_namespaces) namespace = find_namespace(obj, cached_namespaces) cached_namespaces = [sr.lower_bound() for sr in shard_ranges] infocache[cache_key] = tuple(cached_namespaces) cache_key, cached_namespaces,",39,39
openstack%2Fcinder~stable%2Fwallaby~I7527a7493752c1b3db774de989250ec5b514237b,openstack/cinder,stable/wallaby,I7527a7493752c1b3db774de989250ec5b514237b,[stable-em only] move grenade jobs to experimental,MERGED,2023-01-25 21:39:58.000000000,2023-01-27 18:23:12.000000000,2023-01-27 16:01:12.000000000,"[{'_account_id': 4523}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-25 21:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e966c3bdc4055615f63879653294bf6a46d74e8a', 'message': '[stable-em only] move grenade jobs to experimental\n\nGiven that ""upgrades from Extended Maintenance are not supported\nwithin the Community"" [0], move the grenade jobs to the experimental\nqueue for the stable branches in EM status.\n\n[0] https://docs.openstack.org/project-team-guide/stable-branches.html#extended-maintenance\n\nChange-Id: I7527a7493752c1b3db774de989250ec5b514237b\n'}, {'number': 2, 'created': '2023-01-26 14:12:50.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/4cdd18b42925e88b9d777373c0c73dff32aa78ff', 'message': '[stable-em only] move grenade jobs to experimental\n\nGiven that ""upgrades from Extended Maintenance are not supported\nwithin the Community"" [0], move the grenade jobs to the experimental\nqueue for the stable branches in EM status.  Additionally, remove\nthe integrated-gate-storage template because it includes grenade.\n(The other jobs in that template were already configured in check\nand gate in our .zuul.yaml, so they continue to be run.)\n\n[0] https://docs.openstack.org/project-team-guide/stable-branches.html#extended-maintenance\n\nChange-Id: I7527a7493752c1b3db774de989250ec5b514237b\n'}]",3,871790,4cdd18b42925e88b9d777373c0c73dff32aa78ff,32,4,2,5314,,,0,"[stable-em only] move grenade jobs to experimental

Given that ""upgrades from Extended Maintenance are not supported
within the Community"" [0], move the grenade jobs to the experimental
queue for the stable branches in EM status.  Additionally, remove
the integrated-gate-storage template because it includes grenade.
(The other jobs in that template were already configured in check
and gate in our .zuul.yaml, so they continue to be run.)

[0] https://docs.openstack.org/project-team-guide/stable-branches.html#extended-maintenance

Change-Id: I7527a7493752c1b3db774de989250ec5b514237b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/90/871790/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e966c3bdc4055615f63879653294bf6a46d74e8a,grenade-drop, - grenade: irrelevant-files: *gate-irrelevant-files - cinder-grenade-mn-sub-volbak: irrelevant-files: *gate-irrelevant-files, - cinder-grenade-mn-sub-volbak: irrelevant-files: *gate-irrelevant-files - grenade: irrelevant-files: *gate-irrelevant-files - cinder-grenade-mn-sub-volbak: irrelevant-files: *gate-irrelevant-files - grenade: irrelevant-files: *gate-irrelevant-files,4,8
openstack%2Fneutron~stable%2Fyoga~I5f703d82175d71a222c76df37a82b5ccad890d14,openstack/neutron,stable/yoga,I5f703d82175d71a222c76df37a82b5ccad890d14,Never raise an exception in notify(),MERGED,2023-01-27 11:26:44.000000000,2023-01-27 18:18:45.000000000,2023-01-27 18:17:10.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 11:26:44.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cb3428d770ccd5a95bd3a5fcf799ad07f30f64d', 'message': 'Never raise an exception in notify()\n\nnotify() is called from python-ovs code which is not built to\nrecover from an exception in this user-overriden code. If there\nis an exception (e.g. the DB server is down when we process\nthe hash ring), this exception can cause an unrecoverable error\nin processing OVSDB messages, rendering the neutron worker useless.\n\nChange-Id: I5f703d82175d71a222c76df37a82b5ccad890d14\n(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)\n'}]",4,871909,5cb3428d770ccd5a95bd3a5fcf799ad07f30f64d,17,6,1,13861,,,0,"Never raise an exception in notify()

notify() is called from python-ovs code which is not built to
recover from an exception in this user-overriden code. If there
is an exception (e.g. the DB server is down when we process
the hash ring), this exception can cause an unrecoverable error
in processing OVSDB messages, rendering the neutron worker useless.

Change-Id: I5f703d82175d71a222c76df37a82b5ccad890d14
(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/871909/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,5cb3428d770ccd5a95bd3a5fcf799ad07f30f64d,," try: self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) except Exception as e: LOG.exception(e)"," self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates)",34,30
openstack%2Fneutron~stable%2Fxena~I5f703d82175d71a222c76df37a82b5ccad890d14,openstack/neutron,stable/xena,I5f703d82175d71a222c76df37a82b5ccad890d14,Never raise an exception in notify(),MERGED,2023-01-27 11:27:05.000000000,2023-01-27 18:05:15.000000000,2023-01-27 18:04:01.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 11:27:05.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e6ffa31c173025e85573990bc8c91bef9d34440', 'message': 'Never raise an exception in notify()\n\nnotify() is called from python-ovs code which is not built to\nrecover from an exception in this user-overriden code. If there\nis an exception (e.g. the DB server is down when we process\nthe hash ring), this exception can cause an unrecoverable error\nin processing OVSDB messages, rendering the neutron worker useless.\n\nChange-Id: I5f703d82175d71a222c76df37a82b5ccad890d14\n(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)\n'}]",0,871990,6e6ffa31c173025e85573990bc8c91bef9d34440,9,5,1,13861,,,0,"Never raise an exception in notify()

notify() is called from python-ovs code which is not built to
recover from an exception in this user-overriden code. If there
is an exception (e.g. the DB server is down when we process
the hash ring), this exception can cause an unrecoverable error
in processing OVSDB messages, rendering the neutron worker useless.

Change-Id: I5f703d82175d71a222c76df37a82b5ccad890d14
(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/90/871990/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,6e6ffa31c173025e85573990bc8c91bef9d34440,," try: self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) except Exception as e: LOG.exception(e)"," self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates)",34,30
openstack%2Fironic~master~I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,openstack/ironic,master,I4d46ba06ada1afb5fd1c63db5850a1983e502a6c,Move and fix reno config for releasenotes job,MERGED,2023-01-26 23:37:19.000000000,2023-01-27 17:54:45.000000000,2023-01-27 17:53:31.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/546681a3a195390dc029afdb8bf52cf024466a8e', 'message': 'Move reno config so that releasenotes job will run\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n'}, {'number': 2, 'created': '2023-01-26 23:53:06.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fbe22b23bc3f1c89822e17417747378c9449ebeb', 'message': 'Move and fix reno config for releasenotes job\n\nIn its current place, reno config changes will not cause\nbuild-openstack-releasenotes job to run, which means changes can land to\nthat config without being tested. Yikes!\n\nAlso fixes error in regexp which was preventing this from actually\nfixing the build-openstack-releasenotes job.\n\nChange-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c\n'}]",0,871862,fbe22b23bc3f1c89822e17417747378c9449ebeb,8,2,2,10342,,,0,"Move and fix reno config for releasenotes job

In its current place, reno config changes will not cause
build-openstack-releasenotes job to run, which means changes can land to
that config without being tested. Yikes!

Also fixes error in regexp which was preventing this from actually
fixing the build-openstack-releasenotes job.

Change-Id: I4d46ba06ada1afb5fd1c63db5850a1983e502a6c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/871862/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,546681a3a195390dc029afdb8bf52cf024466a8e,,,,0,0
openstack%2Ftripleo-heat-templates~master~I7d5c01d21af34df5e9fa8842f46aa435975a2ace,openstack/tripleo-heat-templates,master,I7d5c01d21af34df5e9fa8842f46aa435975a2ace,Role-spec NovaComputeStartupDelay,MERGED,2023-01-24 13:12:11.000000000,2023-01-27 17:48:05.000000000,2023-01-27 17:48:05.000000000,"[{'_account_id': 6926}, {'_account_id': 9816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 13:12:11.000000000', 'files': ['deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/768b8f3964cb655fdc09c29cee554e6402b7e9f9', 'message': 'Role-spec NovaComputeStartupDelay\n\nMake it role-specific for other compute roles, like HCI,\nto work with it\n\nFollow-up Ie7ad2d835c1762dc4b9341e305e6a428cb087935\n\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I7d5c01d21af34df5e9fa8842f46aa435975a2ace\n'}]",2,871602,768b8f3964cb655fdc09c29cee554e6402b7e9f9,13,3,1,6926,,,0,"Role-spec NovaComputeStartupDelay

Make it role-specific for other compute roles, like HCI,
to work with it

Follow-up Ie7ad2d835c1762dc4b9341e305e6a428cb087935

Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
Change-Id: I7d5c01d21af34df5e9fa8842f46aa435975a2ace
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/871602/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-compute-container-puppet.yaml'],1,768b8f3964cb655fdc09c29cee554e6402b7e9f9,," tags: - role_specific - not: and: - {equals: [{get_param: NovaComputeStartupDelay}, 0]} - or: - {equals: [{get_param: [RoleParameters, NovaComputeStartupDelay]}, 0]} - {equals: [{get_param: [RoleParameters, NovaComputeStartupDelay]}, '']} nova_compute_startup_delay: NovaComputeStartupDelay NovaComputeStartupDelay: {get_param: NovaComputeStartupDelay} params: { DELAY: {get_attr: [RoleParametersValue, value, nova_compute_startup_delay]} } nova_compute_delay: {get_attr: [RoleParametersValue, value, nova_compute_startup_delay]}"," - not: {equals: [{get_param: NovaComputeStartupDelay}, 0]} params: { DELAY: {get_param: NovaComputeStartupDelay} } nova_compute_delay: {get_param: NovaComputeStartupDelay}",12,3
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I2c14da9fb44bb3588681c2e996140ac898317b57,openstack/tripleo-heat-templates,stable/wallaby,I2c14da9fb44bb3588681c2e996140ac898317b57,[wallaby-only] Fix GlanceApi service in mixed-os job,MERGED,2023-01-25 14:27:01.000000000,2023-01-27 17:48:01.000000000,2023-01-27 17:48:01.000000000,"[{'_account_id': 8449}, {'_account_id': 13861}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2023-01-25 14:27:01.000000000', 'files': ['ci/environments/multinode-containers-mixed-os.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/33e6f8db5e0bbacb11c44923a0a67e7607a8faaa', 'message': '[wallaby-only] Fix GlanceApi service in mixed-os job\n\nId093613f9d410eb3fe5564a724c0f75275eeb4e8 adds the GlanceApiInternal\nservice, which needs to be included in every role that deploys the\nGlanceApi service. The mixed-os job is only in wallaby, and was\noverlooked when backporting the patch that adds the GlanceApiInternal\nservice.\n\nCloses-Bug: #2003865\nDepends-On: I111af443220f519befa0669dfefe20b9c56fd37c\nChange-Id: I2c14da9fb44bb3588681c2e996140ac898317b57\n'}]",2,871735,33e6f8db5e0bbacb11c44923a0a67e7607a8faaa,12,5,1,21129,,,0,"[wallaby-only] Fix GlanceApi service in mixed-os job

Id093613f9d410eb3fe5564a724c0f75275eeb4e8 adds the GlanceApiInternal
service, which needs to be included in every role that deploys the
GlanceApi service. The mixed-os job is only in wallaby, and was
overlooked when backporting the patch that adds the GlanceApiInternal
service.

Closes-Bug: #2003865
Depends-On: I111af443220f519befa0669dfefe20b9c56fd37c
Change-Id: I2c14da9fb44bb3588681c2e996140ac898317b57
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/871735/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/multinode-containers-mixed-os.yaml'],1,33e6f8db5e0bbacb11c44923a0a67e7607a8faaa,bug/2003865, - OS::TripleO::Services::GlanceApiInternal,,1,0
openstack%2Fkayobe~master~I1687ea33f27dee6ba145514db5cf213b28cc8cd2,openstack/kayobe,master,I1687ea33f27dee6ba145514db5cf213b28cc8cd2,CI: add Rocky9 upgrade jobs,MERGED,2023-01-26 13:59:33.000000000,2023-01-27 17:47:32.000000000,2023-01-27 17:45:40.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-01-26 13:59:33.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/094852e3c6d4b0652abf620368e0a1251d624708', 'message': 'CI: add Rocky9 upgrade jobs\n\nChange-Id: I1687ea33f27dee6ba145514db5cf213b28cc8cd2\n'}]",2,871823,094852e3c6d4b0652abf620368e0a1251d624708,14,3,1,23084,,,0,"CI: add Rocky9 upgrade jobs

Change-Id: I1687ea33f27dee6ba145514db5cf213b28cc8cd2
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/23/871823/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,094852e3c6d4b0652abf620368e0a1251d624708,, name: kayobe-overcloud-upgrade-rocky9 nodeset: kayobe-rocky9 name: kayobe-seed-upgrade-rocky9 nodeset: kayobe-rocky9, name: kayobe-overcloud-upgrade-centos8s nodeset: kayobe-centos8s name: kayobe-seed-upgrade-centos8s nodeset: kayobe-centos8s,8,4
openstack%2Fironic~master~Iac8e6e58653ac616250f4ce3ab3ae7f5164e5b03,openstack/ironic,master,Iac8e6e58653ac616250f4ce3ab3ae7f5164e5b03,[CI] Swap anaconda urls,MERGED,2023-01-26 22:01:45.000000000,2023-01-27 17:36:07.000000000,2023-01-27 17:34:04.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-26 22:01:45.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/692a383fdc758b56ffd8ea803c7c61c0c2f374f2', 'message': '[CI] Swap anaconda urls\n\nThe anaconda job is failing as were getting a redirect issued back\nupon attempting to validate URLs. The servers are now directing us\nto use HTTPS instead.\n\nChange-Id: Iac8e6e58653ac616250f4ce3ab3ae7f5164e5b03\n'}]",0,871855,692a383fdc758b56ffd8ea803c7c61c0c2f374f2,10,3,1,11655,,,0,"[CI] Swap anaconda urls

The anaconda job is failing as were getting a redirect issued back
upon attempting to validate URLs. The servers are now directing us
to use HTTPS instead.

Change-Id: Iac8e6e58653ac616250f4ce3ab3ae7f5164e5b03
",git fetch https://review.opendev.org/openstack/ironic refs/changes/55/871855/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,692a383fdc758b56ffd8ea803c7c61c0c2f374f2,, IRONIC_ANACONDA_IMAGE_REF: https://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/ IRONIC_ANACONDA_KERNEL_REF: https://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/images/pxeboot/vmlinuz IRONIC_ANACONDA_RAMDISK_REF: https://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/images/pxeboot/initrd.img, IRONIC_ANACONDA_IMAGE_REF: http://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/ IRONIC_ANACONDA_KERNEL_REF: http://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/images/pxeboot/vmlinuz IRONIC_ANACONDA_RAMDISK_REF: http://mirror.stream.centos.org/9-stream/BaseOS/x86_64/os/images/pxeboot/initrd.img,3,3
openstack%2Fheat~master~Ifc51ff6a4deab05002ccded59383416f9a586aa0,openstack/heat,master,Ifc51ff6a4deab05002ccded59383416f9a586aa0,Honor 'hidden' parameter in 'stack environment show' command,MERGED,2022-12-20 10:06:25.000000000,2023-01-27 17:31:41.000000000,2023-01-27 17:30:30.000000000,"[{'_account_id': 4257}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2022-12-20 10:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/51fc58621f9cc05e29803bcab56eb15e8c1a90a6', 'message': ""Honor 'hidden' parameter in 'stack environment show' command\n\nRelated-Bug: #1999665\nStory: 2010484\nTask: 47052\nChange-Id: Ifc51ff6a4deab05002ccded59383416f9a586aa0\n""}, {'number': 2, 'created': '2023-01-04 06:35:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5dbddb9da44c793bceeb0b69535ad3c3a96a023f', 'message': ""Honor 'hidden' parameter in 'stack environment show' command\n\nRelated-Bug: #1999665\nStory: 2010484\nTask: 47052\nChange-Id: Ifc51ff6a4deab05002ccded59383416f9a586aa0\n""}, {'number': 3, 'created': '2023-01-11 08:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3add5acf16e67db267d48f2b75e1f619a0dba93e', 'message': ""Honor 'hidden' parameter in 'stack environment show' command\n\nRelated-Bug: #1999665\nStory: 2010484\nTask: 47052\nChange-Id: Ifc51ff6a4deab05002ccded59383416f9a586aa0\n""}, {'number': 4, 'created': '2023-01-11 08:51:26.000000000', 'files': ['heat/tests/test_engine_service.py', 'releasenotes/notes/honor-hidden-parameter-in-stack-env-show-cmd-062065545dfef82a.yaml', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/1305a3152f75c6e62ec5094ea2bfc38f165204cf', 'message': ""Honor 'hidden' parameter in 'stack environment show' command\n\nRelated-Bug: #1999665\nStory: 2010484\nTask: 47052\nChange-Id: Ifc51ff6a4deab05002ccded59383416f9a586aa0\n""}]",22,868166,1305a3152f75c6e62ec5094ea2bfc38f165204cf,50,4,4,35639,,,0,"Honor 'hidden' parameter in 'stack environment show' command

Related-Bug: #1999665
Story: 2010484
Task: 47052
Change-Id: Ifc51ff6a4deab05002ccded59383416f9a586aa0
",git fetch https://review.opendev.org/openstack/heat refs/changes/66/868166/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/engine/service.py']",2,51fc58621f9cc05e29803bcab56eb15e8c1a90a6,bug/2010484,"import copy tmpl = templatem.Template.load(cnxt, s.raw_template_id, s.raw_template) env = copy.deepcopy(s.raw_template.environment) for param_name in env.get(env_fmt.PARAMETERS, {}).keys(): if not tmpl.param_schemata()[param_name].hidden: continue env[env_fmt.PARAMETERS][param_name] = str('******') return env", return s.raw_template.environment,10,2
openstack%2Ftripleo-ansible~stable%2Fwallaby~Idb922e90028743c688eeb4e6d5fcae713cf14312,openstack/tripleo-ansible,stable/wallaby,Idb922e90028743c688eeb4e6d5fcae713cf14312,HA: Minor update with new container image name,ABANDONED,2022-10-17 09:50:27.000000000,2023-01-27 16:59:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-10-17 09:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cc1ed7fd4c132545a3df7c3f24a6459052dff268', 'message': 'HA: Minor update with new container image name\n\nThis role encapsulates preparation steps that are required\nduring a minor update to change the container image name\nused by a HA service, without causing service disruption.\n\nRelated-Bug: #1992988\n\nChange-Id: Idb922e90028743c688eeb4e6d5fcae713cf14312\n'}, {'number': 2, 'created': '2022-10-18 20:45:38.000000000', 'files': ['tripleo_ansible/roles/tripleo_ha_image_update/tasks/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/verify.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/converge.yml', 'tripleo_ansible/roles/tripleo_ha_wrapper/tasks/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/meta/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/Dockerfile', 'tripleo_ansible/roles/tripleo_ha_wrapper/defaults/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/prepare.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/ac476fb985409df73ef89f8ba14e20b6dafe3a82', 'message': 'HA: Minor update with new container image name\n\nThis role encapsulates preparation steps that are required\nduring a minor update to change the container image name\nused by a HA service, without causing service disruption.\n\nRelated-Bug: #1992988\n\nChange-Id: Idb922e90028743c688eeb4e6d5fcae713cf14312\n'}]",2,861610,ac476fb985409df73ef89f8ba14e20b6dafe3a82,11,2,2,20778,,,0,"HA: Minor update with new container image name

This role encapsulates preparation steps that are required
during a minor update to change the container image name
used by a HA service, without causing service disruption.

Related-Bug: #1992988

Change-Id: Idb922e90028743c688eeb4e6d5fcae713cf14312
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/10/861610/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_ha_image_update/tasks/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/molecule.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/verify.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/converge.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/meta/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/Dockerfile', 'tripleo_ansible/roles/tripleo_ha_image_update/defaults/main.yml', 'tripleo_ansible/roles/tripleo_ha_image_update/molecule/default/prepare.yml']",8,cc1ed7fd4c132545a3df7c3f24a6459052dff268,ha_image_upd-stable/wallaby,"--- # Copyright 2022 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. - name: Prepare hosts: all roles: - role: test_deps post_tasks: - name: Clean up tripleo_ha_image_update markers file: path: '{{ item }}' state: absent with_fileglob: /tmp/tripleo_ha_image_* - name: Create fake podman binary copy: dest: /usr/bin/podman content: | #!/bin/bash echo ""podman $*"" >> /tmp/podman mode: 0755 - name: Create fake pcs script copy: dest: /usr/bin/pcs content: | #!/bin/bash echo ""pcs $*"" >> /tmp/pcs mode: 0755 ",,370,0
openstack%2Fneutron~stable%2Fzed~I5f703d82175d71a222c76df37a82b5ccad890d14,openstack/neutron,stable/zed,I5f703d82175d71a222c76df37a82b5ccad890d14,Never raise an exception in notify(),MERGED,2023-01-27 11:26:20.000000000,2023-01-27 16:54:00.000000000,2023-01-27 16:52:37.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 11:26:20.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/931f0af2e35b68c4ca40dd8e323bf07d74f48083', 'message': 'Never raise an exception in notify()\n\nnotify() is called from python-ovs code which is not built to\nrecover from an exception in this user-overriden code. If there\nis an exception (e.g. the DB server is down when we process\nthe hash ring), this exception can cause an unrecoverable error\nin processing OVSDB messages, rendering the neutron worker useless.\n\nChange-Id: I5f703d82175d71a222c76df37a82b5ccad890d14\n(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)\n'}]",1,871908,931f0af2e35b68c4ca40dd8e323bf07d74f48083,9,6,1,13861,,,0,"Never raise an exception in notify()

notify() is called from python-ovs code which is not built to
recover from an exception in this user-overriden code. If there
is an exception (e.g. the DB server is down when we process
the hash ring), this exception can cause an unrecoverable error
in processing OVSDB messages, rendering the neutron worker useless.

Change-Id: I5f703d82175d71a222c76df37a82b5ccad890d14
(cherry picked from commit 67e616b2380d6549308a15077b2043721dbea5d0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/871908/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,931f0af2e35b68c4ca40dd8e323bf07d74f48083,," try: self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) except Exception as e: LOG.exception(e)"," self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates)",34,30
openstack%2Fcinder~master~I3c60ee4c0795aadf03108ed9b5a46ecd116894af,openstack/cinder,master,I3c60ee4c0795aadf03108ed9b5a46ecd116894af,Check VMDK subformat against an allowed list,MERGED,2023-01-24 15:02:16.000000000,2023-01-27 16:46:22.000000000,2023-01-24 21:32:54.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-24 15:02:16.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/930fc93e9fda82a4aa4568ae149c3c80af7379d0', 'message': 'Check VMDK subformat against an allowed list\n\nAlso add a more general check to convert_image that the image format\nreported by qemu-img matches what the caller says it is.\n\nChange-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af\nPartial-bug: #1996188\n'}]",4,871615,930fc93e9fda82a4aa4568ae149c3c80af7379d0,29,7,1,5314,,,0,"Check VMDK subformat against an allowed list

Also add a more general check to convert_image that the image format
reported by qemu-img matches what the caller says it is.

Change-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af
Partial-bug: #1996188
",git fetch https://review.opendev.org/openstack/cinder refs/changes/15/871615/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml']",3,930fc93e9fda82a4aa4568ae149c3c80af7379d0,CVE-2022-47951,"--- upgrade: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. security: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow in order to prevent exposure of host information by modifying the named extents in a VMDK image. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. - | As part of the fix for `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_, cinder is now more strict in checking that the ``disk_format`` recorded for an image (as revealed by the Image Service API image-show response) matches what cinder detects when it downloads the image. Thus, some requests to create a volume from a source image that had previously succeeded may fail with an ``ImageUnacceptable`` error. fixes: - | `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_: Fixed issue where a VMDK image file whose createType allowed named extents could expose host information. This change introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats. ",,567,47
openstack%2Fheat~master~Ia48de36e3cb97378785bb4946b1a387c0da1ff81,openstack/heat,master,Ia48de36e3cb97378785bb4946b1a387c0da1ff81,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 20:25:58.000000000,2023-01-27 16:38:20.000000000,2023-01-27 16:36:59.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 30073}, {'_account_id': 32102}]","[{'number': 1, 'created': '2023-01-19 20:25:58.000000000', 'files': ['requirements.txt', 'heat/common/messaging.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/29eaf4ef716b954f6b32f0563ff03bf7f486c75c', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: Ia48de36e3cb97378785bb4946b1a387c0da1ff81\n'}]",6,871157,29eaf4ef716b954f6b32f0563ff03bf7f486c75c,30,7,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: Ia48de36e3cb97378785bb4946b1a387c0da1ff81
",git fetch https://review.opendev.org/openstack/heat refs/changes/57/871157/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'heat/common/messaging.py']",2,29eaf4ef716b954f6b32f0563ff03bf7f486c75c,," return oslo_messaging.get_rpc_client( TRANSPORT, target, serializer=serializer)"," return oslo_messaging.RPCClient(TRANSPORT, target, serializer=serializer)",3,3
openstack%2Fmanila-ui~master~Ib4fac275b5dd309eaa68c3a612e8b30751ce130f,openstack/manila-ui,master,Ib4fac275b5dd309eaa68c3a612e8b30751ce130f,Imported Translations from Zanata,MERGED,2023-01-27 02:59:01.000000000,2023-01-27 16:31:17.000000000,2023-01-27 16:29:51.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 02:59:01.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/c5184b28fc8415e037aa947135ad7cc0ebf4a91c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ib4fac275b5dd309eaa68c3a612e8b30751ce130f\n'}]",0,871926,c5184b28fc8415e037aa947135ad7cc0ebf4a91c,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ib4fac275b5dd309eaa68c3a612e8b30751ce130f
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/26/871926/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,c5184b28fc8415e037aa947135ad7cc0ebf4a91c,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-05 17:11+0000\n""""PO-Revision-Date: 2023-01-26 10:13+0000\n""msgid ""8.0.0"" msgstr ""8.0.0""","""POT-Creation-Date: 2022-09-13 15:16+0000\n""""PO-Revision-Date: 2022-09-24 01:16+0000\n""msgid ""8.0.0.0rc1"" msgstr ""8.0.0.0rc1""",5,4
openstack%2Fcastellan~master~I598209e30d8f0e4515292b1f8c9a89aa952bac4e,openstack/castellan,master,I598209e30d8f0e4515292b1f8c9a89aa952bac4e,Initial change to add secret consumers,MERGED,2023-01-20 10:10:45.000000000,2023-01-27 16:19:01.000000000,2023-01-27 16:18:00.000000000,"[{'_account_id': 9914}, {'_account_id': 14250}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 10:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/4720d80f3fb5a7c6f320914d095aab47d4be6e28', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 2, 'created': '2023-01-20 10:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/f447e1bf3ed22ce90e22ca63e37aa5279e54ec04', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 3, 'created': '2023-01-20 10:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/f33ab3d6d5382879e4d2932be4ae2538262d29e1', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 4, 'created': '2023-01-20 12:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/792f2f7404d4a5688eb1c6a10ac9c284737f1361', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 5, 'created': '2023-01-26 16:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/767af09429d99e340a93380f32d66d08b973f3cb', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects. Unit tests are\nalso covered.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 6, 'created': '2023-01-27 09:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/castellan/commit/ee1ecce8bb0d3af1ac54fb8c77fc134c12e6a03f', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects. Unit tests are\nalso covered.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}, {'number': 7, 'created': '2023-01-27 12:11:14.000000000', 'files': ['castellan/common/objects/managed_object.py', 'castellan/common/objects/public_key.py', 'castellan/tests/unit/objects/test_opaque.py', 'castellan/tests/unit/objects/test_symmetric_key.py', 'castellan/common/objects/passphrase.py', 'castellan/common/objects/key.py', 'castellan/common/objects/x_509.py', 'castellan/tests/unit/objects/test_public_key.py', 'castellan/tests/unit/objects/test_x_509.py', 'castellan/common/objects/private_key.py', 'castellan/common/objects/symmetric_key.py', 'castellan/tests/unit/objects/test_private_key.py', 'castellan/common/objects/opaque_data.py', 'castellan/tests/unit/objects/test_passphrase.py'], 'web_link': 'https://opendev.org/openstack/castellan/commit/fe10397ac05b0376a75be57d7c6f31dc5f470e9e', 'message': 'Initial change to add secret consumers\n\nThis adds consumers to the objects. Unit tests are\nalso covered.\n\nCo-Authored-By: Ade Lee <alee@redhat.com>\nCo-Authored-By: Mauricio Harley <mharley@redhat.com>\nChange-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e\n'}]",1,871227,fe10397ac05b0376a75be57d7c6f31dc5f470e9e,19,3,7,14250,,,0,"Initial change to add secret consumers

This adds consumers to the objects. Unit tests are
also covered.

Co-Authored-By: Ade Lee <alee@redhat.com>
Co-Authored-By: Mauricio Harley <mharley@redhat.com>
Change-Id: I598209e30d8f0e4515292b1f8c9a89aa952bac4e
",git fetch https://review.opendev.org/openstack/castellan refs/changes/27/871227/5 && git format-patch -1 --stdout FETCH_HEAD,"['castellan/common/objects/managed_object.py', 'castellan/common/objects/public_key.py', 'castellan/common/objects/x_509.py', 'castellan/common/objects/private_key.py', 'castellan/common/objects/symmetric_key.py', 'castellan/common/objects/opaque_data.py', 'castellan/common/objects/passphrase.py', 'castellan/common/objects/key.py']",8,4720d80f3fb5a7c6f320914d095aab47d4be6e28,add-consumers," dict_fields[""consumers""] = self.consumers consumers=dict_fields[""consumers""]",,35,14
openstack%2Fdesignate~master~Ib52a430bfd06c3bed8be6711529cd006949dc72c,openstack/designate,master,Ib52a430bfd06c3bed8be6711529cd006949dc72c,add multiple-bind9 example config file,NEW,2022-09-11 07:49:34.000000000,2023-01-27 16:16:58.000000000,,"[{'_account_id': 5572}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-11 07:49:34.000000000', 'files': ['designate/tests/resources/pools_yaml/multiple-bind9-pools.yaml'], 'web_link': 'https://opendev.org/openstack/designate/commit/d6eb154d8596068ea12c94aa64b8c2d8731af9cf', 'message': ""add multiple-bind9 example config file\n\nWhen I want to dock multiple BIND9 in pools.yaml, I can't find an\nexample, so I add it.\n\nChange-Id: Ib52a430bfd06c3bed8be6711529cd006949dc72c\n""}]",2,856944,d6eb154d8596068ea12c94aa64b8c2d8731af9cf,4,3,1,34340,,,0,"add multiple-bind9 example config file

When I want to dock multiple BIND9 in pools.yaml, I can't find an
example, so I add it.

Change-Id: Ib52a430bfd06c3bed8be6711529cd006949dc72c
",git fetch https://review.opendev.org/openstack/designate refs/changes/44/856944/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/tests/resources/pools_yaml/multiple-bind9-pools.yaml'],1,d6eb154d8596068ea12c94aa64b8c2d8731af9cf,,--- - name: pool-1 description: Default Bind 9 Pool attributes: internal: true ns_records: - hostname: ns1-1.example.org. priority: 1 - hostname: ns1-2.example.org. priority: 2 nameservers: - host: 192.0.2.2 port: 53 - host: 192.0.2.3 port: 53 targets: - type: bind9 description: Bind 9 Server 1 masters: - host: 192.0.2.1 port: 5354 options: host: 192.0.2.2 port: 53 rndc_host: 192.0.2.2 rndc_port: 953 rndc_key_file: /etc/bind1/rndc.key rndc_config_file: /etc/bind1/rndc.conf - type: bind9 description: Bind 9 Server 2 masters: - host: 192.0.2.1 port: 5354 options: host: 192.0.2.3 port: 53 rndc_host: 192.0.2.3 rndc_port: 953 rndc_key_file: /etc/bind2/rndc.key rndc_config_file: /etc/bind2/rndc.conf ,,41,0
openstack%2Fkeystonemiddleware~stable%2Fzed~Ice8e34440a5fe1baa370646ed70b5e085c4af70e,openstack/keystonemiddleware,stable/zed,Ice8e34440a5fe1baa370646ed70b5e085c4af70e,Remove cache invalidation when using expired token,MERGED,2022-12-21 16:56:26.000000000,2023-01-27 16:12:45.000000000,2023-01-27 16:11:40.000000000,"[{'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-21 16:56:26.000000000', 'files': ['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py', 'keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f602fa718d12e4ab15ab134256fa835db2a1b7ee', 'message': ""Remove cache invalidation when using expired token\n\nThis can create a race condition for long running services that reuse\ntheir token (eg. Kubernetes Cinder CSI plugin) in this case for\nexample:\n\n1 [user] Asks nova to attach a volume to a server\n2 ...the user's token expires\n3 [user] Asks cinder if the volume has been attached\n4 [nova] Asks cinder to attach the volume\n\nIn step 3 the token is marked as invalid in the cache and step 4 fails\neven if allow_expired is true\n\nCloses-Bug: #1987355\nChange-Id: Ice8e34440a5fe1baa370646ed70b5e085c4af70e\n(cherry picked from commit e05466c5f439cd05482f109e6eb97a50ba156698)\n""}]",0,868284,f602fa718d12e4ab15ab134256fa835db2a1b7ee,7,2,1,34275,,,0,"Remove cache invalidation when using expired token

This can create a race condition for long running services that reuse
their token (eg. Kubernetes Cinder CSI plugin) in this case for
example:

1 [user] Asks nova to attach a volume to a server
2 ...the user's token expires
3 [user] Asks cinder if the volume has been attached
4 [nova] Asks cinder to attach the volume

In step 3 the token is marked as invalid in the cache and step 4 fails
even if allow_expired is true

Closes-Bug: #1987355
Change-Id: Ice8e34440a5fe1baa370646ed70b5e085c4af70e
(cherry picked from commit e05466c5f439cd05482f109e6eb97a50ba156698)
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/84/868284/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/tests/unit/auth_token/test_auth_token_middleware.py', 'keystonemiddleware/auth_token/__init__.py']",2,f602fa718d12e4ab15ab134256fa835db2a1b7ee,lp1987355-stable/zed,,"_CACHE_INVALID_INDICATOR = 'invalid' if cached == _CACHE_INVALID_INDICATOR: self.log.debug('Cached token is marked unauthorized') raise ksm_exceptions.InvalidToken() self._token_cache.set(token, _CACHE_INVALID_INDICATOR)",0,25
openstack%2Fcinder~stable%2Fxena~Ic1b5737281e542d2782089a369e4b7941fc3d921,openstack/cinder,stable/xena,Ic1b5737281e542d2782089a369e4b7941fc3d921,Fix and unify capacity calculations,MERGED,2023-01-19 18:34:35.000000000,2023-01-27 16:05:37.000000000,2023-01-27 16:01:20.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-19 18:34:35.000000000', 'files': ['cinder/tests/unit/scheduler/test_host_manager.py', 'releasenotes/notes/slug-b6a0fc3db0a2dd45.yaml', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/tests/unit/test_utils.py', 'cinder/utils.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py', 'cinder/tests/unit/scheduler/test_host_filters.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff042a2b5df3624a845b2cfeb5acac199167ed7e', 'message': ""Fix and unify capacity calculations\n\nThis patch updates how cinder calculates it's free capacity.\nThe new calculations are based off of the queens cinder specs\nthat describes each of the capacity factors here:\nhttps://specs.openstack.org/openstack/cinder-specs/specs/queens/provisioning-improvements.html\n\nThis patch updates the capacity filter to use the new capacity factors\ncalculations, which is also used by the capacity weigher.\n\nThe new calculate_capacity_factors describes each of the factors and\nreturns a dictionary of each of the factors as calculated.\n\nChange-Id: Ic1b5737281e542d2782089a369e4b7941fc3d921\n(cherry picked from commit 856d3e108035ac1ed9c6a3cec4de47b1eb6ad18b)\n(cherry picked from commit ae08757d9fabc9743fe5fd3c8220885e48835c0b)\n""}]",3,871120,ff042a2b5df3624a845b2cfeb5acac199167ed7e,19,5,1,21129,,,0,"Fix and unify capacity calculations

This patch updates how cinder calculates it's free capacity.
The new calculations are based off of the queens cinder specs
that describes each of the capacity factors here:
https://specs.openstack.org/openstack/cinder-specs/specs/queens/provisioning-improvements.html

This patch updates the capacity filter to use the new capacity factors
calculations, which is also used by the capacity weigher.

The new calculate_capacity_factors describes each of the factors and
returns a dictionary of each of the factors as calculated.

Change-Id: Ic1b5737281e542d2782089a369e4b7941fc3d921
(cherry picked from commit 856d3e108035ac1ed9c6a3cec4de47b1eb6ad18b)
(cherry picked from commit ae08757d9fabc9743fe5fd3c8220885e48835c0b)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/871120/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/scheduler/test_host_manager.py', 'releasenotes/notes/slug-b6a0fc3db0a2dd45.yaml', 'cinder/scheduler/filters/capacity_filter.py', 'cinder/tests/unit/test_utils.py', 'cinder/utils.py', 'cinder/tests/unit/scheduler/test_capacity_weigher.py', 'cinder/tests/unit/scheduler/test_host_filters.py']",7,ff042a2b5df3624a845b2cfeb5acac199167ed7e,capacity_factors_reporting," filter_properties = {'size': 121, filter_properties = {'size': 2400, filter_properties = {'size': 151,"," filter_properties = {'size': 100, filter_properties = {'size': 3000, filter_properties = {'size': 100,",260,38
openstack%2Fcinder~stable%2Fxena~Idcaf657692c2597887476ec1834d790f39b1fe94,openstack/cinder,stable/xena,Idcaf657692c2597887476ec1834d790f39b1fe94,Erroneous log message args location causes a misconception,MERGED,2023-01-19 18:34:35.000000000,2023-01-27 16:04:13.000000000,2023-01-27 16:01:16.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-19 18:34:35.000000000', 'files': ['releasenotes/notes/bug-1953168-fix-capacity-filter-message-456dea41fa8a4a1b.yaml', 'cinder/scheduler/filters/capacity_filter.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fc7cf4a598cfe8b96d6235d7495759d54c36e697', 'message': 'Erroneous log message args location causes a misconception\n\nThis patch modifies log message args location so that the log\nmessage can report free space correctly.\n\nstable/xena:\n- Two small follow-up patches that fix minor issues are squashed into\n  this patch: I41080795cc1c3c91de1e35d6d6eba3f05068b26e fixes a bug,\n  and I6976569ac3617cc247a4c39f786ece8443d43d0b fixes a typo in the\n  release note.\n- Backporting this patch facilitates backporting the patch that fixes\n  capacity calculations.\n\nChange-Id: Idcaf657692c2597887476ec1834d790f39b1fe94\n(cherry picked from commit 4efd313d419253f5c3718867f17b8d229b3c2df8)\n'}]",4,871119,fc7cf4a598cfe8b96d6235d7495759d54c36e697,19,5,1,21129,,,0,"Erroneous log message args location causes a misconception

This patch modifies log message args location so that the log
message can report free space correctly.

stable/xena:
- Two small follow-up patches that fix minor issues are squashed into
  this patch: I41080795cc1c3c91de1e35d6d6eba3f05068b26e fixes a bug,
  and I6976569ac3617cc247a4c39f786ece8443d43d0b fixes a typo in the
  release note.
- Backporting this patch facilitates backporting the patch that fixes
  capacity calculations.

Change-Id: Idcaf657692c2597887476ec1834d790f39b1fe94
(cherry picked from commit 4efd313d419253f5c3718867f17b8d229b3c2df8)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/19/871119/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1953168-fix-capacity-filter-message-456dea41fa8a4a1b.yaml', 'cinder/scheduler/filters/capacity_filter.py']",2,fc7cf4a598cfe8b96d6235d7495759d54c36e697,capacity_factors_reporting," msg_args[""available""] = adjusted_free_virtual ""provisioned %(requested)sGB volume on "" ""%(grouping)s %(grouping_name)s."", msg_args)"," msg_args = {""available"": adjusted_free_virtual, ""size"": requested_size, ""grouping"": grouping, ""grouping_name"": backend_state.backend_id} ""provisioned %(size)sGB volume on %(grouping)s"" "" %(grouping_name)s."", msg_args)",8,6
openstack%2Fnova~stable%2Fyoga~Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1,openstack/nova,stable/yoga,Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1,Add a workaround to skip hypervisor version check on LM,MERGED,2022-07-27 09:58:22.000000000,2023-01-27 16:03:03.000000000,2023-01-27 16:01:02.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-27 09:58:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e3b4424b7f587e3e274a5ef81ac35cfd14f0c96', 'message': ""Add a workaround to skip hypervisor version check on LM\n\nWhen turned on, this will disable the version-checking of hypervisors\nduring live-migration.  This can be useful for operators in certain\nscenarios when upgrading.  E.g. if you want to relocate all instances\noff a compute node due to an emergency hardware issue, and you only have\nanother old compute node ready at the time.\n\nNote, though: libvirt will do its own internal compatibility checks, and\nmight still reject live migration if the destination is incompatible.\n\nConflicts: nova/conf/workarounds.py\n - The other config 'skip_cpu_compare_on_dest' was not backported to\n   'stable/yoga' branch\n\nCloses-Bug: #1982853\n\nChange-Id: Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n(cherry picked from commit 5032cb62e6458282e1282ac64cf7dd49a2497ac1)\n""}, {'number': 2, 'created': '2022-07-27 10:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4436ea63e3137a87708aa9b3f6b81696e482470a', 'message': ""Add a workaround to skip hypervisor version check on LM\n\nWhen turned on, this will disable the version-checking of hypervisors\nduring live-migration.  This can be useful for operators in certain\nscenarios when upgrading.  E.g. if you want to relocate all instances\noff a compute node due to an emergency hardware issue, and you only have\nanother old compute node ready at the time.\n\nNote, though: libvirt will do its own internal compatibility checks, and\nmight still reject live migration if the destination is incompatible.\n\nConflicts: nova/conf/workarounds.py\n - The other config 'skip_cpu_compare_on_dest' was not backported to\n   'stable/yoga' branch\n\nCloses-Bug: #1982853\n\nChange-Id: Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n(cherry picked from commit 5032cb62e6458282e1282ac64cf7dd49a2497ac1)\n""}, {'number': 3, 'created': '2023-01-27 09:54:34.000000000', 'files': ['releasenotes/notes/skip-hypervisor-version-check-on-lm-a87f2dcb4f8bf0f2.yaml', 'nova/conductor/tasks/live_migrate.py', 'nova/conf/workarounds.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c07495d9d64dd0635d72fc7ff67d73a656a40d13', 'message': 'Add a workaround to skip hypervisor version check on LM\n\nWhen turned on, this will disable the version-checking of hypervisors\nduring live-migration.  This can be useful for operators in certain\nscenarios when upgrading.  E.g. if you want to relocate all instances\noff a compute node due to an emergency hardware issue, and you only have\nanother old compute node ready at the time.\n\nNote, though: libvirt will do its own internal compatibility checks, and\nmight still reject live migration if the destination is incompatible.\n\nCloses-Bug: #1982853\n\nChange-Id: Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n(cherry picked from commit 00ed8a232bc22f48011e95a0b47750520a5b4d47)\n'}]",4,851202,c07495d9d64dd0635d72fc7ff67d73a656a40d13,23,4,3,6962,,,0,"Add a workaround to skip hypervisor version check on LM

When turned on, this will disable the version-checking of hypervisors
during live-migration.  This can be useful for operators in certain
scenarios when upgrading.  E.g. if you want to relocate all instances
off a compute node due to an emergency hardware issue, and you only have
another old compute node ready at the time.

Note, though: libvirt will do its own internal compatibility checks, and
might still reject live migration if the destination is incompatible.

Closes-Bug: #1982853

Change-Id: Iec387dcbc49ddb91ebf5cfd188224eaf6021c0e1
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
(cherry picked from commit 00ed8a232bc22f48011e95a0b47750520a5b4d47)
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/851202/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/skip-hypervisor-version-check-on-lm-a87f2dcb4f8bf0f2.yaml', 'nova/conductor/tasks/live_migrate.py', 'nova/conf/workarounds.py', 'nova/tests/unit/conductor/tasks/test_live_migrate.py']",4,0e3b4424b7f587e3e274a5ef81ac35cfd14f0c96,bug/1982853," @mock.patch.object(live_migrate.LiveMigrationTask, '_get_compute_info') def test_skip_hypervisor_version_check_on_lm_raise_ex(self, mock_get_info): host1 = {'hypervisor_type': 'a', 'hypervisor_version': 7} host2 = {'hypervisor_type': 'a', 'hypervisor_version': 6} self.flags(group='workarounds', skip_hypervisor_version_check_on_lm=False) mock_get_info.side_effect = [objects.ComputeNode(**host1), objects.ComputeNode(**host2)] self.assertRaises(exception.DestinationHypervisorTooOld, self.task._check_compatible_with_source_hypervisor, self.destination) self.assertEqual([mock.call(self.instance_host), mock.call(self.destination)], mock_get_info.call_args_list) @mock.patch.object(live_migrate.LiveMigrationTask, '_get_compute_info') def test_skip_hypervisor_version_check_on_lm_do_not_raise_ex( self, mock_get_info ): host1 = {'hypervisor_type': 'a', 'hypervisor_version': 7} host2 = {'hypervisor_type': 'a', 'hypervisor_version': 6} self.flags(group='workarounds', skip_hypervisor_version_check_on_lm=True) mock_get_info.side_effect = [objects.ComputeNode(**host1), objects.ComputeNode(**host2)] self.task._check_compatible_with_source_hypervisor(self.destination) self.assertEqual([mock.call(self.instance_host), mock.call(self.destination)], mock_get_info.call_args_list) ",,53,2
openstack%2Fhorizon~master~Id921b69df13af3cc209236f0446d82dd30e4d8a2,openstack/horizon,master,Id921b69df13af3cc209236f0446d82dd30e4d8a2,Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value,MERGED,2022-12-19 12:54:35.000000000,2023-01-27 15:40:08.000000000,2023-01-27 15:38:33.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32029}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-12-19 12:54:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/229ae162faf43ed51457ef448641eccc6c8b837d', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}, {'number': 2, 'created': '2023-01-20 14:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e4d351ad55e958b5b0a99e61957b273a3da9db1', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}, {'number': 3, 'created': '2023-01-24 14:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/489b10b94139bf554610a35a388cc4f10137b0a2', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nAlso, this commit updates the docs with a proper horizon version that\ncorresponds to Zed release (the feature was introduced before final Zed\ncut so the author tried to guess the final release number).\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}, {'number': 4, 'created': '2023-01-25 11:26:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8bd373d2deed34c900650a246dd0c20234905d1a', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nAlso, this commit updates the docs with a proper horizon version that\ncorresponds to Zed release (the feature was introduced before final Zed\ncut so the author tried to guess the final release number).\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}, {'number': 5, 'created': '2023-01-25 14:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bb69655154e1a584cca8ac5a75b00f43e57ea7f6', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nAlso, this commit updates the docs with a proper horizon version that\ncorresponds to Zed release (the feature was introduced before final Zed\ncut so the author tried to guess the final release number).\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}, {'number': 6, 'created': '2023-01-26 13:52:49.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js', 'doc/source/configuration/settings.rst', 'releasenotes/notes/fix-default-userdata-3cb75b85b1a5708f.yaml', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c8ee8c1965b280e24fb6266cbb2523230fea605f', 'message': ""Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value\n\nThe final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy\nand doesn't work.\nThis commit fixes it and adds a proper test.\n\nAlso, this commit updates the docs with a proper horizon version that\ncorresponds to Zed release (the feature was introduced before final Zed\ncut so the author tried to guess the final release number).\n\nChange-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2\n""}]",28,868083,c8ee8c1965b280e24fb6266cbb2523230fea605f,34,7,6,9545,,,0,"Fix applying OPENSTACK_SERVER_DEFAULT_USER_DATA value

The final revision of I86ac21bf82c1667135abd4f20fb4514da0899450 is buggy
and doesn't work.
This commit fixes it and adds a proper test.

Also, this commit updates the docs with a proper horizon version that
corresponds to Zed release (the feature was introduced before final Zed
cut so the author tried to guess the final release number).

Change-Id: Id921b69df13af3cc209236f0446d82dd30e4d8a2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/83/868083/6 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js', 'releasenotes/notes/fix-default-userdata-3cb75b85b1a5708f.yaml', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.spec.js']",3,229ae162faf43ed51457ef448641eccc6c8b837d,fix_default_user_data," it('should default user_data based on setting', function() { settings.OPENSTACK_SERVER_DEFAULT_USER_DATA = 'default-data'; model.initialize(true); scope.$apply(); expect(model.newInstanceSpec.default_user_data).toBe('default-data'); }); ", OPENSTACK_SERVER_DEFAULT_USER_DATA: '',11,2
openstack%2Freleases~master~I230895f45c85c6f86c6c984f45364877efa4ea28,openstack/releases,master,I230895f45c85c6f86c6c984f45364877efa4ea28,Release nova for stable/xena,ABANDONED,2023-01-16 16:02:36.000000000,2023-01-27 15:21:04.000000000,,"[{'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-16 16:02:36.000000000', 'files': ['deliverables/xena/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/dd1fdf01a290f517862076d0dd790e089662a1e5', 'message': 'Release nova for stable/xena\n\nThis release picks up new commits to nova since\nthe last release from stable/xena.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\n$ git log --oneline --no-merges 24.1.1..fe5aee061b\nc3092e3ee7 enable blocked VDPA move operations\nafc55c564f Add compute restart capability for libvirt func tests\nb36bc9247f Remove double mocking... again\n54c7c97cb8 Remove double mocking\na340630c5c Record SRIOV PF MAC in the binding profile\ne7c2e55c66 refactor: remove duplicated logic\n0e4a257e86 Adapt websocketproxy tests for SimpleHTTPServer fix\n14f9b7627e Retry attachment delete API call for 504 Gateway Timeout\n15502ddedc [compute] always set instance.host in post_livemigration\n5efcc3f695 Adds a repoducer for post live migration fail\n98d9936e54 Handle ""no RAM info was set"" migration case\n8e9aa71e1a For evacuation, ignore if task_state is not None\n1e0af92e17 add regression test case for bug 1978983\n62e1a621d1 [nova/libvirt] Support for checking and enabling SMM when needed\n076f95371a Fix instance\'s image_ref lost on failed unshelving\nec73ff1f78 Reproducer unit test for bug 1934094\nd322f8e8b5 neutron: Unbind remaining ports after PortNotFound\nb12f7ebcdd Retry in CellDatabases fixture when global DB state changes\na913ab1aab reenable greendns in nova.\n513241a7e4 Fix the wrong exception used to retry detach API calls\n\nSigned-off-by: Herv Beraud <hberaud@redhat.com>\nChange-Id: I230895f45c85c6f86c6c984f45364877efa4ea28\n'}]",0,870622,dd1fdf01a290f517862076d0dd790e089662a1e5,3,3,1,28522,,,0,"Release nova for stable/xena

This release picks up new commits to nova since
the last release from stable/xena.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

$ git log --oneline --no-merges 24.1.1..fe5aee061b
c3092e3ee7 enable blocked VDPA move operations
afc55c564f Add compute restart capability for libvirt func tests
b36bc9247f Remove double mocking... again
54c7c97cb8 Remove double mocking
a340630c5c Record SRIOV PF MAC in the binding profile
e7c2e55c66 refactor: remove duplicated logic
0e4a257e86 Adapt websocketproxy tests for SimpleHTTPServer fix
14f9b7627e Retry attachment delete API call for 504 Gateway Timeout
15502ddedc [compute] always set instance.host in post_livemigration
5efcc3f695 Adds a repoducer for post live migration fail
98d9936e54 Handle ""no RAM info was set"" migration case
8e9aa71e1a For evacuation, ignore if task_state is not None
1e0af92e17 add regression test case for bug 1978983
62e1a621d1 [nova/libvirt] Support for checking and enabling SMM when needed
076f95371a Fix instance's image_ref lost on failed unshelving
ec73ff1f78 Reproducer unit test for bug 1934094
d322f8e8b5 neutron: Unbind remaining ports after PortNotFound
b12f7ebcdd Retry in CellDatabases fixture when global DB state changes
a913ab1aab reenable greendns in nova.
513241a7e4 Fix the wrong exception used to retry detach API calls

Signed-off-by: Herv Beraud <hberaud@redhat.com>
Change-Id: I230895f45c85c6f86c6c984f45364877efa4ea28
",git fetch https://review.opendev.org/openstack/releases refs/changes/22/870622/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/nova.yaml'],1,dd1fdf01a290f517862076d0dd790e089662a1e5,xena-stable, - version: 24.2.0 projects: - repo: openstack/nova hash: fe5aee061bd03631d9e9d1810eb698d0a29bf37b,,4,0
openstack%2Fnova~master~I4313b2dc5d913b37ae685769b2e7fdb39806e5fc,openstack/nova,master,I4313b2dc5d913b37ae685769b2e7fdb39806e5fc,DNM: Testing check pipeline on master branch,ABANDONED,2023-01-27 13:44:36.000000000,2023-01-27 14:57:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 13:44:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/2183dc298d7a4f29f9f1391c09f0889e8ac0c2c9', 'message': 'DNM: Testing check pipeline on master branch\n\nChange-Id: I4313b2dc5d913b37ae685769b2e7fdb39806e5fc\n'}]",1,872018,2183dc298d7a4f29f9f1391c09f0889e8ac0c2c9,7,1,1,34443,,,0,"DNM: Testing check pipeline on master branch

Change-Id: I4313b2dc5d913b37ae685769b2e7fdb39806e5fc
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/872018/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2183dc298d7a4f29f9f1391c09f0889e8ac0c2c9,,extras=,extras =,1,1
openstack%2Ftrove~master~I41ebe8cf844c24f9eb178f232bd66af5ed7298e8,openstack/trove,master,I41ebe8cf844c24f9eb178f232bd66af5ed7298e8,Fixes the error when stopping a container,ABANDONED,2022-10-27 08:15:42.000000000,2023-01-27 14:54:56.000000000,,"[{'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2022-10-27 08:15:42.000000000', 'files': ['trove/tests/unittests/guestagent/utils/__init__.py', 'trove/guestagent/utils/docker.py', 'trove/tests/unittests/guestagent/utils/test_docker.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/70c182bc43904ed7ac2b74744506a2a67d59581d', 'message': ""Fixes the error when stopping a container\n\nThis PR fixes the following error when stopping a docker container.:\n```\nUnboundLocalError: local variable 'container' referenced before assignment\n```\n\nStory: 2010242\nTask: 46055\nChange-Id: I41ebe8cf844c24f9eb178f232bd66af5ed7298e8\n""}]",1,862784,70c182bc43904ed7ac2b74744506a2a67d59581d,5,2,1,31737,,,0,"Fixes the error when stopping a container

This PR fixes the following error when stopping a docker container.:
```
UnboundLocalError: local variable 'container' referenced before assignment
```

Story: 2010242
Task: 46055
Change-Id: I41ebe8cf844c24f9eb178f232bd66af5ed7298e8
",git fetch https://review.opendev.org/openstack/trove refs/changes/84/862784/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/guestagent/utils/__init__.py', 'trove/guestagent/utils/docker.py', 'trove/tests/unittests/guestagent/utils/test_docker.py']",3,70c182bc43904ed7ac2b74744506a2a67d59581d,story/2010242,"# Copyright 2022 Yahoo Japan Corporation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from unittest import TestCase from unittest.mock import Mock from trove.guestagent.utils import docker as ga_utils_docker class TestTroveGuestagentUtilsDocker(TestCase): def setUp(self): """"""Sets up a test case."""""" def tearDown(self): """"""Tears down a test case."""""" def test_stop_container(self): """"""Stop container"""""" try: docker_client = Mock() ga_utils_docker.stop_container(docker_client, ""foobar"") docker_client.containers.get.assert_called_once_with(""foobar"") except Exception: self.assertTrue(False) def test_stop_container_exception(self): """"""Catch the exception fot Stop container"""""" try: docker_client = Mock(side_effect=Exception) ga_utils_docker.stop_container(docker_client) self.assertTrue(False) except Exception: self.assertTrue(True) ",,47,5
openstack%2Freleases~master~I74f77cadd76ea887d8aa5b79251615c78d46aa1a,openstack/releases,master,I74f77cadd76ea887d8aa5b79251615c78d46aa1a,Proposed 2023.2 Bobcat release schedule,MERGED,2023-01-12 13:15:37.000000000,2023-01-27 14:21:04.000000000,2023-01-27 14:21:04.000000000,"[{'_account_id': 308}, {'_account_id': 7166}, {'_account_id': 11805}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-12 13:15:37.000000000', 'files': ['doc/source/bobcat/highlights.rst', 'doc/source/index.rst', 'doc/source/bobcat/index.rst', 'doc/source/bobcat/schedule.yaml', 'data/series_status.yaml', 'doc/source/bobcat/schedule.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/41891030e478e1b7dcda84bcd324cf4c3c5fbf96', 'message': 'Proposed 2023.2 Bobcat release schedule\n\nThis is a proposed release schedule for OpenStack 2023.2 ""Bobcat"",\nwith a total duration of 28 weeks.\n\nChange-Id: I74f77cadd76ea887d8aa5b79251615c78d46aa1a\n'}]",9,869976,41891030e478e1b7dcda84bcd324cf4c3c5fbf96,14,7,1,308,,,0,"Proposed 2023.2 Bobcat release schedule

This is a proposed release schedule for OpenStack 2023.2 ""Bobcat"",
with a total duration of 28 weeks.

Change-Id: I74f77cadd76ea887d8aa5b79251615c78d46aa1a
",git fetch https://review.opendev.org/openstack/releases refs/changes/76/869976/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/bobcat/highlights.rst', 'doc/source/index.rst', 'doc/source/bobcat/index.rst', 'doc/source/bobcat/schedule.yaml', 'data/series_status.yaml', 'doc/source/bobcat/schedule.rst']",6,41891030e478e1b7dcda84bcd324cf4c3c5fbf96,proposed-bobcat-schedule,"============================== 2023.2 Bobcat Release Schedule ============================== .. note:: Deadlines are generally the Thursday of the week on which they are noted below. Exceptions to this policy will be explicitly mentioned in the event description. March 22, 2023 - October 4, 2023 (28 weeks) .. datatemplate:: :source: schedule.yaml :template: schedule_table.tmpl .. ics:: :source: schedule.yaml :name: Bobcat `Subscribe to iCalendar file <schedule.ics>`_ Cross-project events ==================== .. _b-1: Bobcat-1 milestone ------------------ May 11, 2023 is the Bobcat-1 milestone. See project-specific notes for relevant deadlines. .. _b-cycle-trail: Bobcat Cycle-Trailing Release Deadline -------------------------------------- All projects following the cycle-trailing release model must release their Bobcat deliverables by June 1st, 2023. .. _b-summit: OpenInfra Summit in Vancouver ----------------------------- From June 13 to June 15, 2023, the OpenStack community will gather in Vancouver for the OpenInfra Summit. Discussions on the future of the software, as well as project team meetings will happen there. .. _b-2: Bobcat-2 milestone ------------------ July 6, 2023 is the Bobcat-2 milestone. See project-specific notes for relevant deadlines. .. _b-mf: Membership Freeze ----------------- Projects must participate in at least two milestones in order to be considered part of the release. Projects made official after the second milestone, or which fail to produce milestone releases for at least one of the first and second milestones as well as the third milestone, are therefore not considered part of the release for the cycle. This does not apply to cycle-trailing packaging / lifecycle management projects. .. _b-extra-atc-freeze: Extra-ATC freeze ---------------- All contributions to OpenStack are valuable, but some are not expressed as Gerrit code changes. That allow teams to list active contributors to their projects and who do not have a code contribution this cycle, and therefore won't automatically be considered an Active Technical Contributor and allowed to vote. This is done by adding extra-atcs to https://opendev.org/openstack/governance/src/branch/master/reference/projects.yaml before the Extra-ATC freeze on August 17, 2023. .. _b-final-lib: Final release for non-client libraries -------------------------------------- Libraries that are not client libraries (Oslo and others) should issue their final release during this week. That allows to give time for last-minute changes before feature freeze. .. _b-3: Bobcat-3 milestone ------------------ August 31, 2023 is the Bobcat-3 milestone. See project-specific notes for relevant deadlines. .. _b-ff: Feature freeze -------------- The Bobcat-3 milestone marks feature freeze for projects following the `release:cycle-with-rc`_ model. No featureful patch should be landed after this point. Exceptions may be granted by the project PTL. .. _release:cycle-with-rc: https://releases.openstack.org/reference/release_models.html#cycle-with-rc .. _b-final-clientlib: Final release for client libraries ---------------------------------- Client libraries should issue their final release during this week, to match feature freeze. .. _b-soft-sf: Soft StringFreeze ----------------- You are no longer allowed to accept proposed changes containing modifications in user-facing strings. Such changes should be rejected by the review team and postponed until the next series development opens (which should happen when RC1 is published). .. _b-rf: Requirements freeze ------------------- After the Bobcat-3 milestone, only critical requirements and constraints changes will be allowed. Freezing our requirements list gives packagers downstream an opportunity to catch up and prepare packages for everything necessary for distributions of the upcoming release. The requirements remain frozen until the stable branches are created, with the release candidates. .. _b-rc1: RC1 target week --------------- The week of September 11, 2023 is the target date for projects following the `release:cycle-with-rc`_ model to issue their first release candidate. .. _b-hard-sf: Hard StringFreeze ----------------- This happens when the RC1 for the project is tagged. At this point, ideally no strings are changed (or added, or removed), to give translators time to finish up their efforts. .. _b-finalrc: Final RCs and intermediary releases ----------------------------------- The week of September 25, 2023 is the last week to issue release candidates or intermediary releases before release week. During release week, only final-release-critical releases will be accepted (at the discretion of the release team). .. _b-final: Bobcat release -------------- The Bobcat coordinated release will happen on Wednesday, October 4, 2023. .. _b-cycle-highlights: Cycle Highlights ---------------- Cycle highlights need to be added to the release deliverables after the feature freeze to be included in any marketing release messaging. Highlights may be added after this point, but they will likely only be useful for historical purposes. See the `Project Team Guide`_ for more details and instructions on adding these highlights. For examples of previous release highlights: `Stein Highlights <https://releases.openstack.org/stein/highlights.html>`_, `Train Highlights <https://releases.openstack.org/train/highlights.html>`_, `Ussuri Highlights <https://releases.openstack.org/ussuri/highlights.html>`_, `Victoria Highlights <https://releases.openstack.org/victoria/highlights.html>`_, `Wallaby Highlights <https://releases.openstack.org/wallaby/highlights.html>`_, `Xena Highlights <https://releases.openstack.org/xena/highlights.html>`_, `Yoga Highlights <https://releases.openstack.org/yoga/highlights.html>`_, `Zed Highlights <https://releases.openstack.org/zed/highlights.html>`_. .. _Project Team Guide: https://docs.openstack.org/project-team-guide/release-management.html#cycle-highlights Project-specific events ======================= ",,362,0
openstack%2Foslo.log~master~I07d2126176d00acf361349fa6f8de6b34ae64a16,openstack/oslo.log,master,I07d2126176d00acf361349fa6f8de6b34ae64a16,tox - fix allowlist_external issues,MERGED,2023-01-27 09:28:14.000000000,2023-01-27 14:20:49.000000000,2023-01-27 14:19:29.000000000,"[{'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 09:28:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/f104bc44115794b4cd36337750835c35ec344bc5', 'message': 'tox - fix allowlist_external issues\n\nChange-Id: I07d2126176d00acf361349fa6f8de6b34ae64a16\n'}]",0,871967,f104bc44115794b4cd36337750835c35ec344bc5,7,2,1,28522,,,0,"tox - fix allowlist_external issues

Change-Id: I07d2126176d00acf361349fa6f8de6b34ae64a16
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/67/871967/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f104bc44115794b4cd36337750835c35ec344bc5,,allowlist_externals =allowlist_externals = rmallowlist_externals = rm,whitelist_externals =whitelist_externals = rmwhitelist_externals = rm,3,3
openstack%2Fcharm-designate~master~Ic6040969d2119383ce3f1b69a373363dec7428f1,openstack/charm-designate,master,Ic6040969d2119383ce3f1b69a373363dec7428f1,"Update bundles to use ""edge"" for mysql-* charms.",ABANDONED,2022-12-06 15:53:04.000000000,2023-01-27 13:19:09.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-06 15:53:04.000000000', 'files': ['src/tests/bundles/jammy-yoga.yaml', 'src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/164f00941f3a5a31c86ad4c25618b339aa22841b', 'message': 'Update bundles to use ""edge"" for mysql-* charms.\n\nThis change drops the use of the ""8.0/edge"" track for the mysql-* charms\nin favor of just ""edge"" as a workaround of charmhub/juju issue that\nmakes ""--force"" not able of deploying those charms to a ""base"" that the\ncharm doesn\'t advertise as supported.\n\nAs part of this change also the \'source\' config option override is being\ndropped from mysql-innodb-cluster and rabbitmq-server.\n\nRelated-Bug: #1996794\nChange-Id: Ic6040969d2119383ce3f1b69a373363dec7428f1\n'}]",0,866742,164f00941f3a5a31c86ad4c25618b339aa22841b,4,2,1,2424,,,0,"Update bundles to use ""edge"" for mysql-* charms.

This change drops the use of the ""8.0/edge"" track for the mysql-* charms
in favor of just ""edge"" as a workaround of charmhub/juju issue that
makes ""--force"" not able of deploying those charms to a ""base"" that the
charm doesn't advertise as supported.

As part of this change also the 'source' config option override is being
dropped from mysql-innodb-cluster and rabbitmq-server.

Related-Bug: #1996794
Change-Id: Ic6040969d2119383ce3f1b69a373363dec7428f1
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/42/866742/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/jammy-yoga.yaml', 'src/tests/bundles/jammy-zed.yaml', 'src/tests/bundles/kinetic-zed.yaml']",3,164f00941f3a5a31c86ad4c25618b339aa22841b,bug/1996794,applications: channel: edge channel: edge channel: edge channel: edge - '3' - '4' - '5' #openstack-origin: *openstack-origin to: - '6' - '7' - '8', applications: channel: latest/edge channel: latest/edge channel: latest/edge channel: latest/edge - '3' - '4' - '5' #openstack-origin: *openstack-origin to: - '6' - '7' - '8' ,33,109
openstack%2Fironic-inspector~master~I7ba858fb3f259b8e7a3becde94b7ba6b90615287,openstack/ironic-inspector,master,I7ba858fb3f259b8e7a3becde94b7ba6b90615287,Rename NodeInfo._lock to avoid conflict with Mock._lock in tests,MERGED,2023-01-10 13:31:06.000000000,2023-01-27 13:13:57.000000000,2023-01-27 13:12:40.000000000,"[{'_account_id': 6476}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 11805}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-10 13:31:06.000000000', 'files': ['ironic_inspector/node_cache.py', 'ironic_inspector/test/unit/test_introspect.py', 'ironic_inspector/test/unit/test_node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/cb1e856b9f04e17a7465a2cce5eb422d72736836', 'message': ""Rename NodeInfo._lock to avoid conflict with Mock._lock in tests\n\nStarting with https://github.com/python/cpython/pull/98797, Python's\nMock has its own _lock. I hope they rename it to something really\nprivate (e.g. __lock), but for now rename our attribute (and hope that\nno downstream plugins relied on it, sigh).\n\nChange-Id: I7ba858fb3f259b8e7a3becde94b7ba6b90615287\n""}]",7,869719,cb1e856b9f04e17a7465a2cce5eb422d72736836,20,6,1,10239,,,0,"Rename NodeInfo._lock to avoid conflict with Mock._lock in tests

Starting with https://github.com/python/cpython/pull/98797, Python's
Mock has its own _lock. I hope they rename it to something really
private (e.g. __lock), but for now rename our attribute (and hope that
no downstream plugins relied on it, sigh).

Change-Id: I7ba858fb3f259b8e7a3becde94b7ba6b90615287
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/19/869719/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_inspector/node_cache.py', 'ironic_inspector/test/unit/test_introspect.py', 'ironic_inspector/test/unit/test_node_cache.py']",3,cb1e856b9f04e17a7465a2cce5eb422d72736836,is_locked, self.assertFalse(node._node_lock.is_locked()) self.assertTrue(res._node_lock.is_locked()) self.assertTrue(res._node_lock.is_locked()) self.assertTrue(res._node_lock.is_locked()) self.assertFalse(info._node_lock.is_locked()) self.assertFalse(info._node_lock.is_locked()) self.assertFalse(self.node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertTrue(node_info._node_lock.is_locked()) self.assertFalse(node_info._node_lock.is_locked()), self.assertFalse(node._lock.is_locked()) self.assertTrue(res._lock.is_locked()) self.assertTrue(res._lock.is_locked()) self.assertTrue(res._lock.is_locked()) self.assertFalse(info._lock.is_locked()) self.assertFalse(info._lock.is_locked()) self.assertFalse(self.node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertTrue(node_info._lock.is_locked()) self.assertFalse(node_info._lock.is_locked()),28,27
openstack%2Fironic-specs~master~I336b437f1914c0b18ca299dff9dd022628e5f445,openstack/ironic-specs,master,I336b437f1914c0b18ca299dff9dd022628e5f445,Clarify model; bugfix branches not guaranteed,MERGED,2023-01-23 20:41:49.000000000,2023-01-27 13:12:56.000000000,2023-01-27 13:11:41.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-23 20:41:49.000000000', 'files': ['specs/approved/new-release-model.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/ffd639ea62966a275904a4b0871fe5b2970415ff', 'message': 'Clarify model; bugfix branches not guaranteed\n\nIn practice, we often skip bugfix branch releases if we do not have\ndownstream consumers for those releases or do not have significant\nchanges. Ensure our docs are clear on this.\n\nChange-Id: I336b437f1914c0b18ca299dff9dd022628e5f445\n'}]",1,871535,ffd639ea62966a275904a4b0871fe5b2970415ff,10,4,1,10342,,,0,"Clarify model; bugfix branches not guaranteed

In practice, we often skip bugfix branch releases if we do not have
downstream consumers for those releases or do not have significant
changes. Ensure our docs are clear on this.

Change-Id: I336b437f1914c0b18ca299dff9dd022628e5f445
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/35/871535/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/new-release-model.rst'],1,ffd639ea62966a275904a4b0871fe5b2970415ff,,"* Releases for all deliverables are evaluated on a loose bi-monthly basis, i.e. roughly every 2 months. If there are significant valuable changes, and a clear user interest in performing a release, we should do so. In most cases, this means a downstream distributor of Ironic is going to consume the release. This gives up to 6 releases a year, 3 per each OpenStack cycle. * Two releases a year correspond to OpenStack named releases, the others happen skipped if there are no known consumers for that release or a deliverable does not see notable changes within 2 months.","* Releases for all deliverables are created on a loose bi-monthly basis, i.e. roughly every 2 months. Here *roughly* means that the team may decide to release a few days earlier (if the desired scope is already implemented) or later (if last minute merges are required). This gives 6 releases a year, 3 per each OpenStack cycle. * Two releases a year correspond to OpenStack named releases, other 4 happen skipped if a deliverable does not see notable changes within 2 months.",9,7
openstack%2Freleases~master~I75a8d9d941151ee6fb55a275128df6e19e5e6655,openstack/releases,master,I75a8d9d941151ee6fb55a275128df6e19e5e6655,[cinder-tempest-plugin] Tag wallaby-last,MERGED,2022-12-26 04:22:17.000000000,2023-01-27 12:55:40.000000000,2023-01-27 12:55:40.000000000,"[{'_account_id': 308}, {'_account_id': 9236}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2022-12-26 04:22:17.000000000', 'files': ['deliverables/antelope/cinder-tempest-plugin.yaml', 'deliverables/wallaby/cinder-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/336858cda294aec582c1dd207dbc0e8cad23d885', 'message': ""[cinder-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: I75a8d9d941151ee6fb55a275128df6e19e5e6655\n""}]",7,868581,336858cda294aec582c1dd207dbc0e8cad23d885,11,5,1,8556,,,0,"[cinder-tempest-plugin] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' as well as a new version also with same hash.

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: I75a8d9d941151ee6fb55a275128df6e19e5e6655
",git fetch https://review.opendev.org/openstack/releases refs/changes/81/868581/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/cinder-tempest-plugin.yaml', 'deliverables/wallaby/cinder-tempest-plugin.yaml']",2,336858cda294aec582c1dd207dbc0e8cad23d885,wallaby-last, - version: wallaby-last projects: - repo: openstack/cinder-tempest-plugin hash: 0e9461155e2acf2d68f2b42c8a5942af8975190a,,9,0
openstack%2Fnova~stable%2Fvictoria~Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,openstack/nova,stable/victoria,Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,Improving logging at '_allocate_mdevs'.,ABANDONED,2023-01-23 05:17:57.000000000,2023-01-27 12:42:24.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 05:17:57.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/686f622901132f41b5863602bafd54affb3aec69', 'message': ""Improving logging at '_allocate_mdevs'.\n\nAdding both 'info' and 'debug' messages with the intention of telling\nwhich mdevs are available, which get allocated and whether new ones\nare created.\n\nCloses-Bug: #1992451\nChange-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452\n(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)\n(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)\n(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)\n(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)\n(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)\n""}]",5,871417,686f622901132f41b5863602bafd54affb3aec69,15,1,1,34860,,,0,"Improving logging at '_allocate_mdevs'.

Adding both 'info' and 'debug' messages with the intention of telling
which mdevs are available, which get allocated and whether new ones
are created.

Closes-Bug: #1992451
Change-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452
(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)
(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)
(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)
(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)
(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/871417/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,686f622901132f41b5863602bafd54affb3aec69,bug/1992451," LOG.debug('Searching for available mdevs...') LOG.info('Available mdevs at: %s.', available_mdevs) LOG.debug('Attempting to create new mdev...') LOG.debug('Trying on: %s.', dev_name) LOG.info('Created mdev: %s on pGPU: %s.', chosen_mdev, pci_addr) LOG.debug('Failed: No available instances on device.') LOG.info('Failed to create mdev. ' 'No free space found among the following devices: %s.', [dev['dev_id'] for dev in devices]) LOG.debug('No available mdevs where found. ' 'Creating an new one...') LOG.info('Allocated mdev: %s.', chosen_mdev)",,13,0
openstack%2Fnova~stable%2Fussuri~Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,openstack/nova,stable/ussuri,Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,Improving logging at '_allocate_mdevs'.,ABANDONED,2023-01-23 05:19:40.000000000,2023-01-27 12:42:05.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 05:19:40.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/54b8a8d9e7eec6c89a90b4e65348401cdb8561e2', 'message': ""Improving logging at '_allocate_mdevs'.\n\nAdding both 'info' and 'debug' messages with the intention of telling\nwhich mdevs are available, which get allocated and whether new ones\nare created.\n\nCloses-Bug: #1992451\nChange-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452\n(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)\n(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)\n(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)\n(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)\n(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)\n(cherry picked from commit 686f622901132f41b5863602bafd54affb3aec69)\n""}]",2,871419,54b8a8d9e7eec6c89a90b4e65348401cdb8561e2,9,1,1,34860,,,0,"Improving logging at '_allocate_mdevs'.

Adding both 'info' and 'debug' messages with the intention of telling
which mdevs are available, which get allocated and whether new ones
are created.

Closes-Bug: #1992451
Change-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452
(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)
(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)
(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)
(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)
(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)
(cherry picked from commit 686f622901132f41b5863602bafd54affb3aec69)
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/871419/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,54b8a8d9e7eec6c89a90b4e65348401cdb8561e2,bug/1992451," LOG.debug('Searching for available mdevs...') LOG.info('Available mdevs at: %s.', available_mdevs) LOG.debug('Attempting to create new mdev...') LOG.debug('Trying on: %s.', dev_name) LOG.info('Created mdev: %s on pGPU: %s.', chosen_mdev, pci_addr) LOG.debug('Failed: No available instances on device.') LOG.info('Failed to create mdev. ' 'No free space found among the following devices: %s.', [dev['dev_id'] for dev in devices]) LOG.debug('No available mdevs where found. ' 'Creating an new one...') LOG.info('Allocated mdev: %s.', chosen_mdev)",,13,0
openstack%2Fnova~stable%2Ftrain~Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,openstack/nova,stable/train,Ibd331df51fd4eaeed4831a98469f06a4ce0cd452,Improving logging at '_allocate_mdevs'.,ABANDONED,2023-01-23 06:09:35.000000000,2023-01-27 12:41:43.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 06:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/543f34d41150c11b8c837c8897611c54c398b212', 'message': ""Improving logging at '_allocate_mdevs'.\n\nAdding both 'info' and 'debug' messages with the intention of telling\nwhich mdevs are available, which get allocated and whether new ones\nare created.\n\nNOTE(auniyal): Differences from ussuri to train\n  * create_mdev: supported vgpu types were not required in train,\n    dev_name is defined once dev_type is verified.\n\nCloses-Bug: #1992451\nChange-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452\n(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)\n(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)\n(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)\n(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)\n(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)\n(cherry picked from commit 686f622901132f41b5863602bafd54affb3aec69)\n(cherry picked from commit 54b8a8d9e7eec6c89a90b4e65348401cdb8561e2)\n""}, {'number': 2, 'created': '2023-01-23 06:26:40.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fddd8d672aaac2f1d233be40b22dcd213e8b95fd', 'message': ""Improving logging at '_allocate_mdevs'.\n\nAdding both 'info' and 'debug' messages with the intention of telling\nwhich mdevs are available, which get allocated and whether new ones\nare created.\n\nNOTE(auniyal): Differences from ussuri to train\n  * create_mdev: supported vgpu types were not required in train,\n    dev_name is defined once dev_type is verified.\n\nCloses-Bug: #1992451\nChange-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452\n(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)\n(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)\n(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)\n(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)\n(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)\n(cherry picked from commit 686f622901132f41b5863602bafd54affb3aec69)\n(cherry picked from commit 54b8a8d9e7eec6c89a90b4e65348401cdb8561e2)\n""}]",0,871444,fddd8d672aaac2f1d233be40b22dcd213e8b95fd,5,1,2,34860,,,0,"Improving logging at '_allocate_mdevs'.

Adding both 'info' and 'debug' messages with the intention of telling
which mdevs are available, which get allocated and whether new ones
are created.

NOTE(auniyal): Differences from ussuri to train
  * create_mdev: supported vgpu types were not required in train,
    dev_name is defined once dev_type is verified.

Closes-Bug: #1992451
Change-Id: Ibd331df51fd4eaeed4831a98469f06a4ce0cd452
(cherry picked from commit 6feb3350b048606297068841e3feba110bb0b0ab)
(cherry picked from commit 03374cf4a2ff98c938691a209d6a3fb14a06d3a0)
(cherry picked from commit 9f6ca77a184379e90e10d6705fbd78208debb612)
(cherry picked from commit e099571d0f0120e481d966337388fdd563edbaff)
(cherry picked from commit b5ea5f1902ea1976fcc8485c21e7a8ec4896ae36)
(cherry picked from commit 686f622901132f41b5863602bafd54affb3aec69)
(cherry picked from commit 54b8a8d9e7eec6c89a90b4e65348401cdb8561e2)
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/871444/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,543f34d41150c11b8c837c8897611c54c398b212,bug/1992451," LOG.debug('Searching for available mdevs...') LOG.info('Available mdevs at: %s.', available_mdevs) LOG.debug('Attempting to create new mdev...') LOG.debug('Trying on: %s.', device['dev_id']) LOG.info('Created mdev: %s on pGPU: %s.', chosen_mdev, pci_addr) LOG.debug('Failed: No available instances on device.') LOG.info('Failed to create mdev. ' 'No free space found among the following devices: %s.', [dev['dev_id'] for dev in devices]) LOG.debug('No available mdevs where found. ' 'Creating an new one...') LOG.info('Allocated mdev: %s.', chosen_mdev)",,13,0
openstack%2Ftripleo-common~master~I742891ca11d77ef4b280d1a1518667992563a16a,openstack/tripleo-common,master,I742891ca11d77ef4b280d1a1518667992563a16a,Fix still missing become to get deployment result,MERGED,2023-01-26 09:27:13.000000000,2023-01-27 12:04:22.000000000,2023-01-27 12:03:14.000000000,"[{'_account_id': 6926}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 31245}]","[{'number': 1, 'created': '2023-01-26 09:27:13.000000000', 'files': ['tripleo_common/templates/deployments.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2b51904a35c454923a92bbbbc162878bf7a9932d', 'message': 'Fix still missing become to get deployment result\n\nThis is follow-up of I1bf6987f2feab13ee22ffd240e7a5b0c19346c58 and\nfixes the missing become to read the deployment result. The previous\nchange fixed only the task to check whether the result file exists.\n\nChange-Id: I742891ca11d77ef4b280d1a1518667992563a16a\n'}]",1,871811,2b51904a35c454923a92bbbbc162878bf7a9932d,13,6,1,9816,,,0,"Fix still missing become to get deployment result

This is follow-up of I1bf6987f2feab13ee22ffd240e7a5b0c19346c58 and
fixes the missing become to read the deployment result. The previous
change fixed only the task to check whether the result file exists.

Change-Id: I742891ca11d77ef4b280d1a1518667992563a16a
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/11/871811/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/templates/deployments.yaml'],1,2b51904a35c454923a92bbbbc162878bf7a9932d,, become: true,,1,0
openstack%2Fcloudkitty~master~I69f8eab3c71a469f81561beac32b8193339237c0,openstack/cloudkitty,master,I69f8eab3c71a469f81561beac32b8193339237c0,"Add missing ""."" for api-ref",MERGED,2023-01-27 08:38:36.000000000,2023-01-27 11:42:51.000000000,2023-01-27 11:41:43.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 25277}, {'_account_id': 28356}]","[{'number': 1, 'created': '2023-01-27 08:38:36.000000000', 'files': ['api-ref/source/v2/http_status.yml'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/73d5543f15ec188fafa1562f4142edd41afbad5c', 'message': 'Add missing ""."" for api-ref\n\nAdd missing ""."" for list of errors, all others have a ""."" except 404.\n\nThis change is also meant to help debug why api-ref is not published at\nall. See\nhttps://review.opendev.org/c/openstack/openstack-manuals/+/867357 for\ndetails.\n\nChange-Id: I69f8eab3c71a469f81561beac32b8193339237c0\n'}]",3,871964,73d5543f15ec188fafa1562f4142edd41afbad5c,9,4,1,6547,,,0,"Add missing ""."" for api-ref

Add missing ""."" for list of errors, all others have a ""."" except 404.

This change is also meant to help debug why api-ref is not published at
all. See
https://review.opendev.org/c/openstack/openstack-manuals/+/867357 for
details.

Change-Id: I69f8eab3c71a469f81561beac32b8193339237c0
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/64/871964/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/http_status.yml'],1,73d5543f15ec188fafa1562f4142edd41afbad5c,api-ref, default: Not found., default: Not found,1,1
openstack%2Fnova-specs~master~I195337b2f927bc3ce51e25d623a122d0b164730e,openstack/nova-specs,master,I195337b2f927bc3ce51e25d623a122d0b164730e,Add audio device to libvirt XML by nova libvirt driver,NEW,2022-11-27 15:25:58.000000000,2023-01-27 11:29:24.000000000,,"[{'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 16198}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-27 15:25:58.000000000', 'files': ['specs/2023.1/approved/libvirt-audio-device.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2fc10a243448cd2d3503c146b499c8b02754c3a3', 'message': 'Add audio device to libvirt XML by nova libvirt driver\n\nThis spec proposes adding the ability to add an audio card to an\ninstance with processing custom image metadata.\n\nBlueprint: libvirt-audio-device\nChange-Id: I195337b2f927bc3ce51e25d623a122d0b164730e\n'}]",11,865634,2fc10a243448cd2d3503c146b499c8b02754c3a3,6,4,1,33855,,,0,"Add audio device to libvirt XML by nova libvirt driver

This spec proposes adding the ability to add an audio card to an
instance with processing custom image metadata.

Blueprint: libvirt-audio-device
Change-Id: I195337b2f927bc3ce51e25d623a122d0b164730e
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/34/865634/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/2023.1/approved/libvirt-audio-device.rst'],1,2fc10a243448cd2d3503c146b499c8b02754c3a3,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================================== Add audio device to libvirt XML by nova libvirt driver =========================================================== https://blueprints.launchpad.net/nova/+spec/libvirt-audio-device This spec proposes adding the ability to add an audio card to an instance with processing custom image metadata. In the absence of metadata data, the audio card will not be added. Problem description =================== For the purposes of using a vm with a graphical interface or vdi with an openstack, it is not possible to connect an audio device via spice. Use Cases --------- * An operator should be able to cofigure possibility of adding audio device for instance. * A user should be able to access the graphical console of an instance (via VNC or SPICE) with audio transmission. Proposed change =============== This spec proposes to add ability to extend devices section in instance libvirt xml with sound cart field. [1]_ .. code-block:: xml <devices> <sound model='es1370'/> </devices> To set the sound card model, it is proposed to use user metadata of the operating system image (for example, hw_sound_model, hw_sound_codec). Thus, when creating an instance from this image, the sound card will be automatically added to libvirt xml. You can specify a codec for the card, but only for two models [1]_. The codec name is suggested to be specified via the hw_sound_codec property. .. code-block:: xml <devices> <sound model='ich6'> <codec type='micro'/> </sound> </devices> In the absence of the specified metadata, xml will not change. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Upgrade impact -------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: weanew Other contributors: None Feature Liaison --------------- Feature liaison: None Work Items ---------- * Add metadata processing to the nova libvirt driver. * Add information about new metadata to the nova documentation. Dependencies ============ None. Testing ======= * Implement unit tests for each function to cover testing of added and changed methods. Documentation Impact ==================== * Extend the Nova extra specs documentation. References ========== .. [1] https://libvirt.org/formatdomain.html#sound-devices History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - 2023.1 Antelope - Introduced",,168,0
openstack%2Fos-brick~master~I3149e0067f97d373333e0901e49725401fc6c068,openstack/os-brick,master,I3149e0067f97d373333e0901e49725401fc6c068,mypy: Annotate utils.get_device_size,MERGED,2022-11-15 18:05:10.000000000,2023-01-27 11:05:03.000000000,2023-01-20 17:37:30.000000000,"[{'_account_id': 13425}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 32074}]","[{'number': 1, 'created': '2022-11-15 18:05:10.000000000', 'files': ['os_brick/utils.py', 'os_brick/initiator/connectors/nvmeof.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/dc953012b7e83a7dabaa6dec8697caec3dec9d71', 'message': 'mypy: Annotate utils.get_device_size\n\nAdd annotations for parameters of this method.\n\nChange-Id: I3149e0067f97d373333e0901e49725401fc6c068\n'}]",10,864288,dc953012b7e83a7dabaa6dec8697caec3dec9d71,26,5,1,4523,,,0,"mypy: Annotate utils.get_device_size

Add annotations for parameters of this method.

Change-Id: I3149e0067f97d373333e0901e49725401fc6c068
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/88/864288/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/utils.py', 'os_brick/initiator/connectors/nvmeof.py']",2,dc953012b7e83a7dabaa6dec8697caec3dec9d71,," size = utils.get_device_size(self, device_path) if size is None: raise exception.BrickException( 'get_device_size returned non-numeric size') return size"," return utils.get_device_size(self, device_path)",7,2
openstack%2Fovsdbapp~master~I7ec80abf6bda33ad3f074309f64491ee4af1c71b,openstack/ovsdbapp,master,I7ec80abf6bda33ad3f074309f64491ee4af1c71b,Update tox.ini for tox4,MERGED,2023-01-27 08:30:54.000000000,2023-01-27 11:04:38.000000000,2023-01-27 11:03:39.000000000,"[{'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 08:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/3ceebc80a7a9f88e48c5448d4c9bebeac6aa013e', 'message': 'Update tox.ini for tox4\n\nChange-Id: I7ec80abf6bda33ad3f074309f64491ee4af1c71b\n'}, {'number': 2, 'created': '2023-01-27 08:44:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/149d7db4a70fd9c87a6b6fe8275d779babd30374', 'message': 'Update tox.ini for tox4\n\nChange-Id: I7ec80abf6bda33ad3f074309f64491ee4af1c71b\n'}]",0,871963,149d7db4a70fd9c87a6b6fe8275d779babd30374,10,4,2,16688,,,0,"Update tox.ini for tox4

Change-Id: I7ec80abf6bda33ad3f074309f64491ee4af1c71b
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/63/871963/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3ceebc80a7a9f88e48c5448d4c9bebeac6aa013e,tox4,minversion = 3.18.0basepython = {env:TOX_PYTHON:python3}allowlist_externals =,minversion = 3.1.1skipsdist = Truebasepython = python3whitelist_externals =,3,4
openstack%2Fopenstack-ansible~master~I13b9a8994f85df9facd9d077c9a5b5964513b1f4,openstack/openstack-ansible,master,I13b9a8994f85df9facd9d077c9a5b5964513b1f4,Imported Translations from Zanata,MERGED,2023-01-27 03:24:52.000000000,2023-01-27 10:53:07.000000000,2023-01-27 10:51:38.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-01-27 03:24:52.000000000', 'files': ['doc/source/locale/en_GB/LC_MESSAGES/doc-contributor.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/id/LC_MESSAGES/doc-user.po', 'doc/source/locale/id/LC_MESSAGES/doc-admin.po', 'doc/source/locale/ru/LC_MESSAGES/doc-user.po', 'doc/source/locale/de/LC_MESSAGES/doc-admin.po', 'doc/source/locale/de/LC_MESSAGES/doc-user.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-admin.po'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/168febc03a1167156ae9d18e821bc4fd52161b93', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I13b9a8994f85df9facd9d077c9a5b5964513b1f4\n'}]",0,871929,168febc03a1167156ae9d18e821bc4fd52161b93,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I13b9a8994f85df9facd9d077c9a5b5964513b1f4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/29/871929/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/locale/en_GB/LC_MESSAGES/doc-contributor.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc.po', 'doc/source/locale/id/LC_MESSAGES/doc-user.po', 'doc/source/locale/id/LC_MESSAGES/doc-admin.po', 'doc/source/locale/ru/LC_MESSAGES/doc-user.po', 'doc/source/locale/de/LC_MESSAGES/doc-admin.po', 'doc/source/locale/de/LC_MESSAGES/doc-user.po', 'doc/source/locale/en_GB/LC_MESSAGES/doc-admin.po']",8,168febc03a1167156ae9d18e821bc4fd52161b93,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""Project-Id-Version: openstack-ansible 26.1.0.dev49\n""""POT-Creation-Date: 2023-01-25 16:18+0000\n""""PO-Revision-Date: 2023-01-26 10:24+0000\n""msgid """" ""Ceph related playbooks are included as part of ``setup-infrastructure.yml`` "" ""and ``setup-openstack.yml`` playbooks, so you should be cautious when "" ""running them during OpenStack upgrades. If you have ``upgrade_ceph_packages: "" ""true`` in your user variables or provided ``-e upgrade_ceph_packages=true`` "" ""as argument and run ``setup-infrastructure.yml`` this will result in Ceph "" ""package being upgraded as well."" msgstr """" ""Ceph related playbooks are included as part of ``setup-infrastructure.yml`` "" ""and ``setup-openstack.yml`` playbooks, so you should be cautious when "" ""running them during OpenStack upgrades. If you have ``upgrade_ceph_packages: "" ""true`` in your user variables or provided ``-e upgrade_ceph_packages=true`` "" ""as argument and run ``setup-infrastructure.yml`` this will result in Ceph "" ""package being upgraded as well."" ""Ensure that you have defined all required variables for current Neutron "" ""plugin"" msgstr """" ""Ensure that you have defined all required variables for current Neutron "" ""plugin"" msgid """"""If Ceph has been deployed as part of an OpenStack-Ansible deployment using "" ""the roles maintained by the `Ceph-Ansible`_ project you will also need to "" ""upgrade the Ceph version. Each OpenStack-Ansible release is tested only with "" ""specific Ceph-Ansible release and Ceph upgrades are not checked in any "" ""Openstack-Ansible integration tests. So we do not test or guarantee an "" ""upgrade path for such deployments. In this case tests should be done in a "" ""lab environment before upgrading."" msgstr """" ""If Ceph has been deployed as part of an OpenStack-Ansible deployment using "" ""the roles maintained by the `Ceph-Ansible`_ project you will also need to "" ""upgrade the Ceph version. Each OpenStack-Ansible release is tested only with "" ""specific Ceph-Ansible release and Ceph upgrades are not checked in any "" ""Openstack-Ansible integration tests. So we do not test or guarantee an "" ""upgrade path for such deployments. In this case tests should be done in a "" ""lab environment before upgrading."" msgid """"msgid ""In order to upgrade Ceph in the deployment you will need to run:"" msgstr ""In order to upgrade Ceph in the deployment you will need to run:"" msgid """" ""Now, once all services are being re-configured, we can run haproxy role to "" ""apply new configuration for the backends"" msgstr """" ""Now, once all services are being re-configured, we can run haproxy role to "" ""apply new configuration for the backends"" msgid ""Run haproxy re-configuration"" msgstr ""Run haproxy re-configuration"" msgid ""Upgrade Ceph"" msgstr ""Upgrade Ceph"" ""flags. We also skip upgrading haproxy re-configuration at this step, since "" ""some services will become unavailable right after running haproxy role, "" ""which we want to avoid""""To ensure that RabbitMQ and MariaDB are upgraded, we pass the appropriate "" ""flags. We also skip upgrading haproxy re-configuration at this step, since "" ""some services will become unavailable right after running haproxy role, "" ""which we want to avoid""""With each OpenStack-Ansible version we define default Ceph client version "" ""that will be installed on Glance/Cinder/Nova hosts and used by these "" ""services. If you want to preserve the previous version of the ceph client "" ""during an OpenStack-Ansible upgrade, you will need to override a variable "" ""``ceph_stable_release`` in your user_variables.yml"" msgstr """" ""With each OpenStack-Ansible version we define the default Ceph client "" ""version that will be installed on Glance/Cinder/Nova hosts and used by these "" ""services. If you want to preserve the previous version of the ceph client "" ""during an OpenStack-Ansible upgrade, you will need to override a variable "" ""``ceph_stable_release`` in your user_variables.yml"" msgid """"","""Project-Id-Version: openstack-ansible 26.1.0.dev1\n""""POT-Creation-Date: 2022-12-16 09:53+0000\n""""PO-Revision-Date: 2022-11-07 02:47+0000\n""""flags.""""To ensure that rabbitmq and mariadb are upgraded, we pass the appropriate "" ""flags.""",150,225
openstack%2Fopenstack-ansible~stable%2Fzed~I348dc1220106ff5ed65b4a7ee3765e13835960ae,openstack/openstack-ansible,stable/zed,I348dc1220106ff5ed65b4a7ee3765e13835960ae,Bump OSA for stable/zed to cover CVE-2022-47951,MERGED,2023-01-26 16:03:07.000000000,2023-01-27 10:52:50.000000000,2023-01-27 10:51:35.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-26 16:03:07.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/ossa-2023-002-0ee5aa141d4ee69d.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f54fc43f0d3097a78dd73477e4a57e5e03280268', 'message': 'Bump OSA for stable/zed to cover CVE-2022-47951\n\nChange-Id: I348dc1220106ff5ed65b4a7ee3765e13835960ae\n'}]",0,871830,f54fc43f0d3097a78dd73477e4a57e5e03280268,8,3,1,28619,,,0,"Bump OSA for stable/zed to cover CVE-2022-47951

Change-Id: I348dc1220106ff5ed65b4a7ee3765e13835960ae
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/30/871830/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'releasenotes/notes/ossa-2023-002-0ee5aa141d4ee69d.yaml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'ansible-role-requirements.yml']",6,f54fc43f0d3097a78dd73477e4a57e5e03280268,bump_osa, version: 6551e127f283e202956e0efb89d9e3caed2c4007 shallow_since: '2023-01-24' version: 18ec82051494d2fe5c7d1398a4096a57d7275ce6 shallow_since: '2023-01-24', version: aa6b331296f808c2bc1161edc672f18ab39b4897 shallow_since: '2022-12-27' version: 8bda73adff6a405e81a83c0d6007564be6fa1599 shallow_since: '2022-12-12',22,17
openstack%2Fneutron~stable%2Fxena~Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,openstack/neutron,stable/xena,Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,[Trunk] Update the trunk status with the parent status,MERGED,2023-01-26 16:23:30.000000000,2023-01-27 10:49:04.000000000,2023-01-27 10:47:26.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 16:23:30.000000000', 'files': ['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a94143d4fdb140f1df15044c0350c1fc699978b2', 'message': '[Trunk] Update the trunk status with the parent status\n\nAfter a trunk VM has been migrated the trunk status remains\nDOWN, After the parent port is back to active modify the trunk\nstatus.\n\nCloses-Bug: #1988549\nChange-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79\n(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)\n'}]",1,871762,a94143d4fdb140f1df15044c0350c1fc699978b2,9,3,1,34118,,,0,"[Trunk] Update the trunk status with the parent status

After a trunk VM has been migrated the trunk status remains
DOWN, After the parent port is back to active modify the trunk
status.

Closes-Bug: #1988549
Change-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79
(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/871762/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py']",2,a94143d4fdb140f1df15044c0350c1fc699978b2,trunk-status-stable/xena,"from neutron_lib import constants as const orig_status = original_port.get('status') new_status = updated_port.get('status') trunk_id = trunk_details['trunk_id'] if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: elif new_status == const.PORT_STATUS_ACTIVE and \ new_status != orig_status: self.update_trunk( context, trunk_id, {'trunk': {'status': constants.TRUNK_ACTIVE_STATUS}})", if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: trunk_id = trunk_details['trunk_id'],36,1
openstack%2Fneutron~stable%2Fzed~Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,openstack/neutron,stable/zed,Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,[Trunk] Update the trunk status with the parent status,MERGED,2023-01-26 16:22:39.000000000,2023-01-27 10:48:57.000000000,2023-01-27 10:47:18.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 16:22:39.000000000', 'files': ['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2617f7b93c468263c81f57073f8828063454838b', 'message': '[Trunk] Update the trunk status with the parent status\n\nAfter a trunk VM has been migrated the trunk status remains\nDOWN, After the parent port is back to active modify the trunk\nstatus.\n\nCloses-Bug: #1988549\nChange-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79\n(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)\n'}]",2,871760,2617f7b93c468263c81f57073f8828063454838b,9,3,1,34118,,,0,"[Trunk] Update the trunk status with the parent status

After a trunk VM has been migrated the trunk status remains
DOWN, After the parent port is back to active modify the trunk
status.

Closes-Bug: #1988549
Change-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79
(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/60/871760/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py']",2,2617f7b93c468263c81f57073f8828063454838b,trunk-status-stable/zed,"from neutron_lib import constants as const orig_status = original_port.get('status') new_status = updated_port.get('status') trunk_id = trunk_details['trunk_id'] if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: elif new_status == const.PORT_STATUS_ACTIVE and \ new_status != orig_status: self.update_trunk( context, trunk_id, {'trunk': {'status': constants.TRUNK_ACTIVE_STATUS}})", if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: trunk_id = trunk_details['trunk_id'],36,1
openstack%2Fneutron~stable%2Fyoga~Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,openstack/neutron,stable/yoga,Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79,[Trunk] Update the trunk status with the parent status,MERGED,2023-01-26 16:23:13.000000000,2023-01-27 10:48:46.000000000,2023-01-27 10:47:22.000000000,"[{'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 16:23:13.000000000', 'files': ['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/254d3d0e5cc5fc0fb3fbc28606cde1f36ab57ba9', 'message': '[Trunk] Update the trunk status with the parent status\n\nAfter a trunk VM has been migrated the trunk status remains\nDOWN, After the parent port is back to active modify the trunk\nstatus.\n\nCloses-Bug: #1988549\nChange-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79\n(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)\n'}]",1,871761,254d3d0e5cc5fc0fb3fbc28606cde1f36ab57ba9,9,3,1,34118,,,0,"[Trunk] Update the trunk status with the parent status

After a trunk VM has been migrated the trunk status remains
DOWN, After the parent port is back to active modify the trunk
status.

Closes-Bug: #1988549
Change-Id: Ia0f7a6e8510af2c3545993e0d0d4bb06a9b70b79
(cherry picked from commit 178ee6fd3d76802cd7f577ad3d0d190117e78962)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/871761/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/services/trunk/test_plugin.py', 'neutron/services/trunk/plugin.py']",2,254d3d0e5cc5fc0fb3fbc28606cde1f36ab57ba9,trunk-status-stable/yoga,"from neutron_lib import constants as const orig_status = original_port.get('status') new_status = updated_port.get('status') trunk_id = trunk_details['trunk_id'] if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: elif new_status == const.PORT_STATUS_ACTIVE and \ new_status != orig_status: self.update_trunk( context, trunk_id, {'trunk': {'status': constants.TRUNK_ACTIVE_STATUS}})", if vif_type_changed and new_vif_type == portbindings.VIF_TYPE_UNBOUND: trunk_id = trunk_details['trunk_id'],36,1
openstack%2Fneutron~master~I3aafe1aba406a52bc2b57be5133dee15b8848796,openstack/neutron,master,I3aafe1aba406a52bc2b57be5133dee15b8848796,[API] Add API extension and definition for default SG rules,MERGED,2023-01-09 11:08:51.000000000,2023-01-27 10:48:38.000000000,2023-01-27 10:47:12.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 32586}, {'_account_id': 34271}]","[{'number': 1, 'created': '2023-01-09 11:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/491202951d198e512649ae7da2fda985b03582d9', 'message': '[API] Add API extension and definition for default SG rules\n\nThis patch adds API definition and API extension class for\nsecurity group rules templates API described in the spec [1].\nAPI definition in this case is very similar to the securitygroup API\ndefinition and uses same converters and validators which are still in\nNeutron instead of neutron-lib repo. Because of that this new API\ndefinition is proposed to the neutron repo first and will be rehomed to\nneutron-lib together with security groups API definition later.\n\n[1] https://specs.openstack.org/openstack/neutron-specs/specs/2023.1/configurable-default-sg-rules.html\n\nRelated-bug: #1983053\nChange-Id: I3aafe1aba406a52bc2b57be5133dee15b8848796\n'}, {'number': 2, 'created': '2023-01-23 11:35:45.000000000', 'files': ['neutron/extensions/security_groups_default_rules.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d73f75c551c36b15eed43f0b19ed796626cc8cb5', 'message': '[API] Add API extension and definition for default SG rules\n\nThis patch adds API definition and API extension class for\nsecurity group rules templates API described in the spec [1].\nAPI definition in this case is very similar to the securitygroup API\ndefinition and uses same converters and validators which are still in\nNeutron instead of neutron-lib repo. Because of that this new API\ndefinition is proposed to the neutron repo first and will be rehomed to\nneutron-lib together with security groups API definition later.\n\n[1] https://specs.openstack.org/openstack/neutron-specs/specs/2023.1/configurable-default-sg-rules.html\n\nRelated-bug: #1983053\nChange-Id: I3aafe1aba406a52bc2b57be5133dee15b8848796\n'}]",7,869554,d73f75c551c36b15eed43f0b19ed796626cc8cb5,18,8,2,11975,,,0,"[API] Add API extension and definition for default SG rules

This patch adds API definition and API extension class for
security group rules templates API described in the spec [1].
API definition in this case is very similar to the securitygroup API
definition and uses same converters and validators which are still in
Neutron instead of neutron-lib repo. Because of that this new API
definition is proposed to the neutron repo first and will be rehomed to
neutron-lib together with security groups API definition later.

[1] https://specs.openstack.org/openstack/neutron-specs/specs/2023.1/configurable-default-sg-rules.html

Related-bug: #1983053
Change-Id: I3aafe1aba406a52bc2b57be5133dee15b8848796
",git fetch https://review.opendev.org/openstack/neutron refs/changes/54/869554/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/security_groups_default_rules.py'],1,491202951d198e512649ae7da2fda985b03582d9,bug/1983053,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron_lib.api import converters from neutron_lib.api import extensions as api_extensions from neutron_lib.plugins import directory from neutron.api import extensions from neutron.api.v2 import base from neutron.extensions import securitygroup # TODO(slaweq): rehome API definition to neutron-lib together with # securitygroup API definition ALIAS = 'security-groups-default-rules' IS_SHIM_EXTENSION = False IS_STANDARD_ATTR_EXTENSION = False NAME = 'Default rules for security groups' DESCRIPTION = ( 'Configure set of security group rules used as default rules ' 'for every new security group') UPDATED_TIMESTAMP = '2022-12-19T10:00:00-00:00' RESOURCE_NAME = 'default_security_group_rule' COLLECTION_NAME = 'default_security_group_rules' RESOURCE_ATTRIBUTE_MAP = { COLLECTION_NAME: { 'id': { 'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'is_filter': True, 'is_sort_key': True, 'primary_key': True}, 'remote_group_id': { 'allow_post': True, 'allow_put': False, 'default': None, 'is_visible': True, 'is_sort_key': True, 'is_filter': True}, 'direction': { 'allow_post': True, 'allow_put': False, 'is_visible': True, 'is_filter': True, 'is_sort_key': True, 'validate': {'type:values': ['ingress', 'egress']}}, 'protocol': { 'allow_post': True, 'allow_put': False, 'is_visible': True, 'default': None, 'is_sort_key': True, 'is_filter': True, 'convert_to': securitygroup.convert_protocol}, 'port_range_min': { 'allow_post': True, 'allow_put': False, 'convert_to': securitygroup.convert_validate_port_value, 'default': None, 'is_visible': True, 'is_sort_key': True, 'is_filter': True}, 'port_range_max': { 'allow_post': True, 'allow_put': False, 'convert_to': securitygroup.convert_validate_port_value, 'default': None, 'is_visible': True, 'is_sort_key': True, 'is_filter': True}, 'ethertype': { 'allow_post': True, 'allow_put': False, 'is_visible': True, 'default': 'IPv4', 'is_filter': True, 'is_sort_key': True, 'convert_to': securitygroup.convert_ethertype_to_case_insensitive, 'validate': { 'type:values': securitygroup.sg_supported_ethertypes}}, 'remote_ip_prefix': { 'allow_post': True, 'allow_put': False, 'default': None, 'is_visible': True, 'is_sort_key': True, 'is_filter': True, 'convert_to': securitygroup.convert_ip_prefix_to_cidr}, 'used_in_default_sg': { 'allow_post': True, 'allow_put': False, 'convert_to': converters.convert_to_boolean, 'is_visible': True, 'is_filter': True}, } } SUB_RESOURCE_ATTRIBUTE_MAP = None ACTION_MAP = { } ACTION_STATUS = { } REQUIRED_EXTENSIONS = [ 'security-group' ] OPTIONAL_EXTENSIONS = [ ] class Security_groups_default_rules(api_extensions.ExtensionDescriptor): """"""Security group extension."""""" @classmethod def get_name(cls): return NAME @classmethod def get_alias(cls): return ALIAS @classmethod def get_description(cls): return DESCRIPTION @classmethod def get_updated(cls): return UPDATED_TIMESTAMP @classmethod def get_resources(cls): """"""Returns Ext Resources."""""" plugin = directory.get_plugin() params = RESOURCE_ATTRIBUTE_MAP.get(COLLECTION_NAME) controller = base.create_resource(COLLECTION_NAME, RESOURCE_NAME, plugin, params) ex = extensions.ResourceExtension(COLLECTION_NAME, controller) return [ex] ",,135,0
openstack%2Fnova~master~I2972425626efeaa93a34a0e589b473f6a562841f,openstack/nova,master,I2972425626efeaa93a34a0e589b473f6a562841f,[DNM] Testing effects on privsep on a build.,ABANDONED,2023-01-24 14:04:40.000000000,2023-01-27 10:45:48.000000000,,"[{'_account_id': 22348}, {'_account_id': 27623}]","[{'number': 1, 'created': '2023-01-24 14:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9645b02afb2db3ba6996933f8e0a2709d46bf1c', 'message': '[DNM] Testing effects on privsep on a build.\n\nChange-Id: I2972425626efeaa93a34a0e589b473f6a562841f\n'}, {'number': 2, 'created': '2023-01-24 14:05:00.000000000', 'files': ['nova/privsep/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/433a54e6307e5db52bfcab8c2e93690e64b1c1bc', 'message': '[DNM] Testing effects on privsep on a build.\n\nChange-Id: I2972425626efeaa93a34a0e589b473f6a562841f\n'}]",0,871607,433a54e6307e5db52bfcab8c2e93690e64b1c1bc,7,2,2,34443,,,0,"[DNM] Testing effects on privsep on a build.

Change-Id: I2972425626efeaa93a34a0e589b473f6a562841f
",git fetch https://review.opendev.org/openstack/nova refs/changes/07/871607/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/privsep/__init__.py'],1,c9645b02afb2db3ba6996933f8e0a2709d46bf1c,," capabilities=[],"," capabilities=[capabilities.CAP_CHOWN, capabilities.CAP_DAC_OVERRIDE, capabilities.CAP_DAC_READ_SEARCH, capabilities.CAP_FOWNER, capabilities.CAP_NET_ADMIN, capabilities.CAP_SYS_ADMIN],",1,6
openstack%2Ftripleo-quickstart~master~I111af443220f519befa0669dfefe20b9c56fd37c,openstack/tripleo-quickstart,master,I111af443220f519befa0669dfefe20b9c56fd37c,[wallaby only] Enable distro specific gating repo,MERGED,2023-01-25 13:47:41.000000000,2023-01-27 10:19:11.000000000,2023-01-27 10:18:12.000000000,"[{'_account_id': 8449}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2023-01-25 13:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1253a2316cd0bc5bd07b19d177e2dfbd285367f7', 'message': 'Enable distro specific gating repo\n\nIn mixed os jobs gating repo is named\nafter distro, so need to enable them so\nthese jobs test patches under review.\n\nRelated-Bug: #2003865\nChange-Id: I111af443220f519befa0669dfefe20b9c56fd37c\n'}, {'number': 2, 'created': '2023-01-26 09:30:51.000000000', 'files': ['config/release/tripleo-ci/CentOS-9/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-9/wallaby.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/41c92c7895cd49445142ab1cda8e441dde153220', 'message': '[wallaby only] Enable distro specific gating repo\n\nIn mixed os jobs gating repo is named\nafter distro, so need to enable them so\nthese jobs test patches under review.\n\nThese jobs run only for wallaby so update\nis required only there.\n\nRelated-Bug: #2003865\nChange-Id: I111af443220f519befa0669dfefe20b9c56fd37c\n'}]",14,871730,41c92c7895cd49445142ab1cda8e441dde153220,23,4,2,13861,,,0,"[wallaby only] Enable distro specific gating repo

In mixed os jobs gating repo is named
after distro, so need to enable them so
these jobs test patches under review.

These jobs run only for wallaby so update
is required only there.

Related-Bug: #2003865
Change-Id: I111af443220f519befa0669dfefe20b9c56fd37c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/30/871730/2 && git format-patch -1 --stdout FETCH_HEAD,"['config/release/tripleo-ci/CentOS-9/zed.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-wallaby.yml', 'config/release/tripleo-ci/CentOS-9/wallaby.yml', 'config/release/tripleo-ci/CentOS-9/master.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-master.yml', 'config/release/tripleo-ci/CentOS-9/promotion-testing-hash-zed.yml']",6,1253a2316cd0bc5bd07b19d177e2dfbd285367f7,bug/2003865," # Enable distro specific gating repo, it exists in mixed-os jobs sudo dnf config-manager --enable gating-repo-{{ ansible_distribution_major_version }} || true;",,12,0
openstack%2Fneutron~master~I5f703d82175d71a222c76df37a82b5ccad890d14,openstack/neutron,master,I5f703d82175d71a222c76df37a82b5ccad890d14,Never raise an exception in notify(),MERGED,2023-01-26 14:40:18.000000000,2023-01-27 09:53:25.000000000,2023-01-27 09:52:10.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 8655}, {'_account_id': 9845}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 14:40:18.000000000', 'files': ['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/67e616b2380d6549308a15077b2043721dbea5d0', 'message': 'Never raise an exception in notify()\n\nnotify() is called from python-ovs code which is not built to\nrecover from an exception in this user-overriden code. If there\nis an exception (e.g. the DB server is down when we process\nthe hash ring), this exception can cause an unrecoverable error\nin processing OVSDB messages, rendering the neutron worker useless.\n\nChange-Id: I5f703d82175d71a222c76df37a82b5ccad890d14\n'}]",1,871825,67e616b2380d6549308a15077b2043721dbea5d0,11,6,1,5756,,,0,"Never raise an exception in notify()

notify() is called from python-ovs code which is not built to
recover from an exception in this user-overriden code. If there
is an exception (e.g. the DB server is down when we process
the hash ring), this exception can cause an unrecoverable error
in processing OVSDB messages, rendering the neutron worker useless.

Change-Id: I5f703d82175d71a222c76df37a82b5ccad890d14
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/871825/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py'],1,67e616b2380d6549308a15077b2043721dbea5d0,," try: self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates) except Exception as e: LOG.exception(e)"," self.handle_db_schema_changes(event, row) self.notify_handler.notify(event, row, updates, global_=True) try: target_node = self._hash_ring.get_node(str(row.uuid)) except exceptions.HashRingIsEmpty as e: LOG.error('HashRing is empty, error: %s', e) return if target_node != self._node_uuid: return # If the worker hasn't been health checked by the maintenance # thread (see bug #1834498), indicate that it's alive here time_now = timeutils.utcnow() touch_timeout = time_now - datetime.timedelta( seconds=ovn_const.HASH_RING_TOUCH_INTERVAL) if not self._last_touch or touch_timeout >= self._last_touch: # NOTE(lucasagomes): Guard the db operation with an exception # handler. If heartbeating fails for whatever reason, log # the error and continue with processing the event try: ctx = neutron_context.get_admin_context() ovn_hash_ring_db.touch_node(ctx, self._node_uuid) self._last_touch = time_now except Exception: LOG.exception('Hash Ring node %s failed to heartbeat', self._node_uuid) LOG.debug('Hash Ring: Node %(node)s (host: %(hostname)s) ' 'handling event ""%(event)s"" for row %(row)s ' '(table: %(table)s)', {'node': self._node_uuid, 'hostname': CONF.host, 'event': event, 'row': row.uuid, 'table': row._table.name}) self.notify_handler.notify(event, row, updates)",34,30
openstack%2Fblazar-tempest-plugin~master~I3979f6e275f7b189546f4cc02e7db68238d77721,openstack/blazar-tempest-plugin,master,I3979f6e275f7b189546f4cc02e7db68238d77721,Remove stable/wallaby job from master gate,MERGED,2023-01-27 01:29:53.000000000,2023-01-27 09:38:12.000000000,2023-01-27 09:36:20.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 01:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/fc6ac5e310c8870b01c156696c2442914a370ab9', 'message': 'Remove stable/wallaby job from master gate\n\nstable/wallaby is in EM state. As Tempest and\nplugins masters does not support EM stable branches,\nQA team is pinning tempest in devstack stable/wallaby\ntesitng[1]. With that we do not need to test the\nstable/wallaby jobs on master gate\n\n[1] https://review.opendev.org/c/openstack/devstack/+/871782\n\nChange-Id: I3979f6e275f7b189546f4cc02e7db68238d77721\n'}, {'number': 2, 'created': '2023-01-27 08:10:26.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/blazar-tempest-plugin/commit/190a7c165e8bcf738e87e5d32035c6caa123f76b', 'message': 'Remove stable/wallaby job from master gate\n\nstable/wallaby is in EM state. As Tempest and\nplugins masters does not support EM stable branches,\nQA team is pinning tempest in devstack stable/wallaby\ntesting[1]. With that we do not need to test the\nstable/wallaby jobs on master gate.\n\n[1] https://review.opendev.org/c/openstack/devstack/+/871782\n\nChange-Id: I3979f6e275f7b189546f4cc02e7db68238d77721\n'}]",0,871912,190a7c165e8bcf738e87e5d32035c6caa123f76b,11,2,2,8556,,,0,"Remove stable/wallaby job from master gate

stable/wallaby is in EM state. As Tempest and
plugins masters does not support EM stable branches,
QA team is pinning tempest in devstack stable/wallaby
testing[1]. With that we do not need to test the
stable/wallaby jobs on master gate.

[1] https://review.opendev.org/c/openstack/devstack/+/871782

Change-Id: I3979f6e275f7b189546f4cc02e7db68238d77721
",git fetch https://review.opendev.org/openstack/blazar-tempest-plugin refs/changes/12/871912/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,fc6ac5e310c8870b01c156696c2442914a370ab9,wallaby-last,, - blazar-tempest-plugin-wallaby - job: name: blazar-tempest-plugin-wallaby parent: blazar-tempest-plugin-base nodeset: openstack-single-node-focal override-checkout: stable/wallaby,0,7
openstack%2Ftripleo-upgrade~master~I9a50b8b298cfa6ef18c29e90f99130a7a103eb74,openstack/tripleo-upgrade,master,I9a50b8b298cfa6ef18c29e90f99130a7a103eb74,infrared_plugin: use plugins/ dir as roles path,NEW,2023-01-13 14:01:19.000000000,2023-01-27 09:38:07.000000000,,"[{'_account_id': 6816}, {'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 32432}, {'_account_id': 33080}, {'_account_id': 34847}]","[{'number': 1, 'created': '2023-01-13 14:01:19.000000000', 'files': ['README.rst', 'infrared_plugin/plugin.spec'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/895979b3ba34ebee0ba56fdb1cda8708bc56406f', 'message': 'infrared_plugin: use plugins/ dir as roles path\n\nAfter tripleo-upgrade repo/plugin is installed by\ninfrared, it is placed under plugins/ directory,\nas this triple-upgrade repo is the ansible role itself,\nuse that folder above this repo as path for scanning for roles.\n\nThat way there should be no need to create extra symlinks after installation.\n\nChange-Id: I9a50b8b298cfa6ef18c29e90f99130a7a103eb74\n'}]",1,870095,895979b3ba34ebee0ba56fdb1cda8708bc56406f,3,6,1,6683,,,0,"infrared_plugin: use plugins/ dir as roles path

After tripleo-upgrade repo/plugin is installed by
infrared, it is placed under plugins/ directory,
as this triple-upgrade repo is the ansible role itself,
use that folder above this repo as path for scanning for roles.

That way there should be no need to create extra symlinks after installation.

Change-Id: I9a50b8b298cfa6ef18c29e90f99130a7a103eb74
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/95/870095/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'infrared_plugin/plugin.spec']",2,895979b3ba34ebee0ba56fdb1cda8708bc56406f,,config: roles_path: ../../,,2,6
openstack%2Ftempest~master~Ibac9d0c2fa2f30605dd44ee58b84946464ea6449,openstack/tempest,master,Ibac9d0c2fa2f30605dd44ee58b84946464ea6449,Remove usage of unittest2,MERGED,2022-01-24 22:54:47.000000000,2023-01-27 09:13:05.000000000,2022-02-09 20:42:29.000000000,"[{'_account_id': 8367}, {'_account_id': 8556}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 30742}]","[{'number': 1, 'created': '2022-01-24 22:54:47.000000000', 'files': ['tempest/tests/lib/test_base.py', 'tempest/test_discover/test_discover.py', 'requirements.txt', 'tempest/lib/base.py', 'tempest/test.py', 'tempest/tests/test_test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1ff7748623c2d02122bec36542f8bc310d296836', 'message': 'Remove usage of unittest2\n\nfrom comments when it was last touched it looks like workarounds for\nunittest2 might be able to be dropped.\n\nrelated: https://github.com/mtreinish/stestr/pull/265\n\nsimplify the workaround logic around unittest2 TestCase logic\n\nChange-Id: Ibac9d0c2fa2f30605dd44ee58b84946464ea6449\n'}]",5,826191,1ff7748623c2d02122bec36542f8bc310d296836,14,6,1,16282,,,0,"Remove usage of unittest2

from comments when it was last touched it looks like workarounds for
unittest2 might be able to be dropped.

related: https://github.com/mtreinish/stestr/pull/265

simplify the workaround logic around unittest2 TestCase logic

Change-Id: Ibac9d0c2fa2f30605dd44ee58b84946464ea6449
",git fetch https://review.opendev.org/openstack/tempest refs/changes/91/826191/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/lib/test_base.py', 'tempest/test_discover/test_discover.py', 'requirements.txt', 'tempest/lib/base.py', 'tempest/test.py', 'tempest/tests/test_test.py']",6,1ff7748623c2d02122bec36542f8bc310d296836,,import unittest,"import sysif sys.version_info >= (2, 7): import unittest else: import unittest2 as unittest ",3,62
openstack%2Fpython-aodhclient~stable%2Ftrain~Iefcce38ea939718f1ee8344c6fd85f558b213921,openstack/python-aodhclient,stable/train,Iefcce38ea939718f1ee8344c6fd85f558b213921,[DNM] Test CI,ABANDONED,2023-01-27 05:54:02.000000000,2023-01-27 08:48:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 05:54:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/3a55e9ee6f67065c679f6cd3bd657af1f27f6c96', 'message': '[DNM] Test CI\n\nChange-Id: Iefcce38ea939718f1ee8344c6fd85f558b213921\n'}, {'number': 2, 'created': '2023-01-27 06:01:26.000000000', 'files': ['.dnm', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/33772d7d0d7a6954a361b4fb63d196496807da2d', 'message': '[DNM] Test CI\n\nChange-Id: Iefcce38ea939718f1ee8344c6fd85f558b213921\n'}]",0,871954,33772d7d0d7a6954a361b4fb63d196496807da2d,4,1,2,32240,,,0,"[DNM] Test CI

Change-Id: Iefcce38ea939718f1ee8344c6fd85f558b213921
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/54/871954/1 && git format-patch -1 --stdout FETCH_HEAD,['.dnm'],1,3a55e9ee6f67065c679f6cd3bd657af1f27f6c96,,,,0,0
openstack%2Fvitrage-tempest-plugin~master~I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec,openstack/vitrage-tempest-plugin,master,I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec,Add stable/zed jobs on master gate,MERGED,2022-10-16 04:04:22.000000000,2023-01-27 08:42:13.000000000,2023-01-27 08:40:29.000000000,"[{'_account_id': 19134}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-16 04:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/a1249cbaf7fe4677313049fafe76f0827389dd89', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec\n'}, {'number': 2, 'created': '2022-10-19 15:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/51a27c387b07779a3aab18ab38f6135cb17a9e77', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec\n'}, {'number': 3, 'created': '2022-10-19 15:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/eff3cebe431ddf5227e079b1134ef62774ae604c', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec\n'}, {'number': 4, 'created': '2022-10-20 10:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d58565a0ac43eb10ddb9186c18fef3504cbcf1d3', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec\n'}, {'number': 5, 'created': '2023-01-27 01:50:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/816b2350a1e7b05ec35b82546afb66d8255df76a', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec\n'}]",2,861533,816b2350a1e7b05ec35b82546afb66d8255df76a,17,2,5,8556,,,0,"Add stable/zed jobs on master gate

As zed is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: I2f81f1801f8f7a049a6fc012c8e9455adceeb9ec
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/33/861533/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a1249cbaf7fe4677313049fafe76f0827389dd89,zed-stable-job, - vitrage-tempest-plugin-datasources-zed - vitrage-tempest-plugin-api-zed name: vitrage-tempest-plugin-api-zed parent: vitrage-tempest-plugin-api nodeset: openstack-single-node-focal override-checkout: stable/zed - job: name: vitrage-tempest-plugin-datasources-zed parent: vitrage-tempest-plugin-datasources nodeset: openstack-single-node-focal override-checkout: stable/zed - job:,,14,0
openstack%2Faodh~master~Id64afa53b7c1ae059ecac2c6823840cf116fad53,openstack/aodh,master,Id64afa53b7c1ae059ecac2c6823840cf116fad53,Imported Translations from Zanata,MERGED,2023-01-27 02:34:14.000000000,2023-01-27 08:29:56.000000000,2023-01-27 08:28:50.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 02:34:14.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/aodh/commit/aa91a3b6141dd3177d581c5517ae9fe37e75ab4c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Id64afa53b7c1ae059ecac2c6823840cf116fad53\n'}]",0,871921,aa91a3b6141dd3177d581c5517ae9fe37e75ab4c,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Id64afa53b7c1ae059ecac2c6823840cf116fad53
",git fetch https://review.opendev.org/openstack/aodh refs/changes/21/871921/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po'],1,aa91a3b6141dd3177d581c5517ae9fe37e75ab4c,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-17 20:25+0000\n""""PO-Revision-Date: 2023-01-26 09:53+0000\n""msgid ""15.0.0"" msgstr ""15.0.0""","""POT-Creation-Date: 2022-09-15 17:48+0000\n""""PO-Revision-Date: 2022-09-15 08:52+0000\n""msgid ""15.0.0.0rc1"" msgstr ""15.0.0.0rc1""",5,4
openstack%2Fceilometer~master~I811d00ac0995980b4f6ab17b580f164d956d0bfe,openstack/ceilometer,master,I811d00ac0995980b4f6ab17b580f164d956d0bfe,Imported Translations from Zanata,MERGED,2023-01-27 03:52:45.000000000,2023-01-27 08:29:48.000000000,2023-01-27 08:28:47.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 03:52:45.000000000', 'files': ['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e83a6802ca7b88f874e7476d5a46decaa74f0359', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I811d00ac0995980b4f6ab17b580f164d956d0bfe\n'}]",0,871934,e83a6802ca7b88f874e7476d5a46decaa74f0359,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I811d00ac0995980b4f6ab17b580f164d956d0bfe
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/34/871934/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'ceilometer/locale/en_GB/LC_MESSAGES/ceilometer.po']",2,e83a6802ca7b88f874e7476d5a46decaa74f0359,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-20 09:59+0000\n""""PO-Revision-Date: 2023-01-26 09:54+0000\n""msgid ""Unable to reconnect and resendsample over TCP"" msgstr ""Unable to reconnect and resend sample over TCP"" msgid """" ""Unable to send sample over TCP,trying to reconnect and resend the message"" msgstr """" ""Unable to send sample over TCP, trying to reconnect and resend the message"" ","""POT-Creation-Date: 2022-08-22 19:15+0000\n""""PO-Revision-Date: 2020-10-03 09:52+0000\n""",21,8
openstack%2Ftripleo-quickstart-extras~master~Ia2d664c89a00f139454a4e7b6322eb3fd383e473,openstack/tripleo-quickstart-extras,master,Ia2d664c89a00f139454a4e7b6322eb3fd383e473,Remove quotation marks from set statements in standalone_config template,MERGED,2022-10-06 12:01:16.000000000,2023-01-27 08:27:37.000000000,2022-10-06 23:51:44.000000000,"[{'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-10-06 12:01:16.000000000', 'files': ['roles/standalone/templates/standalone_config.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/db86a9352bec6f982ca10acc2ed6ffb910088d29', 'message': 'Remove quotation marks from set statements in standalone_config template\n\nQuotation marks should be removed in set statements from\nstandalone_config jinja template to make the template compatible with\nall ansible versions. When quotation marks are used, variable does not\nreturn its value, but is passed as regular string value.\n\nChange-Id: Ia2d664c89a00f139454a4e7b6322eb3fd383e473\n'}]",2,860558,db86a9352bec6f982ca10acc2ed6ffb910088d29,10,4,1,33080,,,0,"Remove quotation marks from set statements in standalone_config template

Quotation marks should be removed in set statements from
standalone_config jinja template to make the template compatible with
all ansible versions. When quotation marks are used, variable does not
return its value, but is passed as regular string value.

Change-Id: Ia2d664c89a00f139454a4e7b6322eb3fd383e473
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/58/860558/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/standalone/templates/standalone_config.yaml.j2'],1,db86a9352bec6f982ca10acc2ed6ffb910088d29,,"{% set source_ci_ip_address = ansible_default_ipv4.address + ""/"" + ansible_default_ipv4.netmask %} {% set source_ci_network = source_ci_ip_address | ipaddr('network/prefix') %}","{% set source_ci_ip_address = ""{{ ansible_default_ipv4.address }}/{{ ansible_default_ipv4.netmask }}"" %} {% set source_ci_network = ""{{ source_ci_ip_address | ipaddr('network/prefix') }}"" %}",2,2
openstack%2Fovn-bgp-agent~master~Ic55a77c495e7cf7fcc032e5fc17ba58d43715cb2,openstack/ovn-bgp-agent,master,Ic55a77c495e7cf7fcc032e5fc17ba58d43715cb2,Add releasenotes job,MERGED,2023-01-25 13:31:14.000000000,2023-01-27 08:08:59.000000000,2023-01-27 08:08:59.000000000,"[{'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-01-25 13:31:14.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/ff5ee813e731456abd5d0ff8fb7dc39f4802d62d', 'message': 'Add releasenotes job\n\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: Ic55a77c495e7cf7fcc032e5fc17ba58d43715cb2\n'}]",0,871726,ff5ee813e731456abd5d0ff8fb7dc39f4802d62d,6,2,1,6773,,,0,"Add releasenotes job

Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Change-Id: Ic55a77c495e7cf7fcc032e5fc17ba58d43715cb2
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/26/871726/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,ff5ee813e731456abd5d0ff8fb7dc39f4802d62d,, - release-notes-jobs-python3,,1,0
openstack%2Fovn-bgp-agent~master~Id130a0dd9eabc2ed8847b25e8787947086863f79,openstack/ovn-bgp-agent,master,Id130a0dd9eabc2ed8847b25e8787947086863f79,Fix tox -e releasenotes,MERGED,2023-01-25 12:58:00.000000000,2023-01-27 08:05:07.000000000,2023-01-27 08:05:07.000000000,"[{'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-01-25 12:58:00.000000000', 'files': ['releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/ovn-bgp-agent/commit/a9eef36c2591412b28f13ff2fd3a827f7eeb309b', 'message': 'Fix tox -e releasenotes\n\nFix the ""openstackdocs_auto_name"" configuration value type, otherwise\nthe command will fail with the following error:\n\nWarning, treated as error:\nThe config value `openstackdocs_auto_name\' has type `str\', defaults to\n`bool\'.\n\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: Id130a0dd9eabc2ed8847b25e8787947086863f79\n'}]",0,871714,a9eef36c2591412b28f13ff2fd3a827f7eeb309b,6,2,1,6773,,,0,"Fix tox -e releasenotes

Fix the ""openstackdocs_auto_name"" configuration value type, otherwise
the command will fail with the following error:

Warning, treated as error:
The config value `openstackdocs_auto_name' has type `str', defaults to
`bool'.

Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
Change-Id: Id130a0dd9eabc2ed8847b25e8787947086863f79
",git fetch https://review.opendev.org/openstack/ovn-bgp-agent refs/changes/14/871714/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/conf.py'],1,a9eef36c2591412b28f13ff2fd3a827f7eeb309b,,openstackdocs_auto_name = False,openstackdocs_auto_name = 'False',1,1
openstack%2Fpython-aodhclient~stable%2Ftrain~Ia11f25fa8c36c6051a44994f2545e2b64a665593,openstack/python-aodhclient,stable/train,Ia11f25fa8c36c6051a44994f2545e2b64a665593,Change aggregation method to mean and don't use */* in accept header,MERGED,2022-12-22 07:39:44.000000000,2023-01-27 07:57:38.000000000,2023-01-27 07:56:39.000000000,"[{'_account_id': 4264}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-22 07:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/1c64507de960adfe7f13c758e438ebf41f9e9f92', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    ""importlib-metadata"" released v5.0.0, it removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 2, 'created': '2022-12-22 07:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/a81b8aeffd9349450ad12f2a4385cc9dc1f97289', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    ""importlib-metadata"" released v5.0.0, it removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 3, 'created': '2022-12-22 07:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/6909624438230db8ed9e5df7b3f5379899562446', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    ""importlib-metadata"" released v5.0.0, it removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 4, 'created': '2022-12-22 09:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/a44ed54d79849eda7cb69b9c3bf04a4dccaf03b4', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 5, 'created': '2022-12-22 09:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/cf12ac67055cd98f5e84385a39db04333148dd20', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 6, 'created': '2022-12-22 10:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/effa08545dbcc3d1a5ffc6fe935e6a7debc17570', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 7, 'created': '2022-12-23 07:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/2c9123faf52e3e9599cd5f6a6f8e0937c642c547', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 8, 'created': '2023-01-25 07:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/b673144b16e69c11948f4c2ae98a985e01508000', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 9, 'created': '2023-01-25 10:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/bfc5159812971250ffdbb85fa209ee9c3bd5f790', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 10, 'created': '2023-01-25 10:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/84e44549e90c1a45f8c05ad0836e6cab2cba56ad', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 11, 'created': '2023-01-25 11:05:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/c2e75c26c4ca4721db3f501da765b39f2b755cbb', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 12, 'created': '2023-01-27 04:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/08ad2106ff313599818828eb7dece7f3a00f4e35', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 13, 'created': '2023-01-27 04:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/1bf80e0da8d616de15a12ee495be2b4baad7b59f', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 14, 'created': '2023-01-27 04:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/4415919842ebc7e3be077763bdfea59f3735dc16', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 15, 'created': '2023-01-27 07:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/53e0cdb62ef73efa32f49a09b6285d181cc43ccf', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}, {'number': 16, 'created': '2023-01-27 07:31:22.000000000', 'files': ['aodhclient/tests/functional/test_alarm.py', 'aodhclient/utils.py', 'requirements.txt', 'aodhclient/v2/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/d672fc2117fb74803e52fd34fd8205fd769c5c7b', 'message': 'Change aggregation method to mean and don\'t use */* in accept header\n\nThis commit combines the following changes\n\n* Change aggregation method to mean\n\n     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles\n     ignoring gnocchi api error when metric is not created.\n     However there are functional test failures when the\n     aggregation method is set to last for alarm type\n     gnocchi_aggregation_by_resources_threshold,\n\n     This fix changes the aggregration method to mean for\n     any create/update of alarm type\n     gnocchi_aggregation_by_resources_threshold.\n\n     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""\n     attribute because of change[1] in pyparsing module. Adjust to\n     this change by using ""infixNotation"" in place of ""operatorPrecedence"".\n\n* Don\'t use */* in accept header\n\n    The response is returned as text/plain in case of exception.\n    Pecan 1.4 uses accept header to decide the response content type.\n\n    This also affected gnocciclient and has been fixed there.\n    https://github.com/gnocchixyz/python-gnocchiclient/pull/110\n\n    https://review.opendev.org/747722 (master)\n    Co-authored-by: Dan Radez <dradez@redhat.com>\n\n* Set upper-constraint for import-metadata\n\n    py37 job fails with error\n    ```\n    \'EntryPoints\' object has no attribute \'get\'\n    ```\n\n    importlib-metadata v5.0.0 removed the\n    deprecated endpoint. So use the version <5.0 and do not\n    install the latest version.\n\n* Set upper-constraint for kombu\n\n    py27 job attempts to install kombu 5.0.2 which requires\n    Python >=3.6. Install kombu<=4.6.11 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for daiquiri\n\n    py27 job attempts to install daiquiri 3.2.1 which requires\n    Python >=3. Install daiquiri<=2.1.1 which is the highest\n    version supported on Python 2.7\n\n* Set upper-constraint for pifpaf\n\n    py27 job attempts to install pifpaf 3.1.5 which requires\n    Python >=3. Install daiquiri<=2.6.0 which is the highest\n    version supported on Python 2.7\n\nDepends-On: https://review.opendev.org/868173\nDepends-On: https://review.opendev.org/868174\n\n[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4\n\nChange-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593\nCloses-Bug: #1974682\n(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)\n(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)\n(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)\n(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)\n'}]",5,868287,d672fc2117fb74803e52fd34fd8205fd769c5c7b,38,2,16,32240,,,0,"Change aggregation method to mean and don't use */* in accept header

This commit combines the following changes

* Change aggregation method to mean

     Commit 8454cac06a654bb1e4eea20e6a36417796a94d82 handles
     ignoring gnocchi api error when metric is not created.
     However there are functional test failures when the
     aggregation method is set to last for alarm type
     gnocchi_aggregation_by_resources_threshold,

     This fix changes the aggregration method to mean for
     any create/update of alarm type
     gnocchi_aggregation_by_resources_threshold.

     openstack-tox-py* jobs fail due to missing ""operatorPrecedence""
     attribute because of change[1] in pyparsing module. Adjust to
     this change by using ""infixNotation"" in place of ""operatorPrecedence"".

* Don't use */* in accept header

    The response is returned as text/plain in case of exception.
    Pecan 1.4 uses accept header to decide the response content type.

    This also affected gnocciclient and has been fixed there.
    https://github.com/gnocchixyz/python-gnocchiclient/pull/110

    https://review.opendev.org/747722 (master)
    Co-authored-by: Dan Radez <dradez@redhat.com>

* Set upper-constraint for import-metadata

    py37 job fails with error
    ```
    'EntryPoints' object has no attribute 'get'
    ```

    importlib-metadata v5.0.0 removed the
    deprecated endpoint. So use the version <5.0 and do not
    install the latest version.

* Set upper-constraint for kombu

    py27 job attempts to install kombu 5.0.2 which requires
    Python >=3.6. Install kombu<=4.6.11 which is the highest
    version supported on Python 2.7

* Set upper-constraint for daiquiri

    py27 job attempts to install daiquiri 3.2.1 which requires
    Python >=3. Install daiquiri<=2.1.1 which is the highest
    version supported on Python 2.7

* Set upper-constraint for pifpaf

    py27 job attempts to install pifpaf 3.1.5 which requires
    Python >=3. Install daiquiri<=2.6.0 which is the highest
    version supported on Python 2.7

Depends-On: https://review.opendev.org/868173
Depends-On: https://review.opendev.org/868174

[1] https://github.com/pyparsing/pyparsing/commit/ab2f220dd26ead73ce5bf496db85c07810e458f4

Change-Id: Ia11f25fa8c36c6051a44994f2545e2b64a665593
Closes-Bug: #1974682
(cherry picked from commit d656c191131e20bb634e4eeb6d074bc32a6df60f)
(cherry picked from commit 621b4aef88edcb34712c2060a27a9f10431974d7)
(cherry picked from commit 17677567f7d58f8eb8885feda81fbffcba53311b)
(cherry picked from commit 1c67e9a167b6612f45313af978eaa3c10b701621)
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/87/868287/10 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/tests/functional/test_alarm.py', 'aodhclient/utils.py', 'requirements.txt', 'aodhclient/v2/base.py', 'tox.ini']",5,1c64507de960adfe7f13c758e438ebf41f9e9f92,," PYTHONWARNINGS=ignore:DEPRECATION::pip._internal.cli.base_command,ignore::UserWarning http://tarballs.openstack.org/aodh/aodh-stable-ussuri.tar.gz#egg=aodh[mysql]", http://tarballs.openstack.org/aodh/aodh-master.tar.gz#egg=aodh[mysql],16,14
openstack%2Fneutron~master~Icb6f4aff9b69b41d193d2420fd7b9a5f849675fd,openstack/neutron,master,Icb6f4aff9b69b41d193d2420fd7b9a5f849675fd,Imported Translations from Zanata,MERGED,2023-01-27 03:53:27.000000000,2023-01-27 07:55:48.000000000,2023-01-27 07:54:24.000000000,"[{'_account_id': 841}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 13861}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 03:53:27.000000000', 'files': ['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/48c362129225b8ba4f83879b7bf5b5394d066f5d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Icb6f4aff9b69b41d193d2420fd7b9a5f849675fd\n'}]",0,871935,48c362129225b8ba4f83879b7bf5b5394d066f5d,9,5,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Icb6f4aff9b69b41d193d2420fd7b9a5f849675fd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/35/871935/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/ja/LC_MESSAGES/neutron.po', 'neutron/locale/pt_BR/LC_MESSAGES/neutron.po', 'neutron/locale/it/LC_MESSAGES/neutron.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron.po', 'neutron/locale/es/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/ko_KR/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'neutron/locale/de/LC_MESSAGES/neutron.po', 'neutron/locale/fr/LC_MESSAGES/neutron.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron.po', 'releasenotes/source/locale/fr/LC_MESSAGES/releasenotes.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron.po', 'neutron/locale/ru/LC_MESSAGES/neutron.po']",13,48c362129225b8ba4f83879b7bf5b5394d066f5d,zanata/translations,"""POT-Creation-Date: 2023-01-26 15:02+0000\n""","""POT-Creation-Date: 2022-04-29 17:06+0000\n""""Cannot have multiple router ports with the same network id if both contain "" ""IPv6 subnets. Existing port %(p)s has IPv6 subnet(s) and network id %(nid)s"" msgstr """" ""        ,  "" ""  IPv6.   %(p)s      "" ""IPv6 %(nid)s"" #, python-format msgid """"",88,311
openstack%2Ftripleo-heat-templates~master~Ibb8037fad70c628ab26a6cf0dd4401bb6b23cc7c,openstack/tripleo-heat-templates,master,Ibb8037fad70c628ab26a6cf0dd4401bb6b23cc7c,Fix wrong tcp port for heat-cfn endpoint with ssl,MERGED,2023-01-26 04:20:26.000000000,2023-01-27 07:03:43.000000000,2023-01-27 07:03:43.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-26 04:20:26.000000000', 'files': ['deployment/heat/heat-api-cfn-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e98f23fd150886a2573dd5eb1f73677d62827433', 'message': 'Fix wrong tcp port for heat-cfn endpoint with ssl\n\nThe heat-cfn api uses tcp/13005 for its public endpoint when ssl is\nenabled. This corrects the wrong port in iptables rule.\n\nCloses-Bug: #2003929\nChange-Id: Ibb8037fad70c628ab26a6cf0dd4401bb6b23cc7c\n'}]",0,871805,e98f23fd150886a2573dd5eb1f73677d62827433,7,3,1,9816,,,0,"Fix wrong tcp port for heat-cfn endpoint with ssl

The heat-cfn api uses tcp/13005 for its public endpoint when ssl is
enabled. This corrects the wrong port in iptables rule.

Closes-Bug: #2003929
Change-Id: Ibb8037fad70c628ab26a6cf0dd4401bb6b23cc7c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/871805/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/heat/heat-api-cfn-container-puppet.yaml'],1,e98f23fd150886a2573dd5eb1f73677d62827433,bug/2003929, - 13005, - 13800,1,1
openstack%2Fhorizon~stable%2Fwallaby~I3652d87d817030bcd3855d26bfa41b8b7061d08e,openstack/horizon,stable/wallaby,I3652d87d817030bcd3855d26bfa41b8b7061d08e,Pin tox<4 for stable branches testing,MERGED,2023-01-13 15:41:14.000000000,2023-01-27 06:25:25.000000000,2023-01-27 06:23:35.000000000,"[{'_account_id': 841}, {'_account_id': 6914}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 15:41:14.000000000', 'files': ['.zuul.d/nodejs-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/horizon/commit/15f9f1777e2205e8fe89c6eb35915c5e14ee6af7', 'message': ""Pin tox<4 for stable branches testing\n\nhorizon npm jobs start failing due to some recent changes in tox4.\nAs discussed on open-discuss ML, it is decided to keep testing the\nstable branch with the tox version that they release with and not\nwith the tox 4. This patch set the 'ensure_tox_version' to use 4,\nwhich will tell zuul to install tox<4 if it's not present.\nFor more info. please refer [1].\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031668.html\n\nChange-Id: I3652d87d817030bcd3855d26bfa41b8b7061d08e\n(cherry picked from commit 4cc580d94b1e579c307583d2f8eb2a5cb699b14f)\n""}]",0,870055,15f9f1777e2205e8fe89c6eb35915c5e14ee6af7,8,4,1,29313,,,0,"Pin tox<4 for stable branches testing

horizon npm jobs start failing due to some recent changes in tox4.
As discussed on open-discuss ML, it is decided to keep testing the
stable branch with the tox version that they release with and not
with the tox 4. This patch set the 'ensure_tox_version' to use 4,
which will tell zuul to install tox<4 if it's not present.
For more info. please refer [1].

[1] https://lists.openstack.org/pipermail/openstack-discuss/2023-January/031668.html

Change-Id: I3652d87d817030bcd3855d26bfa41b8b7061d08e
(cherry picked from commit 4cc580d94b1e579c307583d2f8eb2a5cb699b14f)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/870055/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/nodejs-jobs.yaml'],1,15f9f1777e2205e8fe89c6eb35915c5e14ee6af7,869431-stable/wallaby, # NOTE: This is stable branch (<=stable/zed) job and new tox 4 # require some changes in tox.ini to be compatible with it. Let's # pin tox <4 for stable branches testing (<=stable/zed). ensure_tox_version: '<4' # NOTE: This is stable branch (<=stable/zed) job and new tox 4 # require some changes in tox.ini to be compatible with it. Let's # pin tox <4 for stable branches testing (<=stable/zed). ensure_tox_version: '<4',,8,0
openstack%2Ftacker~master~Ib28d1f7e01e977b17877efa5df9d5258b10c8e21,openstack/tacker,master,Ib28d1f7e01e977b17877efa5df9d5258b10c8e21,Switch the Legacy FT non-voting,MERGED,2022-11-28 05:39:07.000000000,2023-01-27 06:13:14.000000000,2023-01-27 06:11:04.000000000,"[{'_account_id': 17255}, {'_account_id': 22348}, {'_account_id': 25701}, {'_account_id': 32102}, {'_account_id': 33455}]","[{'number': 1, 'created': '2022-11-28 05:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b4d6e05f1920f5817c497589d58c073d74226464', 'message': '[DNM] Test to drop legacy FT\n\nThis patch tests whether the test environment become stable\nby dropping Legacy FT.\n\nTODO:\n* VIM testing needs to be ported elsewhere if exists.\n* If delete the Legaccy FT, need to reorganize the .zuul.yaml\n  because other tests are based on the legacy setting.\n\nChange-Id: Ib28d1f7e01e977b17877efa5df9d5258b10c8e21\n'}, {'number': 2, 'created': '2023-01-25 02:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/24755a6e06d39ff946dae2f0a5162e8655df4641', 'message': 'Switch the Legacy FT non-voting\n\nThis patch makes to stable Zuul CI by switching the Legacy FT\nto non-voting because the Legacy API, excluding VIM functionality,\nwill be deprecated in Antelope release and will not be updated\nin the future.\n\nChange-Id: Ib28d1f7e01e977b17877efa5df9d5258b10c8e21\n'}, {'number': 3, 'created': '2023-01-25 02:57:05.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/01af921686f8e0af23c892b4536dcbdc2a9f2cf4', 'message': 'Switch the Legacy FT non-voting\n\nThis patch makes to stable Zuul CI by switching the Legacy FT\nto non-voting because the Legacy API, excluding VIM functionality,\nwill be deprecated in Antelope release and will not be updated\nin the future.\n\nImplements: blueprint deprecate-legacy-apis\nChange-Id: Ib28d1f7e01e977b17877efa5df9d5258b10c8e21\n'}]",6,865788,01af921686f8e0af23c892b4536dcbdc2a9f2cf4,18,5,3,31857,,,0,"Switch the Legacy FT non-voting

This patch makes to stable Zuul CI by switching the Legacy FT
to non-voting because the Legacy API, excluding VIM functionality,
will be deprecated in Antelope release and will not be updated
in the future.

Implements: blueprint deprecate-legacy-apis
Change-Id: Ib28d1f7e01e977b17877efa5df9d5258b10c8e21
",git fetch https://review.opendev.org/openstack/tacker refs/changes/88/865788/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,b4d6e05f1920f5817c497589d58c073d74226464,bp/deprecate-legacy-apis, # - tacker-functional-devstack-multinode-legacy # - tacker-functional-devstack-multinode-libs-master, - tacker-functional-devstack-multinode-legacy - tacker-functional-devstack-multinode-libs-master,2,2
openstack%2Fsenlin~master~Ibb44b96108ef6029fe693d0765d59aa15570107e,openstack/senlin,master,Ibb44b96108ef6029fe693d0765d59aa15570107e,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 20:40:05.000000000,2023-01-27 05:47:35.000000000,2023-01-23 18:11:28.000000000,"[{'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}]","[{'number': 1, 'created': '2023-01-19 20:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2466aec2de2e7adc01cfb88f1037f70804a32b5d', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: Ibb44b96108ef6029fe693d0765d59aa15570107e\n'}, {'number': 2, 'created': '2023-01-21 23:52:25.000000000', 'files': ['requirements.txt', 'senlin/common/messaging.py', 'senlin/tests/unit/test_common_messaging.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a6bc01a7f9e112041ef8daf598177bd4d9e0fcfc', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: Ibb44b96108ef6029fe693d0765d59aa15570107e\n'}]",4,871166,a6bc01a7f9e112041ef8daf598177bd4d9e0fcfc,13,4,2,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: Ibb44b96108ef6029fe693d0765d59aa15570107e
",git fetch https://review.opendev.org/openstack/senlin refs/changes/66/871166/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'senlin/common/messaging.py']",2,2466aec2de2e7adc01cfb88f1037f70804a32b5d,," return messaging.get_rpc_client( TRANSPORT, target, serializer=serializer)"," return messaging.RPCClient(TRANSPORT, target, serializer=serializer)",3,2
openstack%2Fgrenade~stable%2Fxena~I587027181f4c52ca1d22d105b3ad6b59b5ca2dd4,openstack/grenade,stable/xena,I587027181f4c52ca1d22d105b3ad6b59b5ca2dd4,DNM: testing tempest pin,ABANDONED,2023-01-27 03:38:16.000000000,2023-01-27 05:39:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 03:38:16.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/grenade/commit/c6cb9b9b1d0b4310fed7a53fb9646796ea70731b', 'message': 'DNM: testing tempest pin\n\nChange-Id: I587027181f4c52ca1d22d105b3ad6b59b5ca2dd4\n'}]",0,871931,c6cb9b9b1d0b4310fed7a53fb9646796ea70731b,4,1,1,8556,,,0,"DNM: testing tempest pin

Change-Id: I587027181f4c52ca1d22d105b3ad6b59b5ca2dd4
",git fetch https://review.opendev.org/openstack/grenade refs/changes/31/871931/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c6cb9b9b1d0b4310fed7a53fb9646796ea70731b,wallaby-pin-tempest,#test,,1,0
openstack%2Fdevstack~stable%2Fwallaby~Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa,openstack/devstack,stable/wallaby,Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa,DNM: testing gate,ABANDONED,2023-01-27 02:45:56.000000000,2023-01-27 05:07:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 02:45:56.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2291f46a7627364a916fe38221624e477ba54362', 'message': 'DNM: testing gate\n\nChange-Id: Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa\n'}]",0,871902,2291f46a7627364a916fe38221624e477ba54362,3,1,1,8556,,,0,"DNM: testing gate

Change-Id: Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/871902/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2291f46a7627364a916fe38221624e477ba54362,,#test,,1,0
openstack%2Fhorizon~master~I3daacbfeac05a2334946088e069434456dd75fe6,openstack/horizon,master,I3daacbfeac05a2334946088e069434456dd75fe6,Imported Translations from Zanata,MERGED,2023-01-27 03:09:24.000000000,2023-01-27 04:59:55.000000000,2023-01-27 04:58:47.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-27 03:09:24.000000000', 'files': ['openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/501d446e1e2657e8303a40a4198cf513c5cb867b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I3daacbfeac05a2334946088e069434456dd75fe6\n'}]",0,871927,501d446e1e2657e8303a40a4198cf513c5cb867b,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I3daacbfeac05a2334946088e069434456dd75fe6
",git fetch https://review.opendev.org/openstack/horizon refs/changes/27/871927/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po'],1,501d446e1e2657e8303a40a4198cf513c5cb867b,zanata/translations,"# Andi Chandler <andi@gowling.com>, 2023. #zanata""POT-Creation-Date: 2023-01-25 15:43+0000\n""""PO-Revision-Date: 2023-01-26 10:07+0000\n""msgid ""Backup Name ="" msgstr ""Backup Name ="" msgid ""Volume ID ="" msgstr ""Volume ID ="" ","""POT-Creation-Date: 2022-11-04 11:42+0000\n""""PO-Revision-Date: 2022-11-04 10:35+0000\n""",9,2
openstack%2Fdevstack~stable%2Fyoga~Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa,openstack/devstack,stable/yoga,Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa,DNM: testing gate,ABANDONED,2023-01-27 02:45:00.000000000,2023-01-27 04:33:39.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-27 02:45:00.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/59f4495aa153d3813a73ec2ef923b54366babf6b', 'message': 'DNM: testing gate\n\nChange-Id: Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa\n'}]",0,871922,59f4495aa153d3813a73ec2ef923b54366babf6b,3,1,1,8556,,,0,"DNM: testing gate

Change-Id: Ie7d6f9fd662463757f898c6ca97c1c99e70a62fa
",git fetch https://review.opendev.org/openstack/devstack refs/changes/22/871922/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,59f4495aa153d3813a73ec2ef923b54366babf6b,,#test,,1,0
openstack%2Fnova~master~I654e3d9dba09bfb4574f2c44a23b27585addf14a,openstack/nova,master,I654e3d9dba09bfb4574f2c44a23b27585addf14a,Nova: Add workaround to mask mpx on compareCPU(),ABANDONED,2023-01-09 03:52:15.000000000,2023-01-27 03:10:14.000000000,,"[{'_account_id': 9708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-09 03:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8fea6f58ea56a522e53003c0d2ce337d7315a41e', 'message': ""Nova: Add workaround to mask mpx on compareCPU()\nBecause of the cpu_map used by libvirt and nova's use of the\ncompareCPU() API.\nCustom CPU models which would be consider compatible from libvirt\nwith certain hypervisor cpu which no longer have mpx.\nSuch as Ice Lake.\nCause nova-compute to crash at _check_cpu_compatibility when\na compatible model is configured.\nThis workaround adds -mpx to the feature flags when running\n_check_cpu_compatibility.\n\nChange-Id: I654e3d9dba09bfb4574f2c44a23b27585addf14a\n""}, {'number': 2, 'created': '2023-01-09 03:54:28.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/conf/workarounds.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/834874d9814b7ced2e9ef04558f1776e3c4a4ca6', 'message': ""Nova: Add workaround to mask mpx on compareCPU()\n\n\nBecause of the cpu_map used by libvirt and nova's use of the\ncompareCPU() API.\nCustom CPU models which would be consider compatible from libvirt\nwith certain hypervisor cpu which no longer have mpx.\nSuch as Ice Lake.\nCause nova-compute to crash at _check_cpu_compatibility when\na compatible model is configured.\nThis workaround adds -mpx to the feature flags when running\n_check_cpu_compatibility.\n\nChange-Id: I654e3d9dba09bfb4574f2c44a23b27585addf14a\n""}]",3,869536,834874d9814b7ced2e9ef04558f1776e3c4a4ca6,9,2,2,30074,,,0,"Nova: Add workaround to mask mpx on compareCPU()


Because of the cpu_map used by libvirt and nova's use of the
compareCPU() API.
Custom CPU models which would be consider compatible from libvirt
with certain hypervisor cpu which no longer have mpx.
Such as Ice Lake.
Cause nova-compute to crash at _check_cpu_compatibility when
a compatible model is configured.
This workaround adds -mpx to the feature flags when running
_check_cpu_compatibility.

Change-Id: I654e3d9dba09bfb4574f2c44a23b27585addf14a
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/869536/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/conf/workarounds.py']",2,8fea6f58ea56a522e53003c0d2ce337d7315a41e,maskmpx," cfg.BoolOpt( 'mask_mpx_for_custom_models', default=False, help="""""" When trying to configure backwards compatibilty on Ice lake Processor with mpx feature not being avalible but expected in the cpu maps. """""" )", ,28,10
openstack%2Fdiskimage-builder~master~I7ca002783f8f15946bc84af95eecaa097e70aaf1,openstack/diskimage-builder,master,I7ca002783f8f15946bc84af95eecaa097e70aaf1,Reduce thin pool by one more extent,MERGED,2022-12-22 04:21:23.000000000,2023-01-27 02:36:39.000000000,2023-01-27 02:34:56.000000000,"[{'_account_id': 4571}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-22 04:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cc35e21f3161737eac95eaa72a53ad4599abe269', 'message': 'Reduce thin pool by one more extent\n\nThe previous commit was tested on 2TB without issue, but testing on a\nvery small volume (80GB) resulted in the thin pool lvextend failing\nfor being one extent too large.\n\nThis change reduces the pool size by one extent.\n\nChange-Id: I7ca002783f8f15946bc84af95eecaa097e70aaf1\nRelated: rhbz#2149586\n'}, {'number': 2, 'created': '2022-12-22 04:30:30.000000000', 'files': ['diskimage_builder/elements/growvols/tests/test_growvols.py', 'diskimage_builder/elements/growvols/static/usr/local/sbin/growvols'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/7e2a2aa027a96bf71a48428c8821f1be3aec4c7c', 'message': 'Reduce thin pool by one more extent\n\nThe previous commit was tested on 2TB without issue, but testing on a\nvery small volume (80GB) resulted in the thin pool lvextend failing\nfor being one extent too large.\n\nThis change reduces the pool size by one extent.\n\nChange-Id: I7ca002783f8f15946bc84af95eecaa097e70aaf1\nRelated: rhbz#2149586\n'}]",9,868376,7e2a2aa027a96bf71a48428c8821f1be3aec4c7c,36,3,2,4571,,,0,"Reduce thin pool by one more extent

The previous commit was tested on 2TB without issue, but testing on a
very small volume (80GB) resulted in the thin pool lvextend failing
for being one extent too large.

This change reduces the pool size by one extent.

Change-Id: I7ca002783f8f15946bc84af95eecaa097e70aaf1
Related: rhbz#2149586
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/76/868376/1 && git format-patch -1 --stdout FETCH_HEAD,['diskimage_builder/elements/growvols/static/usr/local/sbin/growvols'],1,cc35e21f3161737eac95eaa72a53ad4599abe269,rhbz/2149586, # rounded down to whole extent and reduced by 1 extent # for metadata overhead size_bytes -= PHYSICAL_EXTENT_BYTES, # rounded down to whole extent,3,1
openstack%2Fvitrage-tempest-plugin~master~Iacc49c43c5159d496fb47aaf358abbd4c46bbef6,openstack/vitrage-tempest-plugin,master,Iacc49c43c5159d496fb47aaf358abbd4c46bbef6,Add stable/zed jobs on master gate,ABANDONED,2023-01-27 01:49:09.000000000,2023-01-27 01:50:39.000000000,,[],"[{'number': 1, 'created': '2023-01-27 01:49:09.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/76462a59f25d6f2a16946ae6ee96e10251dde1ba', 'message': 'Add stable/zed jobs on master gate\n\nAs zed is released, we should add its job on master\ngate to keep branchless tempest plugins compatible\nto stable branch.\n\nRef: Tempest plugins guide for stable branch testing:\n- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html\n\nChange-Id: Iacc49c43c5159d496fb47aaf358abbd4c46bbef6\n'}]",0,871914,76462a59f25d6f2a16946ae6ee96e10251dde1ba,2,0,1,8556,,,0,"Add stable/zed jobs on master gate

As zed is released, we should add its job on master
gate to keep branchless tempest plugins compatible
to stable branch.

Ref: Tempest plugins guide for stable branch testing:
- https://docs.openstack.org/tempest/latest/stable_branch_testing_policy.html

Change-Id: Iacc49c43c5159d496fb47aaf358abbd4c46bbef6
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/14/871914/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,76462a59f25d6f2a16946ae6ee96e10251dde1ba,zed-stable-job, - vitrage-tempest-plugin-datasources-zed - vitrage-tempest-plugin-api-zed name: vitrage-tempest-plugin-api-zed parent: vitrage-tempest-plugin-api nodeset: openstack-single-node-focal override-checkout: stable/zed - job: name: vitrage-tempest-plugin-datasources-zed parent: vitrage-tempest-plugin-datasources nodeset: openstack-single-node-focal override-checkout: stable/zed - job:,,14,0
openstack%2Fnova~master~Ib523753f52993cfe72e35e0309e429ca879c125c,openstack/nova,master,Ib523753f52993cfe72e35e0309e429ca879c125c,libvirt: Replace usage of compareCPU() with compareHypervisorCPU(),MERGED,2023-01-12 10:38:55.000000000,2023-01-27 00:43:48.000000000,2023-01-26 17:50:28.000000000,"[{'_account_id': 7730}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-12 10:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/807761f573c0de2c93de604495405b85c3904055', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  To fix this and other\nrelated problems, for a couple of years now, libvirt has introduced a\nnewer counterpart API, compareHypervisorCPU(), which _does_ take into\naccount the host hypervisor\'s capabilities before comparing CPUs.  This\nwill solve a host of problems such as [1].\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 2, 'created': '2023-01-12 15:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d94fe5cc8c8f8b2eb1da56255ba7a3be24398e2c', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  To fix this and other\nrelated problems, for a couple of years now, libvirt has introduced a\nnewer counterpart API, compareHypervisorCPU(), which _does_ take into\naccount the host hypervisor\'s capabilities before comparing CPUs.  This\nwill solve a host of problems such as [1].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2023-01-12 15:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9277ff8fe7dff326ced9bb109a1390f329001057', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  To fix this and other\nrelated problems, for a couple of years now, libvirt has introduced a\nnewer counterpart API, compareHypervisorCPU(), which _does_ take into\naccount the host hypervisor\'s capabilities before comparing CPUs.  This\nwill solve a host of problems such as [1].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 4, 'created': '2023-01-12 17:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85978679ed3eda76a7ca2e4748f1b287361bb241', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 5, 'created': '2023-01-19 14:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00de6fd853ba4c826bd3e5d8148cd79fcbae36a4', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 6, 'created': '2023-01-20 11:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94674b054cf8c829361c911ac50e5fd870423877', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 7, 'created': '2023-01-20 15:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6bd40fca4851925c079a22589b6fba18fa47a89', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 8, 'created': '2023-01-23 14:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/94de5a71440de089dfc30d2b1d5ea75ad6f328ce', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 9, 'created': '2023-01-24 10:28:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/host.py', 'releasenotes/notes/use-compareHypervisorCPU-b75c8f097cc73556.yaml', 'nova/tests/fixtures/libvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/468b03e0ee4a917ae26106f6e57081bcd9e7a65b', 'message': 'libvirt: Replace usage of compareCPU() with compareHypervisorCPU()\n\nThe older libvirt API compareCPU() does not take into account the\ncapabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt\nknows about the host) when comparing CPUs.  This is causing unwanted\nfailures during CPU compatibility checks.  To fix this and other related\nproblems, libvirt has introduced (in v4.4.0) a newer API,\ncompareHypervisorCPU(), which _does_ take into account the host\nhypervisor\'s capabilities before comparing CPUs.  This will help fix a\nrange of problems, such as[1][2].\n\nSo let\'s switch to the newer API, which is largely a drop-in\nreplacement.\n\nIn this patch:\n\n - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt\'s\n   compareHypervisorCPU() API.\n\n - Update the _compare_cpu() method to use the wrapper method,\n   compare_hypervisor_cpu().\n\n - Update the unit tests to use the newer API, compareHypervisorCPU().\n\n[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064\n[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381\n\nChange-Id: Ib523753f52993cfe72e35e0309e429ca879c125c\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",28,869950,468b03e0ee4a917ae26106f6e57081bcd9e7a65b,70,4,9,6962,,,0,"libvirt: Replace usage of compareCPU() with compareHypervisorCPU()

The older libvirt API compareCPU() does not take into account the
capabilities of the ""host hypervisor"" (KVM, QEMU and the details libvirt
knows about the host) when comparing CPUs.  This is causing unwanted
failures during CPU compatibility checks.  To fix this and other related
problems, libvirt has introduced (in v4.4.0) a newer API,
compareHypervisorCPU(), which _does_ take into account the host
hypervisor's capabilities before comparing CPUs.  This will help fix a
range of problems, such as[1][2].

So let's switch to the newer API, which is largely a drop-in
replacement.

In this patch:

 - Introduce a wrapper method, compare_hypervisor_cpu() for libvirt's
   compareHypervisorCPU() API.

 - Update the _compare_cpu() method to use the wrapper method,
   compare_hypervisor_cpu().

 - Update the unit tests to use the newer API, compareHypervisorCPU().

[1] https://bugs.launchpad.net/ubuntu/+source/libvirt/+bug/1978064
[2] https://bugzilla.redhat.com/show_bug.cgi?id=2138381

Change-Id: Ib523753f52993cfe72e35e0309e429ca879c125c
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/869950/9 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/libvirt/host.py', 'releasenotes/notes/use-compareHypervisorCPU-b75c8f097cc73556.yaml', 'nova/tests/fixtures/libvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,807761f573c0de2c93de604495405b85c3904055,fix_compareCPU_usage," @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU', @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(fakelibvirt.Connection, 'compareHypervisorCPU') @mock.patch.object(host.Host, 'compare_hypervisor_cpu') @mock.patch.object(host.Host, 'compare_hypervisor_cpu') @mock.patch.object(host.Host, 'compare_hypervisor_cpu') @mock.patch.object(host.Host, 'compare_hypervisor_cpu') @mock.patch.object(host.Host, 'compare_hypervisor_cpu')"," @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(fakelibvirt.Connection, 'compareCPU', @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(fakelibvirt.Connection, 'compareCPU') @mock.patch.object(host.Host, 'compare_cpu') @mock.patch.object(host.Host, 'compare_cpu') @mock.patch.object(host.Host, 'compare_cpu') @mock.patch.object(host.Host, 'compare_cpu') @mock.patch.object(host.Host, 'compare_cpu')",72,13
openstack%2Fironic-inspector~bugfix%2F10.7~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,bugfix/10.7,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:18:55.000000000,2023-01-27 00:22:57.000000000,2023-01-27 00:21:55.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:18:55.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/dd8feda8cbff174dee35c6aab9ae2212f184eceb', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",0,871884,dd8feda8cbff174dee35c6aab9ae2212f184eceb,9,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/84/871884/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,dd8feda8cbff174dee35c6aab9ae2212f184eceb,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~stable%2Fvictoria~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/victoria,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:19:54.000000000,2023-01-26 23:51:20.000000000,2023-01-26 23:50:15.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:19:54.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/1388329b2febeb21a48c365212bef05d83ee48c5', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",0,871886,1388329b2febeb21a48c365212bef05d83ee48c5,7,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/86/871886/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,1388329b2febeb21a48c365212bef05d83ee48c5,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~bugfix%2F10.12~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,bugfix/10.12,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:17:21.000000000,2023-01-26 23:49:35.000000000,2023-01-26 23:48:38.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:17:21.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/aa841486ca058892e4ae8901be500facaf2c1529', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",0,871880,aa841486ca058892e4ae8901be500facaf2c1529,7,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/80/871880/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,aa841486ca058892e4ae8901be500facaf2c1529,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-inspector~stable%2Fzed~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,stable/zed,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:09:20.000000000,2023-01-26 23:48:13.000000000,2023-01-26 23:47:04.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:09:20.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e1932cd86b2ec977f6f16a688e676547e4e6a14b', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)\n""}]",0,871766,e1932cd86b2ec977f6f16a688e676547e4e6a14b,7,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
(cherry picked from commit e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d)
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/66/871766/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,e1932cd86b2ec977f6f16a688e676547e4e6a14b,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~stable%2Fzed~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,stable/zed,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-26 23:09:35.000000000,2023-01-26 23:36:04.000000000,2023-01-26 23:35:07.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-26 23:09:35.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/fa7e33b0b48480f0836f9ded8561cd35bf40ebab', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)\n""}]",0,871767,fa7e33b0b48480f0836f9ded8561cd35bf40ebab,7,2,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
(cherry picked from commit f8fc7e52f36de5c3515e60f5d2e6347a538a80d8)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/67/871767/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,fa7e33b0b48480f0836f9ded8561cd35bf40ebab,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fnova~master~I1491c9b234ef0c262b5ed01d4c138eba8dedff77,openstack/nova,master,I1491c9b234ef0c262b5ed01d4c138eba8dedff77,"Pass service ref to init_host(), if exists",MERGED,2022-11-07 18:32:10.000000000,2023-01-26 22:50:54.000000000,2023-01-26 22:48:51.000000000,"[{'_account_id': 4690}, {'_account_id': 7730}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2a2f9722ac05b73cdfff871000fd55e409ae23c', 'message': 'WIP: Pass service ref to init_host(), if exists\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n'}, {'number': 2, 'created': '2023-01-09 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec9426ae2bcd9ae4a6b9ca193b65872ebea504b3', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}, {'number': 3, 'created': '2023-01-10 18:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ef8d083c992cf57bf52174049d7d8a8ab6192a1', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}, {'number': 4, 'created': '2023-01-10 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/061f33bfc44a4c56662b5f09f118a45795d4e97b', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}, {'number': 5, 'created': '2023-01-10 19:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b9e91149a921f610210fa584de40ae85406bd5b', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}, {'number': 6, 'created': '2023-01-11 20:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b04ad937c2ffd3f932289daa6ed4258ed95f5e9', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}, {'number': 7, 'created': '2023-01-20 15:57:55.000000000', 'files': ['nova/service.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/test_service.py', 'nova/manager.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cf111d10013eedca0f377d84307e7e41181b7200', 'message': ""Pass service ref to init_host(), if exists\n\nThis just adds the service ref to init_host() so that we can pass it\n(if it exists) at startup. On the first run, this will be None, so\nwe know that we don't have an existing service record and thus do not\nneed to do any migration.\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77\n""}]",19,863916,cf111d10013eedca0f377d84307e7e41181b7200,54,5,7,4393,,,0,"Pass service ref to init_host(), if exists

This just adds the service ref to init_host() so that we can pass it
(if it exists) at startup. On the first run, this will be None, so
we know that we don't have an existing service record and thus do not
need to do any migration.

Related to blueprint stable-compute-uuid

Change-Id: I1491c9b234ef0c262b5ed01d4c138eba8dedff77
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/863916/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/service.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/test_service.py', 'nova/manager.py', 'nova/compute/manager.py']",5,d2a2f9722ac05b73cdfff871000fd55e409ae23c,bp/stable-compute-uuid," def init_host(self, service_ref):", def init_host(self):,22,18
openstack%2Fnova~master~Ie8897a843fadf325c696b411923f075e237a7342,openstack/nova,master,Ie8897a843fadf325c696b411923f075e237a7342,Add virt/node module for stable uuids,MERGED,2022-11-07 18:32:10.000000000,2023-01-26 22:49:57.000000000,2023-01-26 22:48:44.000000000,"[{'_account_id': 4690}, {'_account_id': 7166}, {'_account_id': 7730}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 18:32:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6631ccd6b6690b0d6ad30ebf13e1b1fa8b03d2f', 'message': 'Add virt/node module for stable uuids\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 2, 'created': '2023-01-09 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c77cacaef420bfa8052d9f8015d87ca14e4c2be2', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 3, 'created': '2023-01-10 18:31:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28bf33ddc59e551445ac999cc41b841a4c49b4d8', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 4, 'created': '2023-01-10 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/348e31f66735facc6103d932e489eb47164209e0', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 5, 'created': '2023-01-10 19:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e1e88a11b516a9d76fe5eb472dcb761007ce831', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 6, 'created': '2023-01-11 20:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2dec7d46790f489dcf1333c073065a6448630d31', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}, {'number': 7, 'created': '2023-01-20 15:57:55.000000000', 'files': ['nova/exception.py', 'nova/tests/fixtures/nova.py', 'nova/virt/node.py', 'nova/tests/functional/integrated_helpers.py', 'nova/test.py', 'nova/tests/unit/virt/test_node.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3b33b0938ea4f5b00537298bc7fcb531fb9ec811', 'message': 'Add virt/node module for stable uuids\n\nRelated to blueprint stable-compute-uuid\n\nChange-Id: Ie8897a843fadf325c696b411923f075e237a7342\n'}]",48,863915,3b33b0938ea4f5b00537298bc7fcb531fb9ec811,55,6,7,4393,,,0,"Add virt/node module for stable uuids

Related to blueprint stable-compute-uuid

Change-Id: Ie8897a843fadf325c696b411923f075e237a7342
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/863915/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/tests/fixtures/nova.py', 'nova/virt/node.py', 'nova/test.py', 'nova/tests/functional/integrated_helpers.py', 'nova/tests/unit/virt/test_node.py']",6,d6631ccd6b6690b0d6ad30ebf13e1b1fa8b03d2f,bp/stable-compute-uuid,"# Copyright 2022 Red Hat, inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import os from unittest import mock import uuid import fixtures from oslo_config import cfg from oslo_utils.fixture import uuidsentinel as uuids import testtools from nova import exception from nova import test from nova.tests import fixtures as nova_fixtures from nova.virt import node CONF = cfg.CONF # NOTE(danms): We do not inherit from test.TestCase because we need # our node methods not stubbed out in order to exercise them. class TestNodeIdentity(testtools.TestCase): def flags(self, **kw): """"""Override flag variables for a test."""""" group = kw.pop('group', None) for k, v in kw.items(): CONF.set_override(k, v, group) def setUp(self): super().setUp() self.useFixture(nova_fixtures.ConfFixture(CONF)) self.tempdir = self.useFixture(fixtures.TempDir()).path self.identity_file = os.path.join(self.tempdir, node.COMPUTE_ID_FILE) self.fake_config_files = ['%s/etc/nova.conf' % self.tempdir, '%s/etc/nova/nova.conf' % self.tempdir, '%s/opt/etc/nova/nova.conf' % self.tempdir] for fn in self.fake_config_files: os.makedirs(os.path.dirname(fn)) self.flags(state_path=self.tempdir, config_file=self.fake_config_files) node.LOCAL_NODE_UUID = None def test_generate_local_node_uuid(self): node_uuid = uuids.node node.write_local_node_uuid(node_uuid) e = self.assertRaises(exception.InvalidNodeConfiguration, node.write_local_node_uuid, 'anything') self.assertIn( 'Identity file %s appeared unexpectedly' % self.identity_file, str(e)) def test_generate_local_node_uuid_unexpected_open_fail(self): with mock.patch('builtins.open') as mock_open: mock_open.side_effect = IndexError() e = self.assertRaises(exception.InvalidNodeConfiguration, node.write_local_node_uuid, 'foo') self.assertIn('Unable to write uuid to %s' % ( self.identity_file), str(e)) def test_generate_local_node_uuid_unexpected_write_fail(self): with mock.patch('builtins.open') as mock_open: mock_open.return_value.write.side_effect = IndexError() e = self.assertRaises(exception.InvalidNodeConfiguration, node.write_local_node_uuid, 'foo') self.assertIn('Unable to write uuid to %s' % ( self.identity_file), str(e)) def test_get_local_node_uuid_simple_exists(self): node_uuid = uuids.node with test.patch_open('%s/etc/nova/compute_id' % self.tempdir, node_uuid): self.assertEqual(node_uuid, node.get_local_node_uuid()) def test_get_local_node_uuid_simple_exists_whitespace(self): node_uuid = uuids.node # Make sure we strip whitespace from the file contents with test.patch_open('%s/etc/nova/compute_id' % self.tempdir, ' %s \n' % node_uuid): self.assertEqual(node_uuid, node.get_local_node_uuid()) def test_get_local_node_uuid_simple_generate(self): self.assertIsNone(node.LOCAL_NODE_UUID) node_uuid1 = node.get_local_node_uuid() self.assertEqual(node_uuid1, node.LOCAL_NODE_UUID) node_uuid2 = node.get_local_node_uuid() self.assertEqual(node_uuid1, node.LOCAL_NODE_UUID) # Make sure we got the same thing each time, and that it's a # valid uuid. Since we provided no uuid, it must have been # generated the first time and read/returned the second. self.assertEqual(node_uuid1, node_uuid2) uuid.UUID(node_uuid1) # Try to read it directly to make sure the file was really # created and with the right value. self.assertEqual(node_uuid1, node.read_local_node_uuid()) def test_get_local_node_uuid_two(self): node_uuid = uuids.node # Write the uuid to two of our locations for cf in (self.fake_config_files[0], self.fake_config_files[1]): open(os.path.join(os.path.dirname(cf), node.COMPUTE_ID_FILE), 'w').write(node_uuid) # Make sure we got the expected uuid and that no exceptions # were raised about the files disagreeing self.assertEqual(node_uuid, node.get_local_node_uuid()) def test_get_local_node_uuid_two_mismatch(self): node_uuids = [uuids.node1, uuids.node2] # Write a different uuid to each file for i, cf in enumerate((self.fake_config_files[0], self.fake_config_files[1])): open(os.path.join( os.path.dirname(cf), node.COMPUTE_ID_FILE), 'w').write(node_uuids[i]) # Make sure we get an error that identifies the mismatching # file with its uuid, as well as what we expected to find e = self.assertRaises(exception.InvalidNodeConfiguration, node.get_local_node_uuid) expected = ('UUID %s in %s does not match %s' % ( node_uuids[1], os.path.join(os.path.dirname(self.fake_config_files[1]), 'compute_id'), node_uuids[0])) self.assertIn(expected, str(e)) ",,274,0
openstack%2Fmanila~master~I778e47dabbd518dd4f7797b99f09e52fa7f56a3d,openstack/manila,master,I778e47dabbd518dd4f7797b99f09e52fa7f56a3d,[NetApp] fallback to cifs-server force delete on vserver cleanup,MERGED,2022-11-04 16:29:47.000000000,2023-01-26 22:18:06.000000000,2023-01-26 22:16:33.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 31721}]","[{'number': 1, 'created': '2022-11-04 16:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/5f664ae31388e84aac68f353d9200dbf415fa80a', 'message': ""[NetApp] fallback to cifs-server force delete on vserver cleanup\n\nIf deletion with username + password is not working.\n\nFixes error: 'NetApp API failed. Reason - 19149:Username cannot be empty.'\nThe parameter username is marked as optional, but it has to be given\neither the force option or username + password.\n\nCloses-Bug: #1995733\nChange-Id: I778e47dabbd518dd4f7797b99f09e52fa7f56a3d\n""}, {'number': 2, 'created': '2022-11-23 09:28:06.000000000', 'files': ['releasenotes/notes/bug-1995733-netapp-cifs-server-force-delete-d513c548ebf56448.yaml', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/46d0c4d34a5a0d477788cdc036f8e575bbc8ed58', 'message': ""[NetApp] fallback to cifs-server force delete on vserver cleanup\n\nIf deletion with username + password is not working.\n\nFixes error: 'NetApp API failed. Reason - 19149:Username cannot be empty.'\nThe parameter username is marked as optional, but it has to be given\neither the force option or username + password.\n\nCloses-Bug: #1995733\nChange-Id: I778e47dabbd518dd4f7797b99f09e52fa7f56a3d\n""}]",14,863295,46d0c4d34a5a0d477788cdc036f8e575bbc8ed58,25,4,2,18816,,,0,"[NetApp] fallback to cifs-server force delete on vserver cleanup

If deletion with username + password is not working.

Fixes error: 'NetApp API failed. Reason - 19149:Username cannot be empty.'
The parameter username is marked as optional, but it has to be given
either the force option or username + password.

Closes-Bug: #1995733
Change-Id: I778e47dabbd518dd4f7797b99f09e52fa7f56a3d
",git fetch https://review.opendev.org/openstack/manila refs/changes/95/863295/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1995733-netapp-cifs-server-force-delete-d513c548ebf56448.yaml', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py']",3,5f664ae31388e84aac68f353d9200dbf415fa80a,bug/1995733," LOG.debug('CIFS server force deleted for ' 'Vserver %s.', vserver_name) force_args = { 'force-account-delete': 'true' } vserver_client.send_request('cifs-server-delete', force_args)", vserver_client.send_request('cifs-server-delete'),19,2
openstack%2Fpuppet-tripleo~master~I65720576249f2242331e38762dd0d5860d74de9d,openstack/puppet-tripleo,master,I65720576249f2242331e38762dd0d5860d74de9d,Ensure haproxy::balancemember::ports is a string,MERGED,2023-01-26 06:14:31.000000000,2023-01-26 20:59:06.000000000,2023-01-26 20:59:06.000000000,"[{'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2023-01-26 06:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c3d1432c719f998045d1911b2cd14a77fd15b79a', 'message': 'Ensure haproxy::balancemember::ports is a string\n\nThe recent change[1] in puppetlabs-haproxy introduced data type check\nand now the ports parameter accept only string or array of strings and\nno longer accepts an integer.\n\nThis ensures the value is converted to avoid validation errors.\n\n[1] https://github.com/puppetlabs/puppetlabs-haproxy/commit/95ca912f77966ed0da7a5bec9265cdacbf09da4c\n\nCloses-Bug: #2003882\nChange-Id: I65720576249f2242331e38762dd0d5860d74de9d\n'}, {'number': 2, 'created': '2023-01-26 09:30:02.000000000', 'files': ['manifests/haproxy/horizon_endpoint.pp', 'manifests/haproxy/endpoint.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/6372a182e4366c9c49c69d80bf2418ff0e7f5e58', 'message': 'Ensure haproxy::balancemember::ports is a string\n\nThe recent change[1] in puppetlabs-haproxy introduced data type check\nand now the ports parameter accept only string or array of strings and\nno longer accepts an integer.\n\nThis ensures the value is converted to avoid validation errors.\n\n[1] https://github.com/puppetlabs/puppetlabs-haproxy/commit/95ca912f77966ed0da7a5bec9265cdacbf09da4c\n\nCloses-Bug: #2003882\nChange-Id: I65720576249f2242331e38762dd0d5860d74de9d\n'}]",4,871807,6372a182e4366c9c49c69d80bf2418ff0e7f5e58,12,3,2,9816,,,0,"Ensure haproxy::balancemember::ports is a string

The recent change[1] in puppetlabs-haproxy introduced data type check
and now the ports parameter accept only string or array of strings and
no longer accepts an integer.

This ensures the value is converted to avoid validation errors.

[1] https://github.com/puppetlabs/puppetlabs-haproxy/commit/95ca912f77966ed0da7a5bec9265cdacbf09da4c

Closes-Bug: #2003882
Change-Id: I65720576249f2242331e38762dd0d5860d74de9d
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/07/871807/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/haproxy/horizon_endpoint.pp', 'manifests/haproxy/endpoint.pp']",2,c3d1432c719f998045d1911b2cd14a77fd15b79a,bug/2003882," ports => ""${service_port_real}"", ports => ""${service_port_real}"","," ports => $service_port_real, ports => $service_port_real,",3,3
openstack%2Fpuppet-ironic~stable%2Fzed~I49a295dd23eedd758bc9bb2e8a7ff9e740cb2c42,openstack/puppet-ironic,stable/zed,I49a295dd23eedd758bc9bb2e8a7ff9e740cb2c42,inspector: Fix wrong group of policy file,MERGED,2023-01-24 12:42:15.000000000,2023-01-26 19:25:20.000000000,2023-01-26 19:25:20.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 12:42:15.000000000', 'files': ['manifests/inspector/policy.pp', 'spec/classes/ironic_inspector_policy_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/3802e37495513b9c306d57a90159eac028611d59', 'message': 'inspector: Fix wrong group of policy file\n\nThe ironic-inspector service is launched using the separate user/group\n(ironic-inspector) so the file should be owned by that group instead of\nthe ironic group.\n\nCloses-Bug: #2003681\nChange-Id: I49a295dd23eedd758bc9bb2e8a7ff9e740cb2c42\n(cherry picked from commit 439927462fe651a8d4ee7788e5f0b00ed0f64d09)\n'}]",1,871553,3802e37495513b9c306d57a90159eac028611d59,11,3,1,9816,,,0,"inspector: Fix wrong group of policy file

The ironic-inspector service is launched using the separate user/group
(ironic-inspector) so the file should be owned by that group instead of
the ironic group.

Closes-Bug: #2003681
Change-Id: I49a295dd23eedd758bc9bb2e8a7ff9e740cb2c42
(cherry picked from commit 439927462fe651a8d4ee7788e5f0b00ed0f64d09)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/53/871553/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/inspector/policy.pp', 'spec/classes/ironic_inspector_policy_spec.rb']",2,3802e37495513b9c306d57a90159eac028611d59,bug/2003681," :file_group => 'ironic-inspector', :file_group => 'ironic-inspector',"," :file_group => 'ironic', :file_group => 'ironic',",3,3
openstack%2Fmanila~stable%2Fyoga~I29b51fcec28dd5110de6ad196ff8b67c875ce8fa,openstack/manila,stable/yoga,I29b51fcec28dd5110de6ad196ff8b67c875ce8fa,[Infinidat] fixed host assisted migration,MERGED,2023-01-19 12:42:46.000000000,2023-01-26 19:16:56.000000000,2023-01-26 19:15:50.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2023-01-19 12:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6a626d005a119550c5830b9c1d346afe3254f95e', 'message': '[Infinidat] fixed host assisted migration\n\nFixed an issue in Infinidat driver to support host assisted migration.\nAnd added new configuration options:\n* `infinidat_snapdir_accessible` to configure access to the `.snapshot`\n  directory on the client side.\n* `infinidat_snapdir_visible` to configure visibility of the `.snapshot`\n  directory on the client side.\n\nCloses-Bug: #1992443\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\nChange-Id: I29b51fcec28dd5110de6ad196ff8b67c875ce8fa\n(cherry picked from commit 7ec7321053c73c18764782d4c40cf77a998f8d41)\n(cherry picked from commit e105df94a7ad858538f20609595621a63df14070)\n'}, {'number': 2, 'created': '2023-01-19 12:50:38.000000000', 'files': ['manila/tests/share/drivers/infinidat/test_infinidat.py', 'doc/source/configuration/tables/manila-infinidat.inc', 'releasenotes/notes/bug-1992443-infinidat-host-assisted-migration-4344c4d076b66796.yaml', 'doc/source/configuration/shared-file-systems/drivers/infinidat-share-driver.rst', 'manila/share/drivers/infinidat/infinibox.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/594fb45ce41f23f13eadbcfc537790ca8374e774', 'message': '[Infinidat] fixed host assisted migration\n\nFixed an issue in Infinidat driver to support host assisted migration.\nAnd added new configuration options:\n* `infinidat_snapdir_accessible` to configure access to the `.snapshot`\n  directory on the client side.\n* `infinidat_snapdir_visible` to configure visibility of the `.snapshot`\n  directory on the client side.\n\nCloses-Bug: #1992443\nSigned-off-by: Alexander Deiter <adeiter@infinidat.com>\nChange-Id: I29b51fcec28dd5110de6ad196ff8b67c875ce8fa\n(cherry picked from commit 7ec7321053c73c18764782d4c40cf77a998f8d41)\n(cherry picked from commit e105df94a7ad858538f20609595621a63df14070)\n'}]",15,871046,594fb45ce41f23f13eadbcfc537790ca8374e774,31,3,2,35075,,,0,"[Infinidat] fixed host assisted migration

Fixed an issue in Infinidat driver to support host assisted migration.
And added new configuration options:
* `infinidat_snapdir_accessible` to configure access to the `.snapshot`
  directory on the client side.
* `infinidat_snapdir_visible` to configure visibility of the `.snapshot`
  directory on the client side.

Closes-Bug: #1992443
Signed-off-by: Alexander Deiter <adeiter@infinidat.com>
Change-Id: I29b51fcec28dd5110de6ad196ff8b67c875ce8fa
(cherry picked from commit 7ec7321053c73c18764782d4c40cf77a998f8d41)
(cherry picked from commit e105df94a7ad858538f20609595621a63df14070)
",git fetch https://review.opendev.org/openstack/manila refs/changes/46/871046/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/infinidat/test_infinidat.py', 'doc/source/configuration/tables/manila-infinidat.inc', 'releasenotes/notes/bug-1992443-infinidat-host-assisted-migration-4344c4d076b66796.yaml', 'doc/source/configuration/shared-file-systems/drivers/infinidat-share-driver.rst', 'manila/share/drivers/infinidat/infinibox.py']",5,6a626d005a119550c5830b9c1d346afe3254f95e,bug/1992443," default=True), cfg.BoolOpt('infinidat_snapdir_accessible', help=('Controls access to the .snapshot directory. ' 'By default, each share allows access to its own ' '.snapshot directory, which contains files and ' 'directories of each snapshot taken. To restrict ' 'access to the .snapshot directory, this option ' 'should be set to False.'), default=True), cfg.BoolOpt('infinidat_snapdir_visible', help=('Controls visibility of the .snapshot directory. ' 'By default, each share contains the .snapshot ' 'directory, which is hidden on the client side. ' 'To make the .snapshot directory visible, this ' 'option should be set to True.'), default=False), ] """"""INFINIDAT InfiniBox Share driver. Version history: 1.0 - initial release 1.1 - added support for TLS/SSL communication 1.2 - fixed host assisted migration """""" VERSION = '1.2' # driver version snapdir_visible = self.configuration.infinidat_snapdir_visible infinidat_export = infinidat_filesystem.add_export( permissions=[], snapdir_visible=snapdir_visible) return self._make_export_locations(infinidat_export) @infinisdk_to_manila_exceptions def _ensure_filesystem_export(self, infinidat_filesystem): try: infinidat_export = self._get_export(infinidat_filesystem) except exception.ShareBackendException: return self._create_filesystem_export(infinidat_filesystem) actual = infinidat_export.is_snapdir_visible() expected = self.configuration.infinidat_snapdir_visible if actual is not expected: LOG.debug('Update snapdir_visible for %s: %s -> %s', infinidat_filesystem.get_name(), actual, expected) infinidat_export.update_snapdir_visible(expected) return self._make_export_locations(infinidat_export) @infinisdk_to_manila_exceptions def _make_export_locations(self, infinidat_export): name = self._make_share_name(share) snapdir_accessible = self.configuration.infinidat_snapdir_accessible pool=pool, name=name, size=size, provtype=self._provtype, snapdir_accessible=snapdir_accessible) snapdir_accessible = self.configuration.infinidat_snapdir_accessible name=name, write_protected=False, snapdir_accessible=snapdir_accessible) snapdir_accessible = self.configuration.infinidat_snapdir_accessible infinidat_snapshot = infinidat_filesystem.create_snapshot( name=name, snapdir_accessible=snapdir_accessible) """"""Ensure that share is properly configured and exported."""""" actual = infinidat_filesystem.is_snapdir_accessible() expected = self.configuration.infinidat_snapdir_accessible if actual is not expected: LOG.debug('Update snapdir_accessible for %s: %s -> %s', infinidat_filesystem.get_name(), actual, expected) infinidat_filesystem.update_field('snapdir_accessible', expected) return self._ensure_filesystem_export(infinidat_filesystem) def ensure_shares(self, context, shares): """"""Invoked to ensure that shares are exported."""""" updates = {} for share in shares: updates[share['id']] = { 'export_locations': self.ensure_share(context, share)} return updates def get_backend_info(self, context): snapdir_accessible = self.configuration.infinidat_snapdir_accessible snapdir_visible = self.configuration.infinidat_snapdir_visible return { 'snapdir_accessible': snapdir_accessible, 'snapdir_visible': snapdir_visible }"," default=True)] VERSION = '1.1' # driver version infinidat_export = infinidat_filesystem.add_export(permissions=[]) share_name = self._make_share_name(share) pool=pool, name=share_name, size=size, provtype=self._provtype) name=name, write_protected=False) infinidat_snapshot = infinidat_filesystem.create_snapshot(name=name) try: infinidat_export = self._get_export(infinidat_filesystem) return self._get_full_nfs_export_paths( infinidat_export.get_export_path()) except exception.ShareBackendException: # export not found, need to re-export message = (""missing export for share %(share)s, trying to "" ""re-export"") LOG.info(message, {""share"": share}) return self._create_filesystem_export(infinidat_filesystem)",261,49
openstack%2Fpuppet-glance~stable%2Fwallaby~I6c0ea1276d16722c9908a20333890a4a17404b61,openstack/puppet-glance,stable/wallaby,I6c0ea1276d16722c9908a20333890a4a17404b61,Add support for MultiStrOpt,MERGED,2023-01-24 01:16:13.000000000,2023-01-26 19:15:21.000000000,2023-01-26 19:15:21.000000000,"[{'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 01:16:13.000000000', 'files': ['lib/puppet/provider/glance_api_config/ini_setting.rb', 'lib/puppet/provider/glance_api_config/openstackconfig.rb', 'spec/unit/type/glance_api_config_spec.rb', 'lib/puppet/type/glance_api_config.rb', 'spec/unit/provider/glance_api_config/openstackconfig_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/81b081d759883b23fa01d5ef6abdd3c0c41b603d', 'message': 'Add support for MultiStrOpt\n\nThis replaces the provider implementation of glance_api_config type\nso that MultiStrOpt, which is used by several options like\n - oslo_messaging_notifications/driver\n - oslo_policy/policy_dirs\nis handled correctly.\n\nChange-Id: I6c0ea1276d16722c9908a20333890a4a17404b61\n(cherry picked from commit 10872d13eb3e30636b0b22f2b813a0a18c875728)\n'}]",1,871505,81b081d759883b23fa01d5ef6abdd3c0c41b603d,9,3,1,9816,,,0,"Add support for MultiStrOpt

This replaces the provider implementation of glance_api_config type
so that MultiStrOpt, which is used by several options like
 - oslo_messaging_notifications/driver
 - oslo_policy/policy_dirs
is handled correctly.

Change-Id: I6c0ea1276d16722c9908a20333890a4a17404b61
(cherry picked from commit 10872d13eb3e30636b0b22f2b813a0a18c875728)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/05/871505/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/glance_api_config/ini_setting.rb', 'lib/puppet/provider/glance_api_config/openstackconfig.rb', 'spec/unit/type/glance_api_config_spec.rb', 'lib/puppet/type/glance_api_config.rb', 'spec/unit/provider/glance_api_config/openstackconfig_spec.rb']",5,81b081d759883b23fa01d5ef6abdd3c0c41b603d,multistropt-stable/wallaby,"# # these tests are a little concerning b/c they are hacking around the # modulepath, so these tests will not catch issues that may eventually arise # related to loading these plugins. # I could not, for the life of me, figure out how to programmatically set the modulepathprovider_class = Puppet::Type.type(:glance_api_config).provider(:openstackconfig) {:name => 'DEFAULT/foo', :value => 'bar'} {:name => 'dude/foo', :value => 'bar'}"," provider_class = Puppet::Type.type(:glance_api_config).provider(:ini_setting) { :name => 'DEFAULT/foo', :value => 'bar' } { :name => 'dude/foo', :value => 'bar' }",74,24
openstack%2Fpuppet-ironic~stable%2Fwallaby~Icbc4d60d2538317c05ff5760359b45327abfb533,openstack/puppet-ironic,stable/wallaby,Icbc4d60d2538317c05ff5760359b45327abfb533,Add support for MultiStrOpt,MERGED,2023-01-23 19:27:17.000000000,2023-01-26 19:09:00.000000000,2023-01-26 19:09:00.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 19:27:17.000000000', 'files': ['spec/unit/provider/ironic_config/openstackconfig_spec.rb', 'lib/puppet/type/ironic_config.rb', 'spec/unit/type/ironic_config_spec.rb', 'lib/puppet/provider/ironic_config/openstackconfig.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/e1ea3991460a6a2c4f1f34542b6d9c84e022c4e4', 'message': 'Add support for MultiStrOpt\n\nThis replaces the provider implementation of ironic_config type so that\nMultiStrOpt, which is used by several options like\n - oslo_messaging_notifications/driver\n - oslo_policy/policy_dirs\nare handled correctly.\n\nChange-Id: Icbc4d60d2538317c05ff5760359b45327abfb533\n(cherry picked from commit 0f4a5263a7f4264f6148e8c04f32992b0b07e1a5)\n'}]",2,871500,e1ea3991460a6a2c4f1f34542b6d9c84e022c4e4,10,3,1,24245,,,0,"Add support for MultiStrOpt

This replaces the provider implementation of ironic_config type so that
MultiStrOpt, which is used by several options like
 - oslo_messaging_notifications/driver
 - oslo_policy/policy_dirs
are handled correctly.

Change-Id: Icbc4d60d2538317c05ff5760359b45327abfb533
(cherry picked from commit 0f4a5263a7f4264f6148e8c04f32992b0b07e1a5)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/00/871500/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/ironic_config/openstackconfig_spec.rb', 'lib/puppet/type/ironic_config.rb', 'spec/unit/type/ironic_config_spec.rb', 'lib/puppet/provider/ironic_config/openstackconfig.rb']",4,e1ea3991460a6a2c4f1f34542b6d9c84e022c4e4,multistropt-stable/wallaby," :openstackconfig, :parent => Puppet::Type.type(:openstack_config).provider(:ruby)"," :ini_setting, :parent => Puppet::Type.type(:openstack_config).provider(:ini_setting)",24,21
openstack%2Fpuppet-cinder~stable%2Fwallaby~If052cde4da84970df4af657136060532ccb422f7,openstack/puppet-cinder,stable/wallaby,If052cde4da84970df4af657136060532ccb422f7,Add support for MultiStrOpt,MERGED,2023-01-24 01:16:23.000000000,2023-01-26 19:03:28.000000000,2023-01-26 19:03:28.000000000,"[{'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 01:16:23.000000000', 'files': ['lib/puppet/provider/cinder_config/openstackconfig.rb', 'spec/unit/provider/cinder_config/openstackconfig_spec.rb', 'lib/puppet/provider/cinder_config/ini_setting.rb', 'lib/puppet/type/cinder_config.rb', 'spec/unit/type/cinder_config_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/6aa60e78871eaef035620d9b9d871cfabedb6193', 'message': 'Add support for MultiStrOpt\n\nThis replaces the provider implementation of cinder_config type so that\nMultiStrOpt, which is used by several options like\n - oslo_messaging_notifications/driver\n - oslo_policy/policy_dirs\nis handled correctly.\n\nChange-Id: If052cde4da84970df4af657136060532ccb422f7\n(cherry picked from commit 870ff626558c0203a4be1ae64e5d31212c0cd80f)\n'}]",1,871506,6aa60e78871eaef035620d9b9d871cfabedb6193,9,3,1,9816,,,0,"Add support for MultiStrOpt

This replaces the provider implementation of cinder_config type so that
MultiStrOpt, which is used by several options like
 - oslo_messaging_notifications/driver
 - oslo_policy/policy_dirs
is handled correctly.

Change-Id: If052cde4da84970df4af657136060532ccb422f7
(cherry picked from commit 870ff626558c0203a4be1ae64e5d31212c0cd80f)
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/06/871506/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/cinder_config/openstackconfig.rb', 'spec/unit/provider/cinder_config/openstackconfig_spec.rb', 'lib/puppet/provider/cinder_config/ini_setting.rb', 'lib/puppet/type/cinder_config.rb', 'spec/unit/type/cinder_config_spec.rb']",5,6aa60e78871eaef035620d9b9d871cfabedb6193,multistropt-stable/wallaby, expect(@cinder_config[:value]).to eq(['bar']) expect(@cinder_config[:value]).to eq(['b ar']), expect(@cinder_config[:value]).to eq('bar') expect(@cinder_config[:value]).to eq('b ar'),31,26
openstack%2Fpuppet-ironic~stable%2Fwallaby~If032600c34394f9f0f3686971082aafeab9be3ea,openstack/puppet-ironic,stable/wallaby,If032600c34394f9f0f3686971082aafeab9be3ea,Add support for MultiStrOpt (inspector),MERGED,2023-01-23 19:26:39.000000000,2023-01-26 19:02:29.000000000,2023-01-26 19:02:29.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 19:26:39.000000000', 'files': ['lib/puppet/provider/ironic_inspector_config/openstackconfig.rb', 'lib/puppet/type/ironic_inspector_config.rb', 'spec/unit/type/ironic_inspector_config_spec.rb', 'spec/unit/provider/ironic_inspector_config/openstackconfig_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/6722b8cc463f76f6afd187da558be813fc3f0ca6', 'message': 'Add support for MultiStrOpt (inspector)\n\nThis replaces the provider implementation of ironic_inspector_config\ntype so that MultiStrOpt, which is used by several options like\n - oslo_policy/policy_dirs\nare handled correctly.\n\nThe same was already implemented for ironic_config by [1].\n\n[1] 0f4a5263a7f4264f6148e8c04f32992b0b07e1a5\n\nChange-Id: If032600c34394f9f0f3686971082aafeab9be3ea\n(cherry picked from commit ecdeb8f36575675998e1d3e77fba53fb5ee87e50)\n(cherry picked from commit 7e1f4200372542e9169c4e18fcf5f557b9e2ce46)\n'}]",2,871499,6722b8cc463f76f6afd187da558be813fc3f0ca6,13,3,1,24245,,,0,"Add support for MultiStrOpt (inspector)

This replaces the provider implementation of ironic_inspector_config
type so that MultiStrOpt, which is used by several options like
 - oslo_policy/policy_dirs
are handled correctly.

The same was already implemented for ironic_config by [1].

[1] 0f4a5263a7f4264f6148e8c04f32992b0b07e1a5

Change-Id: If032600c34394f9f0f3686971082aafeab9be3ea
(cherry picked from commit ecdeb8f36575675998e1d3e77fba53fb5ee87e50)
(cherry picked from commit 7e1f4200372542e9169c4e18fcf5f557b9e2ce46)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/99/871499/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/ironic_inspector_config/openstackconfig.rb', 'lib/puppet/type/ironic_inspector_config.rb', 'spec/unit/type/ironic_inspector_config_spec.rb', 'spec/unit/provider/ironic_inspector_config/openstackconfig_spec.rb']",4,6722b8cc463f76f6afd187da558be813fc3f0ca6,multistropt-stable/wallaby,"# # these tests are a little concerning b/c they are hacking around the # modulepath, so these tests will not catch issues that may eventually arise # related to loading these plugins. # I could not, for the life of me, figure out how to programmatically set the modulepathprovider_class = Puppet::Type.type(:ironic_inspector_config).provider(:openstackconfig) {:name => 'DEFAULT/foo', :value => 'bar'} {:name => 'dude/foo', :value => 'bar'}","provider_class = Puppet::Type.type(:ironic_inspector_config).provider(:ini_setting) { :name => 'DEFAULT/foo', :value => 'bar' } { :name => 'dude/foo', :value => 'bar' }",66,13
openstack%2Fpuppet-manila~stable%2Fwallaby~Id09addfa7f930e0f2279dc114e68ca8a635b0d9d,openstack/puppet-manila,stable/wallaby,Id09addfa7f930e0f2279dc114e68ca8a635b0d9d,Add support for MultiStrOpt,MERGED,2023-01-24 01:16:34.000000000,2023-01-26 18:56:21.000000000,2023-01-26 18:56:21.000000000,"[{'_account_id': 14985}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 01:16:34.000000000', 'files': ['lib/puppet/provider/manila_config/ini_setting.rb', 'lib/puppet/type/manila_config.rb', 'lib/puppet/provider/manila_config/openstackconfig.rb', 'spec/unit/type/manila_config_spec.rb', 'spec/unit/provider/manila_config/openstackconfig_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/a72a7d5ed9169da17741c22a01bbe191b4fbaf2a', 'message': 'Add support for MultiStrOpt\n\nThis replaces the provider implementation of manila_config type so that\nMultiStrOpt, which is used by several options like\n - oslo_messaging_notifications/driver\n - oslo_policy/policy_dirs\nare handled correctly.\n\nChange-Id: Id09addfa7f930e0f2279dc114e68ca8a635b0d9d\n(cherry picked from commit d81d5226e2dedf91c4d9dca107874d002376b279)\n'}]",1,871507,a72a7d5ed9169da17741c22a01bbe191b4fbaf2a,9,3,1,9816,,,0,"Add support for MultiStrOpt

This replaces the provider implementation of manila_config type so that
MultiStrOpt, which is used by several options like
 - oslo_messaging_notifications/driver
 - oslo_policy/policy_dirs
are handled correctly.

Change-Id: Id09addfa7f930e0f2279dc114e68ca8a635b0d9d
(cherry picked from commit d81d5226e2dedf91c4d9dca107874d002376b279)
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/07/871507/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/manila_config/ini_setting.rb', 'lib/puppet/type/manila_config.rb', 'lib/puppet/provider/manila_config/openstackconfig.rb', 'spec/unit/type/manila_config_spec.rb', 'spec/unit/provider/manila_config/openstackconfig_spec.rb']",5,a72a7d5ed9169da17741c22a01bbe191b4fbaf2a,multistropt-stable/wallaby,"# # these tests are a little concerning b/c they are hacking around the # modulepath, so these tests will not catch issues that may eventually arise # related to loading these plugins. # I could not, for the life of me, figure out how to programmatically set the modulepathprovider_class = Puppet::Type.type(:manila_config).provider(:openstackconfig) {:name => 'DEFAULT/foo', :value => 'bar'} {:name => 'dude/foo', :value => 'bar'}"," provider_class = Puppet::Type.type(:manila_config).provider(:ini_setting) { :name => 'DEFAULT/foo', :value => 'bar' } { :name => 'dude/foo', :value => 'bar' }",30,26
openstack%2Fmanila-tempest-plugin~master~I79ef199c5fe8b3aa37a3932d5dd48b54dd9b7a36,openstack/manila-tempest-plugin,master,I79ef199c5fe8b3aa37a3932d5dd48b54dd9b7a36,Add dummy dhss job to stable/zed,NEW,2023-01-25 19:31:54.000000000,2023-01-26 18:55:43.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 19:31:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/3b4909700a779a97b2365f1c6c97174760ae3674', 'message': ""Add dummy dhss job to stable/zed\n\nWe currently have tests being run on stable branches for every\nchange we propose on manila-tempest-plugin. That has helped us to\nprevent bugs and to see how changes are behaving with the older\nbranches.\n\nWe have jobs using the LVM driver, which is great, and provides us\na good API coverage but more importantly good scenario tests\ncoverage. However, the LVM driver has limitations while testing and\ncan not run a lot of the most recent features implemented in manila\ni.e. share replication, share server migration and few other.\n\nSo it's difficult to anticipate bugs coming in when changes are\nstill being proposed on the active branch, and we would catch bugs\nonly when code is already merged and we see that plugin code on the\nstable branches CI.\n\nSo we introduce a new dummy DHSS=True job to be run in every single\nchange proposed against manila-tempest-plugin and test such change\nin one stable branch. With that, we can cover more APIs and reduce\nthe risk of merging a change that will break tests on the older\nbranches.\n\nChange-Id: I79ef199c5fe8b3aa37a3932d5dd48b54dd9b7a36\n""}, {'number': 2, 'created': '2023-01-26 12:06:05.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/manila-tempest-stable-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/071b2b22f7dcb24bb3b7853e519f456eb9b877eb', 'message': ""Add dummy dhss job to stable/zed\n\nWe currently have tests being run on stable branches for every\nchange we propose on manila-tempest-plugin. That has helped us to\nprevent bugs and to see how changes are behaving with the older\nbranches.\n\nWe have jobs using the LVM driver, which is great, and provides us\na good API coverage but more importantly good scenario tests\ncoverage. However, the LVM driver has limitations while testing and\ncan not run a lot of the most recent features implemented in manila\ni.e. share replication, share server migration and few other.\n\nSo it's difficult to anticipate bugs coming in when changes are\nstill being proposed on the active branch, and we would catch bugs\nonly when code is already merged and we see that plugin code on the\nstable branches CI.\n\nSo we introduce a new dummy DHSS=True job to be run in every single\nchange proposed against manila-tempest-plugin and test such change\nin one stable branch. With that, we can cover more APIs and reduce\nthe risk of merging a change that will break tests on the older\nbranches.\n\nChange-Id: I79ef199c5fe8b3aa37a3932d5dd48b54dd9b7a36\n""}]",7,871779,071b2b22f7dcb24bb3b7853e519f456eb9b877eb,10,2,2,29632,,,0,"Add dummy dhss job to stable/zed

We currently have tests being run on stable branches for every
change we propose on manila-tempest-plugin. That has helped us to
prevent bugs and to see how changes are behaving with the older
branches.

We have jobs using the LVM driver, which is great, and provides us
a good API coverage but more importantly good scenario tests
coverage. However, the LVM driver has limitations while testing and
can not run a lot of the most recent features implemented in manila
i.e. share replication, share server migration and few other.

So it's difficult to anticipate bugs coming in when changes are
still being proposed on the active branch, and we would catch bugs
only when code is already merged and we see that plugin code on the
stable branches CI.

So we introduce a new dummy DHSS=True job to be run in every single
change proposed against manila-tempest-plugin and test such change
in one stable branch. With that, we can cover more APIs and reduce
the risk of merging a change that will break tests on the older
branches.

Change-Id: I79ef199c5fe8b3aa37a3932d5dd48b54dd9b7a36
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/79/871779/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/manila-tempest-stable-jobs.yaml']",2,3b4909700a779a97b2365f1c6c97174760ae3674,,- job: name: manila-tempest-plugin-dummy-dhss-zed parent: manila-tempest-plugin-dummy-dhss nodeset: openstack-single-node-focal override-checkout: stable/zed vars: *manila_tempest_image_pinned_vars ,,8,0
openstack%2Fpython-cinderclient~master~I7bf6bd91ee5746d1ad4bd4504f3a056d03ae86a9,openstack/python-cinderclient,master,I7bf6bd91ee5746d1ad4bd4504f3a056d03ae86a9,Move print operations to shell_utils,MERGED,2022-11-09 17:56:33.000000000,2023-01-26 18:14:29.000000000,2023-01-26 18:13:28.000000000,"[{'_account_id': 4523}, {'_account_id': 11904}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-09 17:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bc945fa9a461126f97511e5c4a0b2c8d7fbfcaed', 'message': 'Move print operations to shell_utils\n\nMove more code to shell_utils that is only used\nfor shell operations.\n\nThe benefit of this is that the cinderclient library\nbecomes lighter-weight, because users of the lib\nno longer have to import prettytable and extra code.\n\nChange-Id: I7bf6bd91ee5746d1ad4bd4504f3a056d03ae86a9\n'}, {'number': 2, 'created': '2022-11-15 15:23:25.000000000', 'files': ['cinderclient/v3/contrib/list_extensions.py', 'cinderclient/tests/unit/test_shell.py', 'cinderclient/v3/shell.py', 'cinderclient/shell_utils.py', 'cinderclient/tests/unit/test_utils.py', 'cinderclient/v3/shell_base.py', 'cinderclient/tests/unit/v3/test_shell.py', 'cinderclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2d7ae2cd38a2194f98b71d4d98c4273e9ad33e72', 'message': 'Move print operations to shell_utils\n\nMove more code to shell_utils that is only used\nfor shell operations.\n\nThe benefit of this is that the cinderclient library\nbecomes lighter-weight, because users of the lib\nno longer have to import prettytable and extra code.\n\nChange-Id: I7bf6bd91ee5746d1ad4bd4504f3a056d03ae86a9\n'}]",7,863305,2d7ae2cd38a2194f98b71d4d98c4273e9ad33e72,21,4,2,4523,,,0,"Move print operations to shell_utils

Move more code to shell_utils that is only used
for shell operations.

The benefit of this is that the cinderclient library
becomes lighter-weight, because users of the lib
no longer have to import prettytable and extra code.

Change-Id: I7bf6bd91ee5746d1ad4bd4504f3a056d03ae86a9
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/05/863305/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/unit/test_shell.py', 'cinderclient/v3/shell.py', 'cinderclient/shell_utils.py', 'cinderclient/tests/unit/test_utils.py', 'cinderclient/v3/shell_base.py', 'cinderclient/tests/unit/v3/test_shell.py', 'cinderclient/utils.py']",7,bc945fa9a461126f97511e5c4a0b2c8d7fbfcaed,,,"import prettytabledef _print(pt, order): print(pt.get_string(sortby=order)) def print_list(objs, fields, exclude_unavailable=False, formatters=None, sortby_index=0): '''Prints a list of objects. @param objs: Objects to print @param fields: Fields on each object to be printed @param exclude_unavailable: Boolean to decide if unavailable fields are removed @param formatters: Custom field formatters @param sortby_index: Results sorted against the key in the fields list at this index; if None then the object order is not altered ''' formatters = formatters or {} mixed_case_fields = ['serverId'] removed_fields = [] rows = [] for o in objs: row = [] for field in fields: if field in removed_fields: continue if field in formatters: row.append(formatters[field](o)) else: if field in mixed_case_fields: field_name = field.replace(' ', '_') else: field_name = field.lower().replace(' ', '_') if isinstance(o, dict) and field in o: data = o[field] else: if not hasattr(o, field_name) and exclude_unavailable: removed_fields.append(field) continue else: data = getattr(o, field_name, '') if data is None: data = '-' if isinstance(data, str) and ""\r"" in data: data = data.replace(""\r"", "" "") row.append(data) rows.append(row) for f in removed_fields: fields.remove(f) pt = prettytable.PrettyTable((f for f in fields), caching=False) pt.align = 'l' for row in rows: count = 0 # Converts unicode values in dictionary to string for part in row: count = count + 1 if isinstance(part, dict): row[count - 1] = part pt.add_row(row) if sortby_index is None: order_by = None else: order_by = fields[sortby_index] _print(pt, order_by) def _pretty_format_dict(data_dict): formatted_data = [] for k in sorted(data_dict): formatted_data.append(""%s : %s"" % (k, data_dict[k])) return ""\n"".join(formatted_data) def print_dict(d, property=""Property"", formatters=None): pt = prettytable.PrettyTable([property, 'Value'], caching=False) pt.align = 'l' formatters = formatters or {} for r in d.items(): r = list(r) if r[0] in formatters: if isinstance(r[1], dict): r[1] = _pretty_format_dict(r[1]) if isinstance(r[1], str) and ""\r"" in r[1]: r[1] = r[1].replace(""\r"", "" "") pt.add_row(r) _print(pt, property) ",199,197
openstack%2Fironic~bugfix%2F18.1~I550dac9d055ec30ec11530f18a675cf9e16063b5,openstack/ironic,bugfix/18.1,I550dac9d055ec30ec11530f18a675cf9e16063b5,Fix selinux context of published image hardlink,MERGED,2023-01-19 09:31:35.000000000,2023-01-26 18:02:35.000000000,2023-01-26 18:01:16.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-19 09:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ea5d219db792b8cb36d18c1523ccfe5d2f04f2e9', 'message': 'Fix selinux context of published image hardlink\n\nIf the published image is a hardlink, the source selinux context is\npreserved. This could cause access denied when retrieving the image\nusing its URL.\n\nChange-Id: I550dac9d055ec30ec11530f18a675cf9e16063b5\n'}, {'number': 2, 'created': '2023-01-19 14:09:02.000000000', 'files': ['ironic/tests/unit/drivers/modules/test_image_utils.py', 'ironic/drivers/modules/image_utils.py', 'releasenotes/notes/fix-context-image-hardlink-16f452974abc7327.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/44fc637035ad5e25bc11cd2e8e6dd3a3e4add2ca', 'message': 'Fix selinux context of published image hardlink\n\nIf the published image is a hardlink, the source selinux context is\npreserved. This could cause access denied when retrieving the image\nusing its URL.\n\nChange-Id: I550dac9d055ec30ec11530f18a675cf9e16063b5\n'}]",0,871040,44fc637035ad5e25bc11cd2e8e6dd3a3e4add2ca,13,2,2,23851,,,0,"Fix selinux context of published image hardlink

If the published image is a hardlink, the source selinux context is
preserved. This could cause access denied when retrieving the image
using its URL.

Change-Id: I550dac9d055ec30ec11530f18a675cf9e16063b5
",git fetch https://review.opendev.org/openstack/ironic refs/changes/40/871040/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/test_image_utils.py', 'ironic/drivers/modules/image_utils.py', 'releasenotes/notes/fix-context-image-hardlink-16f452974abc7327.yaml']",3,ea5d219db792b8cb36d18c1523ccfe5d2f04f2e9,fix-selinux-context,"--- fixes: - | Fixes an issue where if selinux is enabled and enforcing, and the published image is a hardlink, the source selinux context is preserved, causing access denied when retrieving the image using hardlink URL. ",,74,8
openstack%2Fsushy~stable%2Fwallaby~Ia421ff025f1f0bc72252b5441589beb2e53cc25a,openstack/sushy,stable/wallaby,Ia421ff025f1f0bc72252b5441589beb2e53cc25a,Fix volume deletion on newer iDRACs,MERGED,2023-01-12 12:34:07.000000000,2023-01-26 17:44:19.000000000,2023-01-26 17:43:17.000000000,"[{'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-12 12:34:07.000000000', 'files': ['releasenotes/notes/fix-volume-delete-configuration-unsuported-operational_time_property-f53f650d8612a847.yaml', 'sushy/resources/system/storage/volume.py', 'sushy/tests/unit/resources/system/storage/test_volume.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/0ed4f93a36a890517cf0efa96fa1e595c14ad34f', 'message': ""Fix volume deletion on newer iDRACs\n\nFixes 'Unsupported parameter name @Redfish.OperationApplyTime' General\nerror on iDRAC firmware version 6.00.02.00 or newer when deleting\nvolumes.\nHandles the failure of volume.delete by retrying without operation\napply time. In older iDRAC firmware versions operation apply time was\nsilently ignored, but now in newer iDRAC firmware versions it is\nreturning 501 Not Implemented error.\n\nChange-Id: Ia421ff025f1f0bc72252b5441589beb2e53cc25a\n(cherry picked from commit 74f95b1dd511cbbf36b0e85a596212d96047e345)\n""}]",1,869934,0ed4f93a36a890517cf0efa96fa1e595c14ad34f,11,4,1,33244,,,0,"Fix volume deletion on newer iDRACs

Fixes 'Unsupported parameter name @Redfish.OperationApplyTime' General
error on iDRAC firmware version 6.00.02.00 or newer when deleting
volumes.
Handles the failure of volume.delete by retrying without operation
apply time. In older iDRAC firmware versions operation apply time was
silently ignored, but now in newer iDRAC firmware versions it is
returning 501 Not Implemented error.

Change-Id: Ia421ff025f1f0bc72252b5441589beb2e53cc25a
(cherry picked from commit 74f95b1dd511cbbf36b0e85a596212d96047e345)
",git fetch https://review.opendev.org/openstack/sushy refs/changes/34/869934/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-volume-delete-configuration-unsuported-operational_time_property-f53f650d8612a847.yaml', 'sushy/resources/system/storage/volume.py', 'sushy/tests/unit/resources/system/storage/test_volume.py']",3,0ed4f93a36a890517cf0efa96fa1e595c14ad34f,," @mock.patch.object(volume.LOG, 'debug', autospec=True) def test_delete_retry_on_501_sys029_apply_time(self, mock_debug): payload = {} oat_prop = '@Redfish.OperationApplyTime' payload[oat_prop] = 'Immediate' target_uri = '/redfish/v1/Systems/437XR1138R2/Storage/1/Volumes/1' response_info = {""error"": {""@Message.ExtendedInfo"": [ {'Message': '@Redfish.OperationApplyTime.', 'MessageId': 'IDRAC.2.7.SYS029'}]}} mock_error = mock.Mock() mock_error.status_code = 501 mock_error.json.return_value = response_info mock_success = mock.Mock() mock_success.status_code = 201 self.conn.delete.side_effect = [exceptions.ServerSideError( method='DELETE', url=target_uri, response=mock_error), mock_success] resource = self.stor_volume.delete( payload=payload, apply_time=res_cons.APPLY_TIME_IMMEDIATE) self.assertIsNone(resource) self.assertEqual(2, self.stor_volume._conn.delete.call_count) expected_calls = [ mock.call(self.stor_volume._path, data=payload, blocking=True, timeout=500), mock.call(self.stor_volume._path, data={}, blocking=True, timeout=500) ] self.stor_volume._conn.delete.assert_has_calls(expected_calls) mock_debug.assert_called_once() @mock.patch.object(volume.LOG, 'debug', autospec=True) def test_delete_retry_on_501_sys029_other(self, mock_debug): payload = {} oat_prop = '@Redfish.OperationApplyTime' payload[oat_prop] = 'Immediate' target_uri = '/redfish/v1/Systems/437XR1138R2/Storage/1/Volumes/1' response_info = {""error"": {""@Message.ExtendedInfo"": [ {'Message': '@Redfish.SomethingElse.', 'MessageId': 'IDRAC.2.7.SYS029'}]}} mock_error = mock.Mock() mock_error.status_code = 501 mock_error.json.return_value = response_info mock_success = mock.Mock() mock_success.status_code = 201 self.conn.delete.side_effect = [exceptions.ServerSideError( method='DELETE', url=target_uri, response=mock_error), mock_success] self.assertRaises(exceptions.ServerSideError, self.stor_volume.delete, payload=payload, apply_time=res_cons.APPLY_TIME_IMMEDIATE) self.stor_volume._conn.delete.assert_called_once_with( self.stor_volume._path, data=payload, blocking=True, timeout=500) mock_debug.assert_not_called() @mock.patch.object(volume.LOG, 'debug', autospec=True) def test_delete_raise_on_501_other(self, mock_debug): payload = {} _OAT_PROP = '@Redfish.OperationApplyTime' payload[_OAT_PROP] = 'Immediate' target_uri = '/redfish/v1/Systems/437XR1138R2/Storage/1/Volumes/1' response_info = {""error"": {""@Message.ExtendedInfo"": [ {'Message': 'Other message.'}]}} mock_error = mock.Mock() mock_error.status_code = 501 mock_error.json.return_value = response_info self.conn.delete.side_effect = [exceptions.ServerSideError( method='DELETE', url=target_uri, response=mock_error)] self.assertRaises(exceptions.ServerSideError, self.stor_volume.delete, payload=payload, apply_time=res_cons.APPLY_TIME_IMMEDIATE) self.stor_volume._conn.delete.assert_called_once_with( self.stor_volume._path, data=payload, blocking=True, timeout=500) mock_debug.assert_not_called() ",,98,2
openstack%2Fheat~stable%2Fzed~Ie12c2df93f846629a7c8b7c6415cebc31eaba1bc,openstack/heat,stable/zed,Ie12c2df93f846629a7c8b7c6415cebc31eaba1bc,Decode UTF-8 body data in SwiftSignal,MERGED,2023-01-19 12:57:15.000000000,2023-01-26 17:19:49.000000000,2023-01-26 17:18:39.000000000,"[{'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-19 12:57:15.000000000', 'files': ['heat/engine/resources/openstack/heat/swiftsignal.py', 'heat/tests/openstack/heat/test_swiftsignal.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6343b64e703221402f0d40fc0e62da944551e2dd', 'message': 'Decode UTF-8 body data in SwiftSignal\n\nChange-Id: Ie12c2df93f846629a7c8b7c6415cebc31eaba1bc\nStory: #2010485\nTask: 47053\n(cherry picked from commit a0ff4b98b700c7f31a9f14d3d62eeaf3b2047139)\n'}]",3,871047,6343b64e703221402f0d40fc0e62da944551e2dd,17,3,1,14567,,,0,"Decode UTF-8 body data in SwiftSignal

Change-Id: Ie12c2df93f846629a7c8b7c6415cebc31eaba1bc
Story: #2010485
Task: 47053
(cherry picked from commit a0ff4b98b700c7f31a9f14d3d62eeaf3b2047139)
",git fetch https://review.opendev.org/openstack/heat refs/changes/47/871047/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/heat/swiftsignal.py', 'heat/tests/openstack/heat/test_swiftsignal.py']",2,6343b64e703221402f0d40fc0e62da944551e2dd,," mock_swift_object.get_object.return_value = (obj_header, b'{""id"": ""1""}') mock_swift_object.get_object.return_value = (obj_header, b'') (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 2}).encode()), (obj_header, json.dumps({'id': 3}).encode()), body = json.dumps({'id': 1}).encode() mock_swift_object.get_object.return_value = (obj_header, body) (obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""}).encode()), (obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""}).encode()), (obj_header, json.dumps({'id': 2, 'status': ""SUCCESS""}).encode()), 'reason': ""foo""}).encode()), 'reason': ""bar""}).encode()), 'reason': ""foo""}).encode()), 'reason': ""bar""}).encode()), (obj_header, json.dumps({'id': 1, 'data': ""foo""}).encode()), (obj_header, json.dumps({'id': 2, 'data': ""bar""}).encode()), (obj_header, json.dumps({'id': 3, 'data': ""baz""}).encode()), (obj_header, json.dumps({'id': 1, 'data': ""foo""}).encode()), (obj_header, json.dumps({'id': 2, 'data': ""bar""}).encode()), (obj_header, json.dumps({'id': 3, 'data': ""baz""}).encode()), 'status': ""SUCCESS""}).encode()), 'status': ""SUCCESS""}).encode()), 'status': ""SUCCESS""}).encode()), 'status': ""SUCCESS""}).encode()), (obj_header, b''), (obj_header, b''), (obj_header, b''), (obj_header, b''), obj_header, json.dumps({'status': 'SUCCESS'}).encode()) mock_swift_object.get_object.return_value = (obj_header, b'') obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""}).encode()) obj_header, json.dumps({'id': 1, 'status': ""FAILURE""}).encode()) (obj_header, b''), (obj_header, b''), (obj_header, b''), (obj_header, b''), (obj_header, b''), (obj_header, b''), (obj_header, b'{""status"": ""SUCCESS""'), (obj_header, b'{""status"": ""FAI'), obj_header, b'{""status"": ""BOO""}') # Objects there during create (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 2}).encode()), (obj_header, json.dumps({'id': 3}).encode()), (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 2}).encode()), # Objects there during create (obj_header, json.dumps({'id': 1}).encode()), (obj_header, json.dumps({'id': 2}).encode()), (obj_header, json.dumps({'id': 3}).encode()), (obj_header, b'{""id"": 1}'), (obj_header, b'{""id"": 2}'),"," mock_swift_object.get_object.return_value = (obj_header, '{""id"": ""1""}') mock_swift_object.get_object.return_value = (obj_header, '') (obj_header, json.dumps({'id': 1})), (obj_header, json.dumps({'id': 1})), (obj_header, json.dumps({'id': 1})), (obj_header, json.dumps({'id': 1})), (obj_header, json.dumps({'id': 2})), (obj_header, json.dumps({'id': 3})), mock_swift_object.get_object.return_value = (obj_header, json.dumps({'id': 1})) (obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""})), (obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""})), (obj_header, json.dumps({'id': 2, 'status': ""SUCCESS""})), 'reason': ""foo""})), 'reason': ""bar""})), 'reason': ""foo""})), 'reason': ""bar""})), (obj_header, json.dumps({'id': 1, 'data': ""foo""})), (obj_header, json.dumps({'id': 2, 'data': ""bar""})), (obj_header, json.dumps({'id': 3, 'data': ""baz""})), (obj_header, json.dumps({'id': 1, 'data': ""foo""})), (obj_header, json.dumps({'id': 2, 'data': ""bar""})), (obj_header, json.dumps({'id': 3, 'data': ""baz""})), 'status': ""SUCCESS""})), 'status': ""SUCCESS""})), 'status': ""SUCCESS""})), 'status': ""SUCCESS""})), (obj_header, ''), (obj_header, ''), (obj_header, ''), (obj_header, ''), obj_header, json.dumps({'status': 'SUCCESS'})) mock_swift_object.get_object.return_value = (obj_header, '') obj_header, json.dumps({'id': 1, 'status': ""SUCCESS""})) obj_header, json.dumps({'id': 1, 'status': ""FAILURE""})) (obj_header, ''), (obj_header, ''), (obj_header, ''), (obj_header, ''), (obj_header, ''), (obj_header, ''), (obj_header, '{""status"": ""SUCCESS""'), (obj_header, '{""status"": ""FAI'), obj_header, '{""status"": ""BOO""}') (obj_header, json.dumps({'id': 1})), # Objects there during create (obj_header, json.dumps({'id': 2})), (obj_header, json.dumps({'id': 3})), (obj_header, json.dumps({'id': 1})), (obj_header, json.dumps({'id': 2})), (obj_header, json.dumps({'id': 1})), # Objects there during create (obj_header, json.dumps({'id': 2})), (obj_header, json.dumps({'id': 3})), (obj_header, '{""id"": 1}'), (obj_header, '{""id"": 2}'),",59,54
openstack%2Fnova~master~I8ef9db851b37c5249d2efbe09a15a1ddbae8205d,openstack/nova,master,I8ef9db851b37c5249d2efbe09a15a1ddbae8205d,libvirt: At start-up rework compareCPU() usage with a workaround,MERGED,2023-01-17 11:19:55.000000000,2023-01-26 17:01:24.000000000,2023-01-26 13:48:02.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 11:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/455186e679b456806b75ba7f74179b53c7a9c0b8', 'message': ""libvirt: At start-up skip compareCPU() with a workaround\n\nThis will skip libvirt's compareCPU() call in\n_check_cpu_compatibility() and libvirt handle it more correctly.\n\n(QEMU >=2.9 and libvirt >= 4.4.0 are the mininum required versions, and\nupstream Nova satisfies them by a good margin.)\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n""}, {'number': 2, 'created': '2023-01-17 14:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fa4104e56b7f0b723f7f9a9a86456a6bbdc56b85', 'message': 'libvirt: At start-up skip compareCPU() with a workaround\n\nThis workaround will skip libvirt\'s compareCPU() call in\n_check_cpu_compatibility() and allow libvirt to handle it more\ncorrectly.  This will avoid certain classes of bugs.  (QEMU >=2.9 and\nlibvirt >= 4.4.0 are the mininum required versions, and upstream Nova\nsatisfies them by a good margin.)\n\nIn the ""near future"", we should remove this check altogether.  But\nbefore we bake that in, let\'s put this in a workaround to reduce\nunintended impact elsewhere.  Further we should also introduce the usage\nof replacing the older libvirt CPU API with the newer one[1].\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 3, 'created': '2023-01-17 15:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6885b0ac7edef66b9dd35b6dec32971f94a7adaf', 'message': 'libvirt: At start-up allow skiping compareCPU() with a workaround\n\nThis workaround will skip libvirt\'s compareCPU() call in\n_check_cpu_compatibility() and allow libvirt to handle it more\ncorrectly.  This will avoid certain classes of bugs.  (QEMU >=2.9 and\nlibvirt >= 4.4.0 are the mininum required versions, and upstream Nova\nsatisfies them by a good margin.)\n\nIn the ""near future"", we should remove this check altogether.  But\nbefore we bake that in, let\'s put this in a workaround to reduce\nunintended impact elsewhere.  Further we should also introduce the usage\nof replacing the older libvirt CPU API with the newer one[1].\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 4, 'created': '2023-01-18 16:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc6a865dcbf2aa72060fc71c0caec28950a3cb88', 'message': 'libvirt: At start-up allow skiping compareCPU() with a workaround\n\nThis workaround allows to skip the *first* call to libvirt\'s\ncompareCPU() in _check_cpu_compatibility() and lets libvirt handle it\nmore correctly.  This is because the first call does not evaluate the\nextra CPU flags provided by the user into account.  This will avoid\ncertain classes of bugs.  (QEMU >=2.9 and libvirt >= 4.4.0 are the\nmininum required versions, and upstream Nova satisfies them by a good\nmargin.)\n\nIn the ""near future"", we should consider removing this compareCPU() call\n(and subsequent calls elsewhere) altogether.  This workaround is a small\ntesting ground before we bake that in.\n\nAs a follow up, we should proceed with the patch[1] that replaces the\nolder libvirt CPU API with the newer one[1].\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 5, 'created': '2023-01-18 16:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59b9d151eb266f7f5eaaabee3282a8f33eeb0a59', 'message': 'libvirt: At start-up allow skiping compareCPU() with a workaround\n\nThis workaround allows to skip the *first* call to libvirt\'s\ncompareCPU() in _check_cpu_compatibility() and lets libvirt handle it\nmore correctly.  This is because the first call does not evaluate the\nextra CPU flags provided by the user into account.  This will avoid\ncertain classes of bugs.  (QEMU >=2.9 and libvirt >= 4.4.0 are the\nmininum required versions, and upstream Nova satisfies them by a good\nmargin.)\n\nIn the ""near future"", we should consider removing this compareCPU() call\n(and subsequent calls elsewhere) altogether.  This workaround is a small\ntesting ground before we bake that in.\n\nAs a follow up, we should proceed with the patch[1] that replaces the\nolder libvirt CPU API with the newer one[1].\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 6, 'created': '2023-01-19 12:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6fe080c7fb00e3ebfb96f2e60bc3e11ecfea853a', 'message': 'libvirt: At start-up allow skiping compareCPU() with a workaround\n\nThis workaround allows to skip the *first* call to libvirt\'s\ncompareCPU() in _check_cpu_compatibility() and lets libvirt handle it\nmore correctly.  This is because the first call does not evaluate the\nextra CPU flags provided by the user into account.  This will avoid\ncertain classes of bugs.  (QEMU >=2.9 and libvirt >= 4.4.0 are the\nmininum required versions, and upstream Nova satisfies them by a good\nmargin.)\n\nIn the ""near future"", we should consider removing this compareCPU() call\n(and subsequent calls elsewhere) altogether.  This workaround is a small\ntesting ground before we bake that in.\n\nAs a follow up, we should proceed with the patch[1] that replaces the\nolder libvirt CPU API with the newer one[1].\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 7, 'created': '2023-01-20 11:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd0eccfff4f1ae30c67e8bbd06c798d152267c36', 'message': 'libvirt: At start-up rework compareCPU() usage with a workaround\n\nIn this patch:\n\n  - Remove the first compareCPU() call (called via the wrapper\n    _compare_cpu()) in _check_cpu_compatibility(), and let libvirt\n    handle it.  (QEMU >=2.9 and libvirt >= 4.4.0 are the mininum\n    required versions, and upstream Nova satisfies them by a good\n    margin.)\n\n  - Add a workaround to allow skipping the remaining compareCPU() call\n    in _check_cpu_compatibility() as a potential future-proof (because\n    we cannot test all possible CPU models and hardware).  Unlike the\n    removed first call, this call takes into account the extra CPU flags\n    provided by the user into account when evaluating guest CPU model\n    compatibility.\n\nAs a follow up comes the patch[1] that replaces the older libvirt CPU\nAPI with the newer one.\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 8, 'created': '2023-01-20 15:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01389198cdedf66dc2de0e30831c58f0d8098c7d', 'message': 'libvirt: At start-up rework compareCPU() usage with a workaround\n\nIn this patch:\n\n  - Remove the first compareCPU() call (called via the wrapper\n    _compare_cpu()) in _check_cpu_compatibility(), and let libvirt\n    handle it.  (QEMU >=2.9 and libvirt >= 4.4.0 are the mininum\n    required versions, and upstream Nova satisfies them by a good\n    margin.)\n\n  - Add a workaround to allow skipping the remaining compareCPU() call\n    in _check_cpu_compatibility() as a potential future-proof (because\n    we cannot test all possible CPU models and hardware).  Unlike the\n    removed first call, this call takes into account the extra CPU flags\n    provided by the user into account when evaluating guest CPU model\n    compatibility.\n\nAs a follow up comes the patch[1] that replaces the older libvirt CPU\nAPI with the newer one.\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 9, 'created': '2023-01-23 14:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/93847aaf3a5bb64bf3d15423432fd3d9b80e80c3', 'message': 'libvirt: At start-up rework compareCPU() usage with a workaround\n\nIn this patch:\n\n  - Remove the first compareCPU() call (called via the wrapper\n    _compare_cpu()) in _check_cpu_compatibility(), and let libvirt\n    handle it.  (QEMU >=2.9 and libvirt >= 4.4.0 are the mininum\n    required versions, and upstream Nova satisfies them by a good\n    margin.)\n\n  - Validate the user-configured CPU models from\n    _get_cpu_model_mapping().  And take into account all the CPU flags\n    before calling _compare_cpu().\n\n    (Suggested-by: Sean Mooney -- thanks!)\n\n  - Add a workaround to allow skipping the remaining compareCPU() call\n    in _check_cpu_compatibility() as a potential future-proof (because\n    we cannot test all possible CPU models and hardware).  Unlike the\n    removed first call, this call takes into account the extra CPU flags\n    provided by the user into account when evaluating guest CPU model\n    compatibility.\n\nAs a follow up comes the patch[1] that replaces the older libvirt CPU\nAPI with the newer one.\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}, {'number': 10, 'created': '2023-01-24 10:28:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9caaaf1f221063a4329c72c8b67a6015648644a2', 'message': 'libvirt: At start-up rework compareCPU() usage with a workaround\n\nIn this patch:\n\n  - Remove the first compareCPU() call (called via the wrapper\n    _compare_cpu()) in _check_cpu_compatibility(), and let libvirt\n    handle it.  (QEMU >=2.9 and libvirt >= 4.4.0 are the mininum\n    required versions, and upstream Nova satisfies them by a good\n    margin.)\n\n  - Validate the user-configured CPU models from\n    _get_cpu_model_mapping().  And take into account all the CPU flags\n    before calling _compare_cpu().\n\n    (Suggested-by: Sean Mooney -- thanks!)\n\n  - Add a workaround to allow skipping the remaining compareCPU() call\n    in _check_cpu_compatibility() as a potential future-proof (because\n    we cannot test all possible CPU models and hardware).  Unlike the\n    removed first call, this call takes into account the extra CPU flags\n    provided by the user into account when evaluating guest CPU model\n    compatibility.\n\nAs a follow up comes the patch[1] that replaces the older libvirt CPU\nAPI with the newer one.\n\n[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:\n    Replace usage of compareCPU() with compareHypervisorCPU()\n\nChange-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d\nSigned-off-by: Kashyap Chamarthy <kchamart@redhat.com>\n'}]",39,870794,9caaaf1f221063a4329c72c8b67a6015648644a2,69,4,10,6962,,,0,"libvirt: At start-up rework compareCPU() usage with a workaround

In this patch:

  - Remove the first compareCPU() call (called via the wrapper
    _compare_cpu()) in _check_cpu_compatibility(), and let libvirt
    handle it.  (QEMU >=2.9 and libvirt >= 4.4.0 are the mininum
    required versions, and upstream Nova satisfies them by a good
    margin.)

  - Validate the user-configured CPU models from
    _get_cpu_model_mapping().  And take into account all the CPU flags
    before calling _compare_cpu().

    (Suggested-by: Sean Mooney -- thanks!)

  - Add a workaround to allow skipping the remaining compareCPU() call
    in _check_cpu_compatibility() as a potential future-proof (because
    we cannot test all possible CPU models and hardware).  Unlike the
    removed first call, this call takes into account the extra CPU flags
    provided by the user into account when evaluating guest CPU model
    compatibility.

As a follow up comes the patch[1] that replaces the older libvirt CPU
API with the newer one.

[1] https://review.opendev.org/c/openstack/nova/+/869950 -- libvirt:
    Replace usage of compareCPU() with compareHypervisorCPU()

Change-Id: I8ef9db851b37c5249d2efbe09a15a1ddbae8205d
Signed-off-by: Kashyap Chamarthy <kchamart@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/870794/10 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/conf/workarounds.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,455186e679b456806b75ba7f74179b53c7a9c0b8,fix_compareCPU_usage," @mock.patch('nova.virt.libvirt.host.libvirt.Connection.compareCPU') def test__check_cpu_compatibility_skip_first_compare_at_init(self): self.flags(group='workarounds', at_startup_skip_cpu_compare=True) self.flags(cpu_mode=""custom"", cpu_models=[""Icelake-Server-noTSX""], group=""libvirt"") drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) drvr.init_host(""dummyhost"") ",,28,11
openstack%2Fmanila-tempest-plugin~master~Ia679ab28d9fd9d79294e990c39cd4cd9631f1742,openstack/manila-tempest-plugin,master,Ia679ab28d9fd9d79294e990c39cd4cd9631f1742,Skip replication test if microversion is not supported,MERGED,2023-01-25 19:05:02.000000000,2023-01-26 16:58:13.000000000,2023-01-26 15:24:55.000000000,"[{'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-25 19:05:02.000000000', 'files': ['manila_tempest_tests/tests/api/test_replication_negative.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/54e31e8f5b517d2f1b350c091b29aa518f2c8739', 'message': 'Skip replication test if microversion is not supported\n\nWithout the skip, we break testing against old/stable branches.\n\nChange-Id: Ia679ab28d9fd9d79294e990c39cd4cd9631f1742\nSigned-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>\n'}]",3,871775,54e31e8f5b517d2f1b350c091b29aa518f2c8739,10,3,1,16643,,,0,"Skip replication test if microversion is not supported

Without the skip, we break testing against old/stable branches.

Change-Id: Ia679ab28d9fd9d79294e990c39cd4cd9631f1742
Signed-off-by: Goutham Pacha Ravi <gouthampravi@gmail.com>
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/75/871775/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/test_replication_negative.py'],1,54e31e8f5b517d2f1b350c091b29aa518f2c8739,," """"""From 2.74, we can add rules even if replicas are in error state."""""" utils.check_skip_if_microversion_not_supported(version)"," '''From 2.74, we can add rules even if replicas are in error state.'''",2,1
openstack%2Freleases~master~I186ed1ee6a6ae86556a4e1d8b5f2d4288ac20fb0,openstack/releases,master,I186ed1ee6a6ae86556a4e1d8b5f2d4288ac20fb0,[designate-tempest-plugin] Tag wallaby-last,MERGED,2022-12-26 04:25:36.000000000,2023-01-26 16:53:37.000000000,2023-01-26 15:06:52.000000000,"[{'_account_id': 11628}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-12-26 04:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b629abfb8558fd8204ecd2396fff34d86318f38c', 'message': ""[designate-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: I186ed1ee6a6ae86556a4e1d8b5f2d4288ac20fb0\n""}, {'number': 2, 'created': '2022-12-26 05:23:22.000000000', 'files': ['deliverables/antelope/designate-tempest-plugin.yaml', 'deliverables/wallaby/designate-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a97fd800ce95bef799618866a6c9139c287ad1ec', 'message': ""[designate-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: I186ed1ee6a6ae86556a4e1d8b5f2d4288ac20fb0\n""}]",6,868582,a97fd800ce95bef799618866a6c9139c287ad1ec,13,4,2,8556,,,0,"[designate-tempest-plugin] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' as well as a new version also with same hash.

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: I186ed1ee6a6ae86556a4e1d8b5f2d4288ac20fb0
",git fetch https://review.opendev.org/openstack/releases refs/changes/82/868582/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/designate-tempest-plugin.yaml', 'deliverables/wallaby/designate-tempest-plugin.yaml']",2,b629abfb8558fd8204ecd2396fff34d86318f38c,wallaby-last, - version: wallaby-last projects: - repo: openstack/designate-tempest-plugin hash: ff6c24db8461975b9409505f0dca89909ea410c9,,9,0
openstack%2Fironic-inspector~master~I4bec5dbb224c59048c24cf2189a80014d63bfa36,openstack/ironic-inspector,master,I4bec5dbb224c59048c24cf2189a80014d63bfa36,Stop gating on unit test coverage,MERGED,2023-01-26 15:18:33.000000000,2023-01-26 16:53:14.000000000,2023-01-26 16:51:50.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-26 15:18:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/20797f0a82f3211fa53ccbc82d8c6dbe07986e94', 'message': ""Stop gating on unit test coverage\n\nIt's nice to keep coverage high, but with little active development\nit starts merely hindering refactorings, causing us to gradually lower\nthe expected minimum anyway.\n\nChange-Id: I4bec5dbb224c59048c24cf2189a80014d63bfa36\n""}]",1,871827,20797f0a82f3211fa53ccbc82d8c6dbe07986e94,8,3,1,10239,,,0,"Stop gating on unit test coverage

It's nice to keep coverage high, but with little active development
it starts merely hindering refactorings, causing us to gradually lower
the expected minimum anyway.

Change-Id: I4bec5dbb224c59048c24cf2189a80014d63bfa36
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/27/871827/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,20797f0a82f3211fa53ccbc82d8c6dbe07986e94,gate, coverage report -m --omit='*test*', coverage report -m --omit='*test*' --fail-under 90,1,1
openstack%2Fironic~master~I2aea1d4fb59e7440586d8d9cd27bc61d29f4530c,openstack/ironic,master,I2aea1d4fb59e7440586d8d9cd27bc61d29f4530c,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 20:31:21.000000000,2023-01-26 16:53:14.000000000,2023-01-26 16:51:47.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-19 20:31:21.000000000', 'files': ['requirements.txt', 'ironic/common/rpc.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f8608dbd956224175de9844cd8500c6d06cc3dd5', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I2aea1d4fb59e7440586d8d9cd27bc61d29f4530c\n'}]",0,871160,f8608dbd956224175de9844cd8500c6d06cc3dd5,10,3,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I2aea1d4fb59e7440586d8d9cd27bc61d29f4530c
",git fetch https://review.opendev.org/openstack/ironic refs/changes/60/871160/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ironic/common/rpc.py']",2,f8608dbd956224175de9844cd8500c6d06cc3dd5,," return messaging.get_rpc_client( TRANSPORT, target, version_cap=version_cap, serializer=serializer)"," return messaging.RPCClient(TRANSPORT, target, version_cap=version_cap, serializer=serializer)",4,5
openstack%2Fironic~master~Ie24e959fdb338fafeafdf0e064eede273f2011f4,openstack/ironic,master,Ie24e959fdb338fafeafdf0e064eede273f2011f4,Clarify release docs: bugfix releases optional,MERGED,2023-01-23 21:01:45.000000000,2023-01-26 16:29:46.000000000,2023-01-26 16:28:00.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-23 21:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1c7000dea08bd1035344db70ebaf0d4e6c78b62a', 'message': 'Clarify release docs: bugfix releases optional\n\nBugfix releases are optional in practice; document that truth in\nour release documents.\n\nChange-Id: Ie24e959fdb338fafeafdf0e064eede273f2011f4\n'}, {'number': 2, 'created': '2023-01-23 21:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/be7722d1c788776d9c0e71f056dc9736de68adf6', 'message': 'Clarify release docs: bugfix releases optional\n\nBugfix releases are optional in practice; document that truth in\nour release documents.\n\nChange-Id: Ie24e959fdb338fafeafdf0e064eede273f2011f4\n'}, {'number': 3, 'created': '2023-01-24 16:13:34.000000000', 'files': ['doc/source/contributor/releasing.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/38777e5030d17320fa284fd30f7423e19c55d0ac', 'message': 'Clarify release docs: bugfix releases optional\n\nBugfix releases are optional in practice; document that truth in\nour release documents.\n\nChange-Id: Ie24e959fdb338fafeafdf0e064eede273f2011f4\n'}]",2,871537,38777e5030d17320fa284fd30f7423e19c55d0ac,15,4,3,10342,,,0,"Clarify release docs: bugfix releases optional

Bugfix releases are optional in practice; document that truth in
our release documents.

Change-Id: Ie24e959fdb338fafeafdf0e064eede273f2011f4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/37/871537/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/releasing.rst'],1,1c7000dea08bd1035344db70ebaf0d4e6c78b62a,,These projects recieve releases every six months as part of the coordinated OpenStack release that happens semi-annually. These releases can be found in a ``stable/NAME`` branch. They are also evaluated for additional bugfix releases between scheduled stable releases at the two and four month milestore between stable releases (roughly every 2 months). These releases can be found in a ``bugfix/X.Y`` branch. A bugfix release is only created if there are significant beneficial changes and a known downstream operator or distributor will consume the release.Currently releases and retirements from bugfix branches cannot be automated and must be done by the release team manually.,"They are also released on a regular cadence as opposed to on-demand, namely three times a release cycle (roughly a release every 2 months). One of the releases corresponds to the coordinated OpenStack released and receives a ``stable/NAME`` branch. The other two happen during the cycle and receive a ``bugfix/X.Y`` branch, where ``X.Y`` consists of the major and the minor component of the version (e.g. ``bugfix/8.1`` for 8.1.0).Currently releases from bugfix branches cannot be automated and must be done by the release team manually.",12,8
openstack%2Fironic-inspector~master~I66bef4d339b5ee2462dc46f626fd1b2c6182b2cd,openstack/ironic-inspector,master,I66bef4d339b5ee2462dc46f626fd1b2c6182b2cd,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 21:05:02.000000000,2023-01-26 16:29:14.000000000,2023-01-26 16:27:58.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-19 21:05:02.000000000', 'files': ['requirements.txt', 'ironic_inspector/common/rpc.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/84b5f8cc1b5c97b3d4cf8679e57dd20f2ce9663f', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I66bef4d339b5ee2462dc46f626fd1b2c6182b2cd\n'}]",0,871183,84b5f8cc1b5c97b3d4cf8679e57dd20f2ce9663f,8,3,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I66bef4d339b5ee2462dc46f626fd1b2c6182b2cd
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/83/871183/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'ironic_inspector/common/rpc.py']",2,84b5f8cc1b5c97b3d4cf8679e57dd20f2ce9663f,," return messaging.get_rpc_client(TRANSPORT, target)"," return messaging.RPCClient(TRANSPORT, target)",2,2
openstack%2Fironic-python-agent~master~If082b921d4bf71c4cc41a5a72db6995b08637374,openstack/ironic-python-agent,master,If082b921d4bf71c4cc41a5a72db6995b08637374,Make logs collection a hardware manager call,MERGED,2023-01-25 12:34:21.000000000,2023-01-26 16:28:00.000000000,2023-01-26 16:26:42.000000000,"[{'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-25 12:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/a76cde6e70bd74cf156cd616d57f098814853b8c', 'message': '[WIP] Make logs collection a hardware manager call\n\nChange-Id: If082b921d4bf71c4cc41a5a72db6995b08637374\n'}, {'number': 2, 'created': '2023-01-25 14:17:37.000000000', 'files': ['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_hardware.py', 'releasenotes/notes/collect-manager-a80bcf370048eeec.yaml', 'ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/c26f498f49d506debb5fc62eadb6c0f97e4d7e6f', 'message': 'Make logs collection a hardware manager call\n\nThis allows hardware managers to collect additional logs.\n\nChange-Id: If082b921d4bf71c4cc41a5a72db6995b08637374\n'}]",2,871708,c26f498f49d506debb5fc62eadb6c0f97e4d7e6f,15,3,2,10239,,,0,"Make logs collection a hardware manager call

This allows hardware managers to collect additional logs.

Change-Id: If082b921d4bf71c4cc41a5a72db6995b08637374
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/08/871708/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/hardware.py', 'ironic_python_agent/tests/unit/test_utils.py', 'ironic_python_agent/utils.py']",3,a76cde6e70bd74cf156cd616d57f098814853b8c,collect-manager,"def try_collect_command_output(io_dict, file_name, command): LOG.debug('Collecting command output: %s', command) try: io_dict[file_name] = get_command_output(command) except errors.CommandExecutionError: LOG.debug('Collecting logs from command %s has failed', command) # Avoid circular imports from ironic_python_agent import hardware try: hardware.dispatch_to_all_managers('collect_system_logs', io_dict, file_list) except errors.HardwareManagerMethodNotFound: LOG.warning('All hardware managers failed to collect logs')","import pyudevCOLLECT_LOGS_COMMANDS = { 'ps': ['ps', 'au'], 'df': ['df', '-a'], 'iptables': ['iptables', '-L'], 'ip_addr': ['ip', 'addr'], 'lshw': ['lshw', '-quiet', '-json'], 'lsblk': ['lsblk', '--all', '-o%s' % ','.join(LSBLK_COLUMNS)], 'lsblk-full': ['lsblk', '--all', '--bytes', '--output-all', '--pairs'], 'mdstat': ['cat', '/proc/mdstat'], 'mount': ['mount'], 'parted': ['parted', '-l'], 'multipath': ['multipath', '-ll'], } def _collect_udev(io_dict): """"""Collect device properties from udev."""""" try: out, _e = ironic_utils.execute('lsblk', '-no', 'KNAME') except processutils.ProcessExecutionError as exc: LOG.warning('Could not list block devices: %s', exc) return context = pyudev.Context() for kname in out.splitlines(): kname = kname.strip() if not kname: continue name = os.path.join('/dev', kname) try: udev = pyudev.Devices.from_device_file(context, name) except Exception as e: LOG.warning(""Device %(dev)s is inaccessible, skipping... "" ""Error: %(error)s"", {'dev': name, 'error': e}) continue try: props = dict(udev.properties) except AttributeError: # pyudev < 0.20 props = dict(udev) fp = io.TextIOWrapper(io.BytesIO(), encoding='utf-8') json.dump(props, fp) buf = fp.detach() buf.seek(0) io_dict[f'udev/{kname}'] = buf def try_get_command_output(io_dict, file_name, command): try: io_dict[file_name] = get_command_output(command) except errors.CommandExecutionError: LOG.debug('Collecting logs from command %s has failed', command) try_get_command_output(io_dict, 'dmesg', ['dmesg']) for name, cmd in COLLECT_LOGS_COMMANDS.items(): try_get_command_output(io_dict, name, cmd) try: _collect_udev(io_dict) except Exception: LOG.exception('Unexpected error when collecting udev properties')",86,66
openstack%2Fansible-role-systemd_service~stable%2Fyoga~Ib456b4dc2d631bf81633035820444f13ec0f06cb,openstack/ansible-role-systemd_service,stable/yoga,Ib456b4dc2d631bf81633035820444f13ec0f06cb,Ensure daemon is reloaded on socket change,MERGED,2023-01-25 17:35:05.000000000,2023-01-26 15:54:03.000000000,2023-01-26 15:53:09.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-25 17:35:05.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/5c5813f88f651ee64e507458f39cb67ecaf640cc', 'message': ""Ensure daemon is reloaded on socket change\n\nAt the moment our verification if socket has been changed\nis not valid, since we're checking if string 'true' is presnet in the\nlist, while list consist of only boolean variables. So we replace\nmap filter with selectattr as it can apply truthy test to the elements\nwhile selecting them and checking list length.\n\nChange-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb\nRelated-Bug: #2003631\n(cherry picked from commit 6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2)\n""}]",1,871752,5c5813f88f651ee64e507458f39cb67ecaf640cc,12,3,1,28619,,,0,"Ensure daemon is reloaded on socket change

At the moment our verification if socket has been changed
is not valid, since we're checking if string 'true' is presnet in the
list, while list consist of only boolean variables. So we replace
map filter with selectattr as it can apply truthy test to the elements
while selecting them and checking list length.

Change-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb
Related-Bug: #2003631
(cherry picked from commit 6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2)
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/52/871752/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,5c5813f88f651ee64e507458f39cb67ecaf640cc,," - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or (systemd_socket.results | selectattr('changed', 'true') | length > 0)", - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or ('true' in systemd_socket.results | map(attribute='changed') | list ),1,1
openstack%2Fkolla~stable%2Fzed~I717b4f2215054ef9135a1ac252ed26820bdcb1aa,openstack/kolla,stable/zed,I717b4f2215054ef9135a1ac252ed26820bdcb1aa,Add util-linux to centos base packages,MERGED,2023-01-26 11:26:06.000000000,2023-01-26 15:53:38.000000000,2023-01-26 15:52:39.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}]","[{'number': 1, 'created': '2023-01-26 11:26:06.000000000', 'files': ['docker/base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/055cbf6876216d63f3f3cb8f3460d2409f9855d5', 'message': 'Add util-linux to centos base packages\n\nCurrently /usr/sbin/nologin is missing, because util-linux\nis not installed in the image.\n\nChange-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa\n(cherry picked from commit 1371e4fc5b9d3d55f5bb48540753f740f1d1af02)\n'}]",0,871757,055cbf6876216d63f3f3cb8f3460d2409f9855d5,9,3,1,22629,,,0,"Add util-linux to centos base packages

Currently /usr/sbin/nologin is missing, because util-linux
is not installed in the image.

Change-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa
(cherry picked from commit 1371e4fc5b9d3d55f5bb48540753f740f1d1af02)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/57/871757/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/Dockerfile.j2'],1,055cbf6876216d63f3f3cb8f3460d2409f9855d5,," 'util-linux',{# NOTE(SamYaple): Avoid uid/gid conflicts by creating each user/group up front. #} {# Specifics required such as homedir or shell are configured within the service specific image #} {%- for name, user in users | dictsort() %} {% if loop.first -%}RUN {% else %} && {% endif -%} groupadd --gid {{ user.gid }} {{ user.group }} \ && useradd -l -M --shell /usr/sbin/nologin --uid {{ user.uid }} --gid {{ user.gid }} {{ name }} {%- if not loop.last %} \{% endif -%} {%- endfor %} ","{# NOTE(SamYaple): Avoid uid/gid conflicts by creating each user/group up front. #} {# Specifics required such as homedir or shell are configured within the service specific image #} {%- for name, user in users | dictsort() %} {% if loop.first -%}RUN {% else %} && {% endif -%} groupadd --gid {{ user.gid }} {{ user.group }} \ && useradd -l -M --shell /usr/sbin/nologin --uid {{ user.uid }} --gid {{ user.gid }} {{ name }} {%- if not loop.last %} \{% endif -%} {%- endfor %} ",10,9
openstack%2Fansible-role-zookeeper~stable%2Fzed~I7017bb4c2eea855464989bf10d7984e130cad4b3,openstack/ansible-role-zookeeper,stable/zed,I7017bb4c2eea855464989bf10d7984e130cad4b3,Add configuration option for native Prometheus exporter,MERGED,2023-01-25 20:13:26.000000000,2023-01-26 15:29:55.000000000,2023-01-26 15:28:56.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-01-25 20:13:26.000000000', 'files': ['templates/zoo.cfg.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-zookeeper/commit/18ec82051494d2fe5c7d1398a4096a57d7275ce6', 'message': 'Add configuration option for native Prometheus exporter\n\nZookeeper supports Prometheus metrics as documented in\nhttps://zookeeper.apache.org/doc/r3.8.0/zookeeperMonitor.html#Prometheus\n\nThis patch adds configuration options to enable it and change\nthe default port.\n\nChange-Id: I7017bb4c2eea855464989bf10d7984e130cad4b3\n(cherry picked from commit 1cd6ac5b4c5358be4fbdfd0f5bffa194274e94d7)\n'}]",1,871753,18ec82051494d2fe5c7d1398a4096a57d7275ce6,12,3,1,28619,,,0,"Add configuration option for native Prometheus exporter

Zookeeper supports Prometheus metrics as documented in
https://zookeeper.apache.org/doc/r3.8.0/zookeeperMonitor.html#Prometheus

This patch adds configuration options to enable it and change
the default port.

Change-Id: I7017bb4c2eea855464989bf10d7984e130cad4b3
(cherry picked from commit 1cd6ac5b4c5358be4fbdfd0f5bffa194274e94d7)
",git fetch https://review.opendev.org/openstack/ansible-role-zookeeper refs/changes/53/871753/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/zoo.cfg.j2', 'defaults/main.yml']",2,18ec82051494d2fe5c7d1398a4096a57d7275ce6,, zookeeper_prometheus_enable: False zookeeper_prometheus_port: 7000,,8,0
openstack%2Fovsdbapp~stable%2Fzed~I237136262862d5117d08eb3b513a0b8658a79f05,openstack/ovsdbapp,stable/zed,I237136262862d5117d08eb3b513a0b8658a79f05,Fix TRY_AGAIN handling,MERGED,2023-01-25 11:43:38.000000000,2023-01-26 15:12:12.000000000,2023-01-26 15:11:15.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 11:43:38.000000000', 'files': ['ovsdbapp/backend/ovs_idl/transaction.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/97e738dc2b81590120d76a9ec6ac521067a536b7', 'message': 'Fix TRY_AGAIN handling\n\nI believe removing wait_for_change back in the day was an error.\nWe can\'t do the exponential backoff ourselves because that will\nalso delay reconnecting to the the db, because idl.run() needs to\nbe called. Also, do_commit() doesn\'t ensure that idl.run() is\ncalled if status is TRY_AGAIN. wait_for_change() will ensure that\nwe call idl.run() to reconnect quickly and don\'t try the txn again\nuntil we have reconnected and the seqno has changed.\n\nRevert ""Don\'t spam retries 100s of times a second""\nThis reverts commit 6596164f51217cc7fabf302ce14ccc9d9beaff1f.\n\nRevert ""Ensure idl.run() called on TRY_AGAIN""\nThis reverts commit 1810faecc9ad2345f3e2f9185ac64194c5a0d711.\n\nRevert ""Don\'t wait on TRY_AGAIN when calling commit_block()""\nThis reverts commit 158ae06bce0f56e93677f94c59f81e5e76ee1ccc.\n\nCloses-Bug: #1988457\nChange-Id: I237136262862d5117d08eb3b513a0b8658a79f05\n(cherry picked from commit c3bacb3ba37e2824920ac79766205a3b51ab12d5)\n'}]",5,871563,97e738dc2b81590120d76a9ec6ac521067a536b7,12,5,1,13861,,,0,"Fix TRY_AGAIN handling

I believe removing wait_for_change back in the day was an error.
We can't do the exponential backoff ourselves because that will
also delay reconnecting to the the db, because idl.run() needs to
be called. Also, do_commit() doesn't ensure that idl.run() is
called if status is TRY_AGAIN. wait_for_change() will ensure that
we call idl.run() to reconnect quickly and don't try the txn again
until we have reconnected and the seqno has changed.

Revert ""Don't spam retries 100s of times a second""
This reverts commit 6596164f51217cc7fabf302ce14ccc9d9beaff1f.

Revert ""Ensure idl.run() called on TRY_AGAIN""
This reverts commit 1810faecc9ad2345f3e2f9185ac64194c5a0d711.

Revert ""Don't wait on TRY_AGAIN when calling commit_block()""
This reverts commit 158ae06bce0f56e93677f94c59f81e5e76ee1ccc.

Closes-Bug: #1988457
Change-Id: I237136262862d5117d08eb3b513a0b8658a79f05
(cherry picked from commit c3bacb3ba37e2824920ac79766205a3b51ab12d5)
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/63/871563/1 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/backend/ovs_idl/transaction.py'],1,97e738dc2b81590120d76a9ec6ac521067a536b7,," seqno = self.api.idl.change_seqno idlutils.wait_for_change(self.api.idl, self.time_remaining(), seqno)","MAX_SLEEP = 8 retries = 0 # In the case that there is a reconnection after # Connection.run() calls self.idl.run() but before do_commit() # is called, commit_block() can loop w/o calling idl.run() # which does the reconnect logic. It will then always return # TRY_AGAIN until we time out and Connection.run() calls # idl.run() again. So, call idl.run() here just in case. self.api.idl.run() # In the event that there is an issue with the txn or the db # is down, don't spam new txns as fast as we can time.sleep(min(2 ** retries, self.time_remaining(), MAX_SLEEP)) retries += 1 retries = 0",3,15
openstack%2Freleases~master~Ibe6993d95592fde1668569f32c19005bde990f71,openstack/releases,master,Ibe6993d95592fde1668569f32c19005bde990f71,[ironic-tempest-plugin] Tag wallaby-last,MERGED,2022-12-26 03:57:54.000000000,2023-01-26 15:06:55.000000000,2023-01-26 15:06:55.000000000,"[{'_account_id': 308}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 15519}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2022-12-26 03:57:54.000000000', 'files': ['deliverables/antelope/ironic-tempest-plugin.yaml', 'deliverables/wallaby/ironic-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/df7bd3f718771a5b2994fcdd14d0f98d2bccac29', 'message': ""[ironic-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: Ibe6993d95592fde1668569f32c19005bde990f71\n""}]",3,868578,df7bd3f718771a5b2994fcdd14d0f98d2bccac29,10,7,1,8556,,,0,"[ironic-tempest-plugin] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' as well as a new version also with same hash.

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: Ibe6993d95592fde1668569f32c19005bde990f71
",git fetch https://review.opendev.org/openstack/releases refs/changes/78/868578/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/ironic-tempest-plugin.yaml', 'deliverables/wallaby/ironic-tempest-plugin.yaml']",2,df7bd3f718771a5b2994fcdd14d0f98d2bccac29,wallaby-last, - version: wallaby-last projects: - repo: openstack/ironic-tempest-plugin hash: 4684f915b58d2c161295100802dec7076920451f,,9,0
openstack%2Fneutron~master~I55871eff1e37d4155b8d2b5ae8c182d160c4af9f,openstack/neutron,master,I55871eff1e37d4155b8d2b5ae8c182d160c4af9f,Add doc note on nf_conntrack module requirement,MERGED,2023-01-24 20:19:47.000000000,2023-01-26 14:49:34.000000000,2023-01-26 14:48:09.000000000,"[{'_account_id': 5948}, {'_account_id': 7730}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 20:19:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d03cc220ee910c408070efbe061c1ef6604d492b', 'message': 'Add doc note on nf_conntrack module requirement\n\nThe OVS firewall driver requires nf_conntrack module(s)\nto be loaded to function properly. While they are typically\nloaded automatically, add a note to the admin guide about\nthe requirement to make it explicit.\n\nPartial bug: #1834213\n\nChange-Id: I55871eff1e37d4155b8d2b5ae8c182d160c4af9f\n'}, {'number': 2, 'created': '2023-01-25 15:27:09.000000000', 'files': ['doc/source/admin/config-ovsfwdriver.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c609084b59c68f003153a58c2063f99b52f169e0', 'message': 'Add doc note on nf_conntrack module requirement\n\nThe OVS firewall driver requires nf_conntrack module(s)\nto be loaded to function properly. While they are typically\nloaded automatically, add a note to the admin guide about\nthe requirement to make it explicit.\n\nCloses-bug: #1834213\n\nChange-Id: I55871eff1e37d4155b8d2b5ae8c182d160c4af9f\n'}]",8,871659,c609084b59c68f003153a58c2063f99b52f169e0,13,4,2,1131,,,0,"Add doc note on nf_conntrack module requirement

The OVS firewall driver requires nf_conntrack module(s)
to be loaded to function properly. While they are typically
loaded automatically, add a note to the admin guide about
the requirement to make it explicit.

Closes-bug: #1834213

Change-Id: I55871eff1e37d4155b8d2b5ae8c182d160c4af9f
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/871659/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-ovsfwdriver.rst'],1,d03cc220ee910c408070efbe061c1ef6604d492b,bug/1834213,"It also requires the conntrack kernel module(s) to be loaded, which varies depending on the kernel version. * Kernel version 4.19 or newer requires the *nf_conntrack* module. * Kernel versions 4.18 or older require the *nf_conntrack_ipv4* and *nf_conntrack_ipv6* modules. ",,7,0
openstack%2Fglance~stable%2Fvictoria~Idf561f6306cebf756c787d8eefdc452ce44bd5e0,openstack/glance,stable/victoria,Idf561f6306cebf756c787d8eefdc452ce44bd5e0,Enforce image safety during image_conversion,MERGED,2023-01-24 15:03:23.000000000,2023-01-26 14:49:19.000000000,2023-01-26 14:48:06.000000000,"[{'_account_id': 5314}, {'_account_id': 8122}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:03:23.000000000', 'files': ['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/06e6be579156d8bf2ce8e021d07d6f351fb88c07', 'message': ""Enforce image safety during image_conversion\n\nThis does two things:\n\n1. It makes us check that the QCOW backing_file is unset on those\ntypes of images. Nova and Cinder do this already to prevent an\narbitrary (and trivial to accomplish) host file exposure exploit.\n2. It makes us restrict VMDK files to only allowed subtypes. These\nfiles can name arbitrary files on disk as extents, providing the\nsame sort of attack. Default that list to just the types we believe\nare actually useful for openstack, and which are monolithic.\n\nThe configuration option to specify allowed subtypes is added in\nglance's config and not in the import options so that we can extend\nthis check later to image ingest. The format_inspector can tell us\nwhat the type and subtype is, and we could reject those images early\nand even in the case where image_conversion is not enabled.\n\nCloses-Bug: #1996188\nChange-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0\n(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)\n(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)\n(cherry picked from commit dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b)\n(cherry picked from commit f45b5f024e765f0000884dfec5ac222124cfbc6d)\n(cherry picked from commit 9a98c4a7d1358cdae009cc8fb6377160a126ea7b)\nConflicts: glance/tests/unit/async_/flows/plugins/test_image_conversion.py\n   - removed code related to missing tests - 050802dd67b9135e04a65d340531157c94248c51\n""}]",2,871623,06e6be579156d8bf2ce8e021d07d6f351fb88c07,12,6,1,9303,,,0,"Enforce image safety during image_conversion

This does two things:

1. It makes us check that the QCOW backing_file is unset on those
types of images. Nova and Cinder do this already to prevent an
arbitrary (and trivial to accomplish) host file exposure exploit.
2. It makes us restrict VMDK files to only allowed subtypes. These
files can name arbitrary files on disk as extents, providing the
same sort of attack. Default that list to just the types we believe
are actually useful for openstack, and which are monolithic.

The configuration option to specify allowed subtypes is added in
glance's config and not in the import options so that we can extend
this check later to image ingest. The format_inspector can tell us
what the type and subtype is, and we could reject those images early
and even in the case where image_conversion is not enabled.

Closes-Bug: #1996188
Change-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0
(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)
(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)
(cherry picked from commit dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b)
(cherry picked from commit f45b5f024e765f0000884dfec5ac222124cfbc6d)
(cherry picked from commit 9a98c4a7d1358cdae009cc8fb6377160a126ea7b)
Conflicts: glance/tests/unit/async_/flows/plugins/test_image_conversion.py
   - removed code related to missing tests - 050802dd67b9135e04a65d340531157c94248c51
",git fetch https://review.opendev.org/openstack/glance refs/changes/23/871623/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py']",3,06e6be579156d8bf2ce8e021d07d6f351fb88c07,glance-1996188-victoria.patch," if 'backing-filename' in metadata: LOG.warning('Refusing to process QCOW image with a backing file') raise RuntimeError( 'QCOW images with backing files are not allowed') if metadata.get('format') == 'vmdk': create_type = metadata.get( 'format-specific', {}).get( 'data', {}).get('create-type') allowed = CONF.image_format.vmdk_allowed_types if not create_type: raise RuntimeError(_('Unable to determine VMDK create-type')) if not len(allowed): LOG.warning(_('Refusing to process VMDK file as ' 'vmdk_allowed_types is empty')) raise RuntimeError(_('Image is a VMDK, but no VMDK createType ' 'is specified')) if create_type not in allowed: LOG.warning(_('Refusing to process VMDK file with create-type ' 'of %r which is not in allowed set of: %s'), create_type, ','.join(allowed)) raise RuntimeError(_('Invalid VMDK create-type specified')) ",,97,0
openstack%2Fcinder~master~Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab,openstack/cinder,master,Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab,NVMe-TCP volume driver for Fungible Storage,MERGED,2022-07-08 19:30:09.000000000,2023-01-26 14:49:16.000000000,2023-01-25 05:11:46.000000000,"[{'_account_id': 5314}, {'_account_id': 13425}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 29122}, {'_account_id': 31721}]","[{'number': 1, 'created': '2022-07-08 19:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b18b8dfcea2f7455853f4d9fad709c07b72b2199', 'message': 'NVMEoF volume driver for Fungible Storage\n\nAdd cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nDepends-On: Id5b3683b3722f4cdde05da68053048cee52f4352\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 2, 'created': '2022-09-16 01:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4cd1f33af8a8eaf600dd49c61125e61946e8880', 'message': 'NVMEoF volume driver for Fungible Storage\n\nAdd cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 3, 'created': '2022-09-17 02:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c076b5155401b99b70c577800e6b06f872d46c1b', 'message': 'NVMEoF volume driver for Fungible Storage\n\nAdd cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 4, 'created': '2022-09-21 04:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/82e9d15db2aefbec5050072e4b76aaa26c27b4d0', 'message': 'NVMEoF volume driver for Fungible Storage\n\nAdd cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 5, 'created': '2022-09-21 04:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/11dda9af2027e81fe55a701a8cd89203bbe6a264', 'message': 'NVMEoF volume driver for Fungible Storage\n\nAdd cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 6, 'created': '2022-09-22 21:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/40ade307e4a278ff50049af0335e23d1d3ebd507', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 7, 'created': '2022-09-23 00:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9ba754e3ba91a7d24f33fbd7733c048c5ae3b8b9', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 8, 'created': '2022-09-27 16:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b08cc869ee55647c45ce592dc597f45317b64146', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 9, 'created': '2022-10-04 02:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4375ad0f2743bf7581432c5bdfdaa4e61ad1f858', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 10, 'created': '2022-10-04 04:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/83197f195ad2779d7c071dbe6f3df4ecda01de6c', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 11, 'created': '2022-10-06 21:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1feb56fc3cbeed92999978a0626777740f30eace', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 12, 'created': '2022-10-08 03:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/676d66e7b48a06a8d3fdeabc0f81fc7f51d988ef', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 13, 'created': '2022-10-11 23:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e2036896f75a2813e3276d19d3ca91538251c14b', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 14, 'created': '2022-10-12 01:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/add476338f99d0b99376fc5f7ea097cc314f420f', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 15, 'created': '2023-01-12 05:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9230ee0fe589eee80f63fc64d93cc01e3b458efc', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 16, 'created': '2023-01-18 04:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7f61a958285f93797211eb9642e098ea4f059e9d', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 17, 'created': '2023-01-22 20:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f45414fd1f7f7c11539d252e0840924eee38adc0', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}, {'number': 18, 'created': '2023-01-22 23:35:04.000000000', 'files': ['cinder/volume/drivers/fungible/swagger_api_client.py', 'cinder/tests/unit/volume/drivers/fungible/__init__.py', 'cinder/tests/unit/volume/drivers/fungible/test_driver.py', 'cinder/opts.py', 'doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/fungible/driver.py', 'cinder/volume/drivers/fungible/constants.py', 'cinder/volume/drivers/fungible/rest_client.py', 'doc/source/configuration/block-storage/drivers/fungible-storage-driver.rst', 'releasenotes/notes/fungible-cinder-driver-af8aeb57846c8ecc.yaml', 'cinder/tests/unit/volume/drivers/fungible/test_adapter.py', 'cinder/volume/drivers/fungible/__init__.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/00cb2887bac1c37bd100bdfce37b9f94cc7fbf2b', 'message': 'NVMe-TCP volume driver for Fungible Storage\n\nAdd NVMe-TCP cinder volume driver for the Fungible Storage Cluster.\n\nImplements: blueprint fungible-volume-driver\nChange-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab\n'}]",247,849143,00cb2887bac1c37bd100bdfce37b9f94cc7fbf2b,347,7,18,34815,,,0,"NVMe-TCP volume driver for Fungible Storage

Add NVMe-TCP cinder volume driver for the Fungible Storage Cluster.

Implements: blueprint fungible-volume-driver
Change-Id: Ie3a8ef6694b1c6ac857d3314890f6b8eeef44bab
",git fetch https://review.opendev.org/openstack/cinder refs/changes/43/849143/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/opts.py', 'cinder/volume/drivers/fungible/swagger_api_client.py', 'cinder/volume/drivers/fungible/driver.py', 'cinder/volume/drivers/fungible/constants.py', 'cinder/volume/drivers/fungible/rest_client.py', 'cinder/tests/unit/volume/drivers/fungible/__init__.py', 'cinder/tests/unit/volume/drivers/fungible/test_driver.py', 'cinder/tests/unit/volume/drivers/fungible/test_adapter.py', 'cinder/volume/drivers/fungible/__init__.py', 'cinder/volume/drivers/fungible/options.py']",10,b18b8dfcea2f7455853f4d9fad709c07b72b2199,bp/fungible-volume-driver,"# (c) Copyright 2022 Fungible, Inc. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Configuration options for Fungible Volume type. """""" from oslo_config import cfg volume_opts = [ cfg.StrOpt('storage_cluster_ip', default='127.0.0.1', help='storage cluster ip'), cfg.PortOpt('storage_cluster_port', default=443, help='storage cluster port'), cfg.StrOpt('username', default='admin', help='username for authenticating api'), cfg.StrOpt('password', default='password', help='password for authenticating api'), cfg.PortOpt('connect_port', default=4420, help='connect nvme port'), cfg.BoolOpt('enable_ssl', default=True, help='enable secure url for api'), cfg.IntOpt('iops_for_image_migration', default=250000, help='max read iops value'), cfg.PortOpt('nvme_controller_loss_timeout', default=600, help='controller loss timeout period in seconds'), cfg.PortOpt('nvme_queue_size', default=128, help='number of io queue elements to use'), ] ",,17354,0
openstack%2Fneutron~stable%2Fwallaby~Ia2a66cfd3fd1380c5204109742d44f09160548d2,openstack/neutron,stable/wallaby,Ia2a66cfd3fd1380c5204109742d44f09160548d2,Improve agent provision performance for large networks,MERGED,2023-01-18 03:14:06.000000000,2023-01-26 14:01:55.000000000,2023-01-26 14:00:43.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-18 03:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d01bf7ac1b1008abba557a42f58e0bbcd9860c5', 'message': 'Improve agent provision performance for large networks\n\nBefore this patch, the metadata agent would provision network namespace\nfor all subnets under a network(datapath) as soon as the first\nVM(vif port) was mounted on the chassis. This operation can take very\nlong time for networks with lots of subnets. See the linked bug for\nmore details.\nThis patch changes this mechanism to ""lazy load"" where metadata agent\nprovisions metadata namespace with only the subnets belonging to the\nactive ports on the chassis. This results in virtually constant\nthroughput not effected by the number of subnets.\n\nCloses-Bug: #1981113\nChange-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2\n(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)\n'}, {'number': 2, 'created': '2023-01-23 16:38:29.000000000', 'files': ['neutron/agent/ovn/metadata/agent.py', 'neutron/tests/unit/agent/ovn/metadata/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f90d18ad2bc5209c3caece51898401851ee738b', 'message': 'Improve agent provision performance for large networks\n\nBefore this patch, the metadata agent would provision network namespace\nfor all subnets under a network(datapath) as soon as the first\nVM(vif port) was mounted on the chassis. This operation can take very\nlong time for networks with lots of subnets. See the linked bug for\nmore details.\nThis patch changes this mechanism to ""lazy load"" where metadata agent\nprovisions metadata namespace with only the subnets belonging to the\nactive ports on the chassis. This results in virtually constant\nthroughput not effected by the number of subnets.\n\nMerge Conflict:\n        Using datapath_uuid :str in addition to net_name for\n        teardown_datapath method to remain compatible with the\n        method implementation in Yoga and before. Updated unit\n        tests accordingly\n        neutron/agent/ovn/metadata/agent.py\n        neutron/tests/unit/agent/ovn/metadata/test_agent.py\n\nCloses-Bug: #1981113\nChange-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2\n(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)\n'}]",1,870786,9f90d18ad2bc5209c3caece51898401851ee738b,12,4,2,34271,,,0,"Improve agent provision performance for large networks

Before this patch, the metadata agent would provision network namespace
for all subnets under a network(datapath) as soon as the first
VM(vif port) was mounted on the chassis. This operation can take very
long time for networks with lots of subnets. See the linked bug for
more details.
This patch changes this mechanism to ""lazy load"" where metadata agent
provisions metadata namespace with only the subnets belonging to the
active ports on the chassis. This results in virtually constant
throughput not effected by the number of subnets.

Merge Conflict:
        Using datapath_uuid :str in addition to net_name for
        teardown_datapath method to remain compatible with the
        method implementation in Yoga and before. Updated unit
        tests accordingly
        neutron/agent/ovn/metadata/agent.py
        neutron/tests/unit/agent/ovn/metadata/test_agent.py

Closes-Bug: #1981113
Change-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2
(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/86/870786/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/ovn/metadata/agent.py', 'neutron/tests/unit/agent/ovn/metadata/test_agent.py']",2,8d01bf7ac1b1008abba557a42f58e0bbcd9860c5,bug/1981113-stable/yoga-stable/xena-stable/wallaby," class DatapathInfo: def __init__(self, uuid, external_ids): self.uuid = uuid self.external_ids = external_ids def __hash__(self): return hash(self.uuid) self.agent, 'provision_datapath') as pdp,\ pdp.assert_has_calls( [ mock.call(p.datapath) for p in self.ports ], any_order=True ) self.agent, 'provision_datapath') as pdp,\ pdp.assert_has_calls( [ mock.call(p.datapath) for p in self.ports ], any_order=True ) def test_get_networks_datapaths(self): """"""Test get_networks_datapaths returns only datapath objects for the networks containing vif ports of type ''(blank) and 'external'. This test simulates that this chassis has the following ports: * datapath '1': 1 port type '' , 1 port 'external' and 1 port 'unknown' * datapath '2': 1 port type '' * datapath '4': 1 port with type 'unknown' It is expected that only datapaths '1', '2' and '3' are returned datapath_1 = DatapathInfo(uuid='uuid1', external_ids={'name': 'neutron-1'}) datapath_2 = DatapathInfo(uuid='uuid2', external_ids={'name': 'neutron-2'}) datapath_3 = DatapathInfo(uuid='uuid3', external_ids={'name': 'neutron-3'}) datapath_4 = DatapathInfo(uuid='uuid4', external_ids={'name': 'neutron-4'}) ports = [ makePort(datapath_1, type=''), makePort(datapath_1, type='external'), makePort(datapath_1, type='unknown'), makePort(datapath_2, type=''), makePort(datapath_3, type='external'), makePort(datapath_4, type='unknown') ] with mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=ports): expected_datapaths = set([datapath_1, datapath_2, datapath_3]) self.assertSetEqual( expected_datapaths, self.agent.get_networks_datapaths() ) def test__process_cidrs_when_current_namespace_empty(self): current_namespace_cidrs = set() datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28', n_const.METADATA_CIDR]) expected_cidrs_to_delete = set() actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_only_contains_metadata_cidr( self): current_namespace_cidrs = set([n_const.METADATA_CIDR]) datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28']) expected_cidrs_to_delete = set() actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_contains_stale_cidr(self): current_namespace_cidrs = set([n_const.METADATA_CIDR, '10.0.1.0/31']) datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28']) expected_cidrs_to_delete = set(['10.0.1.0/31']) actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_contains_mix_cidrs(self): """"""Current namespace cidrs contains stale cidrs and it is missing new required cidrs. """""" current_namespace_cidrs = set([n_const.METADATA_CIDR, '10.0.1.0/31', '10.0.1.0/28']) datapath_port_ips = ['10.0.0.2', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30']) expected_cidrs_to_delete = set(['10.0.1.0/31']) actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__get_provision_params_returns_none_when_metadata_port_is_missing( self): """"""Should return None when there is no metadata port in datapath and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) with mock.patch.object( self.agent.sb_idl, 'get_metadata_port_network', return_value=None),\ mock.patch.object( self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_none_when_metadata_port_missing_mac( self): """"""Should return None when metadata port is missing MAC and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) metadadata_port = makePort(datapath, mac=['NO_MAC_HERE 1.2.3.4'], external_ids={'neutron:cidrs': '10.204.0.10/29'}) with mock.patch.object( self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object( self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_none_when_no_vif_ports(self): """"""Should return None when there are no datapath ports with type ""external"" or """"(blank) and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) datapath_ports = [makePort(datapath, type='not_vif_type')] metadadata_port = makePort(datapath, mac=['fa:16:3e:22:65:18 1.2.3.4'], external_ids={'neutron:cidrs': '10.204.0.10/29'}) with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=datapath_ports),\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_provision_parameters(self): """"""The happy path when datapath has ports with ""external"" or """"(blank) types and metadata port contains MAC and subnet CIDRs. """""" network_id = '1' port_ip = '1.2.3.4' metada_port_mac = ""fa:16:3e:22:65:18"" metada_port_subnet_cidr = ""10.204.0.10/29"" metada_port_logical_port = ""3b66c176-199b-48ec-8331-c1fd3f6e2b44"" datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) datapath_ports = [makePort(datapath, mac=['fa:16:3e:e7:ac {}'.format(port_ip)])] metadadata_port = makePort(datapath, mac=[ '{} 10.204.0.1'.format(metada_port_mac) ], external_ids={'neutron:cidrs': metada_port_subnet_cidr}, logical_port=metada_port_logical_port) with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=datapath_ports): actual_params = self.agent._get_provision_params(datapath) net_name, datapath_port_ips, metadata_port_info = actual_params self.assertEqual(network_id, net_name) self.assertListEqual([port_ip], datapath_port_ips) self.assertEqual(metada_port_mac, metadata_port_info.mac) self.assertSetEqual(set([metada_port_subnet_cidr]), metadata_port_info.ip_addresses) self.assertEqual(metada_port_logical_port, metadata_port_info.logical_port) net_name = '123' metadaport_logical_port = '123-abc-456' datapath_ports_ips = ['10.0.0.1', '10.0.0.2'] metada_port_info = agent.MetadataPortInfo( mac='aa:bb:cc:dd:ee:ff', ip_addresses=['10.0.0.1/23', '2001:470:9:1224:5595:dd51:6ba2:e788/64'], logical_port=metadaport_logical_port ) provision_params = (net_name, datapath_ports_ips, metada_port_info,) nemaspace_name = 'namespace' with mock.patch.object(self.agent, '_get_provision_params', return_value=provision_params),\ return_value=nemaspace_name),\ self.agent.provision_datapath('fake_datapath') add_veth.assert_called_once_with('veth_0', 'veth_1', nemaspace_name) 'Interface', 'veth_0', ('external_ids', {'iface-id': metadaport_logical_port})) mock.ANY, nemaspace_name, 80, mock.ANY, bind_address=n_const.METADATA_V4_IP, network_id=net_name) mock_checksum.assert_called_once_with(nemaspace_name)","DatapathInfo = collections.namedtuple('DatapathInfo', ['uuid', 'external_ids']) self.agent, 'ensure_all_networks_provisioned') as enp,\ enp.assert_called_once_with({ (p.datapath.uuid, p.datapath.uuid) for p in self.ports }) self.agent, 'ensure_all_networks_provisioned') as enp,\ enp.assert_called_once_with({ (p.datapath.uuid, p.datapath.uuid) for p in self.ports }) def test_get_networks(self): """"""Test which networks are provisioned. This test simulates that this chassis has the following ports: * datapath '0': 1 port * datapath '1': 2 ports * datapath '2': 1 port * datapath '5': 1 port with type 'unknown' It is expected that only datapaths '0', '1' and '2' are scheduled for provisioning. self.ports.append(makePort(datapath=DatapathInfo(uuid='1', external_ids={'name': 'neutron-1'}))) self.ports.append(makePort(datapath=DatapathInfo(uuid='3', external_ids={'name': 'neutron-3'}), type='external')) self.ports.append(makePort(datapath=DatapathInfo(uuid='5', external_ids={'name': 'neutron-5'}), type='unknown')) expected_networks = {(str(i), str(i)) for i in range(0, 4)} self.assertEqual(expected_networks, self.agent.get_networks()) def test_update_datapath_provision(self): self.ports.append(makePort(datapath=DatapathInfo(uuid='3', external_ids={'name': 'neutron-3'}), type='external')) with mock.patch.object(self.agent, 'provision_datapath', return_value=None) as pdp,\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.agent.update_datapath('1', 'a') self.agent.update_datapath('3', 'b') expected_calls = [mock.call('1', 'a'), mock.call('3', 'b')] pdp.assert_has_calls(expected_calls) tdp.assert_not_called() def test_update_datapath_teardown(self): with mock.patch.object(self.agent, 'provision_datapath', return_value=None) as pdp,\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.agent.update_datapath('5', 'a') tdp.assert_called_once_with('5', 'a') pdp.assert_not_called() metadata_port = makePort(mac=['aa:bb:cc:dd:ee:ff'], external_ids={ 'neutron:cidrs': '10.0.0.1/23 ' '2001:470:9:1224:5595:dd51:6ba2:e788/64'}, logical_port='port') with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadata_port),\ return_value='namespace'),\ self.agent.provision_datapath('1', '1') add_veth.assert_called_once_with('veth_0', 'veth_1', 'namespace') 'Interface', 'veth_0', ('external_ids', {'iface-id': 'port'})) mock.ANY, 'namespace', 80, mock.ANY, bind_address=n_const.METADATA_V4_IP, network_id='1') mock_checksum.assert_called_once_with('namespace')",378,133
openstack%2Fdevstack-plugin-nfs~master~I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581,openstack/devstack-plugin-nfs,master,I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581,Add zed and yoga jobs,MERGED,2023-01-19 10:10:21.000000000,2023-01-26 13:39:38.000000000,2023-01-26 13:37:53.000000000,"[{'_account_id': 8556}, {'_account_id': 10459}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-19 10:10:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-plugin-nfs/commit/86b567aeb533ec81daa44d136ff2ae01956c6e35', 'message': 'Switch testing to Antelope testing runtime\n\nUpdating the testing template to Antelope testing runtime:\nhttps://governance.openstack.org/tc/reference/runtimes/2023.1.html\n\nChange-Id: I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581\n'}, {'number': 2, 'created': '2023-01-23 16:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-plugin-nfs/commit/1706d487b8bfc189ade570d280fce230123bd2f2', 'message': 'Switch testing to Antelope testing runtime\n\nUpdating the testing template to Antelope testing runtime:\nhttps://governance.openstack.org/tc/reference/runtimes/2023.1.html\n\nAdd jobs for stable/yoga and stable/zed.\nRemove the stable/victoria and stable/ussuri jobs.\n\nChange-Id: I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581\n'}, {'number': 3, 'created': '2023-01-23 19:35:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-plugin-nfs/commit/098d030a88f29aa799562831ad0c0e10c5b74ad1', 'message': 'Switch testing to Antelope testing runtime\n\nUpdating the testing template to Antelope testing runtime:\nhttps://governance.openstack.org/tc/reference/runtimes/2023.1.html\n\nChange-Id: I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581\n'}, {'number': 4, 'created': '2023-01-24 08:31:10.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack-plugin-nfs/commit/9f8f5f95960240ff9fb25827f8255b4cca92346f', 'message': 'Add zed and yoga jobs\n\nThe patch adds stable/yoga and stable/zed jobs to test the\nlatest stable branches.\n\nChange-Id: I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581\n'}]",16,871072,9f8f5f95960240ff9fb25827f8255b4cca92346f,24,4,4,22873,,,0,"Add zed and yoga jobs

The patch adds stable/yoga and stable/zed jobs to test the
latest stable branches.

Change-Id: I5a9866c4d84a08d2b451e9b5b5596f59ea3c3581
",git fetch https://review.opendev.org/openstack/devstack-plugin-nfs refs/changes/72/871072/4 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,86b567aeb533ec81daa44d136ff2ae01956c6e35,, - devstack-plugin-nfs-tempest-full-zed - devstack-plugin-nfs-tempest-full-yoga - devstack-plugin-nfs-tempest-full-zed - devstack-plugin-nfs-tempest-full-yoga name: devstack-plugin-nfs-tempest-full-zed parent: devstack-plugin-nfs-tempest-full override-checkout: stable/zed - job: name: devstack-plugin-nfs-tempest-full-yoga parent: devstack-plugin-nfs-tempest-full override-checkout: stable/yoga - job:, - devstack-plugin-nfs-tempest-full-victoria # ussuri disabled due to https://bugs.launchpad.net/nova/+bug/1916750 - devstack-plugin-nfs-tempest-full-ussuri: voting: no - devstack-plugin-nfs-tempest-full-victoria # - devstack-plugin-nfs-tempest-full-ussuri - job: name: devstack-plugin-nfs-tempest-full-victoria parent: devstack-plugin-nfs-tempest-full nodeset: openstack-single-node-focal override-checkout: stable/victoria - job: name: devstack-plugin-nfs-tempest-full-ussuri parent: devstack-plugin-nfs-tempest-full nodeset: openstack-single-node-bionic override-checkout: stable/ussuri,14,18
openstack%2Fneutron~master~I2dddc296826e5ab5e057c32a554e353577cc36e8,openstack/neutron,master,I2dddc296826e5ab5e057c32a554e353577cc36e8,Change flag check order in wait_until_address_ready(),MERGED,2023-01-20 21:59:52.000000000,2023-01-26 13:33:45.000000000,2023-01-26 13:31:20.000000000,"[{'_account_id': 5948}, {'_account_id': 7730}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2023-01-20 21:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c3e5718f7fb9db372f88eeafe2c6ab797e319adf', 'message': ""Change flag check order in wait_until_address_ready()\n\nWhen DAD fails on an IPv6 address, both the 'dadfailed'\nand 'tentative' flags will be set. So change the code\nto check for 'dadfailed' first, since otherwise it\ncould loop unneccesarily thinking DAD is still in\nprogress.\n\nAdded better unit testing to cover more cases as well.\n\nTrivialfix\n\nChange-Id: I2dddc296826e5ab5e057c32a554e353577cc36e8\n""}, {'number': 2, 'created': '2023-01-23 19:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55af3f34e59f37432886e7b71455f1c6d355a686', 'message': ""Change flag check order in wait_until_address_ready()\n\nWhen DAD fails on an IPv6 address, both the 'dadfailed'\nand 'tentative' flags will be set. So change the code\nto check for 'dadfailed' first, just to be explicit.\n\nAdded better unit testing to cover more cases as well.\n\nTrivialfix\n\nChange-Id: I2dddc296826e5ab5e057c32a554e353577cc36e8\n""}, {'number': 3, 'created': '2023-01-24 14:46:14.000000000', 'files': ['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d22cfa99a529933d436a449f1971a96c95f2b66', 'message': ""Change flag check order in wait_until_address_ready()\n\nWhen DAD fails on an IPv6 address, both the 'dadfailed'\nand 'tentative' flags will be set. So change the code\nto check for 'dadfailed' first, just to be explicit.\n\nAdded better unit testing to cover more cases as well.\n\nTrivialfix\n\nChange-Id: I2dddc296826e5ab5e057c32a554e353577cc36e8\n""}]",7,871389,1d22cfa99a529933d436a449f1971a96c95f2b66,32,6,3,1131,,,0,"Change flag check order in wait_until_address_ready()

When DAD fails on an IPv6 address, both the 'dadfailed'
and 'tentative' flags will be set. So change the code
to check for 'dadfailed' first, just to be explicit.

Added better unit testing to cover more cases as well.

Trivialfix

Change-Id: I2dddc296826e5ab5e057c32a554e353577cc36e8
",git fetch https://review.opendev.org/openstack/neutron refs/changes/89/871389/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py']",2,c3e5718f7fb9db372f88eeafe2c6ab797e319adf,ipv6-dad-failed," self.addr_cmd.list = mock.Mock( return_value=[{'tentative': False, 'dadfailed': False}]) def test_wait_until_address_dadfailed(self): self.addr_cmd.list = mock.Mock( return_value=[{'tentative': True, 'dadfailed': True}]) with testtools.ExpectedException(ip_lib.AddressNotReady): self.addr_cmd.wait_until_address_ready('abcd::1234') @mock.patch.object(common_utils, 'wait_until_true') def test_wait_until_address_ready_success_one_timeout(self, mock_wuntil): tentative_address = 'fe80::3023:39ff:febc:22ae' self.addr_cmd.list = mock.Mock(return_value=[ dict(scope='link', dadfailed=False, tentative=True, dynamic=False, cidr=tentative_address + '/64'), dict(scope='link', dadfailed=False, tentative=False, dynamic=False, cidr=tentative_address + '/64')]) self.assertIsNone(self.addr_cmd.wait_until_address_ready( tentative_address, wait_time=3)) self.assertEqual(1, mock_wuntil.call_count) ", self.addr_cmd.list = mock.Mock(return_value=[{'tentative': False}]),27,5
openstack%2Fneutron~master~Ia4c25110ee5a7b7539407d3531f559555fec50cc,openstack/neutron,master,Ia4c25110ee5a7b7539407d3531f559555fec50cc,Fullstack: Wait placement process fixtrue to really stop,MERGED,2023-01-18 13:46:01.000000000,2023-01-26 13:32:40.000000000,2023-01-26 13:31:15.000000000,"[{'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 7730}, {'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-18 13:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c20716b38a456270b4ea1893828f857fa8959d76', 'message': ""Fullstack: Wait placement process fixtrue to really stop\n\nIt seems that in test test_configurations_are_synced_towards_placement\nwhen the fake placement process is stopped it can take longer and\nthe test restarts the agent before it is really dead.\nIn this case neutron-server can report the status and the agent's\n'resources_synced' field is True when the tests checks it.\n\nA simple workaround for this can be to check if the AsyncProcess\nclass' _is_running property is False.\n\nCloses-Bug: #1856319\nChange-Id: Ia4c25110ee5a7b7539407d3531f559555fec50cc\n""}, {'number': 2, 'created': '2023-01-24 13:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e67081920163884389b9ed99daad0a2c24aebd81', 'message': ""Fullstack: Wait placement process fixtrue to really stop\n\nIt seems that in test test_configurations_are_synced_towards_placement\nwhen the fake placement process is stopped it can take longer and\nthe test restarts the agent before it is really dead.\nIn this case neutron-server can report the status and the agent's\n'resources_synced' field is True when the tests checks it.\n\nA simple workaround for this can be to check if the AsyncProcess\nclass' _is_running property is False.\n\nCloses-Bug: #1856319\nChange-Id: Ia4c25110ee5a7b7539407d3531f559555fec50cc\n""}, {'number': 3, 'created': '2023-01-24 13:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d7355d6a3bda2b66317d0eb9ac6ca385c01fd745', 'message': ""Fullstack: Wait placement process fixtrue to really stop\n\nIt seems that in test test_configurations_are_synced_towards_placement\nwhen the fake placement process is stopped it can take longer and\nthe test restarts the agent before it is really dead.\nIn this case neutron-server can report the status and the agent's\n'resources_synced' field is True when the tests checks it.\n\nA simple workaround for this can be to check if the AsyncProcess\nclass' _is_running property is False.\n\nCloses-Bug: #1856319\nChange-Id: Ia4c25110ee5a7b7539407d3531f559555fec50cc\n""}, {'number': 4, 'created': '2023-01-25 13:01:33.000000000', 'files': ['neutron/tests/fullstack/resources/process.py', 'neutron/agent/common/async_process.py', 'neutron/tests/fullstack/test_agent_bandwidth_report.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ae432e71712be671ec93dded3245513b6810cd0', 'message': ""Fullstack: Wait placement process fixtrue to really stop\n\nIt seems that in test test_configurations_are_synced_towards_placement\nwhen the fake placement process is stopped it can take longer and\nthe test restarts the agent before it is really dead.\nIn this case neutron-server can report the status and the agent's\n'resources_synced' field is True when the tests checks it.\n\nA simple workaround for this can be to check if the AsyncProcess\nclass' _is_running property is False.\n\nCloses-Bug: #1856319\nChange-Id: Ia4c25110ee5a7b7539407d3531f559555fec50cc\n""}]",8,870956,0ae432e71712be671ec93dded3245513b6810cd0,24,6,4,8313,,,0,"Fullstack: Wait placement process fixtrue to really stop

It seems that in test test_configurations_are_synced_towards_placement
when the fake placement process is stopped it can take longer and
the test restarts the agent before it is really dead.
In this case neutron-server can report the status and the agent's
'resources_synced' field is True when the tests checks it.

A simple workaround for this can be to check if the AsyncProcess
class' _is_running property is False.

Closes-Bug: #1856319
Change-Id: Ia4c25110ee5a7b7539407d3531f559555fec50cc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/56/870956/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/fullstack/test_agent_bandwidth_report.py'],1,c20716b38a456270b4ea1893828f857fa8959d76,bug/1856319," # Check if the fake placement process is really stopped before # restarting the agent to be sure that the sync will fail. def _placement_is_not_running(): placement_fixt = self.environment.placement.process_fixture return not placement_fixt.process._is_running utils.wait_until_true( predicate=functools.partial(_placement_is_not_running), timeout=report_interval, sleep=1 ) ",,12,0
openstack%2Fansible-collections-openstack~master~I0b04d43d5095ee74ec5af27013b6159a6a4d0f13,openstack/ansible-collections-openstack,master,I0b04d43d5095ee74ec5af27013b6159a6a4d0f13,"Added resource{,s} modules",MERGED,2023-01-11 13:10:35.000000000,2023-01-26 13:29:44.000000000,2023-01-26 13:29:44.000000000,"[{'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 27900}, {'_account_id': 32962}]","[{'number': 1, 'created': '2023-01-11 13:10:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/0198ffa0572fb957645361eef6f208b682691e16', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 2, 'created': '2023-01-11 13:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/78a606df3b379aee26b4941aa0e7b0f5644e79be', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 3, 'created': '2023-01-11 14:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/e05191e74228b084f24e01d8e5785916dd3c6915', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 4, 'created': '2023-01-11 19:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/df5cf286c9ef69ba82e931a3e3738fc59ca78a4e', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 5, 'created': '2023-01-12 12:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/8b7c288fe61e99662633090f5cb3caead46750e8', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 6, 'created': '2023-01-12 17:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/4343bc85d19b55d198b56a849e528297429e6d8d', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 7, 'created': '2023-01-13 15:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/c3d48c72de0692cc7268fcfd89ee3442e86c82f3', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 8, 'created': '2023-01-13 20:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/16f728fc38bc03de69b38e1753c297620673be6e', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 9, 'created': '2023-01-14 08:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/2d99db8ccf4bdf1da605acfbdfc80bfcb2d10e30', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 10, 'created': '2023-01-16 09:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/dc7763e0b588d59889a833dff187ac60d19e0e4e', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 11, 'created': '2023-01-16 09:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/47e199b22083ef41d99decc41505be6f5c498215', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 12, 'created': '2023-01-16 12:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/aff7c94521e848727c594553bc1c0b4efb6bcd9f', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 13, 'created': '2023-01-16 18:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/61967c899d620e7985f9e7ec51fe2c9f48a54227', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 14, 'created': '2023-01-16 20:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/b2a03cac6b0d56ebf8ebb19fe9c6176a8994738e', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 15, 'created': '2023-01-17 16:34:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/83ab1b51594455b63c463bd4b484d590f774f086', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 16, 'created': '2023-01-19 19:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/ef4652f226be351a2555e7fc2a235c6a35e917a5', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}, {'number': 17, 'created': '2023-01-26 08:34:39.000000000', 'files': ['plugins/modules/resources.py', 'ci/roles/resources/tasks/main.yml', 'meta/runtime.yml', 'plugins/modules/resource.py', 'ci/roles/resource/defaults/main.yml', 'ci/run-collection.yml', 'plugins/module_utils/resource.py', 'ci/roles/resource/tasks/check_mode.yml', 'ci/roles/resource/tasks/main.yml', 'ci/roles/resources/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-collections-openstack/commit/a4a6e6d4ec11a81255526b46256b0e10d6ff3587', 'message': 'Added resource{,s} modules\n\nChange-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13\n'}]",21,869822,a4a6e6d4ec11a81255526b46256b0e10d6ff3587,46,4,17,32962,,,0,"Added resource{,s} modules

Change-Id: I0b04d43d5095ee74ec5af27013b6159a6a4d0f13
",git fetch https://review.opendev.org/openstack/ansible-collections-openstack refs/changes/22/869822/12 && git format-patch -1 --stdout FETCH_HEAD,"['plugins/modules/resources.py', 'ci/roles/resources/tasks/main.yml', 'meta/runtime.yml', 'plugins/modules/resource.py', 'ci/roles/resource/defaults/main.yml', 'ci/run-collection.yml', 'plugins/module_utils/resource.py', 'ci/roles/resource/tasks/main.yml', 'ci/roles/resources/defaults/main.yml']",9,0198ffa0572fb957645361eef6f208b682691e16,resource,--- expected_fields: - resources ,,1708,0
openstack%2Fironic~master~Ia563f5e50bbcc789ccc768bef5800a64b38ff3d7,openstack/ironic,master,Ia563f5e50bbcc789ccc768bef5800a64b38ff3d7,Docs: Troubleshooting: how to exit clean failed,MERGED,2023-01-19 19:35:38.000000000,2023-01-26 13:26:21.000000000,2023-01-26 13:25:02.000000000,"[{'_account_id': 10342}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2023-01-19 19:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b533bd8cb0e6f1b0705601bb9916301146a511c0', 'message': 'Docs: Troubleshooting: how to exit clean failed\n\nI got pinged with some questions by an operator who had\nissues attempting to exit cleaning. In the discussion,\nit was realized we lack basic troubleshooting guidance,\nwhich led them to try everything but the command they needed.\n\nAs such, adding some guidance in an attempt to help operators\nnavigate these sorts of issues moving forward.\n\nChange-Id: Ia563f5e50bbcc789ccc768bef5800a64b38ff3d7\n'}, {'number': 2, 'created': '2023-01-20 14:23:06.000000000', 'files': ['doc/source/admin/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8604a799aa2768b93e3826b1e2c8b543c355282c', 'message': 'Docs: Troubleshooting: how to exit clean failed\n\nI got pinged with some questions by an operator who had\nissues attempting to exit cleaning. In the discussion,\nit was realized we lack basic troubleshooting guidance,\nwhich led them to try everything but the command they needed.\n\nAs such, adding some guidance in an attempt to help operators\nnavigate these sorts of issues moving forward.\n\nChange-Id: Ia563f5e50bbcc789ccc768bef5800a64b38ff3d7\n'}]",4,871129,8604a799aa2768b93e3826b1e2c8b543c355282c,10,3,2,11655,,,0,"Docs: Troubleshooting: how to exit clean failed

I got pinged with some questions by an operator who had
issues attempting to exit cleaning. In the discussion,
it was realized we lack basic troubleshooting guidance,
which led them to try everything but the command they needed.

As such, adding some guidance in an attempt to help operators
navigate these sorts of issues moving forward.

Change-Id: Ia563f5e50bbcc789ccc768bef5800a64b38ff3d7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/29/871129/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/troubleshooting.rst'],1,b533bd8cb0e6f1b0705601bb9916301146a511c0,," I'm in ""clean failed"" state, what do I do? ========================================== There is only one way to exit the ``clean failed`` state. But before we visit the answer as to **how**, we need to stress the importance of attempting to understand **why** cleaning failed. On the simple side of things, this may be as simple as a DHCP failure, but on a complex side of things, it could be that a cleaning action failed against the underlying hardware, possibly due to a hardware failure. As such, we encourage everyone to attempt to understand **why** before exiting the ``clean failed`` state, because you could potentially make things worse for yourself. For example if firmware updates were being performed, you may need to perform a rollback operation against the physical server, depending on what, and how the firmware was being updated. Unfortunately this also borders the territory of ""no simple answer"". This can be counter balanced with sometimes there is a transient networking failure and a DHCP address was not obtained. An example of this would be suggested by the ``last_error`` field indicating something about ""Timeout reached while cleaning the node"", however we recommend following several basic troubleshooting steps: * Consult the ``last_error`` field on the node, utilizing the ``baremetal node show <uuid>`` command. * If the version of ironic supports the feature, consult the node history log, ``baremetal node history list`` and ``baremetal node history get <uuid>``. * Consult the acutal console screen of the physical machine. *If* the ramdisk booted, you will generally want to investigate the controller logs and see if an uploaded agent log is being stored on the conductor responsible for the baremetal node. Consult `_retrieve_deploy_ramdisk_logs`_. If the node did not boot for some reason, you can typically just retry at this point and move on. How to get out of the state, once you've understood **why** you reached it in the first place, is to utilize the ``baremetal node manage <node_id>`` command. This returns the node to ``manageable`` state, from where you can retry ""cleaning"" through automated cleaning with the ``provide`` command, or manual cleaning with ``clean`` command. or the next appropriate action in the workflow process you are attempting to follow, which may be ultimately be decommissioning the node because it could have failed and is being removed or replaced.",,44,0
openstack%2Fneutron~master~I4d1a6c799004339489fe35b44b7682f8f744560b,openstack/neutron,master,I4d1a6c799004339489fe35b44b7682f8f744560b,Add new debugging logs for ``ARPSpoofTestCase``,MERGED,2023-01-19 14:30:53.000000000,2023-01-26 13:24:22.000000000,2023-01-26 13:23:00.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 9845}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-19 14:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef4b1c7fa72723fdc940565327533ce4b16223e0', 'message': 'Add new debugging logs for ``ARPSpoofTestCase``\n\nIn case of error, the class ``ARPSpoofTestCase`` now provides the IPv6\nand IPv4 neigh list of the source and destination ports.\n\nThis patch also adds a retry branch on the ``assert_ping`` method. If\nenabled, if the first ping command fails, the method will try to execute\nit again.\n\nRelated-Bug: #2003196\nChange-Id: I4d1a6c799004339489fe35b44b7682f8f744560b\n'}, {'number': 2, 'created': '2023-01-20 09:53:56.000000000', 'files': ['neutron/tests/functional/agent/test_ovs_flows.py', 'neutron/tests/common/net_helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f235ce8791ab31bac598a3ebb40fb48cf2e4d1ab', 'message': 'Add new debugging logs for ``ARPSpoofTestCase``\n\nIn case of error, the class ``ARPSpoofTestCase`` now provides the IPv6\nand IPv4 neigh list of the source and destination ports.\n\nThis patch also adds a retry branch on the ``assert_ping`` method. If\nenabled, if the first ping command fails, the method will try to execute\nit again.\n\nRelated-Bug: #2003196\nChange-Id: I4d1a6c799004339489fe35b44b7682f8f744560b\n'}]",4,871101,f235ce8791ab31bac598a3ebb40fb48cf2e4d1ab,18,4,2,16688,,,0,"Add new debugging logs for ``ARPSpoofTestCase``

In case of error, the class ``ARPSpoofTestCase`` now provides the IPv6
and IPv4 neigh list of the source and destination ports.

This patch also adds a retry branch on the ``assert_ping`` method. If
enabled, if the first ping command fails, the method will try to execute
it again.

Related-Bug: #2003196
Change-Id: I4d1a6c799004339489fe35b44b7682f8f744560b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/871101/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/test_ovs_flows.py', 'neutron/tests/common/net_helpers.py']",2,ef4b1c7fa72723fdc940565327533ce4b16223e0,bug/2003196,"def assert_ping(src_namespace, dst_ip, timeout=1, count=3, retry=False): try: ns_ip_wrapper.netns.execute( [ping_command, '-W', timeout, '-c', count, dst_ip], privsep_exec=True) except n_exc.ProcessExecutionError as exc: if not retry: raise exc ns_ip_wrapper.netns.execute( [ping_command, '-W', timeout, '-c', count, dst_ip], privsep_exec=True)","def assert_ping(src_namespace, dst_ip, timeout=1, count=3): ns_ip_wrapper.netns.execute( [ping_command, '-W', timeout, '-c', count, dst_ip], privsep_exec=True)",26,14
openstack%2Freleases~master~Id738e92130b6bb7a6e6b92a2c358bcc144b5fe87,openstack/releases,master,Id738e92130b6bb7a6e6b92a2c358bcc144b5fe87,Adjust Xena EM deadline with 2023.1 Antelope release,MERGED,2023-01-23 13:01:26.000000000,2023-01-26 12:54:34.000000000,2023-01-26 12:54:34.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-23 13:01:26.000000000', 'files': ['data/series_status.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b71ab63a4b86447dd57734b1e7209a302130de1a', 'message': ""Adjust Xena EM deadline with 2023.1 Antelope release\n\nThe originally planned Extended Maintenance transition deadline for\nXena is too close to the PTG and the 2023.1 Antelope release.\nLet's set a more convenient, less busy period: ~1 month after the\nrelease.\n\nChange-Id: Id738e92130b6bb7a6e6b92a2c358bcc144b5fe87\n""}]",1,871470,b71ab63a4b86447dd57734b1e7209a302130de1a,7,3,1,17685,,,0,"Adjust Xena EM deadline with 2023.1 Antelope release

The originally planned Extended Maintenance transition deadline for
Xena is too close to the PTG and the 2023.1 Antelope release.
Let's set a more convenient, less busy period: ~1 month after the
release.

Change-Id: Id738e92130b6bb7a6e6b92a2c358bcc144b5fe87
",git fetch https://review.opendev.org/openstack/releases refs/changes/70/871470/1 && git format-patch -1 --stdout FETCH_HEAD,['data/series_status.yaml'],1,b71ab63a4b86447dd57734b1e7209a302130de1a,, date: 2023-04-20, date: 2023-04-06,1,1
openstack%2Freleases~master~Ifde9aa5bec30e18a12a9c5107888943a4af3e271,openstack/releases,master,Ifde9aa5bec30e18a12a9c5107888943a4af3e271,Add progress info printouts to list_eol_stale_branches.sh,MERGED,2023-01-23 16:27:08.000000000,2023-01-26 12:54:31.000000000,2023-01-26 12:54:31.000000000,"[{'_account_id': 308}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-23 16:27:08.000000000', 'files': ['tools/list_eol_stale_branches.sh'], 'web_link': 'https://opendev.org/openstack/releases/commit/1502a9d517f5acbfe74c0f2473ff31014cd33c34', 'message': 'Add progress info printouts to list_eol_stale_branches.sh\n\nAs the script runs it takes time to process every branches. This patch\nchanges the script to show the current repository being processed.\nAlso fixes variable name.\n\nChange-Id: Ifde9aa5bec30e18a12a9c5107888943a4af3e271\n'}]",0,871511,1502a9d517f5acbfe74c0f2473ff31014cd33c34,7,3,1,17685,,,0,"Add progress info printouts to list_eol_stale_branches.sh

As the script runs it takes time to process every branches. This patch
changes the script to show the current repository being processed.
Also fixes variable name.

Change-Id: Ifde9aa5bec30e18a12a9c5107888943a4af3e271
",git fetch https://review.opendev.org/openstack/releases refs/changes/11/871511/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/list_eol_stale_branches.sh'],1,1502a9d517f5acbfe74c0f2473ff31014cd33c34,eol-delete-speedup," req=""${GERRIT_URL}/changes/?q=status:open+project:${repo}+branch:stable/${em_branch}"" echo ""https://review.opendev.org/q/status:open+project:${repo}+branch:stable/${em_branch}"" [[ ""$head"" =~ ""${em_branch}-eol"" ]] && [[ ""$head"" =~ ""origin/stable/${em_branch}"" ]] echo ""stable/${em_branch} has patches on top of the ${em_branch}-eol tag"" clone_repo ${repo} stable/${em_branch} cd ${repo} && git checkout -f -q stable/${em_branch} 2>/dev/null echo echo ""${repo} contains eol stale branch (${em_branch})"" read -p ""> Do you want to delete the branch stable/${em_branch} from ${repo} repository? [y/N]: "" YN ${TOOLSDIR}/delete_stable_branch.py ${gerrit_username} ${repo} ${em_branch}for em_branch in ""${em_series[@]}""; do repos=$(list-deliverables -r --series ""${em_branch}"" --is-eol) echo "" --- $repo ($em_branch) --- "" is_eol ""${repo}"" ""${em_branch}"""," req=""${GERRIT_URL}/changes/?q=status:open+project:${repo}+branch:stable/${em_serie}"" echo ""https://review.opendev.org/q/status:open+project:${repo}+branch:stable/${em_serie}"" [[ ""$head"" =~ ""${em_serie}-eol"" ]] && [[ ""$head"" =~ ""origin/stable/${em_serie}"" ]] echo ""stable/${em_serie} has patches on top of the ${em_serie}-eol tag"" clone_repo ${repo} stable/${em_serie} cd ${repo} && git checkout -f -q stable/${em_serie} 2>/dev/null echo ""${repo} contains eol stale branch (${em_serie})"" read -p ""> Do you want to delete the branch stable/${em_serie} from ${repo} repository? [y/N]: "" YN ${TOOLSDIR}/delete_stable_branch.py ${gerrit_username} ${repo} ${em_serie}for em_serie in ""${em_series[@]}""; do repos=$(list-deliverables -r --series ""${em_serie}"" --is-eol) is_eol ""${repo}"" ""${em_serie}""",14,12
openstack%2Ftripleo-heat-templates~stable%2Fzed~Ic361a4d9bebd03e3174260136d53f14c71062f61,openstack/tripleo-heat-templates,stable/zed,Ic361a4d9bebd03e3174260136d53f14c71062f61,Add a tag for package setup,MERGED,2023-01-12 09:59:28.000000000,2023-01-26 12:51:38.000000000,2023-01-26 12:51:38.000000000,"[{'_account_id': 9816}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}]","[{'number': 1, 'created': '2023-01-12 09:59:28.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a854ab94a4a693097cbc14c970fbfda8b09336c0', 'message': 'Add a tag for package setup\n\nWe should be able to select only for the host package updates. To do\nthis we introduce setup_packages tag.\n\nChange-Id: Ic361a4d9bebd03e3174260136d53f14c71062f61\n(cherry picked from commit 88522a478ccf903b2b1740f5874541df0c62ab1e)\n'}]",3,869918,a854ab94a4a693097cbc14c970fbfda8b09336c0,14,6,1,31245,,,0,"Add a tag for package setup

We should be able to select only for the host package updates. To do
this we introduce setup_packages tag.

Change-Id: Ic361a4d9bebd03e3174260136d53f14c71062f61
(cherry picked from commit 88522a478ccf903b2b1740f5874541df0c62ab1e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/869918/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,a854ab94a4a693097cbc14c970fbfda8b09336c0,," - name: Host packages setup tags: setup_packages block: - name: Package and repo update tasks when: step|int == 0 block: - name: Run UpgradeInitCommand shell: list_join: - '' - - ""#!/bin/bash\n\n"" - ""if [[ -f /etc/resolv.conf.save ]] ; then rm /etc/resolv.conf.save; fi\n\n"" - {get_attr: [RoleParametersValue, value, 'upgrade_init_command']} - name: Run UpgradeInitCommonCommand shell: list_join: - '' - - ""#!/bin/bash\n\n"" - {get_param: UpgradeInitCommonCommand} - name: Ensure DNF modules have the right stream vars: dnf_module_list: {get_attr: [RoleParametersValue, value, 'dnf_module_list']} dnf: name: ""@{{ item.module }}:{{ item.stream }}/{{ item.profile|default('common') }}"" state: present loop: ""{{ dnf_module_list|list }}"" when: - dnf_module_list|length > 0 - item.distribution_version is defined - ansible_facts['distribution_major_version'] is version(item.distribution_version, '==') - name: Ensure TripleO prerequisite packages are installed package: name: - jq - lvm2 - openstack-selinux - os-net-config - puppet-tripleo - python3-heat-agent* - rsync state: present when: ansible_facts['distribution_major_version'] is version('8', '==') - name: Ensure TripleO prerequisite packages are installed and use role based heat variable to provide specific list of packages vars: base_tripleo_packages: {get_attr: [RoleParametersValue, value, 'base_tripleo_packages']} package: name: ""{{ base_tripleo_packages }}"" state: present when: - ansible_facts['distribution_major_version'] is version('8', '==') - base_tripleo_packages|length > 0 - name: check if libvirt is installed when: step|int == 0 command: /usr/bin/rpm -q libvirt-daemon failed_when: false register: libvirt_installed check_mode: false - name: make sure libvirt services are disabled and masked service: name: ""{{ item }}"" state: stopped enabled: false masked: true daemon_reload: true loop: - libvirtd.service - virtlogd.socket when: - step|int == 0 - libvirt_installed.rc == 0 - name: Special treatment for OpenvSwitch tripleo_ovs_upgrade: when: - step|int == 2 register: ovs_upgrade - name: Always ensure the openvswitch service is enabled and running after upgrades service: name: openvswitch enabled: true state: started when: - step|int == 2 - ovs_upgrade.changed|bool - name: Install libibverbs (https://bugs.launchpad.net/tripleo/+bug/1817743) when: step|int == 2 package: name: libibverbs state: installed - name: Check for os-net-config upgrade shell: ""yum check-upgrade | awk '/os-net-config/{print}'"" register: os_net_config_need_upgrade when: step|int == 3 - name: Check that os-net-config has configuration when: step|int == 3 stat: path: /etc/os-net-config/config.json get_attributes: false get_checksum: false get_mime: false register: stat_config_json - block: - name: Upgrade os-net-config package: name=os-net-config state=latest - name: take new os-net-config parameters into account now command: os-net-config --no-activate -c /etc/os-net-config/config.json -v --detailed-exit-codes register: os_net_config_upgrade failed_when: os_net_config_upgrade.rc not in [0,2] changed_when: os_net_config_upgrade.rc == 2 when: - step|int == 3 - os_net_config_need_upgrade.stdout - stat_config_json.stat.exists # Exclude ansible until https://github.com/ansible/ansible/issues/56636 # is available - name: Update all packages when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest exclude: ansible vars: skip_package_update: {get_param: SkipPackageUpdate}"," - name: Package and repo update tasks when: step|int == 0 block: - name: Run UpgradeInitCommand shell: list_join: - '' - - ""#!/bin/bash\n\n"" - ""if [[ -f /etc/resolv.conf.save ]] ; then rm /etc/resolv.conf.save; fi\n\n"" - {get_attr: [RoleParametersValue, value, 'upgrade_init_command']} - name: Run UpgradeInitCommonCommand shell: list_join: - '' - - ""#!/bin/bash\n\n"" - {get_param: UpgradeInitCommonCommand} - name: Ensure DNF modules have the right stream vars: dnf_module_list: {get_attr: [RoleParametersValue, value, 'dnf_module_list']} dnf: name: ""@{{ item.module }}:{{ item.stream }}/{{ item.profile|default('common') }}"" state: present loop: ""{{ dnf_module_list|list }}"" when: - dnf_module_list|length > 0 - item.distribution_version is defined - ansible_facts['distribution_major_version'] is version(item.distribution_version, '==') - name: Ensure TripleO prerequisite packages are installed package: name: - jq - lvm2 - openstack-selinux - os-net-config - puppet-tripleo - python3-heat-agent* - rsync state: present when: ansible_facts['distribution_major_version'] is version('8', '==') - name: Ensure TripleO prerequisite packages are installed and use role based heat variable to provide specific list of packages vars: base_tripleo_packages: {get_attr: [RoleParametersValue, value, 'base_tripleo_packages']} package: name: ""{{ base_tripleo_packages }}"" state: present when: - ansible_facts['distribution_major_version'] is version('8', '==') - base_tripleo_packages|length > 0 - name: check if libvirt is installed when: step|int == 0 command: /usr/bin/rpm -q libvirt-daemon failed_when: false register: libvirt_installed check_mode: false - name: make sure libvirt services are disabled and masked service: name: ""{{ item }}"" state: stopped enabled: false masked: true daemon_reload: true loop: - libvirtd.service - virtlogd.socket when: - step|int == 0 - libvirt_installed.rc == 0 - name: Special treatment for OpenvSwitch tripleo_ovs_upgrade: when: - step|int == 2 register: ovs_upgrade - name: Always ensure the openvswitch service is enabled and running after upgrades service: name: openvswitch enabled: true state: started when: - step|int == 2 - ovs_upgrade.changed|bool - name: Install libibverbs (https://bugs.launchpad.net/tripleo/+bug/1817743) when: step|int == 2 package: name: libibverbs state: installed - name: Check for os-net-config upgrade shell: ""yum check-upgrade | awk '/os-net-config/{print}'"" register: os_net_config_need_upgrade when: step|int == 3 - name: Check that os-net-config has configuration when: step|int == 3 stat: path: /etc/os-net-config/config.json get_attributes: false get_checksum: false get_mime: false register: stat_config_json - block: - name: Upgrade os-net-config package: name=os-net-config state=latest - name: take new os-net-config parameters into account now command: os-net-config --no-activate -c /etc/os-net-config/config.json -v --detailed-exit-codes register: os_net_config_upgrade failed_when: os_net_config_upgrade.rc not in [0,2] changed_when: os_net_config_upgrade.rc == 2 when: - step|int == 3 - os_net_config_need_upgrade.stdout - stat_config_json.stat.exists # Exclude ansible until https://github.com/ansible/ansible/issues/56636 # is available - name: Update all packages when: - step|int == 3 - not skip_package_update|bool yum: name: '*' state: latest exclude: ansible vars: skip_package_update: {get_param: SkipPackageUpdate}",122,119
openstack%2Fnova~master~Ia738a0972b050f549f446c85171d3f33e60ada4f,openstack/nova,master,Ia738a0972b050f549f446c85171d3f33e60ada4f,Handle InstanceInvalidState exception,MERGED,2022-10-18 10:56:36.000000000,2023-01-26 12:43:09.000000000,2023-01-26 12:41:37.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-18 10:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11aedb93cd2f036399f1dca89bdf744c59e120f0', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}, {'number': 2, 'created': '2023-01-19 12:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7eb0b946b834abeb6753fca43c5a78ca5b40e83b', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}, {'number': 3, 'created': '2023-01-20 13:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a9ce11312413ba96e51a1f7094853aa71c1d629', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}, {'number': 4, 'created': '2023-01-23 07:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5f7f874b96f99d7902abe48067afe60e537c26be', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}, {'number': 5, 'created': '2023-01-23 09:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92da354171361ee082324c02e3ebd72aa243e757', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}, {'number': 6, 'created': '2023-01-23 11:06:52.000000000', 'files': ['nova/api/openstack/compute/remote_consoles.py', 'nova/tests/unit/api/openstack/compute/test_remote_consoles.py', 'nova/tests/functional/api_sample_tests/test_remote_consoles.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ec40d5aee34e9428e2a19231fc3df4d23d75b779', 'message': ""Handle InstanceInvalidState exception\n\nWhen instance task state is 'deleting' or 'migrating', then\nget_vnc_console throws 500 error, as InstanceInvalidState\nexception is not handled there.\n\nThis change handles InstanceInvalidState in api layer in\nget_vnc_console call.\n\nCloses-Bug: #1968618\nChange-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f\n""}]",7,861738,ec40d5aee34e9428e2a19231fc3df4d23d75b779,44,5,6,20733,,,0,"Handle InstanceInvalidState exception

When instance task state is 'deleting' or 'migrating', then
get_vnc_console throws 500 error, as InstanceInvalidState
exception is not handled there.

This change handles InstanceInvalidState in api layer in
get_vnc_console call.

Closes-Bug: #1968618
Change-Id: Ia738a0972b050f549f446c85171d3f33e60ada4f
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/861738/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/remote_consoles.py'],1,11aedb93cd2f036399f1dca89bdf744c59e120f0,lp_1968618," except exception.InstanceInvalidState as e: common.raise_http_conflict_for_instance_invalid_state( e, 'get_vnc_console', id)",,3,0
openstack%2Freleases~master~Idd3785e35e74ccbd3eb73a8c64e66f9ba5c8c7d1,openstack/releases,master,Idd3785e35e74ccbd3eb73a8c64e66f9ba5c8c7d1,[octavia-tempest-plugin] Tag wallaby-last,MERGED,2022-12-26 04:48:57.000000000,2023-01-26 12:43:07.000000000,2023-01-26 12:43:07.000000000,"[{'_account_id': 308}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29244}]","[{'number': 1, 'created': '2022-12-26 04:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/32747c7db623383dfd78583ee11cbbb7e77ceda9', 'message': ""[octavia-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: Idd3785e35e74ccbd3eb73a8c64e66f9ba5c8c7d1\n""}, {'number': 2, 'created': '2023-01-25 21:36:02.000000000', 'files': ['deliverables/wallaby/octavia-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/52b4a826b92900bc430fafbe9904873bca339512', 'message': ""[octavia-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' with the same hash of 2.2.0 tag.\n- I773627f5d25ea894b5fdaee4be45dd5196c3aed4\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: Idd3785e35e74ccbd3eb73a8c64e66f9ba5c8c7d1\n""}]",0,868585,52b4a826b92900bc430fafbe9904873bca339512,11,6,2,8556,,,0,"[octavia-tempest-plugin] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' with the same hash of 2.2.0 tag.
- I773627f5d25ea894b5fdaee4be45dd5196c3aed4

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: Idd3785e35e74ccbd3eb73a8c64e66f9ba5c8c7d1
",git fetch https://review.opendev.org/openstack/releases refs/changes/85/868585/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/octavia-tempest-plugin.yaml', 'deliverables/wallaby/octavia-tempest-plugin.yaml']",2,32747c7db623383dfd78583ee11cbbb7e77ceda9,wallaby-last, - version: wallaby-last projects: - repo: openstack/octavia-tempest-plugin hash: dddf6515ab4cec0d02255f17bb6a41660eca6289,,8,0
openstack%2Fsushy~master~I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4,openstack/sushy,master,I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4,workaround: requests verify handling if env is set,MERGED,2023-01-18 08:59:37.000000000,2023-01-26 12:31:06.000000000,2023-01-26 12:29:53.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-18 08:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/6c06cba5b6b4917d46189a8569c95fdfb8424555', 'message': 'bugfix: fix requests verify handling if env is set\n\nif the env REQUESTS_CA_BUNDLE is set the requests.Session() ignores the\nverify parameter. Therefore the verify parameter is moved directly into\nthe function call of request.\n\nWorkaround for https://github.com/psf/requests/issues/3829\n\nChange-Id: I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4\n'}, {'number': 2, 'created': '2023-01-20 08:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/6f349135f3a1cfd2a2db092d0e50da6c655ccd6a', 'message': 'bugfix: fix requests verify handling if env is set\n\nif the env REQUESTS_CA_BUNDLE is set the requests.Session() ignores the\nverify parameter. Therefore the verify parameter is moved directly into\nthe function call of request.\n\nWorkaround for https://github.com/psf/requests/issues/3829\n\nChange-Id: I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4\n'}, {'number': 3, 'created': '2023-01-20 09:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/26860eb3f450c888751dd37d720b6ee9c1321fc2', 'message': 'workaround: requests verify handling if env is set\n\nif the env REQUESTS_CA_BUNDLE is set the requests.Session() ignores the\nverify parameter. Therefore the verify parameter is moved directly into\nthe function call of request.\n\nWorkaround for https://github.com/psf/requests/issues/3829\n\nChange-Id: I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4\n'}, {'number': 4, 'created': '2023-01-20 09:44:12.000000000', 'files': ['sushy/connector.py', 'releasenotes/notes/workaround-sushy-requests-verify-handling-6879c273b651246f.yaml', 'sushy/tests/unit/test_connector.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/98c899997f4f7b7aaccf911c41655aad6548fe6c', 'message': 'workaround: requests verify handling if env is set\n\nif the env REQUESTS_CA_BUNDLE is set the requests.Session() ignores the\nverify parameter. Therefore the verify parameter is moved directly into\nthe function call of request.\n\nWorkaround for https://github.com/psf/requests/issues/3829\n\nChange-Id: I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4\n'}]",8,870888,98c899997f4f7b7aaccf911c41655aad6548fe6c,20,3,4,35540,,,0,"workaround: requests verify handling if env is set

if the env REQUESTS_CA_BUNDLE is set the requests.Session() ignores the
verify parameter. Therefore the verify parameter is moved directly into
the function call of request.

Workaround for https://github.com/psf/requests/issues/3829

Change-Id: I66dc7c4d90e5bd5e3d1b331cf1728f27dece6dd4
",git fetch https://review.opendev.org/openstack/sushy refs/changes/88/870888/1 && git format-patch -1 --stdout FETCH_HEAD,"['sushy/connector.py', 'sushy/tests/unit/test_connector.py']",2,6c06cba5b6b4917d46189a8569c95fdfb8424555,bugfix/requests-lib-verify-with-env-set," headers=self.headers, json=None, verify=True) headers=self.headers, json=None, allow_redirects=False, verify=True) json=self.data, headers=self.headers, verify=True) json=self.data, headers=self.headers, verify=True) headers=expected_headers, json=None, verify=True) json=self.data, headers=expected_headers, verify=True) headers=expected_headers, json=None, verify=True) headers=expected_headers, json=None, verify=True) headers=expected_headers, json=None, verify=True)"," headers=self.headers, json=None) headers=self.headers, json=None, allow_redirects=False) json=self.data, headers=self.headers) json=self.data, headers=self.headers) headers=expected_headers, json=None) json=self.data, headers=expected_headers) headers=expected_headers, json=None) headers=expected_headers, json=None) headers=expected_headers, json=None)",20,10
openstack%2Freleases~master~I1ce715f094761d29a281187ad74f94e79bf683e4,openstack/releases,master,I1ce715f094761d29a281187ad74f94e79bf683e4,[tempest] Tag wallaby-last,MERGED,2023-01-25 17:39:12.000000000,2023-01-26 12:03:41.000000000,2023-01-26 12:03:41.000000000,"[{'_account_id': 9708}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-25 17:39:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/c12b5ec71effa6cb8fb180c765a1bf06ff451cab', 'message': ""[tempest] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' with the same hash of tag 33.0.0 which marked\nthe end of support for stable/wallaby in Tempest.\n\n- https://review.opendev.org/c/openstack/releases/+/866857\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: I1ce715f094761d29a281187ad74f94e79bf683e4\n""}, {'number': 2, 'created': '2023-01-25 17:39:32.000000000', 'files': ['deliverables/wallaby/tempest.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3ed3467443a79539c4f1a84ee9e4e2c46fe5f369', 'message': ""[tempest] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' with the same hash of tag 33.0.0 which marked\nthe end of support for stable/wallaby in Tempest.\n\n- https://review.opendev.org/c/openstack/releases/+/866857\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: I1ce715f094761d29a281187ad74f94e79bf683e4\n""}]",3,871746,3ed3467443a79539c4f1a84ee9e4e2c46fe5f369,11,5,2,8556,,,0,"[tempest] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' with the same hash of tag 33.0.0 which marked
the end of support for stable/wallaby in Tempest.

- https://review.opendev.org/c/openstack/releases/+/866857

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: I1ce715f094761d29a281187ad74f94e79bf683e4
",git fetch https://review.opendev.org/openstack/releases refs/changes/46/871746/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/wallaby/tempest.yaml'],1,c12b5ec71effa6cb8fb180c765a1bf06ff451cab,wallaby-last, - projects: - repo: openstack/tempest hash: 1580f6f8437bd07e008ce8451388765d4b9b268f version: wallaby-last ,,5,0
openstack%2Freleases~master~Id8afe820572f51d093db8232f2cba45220a8e879,openstack/releases,master,Id8afe820572f51d093db8232f2cba45220a8e879,[trove-tempest-plugin] Tag wallaby-last,MERGED,2022-12-26 01:15:50.000000000,2023-01-26 12:00:58.000000000,2023-01-26 12:00:58.000000000,"[{'_account_id': 6732}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28522}]","[{'number': 1, 'created': '2022-12-26 01:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/423c7fa77840aff8cd7cf6f1e024a79634cd1071', 'message': ""[trove-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: Id8afe820572f51d093db8232f2cba45220a8e879\n""}, {'number': 2, 'created': '2023-01-25 21:38:18.000000000', 'files': ['deliverables/antelope/trove-tempest-plugin.yaml', 'deliverables/wallaby/trove-tempest-plugin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ad0627fa0cf9169a0843d97fdc4056f9db5645a5', 'message': ""[trove-tempest-plugin] Tag wallaby-last\n\nWallaby branch is in Extended Maintenance now[1]. Tempest and\ntempest plugins are branchless which means master version of\nTempest and its plugins is used to test the supported stable\nbranches.\n\nOnce any stable branch is moved to EM state then, Tempest and\nits plugins compatible tag[2] needs to be released so that we can\nkeep testing the EM stable branches with that tag once master\nTempest and its plugins are not compatible[3].\n\nTagging 'wallaby-last' as well as a new version also with same hash.\n\n[1] https://releases.openstack.org/wallaby/index.html\n[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html\n[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html\n\nChange-Id: Id8afe820572f51d093db8232f2cba45220a8e879\n""}]",6,868544,ad0627fa0cf9169a0843d97fdc4056f9db5645a5,16,5,2,8556,,,0,"[trove-tempest-plugin] Tag wallaby-last

Wallaby branch is in Extended Maintenance now[1]. Tempest and
tempest plugins are branchless which means master version of
Tempest and its plugins is used to test the supported stable
branches.

Once any stable branch is moved to EM state then, Tempest and
its plugins compatible tag[2] needs to be released so that we can
keep testing the EM stable branches with that tag once master
Tempest and its plugins are not compatible[3].

Tagging 'wallaby-last' as well as a new version also with same hash.

[1] https://releases.openstack.org/wallaby/index.html
[2] https://docs.openstack.org/tempest/latest/stable_branch_support_policy.html
[3] https://docs.openstack.org/tempest/latest/tempest_and_plugins_compatible_version_policy.html

Change-Id: Id8afe820572f51d093db8232f2cba45220a8e879
",git fetch https://review.opendev.org/openstack/releases refs/changes/44/868544/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/antelope/trove-tempest-plugin.yaml', 'deliverables/wallaby/trove-tempest-plugin.yaml']",2,423c7fa77840aff8cd7cf6f1e024a79634cd1071,wallaby-last, - version: wallaby-last projects: - repo: openstack/trove-tempest-plugin hash: fe377e07847a515e34274b9173e37fde71a38c4d,,9,0
openstack%2Freleases~master~Iaabb1dffc61bc53a51ce1082519a898af6731afc,openstack/releases,master,Iaabb1dffc61bc53a51ce1082519a898af6731afc,Release octavia for stable/xena,MERGED,2023-01-16 16:19:53.000000000,2023-01-26 11:56:06.000000000,2023-01-26 11:56:06.000000000,"[{'_account_id': 308}, {'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 29244}]","[{'number': 1, 'created': '2023-01-16 16:19:53.000000000', 'files': ['deliverables/xena/octavia.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/91c12041791cd85a118d30be1cd83e7f75b76468', 'message': 'Release octavia for stable/xena\n\nThis release picks up new commits to octavia since\nthe last release from stable/xena.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\n$ git log --oneline --no-merges 9.0.1..c0b6f5c9\nfc55d6cf Increase TCP buffer maximum and MTU discovery\nbc2bded8 Handle feature compatibility of HAProxy server-state-file option\ne6dad97a Restart rsyslog from cloud-init in amphorav1\n980b8e79 Change FIPS jobs to centos-9-stream\n851510f4 Fix barbican client with application credentials/trusts\nc87ff96d Add *.orig to .gitignore\n9c8e5e03 Fix sporadic unit test failure\ncde823eb Update zuul queue configuration\n16fa7f8e Fix plugging member subnets on existing networks\nc513c9e7 Reconfigure amphora network interfaces seamlessly\n9311c825 Ignore status update on deleted objects in driver-agent\n15852b00 Cache subnets validation for batch member update\n81cb9d5e Fix bug when rolling back prov and op status for some API calls\n8b28293d Fix PortNotFound exception when updating a LB after a failover\n279bc0b6 Catch exceptions on I/O in driver-agent\n044de8e5 Apply openstack-selinux policies in Centos amphorae\naa1c69a5 Fix update/delete listener CA/CRL error\ne33414db Fix driver-agent cleanup\n11b9d8ae Move system scoped secure-RBAC to separate file\nc7aa79cd Fix HealthMonitorToErrorOnRevertTask revert method\n9ed984f8 Improve string representation of DB models\n4b87554b Fix potential race conditions on update requests in the v2 worker\n5647db94 Fix duplicate object error messages\n33eaff55 Set sensible nf_conntrack_max value in amphora\n7f960f0e Correct format of release note\nc30aa9df Validate L7Rule value and cookie name\nd668e1f2 Fix new pylint issues\n04207f60 Reject invalid whitespace in HM url_path value\nacd30aeb Remove unneeded sudo in lvs-masquerade.sh\n5997304d Fix compile_amphora_details when using UDP listeners\ndf1ecbda Deny the creation of L7Policies for HTTPS/TCP/UDP listeners\n7adeb21c Fix AttributeError in exception handler\nedcd6931 Save the HAProxy state outside of its systemd unit\n220f13f5 Restart rsyslog from cloud-init\n4e1cc209 Pass timeout_dict to _get_haproxy_versions\n5ade96be Fix Amphora RSyslog configuration for TCP failover\n903b9a76 Use centos amphora image in the FIPS jobs\n6958254a Fix ipv6 interface configuration\n887ffeae Fix unplugging member ports\n3a744f0c Fix amphora-agent elements for RHEL9\n2f9fe00e Optimize DB object to provider dict conversions\n9718e036 Fix detection of member operating status DRAIN\n28220096 Fix amphora build in CentOS Stream 9\n24ebc652 Preserve haproxy server states during reloads\nf78d7b0d Add fips jobs\n58eac3d9 Update scripts to use fips allowed algorithms\n987d6a34 Add keepalive for redis-based taskflow boards\nb47d5dfc Fix nft command line with negative priority values\n\nSigned-off-by: Herv Beraud <hberaud@redhat.com>\nChange-Id: Iaabb1dffc61bc53a51ce1082519a898af6731afc\n'}]",1,870632,91c12041791cd85a118d30be1cd83e7f75b76468,9,6,1,28522,,,0,"Release octavia for stable/xena

This release picks up new commits to octavia since
the last release from stable/xena.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

$ git log --oneline --no-merges 9.0.1..c0b6f5c9
fc55d6cf Increase TCP buffer maximum and MTU discovery
bc2bded8 Handle feature compatibility of HAProxy server-state-file option
e6dad97a Restart rsyslog from cloud-init in amphorav1
980b8e79 Change FIPS jobs to centos-9-stream
851510f4 Fix barbican client with application credentials/trusts
c87ff96d Add *.orig to .gitignore
9c8e5e03 Fix sporadic unit test failure
cde823eb Update zuul queue configuration
16fa7f8e Fix plugging member subnets on existing networks
c513c9e7 Reconfigure amphora network interfaces seamlessly
9311c825 Ignore status update on deleted objects in driver-agent
15852b00 Cache subnets validation for batch member update
81cb9d5e Fix bug when rolling back prov and op status for some API calls
8b28293d Fix PortNotFound exception when updating a LB after a failover
279bc0b6 Catch exceptions on I/O in driver-agent
044de8e5 Apply openstack-selinux policies in Centos amphorae
aa1c69a5 Fix update/delete listener CA/CRL error
e33414db Fix driver-agent cleanup
11b9d8ae Move system scoped secure-RBAC to separate file
c7aa79cd Fix HealthMonitorToErrorOnRevertTask revert method
9ed984f8 Improve string representation of DB models
4b87554b Fix potential race conditions on update requests in the v2 worker
5647db94 Fix duplicate object error messages
33eaff55 Set sensible nf_conntrack_max value in amphora
7f960f0e Correct format of release note
c30aa9df Validate L7Rule value and cookie name
d668e1f2 Fix new pylint issues
04207f60 Reject invalid whitespace in HM url_path value
acd30aeb Remove unneeded sudo in lvs-masquerade.sh
5997304d Fix compile_amphora_details when using UDP listeners
df1ecbda Deny the creation of L7Policies for HTTPS/TCP/UDP listeners
7adeb21c Fix AttributeError in exception handler
edcd6931 Save the HAProxy state outside of its systemd unit
220f13f5 Restart rsyslog from cloud-init
4e1cc209 Pass timeout_dict to _get_haproxy_versions
5ade96be Fix Amphora RSyslog configuration for TCP failover
903b9a76 Use centos amphora image in the FIPS jobs
6958254a Fix ipv6 interface configuration
887ffeae Fix unplugging member ports
3a744f0c Fix amphora-agent elements for RHEL9
2f9fe00e Optimize DB object to provider dict conversions
9718e036 Fix detection of member operating status DRAIN
28220096 Fix amphora build in CentOS Stream 9
24ebc652 Preserve haproxy server states during reloads
f78d7b0d Add fips jobs
58eac3d9 Update scripts to use fips allowed algorithms
987d6a34 Add keepalive for redis-based taskflow boards
b47d5dfc Fix nft command line with negative priority values

Signed-off-by: Herv Beraud <hberaud@redhat.com>
Change-Id: Iaabb1dffc61bc53a51ce1082519a898af6731afc
",git fetch https://review.opendev.org/openstack/releases refs/changes/32/870632/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/octavia.yaml'],1,91c12041791cd85a118d30be1cd83e7f75b76468,xena-stable, - version: 9.1.0 projects: - repo: openstack/octavia hash: c0b6f5c9ef07f777b10d952a70638c3e00e21c05,,4,0
openstack%2Freleases~master~I91081f465dc8cc65dfe31326cd349e179da569f9,openstack/releases,master,I91081f465dc8cc65dfe31326cd349e179da569f9,Cinder stable branch releases for CVE-2022-47951,MERGED,2023-01-24 19:23:36.000000000,2023-01-26 11:50:46.000000000,2023-01-26 11:50:46.000000000,"[{'_account_id': 308}, {'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 16137}, {'_account_id': 17685}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-24 19:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/66d829592226e220f224ed5dae3ab004f2ee66d2', 'message': 'Cinder stable branch releases for CVE-2022-4795\n\nChange-Id: I91081f465dc8cc65dfe31326cd349e179da569f9\n'}, {'number': 2, 'created': '2023-01-25 03:38:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/476ac9f3cae0bdaae9f71d568feb07fbb4b17dc3', 'message': 'Cinder stable branch releases for CVE-2022-47951\n\nChange-Id: I91081f465dc8cc65dfe31326cd349e179da569f9\n'}, {'number': 3, 'created': '2023-01-25 16:13:46.000000000', 'files': ['deliverables/xena/cinder.yaml', 'deliverables/yoga/cinder.yaml', 'deliverables/zed/cinder.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/6fe22e1e7272a6a3f9aaab03e914ac59895f4b82', 'message': 'Cinder stable branch releases for CVE-2022-47951\n\nChange-Id: I91081f465dc8cc65dfe31326cd349e179da569f9\n'}]",6,871656,6fe22e1e7272a6a3f9aaab03e914ac59895f4b82,22,8,3,9236,,,0,"Cinder stable branch releases for CVE-2022-47951

Change-Id: I91081f465dc8cc65dfe31326cd349e179da569f9
",git fetch https://review.opendev.org/openstack/releases refs/changes/56/871656/2 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/xena/cinder.yaml', 'deliverables/yoga/cinder.yaml', 'deliverables/zed/cinder.yaml']",3,66d829592226e220f224ed5dae3ab004f2ee66d2,CVE-2022-47951, - version: 21.1.0 projects: - repo: openstack/cinder hash: ????????????????????????????????????????,,12,0
openstack%2Freleases~master~I9eec31d6bb5d97182dd8990f8315cc1ba04cb30f,openstack/releases,master,I9eec31d6bb5d97182dd8990f8315cc1ba04cb30f,[xena][yoga][zed] Nova stable branch releases for CVE-2022-47951,MERGED,2023-01-25 22:26:16.000000000,2023-01-26 11:44:45.000000000,2023-01-26 11:44:45.000000000,"[{'_account_id': 308}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11604}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-25 22:26:16.000000000', 'files': ['deliverables/yoga/nova.yaml', 'deliverables/xena/nova.yaml', 'deliverables/zed/nova.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c0430665e29c5291189603ccab86de9d85f26338', 'message': '[xena][yoga][zed] Nova stable branch releases for CVE-2022-47951\n\nChange-Id: I9eec31d6bb5d97182dd8990f8315cc1ba04cb30f\n'}]",11,871802,c0430665e29c5291189603ccab86de9d85f26338,12,7,1,16137,,,0,"[xena][yoga][zed] Nova stable branch releases for CVE-2022-47951

Change-Id: I9eec31d6bb5d97182dd8990f8315cc1ba04cb30f
",git fetch https://review.opendev.org/openstack/releases refs/changes/02/871802/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/yoga/nova.yaml', 'deliverables/xena/nova.yaml', 'deliverables/zed/nova.yaml']",3,c0430665e29c5291189603ccab86de9d85f26338,CVE-2022-47951, - version: 26.1.0 projects: - repo: openstack/nova hash: 9bca7f34a0d1e546bff8e226cbe45ccbc520c878,,12,0
openstack%2Fkolla~master~I717b4f2215054ef9135a1ac252ed26820bdcb1aa,openstack/kolla,master,I717b4f2215054ef9135a1ac252ed26820bdcb1aa,Add util-linux to centos base packages,MERGED,2023-01-25 15:44:06.000000000,2023-01-26 11:19:51.000000000,2023-01-26 11:18:53.000000000,"[{'_account_id': 22348}, {'_account_id': 23084}, {'_account_id': 24072}]","[{'number': 1, 'created': '2023-01-25 15:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/49e8eb6cbee1a5eaac91cf389a554608f583e00f', 'message': 'Add util-linux to centos base packages\n\nCurrently /usr/sbin/nologin is missing, because util-linux\nis not installed in the image.\n\nChange-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa\n'}, {'number': 2, 'created': '2023-01-25 15:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/13dff46838f8f26950a6ff6aaca71d68d9997944', 'message': 'Add util-linux to centos base packages\n\nCurrently /usr/sbin/nologin is missing, because util-linux\nis not installed in the image.\n\nChange-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa\n'}, {'number': 3, 'created': '2023-01-25 15:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/54c90000638875cb6663243e78bc5a63f3c14ceb', 'message': 'Add util-linux to centos base packages\n\nCurrently /usr/sbin/nologin is missing, because util-linux\nis not installed in the image.\n\nChange-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa\n'}, {'number': 4, 'created': '2023-01-25 16:22:16.000000000', 'files': ['docker/base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1371e4fc5b9d3d55f5bb48540753f740f1d1af02', 'message': 'Add util-linux to centos base packages\n\nCurrently /usr/sbin/nologin is missing, because util-linux\nis not installed in the image.\n\nChange-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa\n'}]",2,871738,1371e4fc5b9d3d55f5bb48540753f740f1d1af02,14,3,4,22629,,,0,"Add util-linux to centos base packages

Currently /usr/sbin/nologin is missing, because util-linux
is not installed in the image.

Change-Id: I717b4f2215054ef9135a1ac252ed26820bdcb1aa
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/871738/4 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/Dockerfile.j2'],1,49e8eb6cbee1a5eaac91cf389a554608f583e00f,," 'util-linux',",,1,0
openstack%2Ftempest~master~Icd71a2962808628edb611257ac544f0277cde1f3,openstack/tempest,master,Icd71a2962808628edb611257ac544f0277cde1f3,tempest cleanup - don't initialize admin id's,MERGED,2023-01-18 12:31:24.000000000,2023-01-26 11:19:19.000000000,2023-01-26 11:18:14.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-18 12:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b4b66169f1de341b3290c87f2659b317fcd9b10c', 'message': ""tempest cleanup - don't initialize admin id's\n\nTempest cleanup gathers the project, user, and role id. Since\ncommit a857880423, this info is collected but not used. In\nspecific cases this method raises an error so it's better to\nremove it.\n\nCloses-bug: #2003125\nChange-Id: Icd71a2962808628edb611257ac544f0277cde1f3\n""}, {'number': 2, 'created': '2023-01-20 13:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bd1ded507d029b360e200ccbc6b1b1cefeeb5a8b', 'message': ""tempest cleanup - don't initialize admin id's\n\nTempest cleanup gathers the project, user, and role id. Since\ncommit a857880423, this info is collected but not used. In\nspecific cases this method raises an error so it's better to\nremove it.\n\nCloses-bug: #2003125\nChange-Id: Icd71a2962808628edb611257ac544f0277cde1f3\n""}, {'number': 3, 'created': '2023-01-24 12:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/22e3e6c74281dd407997fe52882230d6a9f583dc', 'message': ""tempest cleanup - don't initialize admin id's\n\nTempest cleanup gathers the project, user, and role id. Since\ncommit a857880423, this info is collected but not used. In\nspecific cases this method raises an error so it's better to\nremove it.\n\nCloses-bug: #2003125\nChange-Id: Icd71a2962808628edb611257ac544f0277cde1f3\n""}, {'number': 4, 'created': '2023-01-25 14:17:20.000000000', 'files': ['tempest/cmd/cleanup.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b40d2d55b4e782fe2c10c297c4650b888ad01947', 'message': ""tempest cleanup - don't initialize admin id's\n\nTempest cleanup gathers the project, user, and role id. Since\ncommit a857880423, this info is collected but not used. In\nspecific cases this method raises an error so it's better to\nremove it.\n\nCloses-bug: #2003125\nChange-Id: Icd71a2962808628edb611257ac544f0277cde1f3\n""}]",9,870930,b40d2d55b4e782fe2c10c297c4650b888ad01947,29,3,4,35087,,,0,"tempest cleanup - don't initialize admin id's

Tempest cleanup gathers the project, user, and role id. Since
commit a857880423, this info is collected but not used. In
specific cases this method raises an error so it's better to
remove it.

Closes-bug: #2003125
Change-Id: Icd71a2962808628edb611257ac544f0277cde1f3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/30/870930/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/cmd/cleanup.py'],1,b4b66169f1de341b3290c87f2659b317fcd9b10c,,,"from tempest.common import identity self._init_admin_ids() def _init_admin_ids(self): pr_cl = self.admin_mgr.projects_client rl_cl = self.admin_mgr.roles_v3_client rla_cl = self.admin_mgr.role_assignments_client us_cl = self.admin_mgr.users_v3_client project = identity.get_project_by_name(pr_cl, CONF.auth.admin_project_name) self.admin_project_id = project['id'] user = identity.get_user_by_project(us_cl, rla_cl, self.admin_project_id, CONF.auth.admin_username) self.admin_id = user['id'] roles = rl_cl.list_roles()['roles'] for role in roles: if role['name'] == CONF.identity.admin_role: self.admin_role_id = role['id'] break ",0,22
openstack%2Fopenstack-manuals~master~Ie5d9d977dba1aba308f17682609cfe7b82cc3153,openstack/openstack-manuals,master,Ie5d9d977dba1aba308f17682609cfe7b82cc3153,Add OpenStack-Ansible deploy guide for Zed,MERGED,2023-01-23 10:38:32.000000000,2023-01-26 11:01:25.000000000,2023-01-26 10:09:26.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 10:38:32.000000000', 'files': ['www/project-data/zed.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/812e4f563ed8f331f5363a5f258667aa0bb967c8', 'message': 'Add OpenStack-Ansible deploy guide for Zed\n\nChange-Id: Ie5d9d977dba1aba308f17682609cfe7b82cc3153\n'}]",0,871460,812e4f563ed8f331f5363a5f258667aa0bb967c8,7,2,1,28619,,,0,"Add OpenStack-Ansible deploy guide for Zed

Change-Id: Ie5d9d977dba1aba308f17682609cfe7b82cc3153
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/60/871460/1 && git format-patch -1 --stdout FETCH_HEAD,['www/project-data/zed.yaml'],1,812e4f563ed8f331f5363a5f258667aa0bb967c8,,- name: openstack-ansible type: deployment service: OpenStack-Ansible Deployment has_admin_guide: true has_user_guide: true has_deployment_guide: true, #- name: openstack-ansible # type: deployment # service: OpenStack-Ansible Deployment # has_admin_guide: true # has_user_guide: true # has_deployment_guide: true,6,7
openstack%2Fbifrost~master~I8ac33d0aa0f71b092d2c0538ac3a73491ff44921,openstack/bifrost,master,I8ac33d0aa0f71b092d2c0538ac3a73491ff44921,Support PXE network boot with grub,MERGED,2021-09-02 22:59:47.000000000,2023-01-26 10:52:40.000000000,2023-01-26 10:50:51.000000000,"[{'_account_id': 4571}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2021-09-02 22:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/583c9c9679fff2c3e4a5e21cdf40bfeda2345fe4', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 2, 'created': '2021-09-03 02:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/32b62a54602db88c54f14d1c296885579c5e4c30', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 3, 'created': '2021-09-05 22:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/408643884f8217ed63a8e74c91e8c22c4437fd6e', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 4, 'created': '2021-09-09 01:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/63bcf5ef9077a3097acc31c6beb733d6a6746e34', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 5, 'created': '2021-09-09 20:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/5528dd8314629da6ebe497217231dfa9ab478526', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 6, 'created': '2021-09-10 00:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/263e24e214b1599735df8f5e382366291a2c6746', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 7, 'created': '2021-09-13 21:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d8e238584cf9ef79095ba9378156f4527b9ff2ac', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 8, 'created': '2021-09-14 01:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/76b48e1547eb562525c1b9b9b7ba9274057017f2', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 9, 'created': '2021-09-14 05:04:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/89cd73dd34ea966aae8d698c5b3072d4fae2a6a7', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 10, 'created': '2021-09-15 23:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d617e26e19518d6d5116aee1f7b1bd0e3e8081e0', 'message': 'WIP support grub network boot\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/809295\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 11, 'created': '2021-09-20 23:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b00b3be5f67937b8eaea3c10577604ef48004e57', 'message': 'WIP support grub network boot\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/809295\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 12, 'created': '2021-11-22 04:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/32bafdc12e1d9150c5cd5a98e3eaf6a0b89d8a6c', 'message': 'WIP support grub network boot\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/809295\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 13, 'created': '2021-11-22 04:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/71f16f30a240637c4de5df60f0af501ff8982972', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 14, 'created': '2021-11-22 04:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/03630a187ca77c3730fa86b03d2e6f534e2f7970', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 15, 'created': '2021-11-23 20:27:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/f47053e9b0d47b70c07f31f1f431106aacb1ecc4', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 16, 'created': '2021-11-23 20:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/a3330de95074663f1f22e59b26a61d44629443b9', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 17, 'created': '2021-11-24 03:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/b5b077c4d64e21b7b62b22ba74ef2e884b5063a0', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 18, 'created': '2021-11-25 21:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/2b03bdef9a997c8b300e4e9f0990cf744aabe337', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 19, 'created': '2021-11-26 01:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/89c364e9ca4e9d02b9988cc877e4250a31cea06b', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 20, 'created': '2021-11-26 02:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3d55bfc7568e352371bb8edf33689c2b6a3c25e3', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 21, 'created': '2021-11-30 01:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/bcbfc493bc51045bc08bba83bdc098fd9edf0762', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 22, 'created': '2021-11-30 04:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/916aa145bc47a454bfcd96b2d25c5ba17094b1d7', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 23, 'created': '2021-11-30 22:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1fa4bd61cf0ee1816dd0ea23bffa35c4d2b1c72f', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 24, 'created': '2021-12-03 03:27:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/52dbb2f0a92f602a6334fc13b74fb9a5533bd537', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 25, 'created': '2021-12-05 21:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/c90c5aafa01d66bc5dc1926dc9cb85cec8e3cf3e', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 26, 'created': '2021-12-06 23:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/07c2478da94169a62e605802777435021dbe780c', 'message': 'WIP support grub network boot\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 27, 'created': '2021-12-08 00:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0895d1b79acbef57637359804af621913c2883ad', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 28, 'created': '2021-12-14 00:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0aab55af29875fd621803f3fd6a90a07774b886f', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/821363\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 29, 'created': '2021-12-20 00:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d5f819d4751e4cfc1aa993af827d98ac31f384ee', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis change includes the enablement of passwordless sudo for the\nprivsep-helper to enable copying root readable files.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nDepends-On: https://review.opendev.org/c/openstack/ironic/+/821363\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 30, 'created': '2022-05-16 02:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/60b5dfa5111048fd7b15b17e4171c24706ebb6b5', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 31, 'created': '2022-05-16 05:16:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/4c50b6bdb29677af2d9065c0b0dab8e037d004a2', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 32, 'created': '2022-05-16 21:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/93e71dbcaa2384f874a3cbe2d213fd2ed6b01bf9', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 33, 'created': '2022-07-11 00:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/dfa0f0a62f790d2ee486fb4236762f8a9d10f261', 'message': 'WIP Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``enable_uefi_ipxe`` set to ``false`` and use the ``pxe`` boot\ninterface when deploying nodes.\n\n(WIP this will be reworked to remove enable_uefi_ipxe)\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 34, 'created': '2022-07-11 02:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/3d7657281056836623cc1e7d3cec4953fcedccce', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 35, 'created': '2022-07-11 02:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/25c57cf57b7ab5823ed3fe9d5024678c1bddee1f', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 36, 'created': '2022-07-11 03:06:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/91144b7fb337e3e296e08d38654a6dcd8d31252e', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 37, 'created': '2022-07-11 03:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/07c436fbcbbe56dbdcc3c1be868f621f62b82a43', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 38, 'created': '2022-07-11 23:38:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/ed77e2fd1d4890fd50680377946d53af41f693e8', 'message': 'Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n'}, {'number': 39, 'created': '2022-07-12 02:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d71d7df9afc49221aaa2b0e10e3df3aeaed25d95', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 40, 'created': '2022-07-12 03:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/82e5b2c0bc32c13e9f6bb6d542d7c96328d62a61', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 41, 'created': '2022-07-12 05:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/2be11c046cff1159722d0e26b68c6d0ff4d1645a', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 42, 'created': '2022-08-01 00:54:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/baf43ee3dd2883ae6395ef533c4933819d40f188', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 43, 'created': '2022-10-27 19:51:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/d549aa99de5f0312fd618698b9195d70ec7f16fd', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 44, 'created': '2022-11-16 20:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/425391c30b1fbe71c0816feab7c0d4227b7efbb2', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 45, 'created': '2022-11-17 02:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/eb922141d8a948e7fc2275f91b4bfce03ada9cbb', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}, {'number': 46, 'created': '2023-01-18 21:33:38.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'releasenotes/notes/grub-network-boot-a27beef089e041ef.yaml', 'playbooks/ci/run.yaml', 'zuul.d/bifrost-jobs.yaml', 'scripts/test-bifrost.sh'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/51d988af5408a5c0a63c1f0562d614e3112c1a79', 'message': ""Support PXE network boot with grub\n\nIt is now possible to do a PXE network boot with grub as an\nalternative to iPXE. Grub is loaded via the signed shim, so it may\nallow end-to-end automated deployments with secure-boot enabled.\n\nTo use grub network boot, deploy bifrost with variable\n``default_boot_interface`` set to ``pxe``.\n\nThis feature is tested by job\nbifrost-integration-redfish-uefi-fedora-latest.\n\ntest-bifrost.sh is also modified to only enable the hardware-type\ndriver which matches driver used for test nodes. This allows a default\ninterface to be set which is not supported by one of the enabled\ndrivers (for example, ironic will exit because the ilo driver doesn't\nsupport the pxe boot interface)\n\nChange-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921\n""}]",27,807220,51d988af5408a5c0a63c1f0562d614e3112c1a79,125,6,46,4571,,,0,"Support PXE network boot with grub

It is now possible to do a PXE network boot with grub as an
alternative to iPXE. Grub is loaded via the signed shim, so it may
allow end-to-end automated deployments with secure-boot enabled.

To use grub network boot, deploy bifrost with variable
``default_boot_interface`` set to ``pxe``.

This feature is tested by job
bifrost-integration-redfish-uefi-fedora-latest.

test-bifrost.sh is also modified to only enable the hardware-type
driver which matches driver used for test nodes. This allows a default
interface to be set which is not supported by one of the enabled
drivers (for example, ironic will exit because the ilo driver doesn't
support the pxe boot interface)

Change-Id: I8ac33d0aa0f71b092d2c0538ac3a73491ff44921
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/20/807220/40 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/defaults/required_defaults_CentOS.yml', 'playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'playbooks/roles/bifrost-ironic-install/templates/grub.cfg.j2', 'playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Fedora.yml', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Debian_family.yml', 'playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Suse_family.yml', 'playbooks/roles/bifrost-ironic-install/defaults/required_defaults_RedHat.yml', 'playbooks/roles/bifrost-ironic-install/tasks/create_tftpboot.yml']",9,583c9c9679fff2c3e4a5e21cdf40bfeda2345fe4,grub-network,"- name: ""Set up grub for network booting"" block: - name: ""Copy shim EFI binary into {{ tftp_boot_folder }}"" copy: src: ""{{ shim_efi_binary }}"" dest: ""{{ tftp_boot_folder }}/bootx64.efi"" owner: ironic group: ironic mode: 0644 remote_src: true - name: ""Copy grub EFI binary into {{ tftp_boot_folder }}"" copy: src: ""{{ grub_efi_binary }}"" dest: ""{{ tftp_boot_folder }}/grubx64.efi"" owner: ironic group: ironic mode: 0644 remote_src: true - name: ""Create tftp grub directory"" file: path: ""{{ tftp_boot_folder }}/{{ grub_tftp_dir }}"" state: directory owner: ironic group: ironic mode: 0755 - name: ""Write grub.cfg"" template: src: grub.cfg.j2 dest: ""{{ tftp_boot_folder }}/{{ grub_tftp_dir }}/grub.cfg"" owner: ironic group: ironic mode: 0644 when: not enable_uefi_ipxe | bool ",,52,3
openstack%2Fopenstack-manuals~master~Ia1ddf731ba0370757ea980356a089b2296f11eb5,openstack/openstack-manuals,master,Ia1ddf731ba0370757ea980356a089b2296f11eb5,[www] Set Queens series state as End of Life,MERGED,2023-01-24 09:46:24.000000000,2023-01-26 10:43:44.000000000,2023-01-26 10:09:23.000000000,"[{'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 09:46:24.000000000', 'files': ['tools/www-generator.py'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/05b7a93d25b17ae32e07b3bffb3e043b6633caca', 'message': ""[www] Set Queens series state as End of Life\n\nQueens was proposed to transition to End of Life [1] and since all of\nthe projects have EOL'd their stable/queens branches, we are ready to\nset Queens status to EOL on docs.openstack.org.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html\n\nChange-Id: Ia1ddf731ba0370757ea980356a089b2296f11eb5\n""}]",0,871587,05b7a93d25b17ae32e07b3bffb3e043b6633caca,8,3,1,17685,,,0,"[www] Set Queens series state as End of Life

Queens was proposed to transition to End of Life [1] and since all of
the projects have EOL'd their stable/queens branches, we are ready to
set Queens status to EOL on docs.openstack.org.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html

Change-Id: Ia1ddf731ba0370757ea980356a089b2296f11eb5
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/87/871587/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/www-generator.py'],1,05b7a93d25b17ae32e07b3bffb3e043b6633caca,queens-eol," 'queens': SeriesInfo(date='March 2018', status='EOL'),"," 'queens': SeriesInfo(date='March 2018', status='extended-maintenance'),",1,1
openstack%2Fironic~master~I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,openstack/ironic,master,I568b14097cd46d4d7d365ff894ef5cd29edd1e3a,Make reno ignore bugfix eol tags,MERGED,2023-01-25 21:21:53.000000000,2023-01-26 10:20:58.000000000,2023-01-26 10:19:13.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-25 21:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8d5507f60eb37a78f31811a07e6bf4e332bf9333', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n""}, {'number': 2, 'created': '2023-01-25 21:56:53.000000000', 'files': ['reno.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b63d15ccdb7202af1700ce4f35b892c989356d7a', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a\n""}]",1,871787,b63d15ccdb7202af1700ce4f35b892c989356d7a,13,3,2,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I568b14097cd46d4d7d365ff894ef5cd29edd1e3a
",git fetch https://review.opendev.org/openstack/ironic refs/changes/87/871787/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,8d5507f60eb37a78f31811a07e6bf4e332bf9333,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fopenstack-zuul-jobs~master~I2a41f6399d1063125c22885fa89dc022b78037e6,openstack/openstack-zuul-jobs,master,I2a41f6399d1063125c22885fa89dc022b78037e6,Clean up queens branch filters,MERGED,2023-01-24 11:30:54.000000000,2023-01-26 10:07:09.000000000,2023-01-26 10:05:25.000000000,"[{'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 11:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/6b91bc05b2dbe1f6a763849d8cbb42e811a910b9', 'message': ""Clean up queens branch filters\n\nQueens transitioned to End of Life [1] so let's remove all\nstable/queens related filters from the zuul jobs.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html\n\nChange-Id: I2a41f6399d1063125c22885fa89dc022b78037e6\n""}, {'number': 2, 'created': '2023-01-24 11:45:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/e8dca5b113816657b3c93cc889fdff41e2409cff', 'message': ""Clean up queens branch filters\n\nQueens transitioned to End of Life [1] so let's remove all\nstable/queens related filters from the zuul jobs.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html\n\nChange-Id: I2a41f6399d1063125c22885fa89dc022b78037e6\n""}, {'number': 3, 'created': '2023-01-24 12:45:34.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/791854227d2b5c6d69c6f9ca8e4cd83aa14c2a62', 'message': ""Clean up queens branch filters\n\nQueens transitioned to End of Life [1] so let's remove all\nstable/queens related filters from the zuul jobs.\n\n[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html\n\nChange-Id: I2a41f6399d1063125c22885fa89dc022b78037e6\n""}]",2,871596,791854227d2b5c6d69c6f9ca8e4cd83aa14c2a62,16,3,3,17685,,,0,"Clean up queens branch filters

Queens transitioned to End of Life [1] so let's remove all
stable/queens related filters from the zuul jobs.

[1] https://lists.openstack.org/pipermail/openstack-discuss/2022-November/031323.html

Change-Id: I2a41f6399d1063125c22885fa89dc022b78037e6
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/96/871596/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,6b91bc05b2dbe1f6a763849d8cbb42e811a910b9,queens-eol, branches: stable/rocky branches: ^(?!stable/(rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/rocky. This branches: ^(?!stable/rocky).*$ This job runs on Xenial for stable/rocky. This branches: ^(?!stable/(rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/rocky. This branches: ^(?!stable/(rocky|stein|train|ussuri)).*$ branches: ^(?!stable/(rocky|stein|train|ussuri)).*$ branches: ^(?!stable/(rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/rocky. This This job runs on Xenial and this is for stable/rocky. This job is prepared to make sure all stable branches branches: ^(?!stable/rocky).*$ stable/rocky. This job is prepared to branches: ^(?!stable/rocky).*$ each other. This job runs on Xenial for stable/rocky. This job is prepared to make sure all stable branches branches: ^(?!stable/rocky).*$ This job runs on Xenial for stable/rocky. This job is prepared to make sure all stable branches branches: ^(?!stable/rocky).*$, branches: ^stable/(queens|rocky).*$ branches: ^(?!stable/(queens|rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/queens and rocky. This - stable/queens branches: ^(?!stable/(queens|rocky)).*$ This job runs on Xenial for stable/queens and rocky. This - stable/queens branches: ^(?!stable/(queens|rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/queens and rocky. This - stable/queens branches: ^(?!stable/(queens|rocky|stein|train|ussuri)).*$ - stable/queens branches: ^(?!stable/(queens|rocky|stein|train|ussuri)).*$ - stable/queens branches: ^(?!stable/(queens|rocky|stein|train|ussuri)).*$ This job runs on Xenial for stable/queens and rocky. This - stable/queens This job runs on Xenial and this is for stable/queens and rocky. This job is prepared to make sure all stable branches - stable/queens branches: ^(?!stable/(queens|rocky)).*$ stable/queens and rocky. This job is prepared to - stable/queens branches: ^(?!stable/(queens|rocky)).*$ each other. This job runs on Xenial for stable/queens and rocky. This job is prepared to make sure all stable branches - stable/queens branches: ^(?!stable/(queens|rocky)).*$ This job runs on Xenial for stable/queens and rocky. This job is prepared to make sure all stable branches - stable/queens branches: ^(?!stable/(queens|rocky)).*$,22,32
openstack%2Fcharm-neutron-gateway~stable%2Ftrain~I9599160503eb1bf6b8d24c91feb3180757e266d6,openstack/charm-neutron-gateway,stable/train,I9599160503eb1bf6b8d24c91feb3180757e266d6,Pin tox to < 4.0.0,MERGED,2023-01-13 20:23:21.000000000,2023-01-26 09:42:57.000000000,2023-01-26 09:42:57.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:23:21.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/8b6621f884e8b03a4cc6cfa7ad3c75ca2d9ce56c', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I9599160503eb1bf6b8d24c91feb3180757e266d6\n""}]",2,870410,8b6621f884e8b03a4cc6cfa7ad3c75ca2d9ce56c,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I9599160503eb1bf6b8d24c91feb3180757e266d6
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/10/870410/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8b6621f884e8b03a4cc6cfa7ad3c75ca2d9ce56c,pin-tox-train, tox < 4.0.0,,1,0
openstack%2Fcharm-neutron-gateway~stable%2Fussuri~I8b1f0dbc8c3552ee5f68305327e8fe7ab22d864e,openstack/charm-neutron-gateway,stable/ussuri,I8b1f0dbc8c3552ee5f68305327e8fe7ab22d864e,Pin tox to < 4.0.0,MERGED,2023-01-13 20:19:48.000000000,2023-01-26 09:42:56.000000000,2023-01-26 09:42:56.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:19:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/e323e2ce50589bef5cc560ca7ddc1e370b150d22', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I8b1f0dbc8c3552ee5f68305327e8fe7ab22d864e\n""}]",5,870362,e323e2ce50589bef5cc560ca7ddc1e370b150d22,16,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I8b1f0dbc8c3552ee5f68305327e8fe7ab22d864e
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/62/870362/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e323e2ce50589bef5cc560ca7ddc1e370b150d22,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-masakari-monitors~stable%2Fussuri~I02f44576b8cc9a54cbd9217f50a561c13983f4ac,openstack/charm-masakari-monitors,stable/ussuri,I02f44576b8cc9a54cbd9217f50a561c13983f4ac,Pin tox to < 4.0.0,MERGED,2023-01-13 20:19:28.000000000,2023-01-26 09:41:13.000000000,2023-01-26 09:41:13.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:19:28.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-masakari-monitors/commit/9d797c5438d86ab8e9f49db4c695a0f3e96d064f', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I02f44576b8cc9a54cbd9217f50a561c13983f4ac\n""}]",10,870357,9d797c5438d86ab8e9f49db4c695a0f3e96d064f,24,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I02f44576b8cc9a54cbd9217f50a561c13983f4ac
",git fetch https://review.opendev.org/openstack/charm-masakari-monitors refs/changes/57/870357/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9d797c5438d86ab8e9f49db4c695a0f3e96d064f,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-masakari-monitors~stable%2Fvictoria~Ib114327565b05f04a6b6804bf2c51b669454d7e3,openstack/charm-masakari-monitors,stable/victoria,Ib114327565b05f04a6b6804bf2c51b669454d7e3,Pin tox to < 4.0.0,MERGED,2023-01-13 20:15:50.000000000,2023-01-26 09:41:11.000000000,2023-01-26 09:41:11.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:15:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-masakari-monitors/commit/2a9f8036ad3371d5e0f8834c3052ed73eb3106b8', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ib114327565b05f04a6b6804bf2c51b669454d7e3\n""}]",3,870306,2a9f8036ad3371d5e0f8834c3052ed73eb3106b8,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ib114327565b05f04a6b6804bf2c51b669454d7e3
",git fetch https://review.opendev.org/openstack/charm-masakari-monitors refs/changes/06/870306/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2a9f8036ad3371d5e0f8834c3052ed73eb3106b8,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fcharm-octavia~stable%2Fussuri~Ie42014b415324a3964a50e74cf04beeb298d7d06,openstack/charm-octavia,stable/ussuri,Ie42014b415324a3964a50e74cf04beeb298d7d06,Pin tox to < 4.0.0,MERGED,2023-01-13 20:20:08.000000000,2023-01-26 09:38:38.000000000,2023-01-26 09:38:38.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 34352}]","[{'number': 1, 'created': '2023-01-13 20:20:08.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/13ba5787f17518c3cde67abd026157bfd5152bc4', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ie42014b415324a3964a50e74cf04beeb298d7d06\n""}]",6,870367,13ba5787f17518c3cde67abd026157bfd5152bc4,19,5,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ie42014b415324a3964a50e74cf04beeb298d7d06
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/67/870367/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,13ba5787f17518c3cde67abd026157bfd5152bc4,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-octavia~stable%2Fvictoria~Ibce01340a6821f47e5b99f1e59ddd632d6170147,openstack/charm-octavia,stable/victoria,Ibce01340a6821f47e5b99f1e59ddd632d6170147,Pin tox to < 4.0.0,MERGED,2023-01-13 20:16:34.000000000,2023-01-26 09:38:37.000000000,2023-01-26 09:38:37.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:16:34.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/eb6541cc0b86e4526a213790d3050ad1bab130d3', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ibce01340a6821f47e5b99f1e59ddd632d6170147\n""}]",6,870317,eb6541cc0b86e4526a213790d3050ad1bab130d3,18,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ibce01340a6821f47e5b99f1e59ddd632d6170147
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/17/870317/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,eb6541cc0b86e4526a213790d3050ad1bab130d3,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fcharm-magnum~stable%2Fussuri~Ib17e1ca551bd5e24bfba1c3ec99e368da246f4d5,openstack/charm-magnum,stable/ussuri,Ib17e1ca551bd5e24bfba1c3ec99e368da246f4d5,Pin tox to < 4.0.0,MERGED,2023-01-13 20:18:56.000000000,2023-01-26 09:38:18.000000000,2023-01-26 09:38:18.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:18:56.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-magnum/commit/56ae86a86f5b8e986ee2527a487ea6b379bb1b9e', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ib17e1ca551bd5e24bfba1c3ec99e368da246f4d5\n""}]",3,870349,56ae86a86f5b8e986ee2527a487ea6b379bb1b9e,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ib17e1ca551bd5e24bfba1c3ec99e368da246f4d5
",git fetch https://review.opendev.org/openstack/charm-magnum refs/changes/49/870349/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,56ae86a86f5b8e986ee2527a487ea6b379bb1b9e,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-glance~stable%2Fussuri~I249502fa24668f1dad9a5220f81cab54614a8b16,openstack/charm-glance,stable/ussuri,I249502fa24668f1dad9a5220f81cab54614a8b16,Pin tox to < 4.0.0,MERGED,2023-01-13 20:18:15.000000000,2023-01-26 09:38:15.000000000,2023-01-26 09:38:15.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:18:15.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/e412d0b67f8e5ee20dccca0340ab4374b3abd227', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I249502fa24668f1dad9a5220f81cab54614a8b16\n""}]",3,870339,e412d0b67f8e5ee20dccca0340ab4374b3abd227,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I249502fa24668f1dad9a5220f81cab54614a8b16
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/39/870339/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e412d0b67f8e5ee20dccca0340ab4374b3abd227,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fopenstacksdk~master~I7ea63b2cdda881c621cbb0e212479328a96e73bd,openstack/openstacksdk,master,I7ea63b2cdda881c621cbb0e212479328a96e73bd,Convert cloud layer to use COE proxy layer,MERGED,2022-11-22 11:36:23.000000000,2023-01-26 09:34:24.000000000,2023-01-26 09:33:19.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-22 11:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b72f50bf565a0f12ac254856d9ef5038e40643d2', 'message': ""WIP: Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nWIP because tests need updating and the 'update' method hasn't been\nconverted yet.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 2, 'created': '2023-01-23 17:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a2c217779f6a32eca1bb8f46b2088c75ddfa3511', 'message': ""WIP: Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 3, 'created': '2023-01-24 17:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/423e8db520a4d743d1abf7114a44fb3d6e6e5b80', 'message': ""Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 4, 'created': '2023-01-25 14:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c0c7b925395f063b6397c7206c410e1be733f585', 'message': ""Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 5, 'created': '2023-01-25 19:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/1b7c1fe24797132c7974e2be9b2f2760ef020538', 'message': ""Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}, {'number': 6, 'created': '2023-01-25 19:46:21.000000000', 'files': ['openstack/cloud/_coe.py', 'openstack/tests/unit/cloud/test_coe_clusters.py', 'openstack/tests/unit/container_infrastructure_management/v1/test_proxy.py', 'openstack/container_infrastructure_management/v1/cluster.py', 'openstack/tests/functional/cloud/test_magnum_services.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/289e5c2d3cba0eb1c008988ae5dccab5be05d9b6', 'message': ""Convert cloud layer to use COE proxy layer\n\nWe only have the Cluster resource modelled thus far, so that is all\nthat's converted.\n\nChange-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",2,865267,289e5c2d3cba0eb1c008988ae5dccab5be05d9b6,16,2,6,15334,,,0,"Convert cloud layer to use COE proxy layer

We only have the Cluster resource modelled thus far, so that is all
that's converted.

Change-Id: I7ea63b2cdda881c621cbb0e212479328a96e73bd
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/67/865267/6 && git format-patch -1 --stdout FETCH_HEAD,['openstack/cloud/_coe.py'],1,b72f50bf565a0f12ac254856d9ef5038e40643d2,coe-gaps," """"""List COE (Container Orchestration Engine) cluster. :returns: A list of container infrastructure management ``Cluster`` objects. return self.container_infrastructure_management.clusters() def search_coe_clusters(self, name_or_id=None, filters=None): :returns: A list of container infrastructure management ``Cluster`` objects. return _utils._filter_list(coe_clusters, name_or_id, filters) :returns: A container infrastructure management ``Cluster`` object if found, else None. return _utils._get_entity(self, 'coe_cluster', name_or_id, filters) self, name, cluster_template_id, **kwargs, ): :param string cluster_template_id: ID of the cluster template to use. :param dict kwargs: Any other arguments to pass in. :returns: The created container infrastructure management ``Cluster`` object. cluster = self.cluster_infrastructure_management.create_cluster( name=name, cluster_template_id=cluster_template_id, **kwargs, ) return cluster exc_info=True, ) self.cluster_infrastructure_management.delete_cluster(cluster) self.list_coe_clusters.invalidate(self) # TODO(stephenfin): Convert this."," """"""List COE(Ccontainer Orchestration Engine) cluster. :returns: a list of dicts containing the cluster. with _utils.shade_exceptions(""Error fetching cluster list""): data = self._container_infra_client.get('/clusters') return self._normalize_coe_clusters( self._get_and_munchify('clusters', data)) def search_coe_clusters( self, name_or_id=None, filters=None): :returns: a list of dict containing the cluster return _utils._filter_list( coe_clusters, name_or_id, filters) :returns: A cluster dict or None if no matching cluster is found. return _utils._get_entity(self, 'coe_cluster', name_or_id, filters=filters) self, name, cluster_template_id, **kwargs): :param string image_id: ID of the cluster template to use. Other arguments will be passed in kwargs. error_message = (""Error creating cluster of name"" "" {cluster_name}"".format(cluster_name=name)) with _utils.shade_exceptions(error_message): body = kwargs.copy() body['name'] = name body['cluster_template_id'] = cluster_template_id cluster = self._container_infra_client.post( '/clusters', json=body) return self._normalize_coe_cluster(cluster) exc_info=True) with _utils.shade_exceptions(""Error in deleting COE cluster""): self._container_infra_client.delete( '/clusters/{id}'.format(id=cluster['id'])) self.list_coe_clusters.invalidate(self) ",28,36
openstack%2Fcharm-neutron-gateway~stable%2Fvictoria~I840f9d20a588d4a6d6dae0b33f61fd2bec71913b,openstack/charm-neutron-gateway,stable/victoria,I840f9d20a588d4a6d6dae0b33f61fd2bec71913b,Pin tox to < 4.0.0,MERGED,2023-01-13 20:16:13.000000000,2023-01-26 09:34:05.000000000,2023-01-26 09:34:05.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:16:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/d9c587397ad434a88f544c9343e9f28eebc75fad', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I840f9d20a588d4a6d6dae0b33f61fd2bec71913b\n""}]",3,870311,d9c587397ad434a88f544c9343e9f28eebc75fad,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I840f9d20a588d4a6d6dae0b33f61fd2bec71913b
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/11/870311/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d9c587397ad434a88f544c9343e9f28eebc75fad,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fcharm-vault~stable%2F1.8~I14c06caaf294b699f030546be422b3ebc9678c5d,openstack/charm-vault,stable/1.8,I14c06caaf294b699f030546be422b3ebc9678c5d,Pin tox to < 4.0.0,MERGED,2023-01-20 19:58:04.000000000,2023-01-26 09:32:19.000000000,2023-01-26 09:32:19.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 19:58:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/f8b712c126087ddc1ef99588eac007569dec85b8', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I14c06caaf294b699f030546be422b3ebc9678c5d\n""}]",1,871364,f8b712c126087ddc1ef99588eac007569dec85b8,10,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I14c06caaf294b699f030546be422b3ebc9678c5d
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/64/871364/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f8b712c126087ddc1ef99588eac007569dec85b8,pin-tox-stable-vault, tox < 4.0.0,,1,0
openstack%2Fironic-python-agent~master~Ibfb867ee0ff8274130a19538aa7ff9b9296dc4e1,openstack/ironic-python-agent,master,Ibfb867ee0ff8274130a19538aa7ff9b9296dc4e1,Readd usedevelop true to tox.ini,MERGED,2023-01-25 13:41:15.000000000,2023-01-26 09:29:53.000000000,2023-01-26 09:28:56.000000000,"[{'_account_id': 10239}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-25 13:41:15.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f2b4ac8751f05f5819804e389a644caecd8dc86d', 'message': 'Readd usedevelop true to tox.ini\n\nThis avoid using sdist, which is the wanted behavior\n\nChange-Id: Ibfb867ee0ff8274130a19538aa7ff9b9296dc4e1\n'}]",2,871728,f2b4ac8751f05f5819804e389a644caecd8dc86d,14,4,1,23851,,,0,"Readd usedevelop true to tox.ini

This avoid using sdist, which is the wanted behavior

Change-Id: Ibfb867ee0ff8274130a19538aa7ff9b9296dc4e1
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/28/871728/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f2b4ac8751f05f5819804e389a644caecd8dc86d,usedevelop,usedevelop = True,,1,0
openstack%2Fcharm-cinder-purestorage~stable%2Ftrain~I044e22a9d0d55ce07c102420ff03af93aff49c58,openstack/charm-cinder-purestorage,stable/train,I044e22a9d0d55ce07c102420ff03af93aff49c58,Pin tox to < 4.0.0,MERGED,2023-01-17 20:21:46.000000000,2023-01-26 09:29:07.000000000,2023-01-26 09:29:07.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 20:21:46.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cinder-purestorage/commit/a79b5956e0d5f416ad05ad370d3745aeaa00fb2d', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I044e22a9d0d55ce07c102420ff03af93aff49c58\n""}]",2,870868,a79b5956e0d5f416ad05ad370d3745aeaa00fb2d,10,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I044e22a9d0d55ce07c102420ff03af93aff49c58
",git fetch https://review.opendev.org/openstack/charm-cinder-purestorage refs/changes/68/870868/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a79b5956e0d5f416ad05ad370d3745aeaa00fb2d,pin-tox-train,requires = tox < 4.0.0,,2,0
openstack%2Fcharm-ceph-radosgw~stable%2Fquincy.2~Ie56b7d8506868db45d116a1fd31db3a24361f149,openstack/charm-ceph-radosgw,stable/quincy.2,Ie56b7d8506868db45d116a1fd31db3a24361f149,Pin tox to < 4.0.0,MERGED,2023-01-20 17:21:31.000000000,2023-01-26 09:28:38.000000000,2023-01-26 09:28:38.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 17:21:31.000000000', 'files': ['.gitreview', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/96a6dae2478b171356adf24939a126f75eb8826b', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ie56b7d8506868db45d116a1fd31db3a24361f149\n""}]",0,871321,96a6dae2478b171356adf24939a126f75eb8826b,8,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ie56b7d8506868db45d116a1fd31db3a24361f149
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/21/871321/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'tox.ini']",2,96a6dae2478b171356adf24939a126f75eb8826b,pin-tox-quincy.2, tox < 4.0.0,,3,0
openstack%2Fcharm-keystone-kerberos~stable%2Ftrain~I1d82f437aa87354e69b5cbde5daf06c7a34f5574,openstack/charm-keystone-kerberos,stable/train,I1d82f437aa87354e69b5cbde5daf06c7a34f5574,Pin tox to < 4.0.0,MERGED,2023-01-13 20:22:20.000000000,2023-01-26 09:27:22.000000000,2023-01-26 09:27:22.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:22:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-kerberos/commit/a3ed113d29c7e73bd9834d3f5e554111fcae58a5', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I1d82f437aa87354e69b5cbde5daf06c7a34f5574\n""}]",2,870395,a3ed113d29c7e73bd9834d3f5e554111fcae58a5,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I1d82f437aa87354e69b5cbde5daf06c7a34f5574
",git fetch https://review.opendev.org/openstack/charm-keystone-kerberos refs/changes/95/870395/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a3ed113d29c7e73bd9834d3f5e554111fcae58a5,pin-tox-train, tox < 4.0.0,,1,0
openstack%2Fcharm-cinder-ceph~stable%2Fussuri~I339ea6ee350ea598a6d34aec1ae620079b777a3e,openstack/charm-cinder-ceph,stable/ussuri,I339ea6ee350ea598a6d34aec1ae620079b777a3e,Pin tox to < 4.0.0,MERGED,2023-01-13 20:17:45.000000000,2023-01-26 09:26:53.000000000,2023-01-26 09:26:53.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:17:45.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/d8681a51f203af36851d66158ad5c69b77528046', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I339ea6ee350ea598a6d34aec1ae620079b777a3e\n""}]",6,870332,d8681a51f203af36851d66158ad5c69b77528046,18,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I339ea6ee350ea598a6d34aec1ae620079b777a3e
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/32/870332/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d8681a51f203af36851d66158ad5c69b77528046,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-designate-bind~stable%2Ftrain~Id19c14bca25892a380da0a79aec0fe1d970a2454,openstack/charm-designate-bind,stable/train,Id19c14bca25892a380da0a79aec0fe1d970a2454,Pin tox to < 4.0.0,MERGED,2023-01-13 20:21:48.000000000,2023-01-26 09:26:16.000000000,2023-01-26 09:26:16.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:21:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-designate-bind/commit/7612f19b6b62f03ddf63ec4099ef2448999f422e', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Id19c14bca25892a380da0a79aec0fe1d970a2454\n""}]",2,870387,7612f19b6b62f03ddf63ec4099ef2448999f422e,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Id19c14bca25892a380da0a79aec0fe1d970a2454
",git fetch https://review.opendev.org/openstack/charm-designate-bind refs/changes/87/870387/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7612f19b6b62f03ddf63ec4099ef2448999f422e,pin-tox-train, tox < 4.0.0,,1,0
openstack%2Fcharm-manila-ganesha~stable%2Fussuri~Ib0d00ad44d6defa0df0cb0a5372e8e45b4d3fb0c,openstack/charm-manila-ganesha,stable/ussuri,Ib0d00ad44d6defa0df0cb0a5372e8e45b4d3fb0c,Pin tox to < 4.0.0,MERGED,2023-01-13 20:19:12.000000000,2023-01-26 09:26:08.000000000,2023-01-26 09:26:08.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:19:12.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-manila-ganesha/commit/d8a925dca32cf491bf66f22d37a10bc388c3a8f6', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ib0d00ad44d6defa0df0cb0a5372e8e45b4d3fb0c\n""}]",3,870353,d8a925dca32cf491bf66f22d37a10bc388c3a8f6,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ib0d00ad44d6defa0df0cb0a5372e8e45b4d3fb0c
",git fetch https://review.opendev.org/openstack/charm-manila-ganesha refs/changes/53/870353/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d8a925dca32cf491bf66f22d37a10bc388c3a8f6,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-nova-compute~stable%2Ftrain~I52a098e6404a63f5a46628b7b071507fd3fbb339,openstack/charm-nova-compute,stable/train,I52a098e6404a63f5a46628b7b071507fd3fbb339,Pin tox to < 4.0.0,MERGED,2023-01-13 20:23:37.000000000,2023-01-26 09:24:09.000000000,2023-01-26 09:24:09.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:23:37.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/86dd9b531986471f86a883cc39fa4da42cf3c738', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I52a098e6404a63f5a46628b7b071507fd3fbb339\n""}]",2,870414,86dd9b531986471f86a883cc39fa4da42cf3c738,11,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I52a098e6404a63f5a46628b7b071507fd3fbb339
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/14/870414/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,86dd9b531986471f86a883cc39fa4da42cf3c738,pin-tox-train, tox < 4.0.0,,1,0
openstack%2Fcharm-manila~stable%2Fvictoria~I36ad8f899a72a623b9799bf142fd53b3ed04a879,openstack/charm-manila,stable/victoria,I36ad8f899a72a623b9799bf142fd53b3ed04a879,Pin tox to < 4.0.0,MERGED,2023-01-13 20:15:26.000000000,2023-01-26 09:21:55.000000000,2023-01-26 09:21:55.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:15:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/d7e10c9dedf3fef04ca9cbe0f199e579c3252481', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I36ad8f899a72a623b9799bf142fd53b3ed04a879\n""}]",3,870300,d7e10c9dedf3fef04ca9cbe0f199e579c3252481,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I36ad8f899a72a623b9799bf142fd53b3ed04a879
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/00/870300/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d7e10c9dedf3fef04ca9cbe0f199e579c3252481,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fcharm-keystone-kerberos~stable%2Fussuri~I2c48836ad4bc0dcb36a6a55d9eccc19cc0c04b9f,openstack/charm-keystone-kerberos,stable/ussuri,I2c48836ad4bc0dcb36a6a55d9eccc19cc0c04b9f,Pin tox to < 4.0.0,MERGED,2023-01-13 20:18:44.000000000,2023-01-26 09:20:25.000000000,2023-01-26 09:20:25.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:18:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-kerberos/commit/0936d4c454fa18d915142eda53c84061136349f1', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I2c48836ad4bc0dcb36a6a55d9eccc19cc0c04b9f\n""}]",4,870346,0936d4c454fa18d915142eda53c84061136349f1,14,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I2c48836ad4bc0dcb36a6a55d9eccc19cc0c04b9f
",git fetch https://review.opendev.org/openstack/charm-keystone-kerberos refs/changes/46/870346/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0936d4c454fa18d915142eda53c84061136349f1,pin-tox-ussuri, tox < 4.0.0,,1,0
openstack%2Fcharm-glance~stable%2Fvictoria~Ib83295ea70d8aa5674a2e87c9a04f65cb6e5c6e4,openstack/charm-glance,stable/victoria,Ib83295ea70d8aa5674a2e87c9a04f65cb6e5c6e4,Pin tox to < 4.0.0,MERGED,2023-01-13 20:14:38.000000000,2023-01-26 09:19:41.000000000,2023-01-26 09:19:41.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:14:38.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/279161b156c933c8370b37fff12618502dc183a0', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ib83295ea70d8aa5674a2e87c9a04f65cb6e5c6e4\n""}]",4,870288,279161b156c933c8370b37fff12618502dc183a0,14,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ib83295ea70d8aa5674a2e87c9a04f65cb6e5c6e4
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/88/870288/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,279161b156c933c8370b37fff12618502dc183a0,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fcharm-keystone-saml-mellon~stable%2Fvictoria~I2c8abd6484bb7cf2715b8c071ffd78ea36eb601c,openstack/charm-keystone-saml-mellon,stable/victoria,I2c8abd6484bb7cf2715b8c071ffd78ea36eb601c,Pin tox to < 4.0.0,MERGED,2023-01-13 20:15:14.000000000,2023-01-26 09:18:15.000000000,2023-01-26 09:18:15.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:15:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/6bb183fae7f6ceb4c26145a4b231959b1d2c79cf', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I2c8abd6484bb7cf2715b8c071ffd78ea36eb601c\n""}]",3,870297,6bb183fae7f6ceb4c26145a4b231959b1d2c79cf,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I2c8abd6484bb7cf2715b8c071ffd78ea36eb601c
",git fetch https://review.opendev.org/openstack/charm-keystone-saml-mellon refs/changes/97/870297/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6bb183fae7f6ceb4c26145a4b231959b1d2c79cf,pin-tox-victoria, tox < 4.0.0,,1,0
openstack%2Fironic-inspector~master~I2f8c80bd2aac2d00616ac2a2789a7da303d29656,openstack/ironic-inspector,master,I2f8c80bd2aac2d00616ac2a2789a7da303d29656,Make reno ignore bugfix eol tags,MERGED,2023-01-25 21:22:46.000000000,2023-01-26 09:09:03.000000000,2023-01-26 09:08:01.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-25 21:22:46.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656\n""}]",0,871788,e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d,9,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I2f8c80bd2aac2d00616ac2a2789a7da303d29656
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/88/871788/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,e1f3b71a39ff69521c2a84a3c9fa23cdbc20235d,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fironic-python-agent~master~I265969ab40a98a02962c2fc8460b6519ab576f99,openstack/ironic-python-agent,master,I265969ab40a98a02962c2fc8460b6519ab576f99,Make reno ignore bugfix eol tags,MERGED,2023-01-25 21:20:17.000000000,2023-01-26 09:04:11.000000000,2023-01-26 09:03:05.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2023-01-25 21:20:17.000000000', 'files': ['releasenotes/config.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/f8fc7e52f36de5c3515e60f5d2e6347a538a80d8', 'message': ""Make reno ignore bugfix eol tags\n\nReno was assuming all tags ending in -eol represented an old, EOL'd\nstable branch. That's not true for Ironic projects which have bugfix\nbranches. Update the regexp to exclude those branches.\n\nCo-Authored-By: Adam McArthur <adam@mcaq.me>\nChange-Id: I265969ab40a98a02962c2fc8460b6519ab576f99\n""}]",0,871786,f8fc7e52f36de5c3515e60f5d2e6347a538a80d8,9,3,1,10342,,,0,"Make reno ignore bugfix eol tags

Reno was assuming all tags ending in -eol represented an old, EOL'd
stable branch. That's not true for Ironic projects which have bugfix
branches. Update the regexp to exclude those branches.

Co-Authored-By: Adam McArthur <adam@mcaq.me>
Change-Id: I265969ab40a98a02962c2fc8460b6519ab576f99
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/86/871786/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/config.yaml'],1,f8fc7e52f36de5c3515e60f5d2e6347a538a80d8,,"--- closed_branch_tag_re: 'r""(?!^bugfix.*-eol$).+-eol""' ",,2,0
openstack%2Fmanila~master~I49ca4bfe14824c53faf71d90474050f8420ea0ea,openstack/manila,master,I49ca4bfe14824c53faf71d90474050f8420ea0ea,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 20:33:44.000000000,2023-01-26 07:31:27.000000000,2023-01-26 06:49:11.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2023-01-19 20:33:44.000000000', 'files': ['requirements.txt', 'manila/rpc.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/91b9985a32f2f87fe1b4cd4a56f8f3b4e91e3b4e', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I49ca4bfe14824c53faf71d90474050f8420ea0ea\n'}]",4,871162,91b9985a32f2f87fe1b4cd4a56f8f3b4e91e3b4e,18,3,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I49ca4bfe14824c53faf71d90474050f8420ea0ea
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/871162/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'manila/rpc.py']",2,91b9985a32f2f87fe1b4cd4a56f8f3b4e91e3b4e,," return messaging.get_rpc_client( TRANSPORT, target, version_cap=version_cap, serializer=serializer)"," return messaging.RPCClient(TRANSPORT, target, version_cap=version_cap, serializer=serializer)",4,5
openstack%2Fnova~stable%2Fxena~I5a399f1d3d702bfb76c067893e9c924904c8c360,openstack/nova,stable/xena,I5a399f1d3d702bfb76c067893e9c924904c8c360,[stable-only][cve] Check VMDK create-type against an allowed list,MERGED,2023-01-24 15:03:08.000000000,2023-01-26 07:21:13.000000000,2023-01-25 18:04:13.000000000,"[{'_account_id': 782}, {'_account_id': 9708}, {'_account_id': 11583}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf8b6f698c23c631c0a71d77f2716ca292c45e74', 'message': 'Check VMDK create-type against an allowed list\n\nTrivial conflicts on xena only in:\n\tnova/conf/compute.py\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}, {'number': 2, 'created': '2023-01-25 10:04:53.000000000', 'files': ['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/867c4dd893ea7211e89b78b22b8da920a74622ff', 'message': '[stable-only][cve] Check VMDK create-type against an allowed list\n\nTrivial conflicts on xena only in:\n\tnova/conf/compute.py\n\nNOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport\n\n[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}]",3,871622,867c4dd893ea7211e89b78b22b8da920a74622ff,23,5,2,4393,,,0,"[stable-only][cve] Check VMDK create-type against an allowed list

Trivial conflicts on xena only in:
	nova/conf/compute.py

NOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport

[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes

Related-Bug: #1996188
Change-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360
",git fetch https://review.opendev.org/openstack/nova refs/changes/22/871622/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py']",3,bf8b6f698c23c631c0a71d77f2716ca292c45e74,bug/1996188,"def check_vmdk_image(image_id, data): # Check some rules about VMDK files. Specifically we want to make # sure that the ""create-type"" of the image is one that we allow. # Some types of VMDK files can reference files outside the disk # image and we do not want to allow those for obvious reasons. types = CONF.compute.vmdk_allowed_types if not len(types): LOG.warning('Refusing to allow VMDK image as vmdk_allowed_' 'types is empty') msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) try: create_type = data.format_specific['data']['create-type'] except KeyError: msg = _('Unable to determine VMDK create-type') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if create_type not in CONF.compute.vmdk_allowed_types: LOG.warning('Refusing to process VMDK file with create-type of %r ' 'which is not in allowed set of: %s', create_type, ','.join(CONF.compute.vmdk_allowed_types)) msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if fmt == 'vmdk': check_vmdk_image(image_href, data) ",,86,0
openstack%2Fmanila~master~I639640f738571c77ea9bb1fbf60749c00ffcbd3b,openstack/manila,master,I639640f738571c77ea9bb1fbf60749c00ffcbd3b,Add filesystem info to FSAL in CephFS NFS,MERGED,2022-10-13 18:50:19.000000000,2023-01-26 06:27:20.000000000,2023-01-26 06:26:20.000000000,"[{'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 29632}]","[{'number': 1, 'created': '2022-10-13 18:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7c63019c2c2e97ada2e04e87a2d6d8fdcef8ebe2', 'message': 'Add filesystem info to FSAL in CephFS NFS\n\nThe filesystem information was missing from the exports\nin the CephFS NFS driver. Because of this, the exports\nwere created on the first available filesystem.\n\nThis generates inconsistencies in deployments in which more than\none filesystem is being used.\n\nThis patch set adds the filesystem information in the\ncreated exports.\n\nCloses-Bug: #1991938\nChange-Id: I639640f738571c77ea9bb1fbf60749c00ffcbd3b\n'}, {'number': 2, 'created': '2023-01-26 00:49:54.000000000', 'files': ['manila/share/drivers/cephfs/driver.py', 'manila/tests/share/drivers/cephfs/test_driver.py', 'releasenotes/notes/bug-1991938-add-filesystem-info-cephfs-nfs-fsal-b39ae5ebaeb6fba1.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/e33953a891182b7128660a06f1c7f29532cc36e9', 'message': 'Add filesystem info to FSAL in CephFS NFS\n\nThe filesystem information was missing from the exports\nin the CephFS NFS driver. Because of this, the exports\nwere created on the first available filesystem.\n\nThis generates inconsistencies in deployments in which more than\none filesystem is being used.\n\nThis patch set adds the filesystem information in the\ncreated exports.\n\nCloses-Bug: #1991938\nChange-Id: I639640f738571c77ea9bb1fbf60749c00ffcbd3b\n'}]",3,861216,e33953a891182b7128660a06f1c7f29532cc36e9,18,3,2,6413,,,0,"Add filesystem info to FSAL in CephFS NFS

The filesystem information was missing from the exports
in the CephFS NFS driver. Because of this, the exports
were created on the first available filesystem.

This generates inconsistencies in deployments in which more than
one filesystem is being used.

This patch set adds the filesystem information in the
created exports.

Closes-Bug: #1991938
Change-Id: I639640f738571c77ea9bb1fbf60749c00ffcbd3b
",git fetch https://review.opendev.org/openstack/manila refs/changes/16/861216/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/cephfs/driver.py', 'manila/tests/share/drivers/cephfs/test_driver.py', 'releasenotes/notes/bug-1991938-add-filesystem-info-cephfs-nfs-fsal-b39ae5ebaeb6fba1.yaml']",3,7c63019c2c2e97ada2e04e87a2d6d8fdcef8ebe2,bug/1991938,--- fixes: - | Add the filesystem info in the exports created by the CephFS NFS driver. This fixes inconsistencies when deploying Manila with CephFS NFS with multiple filesystems. ,,11,2
openstack%2Fpuppet-tripleo~stable%2Ftrain~I65720576249f2242331e38762dd0d5860d74de9d,openstack/puppet-tripleo,stable/train,I65720576249f2242331e38762dd0d5860d74de9d,Ensure haproxy::balancemember::ports is a string,ABANDONED,2023-01-25 16:47:36.000000000,2023-01-26 06:14:41.000000000,,"[{'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2023-01-25 16:47:36.000000000', 'files': ['manifests/haproxy/horizon_endpoint.pp', 'manifests/haproxy/endpoint.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/5641c0d3aab9e3f0a3844a20e07d58929f545474', 'message': 'Ensure haproxy::balancemember::ports is a string\n\nThe recent change[1] in puppetlabs-haproxy introduced data type check\nand now the ports parameter accept only string or array of strings and\nno longer accepts an integer.\n\nThis ensures the value is converted to avoid validation errors.\n\n[1] https://github.com/puppetlabs/puppetlabs-haproxy/commit/95ca912f77966ed0da7a5bec9265cdacbf09da4c\n\nCloses-Bug: #2003882\nChange-Id: I65720576249f2242331e38762dd0d5860d74de9d\n'}]",1,871743,5641c0d3aab9e3f0a3844a20e07d58929f545474,4,2,1,9816,,,0,"Ensure haproxy::balancemember::ports is a string

The recent change[1] in puppetlabs-haproxy introduced data type check
and now the ports parameter accept only string or array of strings and
no longer accepts an integer.

This ensures the value is converted to avoid validation errors.

[1] https://github.com/puppetlabs/puppetlabs-haproxy/commit/95ca912f77966ed0da7a5bec9265cdacbf09da4c

Closes-Bug: #2003882
Change-Id: I65720576249f2242331e38762dd0d5860d74de9d
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/43/871743/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/haproxy/horizon_endpoint.pp', 'manifests/haproxy/endpoint.pp']",2,5641c0d3aab9e3f0a3844a20e07d58929f545474,bug/2003882," ports => ""${service_port_real}"", ports => ""${service_port_real}"","," ports => $service_port_real, ports => $service_port_real,",3,3
openstack%2Fhorizon~master~I776b19f053ca74c699ca069e04553740f1e83b3e,openstack/horizon,master,I776b19f053ca74c699ca069e04553740f1e83b3e,Remove console_type parameter for server_mks_console function,MERGED,2022-10-31 10:54:45.000000000,2023-01-26 05:51:19.000000000,2023-01-25 15:28:16.000000000,"[{'_account_id': 841}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2022-10-31 10:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1ad406c526a522155c03e5fdb8e3c1ee90ebbbab', 'message': 'Remove console_type parameter for server_mks_console function\n\nChange-Id: I776b19f053ca74c699ca069e04553740f1e83b3e\n'}, {'number': 2, 'created': '2022-11-02 08:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2d9ca09b3f0ec1413288c3b242db6ee1a9ce5948', 'message': 'Remove console_type parameter for server_mks_console function\n\nThe ""get_mks_console"" use ""console_type"" as param, but causes an issue on Nova.\nIn horizon logs we have ""Recoverable error: No available console found."" and in the dashboard we have ""Unable to load console. Please reload page to try again."" when we load the console.\nThere is no need to call the function with this parameter, as it\'s already defined automatically since microversion 2.53.\n\nChange-Id: I776b19f053ca74c699ca069e04553740f1e83b3e\n'}, {'number': 3, 'created': '2022-11-02 10:03:57.000000000', 'files': ['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ee92961fe5275f85779634aad637d00c15802b49', 'message': 'Remove console_type parameter for server_mks_console function\n\nThe ""get_mks_console"" use ""console_type"" as param, but causes an issue on Nova.\nIn horizon logs we have ""Recoverable error: No available console found."" and in the dashboard we have ""Unable to load console. Please reload page to try again."" when we load the console.\nThere is no need to call the function with this parameter, as it\'s already defined automatically since microversion 2.53.\n\nChange-Id: I776b19f053ca74c699ca069e04553740f1e83b3e\n'}]",5,863032,ee92961fe5275f85779634aad637d00c15802b49,14,3,3,33952,,,0,"Remove console_type parameter for server_mks_console function

The ""get_mks_console"" use ""console_type"" as param, but causes an issue on Nova.
In horizon logs we have ""Recoverable error: No available console found."" and in the dashboard we have ""Unable to load console. Please reload page to try again."" when we load the console.
There is no need to call the function with this parameter, as it's already defined automatically since microversion 2.53.

Change-Id: I776b19f053ca74c699ca069e04553740f1e83b3e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/863032/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/unit/api/test_nova.py', 'openstack_dashboard/api/nova.py']",2,1ad406c526a522155c03e5fdb8e3c1ee90ebbbab,bug/1995253,"def server_mks_console(request, instance_id): console = nc.servers.get_mks_console(instance_id)","def server_mks_console(request, instance_id, console_type='mks'): console = nc.servers.get_mks_console(instance_id, console_type)",4,6
openstack%2Ftempest~master~I0c94ac5e7fd7b6da0fd051b9ff7d4c226be73f76,openstack/tempest,master,I0c94ac5e7fd7b6da0fd051b9ff7d4c226be73f76,Remove leftover todo related to the dhcpcd support,MERGED,2023-01-24 11:44:24.000000000,2023-01-26 03:44:47.000000000,2023-01-26 03:43:34.000000000,"[{'_account_id': 8313}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-24 11:44:24.000000000', 'files': ['tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e72ce41454646fd1d83775c948faf8c451519ade', 'message': 'Remove leftover todo related to the dhcpcd support\n\nWith commit [1] support for dhcpcd client was added to tempest\nbut there was not cleaned one of the TODO notes related to that.\nSo this patch simply cleans that left over.\n\n[1] https://review.opendev.org/c/openstack/tempest/+/871270\n\nChange-Id: I0c94ac5e7fd7b6da0fd051b9ff7d4c226be73f76\n'}]",3,871598,e72ce41454646fd1d83775c948faf8c451519ade,16,4,1,11975,,,0,"Remove leftover todo related to the dhcpcd support

With commit [1] support for dhcpcd client was added to tempest
but there was not cleaned one of the TODO notes related to that.
So this patch simply cleans that left over.

[1] https://review.opendev.org/c/openstack/tempest/+/871270

Change-Id: I0c94ac5e7fd7b6da0fd051b9ff7d4c226be73f76
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/871598/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/config.py'],1,e72ce41454646fd1d83775c948faf8c451519ade,bug/2003063,, # TODO(yfried): add support for dhcpcd,0,1
openstack%2Fswift~stable%2Frocky~I84494123cfc85e234098c554ecd3e77981f8a096,openstack/swift,stable/rocky,I84494123cfc85e234098c554ecd3e77981f8a096,s3api: Prevent XXE injections,MERGED,2023-01-23 20:46:21.000000000,2023-01-26 02:59:41.000000000,2023-01-26 02:59:41.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 20:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/128efbb1a94f9d8f162cfcf9bbf7b2db19f31a5e', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 2, 'created': '2023-01-24 20:28:16.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f10672514217adadfc776d9ea2ffb20a37ce073b', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}]",3,871502,f10672514217adadfc776d9ea2ffb20a37ce073b,12,2,2,15343,,,0,"s3api: Prevent XXE injections

Previously, clients could use XML external entities (XXEs) to read
arbitrary files from proxy-servers and inject the content into the
request. Since many S3 APIs reflect request content back to the user,
this could be used to extract any secrets that the swift user could
read, such as tempauth credentials, keymaster secrets, etc.

Now, disable entity resolution -- any unknown entities will be replaced
with an empty string. Without resolving the entities, the request is
still processed.

[CVE-2022-47950]

Closes-Bug: #1998625
Co-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>
Change-Id: I84494123cfc85e234098c554ecd3e77981f8a096
(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)
",git fetch https://review.opendev.org/openstack/swift refs/changes/02/871502/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py']",3,128efbb1a94f9d8f162cfcf9bbf7b2db19f31a5e,bug/1998625-stable/train-stable/stein-stable/rocky,"#!/usr/bin/env python # Copyright (c) 2022 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import requests import botocore import test.functional as tf from test.functional.s3api import S3ApiBaseBoto3 def setUpModule(): tf.setup_package() def tearDownModule(): tf.teardown_package() class TestS3ApiXxeInjection(S3ApiBaseBoto3): def setUp(self): super(TestS3ApiXxeInjection, self).setUp() self.bucket = 'test-s3api-xxe-injection' def _create_bucket(self, **kwargs): resp = self.conn.create_bucket(Bucket=self.bucket, **kwargs) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) @staticmethod def _clear_data(request, **_kwargs): if 'Content-MD5' in request.headers: del request.headers['Content-MD5'] request.data = b'' def _presign_url(self, method, key=None, **kwargs): params = { 'Bucket': self.bucket } if key: params['Key'] = key params.update(kwargs) try: # https://github.com/boto/boto3/issues/2192 self.conn.meta.events.register( 'before-sign.s3.*', self._clear_data) return self.conn.generate_presigned_url( method, Params=params, ExpiresIn=60) finally: self.conn.meta.events.unregister( 'before-sign.s3.*', self._clear_data) def test_put_bucket_acl(self): if not tf.cluster_info['s3api'].get('s3_acl'): self.skipTest('s3_acl must be enabled') self._create_bucket() url = self._presign_url('put_bucket_acl') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <AccessControlPolicy xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Owner> <DisplayName>test:tester</DisplayName> <ID>test:tester</ID> </Owner> <AccessControlList> <Grant> <Grantee xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""CanonicalUser""> <DisplayName>name&xxe;</DisplayName> <ID>id&xxe;</ID> </Grantee> <Permission>WRITE</Permission> </Grant> </AccessControlList> </AccessControlPolicy> """""") # noqa: E501 self.assertEqual(200, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) acl = self.conn.get_bucket_acl(Bucket=self.bucket) response_metadata = acl.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({ 'Owner': { 'DisplayName': 'test:tester', 'ID': 'test:tester' }, 'Grants': [ { 'Grantee': { 'DisplayName': 'id', 'ID': 'id', 'Type': 'CanonicalUser' }, 'Permission': 'WRITE' } ] }, acl) def test_create_bucket(self): url = self._presign_url('create_bucket') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CreateBucketConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <LocationConstraint>&xxe;</LocationConstraint> </CreateBucketConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) self.assertRaisesRegexp( botocore.exceptions.ClientError, 'Not Found', self.conn.head_bucket, Bucket=self.bucket) def test_delete_objects(self): self._create_bucket() url = self._presign_url( 'delete_objects', Delete={ 'Objects': [ { 'Key': 'string', 'VersionId': 'string' } ] }) body = """""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <Delete xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Object> <Key>&xxe;</Key> </Object> </Delete> """""" body = body.encode('utf-8') resp = requests.post(url, data=body) self.assertEqual(400, resp.status_code, resp.content) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) def test_complete_multipart_upload(self): self._create_bucket() resp = self.conn.create_multipart_upload( Bucket=self.bucket, Key='test') response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) uploadid = resp.get('UploadId') try: url = self._presign_url( 'complete_multipart_upload', Key='key', MultipartUpload={ 'Parts': [ { 'ETag': 'string', 'PartNumber': 1 } ], }, UploadId=uploadid) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""{uploadid}""</ETag> <PartNumber>&xxe;</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""&xxe;""</ETag> <PartNumber>1</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) finally: resp = self.conn.abort_multipart_upload( Bucket=self.bucket, Key='test', UploadId=uploadid) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(204, response_metadata.get('HTTPStatusCode')) ",,250,1
openstack%2Fansible-role-systemd_service~stable%2Fzed~Ib456b4dc2d631bf81633035820444f13ec0f06cb,openstack/ansible-role-systemd_service,stable/zed,Ib456b4dc2d631bf81633035820444f13ec0f06cb,Ensure daemon is reloaded on socket change,MERGED,2023-01-25 17:34:52.000000000,2023-01-26 00:22:08.000000000,2023-01-26 00:21:08.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-01-25 17:34:52.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/6551e127f283e202956e0efb89d9e3caed2c4007', 'message': ""Ensure daemon is reloaded on socket change\n\nAt the moment our verification if socket has been changed\nis not valid, since we're checking if string 'true' is presnet in the\nlist, while list consist of only boolean variables. So we replace\nmap filter with selectattr as it can apply truthy test to the elements\nwhile selecting them and checking list length.\n\nChange-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb\nRelated-Bug: #2003631\n(cherry picked from commit 6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2)\n""}]",0,871751,6551e127f283e202956e0efb89d9e3caed2c4007,8,3,1,28619,,,0,"Ensure daemon is reloaded on socket change

At the moment our verification if socket has been changed
is not valid, since we're checking if string 'true' is presnet in the
list, while list consist of only boolean variables. So we replace
map filter with selectattr as it can apply truthy test to the elements
while selecting them and checking list length.

Change-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb
Related-Bug: #2003631
(cherry picked from commit 6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2)
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/51/871751/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,6551e127f283e202956e0efb89d9e3caed2c4007,," - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or (systemd_socket.results | selectattr('changed', 'true') | length > 0)", - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or ('true' in systemd_socket.results | map(attribute='changed') | list ),1,1
openstack%2Fswift~stable%2Fstein~I84494123cfc85e234098c554ecd3e77981f8a096,openstack/swift,stable/stein,I84494123cfc85e234098c554ecd3e77981f8a096,s3api: Prevent XXE injections,MERGED,2023-01-23 20:46:10.000000000,2023-01-25 23:45:35.000000000,2023-01-25 23:44:19.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 20:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fe08f6282d8bfee370bdaa03d7db714d839736c5', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 2, 'created': '2023-01-23 21:19:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e8bbd744682a31290cfec4b85442a300b3907dd', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 3, 'created': '2023-01-23 21:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/781c4f567f282dcbe160421a9fbe76ea379360ac', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 4, 'created': '2023-01-24 20:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1bea44ae619f14ba48b8652d4c1ca401e252dca3', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 5, 'created': '2023-01-24 20:28:34.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/12e54391861e7d182d58f89fb88b027e65842640', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}]",1,871501,12e54391861e7d182d58f89fb88b027e65842640,12,2,5,15343,,,0,"s3api: Prevent XXE injections

Previously, clients could use XML external entities (XXEs) to read
arbitrary files from proxy-servers and inject the content into the
request. Since many S3 APIs reflect request content back to the user,
this could be used to extract any secrets that the swift user could
read, such as tempauth credentials, keymaster secrets, etc.

Now, disable entity resolution -- any unknown entities will be replaced
with an empty string. Without resolving the entities, the request is
still processed.

[CVE-2022-47950]

Closes-Bug: #1998625
Co-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>
Change-Id: I84494123cfc85e234098c554ecd3e77981f8a096
(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)
",git fetch https://review.opendev.org/openstack/swift refs/changes/01/871501/4 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py']",3,fe08f6282d8bfee370bdaa03d7db714d839736c5,bug/1998625-stable/train-stable/stein,"#!/usr/bin/env python # Copyright (c) 2022 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import requests import botocore import test.functional as tf from test.functional.s3api import S3ApiBaseBoto3 def setUpModule(): tf.setup_package() def tearDownModule(): tf.teardown_package() class TestS3ApiXxeInjection(S3ApiBaseBoto3): def setUp(self): super(TestS3ApiXxeInjection, self).setUp() self.bucket = 'test-s3api-xxe-injection' def _create_bucket(self, **kwargs): resp = self.conn.create_bucket(Bucket=self.bucket, **kwargs) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) @staticmethod def _clear_data(request, **_kwargs): if 'Content-MD5' in request.headers: del request.headers['Content-MD5'] request.data = b'' def _presign_url(self, method, key=None, **kwargs): params = { 'Bucket': self.bucket } if key: params['Key'] = key params.update(kwargs) try: # https://github.com/boto/boto3/issues/2192 self.conn.meta.events.register( 'before-sign.s3.*', self._clear_data) return self.conn.generate_presigned_url( method, Params=params, ExpiresIn=60) finally: self.conn.meta.events.unregister( 'before-sign.s3.*', self._clear_data) def test_put_bucket_acl(self): if not tf.cluster_info['s3api'].get('s3_acl'): self.skipTest('s3_acl must be enabled') self._create_bucket() url = self._presign_url('put_bucket_acl') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <AccessControlPolicy xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Owner> <DisplayName>test:tester</DisplayName> <ID>test:tester</ID> </Owner> <AccessControlList> <Grant> <Grantee xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""CanonicalUser""> <DisplayName>name&xxe;</DisplayName> <ID>id&xxe;</ID> </Grantee> <Permission>WRITE</Permission> </Grant> </AccessControlList> </AccessControlPolicy> """""") # noqa: E501 self.assertEqual(200, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) acl = self.conn.get_bucket_acl(Bucket=self.bucket) response_metadata = acl.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({ 'Owner': { 'DisplayName': 'test:tester', 'ID': 'test:tester' }, 'Grants': [ { 'Grantee': { 'DisplayName': 'id', 'ID': 'id', 'Type': 'CanonicalUser' }, 'Permission': 'WRITE' } ] }, acl) def test_create_bucket(self): url = self._presign_url('create_bucket') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CreateBucketConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <LocationConstraint>&xxe;</LocationConstraint> </CreateBucketConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) self.assertRaisesRegexp( botocore.exceptions.ClientError, 'Not Found', self.conn.head_bucket, Bucket=self.bucket) def test_delete_objects(self): self._create_bucket() url = self._presign_url( 'delete_objects', Delete={ 'Objects': [ { 'Key': 'string', 'VersionId': 'string' } ] }) body = """""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <Delete xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Object> <Key>&xxe;</Key> </Object> </Delete> """""" body = body.encode('utf-8') resp = requests.post(url, data=body) self.assertEqual(400, resp.status_code, resp.content) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) def test_complete_multipart_upload(self): self._create_bucket() resp = self.conn.create_multipart_upload( Bucket=self.bucket, Key='test') response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) uploadid = resp.get('UploadId') try: url = self._presign_url( 'complete_multipart_upload', Key='key', MultipartUpload={ 'Parts': [ { 'ETag': 'string', 'PartNumber': 1 } ], }, UploadId=uploadid) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""{uploadid}""</ETag> <PartNumber>&xxe;</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""&xxe;""</ETag> <PartNumber>1</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) finally: resp = self.conn.abort_multipart_upload( Bucket=self.bucket, Key='test', UploadId=uploadid) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(204, response_metadata.get('HTTPStatusCode')) ",,250,1
openstack%2Fpython-swiftclient~master~I3d89c3ff3d2789d64ba8f9c46fd1cd27c4c3a845,openstack/python-swiftclient,master,I3d89c3ff3d2789d64ba8f9c46fd1cd27c4c3a845,Back-fill a bunch of ChangeLog releases,MERGED,2023-01-06 20:05:22.000000000,2023-01-25 23:19:21.000000000,2023-01-25 23:16:58.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-06 20:05:22.000000000', 'files': ['AUTHORS', 'ChangeLog'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/6954ab1bbb464eebe30875bf53ee79037baf7ea1', 'message': 'Back-fill a bunch of ChangeLog releases\n\nChange-Id: I3d89c3ff3d2789d64ba8f9c46fd1cd27c4c3a845\n'}]",0,869506,6954ab1bbb464eebe30875bf53ee79037baf7ea1,7,2,1,15343,,,0,"Back-fill a bunch of ChangeLog releases

Change-Id: I3d89c3ff3d2789d64ba8f9c46fd1cd27c4c3a845
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/06/869506/1 && git format-patch -1 --stdout FETCH_HEAD,"['AUTHORS', 'ChangeLog']",2,6954ab1bbb464eebe30875bf53ee79037baf7ea1,,"4.1.0 ----- * Tempurl times may now include suffixes: 's', 'm', 'h', or 'd' to indicate seconds, minutes, hours, or days respectively. Times with no suffix continue to be interpretted as seconds. * Rate-limit responses (498, 429) are now retried. * Added a `--skip-container-put` option when uploading. 4.0.1 ----- * Added a new `--digest` option to `swift tempurl` to select the signature algorithm to use. Default is sha256, which has been supported by default since Swift 2.17.0, though older clusters may require sha1 (the previous default). Use `swift capabilities` to check the `allowed_digests`. 4.0.0 ----- * Drop support for Python 2. * Added a `--timeout` option. By default, operations wait indefinitely. * Swiftclient no longer monkey-patches the requests library. 3.13.1 ----- * This is the final release to support Python 2. * Fix some example code. 3.13.0 ----- * Improve account-listing formatting when containers have billions of objects. * Include storage policy information in long-formatted account listings. * Fix aggregation when listings include more than 10,000 items. * Suppress traceback logging for 404s. 3.12.0 ----- * Various minor bug fixes and improvements. 3.11.1 ----- * Various minor bug fixes and improvements. 3.11.0 ----- * Fixed a file descriptor leak on Python 2 that was introduced in 3.9.0. * Transaction IDs are now included in more exceptions. * Fixed a socket leak when using some module-level functions. * `swift delete --all` now implies `--versions` to delete all old versions of objects as well. * Now tested under Python 3.9. 3.10.1 ----- * Tolerate some password-based values for `OS_AUTH_TYPE`. * Added `max_backoff` and `starting_backoff` options in the `SwiftService` API. 3.10.0 ----- * Added support for the new object-versioning API to the `list`, `stat`, `delete`, and `download` subcommands. This optional API was introduced in Swift 2.24.0; for more information on the API, see https://docs.openstack.org/swift/latest/middleware.html#object-versioning-api * Added support for Keystone v3 application credentials using `--os-auth-type v3applicationcredential`. * Fixed an issue with capabilities-endpoint discovery when Swift is exposed as a subpath on the server. ",,118,0
openstack%2Fpython-swiftclient~master~I4b8d75aab6b5d80756fbd83ffb62e5135365a685,openstack/python-swiftclient,master,I4b8d75aab6b5d80756fbd83ffb62e5135365a685,Switch to 2023.1 Python3 unit tests and generic template name,MERGED,2022-09-09 10:27:25.000000000,2023-01-25 23:18:39.000000000,2023-01-25 23:16:56.000000000,"[{'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-09 10:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/ca4b42e8622dedabe01b3a1398d11b1fa6d70add', 'message': 'Add Python3 antelope unit tests\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I4b8d75aab6b5d80756fbd83ffb62e5135365a685\n'}, {'number': 2, 'created': '2022-09-10 14:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/9085fe96e8795b40a40f4d81fd8fd13a8e6fc22c', 'message': 'Add Python3 antelope unit tests\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I4b8d75aab6b5d80756fbd83ffb62e5135365a685\n'}, {'number': 3, 'created': '2022-09-14 09:26:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/d9d6257e3b79bb481a6bca2ab67be4caa30f4ea0', 'message': 'Switch to 2023.1 Python3 unit tests and generic template name\n\nThis is an automatically generated patch to ensure unit testing\nis in place for all the of the tested runtimes for antelope. Also,\nupdating the template name to generic one.\n\nSee also the PTI in governance [1].\n\n[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html\n\nChange-Id: I4b8d75aab6b5d80756fbd83ffb62e5135365a685\n'}]",2,856704,d9d6257e3b79bb481a6bca2ab67be4caa30f4ea0,15,4,3,22816,,,0,"Switch to 2023.1 Python3 unit tests and generic template name

This is an automatically generated patch to ensure unit testing
is in place for all the of the tested runtimes for antelope. Also,
updating the template name to generic one.

See also the PTI in governance [1].

[1]: https://governance.openstack.org/tc/reference/project-testing-interface.html

Change-Id: I4b8d75aab6b5d80756fbd83ffb62e5135365a685
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/04/856704/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,ca4b42e8622dedabe01b3a1398d11b1fa6d70add,add-antelope-python-jobtemplates, - openstack-python3-antelope-jobs, - openstack-python3-zed-jobs,1,1
openstack%2Fpython-swiftclient~master~I1f9d26541e9c8f5aec7a6790c87df397d178efe6,openstack/python-swiftclient,master,I1f9d26541e9c8f5aec7a6790c87df397d178efe6,Allow tempurl to be used to sign /info requests,MERGED,2022-07-23 04:39:04.000000000,2023-01-25 23:14:42.000000000,2023-01-25 23:13:43.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-23 04:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/a5b33264d0f7dd38b20af32a9bb280c4a6e85cd0', 'message': 'Allow tempurl to be used to sign /info requests\n\nChange-Id: I1f9d26541e9c8f5aec7a6790c87df397d178efe6\n'}, {'number': 2, 'created': '2022-08-29 20:14:44.000000000', 'files': ['swiftclient/utils.py', 'test/unit/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/f4e62191bc174e6235130aab36feb3b161de7848', 'message': 'Allow tempurl to be used to sign /info requests\n\nChange-Id: I1f9d26541e9c8f5aec7a6790c87df397d178efe6\n'}]",0,850786,f4e62191bc174e6235130aab36feb3b161de7848,10,3,2,15343,,,0,"Allow tempurl to be used to sign /info requests

Change-Id: I1f9d26541e9c8f5aec7a6790c87df397d178efe6
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/86/850786/1 && git format-patch -1 --stdout FETCH_HEAD,['swiftclient/utils.py'],1,a5b33264d0f7dd38b20af32a9bb280c4a6e85cd0,," if path_for_body == '/info': # /info signatures do not support prefixes or ip ranges prefix = False ip_range = None elif len(parts) != 5 or parts[0] or not all(parts[1:(4 if prefix else 5)]): if path_for_body == '/info': temp_url = '{path}?swiftinfo_sig={sig}&swiftinfo_expires={exp}'.format( path=path_for_body, sig=sig, exp=expiration) else: temp_url = '{path}?temp_url_sig={sig}&temp_url_expires={exp}'.format( path=path_for_body, sig=sig, exp=expiration)"," if len(parts) != 5 or parts[0] or not all(parts[1:(4 if prefix else 5)]): temp_url = '{path}?temp_url_sig={sig}&temp_url_expires={exp}'.format( path=path_for_body, sig=sig, exp=expiration)",11,3
openstack%2Fpython-cinderclient~master~Ib1f55f9431033ad043507c6f751ee9bfe57d5cbb,openstack/python-cinderclient,master,Ib1f55f9431033ad043507c6f751ee9bfe57d5cbb,Continue using tox 3,MERGED,2023-01-18 16:28:10.000000000,2023-01-25 22:09:47.000000000,2023-01-25 22:07:48.000000000,"[{'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-18 16:28:10.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/c66b9911b8dcf89910fcab45e9a8211e30419ccf', 'message': 'Continue using tox 3\n\nUse the classic cinderclient tox.ini that has worked so well in the\npast with tox 3; only change is to add the tox<4 requires statement.\nAlso adjust .zuul.yaml to express our preference for tox<4 in the\ncase that zuul has to install tox.\n\nChange-Id: Ib1f55f9431033ad043507c6f751ee9bfe57d5cbb\n'}]",4,870971,c66b9911b8dcf89910fcab45e9a8211e30419ccf,16,3,1,5314,,,0,"Continue using tox 3

Use the classic cinderclient tox.ini that has worked so well in the
past with tox 3; only change is to add the tox<4 requires statement.
Also adjust .zuul.yaml to express our preference for tox<4 in the
case that zuul has to install tox.

Change-Id: Ib1f55f9431033ad043507c6f751ee9bfe57d5cbb
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/71/870971/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,c66b9911b8dcf89910fcab45e9a8211e30419ccf,tox-4-justincase,requires = tox<4,,3,0
openstack%2Fpython-swiftclient~stable%2Ftrain~Ib4037d0b49da1bce959947100629370805f510d5,openstack/python-swiftclient,stable/train,Ib4037d0b49da1bce959947100629370805f510d5,Fixed capability discovery endpoint hardcode,ABANDONED,2021-04-15 10:14:24.000000000,2023-01-25 21:37:21.000000000,,"[{'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-04-15 10:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/deb1bc0eb692cd52273f361618e2d6fc81ca5d8c', 'message': ""Fixed capability discovery endpoint hardcode\n\nIt fixes get_capabilities() method to process\ncorrectly endpoints like: 'https://<ip>:<port>/v1',\n'https://<ip>:<port>/swift/v1'.\n\nCo-Authored-By: Daniel Cech <dcech@mirantis.com>\nChange-Id: Ib4037d0b49da1bce959947100629370805f510d5\nCloses-bug: #1712358\n(cherry picked from commit 947c09f30c6b603e3f4da060bc913407b158a0ca)\n(cherry picked from commit e1c05cffbe980807f170731028ca1a007fcc6f10)\n""}, {'number': 2, 'created': '2021-04-15 10:33:18.000000000', 'files': ['tests/unit/test_swiftclient.py', 'swiftclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/e1c934a85813f0ad99bd92d877405f4a1f5ec450', 'message': ""Fixed capability discovery endpoint hardcode\n\nIt fixes get_capabilities() method to process\ncorrectly endpoints like: 'https://<ip>:<port>/v1',\n'https://<ip>:<port>/swift/v1'.\n\nConflicts:\n\ttest/unit/test_swiftclient.py\n\nNOTE(Xing Zhang):\nThe file has conflict due to the tests directory was renamed to test\nin stable/ussuri. (patch I558dbf9a657d442e6e19468e543bbec855129eeb)\n\nCo-Authored-By: Daniel Cech <dcech@mirantis.com>\nCO-Authored-By: Xing Zhang <angeiv.zhang@gmail.com>\nChange-Id: Ib4037d0b49da1bce959947100629370805f510d5\nCloses-bug: #1712358\n(cherry picked from commit 947c09f30c6b603e3f4da060bc913407b158a0ca)\n(cherry picked from commit e1c05cffbe980807f170731028ca1a007fcc6f10)\n""}]",0,786235,e1c934a85813f0ad99bd92d877405f4a1f5ec450,9,2,2,21757,,,0,"Fixed capability discovery endpoint hardcode

It fixes get_capabilities() method to process
correctly endpoints like: 'https://<ip>:<port>/v1',
'https://<ip>:<port>/swift/v1'.

Conflicts:
	test/unit/test_swiftclient.py

NOTE(Xing Zhang):
The file has conflict due to the tests directory was renamed to test
in stable/ussuri. (patch I558dbf9a657d442e6e19468e543bbec855129eeb)

Co-Authored-By: Daniel Cech <dcech@mirantis.com>
CO-Authored-By: Xing Zhang <angeiv.zhang@gmail.com>
Change-Id: Ib4037d0b49da1bce959947100629370805f510d5
Closes-bug: #1712358
(cherry picked from commit 947c09f30c6b603e3f4da060bc913407b158a0ca)
(cherry picked from commit e1c05cffbe980807f170731028ca1a007fcc6f10)
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/35/786235/2 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/client.py', 'test/unit/test_swiftclient.py']",2,deb1bc0eb692cd52273f361618e2d6fc81ca5d8c,bug/1712358-stable/train,"<<<<<<< HEAD (34ffb6 Update .gitreview for stable/train) ======= # Copyright (c) 2010-2012 OpenStack, LLC. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import gzip import json import logging import mock import six import socket import string import unittest import warnings import tempfile from hashlib import md5 from six import binary_type from six.moves.urllib.parse import urlparse from requests.exceptions import RequestException from .utils import (MockHttpTest, fake_get_auth_keystone, StubResponse, FakeKeystone) from swiftclient.utils import EMPTY_ETAG from swiftclient.exceptions import ClientException from swiftclient import client as c import swiftclient.utils import swiftclient class TestClientException(unittest.TestCase): def test_is_exception(self): self.assertTrue(issubclass(c.ClientException, Exception)) def test_format(self): exc = c.ClientException('something failed') self.assertIn('something failed', str(exc)) test_kwargs = ( 'scheme', 'host', 'port', 'path', 'query', 'status', 'reason', 'device', 'response_content', ) for value in test_kwargs: kwargs = { 'http_%s' % value: value, } exc = c.ClientException('test', **kwargs) self.assertIn(value, str(exc)) def test_attrs(self): test_kwargs = ( 'scheme', 'host', 'port', 'path', 'query', 'status', 'reason', 'device', 'response_content', 'response_headers', ) for value in test_kwargs: key = 'http_%s' % value kwargs = {key: value} exc = c.ClientException('test', **kwargs) self.assertIs(True, hasattr(exc, key)) self.assertEqual(getattr(exc, key), value) class MockHttpResponse(object): def __init__(self, status=0, headers=None, verify=False): self.status = status self.status_code = status self.reason = ""OK"" self.buffer = [] self.requests_params = None self.verify = verify self.md5sum = md5() self.headers = {'etag': '""%s""' % EMPTY_ETAG} if headers: self.headers.update(headers) self.closed = False class Raw(object): def __init__(self, headers): self.headers = headers def read(self, **kw): return """" def getheader(self, name, default): return self.headers.get(name, default) self.raw = Raw(headers) def read(self): return """" def close(self): self.closed = True def getheader(self, name, default): return self.headers.get(name, default) def getheaders(self): return dict(self.headers).items() def fake_response(self): return self def _fake_request(self, *arg, **kwarg): self.status = 200 self.requests_params = kwarg if self.verify: for chunk in kwarg['data']: self.md5sum.update(chunk) # This simulate previous httplib implementation that would do a # putrequest() and then use putheader() to send header. for k, v in kwarg['headers'].items(): self.buffer.append((k, v)) return self.fake_response() class TestHttpHelpers(MockHttpTest): def test_quote(self): value = b'bytes\xff' self.assertEqual('bytes%FF', c.quote(value)) value = 'native string' self.assertEqual('native%20string', c.quote(value)) value = u'unicode string' self.assertEqual('unicode%20string', c.quote(value)) value = u'unicode:\xe9\u20ac' self.assertEqual('unicode%3A%C3%A9%E2%82%AC', c.quote(value)) def test_parse_header_string(self): value = b'bytes' self.assertEqual(u'bytes', c.parse_header_string(value)) value = u'unicode:\xe9\u20ac' self.assertEqual(u'unicode:\xe9\u20ac', c.parse_header_string(value)) value = 'native%20string' self.assertEqual(u'native string', c.parse_header_string(value)) value = b'encoded%20bytes%E2%82%AC' self.assertEqual(u'encoded bytes\u20ac', c.parse_header_string(value)) value = 'encoded%20unicode%E2%82%AC' self.assertEqual(u'encoded unicode\u20ac', c.parse_header_string(value)) value = b'bad%20bytes%ff%E2%82%AC' self.assertEqual(u'bad%20bytes%ff%E2%82%AC', c.parse_header_string(value)) value = u'bad%20unicode%ff\u20ac' self.assertEqual(u'bad%20unicode%ff\u20ac', c.parse_header_string(value)) value = b'really%20bad\xffbytes' self.assertEqual(u'really%2520bad%FFbytes', c.parse_header_string(value)) def test_http_connection(self): url = 'http://www.test.com' _junk, conn = c.http_connection(url) self.assertIs(type(conn), c.HTTPConnection) url = 'https://www.test.com' _junk, conn = c.http_connection(url) self.assertIs(type(conn), c.HTTPConnection) url = 'ftp://www.test.com' self.assertRaises(c.ClientException, c.http_connection, url) def test_encode_meta_headers(self): headers = {'abc': '123', u'x-container-meta-\u0394': 123, u'x-account-meta-\u0394': 12.3, u'x-object-meta-\u0394': True} r = swiftclient.encode_meta_headers(headers) self.assertEqual(len(headers), len(r)) # ensure non meta headers are not encoded self.assertIs(type(r.get('abc')), binary_type) del r['abc'] for k, v in r.items(): self.assertIs(type(k), binary_type) self.assertIs(type(v), binary_type) self.assertIn(v, (b'123', b'12.3', b'True')) def test_set_user_agent_default(self): _junk, conn = c.http_connection('http://www.example.com') req_headers = {} def my_request_handler(*a, **kw): req_headers.update(kw.get('headers', {})) conn._request = my_request_handler # test the default conn.request('GET', '/') ua = req_headers.get('user-agent', 'XXX-MISSING-XXX') self.assertTrue(ua.startswith('python-swiftclient-')) def test_set_user_agent_per_request_override(self): _junk, conn = c.http_connection('http://www.example.com') req_headers = {} def my_request_handler(*a, **kw): req_headers.update(kw.get('headers', {})) conn._request = my_request_handler # test if it's actually set conn.request('GET', '/', headers={'User-Agent': 'Me'}) ua = req_headers.get('user-agent', 'XXX-MISSING-XXX') self.assertEqual(ua, b'Me', req_headers) def test_set_user_agent_default_override(self): _junk, conn = c.http_connection( 'http://www.example.com', default_user_agent='a-new-default') req_headers = {} def my_request_handler(*a, **kw): req_headers.update(kw.get('headers', {})) conn._request = my_request_handler # test setting a default conn._request = my_request_handler conn.request('GET', '/') ua = req_headers.get('user-agent', 'XXX-MISSING-XXX') self.assertEqual(ua, 'a-new-default') class TestGetAuth(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200) url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf') self.assertIsNone(url) self.assertIsNone(token) def test_invalid_auth(self): self.assertRaises(c.ClientException, c.get_auth, 'http://www.tests.com', 'asdf', 'asdf', auth_version=""foo"") def test_auth_v1(self): c.http_connection = self.fake_http_connection(200, auth_v1=True) url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', auth_version=""1.0"") self.assertEqual(url, 'storageURL') self.assertEqual(token, 'someauthtoken') def test_auth_v1_insecure(self): c.http_connection = self.fake_http_connection(200, 200, auth_v1=True) url, token = c.get_auth('http://www.test.com/invalid_cert', 'asdf', 'asdf', auth_version='1.0', insecure=True) self.assertEqual(url, 'storageURL') self.assertEqual(token, 'someauthtoken') with self.assertRaises(c.ClientException) as exc_context: c.get_auth('http://www.test.com/invalid_cert', 'asdf', 'asdf', auth_version='1.0') # TODO: this test is really on validating the mock and not the # the full plumbing into the requests's 'verify' option self.assertIn('invalid_certificate', str(exc_context.exception)) def test_auth_v1_timeout(self): # this test has some overlap with # TestConnection.test_timeout_passed_down but is required to check that # get_auth does the right thing when it is not passed a timeout arg orig_http_connection = c.http_connection timeouts = [] def fake_request_handler(*a, **kw): if 'timeout' in kw: timeouts.append(kw['timeout']) else: timeouts.append(None) return MockHttpResponse( status=200, headers={ 'x-auth-token': 'a_token', 'x-storage-url': 'http://files.example.com/v1/AUTH_user'}) def fake_connection(*a, **kw): url, conn = orig_http_connection(*a, **kw) conn._request = fake_request_handler return url, conn with mock.patch('swiftclient.client.http_connection', fake_connection): c.get_auth('http://www.test.com', 'asdf', 'asdf', auth_version=""1.0"", timeout=42.0) c.get_auth('http://www.test.com', 'asdf', 'asdf', auth_version=""1.0"", timeout=None) c.get_auth('http://www.test.com', 'asdf', 'asdf', auth_version=""1.0"") self.assertEqual(timeouts, [42.0, None, None]) def test_auth_v2_timeout(self): # this test has some overlap with # TestConnection.test_timeout_passed_down but is required to check that # get_auth does the right thing when it is not passed a timeout arg fake_ks = FakeKeystone(endpoint='http://some_url', token='secret') with mock.patch('swiftclient.client.ksclient_v2', fake_ks): c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=dict(tenant_name='tenant'), auth_version=""2.0"", timeout=42.0) c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=dict(tenant_name='tenant'), auth_version=""2.0"", timeout=None) c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=dict(tenant_name='tenant'), auth_version=""2.0"") self.assertEqual(3, len(fake_ks.calls)) timeouts = [call['timeout'] for call in fake_ks.calls] self.assertEqual([42.0, None, None], timeouts) def test_auth_v2_with_tenant_name(self): os_options = {'tenant_name': 'asdf'} req_args = {'auth_version': '2.0'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_tenant_id(self): os_options = {'tenant_id': 'asdf'} req_args = {'auth_version': '2.0'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_project_name(self): os_options = {'project_name': 'asdf'} req_args = {'auth_version': '2.0'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_project_id(self): os_options = {'project_id': 'asdf'} req_args = {'auth_version': '2.0'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_no_tenant_name_or_tenant_id(self): with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone({})): self.assertRaises(c.ClientException, c.get_auth, 'http://www.tests.com', 'asdf', 'asdf', os_options={}, auth_version='2.0') def test_auth_v2_with_tenant_name_none_and_tenant_id_none(self): os_options = {'tenant_name': None, 'tenant_id': None} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options)): self.assertRaises(c.ClientException, c.get_auth, 'http://www.tests.com', 'asdf', 'asdf', os_options=os_options, auth_version='2.0') def test_auth_v2_with_tenant_user_in_user(self): tenant_option = {'tenant_name': 'foo'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(tenant_option)): url, token = c.get_auth('http://www.test.com', 'foo:bar', 'asdf', os_options={}, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_tenant_name_no_os_options(self): tenant_option = {'tenant_name': 'asdf'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(tenant_option)): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', tenant_name='asdf', os_options={}, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_os_options(self): os_options = {'service_type': 'object-store', 'endpoint_type': 'internalURL', 'tenant_name': 'asdf'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options)): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_tenant_user_in_user_no_os_options(self): tenant_option = {'tenant_name': 'foo'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(tenant_option)): url, token = c.get_auth('http://www.test.com', 'foo:bar', 'asdf', auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_with_os_region_name(self): os_options = {'region_name': 'good-region', 'tenant_name': 'asdf'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options)): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""2.0"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_auth_v2_no_endpoint(self): os_options = {'region_name': 'unknown_region', 'tenant_name': 'asdf'} with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options, c.ClientException)): self.assertRaises(c.ClientException, c.get_auth, 'http://www.tests.com', 'asdf', 'asdf', os_options=os_options, auth_version='2.0') def test_auth_v2_ks_exception(self): with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone({}, c.ClientException)): self.assertRaises(c.ClientException, c.get_auth, 'http://www.tests.com', 'asdf', 'asdf', os_options={}, auth_version='2.0') def test_auth_v2_cacert(self): os_options = {'tenant_name': 'foo'} auth_url_secure = 'https://www.tests.com' auth_url_insecure = 'https://www.tests.com/self-signed-certificate' with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options, None)): url, token = c.get_auth(auth_url_secure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', insecure=False) self.assertTrue(url.startswith(""http"")) self.assertTrue(token) url, token = c.get_auth(auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', cacert='ca.pem', insecure=False) self.assertTrue(url.startswith(""http"")) self.assertTrue(token) self.assertRaises(c.ClientException, c.get_auth, auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0') self.assertRaises(c.ClientException, c.get_auth, auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', insecure=False) def test_auth_v2_insecure(self): os_options = {'tenant_name': 'foo'} auth_url_secure = 'https://www.tests.com' auth_url_insecure = 'https://www.tests.com/invalid-certificate' with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options, None)): url, token = c.get_auth(auth_url_secure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0') self.assertTrue(url.startswith(""http"")) self.assertTrue(token) url, token = c.get_auth(auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', insecure=True) self.assertTrue(url.startswith(""http"")) self.assertTrue(token) self.assertRaises(c.ClientException, c.get_auth, auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0') self.assertRaises(c.ClientException, c.get_auth, auth_url_insecure, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', insecure=False) def test_auth_v2_cert(self): os_options = {'tenant_name': 'foo'} auth_url_no_sslauth = 'https://www.tests.com' auth_url_sslauth = 'https://www.tests.com/client-certificate' with mock.patch('swiftclient.client.get_auth_keystone', fake_get_auth_keystone(os_options, None)): url, token = c.get_auth(auth_url_no_sslauth, 'asdf', 'asdf', os_options=os_options, auth_version='2.0') self.assertTrue(url.startswith(""http"")) self.assertTrue(token) url, token = c.get_auth(auth_url_sslauth, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', cert='minnie', cert_key='mickey') self.assertTrue(url.startswith(""http"")) self.assertTrue(token) self.assertRaises(c.ClientException, c.get_auth, auth_url_sslauth, 'asdf', 'asdf', os_options=os_options, auth_version='2.0') self.assertRaises(c.ClientException, c.get_auth, auth_url_sslauth, 'asdf', 'asdf', os_options=os_options, auth_version='2.0', cert='minnie') def test_auth_v3_with_tenant_name(self): # check the correct auth version is passed to get_auth_keystone os_options = {'tenant_name': 'asdf'} req_args = {'auth_version': '3'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', os_options=os_options, auth_version=""3"") self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_get_keystone_client_2_0(self): # check the correct auth version is passed to get_auth_keystone os_options = {'tenant_name': 'asdf'} req_args = {'auth_version': '2.0'} ks = fake_get_auth_keystone(os_options, required_kwargs=req_args) with mock.patch('swiftclient.client.get_auth_keystone', ks): url, token = c.get_keystoneclient_2_0('http://www.test.com', 'asdf', 'asdf', os_options=os_options) self.assertTrue(url.startswith(""http"")) self.assertTrue(token) def test_get_auth_keystone_versionless(self): fake_ks = FakeKeystone(endpoint='http://some_url', token='secret') with mock.patch('swiftclient.client.ksclient_v3', fake_ks): c.get_auth_keystone('http://authurl', 'user', 'key', {}) self.assertEqual(1, len(fake_ks.calls)) self.assertEqual('http://authurl/v3', fake_ks.calls[0].get('auth_url')) def test_get_auth_keystone_versionless_auth_version_set(self): fake_ks = FakeKeystone(endpoint='http://some_url', token='secret') with mock.patch('swiftclient.client.ksclient_v2', fake_ks): c.get_auth_keystone('http://auth_url', 'user', 'key', {}, auth_version='2.0') self.assertEqual(1, len(fake_ks.calls)) self.assertEqual('http://auth_url/v2.0', fake_ks.calls[0].get('auth_url')) def test_get_auth_keystone_versionful(self): fake_ks = FakeKeystone(endpoint='http://some_url', token='secret') with mock.patch('swiftclient.client.ksclient_v3', fake_ks): c.get_auth_keystone('http://auth_url/v3', 'user', 'key', {}, auth_version='3') self.assertEqual(1, len(fake_ks.calls)) self.assertEqual('http://auth_url/v3', fake_ks.calls[0].get('auth_url')) def test_get_auth_keystone_devstack_versionful(self): fake_ks = FakeKeystone( endpoint='http://storage.example.com/v1/AUTH_user', token='secret') with mock.patch('swiftclient.client.ksclient_v3', fake_ks): c.get_auth_keystone('https://192.168.8.8/identity/v3', 'user', 'key', {}, auth_version='3') self.assertEqual(1, len(fake_ks.calls)) self.assertEqual('https://192.168.8.8/identity/v3', fake_ks.calls[0].get('auth_url')) def test_get_auth_keystone_devstack_versionless(self): fake_ks = FakeKeystone( endpoint='http://storage.example.com/v1/AUTH_user', token='secret') with mock.patch('swiftclient.client.ksclient_v3', fake_ks): c.get_auth_keystone('https://192.168.8.8/identity', 'user', 'key', {}, auth_version='3') self.assertEqual(1, len(fake_ks.calls)) self.assertEqual('https://192.168.8.8/identity/v3', fake_ks.calls[0].get('auth_url')) def test_auth_keystone_url_some_junk_nonsense(self): fake_ks = FakeKeystone( endpoint='http://storage.example.com/v1/AUTH_user', token='secret') with mock.patch('swiftclient.client.ksclient_v3', fake_ks): c.get_auth_keystone('http://blah.example.com/v2moo', 'user', 'key', {}, auth_version='3') self.assertEqual(1, len(fake_ks.calls)) # v2 looks sorta version-y, but it's not an exact match, so this is # probably about just as bad as anything else we might guess at self.assertEqual('http://blah.example.com/v2moo/v3', fake_ks.calls[0].get('auth_url')) def test_auth_with_session(self): mock_session = mock.MagicMock() mock_session.get_endpoint.return_value = 'http://storagehost/v1/acct' mock_session.get_token.return_value = 'token' url, token = c.get_auth('http://www.test.com', 'asdf', 'asdf', session=mock_session) self.assertEqual(url, 'http://storagehost/v1/acct') self.assertTrue(token) class TestGetAccount(MockHttpTest): def test_no_content(self): c.http_connection = self.fake_http_connection(204) value = c.get_account('http://www.test.com/v1/acct', 'asdf')[1] self.assertEqual(value, []) self.assertRequests([ ('GET', '/v1/acct?format=json', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) def test_param_marker(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&marker=marker"") c.get_account('http://www.test.com/v1/acct', 'asdf', marker='marker') self.assertRequests([ ('GET', '/v1/acct?format=json&marker=marker', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) def test_param_limit(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&limit=10"") c.get_account('http://www.test.com/v1/acct', 'asdf', limit=10) self.assertRequests([ ('GET', '/v1/acct?format=json&limit=10', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) def test_param_prefix(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&prefix=asdf/"") c.get_account('http://www.test.com/v1/acct', 'asdf', prefix='asdf/') self.assertRequests([ ('GET', '/v1/acct?format=json&prefix=asdf/', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) def test_param_end_marker(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&end_marker=end_marker"") c.get_account('http://www.test.com/v1/acct', 'asdf', end_marker='end_marker') self.assertRequests([ ('GET', '/v1/acct?format=json&end_marker=end_marker', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) def test_param_delimiter(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&delimiter=-"") c.get_account('http://www.test.com/v1/acct', 'asdf', delimiter='-') self.assertRequests([ ('GET', '/v1/acct?format=json&delimiter=-', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) class TestHeadAccount(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200, headers={ 'x-account-meta-color': 'blue', }) resp_headers = c.head_account('http://www.tests.com', 'asdf') self.assertEqual(resp_headers['x-account-meta-color'], 'blue') self.assertRequests([ ('HEAD', 'http://www.tests.com', '', {'x-auth-token': 'asdf'}) ]) def test_server_error(self): body = 'c' * 65 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.head_account('http://www.tests.com', 'asdf') e = exc_context.exception self.assertEqual(e.http_response_content, body) self.assertEqual(e.http_status, 500) self.assertRequests([ ('HEAD', 'http://www.tests.com', '', {'x-auth-token': 'asdf'}) ]) # TODO: this is a fairly brittle test of the __repr__ on the # ClientException which should probably be in a targeted test new_body = ""[first 60 chars of response] "" + body[0:60] self.assertEqual(e.__str__()[-89:], new_body) class TestPostAccount(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200, headers={ 'X-Account-Meta-Color': 'blue', }, body='foo') headers = {'x-account-meta-shape': 'square'} resp_headers, body = c.post_account( 'http://www.tests.com/path/to/account', 'asdf', headers, query_string='bar=baz', data='some data') self.assertEqual('blue', resp_headers.get('x-account-meta-color')) self.assertEqual('foo', body) self.assertRequests([ ('POST', 'http://www.tests.com/path/to/account?bar=baz', 'some data', {'x-auth-token': 'asdf', 'x-account-meta-shape': 'square'}) ]) # Check that we didn't mutate the request ehader dict self.assertEqual(headers, {'x-account-meta-shape': 'square'}) def test_server_error(self): body = 'c' * 65 c.http_connection = self.fake_http_connection(500, body=body) with self.assertRaises(c.ClientException) as exc_mgr: c.post_account('http://www.tests.com', 'asdf', {}) self.assertEqual(exc_mgr.exception.http_response_content, body) self.assertEqual(exc_mgr.exception.http_status, 500) self.assertRequests([ ('POST', 'http://www.tests.com', None, {'x-auth-token': 'asdf'}) ]) # TODO: this is a fairly brittle test of the __repr__ on the # ClientException which should probably be in a targeted test new_body = ""[first 60 chars of response] "" + body[0:60] self.assertEqual(exc_mgr.exception.__str__()[-89:], new_body) class TestGetContainer(MockHttpTest): def test_no_content(self): c.http_connection = self.fake_http_connection(204) value = c.get_container('http://www.test.com/v1/acct', 'token', 'container')[1] self.assertEqual(value, []) self.assertRequests([ ('GET', '/v1/acct/container?format=json', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_param_marker(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&marker=marker"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', marker='marker') self.assertRequests([ ('GET', '/v1/acct/container?format=json&marker=marker', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_param_limit(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&limit=10"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', limit=10) self.assertRequests([ ('GET', '/v1/acct/container?format=json&limit=10', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_param_prefix(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&prefix=asdf/"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', prefix='asdf/') self.assertRequests([ ('GET', '/v1/acct/container?format=json&prefix=asdf/', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_param_delimiter(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&delimiter=/"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', delimiter='/') self.assertRequests([ ('GET', '/v1/acct/container?format=json&delimiter=/', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_param_end_marker(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&end_marker=end_marker"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', end_marker='end_marker') self.assertRequests([ ('GET', '/v1/acct/container?format=json&end_marker=end_marker', '', {'x-auth-token': 'token', 'accept-encoding': 'gzip'}), ]) def test_param_path(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json&path=asdf"") c.get_container('http://www.test.com/v1/acct', 'token', 'container', path='asdf') self.assertRequests([ ('GET', '/v1/acct/container?format=json&path=asdf', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'token'}), ]) def test_request_headers(self): c.http_connection = self.fake_http_connection( 204, query_string=""format=json"") conn = c.http_connection('http://www.test.com') headers = {'x-client-key': 'client key'} c.get_container('url_is_irrelevant', 'TOKEN', 'container', http_conn=conn, headers=headers) self.assertRequests([ ('GET', '/container?format=json', '', { 'x-auth-token': 'TOKEN', 'x-client-key': 'client key', 'accept-encoding': 'gzip', }), ]) def test_query_string(self): c.http_connection = self.fake_http_connection( 200, query_string=""format=json&hello=20"", body=b'[]') c.get_container('http://www.test.com', 'asdf', 'asdf', query_string=""hello=20"") self.assertRequests([ ('GET', '/asdf?format=json&hello=20', '', { 'accept-encoding': 'gzip', 'x-auth-token': 'asdf'}), ]) class TestHeadContainer(MockHttpTest): def test_head_ok(self): fake_conn = self.fake_http_connection( 200, headers={'x-container-meta-color': 'blue'}) with mock.patch('swiftclient.client.http_connection', new=fake_conn): resp = c.head_container('https://example.com/v1/AUTH_test', 'token', 'container') self.assertEqual(resp['x-container-meta-color'], 'blue') self.assertRequests([ ('HEAD', 'https://example.com/v1/AUTH_test/container', '', {'x-auth-token': 'token'}), ]) def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.head_container('http://www.test.com', 'asdf', 'container') e = exc_context.exception self.assertRequests([ ('HEAD', '/container', '', {'x-auth-token': 'asdf'}), ]) self.assertEqual(e.http_status, 500) self.assertEqual(e.http_response_content, body) self.assertEqual(e.http_response_headers, headers) class TestPutContainer(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200) value = c.put_container('http://www.test.com', 'token', 'container') self.assertIsNone(value) self.assertRequests([ ('PUT', '/container', '', { 'x-auth-token': 'token', 'content-length': '0'}), ]) def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.put_container('http://www.test.com', 'token', 'container') self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) self.assertRequests([ ('PUT', '/container', '', { 'x-auth-token': 'token', 'content-length': '0'}), ]) def test_query_string(self): c.http_connection = self.fake_http_connection(200, query_string=""hello=20"") c.put_container('http://www.test.com', 'asdf', 'asdf', query_string=""hello=20"") for req in self.iter_request_log(): self.assertEqual(req['method'], 'PUT') self.assertEqual(req['parsed_path'].path, '/asdf') self.assertEqual(req['parsed_path'].query, 'hello=20') self.assertEqual(req['headers']['x-auth-token'], 'asdf') class TestDeleteContainer(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200) value = c.delete_container('http://www.test.com', 'token', 'container') self.assertIsNone(value) self.assertRequests([ ('DELETE', '/container', '', { 'x-auth-token': 'token'}), ]) def test_query_string(self): c.http_connection = self.fake_http_connection(200, query_string=""hello=20"") c.delete_container('http://www.test.com', 'token', 'container', query_string=""hello=20"") self.assertRequests([ ('DELETE', 'http://www.test.com/container?hello=20', '', { 'x-auth-token': 'token'}) ]) class TestGetObject(MockHttpTest): def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.get_object('http://www.test.com', 'asdf', 'asdf', 'asdf') self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) def test_query_string(self): c.http_connection = self.fake_http_connection(200, query_string=""hello=20"") c.get_object('http://www.test.com', 'asdf', 'asdf', 'asdf', query_string=""hello=20"") self.assertRequests([ ('GET', '/asdf/asdf?hello=20', '', { 'x-auth-token': 'asdf'}), ]) def test_get_object_as_string(self): c.http_connection = self.fake_http_connection(200, body='abcde') __, resp = c.get_object('http://storage.example.com', 'TOKEN', 'container_name', 'object_name') self.assertEqual(resp, 'abcde') def test_request_headers(self): c.http_connection = self.fake_http_connection(200) conn = c.http_connection('http://www.test.com') headers = {'Range': 'bytes=1-2'} c.get_object('url_is_irrelevant', 'TOKEN', 'container', 'object', http_conn=conn, headers=headers) self.assertRequests([ ('GET', '/container/object', '', { 'x-auth-token': 'TOKEN', 'range': 'bytes=1-2', }), ]) def test_response_headers(self): c.http_connection = self.fake_http_connection( 200, headers={'X-Utf-8-Header': b't%c3%a9st', 'X-Non-Utf-8-Header': b'%ff', 'X-Binary-Header': b'\xff'}) conn = c.http_connection('http://www.test.com') headers, data = c.get_object('url_is_irrelevant', 'TOKEN', 'container', 'object', http_conn=conn) self.assertEqual(u't\xe9st', headers.get('x-utf-8-header', '')) self.assertEqual(u'%ff', headers.get('x-non-utf-8-header', '')) self.assertEqual(u'%FF', headers.get('x-binary-header', '')) def test_chunk_size_read_method(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url/', 'tToken') c.http_connection = self.fake_http_connection(200, body='abcde') __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=3) self.assertTrue(hasattr(resp, 'read')) self.assertEqual(resp.read(3), 'abc') self.assertEqual(resp.read(None), 'de') self.assertEqual(resp.read(), '') def test_chunk_size_iter(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url/', 'tToken') c.http_connection = self.fake_http_connection(200, body='abcde') __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=3) self.assertTrue(hasattr(resp, 'next')) self.assertEqual(next(resp), 'abc') self.assertEqual(next(resp), 'de') self.assertRaises(StopIteration, next, resp) def test_chunk_size_read_and_iter(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url/', 'tToken') c.http_connection = self.fake_http_connection(200, body='abcdef') __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=2) self.assertTrue(hasattr(resp, 'read')) self.assertEqual(resp.read(3), 'abc') self.assertEqual(next(resp), 'de') self.assertEqual(resp.read(), 'f') self.assertRaises(StopIteration, next, resp) self.assertEqual(resp.read(), '') def test_chunk_size_iter_chunked_no_retry(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url/', 'tToken') c.http_connection = self.fake_http_connection( 200, body='abcdef', headers={'Transfer-Encoding': 'chunked'}) __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=2) self.assertEqual(next(resp), 'ab') # simulate a dropped connection resp.resp.read() self.assertRaises(StopIteration, next, resp) def test_chunk_size_iter_retry(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url', 'tToken') c.http_connection = self.fake_http_connection( StubResponse(200, 'abcdef', {'etag': 'some etag', 'content-length': '6'}), StubResponse(206, 'cdef', {'etag': 'some etag', 'content-length': '4', 'content-range': 'bytes 2-5/6'}), StubResponse(206, 'ef', {'etag': 'some etag', 'content-length': '2', 'content-range': 'bytes 4-5/6'}), ) __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=2) self.assertEqual(next(resp), 'ab') self.assertEqual(1, conn.attempts) # simulate a dropped connection resp.resp.read() self.assertEqual(next(resp), 'cd') self.assertEqual(2, conn.attempts) # simulate a dropped connection resp.resp.read() self.assertEqual(next(resp), 'ef') self.assertEqual(3, conn.attempts) self.assertRaises(StopIteration, next, resp) self.assertRequests([ ('GET', '/asdf/asdf', '', { 'x-auth-token': 'tToken', }), ('GET', '/asdf/asdf', '', { 'range': 'bytes=2-', 'if-match': 'some etag', 'x-auth-token': 'tToken', }), ('GET', '/asdf/asdf', '', { 'range': 'bytes=4-', 'if-match': 'some etag', 'x-auth-token': 'tToken', }), ]) def test_chunk_size_iter_retry_no_range_support(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url', 'tToken') c.http_connection = self.fake_http_connection(*[ StubResponse(200, 'abcdef', {'etag': 'some etag', 'content-length': '6'}) ] * 3) __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=2) self.assertEqual(next(resp), 'ab') self.assertEqual(1, conn.attempts) # simulate a dropped connection resp.resp.read() self.assertEqual(next(resp), 'cd') self.assertEqual(2, conn.attempts) # simulate a dropped connection resp.resp.read() self.assertEqual(next(resp), 'ef') self.assertEqual(3, conn.attempts) self.assertRaises(StopIteration, next, resp) self.assertRequests([ ('GET', '/asdf/asdf', '', { 'x-auth-token': 'tToken', }), ('GET', '/asdf/asdf', '', { 'range': 'bytes=2-', 'if-match': 'some etag', 'x-auth-token': 'tToken', }), ('GET', '/asdf/asdf', '', { 'range': 'bytes=4-', 'if-match': 'some etag', 'x-auth-token': 'tToken', }), ]) def test_chunk_size_iter_retry_bad_range_response(self): conn = c.Connection('http://auth.url/', 'some_user', 'some_key') with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.url', 'tToken') c.http_connection = self.fake_http_connection( StubResponse(200, 'abcdef', {'etag': 'some etag', 'content-length': '6'}), StubResponse(206, 'abcdef', {'etag': 'some etag', 'content-length': '6', 'content-range': 'chunk 1-2/3'}) ) __, resp = conn.get_object('asdf', 'asdf', resp_chunk_size=2) self.assertEqual(next(resp), 'ab') self.assertEqual(1, conn.attempts) # simulate a dropped connection resp.resp.read() self.assertRaises(c.ClientException, next, resp) self.assertRequests([ ('GET', '/asdf/asdf', '', { 'x-auth-token': 'tToken', }), ('GET', '/asdf/asdf', '', { 'range': 'bytes=2-', 'if-match': 'some etag', 'x-auth-token': 'tToken', }), ]) def test_get_object_with_resp_chunk_size_zero(self): def get_connection(self): def get_auth(): return 'http://auth.test.com', 'token' conn = c.Connection('http://www.test.com', 'asdf', 'asdf') self.assertIs(type(conn), c.Connection) conn.get_auth = get_auth self.assertEqual(conn.attempts, 0) return conn with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = get_connection(self) conn.get_object('container1', 'obj1', resp_chunk_size=0) self.assertEqual(conn.attempts, 1) class TestHeadObject(MockHttpTest): def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.head_object('http://www.test.com', 'asdf', 'asdf', 'asdf') self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) def test_request_headers(self): c.http_connection = self.fake_http_connection(204) conn = c.http_connection('http://www.test.com') headers = {'x-client-key': 'client key'} c.head_object('url_is_irrelevant', 'TOKEN', 'container', 'asdf', http_conn=conn, headers=headers) self.assertRequests([ ('HEAD', '/container/asdf', '', { 'x-auth-token': 'TOKEN', 'x-client-key': 'client key', }), ]) def test_query_string(self): c.http_connection = self.fake_http_connection(204) conn = c.http_connection('http://www.test.com') query_string = 'foo=bar' c.head_object('url_is_irrelevant', 'token', 'container', 'key', http_conn=conn, query_string=query_string) self.assertRequests([ ('HEAD', '/container/key?foo=bar', '', {'x-auth-token': 'token'}) ]) class TestPutObject(MockHttpTest): @mock.patch('swiftclient.requests.__version__', '2.2.0') def test_ok(self): c.http_connection = self.fake_http_connection(200) args = ('http://www.test.com', 'TOKEN', 'container', 'obj', 'body', 4) value = c.put_object(*args) self.assertIsInstance(value, six.string_types) self.assertEqual(value, EMPTY_ETAG) self.assertRequests([ ('PUT', '/container/obj', 'body', { 'x-auth-token': 'TOKEN', 'content-length': '4', 'content-type': '' }), ]) def test_unicode_ok(self): conn = c.http_connection(u'http://www.test.com/') mock_file = six.StringIO(u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91') args = (u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', mock_file) text = u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' headers = {'X-Header1': text, 'X-2': '1', 'X-3': ""{'a': 'b'}"", 'a-b': '.x:yz mn:fg:lp'} resp = MockHttpResponse() conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request value = c.put_object(*args, headers=headers, http_conn=conn) self.assertIsInstance(value, six.string_types) # Test for RFC-2616 encoded symbols self.assertIn((""a-b"", b"".x:yz mn:fg:lp""), resp.buffer) # Test unicode header self.assertIn(('x-header1', text.encode('utf8')), resp.buffer) def test_chunk_warning(self): conn = c.http_connection('http://www.test.com/') mock_file = six.StringIO('asdf') args = ('asdf', 'asdf', 'asdf', 'asdf', mock_file) resp = MockHttpResponse() conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request with warnings.catch_warnings(record=True) as w: c.put_object(*args, chunk_size=20, headers={}, http_conn=conn) self.assertEqual(len(w), 0) body = 'c' * 60 c.http_connection = self.fake_http_connection(200, body=body) args = ('http://www.test.com', 'asdf', 'asdf', 'asdf', 'asdf') with warnings.catch_warnings(record=True) as w: c.put_object(*args, chunk_size=20) self.assertEqual(len(w), 1) self.assertTrue(issubclass(w[-1].category, UserWarning)) @mock.patch('swiftclient.requests.__version__', '2.2.0') def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) args = ('http://www.test.com', 'asdf', 'asdf', 'asdf', 'asdf') with self.assertRaises(c.ClientException) as exc_context: c.put_object(*args) e = exc_context.exception self.assertEqual(e.http_response_content, body) self.assertEqual(e.http_response_headers, headers) self.assertEqual(e.http_status, 500) self.assertRequests([ ('PUT', '/asdf/asdf', 'asdf', { 'x-auth-token': 'asdf', 'content-type': ''}), ]) def test_query_string(self): c.http_connection = self.fake_http_connection(200, query_string=""hello=20"") c.put_object('http://www.test.com', 'asdf', 'asdf', 'asdf', query_string=""hello=20"") for req in self.iter_request_log(): self.assertEqual(req['method'], 'PUT') self.assertEqual(req['parsed_path'].path, '/asdf/asdf') self.assertEqual(req['parsed_path'].query, 'hello=20') self.assertEqual(req['headers']['x-auth-token'], 'asdf') def test_raw_upload(self): # Raw upload happens when content_length is passed to put_object conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request raw_data = b'asdf' * 256 raw_data_len = len(raw_data) for kwarg in ({'headers': {'Content-Length': str(raw_data_len)}}, {'content_length': raw_data_len}): with tempfile.TemporaryFile() as mock_file: mock_file.write(raw_data) mock_file.seek(0) c.put_object(url='http://www.test.com', http_conn=conn, contents=mock_file, **kwarg) req_data = resp.requests_params['data'] self.assertIs(type(req_data), swiftclient.utils.LengthWrapper) self.assertEqual(raw_data_len, len(req_data.read())) def test_chunk_upload(self): # Chunked upload happens when no content_length is passed to put_object conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request raw_data = b'asdf' * 256 chunk_size = 16 with tempfile.TemporaryFile() as mock_file: mock_file.write(raw_data) mock_file.seek(0) c.put_object(url='http://www.test.com', http_conn=conn, contents=mock_file, chunk_size=chunk_size) req_data = resp.requests_params['data'] self.assertTrue(hasattr(req_data, '__iter__')) data = b'' for chunk in req_data: self.assertEqual(chunk_size, len(chunk)) data += chunk self.assertEqual(data, raw_data) def test_iter_upload(self): def data(): for chunk in ('foo', '', 'bar'): yield chunk conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request c.put_object(url='http://www.test.com', http_conn=conn, contents=data()) req_headers = resp.requests_params['headers'] self.assertNotIn('Content-Length', req_headers) req_data = resp.requests_params['data'] self.assertTrue(hasattr(req_data, '__iter__')) # If we emit an empty chunk, requests will go ahead and send it, # causing the server to close the connection. So make sure we don't # do that. self.assertEqual(['foo', 'bar'], list(req_data)) def test_md5_mismatch(self): conn = c.http_connection('http://www.test.com') resp = MockHttpResponse(status=200, verify=True, headers={'etag': '""badresponseetag""'}) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request raw_data = b'asdf' * 256 raw_data_md5 = md5(raw_data).hexdigest() chunk_size = 16 with tempfile.TemporaryFile() as mock_file: mock_file.write(raw_data) mock_file.seek(0) contents = swiftclient.utils.ReadableToIterable(mock_file, md5=True) etag = c.put_object(url='http://www.test.com', http_conn=conn, contents=contents, chunk_size=chunk_size) self.assertNotEqual(etag, contents.get_md5sum()) self.assertEqual(etag, 'badresponseetag') self.assertEqual(raw_data_md5, contents.get_md5sum()) def test_md5_match(self): conn = c.http_connection('http://www.test.com') raw_data = b'asdf' * 256 raw_data_md5 = md5(raw_data).hexdigest() resp = MockHttpResponse(status=200, verify=True, headers={'etag': '""' + raw_data_md5 + '""'}) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request chunk_size = 16 with tempfile.TemporaryFile() as mock_file: mock_file.write(raw_data) mock_file.seek(0) contents = swiftclient.utils.ReadableToIterable(mock_file, md5=True) etag = c.put_object(url='http://www.test.com', http_conn=conn, contents=contents, chunk_size=chunk_size) self.assertEqual(raw_data_md5, contents.get_md5sum()) self.assertEqual(etag, contents.get_md5sum()) def test_params(self): conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request c.put_object(url='http://www.test.com', http_conn=conn, etag='1234-5678', content_type='text/plain') request_header = resp.requests_params['headers'] self.assertEqual(request_header['etag'], b'1234-5678') self.assertEqual(request_header['content-type'], b'text/plain') @mock.patch('swiftclient.requests.__version__', '2.2.0') def test_no_content_type_old_requests(self): conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request c.put_object(url='http://www.test.com', http_conn=conn) request_header = resp.requests_params['headers'] self.assertEqual(request_header['content-type'], b'') @mock.patch('swiftclient.requests.__version__', '2.4.0') def test_no_content_type_new_requests(self): conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request c.put_object(url='http://www.test.com', http_conn=conn) request_header = resp.requests_params['headers'] self.assertNotIn('content-type', request_header) def test_content_type_in_headers(self): conn = c.http_connection(u'http://www.test.com/') resp = MockHttpResponse(status=200) conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request # title-case header hdrs = {'Content-Type': 'text/Plain'} c.put_object(url='http://www.test.com', http_conn=conn, headers=hdrs) request_header = resp.requests_params['headers'] self.assertEqual(request_header['content-type'], b'text/Plain') # method param overrides headers c.put_object(url='http://www.test.com', http_conn=conn, headers=hdrs, content_type='image/jpeg') request_header = resp.requests_params['headers'] self.assertEqual(request_header['content-type'], b'image/jpeg') class TestPostObject(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200) delete_at = 2.1 # not str! we don't know what other devs will use! args = ('http://www.test.com', 'token', 'container', 'obj', {'X-Object-Meta-Test': 'mymeta', 'X-Delete-At': delete_at}) c.post_object(*args) self.assertRequests([ ('POST', '/container/obj', '', { 'x-auth-token': 'token', 'X-Object-Meta-Test': 'mymeta', 'X-Delete-At': delete_at}), ]) # Check that the request header dict didn't get mutated self.assertEqual(args[-1], { 'X-Object-Meta-Test': 'mymeta', 'X-Delete-At': delete_at, }) def test_unicode_ok(self): conn = c.http_connection(u'http://www.test.com/') args = (u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91', u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91') text = u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' headers = {'X-Header1': text, b'X-Header2': 'value', 'X-2': '1', 'X-3': ""{'a': 'b'}"", 'a-b': '.x:yz mn:kl:qr', 'X-Object-Meta-Header-not-encoded': text, b'X-Object-Meta-Header-encoded': 'value'} resp = MockHttpResponse() conn[1].getresponse = resp.fake_response conn[1]._request = resp._fake_request c.post_object(*args, headers=headers, http_conn=conn) # Test for RFC-2616 encoded symbols self.assertIn(('a-b', b"".x:yz mn:kl:qr""), resp.buffer) # Test unicode header self.assertIn(('x-header1', text.encode('utf8')), resp.buffer) self.assertIn((b'x-object-meta-header-not-encoded', text.encode('utf8')), resp.buffer) self.assertIn((b'x-object-meta-header-encoded', b'value'), resp.buffer) self.assertIn((b'x-header2', b'value'), resp.buffer) def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) args = ('http://www.test.com', 'token', 'container', 'obj', {}) with self.assertRaises(c.ClientException) as exc_context: c.post_object(*args) self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) self.assertRequests([ ('POST', 'http://www.test.com/container/obj', '', { 'x-auth-token': 'token', }), ]) class TestCopyObject(MockHttpTest): def test_server_error(self): c.http_connection = self.fake_http_connection(500) self.assertRaises( c.ClientException, c.copy_object, 'http://www.test.com/v1/AUTH', 'asdf', 'asdf', 'asdf') def test_ok(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj', destination='/container2/obj') self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'X-Auth-Token': 'token', 'Destination': '/container2/obj', }), ]) def test_service_token(self): c.http_connection = self.fake_http_connection(200) c.copy_object('http://www.test.com/v1/AUTH', None, 'container', 'obj', destination='/container2/obj', service_token=""TOKEN"") self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'X-Service-Token': 'TOKEN', 'Destination': '/container2/obj', }), ]) def test_headers(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj', destination='/container2/obj', headers={'some-hdr': 'a', 'other-hdr': 'b'}) self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'X-Auth-Token': 'token', 'Destination': '/container2/obj', 'some-hdr': 'a', 'other-hdr': 'b', }), ]) def test_fresh_metadata_default(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj', '/container2/obj', {'x-fresh-metadata': 'hdr-value'}) self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'X-Auth-Token': 'token', 'Destination': '/container2/obj', 'X-Fresh-Metadata': 'hdr-value', }), ]) def test_fresh_metadata_true(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj', destination='/container2/obj', headers={'x-fresh-metadata': 'hdr-value'}, fresh_metadata=True) self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'X-Auth-Token': 'token', 'Destination': '/container2/obj', 'X-Fresh-Metadata': 'true', }), ]) def test_fresh_metadata_false(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj', destination='/container2/obj', headers={'x-fresh-metadata': 'hdr-value'}, fresh_metadata=False) self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'x-auth-token': 'token', 'Destination': '/container2/obj', 'X-Fresh-Metadata': 'false', }), ]) def test_no_destination(self): c.http_connection = self.fake_http_connection(200) c.copy_object( 'http://www.test.com/v1/AUTH', 'token', 'container', 'obj') self.assertRequests([ ('COPY', 'http://www.test.com/v1/AUTH/container/obj', '', { 'x-auth-token': 'token', 'Destination': '/container/obj', }), ]) class TestDeleteObject(MockHttpTest): def test_ok(self): c.http_connection = self.fake_http_connection(200) c.delete_object('http://www.test.com', 'token', 'container', 'obj') self.assertRequests([ ('DELETE', 'http://www.test.com/container/obj', '', { 'x-auth-token': 'token', }), ]) def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} c.http_connection = self.fake_http_connection( StubResponse(500, body, headers)) with self.assertRaises(c.ClientException) as exc_context: c.delete_object('http://www.test.com', 'asdf', 'asdf', 'asdf') self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) def test_query_string(self): c.http_connection = self.fake_http_connection(200, query_string=""hello=20"") c.delete_object('http://www.test.com', 'token', 'container', 'obj', query_string=""hello=20"") self.assertRequests([ ('DELETE', 'http://www.test.com/container/obj?hello=20', '', { 'x-auth-token': 'token', }), ]) class TestGetCapabilities(MockHttpTest): def test_ok(self): conn = self.fake_http_connection(200, body=b'{}') http_conn = conn('http://www.test.com/info') info = c.get_capabilities(http_conn) self.assertRequests([ ('GET', '/info', '', {'Accept-Encoding': 'gzip'}), ]) self.assertEqual(info, {}) self.assertTrue(http_conn[1].resp.has_been_read) def test_server_error(self): body = 'c' * 60 headers = {'foo': 'bar'} conn = self.fake_http_connection( StubResponse(500, body, headers)) http_conn = conn('http://www.test.com/info') with self.assertRaises(c.ClientException) as exc_context: c.get_capabilities(http_conn) self.assertEqual(exc_context.exception.http_response_content, body) self.assertEqual(exc_context.exception.http_response_headers, headers) def test_conn_get_capabilities_with_auth(self): auth_headers = { 'x-auth-token': 'token', 'x-storage-url': 'http://storage.example.com/v1/AUTH_test' } auth_v1_response = StubResponse(headers=auth_headers) stub_info = {'swift': {'fake': True}} info_response = StubResponse(body=b'{""swift"":{""fake"":true}}') fake_conn = self.fake_http_connection(auth_v1_response, info_response) conn = c.Connection('http://auth.example.com/auth/v1.0', 'user', 'key') with mock.patch('swiftclient.client.http_connection', new=fake_conn): info = conn.get_capabilities() self.assertEqual(info, stub_info) self.assertRequests([ ('GET', '/auth/v1.0', '', { 'x-auth-user': 'user', 'x-auth-key': 'key'}), ('GET', 'http://storage.example.com/info', '', { 'accept-encoding': 'gzip'}), ]) def test_conn_get_capabilities_with_os_auth(self): fake_keystone = fake_get_auth_keystone( storage_url='http://storage.example.com/v1/AUTH_test') stub_info = {'swift': {'fake': True}} info_response = StubResponse(body=b'{""swift"":{""fake"":true}}') fake_conn = self.fake_http_connection(info_response) os_options = {'project_id': 'test'} conn = c.Connection('http://keystone.example.com/v3.0', 'user', 'key', os_options=os_options, auth_version=3) with mock.patch.multiple('swiftclient.client', get_auth_keystone=fake_keystone, http_connection=fake_conn): info = conn.get_capabilities() self.assertEqual(info, stub_info) self.assertRequests([ ('GET', 'http://storage.example.com/info'), ]) def test_conn_get_capabilities_with_url_param(self): stub_info = {'swift': {'fake': True}} info_response = StubResponse(body=b'{""swift"":{""fake"":true}}') fake_conn = self.fake_http_connection(info_response) conn = c.Connection('http://auth.example.com/auth/v1.0', 'user', 'key') with mock.patch('swiftclient.client.http_connection', new=fake_conn): info = conn.get_capabilities( 'http://other-storage.example.com/info') self.assertEqual(info, stub_info) self.assertRequests([ ('GET', 'http://other-storage.example.com/info'), ]) def test_conn_get_capabilities_with_preauthurl_param(self): stub_info = {'swift': {'fake': True}} info_response = StubResponse(body=b'{""swift"":{""fake"":true}}') fake_conn = self.fake_http_connection(info_response) storage_url = 'http://storage.example.com/v1/AUTH_test' conn = c.Connection('http://auth.example.com/auth/v1.0', 'user', 'key', preauthurl=storage_url) with mock.patch('swiftclient.client.http_connection', new=fake_conn): info = conn.get_capabilities() self.assertEqual(info, stub_info) self.assertRequests([ ('GET', 'http://storage.example.com/info'), ]) def test_conn_get_capabilities_with_os_options(self): stub_info = {'swift': {'fake': True}} info_response = StubResponse(body=b'{""swift"":{""fake"":true}}') fake_conn = self.fake_http_connection(info_response) storage_url = 'http://storage.example.com/v1/AUTH_test' os_options = { 'project_id': 'test', 'object_storage_url': storage_url, } conn = c.Connection('http://keystone.example.com/v3.0', 'user', 'key', os_options=os_options, auth_version=3) with mock.patch('swiftclient.client.http_connection', new=fake_conn): info = conn.get_capabilities() self.assertEqual(info, stub_info) self.assertRequests([ ('GET', 'http://storage.example.com/info'), ]) class TestHTTPConnection(MockHttpTest): def test_bad_url_scheme(self): url = u'www.test.com' with self.assertRaises(c.ClientException) as exc_context: c.http_connection(url) exc = exc_context.exception expected = u'Unsupported scheme """" in url ""www.test.com""' self.assertEqual(expected, str(exc)) url = u'://www.test.com' with self.assertRaises(c.ClientException) as exc_context: c.http_connection(url) exc = exc_context.exception expected = u'Unsupported scheme """" in url ""://www.test.com""' self.assertEqual(expected, str(exc)) url = u'blah://www.test.com' with self.assertRaises(c.ClientException) as exc_context: c.http_connection(url) exc = exc_context.exception expected = u'Unsupported scheme ""blah"" in url ""blah://www.test.com""' self.assertEqual(expected, str(exc)) def test_ok_url_scheme(self): for scheme in ('http', 'https', 'HTTP', 'HTTPS'): url = u'%s://www.test.com' % scheme parsed_url, conn = c.http_connection(url) self.assertEqual(scheme.lower(), parsed_url.scheme) self.assertEqual(u'%s://www.test.com' % scheme, conn.url) def test_ok_proxy(self): conn = c.http_connection(u'http://www.test.com/', proxy='http://localhost:8080') self.assertEqual(conn[1].requests_args['proxies']['http'], 'http://localhost:8080') def test_bad_proxy(self): try: c.http_connection(u'http://www.test.com/', proxy='localhost:8080') except c.ClientException as e: self.assertEqual(e.msg, ""Proxy's missing scheme"") def test_cacert(self): conn = c.http_connection(u'http://www.test.com/', cacert='/dev/urandom') self.assertEqual(conn[1].requests_args['verify'], '/dev/urandom') def test_insecure(self): conn = c.http_connection(u'http://www.test.com/', insecure=True) self.assertEqual(conn[1].requests_args['verify'], False) def test_cert(self): conn = c.http_connection(u'http://www.test.com/', cert='minnie') self.assertEqual(conn[1].requests_args['cert'], 'minnie') def test_cert_key(self): conn = c.http_connection( u'http://www.test.com/', cert='minnie', cert_key='mickey') self.assertEqual(conn[1].requests_args['cert'], ('minnie', 'mickey')) def test_response_connection_released(self): _parsed_url, conn = c.http_connection(u'http://www.test.com/') conn.resp = MockHttpResponse() conn.resp.raw = mock.Mock() conn.resp.raw.read.side_effect = [""Chunk"", """"] resp = conn.getresponse() self.assertFalse(resp.closed) self.assertEqual(""Chunk"", resp.read()) self.assertFalse(resp.read()) self.assertTrue(resp.closed) @unittest.skipIf(six.PY3, 'python2 specific test') def test_response_python2_headers(self): '''Test utf-8 headers in Python 2. ''' _, conn = c.http_connection(u'http://www.test.com/') conn.resp = MockHttpResponse( status=200, headers={ '\xd8\xaa-unicode': '\xd8\xaa-value', 'empty-header': '' } ) resp = conn.getresponse() self.assertEqual( '\xd8\xaa-value', resp.getheader('\xd8\xaa-unicode')) self.assertEqual( '\xd8\xaa-value', resp.getheader('\xd8\xaa-UNICODE')) self.assertEqual('', resp.getheader('empty-header')) self.assertEqual( dict([('\xd8\xaa-unicode', '\xd8\xaa-value'), ('empty-header', ''), ('etag', '""%s""' % EMPTY_ETAG)]), dict(resp.getheaders())) @unittest.skipIf(six.PY2, 'python3 specific test') def test_response_python3_headers(self): '''Test latin1-encoded headers in Python 3. ''' _, conn = c.http_connection(u'http://www.test.com/') conn.resp = MockHttpResponse( status=200, headers={ b'\xd8\xaa-unicode'.decode('iso-8859-1'): b'\xd8\xaa-value'.decode('iso-8859-1'), 'empty-header': '' } ) resp = conn.getresponse() self.assertEqual( '\u062a-value', resp.getheader('\u062a-unicode')) self.assertEqual( '\u062a-value', resp.getheader('\u062a-UNICODE')) self.assertEqual('', resp.getheader('empty-header')) self.assertEqual( dict([('\u062a-unicode', '\u062a-value'), ('empty-header', ''), ('etag', ('""%s""' % EMPTY_ETAG))]), dict(resp.getheaders())) class TestConnection(MockHttpTest): def test_instance(self): conn = c.Connection('http://www.test.com', 'asdf', 'asdf') self.assertEqual(conn.retries, 5) def test_instance_kwargs(self): args = {'user': 'ausername', 'key': 'secretpass', 'authurl': 'http://www.test.com', 'tenant_name': 'atenant'} conn = c.Connection(**args) self.assertEqual(type(conn), c.Connection) def test_instance_kwargs_token(self): args = {'preauthtoken': 'atoken123', 'preauthurl': 'http://www.test.com:8080/v1/AUTH_123456'} conn = c.Connection(**args) self.assertEqual(conn.url, args['preauthurl']) self.assertEqual(conn.token, args['preauthtoken']) def test_instance_kwargs_os_token(self): storage_url = 'http://storage.example.com/v1/AUTH_test' token = 'token' args = { 'os_options': { 'object_storage_url': storage_url, 'auth_token': token, } } conn = c.Connection(**args) self.assertEqual(conn.url, storage_url) self.assertEqual(conn.token, token) def test_instance_kwargs_token_precedence(self): storage_url = 'http://storage.example.com/v1/AUTH_test' token = 'token' args = { 'preauthurl': storage_url, 'preauthtoken': token, 'os_options': { 'auth_token': 'less-specific-token', 'object_storage_url': 'less-specific-storage-url', } } conn = c.Connection(**args) self.assertEqual(conn.url, storage_url) self.assertEqual(conn.token, token) def test_storage_url_override(self): static_url = 'http://overridden.storage.url' conn = c.Connection('http://auth.url/', 'some_user', 'some_key', os_options={ 'object_storage_url': static_url}) method_signatures = ( (conn.head_account, []), (conn.get_account, []), (conn.head_container, ('asdf',)), (conn.get_container, ('asdf',)), (conn.put_container, ('asdf',)), (conn.delete_container, ('asdf',)), (conn.head_object, ('asdf', 'asdf')), (conn.get_object, ('asdf', 'asdf')), (conn.put_object, ('asdf', 'asdf', 'asdf')), (conn.post_object, ('asdf', 'asdf', {})), (conn.delete_object, ('asdf', 'asdf')), ) with mock.patch('swiftclient.client.get_auth_1_0') as mock_get_auth: mock_get_auth.return_value = ('http://auth.storage.url', 'tToken') for method, args in method_signatures: c.http_connection = self.fake_http_connection( 200, body=b'[]', storage_url=static_url) method(*args) self.assertEqual(len(self.request_log), 1) for request in self.iter_request_log(): self.assertEqual(request['parsed_path'].netloc, 'overridden.storage.url') self.assertEqual(request['headers']['x-auth-token'], 'tToken') def test_url_mapping(self): conn = c.Connection() uri_versions = { 'http://storage.test.com': 'http://storage.test.com/info', 'http://storage.test.com/': 'http://storage.test.com/info', 'http://storage.test.com/v1': 'http://storage.test.com/info', 'http://storage.test.com/v1/': 'http://storage.test.com/info', 'http://storage.test.com/swift': 'http://storage.test.com/swift/info', 'http://storage.test.com/swift/': 'http://storage.test.com/swift/info', 'http://storage.test.com/v1.0': 'http://storage.test.com/info', 'http://storage.test.com/swift/v1.0': 'http://storage.test.com/swift/info', 'http://storage.test.com/v111': 'http://storage.test.com/info', 'http://storage.test.com/v111/test': 'http://storage.test.com/info', 'http://storage.test.com/v1/test': 'http://storage.test.com/info', 'http://storage.test.com/swift/v1.0/test': 'http://storage.test.com/swift/info', 'http://storage.test.com/v1.0/test': 'http://storage.test.com/info'} for uri_k, uri_v in uri_versions.items(): self.assertEqual(conn._map_url(uri_k), uri_v) def test_get_capabilities(self): conn = c.Connection() with mock.patch('swiftclient.client.get_capabilities') as get_cap: conn.get_capabilities('http://storage2.test.com') parsed = get_cap.call_args[0][0][0] self.assertEqual(parsed.path, '/info') self.assertEqual(parsed.netloc, 'storage2.test.com') conn.get_auth = lambda: ('http://storage.test.com/v1/AUTH_test', 'token') conn.get_capabilities() parsed = get_cap.call_args[0][0][0] self.assertEqual(parsed.path, '/info') self.assertEqual(parsed.netloc, 'storage.test.com') def test_retry(self): def quick_sleep(*args): pass c.sleep = quick_sleep conn = c.Connection('http://www.test.com', 'asdf', 'asdf') code_iter = [500] * (conn.retries + 1) c.http_connection = self.fake_http_connection(*code_iter) self.assertRaises(c.ClientException, conn.head_account) self.assertEqual(conn.attempts, conn.retries + 1) def test_retry_on_ratelimit(self): def quick_sleep(*args): pass c.sleep = quick_sleep # test retries conn = c.Connection('http://www.test.com/auth/v1.0', 'asdf', 'asdf', retry_on_ratelimit=True) code_iter = [200] + [498] * (conn.retries + 1) auth_resp_headers = { 'x-auth-token': 'asdf', 'x-storage-url': 'http://storage/v1/test', } c.http_connection = self.fake_http_connection( *code_iter, headers=auth_resp_headers) with self.assertRaises(c.ClientException) as exc_context: conn.head_account() self.assertIn('Account HEAD failed', str(exc_context.exception)) self.assertEqual(conn.attempts, conn.retries + 1) # test default no-retry c.http_connection = self.fake_http_connection( 200, 498, headers=auth_resp_headers) conn = c.Connection('http://www.test.com/auth/v1.0', 'asdf', 'asdf') with self.assertRaises(c.ClientException) as exc_context: conn.head_account() self.assertIn('Account HEAD failed', str(exc_context.exception)) self.assertEqual(conn.attempts, 1) def test_retry_with_socket_error(self): def quick_sleep(*args): pass c.sleep = quick_sleep conn = c.Connection('http://www.test.com', 'asdf', 'asdf') with mock.patch('swiftclient.client.http_connection') as \ fake_http_connection, \ mock.patch('swiftclient.client.get_auth_1_0') as mock_auth: mock_auth.return_value = ('http://mock.com', 'mock_token') fake_http_connection.side_effect = socket.error self.assertRaises(socket.error, conn.head_account) self.assertEqual(mock_auth.call_count, 1) self.assertEqual(conn.attempts, conn.retries + 1) def test_retry_with_force_auth_retry_exceptions(self): def quick_sleep(*args): pass def do_test(exception): c.sleep = quick_sleep conn = c.Connection( 'http://www.test.com', 'asdf', 'asdf', force_auth_retry=True) with mock.patch('swiftclient.client.http_connection') as \ fake_http_connection, \ mock.patch('swiftclient.client.get_auth_1_0') as mock_auth: mock_auth.return_value = ('http://mock.com', 'mock_token') fake_http_connection.side_effect = exception self.assertRaises(exception, conn.head_account) self.assertEqual(mock_auth.call_count, conn.retries + 1) self.assertEqual(conn.attempts, conn.retries + 1) do_test(socket.error) do_test(RequestException) def test_retry_with_force_auth_retry_client_exceptions(self): def quick_sleep(*args): pass def do_test(http_status, count): def mock_http_connection(*args, **kwargs): raise ClientException('fake', http_status=http_status) c.sleep = quick_sleep conn = c.Connection( 'http://www.test.com', 'asdf', 'asdf', force_auth_retry=True) with mock.patch('swiftclient.client.http_connection') as \ fake_http_connection, \ mock.patch('swiftclient.client.get_auth_1_0') as mock_auth: mock_auth.return_value = ('http://mock.com', 'mock_token') fake_http_connection.side_effect = mock_http_connection self.assertRaises(ClientException, conn.head_account) self.assertEqual(mock_auth.call_count, count) self.assertEqual(conn.attempts, count) # sanity, in case of 401, the auth will be called only twice because of # retried_auth mechanism do_test(401, 2) # others will be tried until retry limits do_test(408, 6) do_test(500, 6) do_test(503, 6) def test_resp_read_on_server_error(self): conn = c.Connection('http://www.test.com', 'asdf', 'asdf', retries=0) def get_auth(*args, **kwargs): return 'http://www.new.com', 'new' conn.get_auth = get_auth self.url, self.token = conn.get_auth() method_signatures = ( (conn.head_account, []), (conn.get_account, []), (conn.head_container, ('asdf',)), (conn.get_container, ('asdf',)), (conn.put_container, ('asdf',)), (conn.delete_container, ('asdf',)), (conn.head_object, ('asdf', 'asdf')), (conn.get_object, ('asdf', 'asdf')), (conn.put_object, ('asdf', 'asdf', 'asdf')), (conn.post_object, ('asdf', 'asdf', {})), (conn.delete_object, ('asdf', 'asdf')), ) for method, args in method_signatures: c.http_connection = self.fake_http_connection(500) self.assertRaises(c.ClientException, method, *args) requests = list(self.iter_request_log()) self.assertEqual(len(requests), 1) for req in requests: msg = '%s did not read resp on server error' % method.__name__ self.assertTrue(req['resp'].has_been_read, msg) def test_reauth(self): c.http_connection = self.fake_http_connection(401, 200) def get_auth(*args, **kwargs): # this mock, and by extension this test are not # representative of the unit under test. The real get_auth # method will always return the os_option dict's # object_storage_url which will be overridden by the # preauthurl parameter to Connection if it is provided. return 'http://www.new.com', 'new' def swap_sleep(*args): self.swap_sleep_called = True c.get_auth = get_auth c.sleep = swap_sleep self.swap_sleep_called = False conn = c.Connection('http://www.test.com', 'asdf', 'asdf', preauthurl='http://www.old.com', preauthtoken='old', ) self.assertEqual(conn.attempts, 0) self.assertEqual(conn.url, 'http://www.old.com') self.assertEqual(conn.token, 'old') conn.head_account() self.assertTrue(self.swap_sleep_called) self.assertEqual(conn.attempts, 2) self.assertEqual(conn.url, 'http://www.new.com') self.assertEqual(conn.token, 'new') def test_reauth_preauth(self): conn = c.Connection( 'http://auth.example.com', 'user', 'password', preauthurl='http://storage.example.com/v1/AUTH_test', preauthtoken='expired') auth_v1_response = StubResponse(200, headers={ 'x-auth-token': 'token', 'x-storage-url': 'http://storage.example.com/v1/AUTH_user', }) fake_conn = self.fake_http_connection(401, auth_v1_response, 200) with mock.patch.multiple('swiftclient.client', http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/AUTH_test', '', {'x-auth-token': 'expired'}), ('GET', 'http://auth.example.com', '', { 'x-auth-user': 'user', 'x-auth-key': 'password'}), ('HEAD', '/v1/AUTH_test', '', {'x-auth-token': 'token'}), ]) def test_reauth_os_preauth(self): os_preauth_options = { 'tenant_name': 'demo', 'object_storage_url': 'http://storage.example.com/v1/AUTH_test', 'auth_token': 'expired', } conn = c.Connection('http://auth.example.com', 'user', 'password', os_options=os_preauth_options, auth_version=2) fake_keystone = fake_get_auth_keystone(os_preauth_options) fake_conn = self.fake_http_connection(401, 200) with mock.patch.multiple('swiftclient.client', get_auth_keystone=fake_keystone, http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/AUTH_test', '', {'x-auth-token': 'expired'}), ('HEAD', '/v1/AUTH_test', '', {'x-auth-token': 'token'}), ]) def test_session_no_invalidate(self): mock_session = mock.MagicMock() mock_session.get_endpoint.return_value = 'http://storagehost/v1/acct' mock_session.get_token.return_value = 'expired' mock_session.invalidate.return_value = False conn = c.Connection(session=mock_session) fake_conn = self.fake_http_connection(401) with mock.patch.multiple('swiftclient.client', http_connection=fake_conn, sleep=mock.DEFAULT): self.assertRaises(c.ClientException, conn.head_account) self.assertEqual(mock_session.get_token.mock_calls, [mock.call()]) self.assertEqual(mock_session.invalidate.mock_calls, [mock.call()]) def test_session_can_invalidate(self): mock_session = mock.MagicMock() mock_session.get_endpoint.return_value = 'http://storagehost/v1/acct' mock_session.get_token.side_effect = ['expired', 'token'] mock_session.invalidate.return_value = True conn = c.Connection(session=mock_session) fake_conn = self.fake_http_connection(401, 200) with mock.patch.multiple('swiftclient.client', http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/acct', '', {'x-auth-token': 'expired'}), ('HEAD', '/v1/acct', '', {'x-auth-token': 'token'}), ]) self.assertEqual(mock_session.get_token.mock_calls, [ mock.call(), mock.call()]) self.assertEqual(mock_session.invalidate.mock_calls, [mock.call()]) def test_preauth_token_with_no_storage_url_requires_auth(self): conn = c.Connection( 'http://auth.example.com', 'user', 'password', preauthtoken='expired') auth_v1_response = StubResponse(200, headers={ 'x-auth-token': 'token', 'x-storage-url': 'http://storage.example.com/v1/AUTH_user', }) fake_conn = self.fake_http_connection(auth_v1_response, 200) with mock.patch.multiple('swiftclient.client', http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('GET', 'http://auth.example.com', '', { 'x-auth-user': 'user', 'x-auth-key': 'password'}), ('HEAD', '/v1/AUTH_user', '', {'x-auth-token': 'token'}), ]) def test_os_preauth_token_with_no_storage_url_requires_auth(self): os_preauth_options = { 'tenant_name': 'demo', 'auth_token': 'expired', } conn = c.Connection('http://auth.example.com', 'user', 'password', os_options=os_preauth_options, auth_version=2) storage_url = 'http://storage.example.com/v1/AUTH_user' fake_keystone = fake_get_auth_keystone(storage_url=storage_url) fake_conn = self.fake_http_connection(200) with mock.patch.multiple('swiftclient.client', get_auth_keystone=fake_keystone, http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/AUTH_user', '', {'x-auth-token': 'token'}), ]) def test_preauth_url_trumps_auth_url(self): storage_url = 'http://storage.example.com/v1/AUTH_pre_url' conn = c.Connection( 'http://auth.example.com', 'user', 'password', preauthurl=storage_url) auth_v1_response = StubResponse(200, headers={ 'x-auth-token': 'post_token', 'x-storage-url': 'http://storage.example.com/v1/AUTH_post_url', }) fake_conn = self.fake_http_connection(auth_v1_response, 200) with mock.patch.multiple('swiftclient.client', http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('GET', 'http://auth.example.com', '', { 'x-auth-user': 'user', 'x-auth-key': 'password'}), ('HEAD', '/v1/AUTH_pre_url', '', {'x-auth-token': 'post_token'}), ]) def test_os_preauth_url_trumps_auth_url(self): storage_url = 'http://storage.example.com/v1/AUTH_pre_url' os_preauth_options = { 'tenant_name': 'demo', 'object_storage_url': storage_url, } conn = c.Connection('http://auth.example.com', 'user', 'password', os_options=os_preauth_options, auth_version=2) fake_keystone = fake_get_auth_keystone( storage_url='http://storage.example.com/v1/AUTH_post_url', token='post_token') fake_conn = self.fake_http_connection(200) with mock.patch.multiple('swiftclient.client', get_auth_keystone=fake_keystone, http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/AUTH_pre_url', '', {'x-auth-token': 'post_token'}), ]) def test_preauth_url_trumps_os_preauth_url(self): storage_url = 'http://storage.example.com/v1/AUTH_pre_url' os_storage_url = 'http://storage.example.com/v1/AUTH_os_pre_url' os_preauth_options = { 'tenant_name': 'demo', 'object_storage_url': os_storage_url, } orig_os_preauth_options = dict(os_preauth_options) conn = c.Connection('http://auth.example.com', 'user', 'password', os_options=os_preauth_options, auth_version=2, preauthurl=storage_url, tenant_name='not_demo') fake_keystone = fake_get_auth_keystone( storage_url='http://storage.example.com/v1/AUTH_post_url', token='post_token') fake_conn = self.fake_http_connection(200) with mock.patch.multiple('swiftclient.client', get_auth_keystone=fake_keystone, http_connection=fake_conn, sleep=mock.DEFAULT): conn.head_account() self.assertRequests([ ('HEAD', '/v1/AUTH_pre_url', '', {'x-auth-token': 'post_token'}), ]) # check that Connection has not modified our os_options self.assertEqual(orig_os_preauth_options, os_preauth_options) def test_get_auth_sets_url_and_token(self): with mock.patch('swiftclient.client.get_auth') as mock_get_auth: mock_get_auth.return_value = ( ""https://storage.url/v1/AUTH_storage_acct"", ""AUTH_token"" ) conn = c.Connection(""https://auth.url/auth/v2.0"", ""user"", ""passkey"", tenant_name=""tenant"") conn.get_auth() self.assertEqual(""https://storage.url/v1/AUTH_storage_acct"", conn.url) self.assertEqual(""AUTH_token"", conn.token) def test_timeout_passed_down(self): # We want to avoid mocking http_connection(), and most especially # avoid passing it down in argument. However, we cannot simply # instantiate C=Connection(), then shim C.http_conn. Doing so would # avoid some of the code under test (where _retry() invokes # http_connection()), and would miss get_auth() completely. # So, with regret, we do mock http_connection(), but with a very # light shim that swaps out _request() as originally intended. orig_http_connection = c.http_connection timeouts = [] def my_request_handler(*a, **kw): if 'timeout' in kw: timeouts.append(kw['timeout']) else: timeouts.append(None) return MockHttpResponse( status=200, headers={ 'x-auth-token': 'a_token', 'x-storage-url': 'http://files.example.com/v1/AUTH_user'}) def shim_connection(*a, **kw): url, conn = orig_http_connection(*a, **kw) conn._request = my_request_handler return url, conn # v1 auth conn = c.Connection( 'http://auth.example.com', 'user', 'password', timeout=33.0) with mock.patch.multiple('swiftclient.client', http_connection=shim_connection, sleep=mock.DEFAULT): conn.head_account() # 1 call is through get_auth, 1 call is HEAD for account self.assertEqual(timeouts, [33.0, 33.0]) # v2 auth timeouts = [] os_options = {'tenant_name': 'tenant', 'auth_token': 'meta-token'} conn = c.Connection( 'http://auth.example.com', 'user', 'password', timeout=33.0, os_options=os_options, auth_version=2.0) fake_ks = FakeKeystone(endpoint='http://some_url', token='secret') with mock.patch('swiftclient.client.ksclient_v2', fake_ks): with mock.patch.multiple('swiftclient.client', http_connection=shim_connection, sleep=mock.DEFAULT): conn.head_account() # check timeout is passed to keystone client self.assertEqual(1, len(fake_ks.calls)) self.assertEqual(33.0, fake_ks.calls[0].get('timeout')) # check timeout passed to HEAD for account self.assertEqual(timeouts, [33.0]) # check token passed to keystone client self.assertIn('token', fake_ks.calls[0]) self.assertEqual('meta-token', fake_ks.calls[0].get('token')) def test_reset_stream(self): class LocalContents(object): def __init__(self, tell_value=0): self.data = six.BytesIO(string.ascii_letters.encode() * 10) self.data.seek(tell_value) self.reads = [] self.seeks = [] self.tells = [] def tell(self): self.tells.append(self.data.tell()) return self.tells[-1] def seek(self, position, mode=0): self.seeks.append((position, mode)) self.data.seek(position, mode) def read(self, size=-1): read_data = self.data.read(size) self.reads.append((size, read_data)) return read_data class LocalConnection(object): def __init__(self, parsed_url=None): self.reason = """" if parsed_url: self.host = parsed_url.netloc self.port = parsed_url.netloc def putrequest(self, *args, **kwargs): self.send('PUT', *args, **kwargs) def putheader(self, *args, **kwargs): return def endheaders(self, *args, **kwargs): return def send(self, *args, **kwargs): data = kwargs.get('data') if data is not None: if hasattr(data, 'read'): data.read() else: for datum in data: pass raise socket.error('oops') def request(self, *args, **kwargs): return def getresponse(self, *args, **kwargs): self.status = 200 return self def getheader(self, *args, **kwargs): return 'header' def getheaders(self): return [('key1', 'value1'), ('key2', 'value2')] def read(self, *args, **kwargs): return '' def close(self): pass def local_http_connection(url, proxy=None, cacert=None, insecure=False, cert=None, cert_key=None, ssl_compression=True, timeout=None): parsed = urlparse(url) return parsed, LocalConnection() with mock.patch.object(c, 'http_connection', local_http_connection): conn = c.Connection('http://www.example.com', 'asdf', 'asdf', retries=1, starting_backoff=.0001) contents = LocalContents() exc = None try: conn.put_object('c', 'o', contents) except socket.error as err: exc = err self.assertEqual(contents.tells, [0]) self.assertEqual(contents.seeks, [(0, 0)]) # four reads: two in the initial pass, two in the retry self.assertEqual(4, len(contents.reads)) self.assertEqual((65536, b''), contents.reads[1]) self.assertEqual((65536, b''), contents.reads[3]) self.assertEqual(str(exc), 'oops') contents = LocalContents(tell_value=123) exc = None try: conn.put_object('c', 'o', contents) except socket.error as err: exc = err self.assertEqual(contents.tells, [123]) self.assertEqual(contents.seeks, [(123, 0)]) # four reads: two in the initial pass, two in the retry self.assertEqual(4, len(contents.reads)) self.assertEqual((65536, b''), contents.reads[1]) self.assertEqual((65536, b''), contents.reads[3]) self.assertEqual(str(exc), 'oops') contents = LocalContents(tell_value=123) wrapped_contents = swiftclient.utils.LengthWrapper( contents, 6, md5=True) exc = None try: conn.put_object('c', 'o', wrapped_contents) except socket.error as err: exc = err self.assertEqual(contents.tells, [123]) self.assertEqual(contents.seeks, [(123, 0)]) self.assertEqual(contents.reads, [(6, b'tuvwxy')] * 2) self.assertEqual(str(exc), 'oops') self.assertEqual(md5(b'tuvwxy').hexdigest(), wrapped_contents.get_md5sum()) contents = LocalContents() contents.tell = None exc = None try: conn.put_object('c', 'o', contents) except c.ClientException as err: exc = err self.assertEqual(contents.seeks, []) self.assertEqual(str(exc), ""put_object('c', 'o', ...) failure "" ""and no ability to reset contents for reupload."") def test_get_container(self): headers = {'X-Favourite-Pet': 'Aardvark'} with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200, body=b'{}')): with mock.patch('swiftclient.client.get_auth', lambda *a, **k: ('http://url:8080/v1/a', 'token')): conn = c.Connection() conn.get_container('c1', prefix='p', limit=5, headers=headers) self.assertEqual(1, len(self.request_log), self.request_log) self.assertRequests([ ('GET', '/v1/a/c1?format=json&limit=5&prefix=p', '', { 'x-auth-token': 'token', 'X-Favourite-Pet': 'Aardvark', 'accept-encoding': 'gzip', }), ]) self.assertEqual(conn.attempts, 1) def test_head_container(self): headers = {'X-Favourite-Pet': 'Aardvark'} with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200, body=b'{}')): with mock.patch('swiftclient.client.get_auth', lambda *a, **k: ('http://url:8080/v1/a', 'token')): conn = c.Connection() conn.head_container('c1', headers=headers) self.assertEqual(1, len(self.request_log), self.request_log) self.assertRequests([ ('HEAD', '/v1/a/c1', '', { 'x-auth-token': 'token', 'X-Favourite-Pet': 'Aardvark', }), ]) self.assertEqual(conn.attempts, 1) def test_head_object(self): headers = {'X-Favourite-Pet': 'Aardvark'} query_string = 'foo=bar' with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): with mock.patch('swiftclient.client.get_auth', lambda *a, **k: ('http://url:8080/v1/a', 'token')): conn = c.Connection() conn.head_object('c1', 'o1', headers=headers, query_string=query_string) self.assertEqual(1, len(self.request_log), self.request_log) self.assertRequests([ ('HEAD', '/v1/a/c1/o1?foo=bar', '', { 'x-auth-token': 'token', 'X-Favourite-Pet': 'Aardvark', }), ]) self.assertEqual(conn.attempts, 1) class TestResponseDict(MockHttpTest): """""" Verify handling of optional response_dict argument. """""" calls = [('post_account', {}), ('post_container', 'c', {}), ('put_container', 'c'), ('delete_container', 'c'), ('post_object', 'c', 'o', {}), ('put_object', 'c', 'o', 'body'), ('copy_object', 'c', 'o'), ('delete_object', 'c', 'o')] def fake_get_auth(*args, **kwargs): return 'http://url', 'token' def test_response_dict_with_auth_error(self): def bad_get_auth(*args, **kwargs): raise c.ClientException('test') for call in self.calls: resp_dict = {'test': 'should be untouched'} with mock.patch('swiftclient.client.get_auth', bad_get_auth): conn = c.Connection('http://127.0.0.1:8080', 'user', 'key') self.assertRaises(c.ClientException, getattr(conn, call[0]), *call[1:], response_dict=resp_dict) self.assertEqual({'test': 'should be untouched'}, resp_dict) def test_response_dict_with_request_error(self): for call in self.calls: resp_dict = {'test': 'should be untouched'} with mock.patch('swiftclient.client.get_auth', self.fake_get_auth): exc = c.ClientException('test') with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200, exc=exc)): conn = c.Connection('http://127.0.0.1:8080', 'user', 'key') self.assertRaises(c.ClientException, getattr(conn, call[0]), *call[1:], response_dict=resp_dict) self.assertEqual('should be untouched', resp_dict.get('test')) self.assertEqual([{}], resp_dict.get('response_dicts')) def test_response_dict(self): # test response_dict is populated and # new list of response_dicts is created for call in self.calls: resp_dict = {'test': 'should be untouched'} with mock.patch('swiftclient.client.get_auth', self.fake_get_auth): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = c.Connection('http://127.0.0.1:8080', 'user', 'key') getattr(conn, call[0])(*call[1:], response_dict=resp_dict) self.assertEqual('should be untouched', resp_dict.pop('test', None)) self.assertEqual('Fake', resp_dict.get('reason')) self.assertEqual(200, resp_dict.get('status')) self.assertIn('headers', resp_dict) self.assertEqual('yes', resp_dict['headers'].get('x-works')) children = resp_dict.pop('response_dicts', []) self.assertEqual(1, len(children)) self.assertEqual(resp_dict, children[0]) def test_response_dict_with_existing(self): # check response_dict is populated and new dict is appended # to existing response_dicts list for call in self.calls: resp_dict = {'test': 'should be untouched', 'response_dicts': [{'existing': 'response dict'}]} with mock.patch('swiftclient.client.get_auth', self.fake_get_auth): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = c.Connection('http://127.0.0.1:8080', 'user', 'key') getattr(conn, call[0])(*call[1:], response_dict=resp_dict) self.assertEqual('should be untouched', resp_dict.pop('test', None)) self.assertEqual('Fake', resp_dict.get('reason')) self.assertEqual(200, resp_dict.get('status')) self.assertIn('headers', resp_dict) self.assertEqual('yes', resp_dict['headers'].get('x-works')) children = resp_dict.pop('response_dicts', []) self.assertEqual(2, len(children)) self.assertEqual({'existing': 'response dict'}, children[0]) self.assertEqual(resp_dict, children[1]) class TestLogging(MockHttpTest): """""" Make sure all the lines in http_log are covered. """""" def setUp(self): super(TestLogging, self).setUp() self.swiftclient_logger = logging.getLogger(""swiftclient"") self.log_level = self.swiftclient_logger.getEffectiveLevel() self.swiftclient_logger.setLevel(logging.INFO) def tearDown(self): self.swiftclient_logger.setLevel(self.log_level) super(TestLogging, self).tearDown() def test_put_ok(self): c.http_connection = self.fake_http_connection(200) args = ('http://www.test.com', 'asdf', 'asdf', 'asdf', 'asdf') value = c.put_object(*args) self.assertIsInstance(value, six.string_types) def test_head_error(self): c.http_connection = self.fake_http_connection(500) self.assertRaises(c.ClientException, c.head_object, 'http://www.test.com', 'asdf', 'asdf', 'asdf') def test_get_error(self): c.http_connection = self.fake_http_connection(404) with self.assertRaises(c.ClientException) as exc_context: c.get_object('http://www.test.com', 'asdf', 'asdf', 'asdf') self.assertEqual(exc_context.exception.http_status, 404) def test_content_encoding_gzip_body_is_logged_decoded(self): buf = six.BytesIO() gz = gzip.GzipFile(fileobj=buf, mode='w') data = {""test"": u""\u2603""} decoded_body = json.dumps(data).encode('utf-8') gz.write(decoded_body) gz.close() # stub a gzip encoded body body = buf.getvalue() headers = {'content-encoding': 'gzip'} # ... and make a content-encoding gzip error response stub_response = StubResponse(500, body, headers) with mock.patch('swiftclient.client.logger.info') as mock_log: # ... if the client gets such a response c.http_connection = self.fake_http_connection(stub_response) with self.assertRaises(c.ClientException) as exc_context: c.get_object('http://www.test.com', 'asdf', 'asdf', 'asdf') self.assertEqual(exc_context.exception.http_status, 500) # it will log the decoded body self.assertEqual([ mock.call('REQ: %s', u'curl -i http://www.test.com/asdf/asdf ' '-X GET -H ""X-Auth-Token: ...""'), mock.call('RESP STATUS: %s %s', 500, 'Fake'), mock.call('RESP HEADERS: %s', {'content-encoding': 'gzip'}), mock.call('RESP BODY: %s', decoded_body) ], mock_log.mock_calls) def test_redact_token(self): with mock.patch('swiftclient.client.logger.debug') as mock_log: token_value = 'tkee96b40a8ca44fc5ad72ec5a7c90d9b' token_encoded = token_value.encode('utf8') unicode_token_value = (u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' u'\u5929\u7a7a\u4e2d\u7684\u4e4c') unicode_token_encoded = unicode_token_value.encode('utf8') set_cookie_value = 'X-Auth-Token=%s' % token_value set_cookie_encoded = set_cookie_value.encode('utf8') c.http_log( ['GET'], {'headers': { 'X-Auth-Token': token_encoded, 'X-Storage-Token': unicode_token_encoded }}, MockHttpResponse( status=200, headers={ 'X-Auth-Token': token_encoded, 'X-Storage-Token': unicode_token_encoded, 'Etag': b'mock_etag', 'Set-Cookie': set_cookie_encoded } ), '' ) out = [] for _, args, kwargs in mock_log.mock_calls: for arg in args: out.append(u'%s' % arg) output = u''.join(out) self.assertIn('X-Auth-Token', output) self.assertIn(token_value[:16] + '...', output) self.assertIn('X-Storage-Token', output) self.assertIn(unicode_token_value[:8] + '...', output) self.assertIn('Set-Cookie', output) self.assertIn(set_cookie_value[:16] + '...', output) self.assertNotIn(token_value, output) self.assertNotIn(unicode_token_value, output) self.assertNotIn(set_cookie_value, output) def test_show_token(self): with mock.patch('swiftclient.client.logger.debug') as mock_log: token_value = 'tkee96b40a8ca44fc5ad72ec5a7c90d9b' token_encoded = token_value.encode('utf8') unicode_token_value = (u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' u'\u5929\u7a7a\u4e2d\u7684\u4e4c\u4e91' u'\u5929\u7a7a\u4e2d\u7684\u4e4c') c.logger_settings['redact_sensitive_headers'] = False unicode_token_encoded = unicode_token_value.encode('utf8') c.http_log( ['GET'], {'headers': { 'X-Auth-Token': token_encoded, 'X-Storage-Token': unicode_token_encoded }}, MockHttpResponse( status=200, headers=[ ('X-Auth-Token', token_encoded), ('X-Storage-Token', unicode_token_encoded), ('Etag', b'mock_etag') ] ), '' ) out = [] for _, args, kwargs in mock_log.mock_calls: for arg in args: out.append(u'%s' % arg) output = u''.join(out) self.assertIn('X-Auth-Token', output) self.assertIn(token_value, output) self.assertIn('X-Storage-Token', output) self.assertIn(unicode_token_value, output) @mock.patch('swiftclient.client.logger.debug') def test_unicode_path(self, mock_log): path = u'http://swift/v1/AUTH_account-\u062a'.encode('utf-8') c.http_log(['GET', path], {}, MockHttpResponse(status=200, headers=[]), '') request_log_line = mock_log.mock_calls[0] self.assertEqual('REQ: %s', request_log_line[1][0]) self.assertEqual(u'curl -i -X GET %s' % path.decode('utf-8'), request_log_line[1][1]) class TestCloseConnection(MockHttpTest): def test_close_none(self): c.http_connection = self.fake_http_connection() conn = c.Connection('http://www.test.com', 'asdf', 'asdf') self.assertIsNone(conn.http_conn) conn.close() self.assertIsNone(conn.http_conn) # Can re-close conn.close() self.assertIsNone(conn.http_conn) def test_close_ok(self): url = 'http://www.test.com' conn = c.Connection(url, 'asdf', 'asdf') self.assertIsNone(conn.http_conn) conn.http_conn = c.http_connection(url) self.assertEqual(type(conn.http_conn), tuple) self.assertEqual(len(conn.http_conn), 2) http_conn_obj = conn.http_conn[1] self.assertIsInstance(http_conn_obj, c.HTTPConnection) self.assertTrue(hasattr(http_conn_obj, 'close')) conn.close() class TestServiceToken(MockHttpTest): def setUp(self): super(TestServiceToken, self).setUp() self.os_options = { 'object_storage_url': 'http://storage_url.com', 'service_username': 'service_username', 'service_project_name': 'service_project_name', 'service_key': 'service_key'} def get_connection(self): conn = c.Connection('http://www.test.com', 'asdf', 'asdf', os_options=self.os_options) self.assertIs(type(conn), c.Connection) conn.get_auth = self.get_auth conn.get_service_auth = self.get_service_auth self.assertEqual(conn.attempts, 0) self.assertIsNone(conn.service_token) self.assertIs(type(conn), c.Connection) return conn def get_auth(self): # The real get_auth function will always return the os_option # dict's object_storage_url which will be overridden by the # preauthurl parameter to Connection if it is provided. return self.os_options.get('object_storage_url'), 'token' def get_service_auth(self): # The real get_auth function will always return the os_option # dict's object_storage_url which will be overridden by the # preauthurl parameter to Connection if it is provided. return self.os_options.get('object_storage_url'), 'stoken' def test_service_token_reauth(self): get_auth_call_list = [] def get_auth(url, user, key, **kwargs): # The real get_auth function will always return the os_option # dict's object_storage_url which will be overridden by the # preauthurl parameter to Connection if it is provided. args = {'url': url, 'user': user, 'key': key, 'kwargs': kwargs} get_auth_call_list.append(args) return_dict = {'asdf': 'new', 'service_username': 'newserv'} storage_url = kwargs['os_options'].get('object_storage_url') return storage_url, return_dict[user] def swap_sleep(*args): self.swap_sleep_called = True c.get_auth = get_auth with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(401, 200)): with mock.patch('swiftclient.client.sleep', swap_sleep): self.swap_sleep_called = False conn = c.Connection('http://www.test.com', 'asdf', 'asdf', preauthurl='http://www.old.com', preauthtoken='old', os_options=self.os_options) self.assertEqual(conn.attempts, 0) self.assertEqual(conn.url, 'http://www.old.com') self.assertEqual(conn.token, 'old') conn.head_account() self.assertTrue(self.swap_sleep_called) self.assertEqual(conn.attempts, 2) # The original 'preauth' storage URL *must* be preserved self.assertEqual(conn.url, 'http://www.old.com') self.assertEqual(conn.token, 'new') self.assertEqual(conn.service_token, 'newserv') # Check get_auth was called with expected args auth_args = get_auth_call_list[0] auth_kwargs = get_auth_call_list[0]['kwargs'] self.assertEqual('asdf', auth_args['user']) self.assertEqual('asdf', auth_args['key']) self.assertEqual('service_key', auth_kwargs['os_options']['service_key']) self.assertEqual('service_username', auth_kwargs['os_options']['service_username']) self.assertEqual('service_project_name', auth_kwargs['os_options']['service_project_name']) auth_args = get_auth_call_list[1] auth_kwargs = get_auth_call_list[1]['kwargs'] self.assertEqual('service_username', auth_args['user']) self.assertEqual('service_key', auth_args['key']) self.assertEqual('service_project_name', auth_kwargs['os_options']['tenant_name']) def test_service_token_reauth_retries_0(self): get_auth_call_list = [] def get_auth(url, user, key, **kwargs): # The real get_auth function will always return the os_option # dict's object_storage_url which will be overridden by the # preauthurl parameter to Connection if it is provided. args = {'url': url, 'user': user, 'key': key, 'kwargs': kwargs} get_auth_call_list.append(args) return_dict = {'asdf': 'new', 'service_username': 'newserv'} storage_url = kwargs['os_options'].get('object_storage_url') return storage_url, return_dict[user] def swap_sleep(*args): self.swap_sleep_called = True c.get_auth = get_auth with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(401, 200)): with mock.patch('swiftclient.client.sleep', swap_sleep): self.swap_sleep_called = False conn = c.Connection('http://www.test.com', 'asdf', 'asdf', preauthurl='http://www.old.com', preauthtoken='old', os_options=self.os_options, retries=0) self.assertEqual(conn.attempts, 0) self.assertEqual(conn.url, 'http://www.old.com') self.assertEqual(conn.token, 'old') conn.head_account() self.assertTrue(self.swap_sleep_called) self.assertEqual(conn.attempts, 2) # The original 'preauth' storage URL *must* be preserved self.assertEqual(conn.url, 'http://www.old.com') self.assertEqual(conn.token, 'new') self.assertEqual(conn.service_token, 'newserv') # Check get_auth was called with expected args auth_args = get_auth_call_list[0] auth_kwargs = get_auth_call_list[0]['kwargs'] self.assertEqual('asdf', auth_args['user']) self.assertEqual('asdf', auth_args['key']) self.assertEqual('service_key', auth_kwargs['os_options']['service_key']) self.assertEqual('service_username', auth_kwargs['os_options']['service_username']) self.assertEqual('service_project_name', auth_kwargs['os_options']['service_project_name']) auth_args = get_auth_call_list[1] auth_kwargs = get_auth_call_list[1]['kwargs'] self.assertEqual('service_username', auth_args['user']) self.assertEqual('service_key', auth_args['key']) self.assertEqual('service_project_name', auth_kwargs['os_options']['tenant_name']) # Ensure this is not an endless loop - it fails after the second 401 with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(401, 401, 401, 401)): with mock.patch('swiftclient.client.sleep', swap_sleep): self.swap_sleep_called = False conn = c.Connection('http://www.test.com', 'asdf', 'asdf', preauthurl='http://www.old.com', preauthtoken='old', os_options=self.os_options, retries=0) self.assertEqual(conn.attempts, 0) self.assertRaises(c.ClientException, conn.head_account) self.assertEqual(conn.attempts, 2) unused_responses = list(self.fake_connect.code_iter) self.assertEqual(unused_responses, [401, 401]) def test_service_token_get_account(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): with mock.patch('swiftclient.client.parse_api_response'): conn = self.get_connection() conn.get_account() self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('GET', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/?format=json', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_head_account(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.head_account() self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('HEAD', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_post_account(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(201)): conn = self.get_connection() conn.post_account(headers={}) self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('POST', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_delete_container(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(204)): conn = self.get_connection() conn.delete_container('container1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('DELETE', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_get_container(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): with mock.patch('swiftclient.client.parse_api_response'): conn = self.get_connection() conn.get_container('container1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('GET', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1?format=json', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_get_container_full_listing(self): # verify service token is sent with each request for a full listing with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200, 200)): with mock.patch('swiftclient.client.parse_api_response') as resp: resp.side_effect = ([{""name"": ""obj1""}], []) conn = self.get_connection() conn.get_container('container1', full_listing=True) self.assertEqual(2, len(self.request_log), self.request_log) expected_urls = iter(( 'http://storage_url.com/container1?format=json', 'http://storage_url.com/container1?format=json&marker=obj1' )) for actual in self.iter_request_log(): self.assertEqual('GET', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual(next(expected_urls), actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_head_container(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.head_container('container1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('HEAD', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_post_container(self): headers = {'X-Container-Meta-Color': 'blue'} with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(201)): conn = self.get_connection() conn.post_container('container1', headers) self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('POST', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1', actual['full_path']) self.assertEqual(conn.attempts, 1) # Check that we didn't mutate the request header dict self.assertEqual(headers, {'X-Container-Meta-Color': 'blue'}) def test_service_token_put_container(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.put_container('container1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('PUT', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_get_object(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.get_object('container1', 'obj1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('GET', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1/obj1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_head_object(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.head_object('container1', 'obj1') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('HEAD', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1/obj1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_put_object(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(200)): conn = self.get_connection() conn.put_object('container1', 'obj1', 'a_string') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('PUT', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1/obj1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_post_object(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(202)): conn = self.get_connection() conn.post_object('container1', 'obj1', {}) self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('POST', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1/obj1', actual['full_path']) self.assertEqual(conn.attempts, 1) def test_service_token_delete_object(self): with mock.patch('swiftclient.client.http_connection', self.fake_http_connection(202)): conn = self.get_connection() conn.delete_object('container1', 'obj1', query_string='a_string') self.assertEqual(1, len(self.request_log), self.request_log) for actual in self.iter_request_log(): self.assertEqual('DELETE', actual['method']) actual_hdrs = actual['headers'] self.assertEqual('stoken', actual_hdrs.get('X-Service-Token')) self.assertEqual('token', actual_hdrs['X-Auth-Token']) self.assertEqual('http://storage_url.com/container1/obj1?a_string', actual['full_path']) self.assertEqual(conn.attempts, 1) >>>>>>> CHANGE (e1c05c Fixed capability discovery endpoint hardcode) ",,3378,2
openstack%2Fswift~stable%2Ftrain~I84494123cfc85e234098c554ecd3e77981f8a096,openstack/swift,stable/train,I84494123cfc85e234098c554ecd3e77981f8a096,s3api: Prevent XXE injections,MERGED,2023-01-21 18:09:33.000000000,2023-01-25 21:04:31.000000000,2023-01-25 21:03:31.000000000,"[{'_account_id': 6968}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-21 18:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30dac86cbf114e74fec9825439685eebab4c8de0', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 2, 'created': '2023-01-23 19:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/01c23d1c98f6cbcb2738c334dfcc65cd522ceb86', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 3, 'created': '2023-01-23 20:14:55.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/70b68dbf65c7bc67795a8dee65f01c14f9eb94e5', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}]",2,871244,70b68dbf65c7bc67795a8dee65f01c14f9eb94e5,12,3,3,6968,,,0,"s3api: Prevent XXE injections

Previously, clients could use XML external entities (XXEs) to read
arbitrary files from proxy-servers and inject the content into the
request. Since many S3 APIs reflect request content back to the user,
this could be used to extract any secrets that the swift user could
read, such as tempauth credentials, keymaster secrets, etc.

Now, disable entity resolution -- any unknown entities will be replaced
with an empty string. Without resolving the entities, the request is
still processed.

[CVE-2022-47950]

Closes-Bug: #1998625
Co-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>
Change-Id: I84494123cfc85e234098c554ecd3e77981f8a096
(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/871244/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py']",3,30dac86cbf114e74fec9825439685eebab4c8de0,bug/1998625-stable/train,"#!/usr/bin/env python # Copyright (c) 2022 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import base64 import requests import botocore from swift.common.utils import md5 import test.functional as tf from test.functional.s3api import S3ApiBaseBoto3 class TestS3ApiXxeInjection(S3ApiBaseBoto3): def setUp(self): super(TestS3ApiXxeInjection, self).setUp() self.bucket = 'test-s3api-xxe-injection' def _create_bucket(self, **kwargs): resp = self.conn.create_bucket(Bucket=self.bucket, **kwargs) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) @staticmethod def _clear_data(request, **_kwargs): request.data = b'' def _presign_url(self, method, key=None, **kwargs): params = { 'Bucket': self.bucket } if key: params['Key'] = key params.update(kwargs) try: # https://github.com/boto/boto3/issues/2192 self.conn.meta.events.register( 'before-sign.s3.*', self._clear_data) return self.conn.generate_presigned_url( method, Params=params, ExpiresIn=60) finally: self.conn.meta.events.unregister( 'before-sign.s3.*', self._clear_data) def test_put_bucket_acl(self): if not tf.cluster_info['s3api'].get('s3_acl'): self.skipTest('s3_acl must be enabled') self._create_bucket() url = self._presign_url('put_bucket_acl') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <AccessControlPolicy xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Owner> <DisplayName>test:tester</DisplayName> <ID>test:tester</ID> </Owner> <AccessControlList> <Grant> <Grantee xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""CanonicalUser""> <DisplayName>name&xxe;</DisplayName> <ID>id&xxe;</ID> </Grantee> <Permission>WRITE</Permission> </Grant> </AccessControlList> </AccessControlPolicy> """""") # noqa: E501 self.assertEqual(200, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) acl = self.conn.get_bucket_acl(Bucket=self.bucket) response_metadata = acl.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({ 'Owner': { 'DisplayName': 'test:tester', 'ID': 'test:tester' }, 'Grants': [ { 'Grantee': { 'DisplayName': 'id', 'ID': 'id', 'Type': 'CanonicalUser' }, 'Permission': 'WRITE' } ] }, acl) def test_create_bucket(self): url = self._presign_url('create_bucket') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CreateBucketConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <LocationConstraint>&xxe;</LocationConstraint> </CreateBucketConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) self.assertRaisesRegex( botocore.exceptions.ClientError, 'Not Found', self.conn.head_bucket, Bucket=self.bucket) def test_delete_objects(self): self._create_bucket() url = self._presign_url( 'delete_objects', Delete={ 'Objects': [ { 'Key': 'string', 'VersionId': 'string' } ] }) body = """""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <Delete xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Object> <Key>&xxe;</Key> </Object> </Delete> """""" body = body.encode('utf-8') content_md5 = ( base64.b64encode(md5(body, usedforsecurity=False).digest())) resp = requests.post( url, headers={'Content-MD5': content_md5}, data=body) self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) def test_complete_multipart_upload(self): self._create_bucket() resp = self.conn.create_multipart_upload( Bucket=self.bucket, Key='test') response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) uploadid = resp.get('UploadId') try: url = self._presign_url( 'complete_multipart_upload', Key='key', MultipartUpload={ 'Parts': [ { 'ETag': 'string', 'PartNumber': 1 } ], }, UploadId=uploadid) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""{uploadid}""</ETag> <PartNumber>&xxe;</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""&xxe;""</ETag> <PartNumber>1</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) finally: resp = self.conn.abort_multipart_upload( Bucket=self.bucket, Key='test', UploadId=uploadid) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(204, response_metadata.get('HTTPStatusCode')) def test_put_bucket_versioning(self): self._create_bucket() url = self._presign_url( 'put_bucket_versioning', VersioningConfiguration={ 'Status': 'Enabled' }) resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <VersioningConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Status>&xxe;</Status> </VersioningConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) versioning = self.conn.get_bucket_versioning(Bucket=self.bucket) response_metadata = versioning.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({}, versioning) ",,270,1
openstack%2Fnova~stable%2Fwallaby~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/wallaby,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,NEW,2022-09-26 16:54:19.000000000,2023-01-25 20:32:09.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 16:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c9087eb5ec4637902e79abc2d4e5f4ff24eca677', 'message': 'Reproduce bug 1981813 in func env\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit a5287d75bf895b13625583bd00c30a44a435fcf6)\n(cherry picked from commit b1a8b63d40bf80934c38366c6481e7045302f4e3)\n'}, {'number': 2, 'created': '2022-10-17 16:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ece728687707c4c3588d06eb3e2705ff5a755cb2', 'message': 'Reproduce bug 1981813 in func env\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 8ec3abe58ef3b21c37765b9ce4314af625967df5)\n(cherry picked from commit 536c795799ea550113de9fb08a3a7be2fbb29f42)\n'}, {'number': 3, 'created': '2023-01-09 17:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4663dd7ded5610630c39a8678e57d96430ae0842', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n(cherry picked from commit d25b2a94e5cf84550dc05c377c12a1fe88e2a74f)\n'}, {'number': 4, 'created': '2023-01-25 16:34:58.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cb4c2b6c04232901f4c5adae724697fec3aed4e8', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)\n(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)\n'}]",2,859320,cb4c2b6c04232901f4c5adae724697fec3aed4e8,16,2,4,9708,,,0,"Reproduce bug 1981813 in func env

There stable/yoga only change in test_pci_sriov_servers.py due to
unittest.mock switch[1] only happened in zed.

[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)
(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/859320/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py']",2,c9087eb5ec4637902e79abc2d4e5f4ff24eca677,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",78,3
openstack%2Fswift~stable%2Fussuri~I84494123cfc85e234098c554ecd3e77981f8a096,openstack/swift,stable/ussuri,I84494123cfc85e234098c554ecd3e77981f8a096,s3api: Prevent XXE injections,MERGED,2023-01-20 19:52:33.000000000,2023-01-25 20:09:56.000000000,2023-01-25 20:08:52.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 19:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4996ac49c6d5f90164d00f6ec8c4b7ca0cb77bfb', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}, {'number': 2, 'created': '2023-01-20 20:25:29.000000000', 'files': ['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/baa98848451b5c234443a068691e12841a5a8383', 'message': 's3api: Prevent XXE injections\n\nPreviously, clients could use XML external entities (XXEs) to read\narbitrary files from proxy-servers and inject the content into the\nrequest. Since many S3 APIs reflect request content back to the user,\nthis could be used to extract any secrets that the swift user could\nread, such as tempauth credentials, keymaster secrets, etc.\n\nNow, disable entity resolution -- any unknown entities will be replaced\nwith an empty string. Without resolving the entities, the request is\nstill processed.\n\n[CVE-2022-47950]\n\nCloses-Bug: #1998625\nCo-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>\nChange-Id: I84494123cfc85e234098c554ecd3e77981f8a096\n(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)\n'}]",2,871243,baa98848451b5c234443a068691e12841a5a8383,16,2,2,15343,,,0,"s3api: Prevent XXE injections

Previously, clients could use XML external entities (XXEs) to read
arbitrary files from proxy-servers and inject the content into the
request. Since many S3 APIs reflect request content back to the user,
this could be used to extract any secrets that the swift user could
read, such as tempauth credentials, keymaster secrets, etc.

Now, disable entity resolution -- any unknown entities will be replaced
with an empty string. Without resolving the entities, the request is
still processed.

[CVE-2022-47950]

Closes-Bug: #1998625
Co-Authored-By: Romain de Joux <romain.de-joux@ovhcloud.com>
Change-Id: I84494123cfc85e234098c554ecd3e77981f8a096
(cherry picked from commit b8467e190f6fc67fd8fb6a8c5e32b2aa6a10fd8e)
",git fetch https://review.opendev.org/openstack/swift refs/changes/43/871243/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/s3api/test_multi_delete.py', 'swift/common/middleware/s3api/etree.py', 'test/functional/s3api/test_xxe_injection.py']",3,4996ac49c6d5f90164d00f6ec8c4b7ca0cb77bfb,bug/1998625-stable/victoria-stable/ussuri,"#!/usr/bin/env python # Copyright (c) 2022 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import requests import botocore import test.functional as tf from test.functional.s3api import S3ApiBaseBoto3 def setUpModule(): tf.setup_package() def tearDownModule(): tf.teardown_package() class TestS3ApiXxeInjection(S3ApiBaseBoto3): def setUp(self): super(TestS3ApiXxeInjection, self).setUp() self.bucket = 'test-s3api-xxe-injection' def _create_bucket(self, **kwargs): resp = self.conn.create_bucket(Bucket=self.bucket, **kwargs) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) @staticmethod def _clear_data(request, **_kwargs): if 'Content-MD5' in request.headers: del request.headers['Content-MD5'] request.data = b'' def _presign_url(self, method, key=None, **kwargs): params = { 'Bucket': self.bucket } if key: params['Key'] = key params.update(kwargs) try: # https://github.com/boto/boto3/issues/2192 self.conn.meta.events.register( 'before-sign.s3.*', self._clear_data) return self.conn.generate_presigned_url( method, Params=params, ExpiresIn=60) finally: self.conn.meta.events.unregister( 'before-sign.s3.*', self._clear_data) def test_put_bucket_acl(self): if not tf.cluster_info['s3api'].get('s3_acl'): self.skipTest('s3_acl must be enabled') self._create_bucket() url = self._presign_url('put_bucket_acl') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <AccessControlPolicy xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Owner> <DisplayName>test:tester</DisplayName> <ID>test:tester</ID> </Owner> <AccessControlList> <Grant> <Grantee xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:type=""CanonicalUser""> <DisplayName>name&xxe;</DisplayName> <ID>id&xxe;</ID> </Grantee> <Permission>WRITE</Permission> </Grant> </AccessControlList> </AccessControlPolicy> """""") # noqa: E501 self.assertEqual(200, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) acl = self.conn.get_bucket_acl(Bucket=self.bucket) response_metadata = acl.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({ 'Owner': { 'DisplayName': 'test:tester', 'ID': 'test:tester' }, 'Grants': [ { 'Grantee': { 'DisplayName': 'id', 'ID': 'id', 'Type': 'CanonicalUser' }, 'Permission': 'WRITE' } ] }, acl) def test_create_bucket(self): url = self._presign_url('create_bucket') resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CreateBucketConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <LocationConstraint>&xxe;</LocationConstraint> </CreateBucketConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) self.assertRaisesRegexp( botocore.exceptions.ClientError, 'Not Found', self.conn.head_bucket, Bucket=self.bucket) def test_delete_objects(self): self._create_bucket() url = self._presign_url( 'delete_objects', Delete={ 'Objects': [ { 'Key': 'string', 'VersionId': 'string' } ] }) body = """""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <Delete xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Object> <Key>&xxe;</Key> </Object> </Delete> """""" body = body.encode('utf-8') resp = requests.post(url, data=body) self.assertEqual(400, resp.status_code, resp.content) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) def test_complete_multipart_upload(self): self._create_bucket() resp = self.conn.create_multipart_upload( Bucket=self.bucket, Key='test') response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) uploadid = resp.get('UploadId') try: url = self._presign_url( 'complete_multipart_upload', Key='key', MultipartUpload={ 'Parts': [ { 'ETag': 'string', 'PartNumber': 1 } ], }, UploadId=uploadid) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""{uploadid}""</ETag> <PartNumber>&xxe;</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) resp = requests.post(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <CompleteMultipartUpload xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Part> <ETag>""&xxe;""</ETag> <PartNumber>1</PartNumber> </Part> </CompleteMultipartUpload> """""") # noqa: E501 self.assertEqual(404, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) finally: resp = self.conn.abort_multipart_upload( Bucket=self.bucket, Key='test', UploadId=uploadid) response_metadata = resp.pop('ResponseMetadata', {}) self.assertEqual(204, response_metadata.get('HTTPStatusCode')) def test_put_bucket_versioning(self): self._create_bucket() url = self._presign_url( 'put_bucket_versioning', VersioningConfiguration={ 'Status': 'Enabled' }) resp = requests.put(url, data="""""" <!DOCTYPE foo [<!ENTITY xxe SYSTEM ""file:///etc/swift/swift.conf""> ]> <VersioningConfiguration xmlns=""http://s3.amazonaws.com/doc/2006-03-01/""> <Status>&xxe;</Status> </VersioningConfiguration> """""") # noqa: E501 self.assertEqual(400, resp.status_code) self.assertNotIn(b'xxe', resp.content) self.assertNotIn(b'[swift-hash]', resp.content) versioning = self.conn.get_bucket_versioning(Bucket=self.bucket) response_metadata = versioning.pop('ResponseMetadata', {}) self.assertEqual(200, response_metadata.get('HTTPStatusCode')) self.assertDictEqual({}, versioning) ",,274,1
openstack%2Fnova~stable%2Fyoga~I5a399f1d3d702bfb76c067893e9c924904c8c360,openstack/nova,stable/yoga,I5a399f1d3d702bfb76c067893e9c924904c8c360,[stable-only][cve] Check VMDK create-type against an allowed list,MERGED,2023-01-24 15:03:37.000000000,2023-01-25 20:09:41.000000000,2023-01-25 20:08:32.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11583}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96522c679bb2beaaa18567b57e09f0d6f95011c5', 'message': 'Check VMDK create-type against an allowed list\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}, {'number': 2, 'created': '2023-01-25 10:04:11.000000000', 'files': ['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/516f0de1f6a54cd24d8ebc906c1e3fd3bab0d32e', 'message': '[stable-only][cve] Check VMDK create-type against an allowed list\n\nNOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport\n\n[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}]",4,871624,516f0de1f6a54cd24d8ebc906c1e3fd3bab0d32e,25,6,2,4393,,,0,"[stable-only][cve] Check VMDK create-type against an allowed list

NOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport

[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes

Related-Bug: #1996188
Change-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360
",git fetch https://review.opendev.org/openstack/nova refs/changes/24/871624/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py']",3,96522c679bb2beaaa18567b57e09f0d6f95011c5,bug/1996188,"def check_vmdk_image(image_id, data): # Check some rules about VMDK files. Specifically we want to make # sure that the ""create-type"" of the image is one that we allow. # Some types of VMDK files can reference files outside the disk # image and we do not want to allow those for obvious reasons. types = CONF.compute.vmdk_allowed_types if not len(types): LOG.warning('Refusing to allow VMDK image as vmdk_allowed_' 'types is empty') msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) try: create_type = data.format_specific['data']['create-type'] except KeyError: msg = _('Unable to determine VMDK create-type') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if create_type not in CONF.compute.vmdk_allowed_types: LOG.warning('Refusing to process VMDK file with create-type of %r ' 'which is not in allowed set of: %s', create_type, ','.join(CONF.compute.vmdk_allowed_types)) msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if fmt == 'vmdk': check_vmdk_image(image_href, data) ",,86,0
openstack%2Fopenstack-ansible-galera_server~master~Ia7d3d1cbfa3aea934d10262a8556952e58e82953,openstack/openstack-ansible-galera_server,master,Ia7d3d1cbfa3aea934d10262a8556952e58e82953,Do not forcefully restart socket,MERGED,2023-01-23 18:17:48.000000000,2023-01-25 20:00:35.000000000,2023-01-25 19:59:41.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-23 18:17:48.000000000', 'files': ['tasks/galera_server_post_install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/bfe6dffee072a14dd838f42df7b53adb9ff2e7a0', 'message': ""Do not forcefully restart socket\n\nWith state:restarted for socket it will be restarted on each playbook\nrun, even when it's not needed. Instead, we should restart socket\nonly when it's changed.\n\nDepends-On: https://review.opendev.org/c/openstack/ansible-role-systemd_service/+/871526\nChange-Id: Ia7d3d1cbfa3aea934d10262a8556952e58e82953\n""}]",0,871527,bfe6dffee072a14dd838f42df7b53adb9ff2e7a0,9,3,1,28619,,,0,"Do not forcefully restart socket

With state:restarted for socket it will be restarted on each playbook
run, even when it's not needed. Instead, we should restart socket
only when it's changed.

Depends-On: https://review.opendev.org/c/openstack/ansible-role-systemd_service/+/871526
Change-Id: Ia7d3d1cbfa3aea934d10262a8556952e58e82953
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/27/871527/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_server_post_install.yml'],1,bfe6dffee072a14dd838f42df7b53adb9ff2e7a0,,," state: ""restarted""",0,1
openstack%2Fansible-role-zookeeper~master~I7017bb4c2eea855464989bf10d7984e130cad4b3,openstack/ansible-role-zookeeper,master,I7017bb4c2eea855464989bf10d7984e130cad4b3,Add configuration option for native Prometheus exporter,MERGED,2023-01-13 09:48:11.000000000,2023-01-25 19:57:05.000000000,2023-01-25 19:56:09.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-01-13 09:48:11.000000000', 'files': ['templates/zoo.cfg.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-zookeeper/commit/1cd6ac5b4c5358be4fbdfd0f5bffa194274e94d7', 'message': 'Add configuration option for native Prometheus exporter\n\nZookeeper supports Prometheus metrics as documented in\nhttps://zookeeper.apache.org/doc/r3.8.0/zookeeperMonitor.html#Prometheus\n\nThis patch adds configuration options to enable it and change\nthe default port.\n\nChange-Id: I7017bb4c2eea855464989bf10d7984e130cad4b3\n'}]",2,870049,1cd6ac5b4c5358be4fbdfd0f5bffa194274e94d7,13,3,1,31542,,,0,"Add configuration option for native Prometheus exporter

Zookeeper supports Prometheus metrics as documented in
https://zookeeper.apache.org/doc/r3.8.0/zookeeperMonitor.html#Prometheus

This patch adds configuration options to enable it and change
the default port.

Change-Id: I7017bb4c2eea855464989bf10d7984e130cad4b3
",git fetch https://review.opendev.org/openstack/ansible-role-zookeeper refs/changes/49/870049/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/zoo.cfg.j2', 'defaults/main.yml']",2,1cd6ac5b4c5358be4fbdfd0f5bffa194274e94d7,, zookeeper_prometheus_enable: False zookeeper_prometheus_port: 7000,,8,0
openstack%2Fheat~master~Id75398d2ed2d4fab467df51057c4167cd77bb32f,openstack/heat,master,Id75398d2ed2d4fab467df51057c4167cd77bb32f,Explicitly pass error kwarg in nested StackValidationFailed,MERGED,2022-11-17 13:26:45.000000000,2023-01-25 19:44:23.000000000,2023-01-25 19:43:16.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 30073}, {'_account_id': 32102}, {'_account_id': 32238}]","[{'number': 1, 'created': '2022-11-17 13:26:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/282d1003750b4a5314980bce6a342717c9f8ed3c', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nCloses-Bug: #2010115\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}, {'number': 2, 'created': '2022-11-17 14:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/de7c83249f9b9be9c4aa6709a39c6b15d716357a', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nCloses-Bug: #2010115\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}, {'number': 3, 'created': '2022-11-18 05:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1b5b24eadb575e345d623e744e1976d7ec2c7e9a', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nTask: #45695\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}, {'number': 4, 'created': '2022-11-22 10:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/54d1268a3ee49b58bfe159885f8b2a2c2dfa55a4', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nTask: #45695\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}, {'number': 5, 'created': '2022-12-06 10:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3e78a2e6863610cb96022981ae0047e01488f989', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nTask: #45695\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}, {'number': 6, 'created': '2022-12-19 06:42:52.000000000', 'files': ['heat/engine/resources/stack_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/53fa8c37497e51d1c40b083790c2d40c71fee3ab', 'message': 'Explicitly pass error kwarg in nested StackValidationFailed\n\nThis fixes the issue when a nested stack is serialized in\noslo.messaging and deserialization fails because we pass\na kwarg as an arg when we generate the exception remotely.\n\nStory: #2010115\nTask: #45695\nChange-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f\n'}]",21,864898,53fa8c37497e51d1c40b083790c2d40c71fee3ab,79,7,6,16137,,,0,"Explicitly pass error kwarg in nested StackValidationFailed

This fixes the issue when a nested stack is serialized in
oslo.messaging and deserialization fails because we pass
a kwarg as an arg when we generate the exception remotely.

Story: #2010115
Task: #45695
Change-Id: Id75398d2ed2d4fab467df51057c4167cd77bb32f
",git fetch https://review.opendev.org/openstack/heat refs/changes/98/864898/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/stack_resource.py'],1,282d1003750b4a5314980bce6a342717c9f8ed3c,," error=ex, path=[self.stack.t.RESOURCES, path])"," ex, path=[self.stack.t.RESOURCES, path])",1,1
openstack%2Fopenstack-ansible-os_neutron~master~I454908a306bfa5d6311261448ebefab6df1b20a7,openstack/openstack-ansible-os_neutron,master,I454908a306bfa5d6311261448ebefab6df1b20a7,"Remove ""warn"" parameter from command module",MERGED,2023-01-10 08:42:47.000000000,2023-01-25 18:51:27.000000000,2023-01-25 18:50:19.000000000,"[{'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-10 08:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/78aea3e58b511f81355acd78fbf92cef56fc8c3f', 'message': 'Remove ""warn"" parameter from command module\n\nThis is removed in ansible 2.14.\n\nChange-Id: I454908a306bfa5d6311261448ebefab6df1b20a7\n'}, {'number': 2, 'created': '2023-01-19 21:25:55.000000000', 'files': ['tasks/neutron_apparmor.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/a6001b7a364218eeea2f32e9b007153856822916', 'message': 'Remove ""warn"" parameter from command module\n\nThis is removed in ansible 2.14.\n\nChange-Id: I454908a306bfa5d6311261448ebefab6df1b20a7\n'}]",2,869662,a6001b7a364218eeea2f32e9b007153856822916,15,3,2,25023,,,0,"Remove ""warn"" parameter from command module

This is removed in ansible 2.14.

Change-Id: I454908a306bfa5d6311261448ebefab6df1b20a7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/62/869662/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/neutron_apparmor.yml'],1,78aea3e58b511f81355acd78fbf92cef56fc8c3f,osa/warn,, warn: no,0,1
openstack%2Fkolla-ansible~master~I20e65a6771ebeee462a3aaaabaa5f0596bdd0581,openstack/kolla-ansible,master,I20e65a6771ebeee462a3aaaabaa5f0596bdd0581,Add systemd container control,MERGED,2021-11-04 16:51:33.000000000,2023-01-25 18:44:52.000000000,2023-01-25 18:43:47.000000000,"[{'_account_id': 13252}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}, {'_account_id': 29636}, {'_account_id': 30491}, {'_account_id': 33708}, {'_account_id': 34911}, {'_account_id': 35105}]","[{'number': 1, 'created': '2021-11-04 16:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2ff334b7123630fc1ab8e063a2e3bfaa7e20d832', 'message': 'Systemd container control PoC\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 2, 'created': '2021-11-09 13:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4ac94fd77bca8147cfa65d8be71b8cb15cc11f54', 'message': 'Systemd container control PoC\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 3, 'created': '2022-01-14 11:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6c35a5cd2ee398cd397b56a057ea761ad6e8428b', 'message': 'Systemd container control PoC\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 4, 'created': '2022-01-27 11:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4351d049f086c19da4ad2f0b8ba0aa28327d51ce', 'message': 'Systemd container control PoC\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 5, 'created': '2022-02-07 09:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/53e30c6d25052e3b60df0809a16fa3a473e733d0', 'message': 'Systemd container control PoC\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 6, 'created': '2022-02-07 10:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d5b28ab3a228912edcbd1b65e1dfac620ffce11e', 'message': 'Systemd container control PoC\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 7, 'created': '2022-02-08 13:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f4343420a4589824b77c2b295fddab19f2c4a3be', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 8, 'created': '2022-02-09 15:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/37c24cc79c88bf9d258c48fe0ac0304ef69e10c7', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 9, 'created': '2022-02-09 15:53:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/466cdf4450a9a53e218b4d28740688064416c887', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 10, 'created': '2022-02-09 15:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/48c88d3179edecaf36b612a28bd7197e06891792', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 11, 'created': '2022-02-09 19:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/02e461a12990b32a470d2f966d7bcd834411e042', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 12, 'created': '2022-02-10 09:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/64ea280721f933fbbdfe22d041216f3c2bd420a3', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 13, 'created': '2022-02-10 11:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/35355237dad7df1e485e32c2d705cb4654261a62', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 14, 'created': '2022-02-10 12:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e7ac658b1650567fd51825e433d12ddd3cbaaf23', 'message': 'Systemd container control\n\nUnit tests are still WIP due to difficulties with testing dbus functionality.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 15, 'created': '2022-02-15 09:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3d720b254867656371cba33266c26fa0e6247b73', 'message': 'Add systemd container control\n\nCreated a class for container status control and unit file generation\nvia the systemd.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd058\n'}, {'number': 16, 'created': '2022-02-15 11:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2aba17c34015e07a615a24ffbd301c5692d5629e', 'message': 'Add systemd container control\n\nCreated a class for container status control and unit file generation\nvia the systemd.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd058\n'}, {'number': 17, 'created': '2022-02-17 11:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9c7b00ef51b8227e3f6363d7fb20231005710680', 'message': 'Add systemd container control\n\nCreated a class for container status control and unit file generation\nvia the systemd.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd058\n'}, {'number': 18, 'created': '2022-02-25 13:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/19555bfe854669984b891024a5944ff554b5adf5', 'message': 'Systemd container control\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 19, 'created': '2022-02-28 10:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c1914001c77b860b83731e39ea00f9cb2696c96b', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 20, 'created': '2022-03-17 10:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/92f4e478a7feb4d8184b857f3a2b824bb42c8102', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 21, 'created': '2022-07-21 11:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2ec65f1d33f07c09ad068e620d84ade023acbc81', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\n'}, {'number': 22, 'created': '2022-08-04 14:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2e532091836745fcefeff33663d680ac57888b3a', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\n'}, {'number': 23, 'created': '2022-08-25 08:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/73a8577802ed894f84d5792ab697676c60b1baf6', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 24, 'created': '2022-08-25 08:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/72689f287254f7dc379e5b3a2861b065fe53ffb1', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 25, 'created': '2022-08-31 15:40:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e9f8e9cdc86fabf965d88b19d46e19311e66f498', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 26, 'created': '2022-09-07 13:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/27b20c7f6b0e9022018e4da5f0ce99d847e0502a', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 27, 'created': '2022-09-07 14:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/36a702579cfedb91a22b2d6adcb415ac621ab829', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 28, 'created': '2022-09-12 15:23:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1e1e8ac9ffebd652f1c0ce7797bdedccac1a6b1b', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 29, 'created': '2022-09-13 09:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ce2485432a2f8a72ff203f45de59d44e047f6c47', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 30, 'created': '2022-09-13 12:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/67f3f0710b3c5f8be92abe398a9fc4d10fed7a6f', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 31, 'created': '2022-09-23 13:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f822850653dcd113232f43310417f98487ffa1ee', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 32, 'created': '2022-09-26 13:05:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/937a66ee56f48e1df05c1510316c1408e31f73d3', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 33, 'created': '2022-09-26 19:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e20e2240bb9ade4fe379b95d54f79947f2a2c60d', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 34, 'created': '2022-09-28 08:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/adc42032cccfb3318524b8aeac0cf1ebb4a58e69', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 35, 'created': '2022-10-13 10:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b0ae152eacd72515fddbb6887aa179498c6b4eca', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 36, 'created': '2022-11-02 16:37:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/567a82713998429e482d4ba83b081591a1a064ab', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 37, 'created': '2022-11-04 13:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/083042619678a0191f1134fc5bf746a06af4d662', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 38, 'created': '2022-11-04 14:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/696997b15d6bb305748898c316790ef508a73369', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 39, 'created': '2022-11-04 14:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ca60708b8363d7bb2738edc4ae10b116fa521800', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 40, 'created': '2022-11-09 14:22:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c66988d900b30b397bf38f139311717c1079f51d', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 41, 'created': '2022-11-27 12:18:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/16de11a56878355ebad01dd9b8a7294b8e03dd73', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 42, 'created': '2022-11-27 12:31:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/36f1773d37929dc98c1d5b12cdc2daa936ef3ebd', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 43, 'created': '2022-11-28 10:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/09e2f900f0855fc6b61db09f63ac01aebb4cbd97', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 44, 'created': '2022-11-28 10:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2f4628ddf223cb397ecbf8a2ea8f1a3c4322a11e', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 45, 'created': '2022-11-28 13:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3ce7b96b373070947f0b324057782354871057c3', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nSigned-off-by: Martin Hiner <martin.hiner@tietoevry.com>\nCo-authored-by: Ivan Halomi <ivan.halomi@tietoevry.com>\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 46, 'created': '2023-01-02 13:47:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bca690d02e4e5f171e3872b8206ca135a9dba9cb', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 47, 'created': '2023-01-19 09:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/71bb802c3d3cf4e1ae92534b5d240a0a0fa0c9a6', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}, {'number': 48, 'created': '2023-01-19 09:38:43.000000000', 'files': ['ansible/module_utils/kolla_docker_worker.py', 'ansible/roles/prechecks/tasks/package_checks.yml', 'releasenotes/notes/add-systemd-container-control-b85dff9ec5fae313.yaml', 'tools/cleanup-containers', 'tests/test_kolla_docker.py', 'ansible/module_utils/kolla_systemd_worker.py', 'ansible/roles/prechecks/tasks/service_checks.yml', 'ansible/gather-facts.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4866017e5256623fe1838817260ce5836cc26ef1', 'message': 'Add systemd container control\n\nThis commit adds SystemdWorker class to kolla_docker ansible module.\nIt is used to manage container state via systemd calls.\n\nChange-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581\nSigned-off-by: Ivan Halomi <i.halomi@partner.samsung.com>\nSigned-off-by: Martin Hiner <m.hiner@partner.samsung.com>\n'}]",244,816724,4866017e5256623fe1838817260ce5836cc26ef1,246,11,48,34113,,,0,"Add systemd container control

This commit adds SystemdWorker class to kolla_docker ansible module.
It is used to manage container state via systemd calls.

Change-Id: I20e65a6771ebeee462a3aaaabaa5f0596bdd0581
Signed-off-by: Ivan Halomi <i.halomi@partner.samsung.com>
Signed-off-by: Martin Hiner <m.hiner@partner.samsung.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/24/816724/12 && git format-patch -1 --stdout FETCH_HEAD,"['tools/cleanup-containers', 'ansible/module_utils/systemd_worker.py', 'ansible/module_utils/templates/service_template.j2', 'ansible/module_utils/docker_worker.py', 'ansible/library/kolla_docker.py']",5,2ff334b7123630fc1ab8e063a2e3bfaa7e20d832,Ic30b67daa2e215524096ad1f4385c569e3d41b95,import syssys.path.append(os.getcwd() + '/module_utils') from docker_worker import DockerWorker # noqa: E402 ,"import jsonimport shleximport docker from distutils.version import StrictVersion COMPARE_CONFIG_CMD = ['/usr/local/bin/kolla_set_configs', '--check'] def get_docker_client(): return docker.APIClient class DockerWorker(object): def __init__(self, module): self.module = module self.params = self.module.params self.changed = False # Use this to store arguments to pass to exit_json(). self.result = {} # TLS not fully implemented # tls_config = self.generate_tls() options = { 'version': self.params.get('api_version'), 'timeout': self.params.get('client_timeout'), } self.dc = get_docker_client()(**options) self._cgroupns_mode_supported = ( StrictVersion(self.dc._version) >= StrictVersion('1.41')) def generate_tls(self): tls = {'verify': self.params.get('tls_verify')} tls_cert = self.params.get('tls_cert'), tls_key = self.params.get('tls_key'), tls_cacert = self.params.get('tls_cacert') if tls['verify']: if tls_cert: self.check_file(tls_cert) self.check_file(tls_key) tls['client_cert'] = (tls_cert, tls_key) if tls_cacert: self.check_file(tls_cacert) tls['verify'] = tls_cacert return docker.tls.TLSConfig(**tls) def check_file(self, path): if not os.path.isfile(path): self.module.fail_json( failed=True, msg='There is no file at ""{}""'.format(path) ) if not os.access(path, os.R_OK): self.module.fail_json( failed=True, msg='Permission denied for file at ""{}""'.format(path) ) def check_image(self): find_image = ':'.join(self.parse_image()) for image in self.dc.images(): repo_tags = image.get('RepoTags') if not repo_tags: continue for image_name in repo_tags: if image_name == find_image: return image def check_volume(self): for vol in self.dc.volumes()['Volumes'] or list(): if vol['Name'] == self.params.get('name'): return vol def check_container(self): find_name = '/{}'.format(self.params.get('name')) for cont in self.dc.containers(all=True): if find_name in cont['Names']: return cont def get_container_info(self): container = self.check_container() if not container: return None return self.dc.inspect_container(self.params.get('name')) def compare_container(self): container = self.check_container() if (not container or self.check_container_differs() or self.compare_config()): self.changed = True return self.changed def check_container_differs(self): container_info = self.get_container_info() return ( self.compare_cap_add(container_info) or self.compare_security_opt(container_info) or self.compare_image(container_info) or self.compare_ipc_mode(container_info) or self.compare_labels(container_info) or self.compare_privileged(container_info) or self.compare_pid_mode(container_info) or self.compare_cgroupns_mode(container_info) or self.compare_tmpfs(container_info) or self.compare_volumes(container_info) or self.compare_volumes_from(container_info) or self.compare_environment(container_info) or self.compare_container_state(container_info) or self.compare_dimensions(container_info) or self.compare_command(container_info) or self.compare_healthcheck(container_info) ) def compare_ipc_mode(self, container_info): new_ipc_mode = self.params.get('ipc_mode') current_ipc_mode = container_info['HostConfig'].get('IpcMode') if not current_ipc_mode: current_ipc_mode = None # only check IPC mode if it is specified if new_ipc_mode is not None and new_ipc_mode != current_ipc_mode: return True return False def compare_cap_add(self, container_info): new_cap_add = self.params.get('cap_add', list()) current_cap_add = container_info['HostConfig'].get('CapAdd', list()) if not current_cap_add: current_cap_add = list() if set(new_cap_add).symmetric_difference(set(current_cap_add)): return True def compare_security_opt(self, container_info): ipc_mode = self.params.get('ipc_mode') pid_mode = self.params.get('pid_mode') privileged = self.params.get('privileged', False) # NOTE(jeffrey4l) security opt is disabled when using host ipc mode or # host pid mode or privileged. So no need to compare security opts if ipc_mode == 'host' or pid_mode == 'host' or privileged: return False new_sec_opt = self.params.get('security_opt', list()) current_sec_opt = container_info['HostConfig'].get('SecurityOpt', list()) if not current_sec_opt: current_sec_opt = list() if set(new_sec_opt).symmetric_difference(set(current_sec_opt)): return True def compare_pid_mode(self, container_info): new_pid_mode = self.params.get('pid_mode') current_pid_mode = container_info['HostConfig'].get('PidMode') if not current_pid_mode: current_pid_mode = None if new_pid_mode != current_pid_mode: return True def compare_cgroupns_mode(self, container_info): if not self._cgroupns_mode_supported: return False new_cgroupns_mode = self.params.get('cgroupns_mode') if new_cgroupns_mode is None: # means we don't care what it is return False current_cgroupns_mode = (container_info['HostConfig'] .get('CgroupnsMode')) if current_cgroupns_mode == '': # means the container was created on Docker pre-20.10 # it behaves like 'host' current_cgroupns_mode = 'host' return new_cgroupns_mode != current_cgroupns_mode def compare_privileged(self, container_info): new_privileged = self.params.get('privileged') current_privileged = container_info['HostConfig']['Privileged'] if new_privileged != current_privileged: return True def compare_image(self, container_info=None): container_info = container_info or self.get_container_info() parse_repository_tag = docker.utils.parse_repository_tag if not container_info: return True new_image = self.check_image() current_image = container_info['Image'] if not new_image: return True if new_image['Id'] != current_image: return True # NOTE(Jeffrey4l) when new image and the current image have # the same id, but the tag name different. elif (parse_repository_tag(container_info['Config']['Image']) != parse_repository_tag(self.params.get('image'))): return True def compare_labels(self, container_info): new_labels = self.params.get('labels') current_labels = container_info['Config'].get('Labels', dict()) image_labels = self.check_image().get('Labels', dict()) for k, v in image_labels.items(): if k in new_labels: if v != new_labels[k]: return True else: del current_labels[k] if new_labels != current_labels: return True def compare_tmpfs(self, container_info): new_tmpfs = self.generate_tmpfs() current_tmpfs = container_info['HostConfig'].get('Tmpfs') if not new_tmpfs: new_tmpfs = [] if not current_tmpfs: current_tmpfs = [] if set(current_tmpfs).symmetric_difference(set(new_tmpfs)): return True def compare_volumes_from(self, container_info): new_vols_from = self.params.get('volumes_from') current_vols_from = container_info['HostConfig'].get('VolumesFrom') if not new_vols_from: new_vols_from = list() if not current_vols_from: current_vols_from = list() if set(current_vols_from).symmetric_difference(set(new_vols_from)): return True def compare_volumes(self, container_info): volumes, binds = self.generate_volumes() current_vols = container_info['Config'].get('Volumes') current_binds = container_info['HostConfig'].get('Binds') if not volumes: volumes = list() if not current_vols: current_vols = list() if not current_binds: current_binds = list() if set(volumes).symmetric_difference(set(current_vols)): return True new_binds = list() if binds: for k, v in binds.items(): new_binds.append(""{}:{}:{}"".format(k, v['bind'], v['mode'])) if set(new_binds).symmetric_difference(set(current_binds)): return True def compare_environment(self, container_info): if self.params.get('environment'): current_env = dict() for kv in container_info['Config'].get('Env', list()): k, v = kv.split('=', 1) current_env.update({k: v}) for k, v in self.params.get('environment').items(): if k not in current_env: return True if current_env[k] != v: return True def compare_container_state(self, container_info): new_state = self.params.get('state') current_state = container_info['State'].get('Status') if new_state != current_state: return True def compare_dimensions(self, container_info): new_dimensions = self.params.get('dimensions') # NOTE(mgoddard): The names used by Docker are inconsisent between # configuration of a container's resources and the resources in # container_info['HostConfig']. This provides a mapping between the # two. dimension_map = { 'mem_limit': 'Memory', 'mem_reservation': 'MemoryReservation', 'memswap_limit': 'MemorySwap', 'cpu_period': 'CpuPeriod', 'cpu_quota': 'CpuQuota', 'cpu_shares': 'CpuShares', 'cpuset_cpus': 'CpusetCpus', 'cpuset_mems': 'CpusetMems', 'kernel_memory': 'KernelMemory', 'blkio_weight': 'BlkioWeight', 'ulimits': 'Ulimits'} unsupported = set(new_dimensions.keys()) - \ set(dimension_map.keys()) if unsupported: self.module.exit_json( failed=True, msg=repr(""Unsupported dimensions""), unsupported_dimensions=unsupported) current_dimensions = container_info['HostConfig'] for key1, key2 in dimension_map.items(): # NOTE(mgoddard): If a resource has been explicitly requested, # check for a match. Otherwise, ensure it is set to the default. if key1 in new_dimensions: if key1 == 'ulimits': if self.compare_ulimits(new_dimensions[key1], current_dimensions[key2]): return True elif new_dimensions[key1] != current_dimensions[key2]: return True elif current_dimensions[key2]: # The default values of all currently supported resources are # '' or 0 - both falsey. return True def compare_ulimits(self, new_ulimits, current_ulimits): # The new_ulimits is dict, we need make it to a list of Ulimit # instance. new_ulimits = self.build_ulimits(new_ulimits) def key(ulimit): return ulimit['Name'] if current_ulimits is None: current_ulimits = [] return sorted(new_ulimits, key=key) != sorted(current_ulimits, key=key) def compare_command(self, container_info): new_command = self.params.get('command') if new_command is not None: new_command_split = shlex.split(new_command) new_path = new_command_split[0] new_args = new_command_split[1:] if (new_path != container_info['Path'] or new_args != container_info['Args']): return True def compare_healthcheck(self, container_info): new_healthcheck = self.parse_healthcheck( self.params.get('healthcheck')) current_healthcheck = container_info['Config'].get('Healthcheck') healthcheck_map = { 'test': 'Test', 'retries': 'Retries', 'interval': 'Interval', 'start_period': 'StartPeriod', 'timeout': 'Timeout'} if new_healthcheck: new_healthcheck = new_healthcheck['healthcheck'] if current_healthcheck: new_healthcheck = dict((healthcheck_map.get(k, k), v) for (k, v) in new_healthcheck.items()) return new_healthcheck != current_healthcheck else: return True else: if current_healthcheck: return True def compare_config(self): try: job = self.dc.exec_create( self.params['name'], COMPARE_CONFIG_CMD, user='root', ) output = self.dc.exec_start(job) exec_inspect = self.dc.exec_inspect(job) except docker.errors.APIError as e: # NOTE(yoctozepto): If we have a client error, then the container # cannot be used for config check (e.g., is restarting, or stopped # in the mean time) - assume config is stale = return True. # Else, propagate the server error back. if e.is_client_error(): return True else: raise # Exit codes: # 0: not changed # 1: changed # 137: abrupt exit -> changed # else: error if exec_inspect['ExitCode'] == 0: return False elif exec_inspect['ExitCode'] == 1: return True elif exec_inspect['ExitCode'] == 137: # NOTE(yoctozepto): This is Docker's command exit due to container # exit. It means the container is unstable so we are better off # marking it as requiring a restart due to config update. return True else: raise Exception('Failed to compare container configuration: ' 'ExitCode: %s Message: %s' % (exec_inspect['ExitCode'], output)) def parse_image(self): full_image = self.params.get('image') if '/' in full_image: registry, image = full_image.split('/', 1) else: image = full_image if ':' in image: return full_image.rsplit(':', 1) else: return full_image, 'latest' def get_image_id(self): full_image = self.params.get('image') image = self.dc.images(name=full_image, quiet=True) return image[0] if len(image) == 1 else None def pull_image(self): if self.params.get('auth_username'): self.dc.login( username=self.params.get('auth_username'), password=self.params.get('auth_password'), registry=self.params.get('auth_registry'), email=self.params.get('auth_email') ) image, tag = self.parse_image() old_image_id = self.get_image_id() statuses = [ json.loads(line.strip().decode('utf-8')) for line in self.dc.pull( repository=image, tag=tag, stream=True ) ] for status in reversed(statuses): if 'error' in status: if status['error'].endswith('not found'): self.module.fail_json( msg=""The requested image does not exist: {}:{}"".format( image, tag), failed=True ) else: self.module.fail_json( msg=""Unknown error message: {}"".format( status['error']), failed=True ) new_image_id = self.get_image_id() self.changed = old_image_id != new_image_id def remove_container(self): if self.check_container(): self.changed = True # NOTE(jeffrey4l): in some case, docker failed to remove container # filesystem and raise error. But the container info is # disappeared already. If this happens, assume the container is # removed. try: self.dc.remove_container( container=self.params.get('name'), force=True ) except docker.errors.APIError: if self.check_container(): raise def generate_tmpfs(self): tmpfs = self.params.get('tmpfs') if tmpfs: # NOTE(mgoddard): Filter out any empty strings. tmpfs = [t for t in tmpfs if t] return tmpfs def generate_volumes(self): volumes = self.params.get('volumes') if not volumes: return None, None vol_list = list() vol_dict = dict() for vol in volumes: if len(vol) == 0: continue if ':' not in vol: vol_list.append(vol) continue split_vol = vol.split(':') if (len(split_vol) == 2 and ('/' not in split_vol[0] or '/' in split_vol[1])): split_vol.append('rw') vol_list.append(split_vol[1]) vol_dict.update({ split_vol[0]: { 'bind': split_vol[1], 'mode': split_vol[2] } }) return vol_list, vol_dict def parse_dimensions(self, dimensions): # When the data object contains types such as # docker.types.Ulimit, Ansible will fail when these are # returned via exit_json or fail_json. HostConfig is derived from dict, # but its constructor requires additional arguments. # to avoid that, here do copy the dimensions and return a new one. dimensions = dimensions.copy() supported = {'cpu_period', 'cpu_quota', 'cpu_shares', 'cpuset_cpus', 'cpuset_mems', 'mem_limit', 'mem_reservation', 'memswap_limit', 'kernel_memory', 'blkio_weight', 'ulimits'} unsupported = set(dimensions) - supported if unsupported: self.module.exit_json(failed=True, msg=repr(""Unsupported dimensions""), unsupported_dimensions=unsupported) ulimits = dimensions.get('ulimits') if ulimits: dimensions['ulimits'] = self.build_ulimits(ulimits) return dimensions def build_ulimits(self, ulimits): ulimits_opt = [] for key, value in ulimits.items(): soft = value.get('soft') hard = value.get('hard') ulimits_opt.append(docker.types.Ulimit(name=key, soft=soft, hard=hard)) return ulimits_opt def build_host_config(self, binds): options = { 'network_mode': 'host', 'ipc_mode': self.params.get('ipc_mode'), 'cap_add': self.params.get('cap_add'), 'security_opt': self.params.get('security_opt'), 'pid_mode': self.params.get('pid_mode'), 'privileged': self.params.get('privileged'), 'tmpfs': self.generate_tmpfs(), 'volumes_from': self.params.get('volumes_from') } dimensions = self.params.get('dimensions') if dimensions: dimensions = self.parse_dimensions(dimensions) options.update(dimensions) restart_policy = self.params.get('restart_policy') if restart_policy is not None: restart_policy = {'Name': restart_policy} # NOTE(Jeffrey4l): MaximumRetryCount is only needed for on-failure # policy if restart_policy['Name'] == 'on-failure': retries = self.params.get('restart_retries') if retries is not None: restart_policy['MaximumRetryCount'] = retries options['restart_policy'] = restart_policy if binds: options['binds'] = binds host_config = self.dc.create_host_config(**options) if self._cgroupns_mode_supported: # NOTE(yoctozepto): python-docker does not support CgroupnsMode # natively so we stuff it in manually. cgroupns_mode = self.params.get('cgroupns_mode') if cgroupns_mode is not None: host_config['CgroupnsMode'] = cgroupns_mode return host_config def _inject_env_var(self, environment_info): newenv = { 'KOLLA_SERVICE_NAME': self.params.get('name').replace('_', '-') } environment_info.update(newenv) return environment_info def _format_env_vars(self): env = self._inject_env_var(self.params.get('environment')) return {k: """" if env[k] is None else env[k] for k in env} def build_container_options(self): volumes, binds = self.generate_volumes() options = { 'command': self.params.get('command'), 'detach': self.params.get('detach'), 'environment': self._format_env_vars(), 'host_config': self.build_host_config(binds), 'labels': self.params.get('labels'), 'image': self.params.get('image'), 'name': self.params.get('name'), 'volumes': volumes, 'tty': self.params.get('tty'), } healthcheck = self.parse_healthcheck(self.params.get('healthcheck')) if healthcheck: options.update(healthcheck) return options def create_container(self): self.changed = True options = self.build_container_options() self.dc.create_container(**options) def recreate_or_restart_container(self): self.changed = True container = self.check_container() # get config_strategy from env environment = self.params.get('environment') config_strategy = environment.get('KOLLA_CONFIG_STRATEGY') if not container: self.start_container() return # If config_strategy is COPY_ONCE or container's parameters are # changed, try to start a new one. if config_strategy == 'COPY_ONCE' or self.check_container_differs(): # NOTE(mgoddard): Pull the image if necessary before stopping the # container, otherwise a failure to pull the image will leave the # container stopped. if not self.check_image(): self.pull_image() self.stop_container() self.remove_container() self.start_container() elif config_strategy == 'COPY_ALWAYS': self.restart_container() def start_container(self): if not self.check_image(): self.pull_image() container = self.check_container() if container and self.check_container_differs(): self.stop_container() self.remove_container() container = self.check_container() if not container: self.create_container() container = self.check_container() if not container['Status'].startswith('Up '): self.changed = True self.dc.start(container=self.params.get('name')) # We do not want to detach so we wait around for container to exit if not self.params.get('detach'): rc = self.dc.wait(self.params.get('name')) # NOTE(jeffrey4l): since python docker package 3.0, wait return a # dict all the time. if isinstance(rc, dict): rc = rc['StatusCode'] # Include container's return code, standard output and error in the # result. self.result['rc'] = rc self.result['stdout'] = self.dc.logs(self.params.get('name'), stdout=True, stderr=False) self.result['stderr'] = self.dc.logs(self.params.get('name'), stdout=False, stderr=True) if self.params.get('remove_on_exit'): self.stop_container() self.remove_container() if rc != 0: self.module.fail_json( changed=True, msg=""Container exited with non-zero return code %s"" % rc, **self.result ) def get_container_env(self): name = self.params.get('name') info = self.get_container_info() if not info: self.module.fail_json(msg=""No such container: {}"".format(name)) else: envs = dict() for env in info['Config']['Env']: if '=' in env: key, value = env.split('=', 1) else: key, value = env, '' envs[key] = value self.module.exit_json(**envs) def get_container_state(self): name = self.params.get('name') info = self.get_container_info() if not info: self.module.fail_json(msg=""No such container: {}"".format(name)) else: self.module.exit_json(**info['State']) def parse_healthcheck(self, healthcheck): if not healthcheck: return None result = dict(healthcheck={}) # All supported healthcheck parameters supported = set(['test', 'interval', 'timeout', 'start_period', 'retries']) unsupported = set(healthcheck) - supported missing = supported - set(healthcheck) duration_options = set(['interval', 'timeout', 'start_period']) if unsupported: self.module.exit_json(failed=True, msg=repr(""Unsupported healthcheck options""), unsupported_healthcheck=unsupported) if missing: self.module.exit_json(failed=True, msg=repr(""Missing healthcheck option""), missing_healthcheck=missing) for key in healthcheck: value = healthcheck.get(key) if key in duration_options: try: result['healthcheck'][key] = int(value) * 1000000000 except TypeError: raise TypeError( 'Cannot parse healthcheck ""{0}"". ' 'Expected an integer, got ""{1}"".' .format(value, type(value).__name__) ) except ValueError: raise ValueError( 'Cannot parse healthcheck ""{0}"". ' 'Expected an integer, got ""{1}"".' .format(value, type(value).__name__) ) else: if key == 'test': # If the user explicitly disables the healthcheck, # return None as the healthcheck object if value in (['NONE'], 'NONE'): return None else: if isinstance(value, (tuple, list)): result['healthcheck'][key] = \ [str(e) for e in value] else: result['healthcheck'][key] = \ ['CMD-SHELL', str(value)] elif key == 'retries': try: result['healthcheck'][key] = int(value) except ValueError: raise ValueError( 'Cannot parse healthcheck number of retries.' 'Expected an integer, got ""{0}"".' .format(type(value)) ) return result def stop_container(self): name = self.params.get('name') graceful_timeout = self.params.get('graceful_timeout') if not graceful_timeout: graceful_timeout = 10 container = self.check_container() if not container: ignore_missing = self.params.get('ignore_missing') if not ignore_missing: self.module.fail_json( msg=""No such container: {} to stop"".format(name)) elif not container['Status'].startswith('Exited '): self.changed = True self.dc.stop(name, timeout=graceful_timeout) def stop_and_remove_container(self): container = self.check_container() if container: self.stop_container() self.remove_container() def restart_container(self): name = self.params.get('name') graceful_timeout = self.params.get('graceful_timeout') if not graceful_timeout: graceful_timeout = 10 info = self.get_container_info() if not info: self.module.fail_json( msg=""No such container: {}"".format(name)) else: self.changed = True self.dc.stop(name, timeout=graceful_timeout) self.dc.start(name) def create_volume(self): if not self.check_volume(): self.changed = True self.dc.create_volume(name=self.params.get('name'), driver='local') def remove_volume(self): if self.check_volume(): self.changed = True try: self.dc.remove_volume(name=self.params.get('name')) except docker.errors.APIError as e: if e.response.status_code == 409: self.module.fail_json( failed=True, msg=""Volume named '{}' is currently in-use"".format( self.params.get('name') ) ) raise def remove_image(self): if self.check_image(): self.changed = True try: self.dc.remove_image(image=self.params.get('image')) except docker.errors.APIError as e: if e.response.status_code == 409: self.module.fail_json( failed=True, msg=""Image '{}' is currently in-use"".format( self.params.get('image') ) ) elif e.response.status_code == 500: self.module.fail_json( failed=True, msg=""Server error"" ) raise def ensure_image(self): if not self.check_image(): self.pull_image() ",1168,858
openstack%2Fos-brick~master~I6fc43ab7e243d50b74036d1af5f9e8f880401cc6,openstack/os-brick,master,I6fc43ab7e243d50b74036d1af5f9e8f880401cc6,Handle FileNotFoundError on get_system_uuid(),MERGED,2022-10-24 23:37:59.000000000,2023-01-25 18:34:23.000000000,2023-01-25 17:40:42.000000000,"[{'_account_id': 4523}, {'_account_id': 13671}, {'_account_id': 20813}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-10-24 23:37:59.000000000', 'files': ['os_brick/tests/privileged/test_nvmeof.py', 'os_brick/privileged/nvmeof.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/bc96120b7e709f345b110921954f44a5dc6c51c3', 'message': ""Handle FileNotFoundError on get_system_uuid()\n\nOn some platforms there is no 'dmidecode' program (e.g. s390x), when\nprivsep attempts to run a program that's not found, it raises a\nFileNotFoundError instead of ProcessExecutionError.\n\nCloses-Bug: #1994083\nChange-Id: I6fc43ab7e243d50b74036d1af5f9e8f880401cc6\n""}]",2,862542,bc96120b7e709f345b110921954f44a5dc6c51c3,22,4,1,2424,,,0,"Handle FileNotFoundError on get_system_uuid()

On some platforms there is no 'dmidecode' program (e.g. s390x), when
privsep attempts to run a program that's not found, it raises a
FileNotFoundError instead of ProcessExecutionError.

Closes-Bug: #1994083
Change-Id: I6fc43ab7e243d50b74036d1af5f9e8f880401cc6
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/42/862542/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/privileged/test_nvmeof.py', 'os_brick/privileged/nvmeof.py']",2,bc96120b7e709f345b110921954f44a5dc6c51c3,bug/1994083," except (putils.ProcessExecutionError, FileNotFoundError) as e:", except putils.ProcessExecutionError as e:,11,1
openstack%2Fneutron~stable%2Fwallaby~I37ec0ba04bafb3b7baec6003155b7d9c43092667,openstack/neutron,stable/wallaby,I37ec0ba04bafb3b7baec6003155b7d9c43092667,Increase fullstack job's timeout,MERGED,2023-01-25 12:26:36.000000000,2023-01-25 18:32:49.000000000,2023-01-25 18:30:48.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 12:26:36.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4e542f3d8c9951998b8be1f2ba37750594d06e76', 'message': ""Increase fullstack job's timeout\n\nIt seems that recently we are often timing out the fullstack job when\nit's executed on some busy node. To avoid that, lets give 20 more\nminutes to the timeout of the fullstack jobs.\n\nChange-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667\n(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)\n""}]",2,871567,4e542f3d8c9951998b8be1f2ba37750594d06e76,11,3,1,13861,,,0,"Increase fullstack job's timeout

It seems that recently we are often timing out the fullstack job when
it's executed on some busy node. To avoid that, lets give 20 more
minutes to the timeout of the fullstack jobs.

Change-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667
(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/67/871567/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,4e542f3d8c9951998b8be1f2ba37750594d06e76,increase-fullstack-timeout-stable/zed-stable/yoga-stable/xena-stable/wallaby, timeout: 9000,,1,0
openstack%2Fneutron~master~I6d48d812541a5d4d829a9e260eea558c10dcdfa3,openstack/neutron,master,I6d48d812541a5d4d829a9e260eea558c10dcdfa3,Load OVS Trunk extension if service plugin configured,ABANDONED,2022-11-30 20:22:44.000000000,2023-01-25 18:20:49.000000000,,"[{'_account_id': 9845}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2022-11-30 20:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a49f4d9beb4871bd475398724dd3544df73832ae', 'message': 'Load OVS Trunk extension if service plugin configured\n\nLoad the OVS Trunk agent extension driver only if the service\nplugin is enabled. If the service plugin is not enabled, the agent\nextension will not subscribe to the port events.\n\nThis patch is similar to [1].\n\n[1]https://review.opendev.org/c/openstack/neutron/+/796008\n\nCloses-Bug: #1998353\nChange-Id: I6d48d812541a5d4d829a9e260eea558c10dcdfa3\n'}, {'number': 2, 'created': '2022-12-01 09:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae045c27bfb81e596152b4f54bbd79fc9325f928', 'message': 'Load OVS Trunk extension if service plugin configured\n\nLoad the OVS Trunk agent extension driver only if the service\nplugin is enabled. If the service plugin is not enabled, the agent\nextension will not subscribe to the port events.\n\nThis patch is similar to [1].\n\n[1]https://review.opendev.org/c/openstack/neutron/+/796008\n\nRelated-Bug: #1998353\nChange-Id: I6d48d812541a5d4d829a9e260eea558c10dcdfa3\n'}, {'number': 3, 'created': '2022-12-01 16:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41ef348b41b08318766f9e209efe76bd760cc21c', 'message': 'Load OVS Trunk extension if service plugin configured\n\nLoad the OVS Trunk agent extension driver only if the service\nplugin is enabled. If the service plugin is not enabled, the agent\nextension will not subscribe to the port events.\n\nThis patch is similar to [1].\n\n[1]https://review.opendev.org/c/openstack/neutron/+/796008\n\nRelated-Bug: #1998353\nChange-Id: I6d48d812541a5d4d829a9e260eea558c10dcdfa3\n'}, {'number': 4, 'created': '2022-12-05 14:53:37.000000000', 'files': ['neutron/services/trunk/drivers/openvswitch/agent/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dae344c801899a86877ad19b87d40c3a6fbcac6e', 'message': 'Load OVS Trunk extension if service plugin configured\n\nLoad the OVS Trunk agent extension driver only if the service\nplugin is enabled. If the service plugin is not enabled, the agent\nextension will not subscribe to the port events.\n\nThis patch is similar to [1].\n\n[1]https://review.opendev.org/c/openstack/neutron/+/796008\n\nRelated-Bug: #1998353\nChange-Id: I6d48d812541a5d4d829a9e260eea558c10dcdfa3\n'}]",5,866210,dae344c801899a86877ad19b87d40c3a6fbcac6e,27,4,4,16688,,,0,"Load OVS Trunk extension if service plugin configured

Load the OVS Trunk agent extension driver only if the service
plugin is enabled. If the service plugin is not enabled, the agent
extension will not subscribe to the port events.

This patch is similar to [1].

[1]https://review.opendev.org/c/openstack/neutron/+/796008

Related-Bug: #1998353
Change-Id: I6d48d812541a5d4d829a9e260eea558c10dcdfa3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/866210/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/trunk/drivers/openvswitch/agent/driver.py'],1,a49f4d9beb4871bd475398724dd3544df73832ae,bug/1998353,from neutron.services.trunk import utils as trunk_utils if not trunk_utils.is_trunk_service_loaded(): return if not trunk_utils.is_trunk_service_loaded(): return ,,8,0
openstack%2Foslo.privsep~master~I3dd86ccc304fea04ff99f647ae19d77134faa5a2,openstack/oslo.privsep,master,I3dd86ccc304fea04ff99f647ae19d77134faa5a2,[WIP][DNM] Move threads to processes,ABANDONED,2021-06-04 15:13:21.000000000,2023-01-25 18:20:02.000000000,,"[{'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2021-06-04 15:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/d0384b7135710469cf6cc1da41c5b08f6ddfbb63', 'message': '[WIP][DNM] Move threads to processes\n\nChange-Id: I3dd86ccc304fea04ff99f647ae19d77134faa5a2\n'}, {'number': 2, 'created': '2021-06-28 16:54:54.000000000', 'files': ['oslo_privsep/daemon.py'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/333cb1bbb38275c2081343291587bcaf8a8e9681', 'message': ""[WIP][DNM] Move threads to processes\n\nIn this patch what I'm trying to do is to move from threads\nto processes (os.fork) to execute the privsep commands. That\nwill allow us to have control over the running process and, if\nneeded, to kill it.\n\nTODO:\n- control os.fork timeout --> kill child PIDs if timeout\n  and return error. Actually this is what is this patch about:\n  to have a way to spawn a (cheap) process and control the time;\n  in case of timeout --> os.kill (no mercy!)\n- create new comm.Message item to check forked child permissions\n  (testing)\n- create new comm.Message item to check forked time (testing,\n  benchmarking)\n\nChange-Id: I3dd86ccc304fea04ff99f647ae19d77134faa5a2\n""}]",9,794847,333cb1bbb38275c2081343291587bcaf8a8e9681,7,2,2,16688,,,0,"[WIP][DNM] Move threads to processes

In this patch what I'm trying to do is to move from threads
to processes (os.fork) to execute the privsep commands. That
will allow us to have control over the running process and, if
needed, to kill it.

TODO:
- control os.fork timeout --> kill child PIDs if timeout
  and return error. Actually this is what is this patch about:
  to have a way to spawn a (cheap) process and control the time;
  in case of timeout --> os.kill (no mercy!)
- create new comm.Message item to check forked child permissions
  (testing)
- create new comm.Message item to check forked time (testing,
  benchmarking)

Change-Id: I3dd86ccc304fea04ff99f647ae19d77134faa5a2
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/47/794847/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_privsep/daemon.py'],1,d0384b7135710469cf6cc1da41c5b08f6ddfbb63,threads_to_processes,"import multiprocessing.queuesdef process_cmd(msgid, mp_queue, cmd, *args): """"""Executes the requested command in an new process."""""" if cmd == Message.PING: mp_queue.put((msgid, Message.PONG.value,)) try: if cmd != Message.CALL: msg = 'Unknown privsep cmd: %s' % cmd mp_queue.put((msgid, msg, 'ProtocolError', None)) return # Extract the callable and arguments name, f_args, f_kwargs = args func = importutils.import_class(name) # TODO(ralonsoh): reimplement this # if not self.context.is_entrypoint(func): # msg = _('Invalid privsep function: %s not exported') % name # raise NameError(msg) ret = func(*f_args, **f_kwargs) mp_queue.put((msgid, Message.RET.value, ret)) except Exception as e: LOG.debug( 'privsep: Exception during request[%(msgid)s]: ' '%(err)s', {'msgid': msgid, 'err': e}, exc_info=True) cls = e.__class__ cls_name = '%s.%s' % (cls.__module__, cls.__name__) mp_queue.put((msgid, Message.ERR.value, cls_name, e.args)) # self.thread_pool = futures.ThreadPoolExecutor( # context.conf.thread_pool_size) self.mp_queue = multiprocessing.queues.Queue() self.recv_thread = threading.Thread(target=self._recv_thread) self.recv_thread.start() def _recv_thread(self): while True: ret = self.mp_queue.get() msgid = ret[0] reply = tuple(list(ret)[1:]) LOG.debug('privsep: reply[%(msgid)s]: %(reply)s', {'msgid': msgid, 'reply': reply}) self.channel.send((msgid, reply)) # def _process_cmd(self, msgid, cmd, *args): # """"""Executes the requested command in an execution thread. # # This executes a call within a thread executor and returns the results # of the execution. # # :param msgid: The message identifier. # :param cmd: The `Message` type indicating the command type. # :param args: The function, args, and kwargs if a Message.CALL type. # :return: A tuple of the return status, optional call output, and # optional error information. # """""" # if cmd == Message.PING: # return (Message.PONG.value,) # # try: # if cmd != Message.CALL: # raise ProtocolError(_('Unknown privsep cmd: %s') % cmd) # # # Extract the callable and arguments # name, f_args, f_kwargs = args # func = importutils.import_class(name) # if not self.context.is_entrypoint(func): # msg = _('Invalid privsep function: %s not exported') % name # raise NameError(msg) # # ret = func(*f_args, **f_kwargs) # return (Message.RET.value, ret) # except Exception as e: # LOG.debug( # 'privsep: Exception during request[%(msgid)s]: ' # '%(err)s', {'msgid': msgid, 'err': e}, exc_info=True) # cls = e.__class__ # cls_name = '%s.%s' % (cls.__module__, cls.__name__) # return (Message.ERR.value, cls_name, e.args) # def _create_done_callback(self, msgid): # """"""Creates a future callback to receive command execution results. # # :param msgid: The message identifier. # :return: A future reply callback. # """""" # channel = self.channel # # def _call_back(result): # """"""Future execution callback. # # :param result: The `future` execution and its results. # """""" # try: # reply = result.result() # LOG.debug('privsep: reply[%(msgid)s]: %(reply)s', # {'msgid': msgid, 'reply': reply}) # channel.send((msgid, reply)) # except IOError: # self.communication_error = sys.exc_info() # except Exception as e: # LOG.debug( # 'privsep: Exception during request[%(msgid)s]: ' # '%(err)s', {'msgid': msgid, 'err': e}, exc_info=True) # cls = e.__class__ # cls_name = '%s.%s' % (cls.__module__, cls.__name__) # reply = (Message.ERR.value, cls_name, e.args) # try: # channel.send((msgid, reply)) # except IOError: # self.communication_error = sys.exc_info() # # return _call_back # future = self.thread_pool.submit(self._process_cmd, msgid, *msg) # future.add_done_callback(self._create_done_callback(msgid)) proc = multiprocessing.Process(target=process_cmd, args=(msgid, self.mp_queue, *msg)) proc.start()"," self.thread_pool = futures.ThreadPoolExecutor( context.conf.thread_pool_size) def _process_cmd(self, msgid, cmd, *args): """"""Executes the requested command in an execution thread. This executes a call within a thread executor and returns the results of the execution. :param msgid: The message identifier. :param cmd: The `Message` type indicating the command type. :param args: The function, args, and kwargs if a Message.CALL type. :return: A tuple of the return status, optional call output, and optional error information. """""" if cmd == Message.PING: return (Message.PONG.value,) try: if cmd != Message.CALL: raise ProtocolError(_('Unknown privsep cmd: %s') % cmd) # Extract the callable and arguments name, f_args, f_kwargs = args func = importutils.import_class(name) if not self.context.is_entrypoint(func): msg = _('Invalid privsep function: %s not exported') % name raise NameError(msg) ret = func(*f_args, **f_kwargs) return (Message.RET.value, ret) except Exception as e: LOG.debug( 'privsep: Exception during request[%(msgid)s]: ' '%(err)s', {'msgid': msgid, 'err': e}, exc_info=True) cls = e.__class__ cls_name = '%s.%s' % (cls.__module__, cls.__name__) return (Message.ERR.value, cls_name, e.args) def _create_done_callback(self, msgid): """"""Creates a future callback to receive command execution results. :param msgid: The message identifier. :return: A future reply callback. """""" channel = self.channel def _call_back(result): """"""Future execution callback. :param result: The `future` execution and its results. """""" try: reply = result.result() LOG.debug('privsep: reply[%(msgid)s]: %(reply)s', {'msgid': msgid, 'reply': reply}) channel.send((msgid, reply)) except IOError: self.communication_error = sys.exc_info() except Exception as e: LOG.debug( 'privsep: Exception during request[%(msgid)s]: ' '%(err)s', {'msgid': msgid, 'err': e}, exc_info=True) cls = e.__class__ cls_name = '%s.%s' % (cls.__module__, cls.__name__) reply = (Message.ERR.value, cls_name, e.args) try: channel.send((msgid, reply)) except IOError: self.communication_error = sys.exc_info() return _call_back future = self.thread_pool.submit(self._process_cmd, msgid, *msg) future.add_done_callback(self._create_done_callback(msgid))",118,73
openstack%2Fnova~stable%2Fxena~I1719f8eda04e8d15a3b01f0612977164c4e55e85,openstack/nova,stable/xena,I1719f8eda04e8d15a3b01f0612977164c4e55e85,Gracefully ERROR in _init_instance if vnic_type changed,MERGED,2022-09-26 16:53:29.000000000,2023-01-25 18:07:22.000000000,2023-01-25 18:05:28.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 16:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06efd484c7818aa6d67cb2579d474cd0f04e3c2b', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n(cherry picked from commit 1ef69cda8674a971834b729179635feb94978385)\n'}, {'number': 2, 'created': '2022-10-17 16:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99b1af563d686ca33e51b2a1c3f48403b05d3fd6', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n(cherry picked from commit 591586df221dcc87ec0b2018a6ad6286dc3398a8)\n'}, {'number': 3, 'created': '2023-01-09 17:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4464141d393a1f3ffd25fec6b5d907ce0320e872', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n(cherry picked from commit 1cdeb44f798fce2ce014a3d7de2310d82a4fd34f)\n'}, {'number': 4, 'created': '2023-01-11 11:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af7221cc0dedb89cd2ab0c87c558178db33bfbc7', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n(cherry picked from commit 1cdeb44f798fce2ce014a3d7de2310d82a4fd34f)\n'}, {'number': 5, 'created': '2023-01-25 14:43:23.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/network/test_neutron.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'releasenotes/notes/bug-1981813-vnic-type-change-9f3e16fae885b57f.yaml', 'nova/network/neutron.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1a98a1a650d065a8ab3e1c474f3b9fd537dc2206', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n(cherry picked from commit a28c82719545d5c8ee7f3ff1361b3a796e05095a)\n'}]",3,859315,1a98a1a650d065a8ab3e1c474f3b9fd537dc2206,29,3,5,9708,,,0,"Gracefully ERROR in _init_instance if vnic_type changed

If the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and
then the compute service is restarted then during _init_instance nova
tries to plug the vif of the changed port. However as it now has macvtap
vnic_type nova tries to look up the netdev of the parent VF. Still that
VF is consumed by the instance so there is no such netdev on the host
OS. This error killed the compute service at startup due to unhandled
exception. This patch adds the exception handler, logs an ERROR and
continue initializing other instances on the host.

Also this patch adds a detailed ERROR log when nova detects that the
vnic_type changed during _heal_instance_info_cache periodic.

Closes-Bug: #1981813
Change-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85
(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)
(cherry picked from commit a28c82719545d5c8ee7f3ff1361b3a796e05095a)
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/859315/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/network/test_neutron.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/network/neutron.py', 'releasenotes/notes/bug-1981813-vnic-type-change-9f3e16fae885b57f.yaml', 'nova/compute/manager.py']",6,06efd484c7818aa6d67cb2579d474cd0f04e3c2b,bug/1981813," except exception.PciDeviceNotFoundById: # This is bug 1981813 where the bound port vnic_type has changed # from direct to macvtap. Nova does not support that and it # already printed an ERROR when the change is detected during # _heal_instance_info_cache. Now we print an ERROR again and skip # plugging the vifs but let the service startup continue to init # the other instances LOG.exception( 'Virtual interface plugging failed for instance. Probably the ' 'vnic_type of the bound port has been changed. Nova does not ' 'support such change.', instance=instance ) return",,250,5
openstack%2Fneutron~master~I0405a1157b785e1b628f3112a9707146cf9020f5,openstack/neutron,master,I0405a1157b785e1b628f3112a9707146cf9020f5,Use dhcpcd client in the tempest slow jobs,MERGED,2023-01-20 11:38:15.000000000,2023-01-25 18:06:34.000000000,2023-01-25 18:03:51.000000000,"[{'_account_id': 5948}, {'_account_id': 7730}, {'_account_id': 8313}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 11:38:15.000000000', 'files': ['zuul.d/tempest-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ec438577bdcf357835365f2dd0a1e250ccc63da4', 'message': 'Use dhcpcd client in the tempest slow jobs\n\nCirros switched from udhcpc to dhcpcd in version 0.6.0.\nSupport for that new client is added in the Tempest in the patch [1]\nand now we can use it in our slow jobs to make it green again.\n\n[1] https://review.opendev.org/c/openstack/tempest/+/871270\n\nDepends-On: https://review.opendev.org/c/openstack/tempest/+/871271\n\nCloses-bug: #2003063\nChange-Id: I0405a1157b785e1b628f3112a9707146cf9020f5\n'}]",6,871272,ec438577bdcf357835365f2dd0a1e250ccc63da4,18,6,1,11975,,,0,"Use dhcpcd client in the tempest slow jobs

Cirros switched from udhcpc to dhcpcd in version 0.6.0.
Support for that new client is added in the Tempest in the patch [1]
and now we can use it in our slow jobs to make it green again.

[1] https://review.opendev.org/c/openstack/tempest/+/871270

Depends-On: https://review.opendev.org/c/openstack/tempest/+/871271

Closes-bug: #2003063
Change-Id: I0405a1157b785e1b628f3112a9707146cf9020f5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/871272/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/tempest-multinode.yaml'],1,ec438577bdcf357835365f2dd0a1e250ccc63da4,bug/2003063, test-config: $TEMPEST_CONFIG: scenario: dhcp_client: dhcpcd scenario: dhcp_client: dhcpcd,,6,0
openstack%2Fopenstacksdk~master~I7ebb75896002ea8e0eca6617eb407e94050bce65,openstack/openstacksdk,master,I7ebb75896002ea8e0eca6617eb407e94050bce65,image: Add missing image import options,MERGED,2022-11-08 17:13:21.000000000,2023-01-25 18:06:23.000000000,2023-01-25 18:03:56.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-08 17:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fa51b77b143314f2767d25de05553a0c958f94a3', 'message': 'image: Add missing image import options\n\nAdd support for the following options:\n\n- remote_region\n- remote_image_id\n- remote_service_interface\n\nIn addition, we now return the response to the user.\n\nChange-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 2, 'created': '2022-11-16 16:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/33faa6818f1a6cc427ae8a2c9386ab5579ec55be', 'message': 'image: Add missing image import options\n\nAdd support for the following options:\n\n- remote_region\n- remote_image_id\n- remote_service_interface\n\nIn addition, we now return the response to the user.\n\nChange-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 3, 'created': '2022-11-21 16:02:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/82706b7b6d1e933de6ea8bcf7db4d67fc26f5714', 'message': 'image: Add missing image import options\n\nAdd support for the following options:\n\n- remote_region\n- remote_image_id\n- remote_service_interface\n\nIn addition, we now return the response to the user.\n\nChange-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 4, 'created': '2022-12-08 18:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0111029ac3e87291098582e60dc17ffecfc94630', 'message': 'image: Add missing image import options\n\nAdd support for the following options:\n\n- remote_region\n- remote_image_id\n- remote_service_interface\n\nIn addition, we now return the response to the user.\n\nChange-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}, {'number': 5, 'created': '2023-01-13 17:26:50.000000000', 'files': ['openstack/image/v2/image.py', 'openstack/tests/unit/image/v2/test_proxy.py', 'releasenotes/notes/image-proxy-layer-kwarg-only-arguments-94c9b2033d386160.yaml', 'openstack/image/v2/_proxy.py', 'releasenotes/notes/image-import-proxy-params-f19d8b6166104ebe.yaml', 'openstack/tests/unit/image/v2/test_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/433d97c40cb65e0986609b852d76040d50d6e032', 'message': 'image: Add missing image import options\n\nAdd support for the following options:\n\n- remote_region\n- remote_image_id\n- remote_service_interface\n\nIn addition, we now return the response to the user.\n\nChange-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n'}]",13,864029,433d97c40cb65e0986609b852d76040d50d6e032,18,2,5,15334,,,0,"image: Add missing image import options

Add support for the following options:

- remote_region
- remote_image_id
- remote_service_interface

In addition, we now return the response to the user.

Change-Id: I7ebb75896002ea8e0eca6617eb407e94050bce65
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/29/864029/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v2/image.py', 'openstack/image/v2/_proxy.py']",2,fa51b77b143314f2767d25de05553a0c958f94a3,glance-gaps," self, image, method='glance-direct', *, uri=None, remote_region=None, remote_image_id=None, remote_service_interface=None, :param remote_region: The remote glance region to download the image from when using glance-direct. :param remote_image_id: The ID of the image of to import from the remote glance when using glance-direct. :param remote_service_interface: The remote glance service interface to use when uding glance-download ""all_stores is mutually exclusive with "" ""store and stores"" ) ""store and stores are mutually exclusive"" ) ""Both container_format and disk_format are required for "" ""importing an image"" ) return image.import_image( self, method=method, uri=uri, remote_region=remote_region, remote_image_id=remote_image_id, remote_service_interface=remote_service_interface,"," self, image, method='glance-direct', uri=None, ""all_stores is mutually exclusive with"" "" store and stores"") ""store and stores are mutually exclusive"") ""Both container_format and disk_format are required for"" "" importing an image"") image.import_image( self, method=method, uri=uri,",72,26
openstack%2Fpython-openstackclient~master~Ie3107ba2155f9008e6065171298f85978957a172,openstack/python-openstackclient,master,Ie3107ba2155f9008e6065171298f85978957a172,image: Add support for additional image import methods,MERGED,2022-11-30 17:15:46.000000000,2023-01-25 18:06:18.000000000,2023-01-25 18:04:00.000000000,"[{'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2022-11-30 17:15:46.000000000', 'files': ['openstackclient/tests/unit/image/v2/test_image.py', 'openstackclient/image/v2/image.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6dea276e5a425cd7fa3fd839e5bb03027b7a9347', 'message': 'image: Add support for additional image import methods\n\nThese are now supported in openstacksdk so we can use them.\n\nChange-Id: Ie3107ba2155f9008e6065171298f85978957a172\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nDepends-on: https://review.opendev.org/c/openstack/openstacksdk/+/864029\n'}]",0,866191,6dea276e5a425cd7fa3fd839e5bb03027b7a9347,7,2,1,15334,,,0,"image: Add support for additional image import methods

These are now supported in openstacksdk so we can use them.

Change-Id: Ie3107ba2155f9008e6065171298f85978957a172
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Depends-on: https://review.opendev.org/c/openstack/openstacksdk/+/864029
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/91/866191/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/image/v2/test_image.py', 'openstackclient/image/v2/image.py']",2,6dea276e5a425cd7fa3fd839e5bb03027b7a9347,glance-gaps," uri=parsed_args.uri, remote_region=parsed_args.remote_region, remote_image=parsed_args.remote_image, remote_service_interface=parsed_args.remote_service_interface,"," # uri=parsed_args.uri, # remote_region=parsed_args.remote_region, # remote_image=parsed_args.remote_image, # remote_service_interface=parsed_args.remote_service_interface,",20,8
openstack%2Ftempest~master~I05d2118125195a387163ad1f0177fd9dfc916238,openstack/tempest,master,I05d2118125195a387163ad1f0177fd9dfc916238,Restore IP addresses configuration after spoofing MAC address,MERGED,2023-01-20 11:30:42.000000000,2023-01-25 18:06:04.000000000,2023-01-25 18:03:47.000000000,"[{'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 13861}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2023-01-20 11:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fc9fa8a4a20e2d5f1636053a8ff8b90b2221fd26', 'message': 'Restore IP addresses configuration after spoofing MAC address\n\nIn the test_port_security_macspoofing_port test, NIC on one of the vms\nis set to DOWN, MAC of this NIC is changed to the spoofed one and NIC is\nthen bring back to UP.\nFor some reason it works fine in Cirros 0.5.x but not in 0.6.0 and newer\nas after bringinig interface back to be UP there is also need to restore\nconfigured previously IP addresses.\nThis patch adds check of IPs configured on that NIC before it is switch\nto DOWN and later restores the same IPs configuration when NIC is UP\nagain.\n\nRelated-Bug: #2003063\nChange-Id: I05d2118125195a387163ad1f0177fd9dfc916238\n'}, {'number': 2, 'created': '2023-01-20 13:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/37ff503bb6b305f708ba6bc338ff5453557f7b37', 'message': 'Restore IP addresses configuration after spoofing MAC address\n\nIn the test_port_security_macspoofing_port test, NIC on one of the vms\nis set to DOWN, MAC of this NIC is changed to the spoofed one and NIC is\nthen bring back to UP.\nFor some reason it works fine in Cirros 0.5.x but not in 0.6.0 and newer\nas after bringinig interface back to be UP there is also need to restore\nconfigured previously IP addresses.\nThis patch adds check of IPs configured on that NIC before it is switch\nto DOWN and later restores the same IPs configuration when NIC is UP\nagain.\n\nRelated-Bug: #2003063\nChange-Id: I05d2118125195a387163ad1f0177fd9dfc916238\n'}, {'number': 3, 'created': '2023-01-23 11:39:56.000000000', 'files': ['tempest/common/utils/linux/remote_client.py', 'tempest/scenario/test_network_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e4a43ee3356b6d726e10fefa4181d382007b02c', 'message': 'Restore IP addresses configuration after spoofing MAC address\n\nIn the test_port_security_macspoofing_port test, NIC on one of the vms\nis set to DOWN, MAC of this NIC is changed to the spoofed one and NIC is\nthen bring back to UP.\nFor some reason it works fine in Cirros 0.5.x but not in 0.6.0 and newer\nas after bringinig interface back to be UP there is also need to restore\nconfigured previously IP addresses.\nThis patch adds check of IPs configured on that NIC before it is switch\nto DOWN and later restores the same IPs configuration when NIC is UP\nagain.\n\nRelated-Bug: #2003063\nChange-Id: I05d2118125195a387163ad1f0177fd9dfc916238\n'}]",8,871271,4e4a43ee3356b6d726e10fefa4181d382007b02c,28,6,3,11975,,,0,"Restore IP addresses configuration after spoofing MAC address

In the test_port_security_macspoofing_port test, NIC on one of the vms
is set to DOWN, MAC of this NIC is changed to the spoofed one and NIC is
then bring back to UP.
For some reason it works fine in Cirros 0.5.x but not in 0.6.0 and newer
as after bringinig interface back to be UP there is also need to restore
configured previously IP addresses.
This patch adds check of IPs configured on that NIC before it is switch
to DOWN and later restores the same IPs configuration when NIC is UP
again.

Related-Bug: #2003063
Change-Id: I05d2118125195a387163ad1f0177fd9dfc916238
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/871271/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/utils/linux/remote_client.py', 'tempest/scenario/test_network_basic_ops.py']",2,fc9fa8a4a20e2d5f1636053a8ff8b90b2221fd26,bug/2003063," spoof_ip_addresses = ssh_client.get_nic_ip_addresses(spoof_nic) ""sudo ip link set {nic} up;"").format(nic=spoof_nic, mac=spoof_mac) for ip_address in spoof_ip_addresses: cmd += ( ""sudo ip addr add {ip_address} dev {nic};"" ).format(ip_address=ip_address, nic=spoof_nic) "," ""sudo ip link set {nic} up"").format(nic=spoof_nic, mac=spoof_mac)",17,2
openstack%2Fironic~bugfix%2F20.2~Ice764866a08647031d16570860ec384204269501,openstack/ironic,bugfix/20.2,Ice764866a08647031d16570860ec384204269501,Prevent pxe retry when agent token exists,MERGED,2022-12-19 20:02:02.000000000,2023-01-25 18:01:29.000000000,2023-01-25 18:00:11.000000000,"[{'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-19 20:02:02.000000000', 'files': ['ironic/drivers/modules/pxe_base.py', 'ironic/tests/unit/drivers/modules/test_pxe.py', 'releasenotes/notes/prevent-pxe-retry-when-token-exists-a4f38f7da56c1397.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0ebc995e5f0c19dcb595ba3cdd282347c872def9', 'message': ""Prevent pxe retry when agent token exists\n\nA race condition can be observed in CI under heavy load where the\nconductor triggers are boot of the agent before it is fully online\nbased upon state, but not considering the existence of an agent\ntoken. As a result, agent is never able to check in with Ironic\nand the overall operation fails.\n\nWe now consider agent token's existence before retrying PXE as\nit is the very earliest indicator of a starting agent.\n\nChange-Id: Ice764866a08647031d16570860ec384204269501\nStory: 2010107\nTask: 45674\n(cherry picked from commit d75424b5e5685a9cf04b30a5b0555efd1313e9c3)\n""}]",7,868026,0ebc995e5f0c19dcb595ba3cdd282347c872def9,18,2,1,6618,,,0,"Prevent pxe retry when agent token exists

A race condition can be observed in CI under heavy load where the
conductor triggers are boot of the agent before it is fully online
based upon state, but not considering the existence of an agent
token. As a result, agent is never able to check in with Ironic
and the overall operation fails.

We now consider agent token's existence before retrying PXE as
it is the very earliest indicator of a starting agent.

Change-Id: Ice764866a08647031d16570860ec384204269501
Story: 2010107
Task: 45674
(cherry picked from commit d75424b5e5685a9cf04b30a5b0555efd1313e9c3)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/26/868026/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe_base.py', 'ironic/tests/unit/drivers/modules/test_pxe.py', 'releasenotes/notes/prevent-pxe-retry-when-token-exists-a4f38f7da56c1397.yaml']",3,0ebc995e5f0c19dcb595ba3cdd282347c872def9,,"--- fixes: - | Fixes a race condition in PXE initialization where logic to retry what we suspect as potentially failed PXE boot operations was not consulting if an ``agent token`` had been established, which is the very first step in agent initialization. ",,25,0
openstack%2Fnova~stable%2Ftrain~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/train,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,NEW,2023-01-10 10:47:12.000000000,2023-01-25 17:51:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-10 10:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/883d5799d497613d9336036ba563526f62e4c4e5', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/train only changes:\n* removed type annotation to support py27\n* _create_server not exists here so used a different way to create the\n  server\n* needed to define physnet in the whitelist to allow booting with a\n  neutron port\n* manually created the port in the neutron fixture as create_port does\n  not work here\n* extended the port with vif_type and vif_details to allow booting with\n  the port\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n(cherry picked from commit d25b2a94e5cf84550dc05c377c12a1fe88e2a74f)\n(cherry picked from commit 4663dd7ded5610630c39a8678e57d96430ae0842)\n(cherry picked from commit c5cdccb32378163a28caea7474be02c48e830284)\n(cherry picked from commit a4bb1cad95e34db573e343fc64c87356d97696dc)\n'}, {'number': 2, 'created': '2023-01-25 16:59:20.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/95c7df9df1543e366d221796a08e3b7ff0c0867a', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/train only changes:\n* removed type annotation to support py27\n* _create_server not exists here so used a different way to create the\n  server\n* needed to define physnet in the whitelist to allow booting with a\n  neutron port\n* manually created the port in the neutron fixture as create_port does\n  not work here\n* extended the port with vif_type and vif_details to allow booting with\n  the port\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)\n(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)\n(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)\n(cherry picked from commit 231881b214e36f256bfb95d806557e6a0852f5e3)\n(cherry picked from commit fd4870b8dcfbc35117b967b703aac40ddbba3b35)\n'}]",0,869673,95c7df9df1543e366d221796a08e3b7ff0c0867a,4,1,2,9708,,,0,"Reproduce bug 1981813 in func env

There stable/train only changes:
* removed type annotation to support py27
* _create_server not exists here so used a different way to create the
  server
* needed to define physnet in the whitelist to allow booting with a
  neutron port
* manually created the port in the neutron fixture as create_port does
  not work here
* extended the port with vif_type and vif_details to allow booting with
  the port

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)
(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)
(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)
(cherry picked from commit 231881b214e36f256bfb95d806557e6a0852f5e3)
(cherry picked from commit fd4870b8dcfbc35117b967b703aac40ddbba3b35)
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/869673/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py']",3,883d5799d497613d9336036ba563526f62e4c4e5,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",105,3
openstack%2Fopenstack-ansible-plugins~master~I9444ef832136783bde1eff5425e4cd369f905a5c,openstack/openstack-ansible-plugins,master,I9444ef832136783bde1eff5425e4cd369f905a5c,Use cryptography backend for openssh_keypair,MERGED,2023-01-18 19:27:34.000000000,2023-01-25 17:42:04.000000000,2023-01-25 17:41:04.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-18 19:27:34.000000000', 'files': ['roles/ssh_keypairs/tasks/standalone/create_keypair.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/1dbc2985d39fae7c73c741a95a486d9014aa036b', 'message': 'Use cryptography backend for openssh_keypair\n\nWith default ""auto"" backend, opensshbin is first pick, which fails\nto read a key in case of insecure permissions. This makes task fail\nin case private key in topic has mode different from 0600, even if\ndifferent mode specified for the module itself [1].\n\nAlong with switching backend we also adding mode key to be supported\n\n[1] https://github.com/ansible-collections/community.crypto/issues/564\nChange-Id: I9444ef832136783bde1eff5425e4cd369f905a5c\n'}]",0,870997,1dbc2985d39fae7c73c741a95a486d9014aa036b,8,3,1,28619,,,0,"Use cryptography backend for openssh_keypair

With default ""auto"" backend, opensshbin is first pick, which fails
to read a key in case of insecure permissions. This makes task fail
in case private key in topic has mode different from 0600, even if
different mode specified for the module itself [1].

Along with switching backend we also adding mode key to be supported

[1] https://github.com/ansible-collections/community.crypto/issues/564
Change-Id: I9444ef832136783bde1eff5425e4cd369f905a5c
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/97/870997/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ssh_keypairs/tasks/standalone/create_keypair.yml'],1,1dbc2985d39fae7c73c741a95a486d9014aa036b,," mode: ""{{ kp.mode | default(omit) }}"" backend: cryptography",,2,0
openstack%2Fnova~stable%2Fxena~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/xena,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,MERGED,2022-09-26 16:53:29.000000000,2023-01-25 17:39:43.000000000,2023-01-25 17:36:38.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 16:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1a8b63d40bf80934c38366c6481e7045302f4e3', 'message': 'Reproduce bug 1981813 in func env\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit a5287d75bf895b13625583bd00c30a44a435fcf6)\n'}, {'number': 2, 'created': '2022-10-17 16:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/536c795799ea550113de9fb08a3a7be2fbb29f42', 'message': 'Reproduce bug 1981813 in func env\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 8ec3abe58ef3b21c37765b9ce4314af625967df5)\n'}, {'number': 3, 'created': '2023-01-09 17:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d25b2a94e5cf84550dc05c377c12a1fe88e2a74f', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n'}, {'number': 4, 'created': '2023-01-11 11:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d1124840825ed851def8269e2e4d8ee649413f48', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n'}, {'number': 5, 'created': '2023-01-25 14:43:23.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures/libvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c87681135cfb3ce61d2a0392928c1dbc1fe5fde', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)\n'}]",3,859314,0c87681135cfb3ce61d2a0392928c1dbc1fe5fde,27,3,5,9708,,,0,"Reproduce bug 1981813 in func env

There stable/yoga only change in test_pci_sriov_servers.py due to
unittest.mock switch[1] only happened in zed.

[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/859314/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures/libvirt.py']",2,b1a8b63d40bf80934c38366c6481e7045302f4e3,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",78,3
openstack%2Fneutron~stable%2Fxena~I37ec0ba04bafb3b7baec6003155b7d9c43092667,openstack/neutron,stable/xena,I37ec0ba04bafb3b7baec6003155b7d9c43092667,Increase fullstack job's timeout,MERGED,2023-01-25 12:26:22.000000000,2023-01-25 17:39:43.000000000,2023-01-25 17:36:17.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 12:26:22.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1353ef8a7a48c7af726c31e948de42cfda80ae50', 'message': ""Increase fullstack job's timeout\n\nIt seems that recently we are often timing out the fullstack job when\nit's executed on some busy node. To avoid that, lets give 20 more\nminutes to the timeout of the fullstack jobs.\n\nChange-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667\n(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)\n""}]",0,871566,1353ef8a7a48c7af726c31e948de42cfda80ae50,8,3,1,13861,,,0,"Increase fullstack job's timeout

It seems that recently we are often timing out the fullstack job when
it's executed on some busy node. To avoid that, lets give 20 more
minutes to the timeout of the fullstack jobs.

Change-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667
(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/871566/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,1353ef8a7a48c7af726c31e948de42cfda80ae50,increase-fullstack-timeout-stable/zed-stable/yoga-stable/xena, timeout: 9000,,1,0
openstack%2Fdevstack~master~Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc,openstack/devstack,master,Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc,'sudo pkill -f' should not match the sudo process,MERGED,2022-12-12 12:26:31.000000000,2023-01-25 17:39:41.000000000,2023-01-25 17:36:27.000000000,"[{'_account_id': 8313}, {'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22873}]","[{'number': 1, 'created': '2022-12-12 12:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9016291a6f37a3f3c8fbf7ec534c5d774dcb9d3e', 'message': ""'sudo pkill -f' should not match the sudo process\n\npkill already takes care that it does not kill itself, however the\nsame problem may happen with 'sudo pkill -f' killing sudo. Use one\nof the usual regex tricks to avoid that.\n\nChange-Id: Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc\nCloses-Bug: #1999395\n""}, {'number': 2, 'created': '2022-12-21 12:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/06fef769449228393f4867587b7bef0501ecf1a9', 'message': ""'sudo pkill -f' should not match the sudo process\n\npkill already takes care that it does not kill itself, however the\nsame problem may happen with 'sudo pkill -f' killing sudo. Use one\nof the usual regex tricks to avoid that.\n\nChange-Id: Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc\nCloses-Bug: #1999395\n""}, {'number': 3, 'created': '2023-01-25 10:38:49.000000000', 'files': ['lib/neutron', 'lib/neutron_plugins/ovn_agent'], 'web_link': 'https://opendev.org/openstack/devstack/commit/71c3c40c269a50303247855319d1d3a5d30f6773', 'message': ""'sudo pkill -f' should not match the sudo process\n\npkill already takes care that it does not kill itself, however the\nsame problem may happen with 'sudo pkill -f' killing sudo. Use one\nof the usual regex tricks to avoid that.\n\nChange-Id: Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc\nCloses-Bug: #1999395\n""}]",22,867215,71c3c40c269a50303247855319d1d3a5d30f6773,42,4,3,15554,,,0,"'sudo pkill -f' should not match the sudo process

pkill already takes care that it does not kill itself, however the
same problem may happen with 'sudo pkill -f' killing sudo. Use one
of the usual regex tricks to avoid that.

Change-Id: Ic6a94f516cbc509a2d77699494aa7bcaecf96ebc
Closes-Bug: #1999395
",git fetch https://review.opendev.org/openstack/devstack refs/changes/15/867215/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/ovn_agent', 'lib/neutron-legacy']",2,9016291a6f37a3f3c8fbf7ec534c5d774dcb9d3e,bug/1999395," sudo pkill -9 -f ""$NEUTRON_ROOTWRAP-[d]aemon"" || :", sudo pkill -9 -f $NEUTRON_ROOTWRAP-daemon || :,2,2
openstack%2Fneutron~stable%2Fyoga~I37ec0ba04bafb3b7baec6003155b7d9c43092667,openstack/neutron,stable/yoga,I37ec0ba04bafb3b7baec6003155b7d9c43092667,Increase fullstack job's timeout,MERGED,2023-01-25 12:26:08.000000000,2023-01-25 17:39:38.000000000,2023-01-25 17:36:08.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 12:26:08.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b0081ea6db6df2bc1abe32cb381377889aae658b', 'message': ""Increase fullstack job's timeout\n\nIt seems that recently we are often timing out the fullstack job when\nit's executed on some busy node. To avoid that, lets give 20 more\nminutes to the timeout of the fullstack jobs.\n\nChange-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667\n(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)\n""}]",0,871565,b0081ea6db6df2bc1abe32cb381377889aae658b,8,3,1,13861,,,0,"Increase fullstack job's timeout

It seems that recently we are often timing out the fullstack job when
it's executed on some busy node. To avoid that, lets give 20 more
minutes to the timeout of the fullstack jobs.

Change-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667
(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/65/871565/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,b0081ea6db6df2bc1abe32cb381377889aae658b,increase-fullstack-timeout-stable/zed-stable/yoga, timeout: 9000,,1,0
openstack%2Fansible-role-systemd_service~master~Ib456b4dc2d631bf81633035820444f13ec0f06cb,openstack/ansible-role-systemd_service,master,Ib456b4dc2d631bf81633035820444f13ec0f06cb,Ensure daemon is reloaded on socket change,MERGED,2023-01-23 15:29:55.000000000,2023-01-25 17:32:48.000000000,2023-01-25 17:31:49.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-23 15:29:55.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2', 'message': ""Ensure daemon is reloaded on socket change\n\nAt the moment our verification if socket has been changed\nis not valid, since we're checking if string 'true' is presnet in the\nlist, while list consist of only boolean variables. So we replace\nmap filter with selectattr as it can apply truthy test to the elements\nwhile selecting them and checking list length.\n\nChange-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb\nRelated-Bug: #2003631\n""}]",0,871487,6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2,9,4,1,28619,,,0,"Ensure daemon is reloaded on socket change

At the moment our verification if socket has been changed
is not valid, since we're checking if string 'true' is presnet in the
list, while list consist of only boolean variables. So we replace
map filter with selectattr as it can apply truthy test to the elements
while selecting them and checking list length.

Change-Id: Ib456b4dc2d631bf81633035820444f13ec0f06cb
Related-Bug: #2003631
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/87/871487/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,6a40ec0b85b96e529eb0e3e1e1a1f62cf34d80d2,," - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or (systemd_socket.results | selectattr('changed', 'true') | length > 0)", - (systemd_services_result is changed) or (systemd_timer_result is changed) or (systemd_override_result is changed ) or ('true' in systemd_socket.results | map(attribute='changed') | list ),1,1
openstack%2Fopenstack-ansible-rabbitmq_server~master~If8c83682093cb08e8a092550c44010134cd210d3,openstack/openstack-ansible-rabbitmq_server,master,If8c83682093cb08e8a092550c44010134cd210d3,Bump rabbitmq to 3.11 and erlang to 25.2,MERGED,2023-01-20 16:31:13.000000000,2023-01-25 17:28:42.000000000,2023-01-25 17:27:38.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-20 16:31:13.000000000', 'files': ['vars/redhat.yml', 'vars/debian.yml', 'releasenotes/notes/rabbit_3_11-f3ec4e2c38ee9a66.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/5281c0e2647a5763642999709e7a8a9fb0127a5f', 'message': 'Bump rabbitmq to 3.11 and erlang to 25.2\n\nChange-Id: If8c83682093cb08e8a092550c44010134cd210d3\n'}]",1,871303,5281c0e2647a5763642999709e7a8a9fb0127a5f,10,3,1,28619,,,0,"Bump rabbitmq to 3.11 and erlang to 25.2

Change-Id: If8c83682093cb08e8a092550c44010134cd210d3
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/03/871303/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat.yml', 'vars/debian.yml', 'releasenotes/notes/rabbit_3_11-f3ec4e2c38ee9a66.yaml']",3,5281c0e2647a5763642999709e7a8a9fb0127a5f,,"--- other: - | Version of RabbitMQ is bumped to 3.11.7, Erlang version is bumped to 25.2. ",,10,4
openstack%2Ftripleo-heat-templates~stable%2Ftrain~Idb16f8664d937d8d11108f2b29b22f8b7ced521c,openstack/tripleo-heat-templates,stable/train,Idb16f8664d937d8d11108f2b29b22f8b7ced521c,Expose /var/lib/glance to cron container,MERGED,2023-01-24 10:02:39.000000000,2023-01-25 17:28:07.000000000,2023-01-25 17:28:07.000000000,"[{'_account_id': 6796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 10:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c41c23d721416009a8148992ffcef7eed4113adc', 'message': 'Expose /var/lib/glance to cron container\n\nThe glance_api_cron container executes the cache clean/prune jobs, thus\nit requires access to the /var/lib/glance directory which contains\nthe cache data.\n\nBecause the directory is now shared by the two containers (glance_api\nand glance_api_cron), the mount flag is updated from slave to shared\nso that any change is propagated between these two containers.\n\nCloses-Bug: #1997625\nChange-Id: Idb16f8664d937d8d11108f2b29b22f8b7ced521c\n(cherry picked from commit b532a042152805e32c2f410bbfe16f5e8e222581)\n(cherry picked from commit 4ddf16a2cc84281d7a2a08bddae5a78972143f8c)\n(cherry picked from commit 2570e4c9e10e7ba10f57a5e5ffa37c5b9cc146de)\n'}, {'number': 2, 'created': '2023-01-24 10:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5da98e50d47e6501b823a28610cd50a97264f392', 'message': 'Expose /var/lib/glance to cron container\n\nThe glance_api_cron container executes the cache clean/prune jobs, thus\nit requires access to the /var/lib/glance directory which contains\nthe cache data.\n\nBecause the directory is now shared by the two containers (glance_api\nand glance_api_cron), the mount flag is updated from slave to shared\nso that any change is propagated between these two containers.\n\nCloses-Bug: #1997625\nChange-Id: Idb16f8664d937d8d11108f2b29b22f8b7ced521c\n(cherry picked from commit b532a042152805e32c2f410bbfe16f5e8e222581)\n(cherry picked from commit 4ddf16a2cc84281d7a2a08bddae5a78972143f8c)\n(cherry picked from commit 2570e4c9e10e7ba10f57a5e5ffa37c5b9cc146de)\n'}, {'number': 3, 'created': '2023-01-24 10:51:19.000000000', 'files': ['deployment/glance/glance-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aa102c181dde24342c407207f151cb7a62844278', 'message': 'Expose /var/lib/glance to cron container\n\nThe glance_api_cron container executes the cache clean/prune jobs, thus\nit requires access to the /var/lib/glance directory which contains\nthe cache data.\n\nBecause the directory is now shared by the two containers (glance_api\nand glance_api_cron), the mount flag is updated from slave to shared\nso that any change is propagated between these two containers.\n\nCloses-Bug: #1997625\nChange-Id: Idb16f8664d937d8d11108f2b29b22f8b7ced521c\n(cherry picked from commit b532a042152805e32c2f410bbfe16f5e8e222581)\n(cherry picked from commit 4ddf16a2cc84281d7a2a08bddae5a78972143f8c)\n(cherry picked from commit 2570e4c9e10e7ba10f57a5e5ffa37c5b9cc146de)\n'}]",0,871590,aa102c181dde24342c407207f151cb7a62844278,9,2,3,33765,,,0,"Expose /var/lib/glance to cron container

The glance_api_cron container executes the cache clean/prune jobs, thus
it requires access to the /var/lib/glance directory which contains
the cache data.

Because the directory is now shared by the two containers (glance_api
and glance_api_cron), the mount flag is updated from slave to shared
so that any change is propagated between these two containers.

Closes-Bug: #1997625
Change-Id: Idb16f8664d937d8d11108f2b29b22f8b7ced521c
(cherry picked from commit b532a042152805e32c2f410bbfe16f5e8e222581)
(cherry picked from commit 4ddf16a2cc84281d7a2a08bddae5a78972143f8c)
(cherry picked from commit 2570e4c9e10e7ba10f57a5e5ffa37c5b9cc146de)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/871590/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/glance/glance-api-container-puppet.yaml'],1,c41c23d721416009a8148992ffcef7eed4113adc,, - /var/lib/glance:/var/lib/glance:shared - /var/lib/glance:/var/lib/glance:shared environment: KOLLA_CONFIG_STRATEGY: COPY_ALWAYS, - /var/lib/glance:/var/lib/glance:slave environment: KOLLA_CONFIG_STRATEGY: COPY_ALWAYS,4,3
openstack%2Fnova~stable%2Fussuri~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/ussuri,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,NEW,2023-01-09 17:48:42.000000000,2023-01-25 17:27:45.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-09 17:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4bb1cad95e34db573e343fc64c87356d97696dc', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/ussuri only change in test_pci_sriov_servers.py due to\nstart_compute() is not exist in ussuri yet\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n(cherry picked from commit d25b2a94e5cf84550dc05c377c12a1fe88e2a74f)\n(cherry picked from commit 4663dd7ded5610630c39a8678e57d96430ae0842)\n(cherry picked from commit c5cdccb32378163a28caea7474be02c48e830284)\n'}, {'number': 2, 'created': '2023-01-25 16:42:31.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fd4870b8dcfbc35117b967b703aac40ddbba3b35', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/ussuri only change in test_pci_sriov_servers.py due to\nstart_compute() is not exist in ussuri yet\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)\n(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)\n(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)\n(cherry picked from commit 231881b214e36f256bfb95d806557e6a0852f5e3)\n'}]",0,869585,fd4870b8dcfbc35117b967b703aac40ddbba3b35,4,1,2,9708,,,0,"Reproduce bug 1981813 in func env

There stable/ussuri only change in test_pci_sriov_servers.py due to
start_compute() is not exist in ussuri yet

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)
(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)
(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)
(cherry picked from commit 231881b214e36f256bfb95d806557e6a0852f5e3)
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/869585/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py']",2,a4bb1cad95e34db573e343fc64c87356d97696dc,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",83,3
openstack%2Fansible-role-systemd_service~master~Ifb6fd9461d7b6a65191b918c0863406cf4de6725,openstack/ansible-role-systemd_service,master,Ifb6fd9461d7b6a65191b918c0863406cf4de6725,Restart sockets when they are changed,MERGED,2023-01-23 18:15:17.000000000,2023-01-25 17:27:07.000000000,2023-01-25 17:26:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-23 18:15:17.000000000', 'files': ['tasks/main.yml', 'handlers/socket_restart.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/17f833f27a1f326b494471575f53bbc7438b05f4', 'message': ""Restart sockets when they are changed\n\nAt the moment it's possible only to forcefully restart sockets under\neach run, which is not idempotent and may cause interruptions for\nservice. To avoid that we add a way to restart socket just on config\nchange with same logic applied as for service.\n\nChange-Id: Ifb6fd9461d7b6a65191b918c0863406cf4de6725\n""}]",0,871526,17f833f27a1f326b494471575f53bbc7438b05f4,8,3,1,28619,,,0,"Restart sockets when they are changed

At the moment it's possible only to forcefully restart sockets under
each run, which is not idempotent and may cause interruptions for
service. To avoid that we add a way to restart socket just on config
change with same logic applied as for service.

Change-Id: Ifb6fd9461d7b6a65191b918c0863406cf4de6725
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/26/871526/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'handlers/socket_restart.yml', 'handlers/main.yml']",3,17f833f27a1f326b494471575f53bbc7438b05f4,,"- name: Restart changed sockets include_tasks: handlers/socket_restart.yml listen: systemd socket changed when: - 'socket_results is changed' loop: ""{{ systemd_socket.results }}"" loop_control: loop_var: socket_results tags: - systemd-service ",,40,0
openstack%2Fnova~stable%2Fvictoria~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/victoria,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,NEW,2023-01-09 17:31:45.000000000,2023-01-25 17:22:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-09 17:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5cdccb32378163a28caea7474be02c48e830284', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 76bcc21e0a47221ce8fdfa126172af546f7028cc)\n(cherry picked from commit d25b2a94e5cf84550dc05c377c12a1fe88e2a74f)\n(cherry picked from commit 4663dd7ded5610630c39a8678e57d96430ae0842)\n'}, {'number': 2, 'created': '2023-01-25 16:38:53.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/231881b214e36f256bfb95d806557e6a0852f5e3', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)\n(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)\n(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)\n'}]",0,869583,231881b214e36f256bfb95d806557e6a0852f5e3,4,1,2,9708,,,0,"Reproduce bug 1981813 in func env

There stable/yoga only change in test_pci_sriov_servers.py due to
unittest.mock switch[1] only happened in zed.

[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
(cherry picked from commit 4954f993680c75fd9d3d507f2dcd00300c9b3d44)
(cherry picked from commit 0c87681135cfb3ce61d2a0392928c1dbc1fe5fde)
(cherry picked from commit cb4c2b6c04232901f4c5adae724697fec3aed4e8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/869583/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/unit/virt/libvirt/fakelibvirt.py']",2,c5cdccb32378163a28caea7474be02c48e830284,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",80,3
openstack%2Fansible-role-collect-logs~master~Iba828c602ee2e7250ec1823fa0989e9a5551bcd6,openstack/ansible-role-collect-logs,master,Iba828c602ee2e7250ec1823fa0989e9a5551bcd6,Pin tox < 4.0,NEW,2022-12-08 09:05:14.000000000,2023-01-25 17:09:12.000000000,,"[{'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 32029}, {'_account_id': 34951}]","[{'number': 1, 'created': '2022-12-08 09:05:14.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-collect-logs/commit/a2a6020974d52fcf2afb61968aaae2ed3495e72c', 'message': 'Pin tox < 4.0\n\ntox 4.0 was released but unfortunately it introduced breaking changes,\nwhich affect the tox jobs.\n\nThis makes sure tox is not updated when installing dependencies.\nThe tox package installed by the common ensure-tox role was already\npinned by [1].\n\n[1] https://review.opendev.org/c/zuul/zuul-jobs/+/866928\n\nChange-Id: Iba828c602ee2e7250ec1823fa0989e9a5551bcd6\n'}]",1,866967,a2a6020974d52fcf2afb61968aaae2ed3495e72c,9,4,1,9816,,,0,"Pin tox < 4.0

tox 4.0 was released but unfortunately it introduced breaking changes,
which affect the tox jobs.

This makes sure tox is not updated when installing dependencies.
The tox package installed by the common ensure-tox role was already
pinned by [1].

[1] https://review.opendev.org/c/zuul/zuul-jobs/+/866928

Change-Id: Iba828c602ee2e7250ec1823fa0989e9a5551bcd6
",git fetch https://review.opendev.org/openstack/ansible-role-collect-logs refs/changes/67/866967/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a2a6020974d52fcf2afb61968aaae2ed3495e72c,pin-tox-4, tox<4,,1,0
openstack%2Fneutron~stable%2Fzed~I37ec0ba04bafb3b7baec6003155b7d9c43092667,openstack/neutron,stable/zed,I37ec0ba04bafb3b7baec6003155b7d9c43092667,Increase fullstack job's timeout,MERGED,2023-01-25 12:25:54.000000000,2023-01-25 16:50:39.000000000,2023-01-25 16:48:21.000000000,"[{'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-25 12:25:54.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/544ae186ab105e52cb5fa63f4ee07c4b3810a38c', 'message': ""Increase fullstack job's timeout\n\nIt seems that recently we are often timing out the fullstack job when\nit's executed on some busy node. To avoid that, lets give 20 more\nminutes to the timeout of the fullstack jobs.\n\nChange-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667\n(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)\n""}]",0,871564,544ae186ab105e52cb5fa63f4ee07c4b3810a38c,8,3,1,13861,,,0,"Increase fullstack job's timeout

It seems that recently we are often timing out the fullstack job when
it's executed on some busy node. To avoid that, lets give 20 more
minutes to the timeout of the fullstack jobs.

Change-Id: I37ec0ba04bafb3b7baec6003155b7d9c43092667
(cherry picked from commit 3354b43d5ad7fd8e950b2d875fc3e017bc87b0a7)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/64/871564/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,544ae186ab105e52cb5fa63f4ee07c4b3810a38c,increase-fullstack-timeout-stable/zed, timeout: 9000,,1,0
openstack%2Fgovernance~master~I72ff79f7f925fc3317835b1f97e23afd1c5f77ce,openstack/governance,master,I72ff79f7f925fc3317835b1f97e23afd1c5f77ce,Add Zaqar in inactive project list,ABANDONED,2023-01-13 14:33:15.000000000,2023-01-25 16:37:48.000000000,,"[{'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 14:33:15.000000000', 'files': ['reference/emerging-technology-and-inactive-projects.rst'], 'web_link': 'https://opendev.org/openstack/governance/commit/7cf2d717eed93a7d98f3fa2516bb755481be90f8', 'message': ""Add Zaqar in inactive project list\n\nZaqar has been inactive since a few days after the Zed release, at\nwhich point their CI pipeline configuration's deprecated gate queue\ndeclaration became invalid, and no jobs have been able to run nor\nchanges merge to the openstack/zaqar repository since that time.\nIt's also no longer usable with master branches of other projects,\nresulting in Senlin removing it from their integration testing[*].\n\nWe have now reached (and effectively passed) the point at which the\nrelease managers need to know whether Zaqar will be included in the\n2023.1 coordinated release, and the project is not presently in a\nreleasable state. Unless someone can commit to resolving this\nsituation, it would be better to send a clear signal that the\nproject is not included in the release due to becoming inactive.\n\n[*] https://review.opendev.org/868976\n\nChange-Id: I72ff79f7f925fc3317835b1f97e23afd1c5f77ce\n""}]",4,870098,7cf2d717eed93a7d98f3fa2516bb755481be90f8,7,2,1,5263,,,0,"Add Zaqar in inactive project list

Zaqar has been inactive since a few days after the Zed release, at
which point their CI pipeline configuration's deprecated gate queue
declaration became invalid, and no jobs have been able to run nor
changes merge to the openstack/zaqar repository since that time.
It's also no longer usable with master branches of other projects,
resulting in Senlin removing it from their integration testing[*].

We have now reached (and effectively passed) the point at which the
release managers need to know whether Zaqar will be included in the
2023.1 coordinated release, and the project is not presently in a
releasable state. Unless someone can commit to resolving this
situation, it would be better to send a clear signal that the
project is not included in the release due to becoming inactive.

[*] https://review.opendev.org/868976

Change-Id: I72ff79f7f925fc3317835b1f97e23afd1c5f77ce
",git fetch https://review.opendev.org/openstack/governance refs/changes/98/870098/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/emerging-technology-and-inactive-projects.rst'],1,7cf2d717eed93a7d98f3fa2516bb755481be90f8,,* Zaqar (Added in 2023.1 cycle),,1,0
openstack%2Fcinder~master~I815706f691a7d1e5a0c54eb15222417008ef1f34,openstack/cinder,master,I815706f691a7d1e5a0c54eb15222417008ef1f34,Send the correct location URI to the Glance v2 API,MERGED,2022-06-08 22:55:11.000000000,2023-01-25 16:32:19.000000000,2023-01-25 16:30:29.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-06-08 22:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e38ca99ab1e5485e9c9abfffd8daa577dbdfe800', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nDiscussed with: Rajat Dhasmana <rajatdhasmana@gmail.com>\n\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 2, 'created': '2022-06-08 22:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c699a60c008072b2fe8d6aa1acedbb7153ebecf4', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nDiscussed with: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 3, 'created': '2022-06-08 23:10:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4e2644c652b668f6898736d24ebf55c8cf98e947', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nDiscussed with: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 4, 'created': '2022-06-14 23:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ae3635296a686a12f48e73b7d59f65133a7db4b', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nDiscussed with: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 5, 'created': '2022-06-14 23:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5a0932bac786b3ffe0cc3bfa1578e12e82bdd64c', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nDiscussed with: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 6, 'created': '2022-06-15 09:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c919e3022e14b29bf2ff8dd0863858906107fa3', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 7, 'created': '2022-06-15 13:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/202d66ac9797e9bd124ea6e06a711c59bfc93639', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 8, 'created': '2022-06-22 07:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8f0964a893b98faa6f8fc751a67601c6b58366ed', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 9, 'created': '2022-06-24 07:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a363693058228d83854f84b52371b36298668689', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 10, 'created': '2022-08-01 13:13:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4af3e86c6eefc152f505f6961082644f5ee18e68', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}, {'number': 11, 'created': '2023-01-16 14:56:42.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_image.py', 'releasenotes/notes/bug-1978020-glance-upload-uri-8fbc70c442ac620c.yaml', 'cinder/tests/unit/volume/test_volume_manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/08e80390f3d83f687552d268e6378fdfcddc0d34', 'message': 'Send the correct location URI to the Glance v2 API\n\nWhen uploading a volume to an image, send the new-style\ncinder://<store-id>/<volume-id> URL to the Glance API if\nimage_service:store_id is present in the volume type extra specs.\n\nCloses-Bug: #1978020\nCo-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>\nChange-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34\n'}]",33,845178,08e80390f3d83f687552d268e6378fdfcddc0d34,212,6,11,12988,,,0,"Send the correct location URI to the Glance v2 API

When uploading a volume to an image, send the new-style
cinder://<store-id>/<volume-id> URL to the Glance API if
image_service:store_id is present in the volume type extra specs.

Closes-Bug: #1978020
Co-Authored-By: Rajat Dhasmana <rajatdhasmana@gmail.com>
Change-Id: I815706f691a7d1e5a0c54eb15222417008ef1f34
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/845178/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_image.py', 'cinder/tests/unit/volume/test_volume_manager.py']",3,e38ca99ab1e5485e9c9abfffd8daa577dbdfe800,storpool-driver-fixes," @mock.patch('cinder.message.api.API.create') @mock.patch('cinder.volume.volume_utils.require_driver_initialized') @mock.patch('cinder.volume.manager.VolumeManager._clone_image_volume') @mock.patch('cinder.db.volume_metadata_update') def test_clone_image_no_volume(self, fake_update, fake_clone, fake_msg_create, fake_init): """"""Make sure nothing happens if no volume was created."""""" manager = vol_manager.VolumeManager() fake_driver = mock.MagicMock() fake_driver.create_snapshot.return_value = False manager.driver = fake_driver ctx = mock.MagicMock(spec=[]) volume = mock.MagicMock(spec=[]) image_service = mock.MagicMock(spec=[]) fake_clone.return_value = None image_meta = {'disk_format': 'raw', 'container_format': 'ova'} manager._clone_image_volume_and_add_location(ctx, volume, image_service, image_meta) fake_clone.assert_not_called() fake_update.assert_not_called() image_meta = {'disk_format': 'qcow2', 'container_format': 'bare'} manager._clone_image_volume_and_add_location(ctx, volume, image_service, image_meta) fake_clone.assert_not_called() fake_update.assert_not_called() image_meta = {'disk_format': 'raw', 'container_format': 'bare'} manager._clone_image_volume_and_add_location(ctx, volume, image_service, image_meta) fake_clone.assert_called_once_with(ctx, volume, image_meta) fake_update.assert_not_called() @mock.patch('cinder.message.api.API.create') @mock.patch('cinder.volume.volume_utils.require_driver_initialized') @mock.patch('cinder.volume.manager.VolumeManager._clone_image_volume') @mock.patch('cinder.db.volume_metadata_update') def test_clone_image_no_store_id(self, fake_update, fake_clone, fake_msg_create, fake_init): """"""Send a cinder://<volume-id> URL if no store ID in extra specs."""""" manager = vol_manager.VolumeManager() fake_driver = mock.MagicMock() fake_driver.create_snapshot.return_value = False manager.driver = fake_driver project_id = '37' ctx = mock.MagicMock(spec=['project_id']) ctx.project_id = project_id volume = mock.MagicMock(spec=['volume_type']) volume.volume_type.extra_specs = {'backend': 'unknown'} image_volume_id = '42' image_volume = mock.MagicMock(spec=['id']) image_volume.id = image_volume_id url = 'cinder://%(vol)s' % {'vol': image_volume_id} image_service = mock.MagicMock(spec=['add_location']) image_meta_id = '616' image_meta = { 'id': image_meta_id, 'disk_format': 'raw', 'container_format': 'bare', } image_volume_meta = { 'image_owner': project_id, 'glance_image_id': image_meta_id, } fake_clone.return_value = image_volume manager._clone_image_volume_and_add_location(ctx, volume, image_service, image_meta) fake_clone.assert_called_once_with(ctx, volume, image_meta) fake_update.assert_called_with(ctx, image_volume_id, image_volume_meta, False) image_service.add_location.assert_called_once_with(ctx, image_meta_id, url, {}) @mock.patch('cinder.message.api.API.create') @mock.patch('cinder.volume.volume_utils.require_driver_initialized') @mock.patch('cinder.volume.manager.VolumeManager._clone_image_volume') @mock.patch('cinder.db.volume_metadata_update') def test_clone_image_with_store_id(self, fake_update, fake_clone, fake_msg_create, fake_init): """"""Send a cinder://<store-id>/<volume-id> URL."""""" manager = vol_manager.VolumeManager() fake_driver = mock.MagicMock() fake_driver.create_snapshot.return_value = False manager.driver = fake_driver project_id = '37' ctx = mock.MagicMock(spec=['project_id']) ctx.project_id = project_id store_id = 'muninn' volume = mock.MagicMock(spec=['volume_type']) volume.volume_type.extra_specs = { 'backend': 'unknown', 'image_service:store_id': store_id, } image_volume_id = '42' image_volume = mock.MagicMock(spec=['id']) image_volume.id = image_volume_id url = 'cinder://%(store)s/%(vol)s' % { 'store': store_id, 'vol': image_volume_id, } image_service = mock.MagicMock(spec=['add_location']) image_meta_id = '616' image_meta = { 'id': image_meta_id, 'disk_format': 'raw', 'container_format': 'bare', } image_volume_meta = { 'image_owner': project_id, 'glance_image_id': image_meta_id, } fake_clone.return_value = image_volume manager._clone_image_volume_and_add_location(ctx, volume, image_service, image_meta) fake_clone.assert_called_once_with(ctx, volume, image_meta) fake_update.assert_called_with(ctx, image_volume_id, image_volume_meta, False) image_service.add_location.assert_called_once_with(ctx, image_meta_id, url, {'store': store_id})",,153,2
openstack%2Fneutron~stable%2Fxena~I54c8fd4d065ae537f396408df16832b158ee8998,openstack/neutron,stable/xena,I54c8fd4d065ae537f396408df16832b158ee8998,"Since OVN 20.06, config is stored in ""Chassis.other_config""",MERGED,2023-01-24 15:30:53.000000000,2023-01-25 16:23:54.000000000,2023-01-25 16:22:22.000000000,"[{'_account_id': 11975}, {'_account_id': 13861}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34271}]","[{'number': 1, 'created': '2023-01-24 15:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a007da1e9a68821de71ee274353b008c1fb6d4d6', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n'}, {'number': 2, 'created': '2023-01-24 16:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/321b5c3ffd9f7ff8934e35261ce2ede769c0e1f4', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n'}, {'number': 3, 'created': '2023-01-25 09:39:06.000000000', 'files': ['neutron/tests/functional/services/ovn_l3/test_plugin.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py', 'neutron/tests/functional/base.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/common/ovn/utils.py', 'neutron/tests/unit/fake_resources.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/ovn-chassis-other-config-7db15b9d10bf7f04.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/common/ovn/test_utils.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/agent/test_neutron_agent.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/70e179e9b74282a6b8272c48c78800b33176aaa9', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n'}]",4,871637,70e179e9b74282a6b8272c48c78800b33176aaa9,19,5,3,16688,,,0,"Since OVN 20.06, config is stored in ""Chassis.other_config""

Since OVN 20.06 [1], the OVN configuration is stored in
""Chassis.other_config"".

Since OVN 22.09, the ""Chassis"" configuration stored in
""Chassis.other_config"" will not be replicated to
""Chassis.external_ids"".

The ML2/OVN plugin tries to retrieve the ""Chassis""
configuration from the ""other_config"" field first; if this
field does not exist (in OVN versions before 20.06), the plugin
will use ""external_ids"" field instead. Neutron will be compatible
with the different OVN versions (with and without ""other_config""
field).

[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4
[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae

NOTE: this patch is similar to [1], but in this case neutron keeps
compatibility with the different OVN versions (with and without
""other_config"" field). Since [2], the Neutron CI has a new job that
uses the OVN/OVS packages distributed by the operating system
installed by the CI (in this case, Ubuntu 20.04 and OVN 20.03).

[1]https://review.opendev.org/c/openstack/neutron/+/859642
[2]https://review.opendev.org/c/openstack/neutron/+/860636

Conflicts:
      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py
      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py
      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py
      neutron/tests/unit/fake_resources.py
      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py
      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py

Closes-Bug: #1990229
Change-Id: I54c8fd4d065ae537f396408df16832b158ee8998
(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)
(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/871637/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/services/ovn_l3/test_plugin.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py', 'neutron/tests/functional/base.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/common/ovn/utils.py', 'neutron/tests/unit/fake_resources.py', 'releasenotes/notes/ovn-chassis-other-config-7db15b9d10bf7f04.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/common/ovn/test_utils.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/agent/test_neutron_agent.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl.py']",17,a007da1e9a68821de71ee274353b008c1fb6d4d6,bug/1990229," {'other_config': {'ovn-bridge-mappings': {'other_config': {'ovn-bridge-mappings': {'other_config': {'ovn-bridge-mappings': other_config=chassis['other_config'])) {'other_config': {'ovn-bridge-mappings': 'p1:br-ex,p2:br-ex'}}"," {'external_ids': {'ovn-bridge-mappings': {'external_ids': {'ovn-bridge-mappings': {'external_ids': {'ovn-bridge-mappings': external_ids=chassis['external_ids'])) {'external_ids': {'ovn-bridge-mappings': 'p1:br-ex,p2:br-ex'}}",603,90
openstack%2Fneutron~stable%2Fwallaby~I54c8fd4d065ae537f396408df16832b158ee8998,openstack/neutron,stable/wallaby,I54c8fd4d065ae537f396408df16832b158ee8998,"Since OVN 20.06, config is stored in ""Chassis.other_config""",MERGED,2023-01-24 16:20:47.000000000,2023-01-25 16:23:52.000000000,2023-01-25 16:22:18.000000000,"[{'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 34271}]","[{'number': 1, 'created': '2023-01-24 16:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9819d13a23fb04b4e10debcd53cd6c9fdb5fc228', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/common/ovn/test_utils.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n(cherry picked from commit a007da1e9a68821de71ee274353b008c1fb6d4d6)\n'}, {'number': 2, 'created': '2023-01-24 16:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86f0e21a51ede32ba798e442e5f1211b9bc72ee2', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/common/ovn/test_utils.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n(cherry picked from commit a007da1e9a68821de71ee274353b008c1fb6d4d6)\n'}, {'number': 3, 'created': '2023-01-24 16:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d4756104c9396d7b89a4f04401505054865c7e6', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/common/ovn/test_utils.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n(cherry picked from commit a007da1e9a68821de71ee274353b008c1fb6d4d6)\n'}, {'number': 4, 'created': '2023-01-25 09:53:44.000000000', 'files': ['neutron/tests/functional/services/ovn_l3/test_plugin.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py', 'neutron/tests/functional/base.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/common/ovn/utils.py', 'neutron/tests/unit/fake_resources.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'releasenotes/notes/ovn-chassis-other-config-7db15b9d10bf7f04.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/common/ovn/test_utils.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/agent/test_neutron_agent.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1ece93f835b2738dc2f9decf52cda3b26a6c619d', 'message': 'Since OVN 20.06, config is stored in ""Chassis.other_config""\n\nSince OVN 20.06 [1], the OVN configuration is stored in\n""Chassis.other_config"".\n\nSince OVN 22.09, the ""Chassis"" configuration stored in\n""Chassis.other_config"" will not be replicated to\n""Chassis.external_ids"".\n\nThe ML2/OVN plugin tries to retrieve the ""Chassis""\nconfiguration from the ""other_config"" field first; if this\nfield does not exist (in OVN versions before 20.06), the plugin\nwill use ""external_ids"" field instead. Neutron will be compatible\nwith the different OVN versions (with and without ""other_config""\nfield).\n\n[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4\n[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae\n\nNOTE: this patch is similar to [1], but in this case neutron keeps\ncompatibility with the different OVN versions (with and without\n""other_config"" field). Since [2], the Neutron CI has a new job that\nuses the OVN/OVS packages distributed by the operating system\ninstalled by the CI (in this case, Ubuntu 20.04 and OVN 20.03).\n\n[1]https://review.opendev.org/c/openstack/neutron/+/859642\n[2]https://review.opendev.org/c/openstack/neutron/+/860636\n\nConflicts:\n      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py\n      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py\n      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/common/ovn/test_utils.py\n      neutron/tests/unit/fake_resources.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py\n      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py\n\nCloses-Bug: #1990229\nChange-Id: I54c8fd4d065ae537f396408df16832b158ee8998\n(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)\n(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)\n(cherry picked from commit a007da1e9a68821de71ee274353b008c1fb6d4d6)\n'}]",3,871640,1ece93f835b2738dc2f9decf52cda3b26a6c619d,21,4,4,16688,,,0,"Since OVN 20.06, config is stored in ""Chassis.other_config""

Since OVN 20.06 [1], the OVN configuration is stored in
""Chassis.other_config"".

Since OVN 22.09, the ""Chassis"" configuration stored in
""Chassis.other_config"" will not be replicated to
""Chassis.external_ids"".

The ML2/OVN plugin tries to retrieve the ""Chassis""
configuration from the ""other_config"" field first; if this
field does not exist (in OVN versions before 20.06), the plugin
will use ""external_ids"" field instead. Neutron will be compatible
with the different OVN versions (with and without ""other_config""
field).

[1]https://github.com/ovn-org/ovn/commit/74d90c2223d0a8c123823fb849b4c2de58c296e4
[2]https://github.com/ovn-org/ovn/commit/51309429cc3032a0cb422603e7bbda4905ca01ae

NOTE: this patch is similar to [1], but in this case neutron keeps
compatibility with the different OVN versions (with and without
""other_config"" field). Since [2], the Neutron CI has a new job that
uses the OVN/OVS packages distributed by the operating system
installed by the CI (in this case, Ubuntu 20.04 and OVN 20.03).

[1]https://review.opendev.org/c/openstack/neutron/+/859642
[2]https://review.opendev.org/c/openstack/neutron/+/860636

Conflicts:
      neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py
      neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py
      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py
      neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py
      neutron/tests/unit/common/ovn/test_utils.py
      neutron/tests/unit/fake_resources.py
      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl_ovn.py
      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py
      neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py

Closes-Bug: #1990229
Change-Id: I54c8fd4d065ae537f396408df16832b158ee8998
(cherry picked from commit 536498a29a4e7662a4d0b1bb923e2521509ad77a)
(cherry picked from commit 8a4c62d094a5419d878c38aa9017e40931a08f21)
(cherry picked from commit a007da1e9a68821de71ee274353b008c1fb6d4d6)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/871640/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/services/ovn_l3/test_plugin.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/test_mech_driver.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/ovsdb_monitor.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/test_placement.py', 'neutron/plugins/ml2/drivers/ovn/agent/neutron_agent.py', 'neutron/tests/functional/base.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_ovsdb_monitor.py', 'neutron/common/ovn/utils.py', 'neutron/tests/unit/fake_resources.py', 'releasenotes/notes/ovn-chassis-other-config-7db15b9d10bf7f04.yaml', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/extensions/placement.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/ovsdb/impl_idl_ovn.py', 'neutron/tests/unit/common/ovn/test_utils.py', 'neutron/tests/unit/plugins/ml2/drivers/ovn/agent/test_neutron_agent.py', 'neutron/plugins/ml2/drivers/ovn/mech_driver/mech_driver.py', 'neutron/tests/functional/plugins/ml2/drivers/ovn/mech_driver/ovsdb/test_impl_idl.py']",17,9819d13a23fb04b4e10debcd53cd6c9fdb5fc228,bug/1990229," {'other_config': {'ovn-bridge-mappings': {'other_config': {'ovn-bridge-mappings': {'other_config': {'ovn-bridge-mappings': other_config=chassis['other_config'])) {'other_config': {'ovn-bridge-mappings': 'p1:br-ex,p2:br-ex'}}"," {'external_ids': {'ovn-bridge-mappings': {'external_ids': {'ovn-bridge-mappings': {'external_ids': {'ovn-bridge-mappings': external_ids=chassis['external_ids'])) {'external_ids': {'ovn-bridge-mappings': 'p1:br-ex,p2:br-ex'}}",646,79
openstack%2Fglance~stable%2Fxena~Idf561f6306cebf756c787d8eefdc452ce44bd5e0,openstack/glance,stable/xena,Idf561f6306cebf756c787d8eefdc452ce44bd5e0,Enforce image safety during image_conversion,MERGED,2023-01-24 15:02:43.000000000,2023-01-25 16:23:50.000000000,2023-01-25 16:22:26.000000000,"[{'_account_id': 5314}, {'_account_id': 8122}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:02:43.000000000', 'files': ['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f45b5f024e765f0000884dfec5ac222124cfbc6d', 'message': ""Enforce image safety during image_conversion\n\nThis does two things:\n\n1. It makes us check that the QCOW backing_file is unset on those\ntypes of images. Nova and Cinder do this already to prevent an\narbitrary (and trivial to accomplish) host file exposure exploit.\n2. It makes us restrict VMDK files to only allowed subtypes. These\nfiles can name arbitrary files on disk as extents, providing the\nsame sort of attack. Default that list to just the types we believe\nare actually useful for openstack, and which are monolithic.\n\nThe configuration option to specify allowed subtypes is added in\nglance's config and not in the import options so that we can extend\nthis check later to image ingest. The format_inspector can tell us\nwhat the type and subtype is, and we could reject those images early\nand even in the case where image_conversion is not enabled.\n\nCloses-Bug: #1996188\nChange-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0\n(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)\n(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)\n(cherry picked from commit dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b)\n""}]",2,871619,f45b5f024e765f0000884dfec5ac222124cfbc6d,15,7,1,9303,,,0,"Enforce image safety during image_conversion

This does two things:

1. It makes us check that the QCOW backing_file is unset on those
types of images. Nova and Cinder do this already to prevent an
arbitrary (and trivial to accomplish) host file exposure exploit.
2. It makes us restrict VMDK files to only allowed subtypes. These
files can name arbitrary files on disk as extents, providing the
same sort of attack. Default that list to just the types we believe
are actually useful for openstack, and which are monolithic.

The configuration option to specify allowed subtypes is added in
glance's config and not in the import options so that we can extend
this check later to image ingest. The format_inspector can tell us
what the type and subtype is, and we could reject those images early
and even in the case where image_conversion is not enabled.

Closes-Bug: #1996188
Change-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0
(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)
(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)
(cherry picked from commit dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/19/871619/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py']",3,f45b5f024e765f0000884dfec5ac222124cfbc6d,glance-1996188-xena.patch," if 'backing-filename' in metadata: LOG.warning('Refusing to process QCOW image with a backing file') raise RuntimeError( 'QCOW images with backing files are not allowed') if metadata.get('format') == 'vmdk': create_type = metadata.get( 'format-specific', {}).get( 'data', {}).get('create-type') allowed = CONF.image_format.vmdk_allowed_types if not create_type: raise RuntimeError(_('Unable to determine VMDK create-type')) if not len(allowed): LOG.warning(_('Refusing to process VMDK file as ' 'vmdk_allowed_types is empty')) raise RuntimeError(_('Image is a VMDK, but no VMDK createType ' 'is specified')) if create_type not in allowed: LOG.warning(_('Refusing to process VMDK file with create-type ' 'of %r which is not in allowed set of: %s'), create_type, ','.join(allowed)) raise RuntimeError(_('Invalid VMDK create-type specified')) ",,82,0
openstack%2Fblazar~master~Iaebbe0346ee198b1134de72eacd07154d3f44d1e,openstack/blazar,master,Iaebbe0346ee198b1134de72eacd07154d3f44d1e,Use new get_rpc_client API from oslo.messaging,ABANDONED,2023-01-19 20:42:30.000000000,2023-01-25 16:16:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 20:42:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/f15c7acb1cc01c7fbb1091eb06516c4fc8214905', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: Iaebbe0346ee198b1134de72eacd07154d3f44d1e\n'}, {'number': 2, 'created': '2023-01-25 15:24:29.000000000', 'files': ['requirements.txt', 'blazar/manager/service.py', 'blazar/rpc.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/859997d21aebdf96688b145b486be56ed8849df0', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: Iaebbe0346ee198b1134de72eacd07154d3f44d1e\n'}]",1,871169,859997d21aebdf96688b145b486be56ed8849df0,7,1,2,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: Iaebbe0346ee198b1134de72eacd07154d3f44d1e
",git fetch https://review.opendev.org/openstack/blazar refs/changes/69/871169/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'blazar/rpc.py']",2,f15c7acb1cc01c7fbb1091eb06516c4fc8214905,, return messaging.get_rpc_client(, return messaging.RPCClient(,2,2
openstack%2Fcharm-cinder-ceph~stable%2Fxena~I333cbae496ab4e61f163ca971767443a3fa3c435,openstack/charm-cinder-ceph,stable/xena,I333cbae496ab4e61f163ca971767443a3fa3c435,Pin tox to < 4.0.0,MERGED,2023-01-13 20:06:21.000000000,2023-01-25 16:12:15.000000000,2023-01-25 16:12:15.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:06:21.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/20c1b478924970a94957de4ca5e69ddcbdf597ca', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I333cbae496ab4e61f163ca971767443a3fa3c435\n""}]",5,870180,20c1b478924970a94957de4ca5e69ddcbdf597ca,16,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I333cbae496ab4e61f163ca971767443a3fa3c435
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/80/870180/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,20c1b478924970a94957de4ca5e69ddcbdf597ca,pin-tox-xena, tox < 4.0.0,,1,0
openstack%2Fneutron~stable%2Fxena~Ia2a66cfd3fd1380c5204109742d44f09160548d2,openstack/neutron,stable/xena,Ia2a66cfd3fd1380c5204109742d44f09160548d2,Improve agent provision performance for large networks,MERGED,2023-01-18 03:13:44.000000000,2023-01-25 16:09:04.000000000,2023-01-25 16:07:15.000000000,"[{'_account_id': 6773}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-18 03:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7d972a2fafd1e799105082aacbf452b580e003e6', 'message': 'Improve agent provision performance for large networks\n\nBefore this patch, the metadata agent would provision network namespace\nfor all subnets under a network(datapath) as soon as the first\nVM(vif port) was mounted on the chassis. This operation can take very\nlong time for networks with lots of subnets. See the linked bug for\nmore details.\nThis patch changes this mechanism to ""lazy load"" where metadata agent\nprovisions metadata namespace with only the subnets belonging to the\nactive ports on the chassis. This results in virtually constant\nthroughput not effected by the number of subnets.\n\nCloses-Bug: #1981113\nChange-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2\n(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)\n'}, {'number': 2, 'created': '2023-01-23 16:37:47.000000000', 'files': ['neutron/agent/ovn/metadata/agent.py', 'neutron/tests/unit/agent/ovn/metadata/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/44f95a48fc6346d009528245dac472f87131ce0a', 'message': 'Improve agent provision performance for large networks\n\nBefore this patch, the metadata agent would provision network namespace\nfor all subnets under a network(datapath) as soon as the first\nVM(vif port) was mounted on the chassis. This operation can take very\nlong time for networks with lots of subnets. See the linked bug for\nmore details.\nThis patch changes this mechanism to ""lazy load"" where metadata agent\nprovisions metadata namespace with only the subnets belonging to the\nactive ports on the chassis. This results in virtually constant\nthroughput not effected by the number of subnets.\n\nMerge Conflict:\n        Using datapath_uuid :str in addition to net_name for\n        teardown_datapath method to remain compatible with the\n        method implementation in Yoga and before. Updated unit\n        tests accordingly\n        neutron/agent/ovn/metadata/agent.py\n        neutron/tests/unit/agent/ovn/metadata/test_agent.py\n\nCloses-Bug: #1981113\nChange-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2\n(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)\n'}]",5,870785,44f95a48fc6346d009528245dac472f87131ce0a,16,3,2,34271,,,0,"Improve agent provision performance for large networks

Before this patch, the metadata agent would provision network namespace
for all subnets under a network(datapath) as soon as the first
VM(vif port) was mounted on the chassis. This operation can take very
long time for networks with lots of subnets. See the linked bug for
more details.
This patch changes this mechanism to ""lazy load"" where metadata agent
provisions metadata namespace with only the subnets belonging to the
active ports on the chassis. This results in virtually constant
throughput not effected by the number of subnets.

Merge Conflict:
        Using datapath_uuid :str in addition to net_name for
        teardown_datapath method to remain compatible with the
        method implementation in Yoga and before. Updated unit
        tests accordingly
        neutron/agent/ovn/metadata/agent.py
        neutron/tests/unit/agent/ovn/metadata/test_agent.py

Closes-Bug: #1981113
Change-Id: Ia2a66cfd3fd1380c5204109742d44f09160548d2
(cherry picked from commit edf3b3f191c2eae229a754dcbfc448fa41bd8bc3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/85/870785/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/ovn/metadata/agent.py', 'neutron/tests/unit/agent/ovn/metadata/test_agent.py']",2,7d972a2fafd1e799105082aacbf452b580e003e6,bug/1981113-stable/yoga-stable/xena," class DatapathInfo: def __init__(self, uuid, external_ids): self.uuid = uuid self.external_ids = external_ids def __hash__(self): return hash(self.uuid) self.agent, 'provision_datapath') as pdp,\ pdp.assert_has_calls( [ mock.call(p.datapath) for p in self.ports ], any_order=True ) self.agent, 'provision_datapath') as pdp,\ pdp.assert_has_calls( [ mock.call(p.datapath) for p in self.ports ], any_order=True ) def test_get_networks_datapaths(self): """"""Test get_networks_datapaths returns only datapath objects for the networks containing vif ports of type ''(blank) and 'external'. This test simulates that this chassis has the following ports: * datapath '1': 1 port type '' , 1 port 'external' and 1 port 'unknown' * datapath '2': 1 port type '' * datapath '4': 1 port with type 'unknown' It is expected that only datapaths '1', '2' and '3' are returned datapath_1 = DatapathInfo(uuid='uuid1', external_ids={'name': 'neutron-1'}) datapath_2 = DatapathInfo(uuid='uuid2', external_ids={'name': 'neutron-2'}) datapath_3 = DatapathInfo(uuid='uuid3', external_ids={'name': 'neutron-3'}) datapath_4 = DatapathInfo(uuid='uuid4', external_ids={'name': 'neutron-4'}) ports = [ makePort(datapath_1, type=''), makePort(datapath_1, type='external'), makePort(datapath_1, type='unknown'), makePort(datapath_2, type=''), makePort(datapath_3, type='external'), makePort(datapath_4, type='unknown') ] with mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=ports): expected_datapaths = set([datapath_1, datapath_2, datapath_3]) self.assertSetEqual( expected_datapaths, self.agent.get_networks_datapaths() ) def test__process_cidrs_when_current_namespace_empty(self): current_namespace_cidrs = set() datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28', n_const.METADATA_CIDR]) expected_cidrs_to_delete = set() actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_only_contains_metadata_cidr( self): current_namespace_cidrs = set([n_const.METADATA_CIDR]) datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28']) expected_cidrs_to_delete = set() actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_contains_stale_cidr(self): current_namespace_cidrs = set([n_const.METADATA_CIDR, '10.0.1.0/31']) datapath_port_ips = ['10.0.0.2', '10.0.0.3', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30', '10.0.1.0/28']) expected_cidrs_to_delete = set(['10.0.1.0/31']) actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__process_cidrs_when_current_namespace_contains_mix_cidrs(self): """"""Current namespace cidrs contains stale cidrs and it is missing new required cidrs. """""" current_namespace_cidrs = set([n_const.METADATA_CIDR, '10.0.1.0/31', '10.0.1.0/28']) datapath_port_ips = ['10.0.0.2', '10.0.1.5'] metadaport_subnet_cidrs = ['10.0.0.0/30', '10.0.1.0/28', '11.0.1.2/24'] expected_cidrs_to_add = set(['10.0.0.0/30']) expected_cidrs_to_delete = set(['10.0.1.0/31']) actual_result = self.agent._process_cidrs(current_namespace_cidrs, datapath_port_ips, metadaport_subnet_cidrs) actual_cidrs_to_add, actual_cidrs_to_delete = actual_result self.assertSetEqual(actual_cidrs_to_add, expected_cidrs_to_add) self.assertSetEqual(actual_cidrs_to_delete, expected_cidrs_to_delete) def test__get_provision_params_returns_none_when_metadata_port_is_missing( self): """"""Should return None when there is no metadata port in datapath and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) with mock.patch.object( self.agent.sb_idl, 'get_metadata_port_network', return_value=None),\ mock.patch.object( self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_none_when_metadata_port_missing_mac( self): """"""Should return None when metadata port is missing MAC and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) metadadata_port = makePort(datapath, mac=['NO_MAC_HERE 1.2.3.4'], external_ids={'neutron:cidrs': '10.204.0.10/29'}) with mock.patch.object( self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object( self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_none_when_no_vif_ports(self): """"""Should return None when there are no datapath ports with type ""external"" or """"(blank) and call teardown datapath. """""" network_id = '1' datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) datapath_ports = [makePort(datapath, type='not_vif_type')] metadadata_port = makePort(datapath, mac=['fa:16:3e:22:65:18 1.2.3.4'], external_ids={'neutron:cidrs': '10.204.0.10/29'}) with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=datapath_ports),\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.assertIsNone(self.agent._get_provision_params(datapath)) tdp.assert_called_once_with(datapath.uuid, network_id) def test__get_provision_params_returns_provision_parameters(self): """"""The happy path when datapath has ports with ""external"" or """"(blank) types and metadata port contains MAC and subnet CIDRs. """""" network_id = '1' port_ip = '1.2.3.4' metada_port_mac = ""fa:16:3e:22:65:18"" metada_port_subnet_cidr = ""10.204.0.10/29"" metada_port_logical_port = ""3b66c176-199b-48ec-8331-c1fd3f6e2b44"" datapath = DatapathInfo(uuid='test123', external_ids={'name': 'neutron-{}'.format(network_id)}) datapath_ports = [makePort(datapath, mac=['fa:16:3e:e7:ac {}'.format(port_ip)])] metadadata_port = makePort(datapath, mac=[ '{} 10.204.0.1'.format(metada_port_mac) ], external_ids={'neutron:cidrs': metada_port_subnet_cidr}, logical_port=metada_port_logical_port) with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadadata_port),\ mock.patch.object(self.agent.sb_idl, 'get_ports_on_chassis', return_value=datapath_ports): actual_params = self.agent._get_provision_params(datapath) net_name, datapath_port_ips, metadata_port_info = actual_params self.assertEqual(network_id, net_name) self.assertListEqual([port_ip], datapath_port_ips) self.assertEqual(metada_port_mac, metadata_port_info.mac) self.assertSetEqual(set([metada_port_subnet_cidr]), metadata_port_info.ip_addresses) self.assertEqual(metada_port_logical_port, metadata_port_info.logical_port) net_name = '123' metadaport_logical_port = '123-abc-456' datapath_ports_ips = ['10.0.0.1', '10.0.0.2'] metada_port_info = agent.MetadataPortInfo( mac='aa:bb:cc:dd:ee:ff', ip_addresses=['10.0.0.1/23', '2001:470:9:1224:5595:dd51:6ba2:e788/64'], logical_port=metadaport_logical_port ) provision_params = (net_name, datapath_ports_ips, metada_port_info,) nemaspace_name = 'namespace' with mock.patch.object(self.agent, '_get_provision_params', return_value=provision_params),\ return_value=nemaspace_name),\ self.agent.provision_datapath('fake_datapath') add_veth.assert_called_once_with('veth_0', 'veth_1', nemaspace_name) 'Interface', 'veth_0', ('external_ids', {'iface-id': metadaport_logical_port})) mock.ANY, nemaspace_name, 80, mock.ANY, bind_address=n_const.METADATA_V4_IP, network_id=net_name) mock_checksum.assert_called_once_with(nemaspace_name)","DatapathInfo = collections.namedtuple('DatapathInfo', ['uuid', 'external_ids']) self.agent, 'ensure_all_networks_provisioned') as enp,\ enp.assert_called_once_with({ (p.datapath.uuid, p.datapath.uuid) for p in self.ports }) self.agent, 'ensure_all_networks_provisioned') as enp,\ enp.assert_called_once_with({ (p.datapath.uuid, p.datapath.uuid) for p in self.ports }) def test_get_networks(self): """"""Test which networks are provisioned. This test simulates that this chassis has the following ports: * datapath '0': 1 port * datapath '1': 2 ports * datapath '2': 1 port * datapath '5': 1 port with type 'unknown' It is expected that only datapaths '0', '1' and '2' are scheduled for provisioning. self.ports.append(makePort(datapath=DatapathInfo(uuid='1', external_ids={'name': 'neutron-1'}))) self.ports.append(makePort(datapath=DatapathInfo(uuid='3', external_ids={'name': 'neutron-3'}), type='external')) self.ports.append(makePort(datapath=DatapathInfo(uuid='5', external_ids={'name': 'neutron-5'}), type='unknown')) expected_networks = {(str(i), str(i)) for i in range(0, 4)} self.assertEqual(expected_networks, self.agent.get_networks()) def test_update_datapath_provision(self): self.ports.append(makePort(datapath=DatapathInfo(uuid='3', external_ids={'name': 'neutron-3'}), type='external')) with mock.patch.object(self.agent, 'provision_datapath', return_value=None) as pdp,\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.agent.update_datapath('1', 'a') self.agent.update_datapath('3', 'b') expected_calls = [mock.call('1', 'a'), mock.call('3', 'b')] pdp.assert_has_calls(expected_calls) tdp.assert_not_called() def test_update_datapath_teardown(self): with mock.patch.object(self.agent, 'provision_datapath', return_value=None) as pdp,\ mock.patch.object(self.agent, 'teardown_datapath') as tdp: self.agent.update_datapath('5', 'a') tdp.assert_called_once_with('5', 'a') pdp.assert_not_called() metadata_port = makePort(mac=['aa:bb:cc:dd:ee:ff'], external_ids={ 'neutron:cidrs': '10.0.0.1/23 ' '2001:470:9:1224:5595:dd51:6ba2:e788/64'}, logical_port='port') with mock.patch.object(self.agent.sb_idl, 'get_metadata_port_network', return_value=metadata_port),\ return_value='namespace'),\ self.agent.provision_datapath('1', '1') add_veth.assert_called_once_with('veth_0', 'veth_1', 'namespace') 'Interface', 'veth_0', ('external_ids', {'iface-id': 'port'})) mock.ANY, 'namespace', 80, mock.ANY, bind_address=n_const.METADATA_V4_IP, network_id='1') mock_checksum.assert_called_once_with('namespace')",378,133
openstack%2Fnova~stable%2Fzed~I5a399f1d3d702bfb76c067893e9c924904c8c360,openstack/nova,stable/zed,I5a399f1d3d702bfb76c067893e9c924904c8c360,[stable-only][cve] Check VMDK create-type against an allowed list,MERGED,2023-01-24 15:02:18.000000000,2023-01-25 16:08:31.000000000,2023-01-25 16:07:06.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11583}, {'_account_id': 11604}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d7bc2a67ee03155ff8be942b41439dc8ba2b002', 'message': 'Check VMDK create-type against an allowed list\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}, {'number': 2, 'created': '2023-01-25 10:09:17.000000000', 'files': ['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6e8ed78470edbae7b58d75e9e9f4f62bdb30a170', 'message': '[stable-only][cve] Check VMDK create-type against an allowed list\n\nNOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport\n\n[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}]",4,871616,6e8ed78470edbae7b58d75e9e9f4f62bdb30a170,27,7,2,4393,,,0,"[stable-only][cve] Check VMDK create-type against an allowed list

NOTE(sbauza): Stable policy allows us to proactively merge a backport without waiting for the parent patch to be merged (exception to rule #4 in [1]. Marking [stable-only] in order to silence nova-tox-validate-backport

[1] https://docs.openstack.org/project-team-guide/stable-branches.html#appropriate-fixes

Related-Bug: #1996188
Change-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/871616/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py']",3,0d7bc2a67ee03155ff8be942b41439dc8ba2b002,bug/1996188,"def check_vmdk_image(image_id, data): # Check some rules about VMDK files. Specifically we want to make # sure that the ""create-type"" of the image is one that we allow. # Some types of VMDK files can reference files outside the disk # image and we do not want to allow those for obvious reasons. types = CONF.compute.vmdk_allowed_types if not len(types): LOG.warning('Refusing to allow VMDK image as vmdk_allowed_' 'types is empty') msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) try: create_type = data.format_specific['data']['create-type'] except KeyError: msg = _('Unable to determine VMDK create-type') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if create_type not in CONF.compute.vmdk_allowed_types: LOG.warning('Refusing to process VMDK file with create-type of %r ' 'which is not in allowed set of: %s', create_type, ','.join(CONF.compute.vmdk_allowed_types)) msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if fmt == 'vmdk': check_vmdk_image(image_href, data) ",,86,0
openstack%2Fcharm-masakari-monitors~stable%2Fxena~I5619db520d7a8a130b72a219ae15abf36a30b359,openstack/charm-masakari-monitors,stable/xena,I5619db520d7a8a130b72a219ae15abf36a30b359,Pin tox to < 4.0.0,MERGED,2023-01-13 20:08:04.000000000,2023-01-25 16:08:00.000000000,2023-01-25 16:08:00.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:08:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-masakari-monitors/commit/61fb7a8753285589dddd93bab1f180d1f93185f4', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I5619db520d7a8a130b72a219ae15abf36a30b359\n""}]",3,870205,61fb7a8753285589dddd93bab1f180d1f93185f4,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I5619db520d7a8a130b72a219ae15abf36a30b359
",git fetch https://review.opendev.org/openstack/charm-masakari-monitors refs/changes/05/870205/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,61fb7a8753285589dddd93bab1f180d1f93185f4,pin-tox-xena, tox < 4.0.0,,1,0
openstack%2Fopenstack-ansible~master~I28973d38f593e043f4a0a57ff7c0c115b75558aa,openstack/openstack-ansible,master,I28973d38f593e043f4a0a57ff7c0c115b75558aa,[doc] Fix storage architecture links,MERGED,2023-01-19 08:34:07.000000000,2023-01-25 16:07:51.000000000,2023-01-25 16:06:07.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 31542}]","[{'number': 1, 'created': '2023-01-19 08:34:07.000000000', 'files': ['doc/source/reference/architecture/storage-arch.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2cd9365c319710f1cef992548673306355060afb', 'message': '[doc] Fix storage architecture links\n\nCloses-Bug: #2003273\nChange-Id: I28973d38f593e043f4a0a57ff7c0c115b75558aa\n'}]",0,871050,2cd9365c319710f1cef992548673306355060afb,8,3,1,28619,,,0,"[doc] Fix storage architecture links

Closes-Bug: #2003273
Change-Id: I28973d38f593e043f4a0a57ff7c0c115b75558aa
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/50/871050/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/architecture/storage-arch.rst'],1,2cd9365c319710f1cef992548673306355060afb,,.. _cinder driver: https://docs.openstack.org/cinder/latest/drivers.html.. _glance_store drivers: https://docs.openstack.org/glance_store/latest/user/drivers.html,.. _cinder driver: https://docs.openstack.org/cinder/drivers.html.. _glance_store drivers: https://docs.openstack.org/glance_store/drivers/,2,2
openstack%2Fcharm-nova-compute~stable%2Fxena~I1848fd6909bbac068077fbccc949e5cc36c782a3,openstack/charm-nova-compute,stable/xena,I1848fd6909bbac068077fbccc949e5cc36c782a3,Pin tox to < 4.0.0,MERGED,2023-01-13 20:08:41.000000000,2023-01-25 16:05:24.000000000,2023-01-25 16:05:24.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:08:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/82e34fbefb7a6c80c46e0eaac86774c3ad0ea30b', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I1848fd6909bbac068077fbccc949e5cc36c782a3\n""}]",4,870214,82e34fbefb7a6c80c46e0eaac86774c3ad0ea30b,14,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I1848fd6909bbac068077fbccc949e5cc36c782a3
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/14/870214/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,82e34fbefb7a6c80c46e0eaac86774c3ad0ea30b,pin-tox-xena, tox < 4.0.0,,1,0
openstack%2Fcharm-keystone-kerberos~stable%2Fxena~Ic611573119fa354171e99e0738e8da60cd86c2fd,openstack/charm-keystone-kerberos,stable/xena,Ic611573119fa354171e99e0738e8da60cd86c2fd,Pin tox to < 4.0.0,MERGED,2023-01-13 20:07:18.000000000,2023-01-25 16:05:01.000000000,2023-01-25 16:05:01.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:07:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-kerberos/commit/4bdba12dcf1d03fb195105e0fcfa515116a39f3a', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ic611573119fa354171e99e0738e8da60cd86c2fd\n""}]",3,870194,4bdba12dcf1d03fb195105e0fcfa515116a39f3a,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ic611573119fa354171e99e0738e8da60cd86c2fd
",git fetch https://review.opendev.org/openstack/charm-keystone-kerberos refs/changes/94/870194/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4bdba12dcf1d03fb195105e0fcfa515116a39f3a,pin-tox-xena, tox < 4.0.0,,1,0
openstack%2Fcharm-keystone-kerberos~stable%2Fwallaby~I95b4ab59a5badc4fb799e35fd8c7fea25a9944f1,openstack/charm-keystone-kerberos,stable/wallaby,I95b4ab59a5badc4fb799e35fd8c7fea25a9944f1,Pin tox to < 4.0.0,MERGED,2023-01-13 20:10:48.000000000,2023-01-25 16:04:59.000000000,2023-01-25 16:04:59.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:10:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-kerberos/commit/f641211768ff4362c7a9480d57b60e6c07c752d4', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I95b4ab59a5badc4fb799e35fd8c7fea25a9944f1\n""}]",3,870245,f641211768ff4362c7a9480d57b60e6c07c752d4,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I95b4ab59a5badc4fb799e35fd8c7fea25a9944f1
",git fetch https://review.opendev.org/openstack/charm-keystone-kerberos refs/changes/45/870245/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f641211768ff4362c7a9480d57b60e6c07c752d4,pin-tox-wallaby, tox < 4.0.0,,1,0
openstack%2Fcharm-neutron-api-plugin-ovn~stable%2Fxena~Ie94ea4fbd661a66e26f2538d68ed3e61b1be3eb4,openstack/charm-neutron-api-plugin-ovn,stable/xena,Ie94ea4fbd661a66e26f2538d68ed3e61b1be3eb4,Pin tox to < 4.0.0,MERGED,2023-01-13 20:08:20.000000000,2023-01-25 16:01:39.000000000,2023-01-25 16:01:39.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:08:20.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/4416844fc9467890473d5cb8bdbf0842328c9911', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ie94ea4fbd661a66e26f2538d68ed3e61b1be3eb4\n""}]",3,870209,4416844fc9467890473d5cb8bdbf0842328c9911,12,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ie94ea4fbd661a66e26f2538d68ed3e61b1be3eb4
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/09/870209/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4416844fc9467890473d5cb8bdbf0842328c9911,pin-tox-xena, tox < 4.0.0,,1,0
openstack%2Fcharm-neutron-api-plugin-ovn~stable%2Fwallaby~I166fd7f5cc71550eed6cbdc9e4b619d007903329,openstack/charm-neutron-api-plugin-ovn,stable/wallaby,I166fd7f5cc71550eed6cbdc9e4b619d007903329,Pin tox to < 4.0.0,MERGED,2023-01-13 20:11:58.000000000,2023-01-25 16:01:38.000000000,2023-01-25 16:01:38.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:11:58.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api-plugin-ovn/commit/d83321c52621201ca473d30d0c5a64ec087c7572', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: I166fd7f5cc71550eed6cbdc9e4b619d007903329\n""}]",6,870260,d83321c52621201ca473d30d0c5a64ec087c7572,18,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: I166fd7f5cc71550eed6cbdc9e4b619d007903329
",git fetch https://review.opendev.org/openstack/charm-neutron-api-plugin-ovn refs/changes/60/870260/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d83321c52621201ca473d30d0c5a64ec087c7572,pin-tox-wallaby, tox < 4.0.0,,1,0
openstack%2Fcharm-masakari~stable%2Fwallaby~Id8767721f8b12aefeacda12ebb4f08d39c232b2d,openstack/charm-masakari,stable/wallaby,Id8767721f8b12aefeacda12ebb4f08d39c232b2d,Pin tox to < 4.0.0,MERGED,2023-01-13 20:11:39.000000000,2023-01-25 16:01:30.000000000,2023-01-25 16:01:30.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:11:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-masakari/commit/80f91e42c926c8b8a2d1f8e30f27f749989c24f6', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Id8767721f8b12aefeacda12ebb4f08d39c232b2d\n""}]",4,870255,80f91e42c926c8b8a2d1f8e30f27f749989c24f6,14,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Id8767721f8b12aefeacda12ebb4f08d39c232b2d
",git fetch https://review.opendev.org/openstack/charm-masakari refs/changes/55/870255/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,80f91e42c926c8b8a2d1f8e30f27f749989c24f6,pin-tox-wallaby, tox < 4.0.0,,1,0
openstack%2Fcharm-masakari-monitors~stable%2Fyoga~Idd8bb0e275ab6513ecd2c6ae11d12cf246c6af81,openstack/charm-masakari-monitors,stable/yoga,Idd8bb0e275ab6513ecd2c6ae11d12cf246c6af81,Pin tox to < 4.0.0,MERGED,2023-01-13 20:04:24.000000000,2023-01-25 15:50:49.000000000,2023-01-25 15:50:49.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-13 20:04:24.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-masakari-monitors/commit/98da687c50e82d81d52f0f939646e56be2d92893', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Idd8bb0e275ab6513ecd2c6ae11d12cf246c6af81\n""}]",6,870154,98da687c50e82d81d52f0f939646e56be2d92893,18,4,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Idd8bb0e275ab6513ecd2c6ae11d12cf246c6af81
",git fetch https://review.opendev.org/openstack/charm-masakari-monitors refs/changes/54/870154/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,98da687c50e82d81d52f0f939646e56be2d92893,pin-tox-yoga, tox < 4.0.0,,1,0
openstack%2Fmurano~master~I1e108865803496e58cc26debd8177b5c3bb2e414,openstack/murano,master,I1e108865803496e58cc26debd8177b5c3bb2e414,Use new get_rpc_client API from oslo.messaging,ABANDONED,2023-01-19 20:47:40.000000000,2023-01-25 15:47:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 20:47:40.000000000', 'files': ['murano/common/rpc.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/murano/commit/25a3e6ae7f438740e87107d2ac4fdb0209488eab', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I1e108865803496e58cc26debd8177b5c3bb2e414\n'}]",1,871174,25a3e6ae7f438740e87107d2ac4fdb0209488eab,5,1,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I1e108865803496e58cc26debd8177b5c3bb2e414
",git fetch https://review.opendev.org/openstack/murano refs/changes/74/871174/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/common/rpc.py', 'requirements.txt']",2,25a3e6ae7f438740e87107d2ac4fdb0209488eab,,oslo.messaging>=14.1.0 # Apache-2.0,oslo.messaging>=5.29.0 # Apache-2.0,2,2
openstack%2Fvitrage~master~I8e63eec682c4ff5185588cbd88983b0fcce20fdc,openstack/vitrage,master,I8e63eec682c4ff5185588cbd88983b0fcce20fdc,Use new get_rpc_client API from oslo.messaging,ABANDONED,2023-01-19 20:51:19.000000000,2023-01-25 15:46:04.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 20:51:19.000000000', 'files': ['requirements.txt', 'vitrage/rpc.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/2b00bdd6373d484c5f50d9e97044802f1f4f5ac8', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I8e63eec682c4ff5185588cbd88983b0fcce20fdc\n'}]",0,871177,2b00bdd6373d484c5f50d9e97044802f1f4f5ac8,3,1,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I8e63eec682c4ff5185588cbd88983b0fcce20fdc
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/77/871177/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'vitrage/rpc.py']",2,2b00bdd6373d484c5f50d9e97044802f1f4f5ac8,," return messaging.get_rpc_client( transport, target, version_cap=version_cap, serializer=serializer)"," return messaging.RPCClient(transport, target, version_cap=version_cap, serializer=serializer)",4,5
openstack%2Fvitrage~master~I4d223e4d2d175bde59110c7e7d549926efcbe5cb,openstack/vitrage,master,I4d223e4d2d175bde59110c7e7d549926efcbe5cb,Fix passenv in tox.ini,ABANDONED,2023-01-23 19:24:39.000000000,2023-01-25 15:42:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 19:24:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/e64629c0c848cc5d6acfd572e8936d5f5fcfde42', 'message': 'Fix passenv in tox.ini\n\nChange-Id: I4d223e4d2d175bde59110c7e7d549926efcbe5cb\n'}]",0,871532,e64629c0c848cc5d6acfd572e8936d5f5fcfde42,3,1,1,16137,,,0,"Fix passenv in tox.ini

Change-Id: I4d223e4d2d175bde59110c7e7d549926efcbe5cb
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/32/871532/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e64629c0c848cc5d6acfd572e8936d5f5fcfde42,,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,7,1
openstack%2Fsahara~master~I8429cfbe3413bf551e1cf6463d5ba1c32fa94119,openstack/sahara,master,I8429cfbe3413bf551e1cf6463d5ba1c32fa94119,Use new get_rpc_client API from oslo.messaging,ABANDONED,2023-01-19 20:44:56.000000000,2023-01-25 15:41:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-19 20:44:56.000000000', 'files': ['requirements.txt', 'sahara/utils/rpc.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/98acad6bb8636ce1936bea3b9d4b587fbdb2f1d6', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I8429cfbe3413bf551e1cf6463d5ba1c32fa94119\n'}]",0,871171,98acad6bb8636ce1936bea3b9d4b587fbdb2f1d6,3,1,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I8429cfbe3413bf551e1cf6463d5ba1c32fa94119
",git fetch https://review.opendev.org/openstack/sahara refs/changes/71/871171/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'sahara/utils/rpc.py']",2,98acad6bb8636ce1936bea3b9d4b587fbdb2f1d6,, self.__client = messaging.get_rpc_client(, self.__client = messaging.RPCClient(,2,2
openstack%2Fsahara~master~Idd68a18257579175d359fed6cb73a643bb94b554,openstack/sahara,master,Idd68a18257579175d359fed6cb73a643bb94b554,Fix passenv in tox.ini,ABANDONED,2023-01-23 19:26:07.000000000,2023-01-25 15:41:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 19:26:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8bf5a7146ebece742d1f99419418e9791fd18416', 'message': 'Fix passenv in tox.ini\n\nChange-Id: Idd68a18257579175d359fed6cb73a643bb94b554\n'}]",0,871533,8bf5a7146ebece742d1f99419418e9791fd18416,3,1,1,16137,,,0,"Fix passenv in tox.ini

Change-Id: Idd68a18257579175d359fed6cb73a643bb94b554
",git fetch https://review.opendev.org/openstack/sahara refs/changes/33/871533/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8bf5a7146ebece742d1f99419418e9791fd18416,,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,7,1
openstack%2Freleases~master~Ie7f53681d8acc065242274b3b57a10d5d7a2fd0e,openstack/releases,master,Ie7f53681d8acc065242274b3b57a10d5d7a2fd0e,Release adjutant for stable/xena,MERGED,2023-01-16 15:14:39.000000000,2023-01-25 15:25:46.000000000,2023-01-25 15:25:46.000000000,"[{'_account_id': 14394}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2023-01-16 15:14:39.000000000', 'files': ['deliverables/xena/adjutant.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b63c76b1657345eb4acbbe75a4a66d74d444bfdc', 'message': ""Release adjutant for stable/xena\n\nThis release picks up new commits to adjutant since\nthe last release from stable/xena.\n\nThis is being proposed as a convenience to help make sure stable\nchanges are being released. If the team is good with this going out,\nplease respond with a +1 to let the release team know it is OK to\nproceed.\n\nIf it is not wanted at this time, or if there are more changes that\nwould be good to get merged before doing a stable release, please\nleave a -1 with a comment with what the team would prefer. We can\nthen either abandon this patch, or wait for an update with a new\ncommit hash to use instead.\n\n$ git log --oneline --no-merges 3.0.0..f8cd1d8\nf8cd1d8 Fix an issue with Adjutant's Invite process not checking inherited roles\n0235c55 Update TOX_CONSTRAINTS_FILE for stable/xena\n7c6e2db Update .gitreview for stable/xena\n\nSigned-off-by: Herv Beraud <hberaud@redhat.com>\nChange-Id: Ie7f53681d8acc065242274b3b57a10d5d7a2fd0e\n""}]",2,870553,b63c76b1657345eb4acbbe75a4a66d74d444bfdc,9,4,1,28522,,,0,"Release adjutant for stable/xena

This release picks up new commits to adjutant since
the last release from stable/xena.

This is being proposed as a convenience to help make sure stable
changes are being released. If the team is good with this going out,
please respond with a +1 to let the release team know it is OK to
proceed.

If it is not wanted at this time, or if there are more changes that
would be good to get merged before doing a stable release, please
leave a -1 with a comment with what the team would prefer. We can
then either abandon this patch, or wait for an update with a new
commit hash to use instead.

$ git log --oneline --no-merges 3.0.0..f8cd1d8
f8cd1d8 Fix an issue with Adjutant's Invite process not checking inherited roles
0235c55 Update TOX_CONSTRAINTS_FILE for stable/xena
7c6e2db Update .gitreview for stable/xena

Signed-off-by: Herv Beraud <hberaud@redhat.com>
Change-Id: Ie7f53681d8acc065242274b3b57a10d5d7a2fd0e
",git fetch https://review.opendev.org/openstack/releases refs/changes/53/870553/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/xena/adjutant.yaml'],1,b63c76b1657345eb4acbbe75a4a66d74d444bfdc,xena-stable, - version: 3.0.1 projects: - repo: openstack/adjutant hash: f8cd1d888fc2335dbc9edcd63e4aa5ff54fac8b7,,4,0
openstack%2Fnova~master~I973b6145353b16e14834fd12f67ffa61011837da,openstack/nova,master,I973b6145353b16e14834fd12f67ffa61011837da,Change microversion to 2.XX,NEW,2022-08-04 07:44:42.000000000,2023-01-25 15:04:53.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-08-04 07:44:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/842eb4fdf9b450032b3a081a121cb81f970beffc', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 2, 'created': '2022-08-05 16:29:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0906a144530910c5f1e6a46a33f109d810b07b7c', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 3, 'created': '2022-08-25 17:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0aa4b63bf99f180bd59ffb89cccdb5004502e4dc', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 4, 'created': '2022-08-26 12:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bec8d500e2cfd9c06647e6fcedfd0bb8b4298d1b', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 5, 'created': '2022-08-26 18:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a159c92eed6a671e0cd8b807713609b78df1f03', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 6, 'created': '2022-08-29 10:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5494f02dd8a762a6636ca88171d2a51716b6445b', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 7, 'created': '2022-08-31 14:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9389005fd0b31e062d1ad02cdfdc72f9f3fcdbf8', 'message': 'Change microversion to 2.93\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 8, 'created': '2022-09-06 16:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a645fb1a0a683a5d389273c4f638cccd0b373874', 'message': 'Change microversion to 2.94\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 9, 'created': '2022-09-07 08:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b01fa4df6839a0199c191f5f04fa29f38950394', 'message': 'Change microversion to 2.94\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 10, 'created': '2022-09-08 09:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4c8cefb649822d79f7349a517c6d0639c480c4e', 'message': 'Change microversion to 2.94\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 11, 'created': '2022-09-14 07:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1161d43fd88646aa277fd4e8b7de862c5209b63', 'message': 'Change microversion to 2.94\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 12, 'created': '2022-10-04 16:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/440944ac73e155c7f91d0b403f40a1f3d226cbac', 'message': 'Change microversion to 2.94\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 13, 'created': '2023-01-24 17:00:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/275badc50a3b3601d3d1ad23879b3ab5173f605a', 'message': 'Change microversion to 2.XX\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}, {'number': 14, 'created': '2023-01-25 10:56:45.000000000', 'files': ['nova/tests/functional/api_sample_tests/test_server_shares.py', 'doc/api_samples/os-server-shares/v2.95/server-shares-list-resp.json', 'nova/api/openstack/compute/server_shares.py', 'nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.95/server-shares-delete-req.json.tpl', 'doc/api_samples/os-server-shares/v2.95/server-shares-create-req.json', 'nova/api/openstack/api_version_request.py', 'nova/api/openstack/compute/rest_api_version_history.rst', 'nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.95/server-shares-list-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/9ef8dc8a40bcc4dc498c0526df226e9cb75ab80b', 'message': 'Change microversion to 2.XX\n\nChange-Id: I973b6145353b16e14834fd12f67ffa61011837da\n'}]",0,852088,9ef8dc8a40bcc4dc498c0526df226e9cb75ab80b,64,1,14,16207,,,0,"Change microversion to 2.XX

Change-Id: I973b6145353b16e14834fd12f67ffa61011837da
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/852088/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.93/server-shares-admin-show-resp.json.tpl', 'doc/api_samples/os-server-shares/v2.93/server-shares-create-resp.json', 'doc/api_samples/os-server-shares/v2.93/server-shares-admin-show-resp.json', 'doc/api_samples/os-server-shares/v2.93/server-shares-show-resp.json', 'doc/api_samples/versions/versions-get-resp.json', 'nova/api/openstack/api_version_request.py', 'nova/tests/unit/api/openstack/compute/test_server_shares.py', 'nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.93/server-shares-create-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.93/server-shares-show-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_server_shares.py', 'nova/api/openstack/compute/server_shares.py', 'doc/api_samples/versions/v21-version-get-resp.json', 'nova/api/openstack/compute/rest_api_version_history.rst', 'nova/tests/functional/api_sample_tests/api_samples/os-server-shares/v2.93/server-shares-create-req.json.tpl']",14,842eb4fdf9b450032b3a081a121cb81f970beffc,bp/manila_shares_attachments_v2,,,20,13
openstack%2Ftripleo-heat-templates~master~I54c42776c583e4501c6654e1cfd07ff4569a31df,openstack/tripleo-heat-templates,master,I54c42776c583e4501c6654e1cfd07ff4569a31df,Rename nova libvirt env var name for umask,ABANDONED,2023-01-23 15:39:43.000000000,2023-01-25 14:22:11.000000000,,"[{'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-23 15:39:43.000000000', 'files': ['deployment/nova/nova-modular-libvirt-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/52919ddfafd24cf970184020fe9fb262c6c826df', 'message': 'Rename nova libvirt env var name for umask\n\nDo not confuse it with Kolla (and Tripleo).\n\nDepends-On: Id4c67f37937b84dac1715b3339876711a8fe2c8e\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\nChange-Id: I54c42776c583e4501c6654e1cfd07ff4569a31df\n'}]",1,871489,52919ddfafd24cf970184020fe9fb262c6c826df,5,5,1,6926,,,0,"Rename nova libvirt env var name for umask

Do not confuse it with Kolla (and Tripleo).

Depends-On: Id4c67f37937b84dac1715b3339876711a8fe2c8e
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
Change-Id: I54c42776c583e4501c6654e1cfd07ff4569a31df
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/871489/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/nova/nova-modular-libvirt-container-puppet.yaml'],1,52919ddfafd24cf970184020fe9fb262c6c826df,libvirt_dynamic_permissions," NOVA_STATEDIR_UMASK: ""0027"""," TRIPLEO_KOLLA_UMASK: ""0027""",1,1
openstack%2Ftripleo-common~master~Id4c67f37937b84dac1715b3339876711a8fe2c8e,openstack/tripleo-common,master,Id4c67f37937b84dac1715b3339876711a8fe2c8e,Rename nova libvirt env var name for umask,ABANDONED,2023-01-23 15:34:24.000000000,2023-01-25 14:19:52.000000000,,"[{'_account_id': 7144}, {'_account_id': 9816}, {'_account_id': 22348}, {'_account_id': 28223}, {'_account_id': 30073}]","[{'number': 1, 'created': '2023-01-23 15:34:24.000000000', 'files': ['container-images/kolla/base/start.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2e59553afa7fa742d93be9f40575ccf7b2983c72', 'message': 'Rename nova libvirt env var name for umask\n\nDo not confuse it with Kolla (and Tripleo).\n\nChange-Id: Id4c67f37937b84dac1715b3339876711a8fe2c8e\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",3,871488,2e59553afa7fa742d93be9f40575ccf7b2983c72,7,5,1,6926,,,0,"Rename nova libvirt env var name for umask

Do not confuse it with Kolla (and Tripleo).

Change-Id: Id4c67f37937b84dac1715b3339876711a8fe2c8e
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/88/871488/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/kolla/base/start.sh'],1,2e59553afa7fa742d93be9f40575ccf7b2983c72,libvirt_dynamic_permissions,"umask ""${NOVA_STATEDIR_UMASK:-0022}""","umask ""${TRIPLEO_KOLLA_UMASK:-0022}""",1,1
openstack%2Fironic~bugfix%2F20.2~I1b11f7d5f2eba42ed6035c325a1e0cebcab61f5d,openstack/ironic,bugfix/20.2,I1b11f7d5f2eba42ed6035c325a1e0cebcab61f5d,Use cinder from stable/zed for CI jobs,MERGED,2023-01-24 13:15:34.000000000,2023-01-25 14:14:35.000000000,2023-01-25 14:12:18.000000000,"[{'_account_id': 10342}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 13:15:34.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/601e178c9174f00f89c66c8b136cae024d925c4c', 'message': 'Use cinder from stable/zed for CI jobs\n\nChange-Id: I1b11f7d5f2eba42ed6035c325a1e0cebcab61f5d\n'}]",1,871604,601e178c9174f00f89c66c8b136cae024d925c4c,12,2,1,23851,,,0,"Use cinder from stable/zed for CI jobs

Change-Id: I1b11f7d5f2eba42ed6035c325a1e0cebcab61f5d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/04/871604/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/ironic-jobs.yaml'],1,601e178c9174f00f89c66c8b136cae024d925c4c,cinder-zed, - name: openstack/cinder override-checkout: stable/zed,,2,0
openstack%2Fkolla-ansible~master~I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c,openstack/kolla-ansible,master,I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c,Adding optional delay between l3 agent restarts,MERGED,2022-10-28 13:46:24.000000000,2023-01-25 14:09:19.000000000,2023-01-25 14:08:06.000000000,"[{'_account_id': 13252}, {'_account_id': 14200}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27339}, {'_account_id': 32761}]","[{'number': 1, 'created': '2022-10-28 13:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/13fff4c12da8e77d855cd68957ac9cc5e34ddff6', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 2, 'created': '2022-10-28 15:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dbebf53ed65afd4eefb96177075f436c0f0251ee', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 3, 'created': '2022-10-28 15:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1d44006051e2a076be9b63ded1297f228147ad18', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 4, 'created': '2022-11-15 16:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/51c522ef2409be7b06747fccd2d3455e615393cb', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 5, 'created': '2022-11-16 09:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8b4d18f2587b8fdde7260743f3e5057a710d243c', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 6, 'created': '2022-11-16 16:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9f43f6387a6622d6395c3ba277ab9f7fccaae034', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 7, 'created': '2022-11-22 15:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/705e3c92fc2dae8386f96cd93fc4fcd0871e85f9', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 8, 'created': '2022-11-22 16:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4bac56e5717a1d4c453cddca7784d04def40bd56', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 9, 'created': '2022-11-23 10:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/25fe1f52b2d9cc6a9906dc82c72a753eb82e3cec', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 10, 'created': '2022-11-23 11:18:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b21fda311439d72656c52ce59cf74d13a745e638', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 11, 'created': '2022-12-01 15:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c134c99784e30392bf31ef02d1b147eb86f583f9', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 12, 'created': '2022-12-01 15:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ab566dfd1a07def81819a51cad5e69681d81b6fc', 'message': 'Adding optional to delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 13, 'created': '2023-01-23 09:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a95c963de433c79283560e89f541c8fb51421218', 'message': 'Adding optional delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issure more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}, {'number': 14, 'created': '2023-01-23 09:14:59.000000000', 'files': ['ansible/roles/neutron/handlers/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'releasenotes/notes/serial-l3-agent-restart-with-delay-7c2ec5875dbb760e.yaml', 'doc/source/reference/networking/neutron.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/391aa4677f394f1581df17fe74da968f19981e9d', 'message': 'Adding optional delay between l3 agent restarts\n\nThis change serialises the neutron l3 agent restart process and adds a\nuser configurable delay between restarts. This can prevent connectivity\nloss due to all agents being restarted at the same time.\n\nRouters increase the recovery time, making this issue more prevalent.\n\nChange-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c\n'}]",55,862916,391aa4677f394f1581df17fe74da968f19981e9d,72,7,14,35264,,,0,"Adding optional delay between l3 agent restarts

This change serialises the neutron l3 agent restart process and adds a
user configurable delay between restarts. This can prevent connectivity
loss due to all agents being restarted at the same time.

Routers increase the recovery time, making this issue more prevalent.

Change-Id: I3be0ebfa12965e6ae32d1b5f13f8fd23c3f52b8c
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/16/862916/8 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/neutron/handlers/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'releasenotes/notes/serial-l3-agent-restart-with-delay-7c2ec5875dbb760e.yaml', 'doc/source/reference/networking/neutron.rst']",4,13fff4c12da8e77d855cd68957ac9cc5e34ddff6,l3-agent-recovery,"L3 agent high availability ~~~~~~~~~~~~~~~~~~~~~~~~~~ L3 agents can be created in a high availability (HA) state with: .. code-block:: yaml enable_neutron_agent_ha: ""yes"" This allows networking to fail over across controllers if the active agent is stopped. If this option is enabled, it can be advantageous to also set: .. code-block:: yaml neutron_l3_agent_failover_delay: Agents sometimes need to be restarted. This delay is invoked between the restart operation of each agent. When set properly, it will stop network outages caused by all agents restarting at the same time. The exact length of time it takes to restart is depenent on hardware and the number of routers present. A good rule of thumb is to set the value to ``40 + 3n`` where ``n`` is the number of routers. A better approach however would be to first time how long an outage lasts, then set the value accordingly. ",,109,1
openstack%2Fmistral~master~I6d1b1844898343b8fa30f704761096e3d2936c4d,openstack/mistral,master,I6d1b1844898343b8fa30f704761096e3d2936c4d,Add an ability to hide sensitive data from http action logs,MERGED,2022-11-16 14:34:40.000000000,2023-01-25 13:51:01.000000000,2023-01-25 13:49:52.000000000,"[{'_account_id': 8731}, {'_account_id': 11583}, {'_account_id': 15895}, {'_account_id': 19134}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 29124}]","[{'number': 1, 'created': '2022-11-16 14:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/153a742a73341a5d7c82ee6676280c9235b1e055', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\n'}, {'number': 2, 'created': '2022-11-16 14:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/710a0e6b011124cb8d28a7b78257a541f5e1d3c8', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\n'}, {'number': 3, 'created': '2022-11-16 14:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f168e4b6ddfedbf114eccbc2c7bf5d678eb635bf', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 4, 'created': '2022-11-16 14:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f8fb7b41ae84a0773c4fb23b1da9e4ccb7a6bb3d', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 5, 'created': '2022-11-16 15:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/9d9252c8332a0275cc6ee10da0f1df3286a203bb', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 6, 'created': '2022-11-17 08:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/a0a6bfa51fc24065d7007a69c869dc21d49ba1ed', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 7, 'created': '2022-11-17 13:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e65d1e2b7383d4e02b21123bbc641ede3d70c985', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Request body\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 8, 'created': '2022-11-17 17:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/746c1c3d914bb5a7dae8a34c259d4e9e7f1b4940', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Request body\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 9, 'created': '2022-12-05 14:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bf7be8ff12123d820e49cbdb425cceb1e5620849', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Request body\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 10, 'created': '2022-12-05 16:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/bb536dd8796528b5990d34244a23e56418e6e4cd', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Request body\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}, {'number': 11, 'created': '2023-01-24 21:54:00.000000000', 'files': ['mistral/config.py', 'doc/source/admin/configuration/config-guide.rst', 'mistral/tests/unit/actions/test_std_http_action.py', 'mistral/utils/rest_utils.py', 'mistral/actions/std_actions.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3919e6a52be657643431b7b9fd4744b3ee48ef85', 'message': 'Add an ability to hide sensitive data from http action logs\n\nOpportunity to hide sensitive data from http action logs, such as:\n* Request headers\n* Request body\n* Response body\n\nChange-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d\nImplements: blueprint mistral-hide-sensitive-data-from-http-actions-logs\nSigned-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>\n'}]",42,864745,3919e6a52be657643431b7b9fd4744b3ee48ef85,31,7,11,29124,,,0,"Add an ability to hide sensitive data from http action logs

Opportunity to hide sensitive data from http action logs, such as:
* Request headers
* Request body
* Response body

Change-Id: I6d1b1844898343b8fa30f704761096e3d2936c4d
Implements: blueprint mistral-hide-sensitive-data-from-http-actions-logs
Signed-off-by: Oleg Ovcharuk <vgvoleg@gmail.com>
",git fetch https://review.opendev.org/openstack/mistral refs/changes/45/864745/2 && git format-patch -1 --stdout FETCH_HEAD,['mistral/config.py'],1,153a742a73341a5d7c82ee6676280c9235b1e055,bp/mistral-hide-sensitive-data-from-http-actions-logs,"action_logging_opts = [ cfg.BoolOpt( 'hide_response_body', default=False, help=( 'If this value is set to True then HTTP action response ' 'body will be hidden in logs.' ) ), cfg.ListOpt( 'sensitive_headers', default=[], help='List of sensitive headers that should be hidden in logs.' ) ] ACTION_LOGGING_GROUP = 'action_logging'CONF.register_opts(action_logging_opts, group=ACTION_LOGGING_GROUP) (ACTION_LOGGING_GROUP, action_logging_opts),",,19,0
openstack%2Fnova~stable%2Fyoga~I1719f8eda04e8d15a3b01f0612977164c4e55e85,openstack/nova,stable/yoga,I1719f8eda04e8d15a3b01f0612977164c4e55e85,Gracefully ERROR in _init_instance if vnic_type changed,MERGED,2022-09-26 16:52:21.000000000,2023-01-25 13:16:38.000000000,2023-01-25 13:15:16.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 16:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ef69cda8674a971834b729179635feb94978385', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n'}, {'number': 2, 'created': '2022-10-17 16:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/591586df221dcc87ec0b2018a6ad6286dc3398a8', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n'}, {'number': 3, 'created': '2023-01-09 17:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cdeb44f798fce2ce014a3d7de2310d82a4fd34f', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n'}, {'number': 4, 'created': '2023-01-11 11:34:26.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/network/test_neutron.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'releasenotes/notes/bug-1981813-vnic-type-change-9f3e16fae885b57f.yaml', 'nova/network/neutron.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a28c82719545d5c8ee7f3ff1361b3a796e05095a', 'message': 'Gracefully ERROR in _init_instance if vnic_type changed\n\nIf the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and\nthen the compute service is restarted then during _init_instance nova\ntries to plug the vif of the changed port. However as it now has macvtap\nvnic_type nova tries to look up the netdev of the parent VF. Still that\nVF is consumed by the instance so there is no such netdev on the host\nOS. This error killed the compute service at startup due to unhandled\nexception. This patch adds the exception handler, logs an ERROR and\ncontinue initializing other instances on the host.\n\nAlso this patch adds a detailed ERROR log when nova detects that the\nvnic_type changed during _heal_instance_info_cache periodic.\n\nCloses-Bug: #1981813\nChange-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85\n(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)\n'}]",4,859313,a28c82719545d5c8ee7f3ff1361b3a796e05095a,31,3,4,9708,,,0,"Gracefully ERROR in _init_instance if vnic_type changed

If the vnic_type of a bound port changes from ""direct"" to ""macvtap"" and
then the compute service is restarted then during _init_instance nova
tries to plug the vif of the changed port. However as it now has macvtap
vnic_type nova tries to look up the netdev of the parent VF. Still that
VF is consumed by the instance so there is no such netdev on the host
OS. This error killed the compute service at startup due to unhandled
exception. This patch adds the exception handler, logs an ERROR and
continue initializing other instances on the host.

Also this patch adds a detailed ERROR log when nova detects that the
vnic_type changed during _heal_instance_info_cache periodic.

Closes-Bug: #1981813
Change-Id: I1719f8eda04e8d15a3b01f0612977164c4e55e85
(cherry picked from commit e43bf900dc8ca66578603bed333c56b215b1876e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/859313/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/network/test_neutron.py', 'nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/network/neutron.py', 'releasenotes/notes/bug-1981813-vnic-type-change-9f3e16fae885b57f.yaml', 'nova/compute/manager.py']",6,1ef69cda8674a971834b729179635feb94978385,bug/1981813," except exception.PciDeviceNotFoundById: # This is bug 1981813 where the bound port vnic_type has changed # from direct to macvtap. Nova does not support that and it # already printed an ERROR when the change is detected during # _heal_instance_info_cache. Now we print an ERROR again and skip # plugging the vifs but let the service startup continue to init # the other instances LOG.exception( 'Virtual interface plugging failed for instance. Probably the ' 'vnic_type of the bound port has been changed. Nova does not ' 'support such change.', instance=instance ) return",,250,5
openstack%2Fmanila~master~Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509,openstack/manila,master,Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509,API Remove non previleged fields,NEW,2022-07-08 13:09:41.000000000,2023-01-25 13:15:13.000000000,,"[{'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-07-08 13:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a803c9696b3ba5291a0443fa0939e6c58e7fb037', 'message': ""WIP API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\npartial-fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 2, 'created': '2022-07-26 13:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/7dee5fe529ef849fa1daa7861cb2960b51b6f5ab', 'message': ""WIP API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\npartial-fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 3, 'created': '2022-07-28 12:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cc4284bdfdd5cdce875d426a5a57fab7ecacf662', 'message': ""WIP API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 4, 'created': '2022-07-28 12:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1e725e9cb435d4d4074208532ada7fc5fd228fdb', 'message': ""WIP API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-Fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 5, 'created': '2022-08-01 13:05:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/6fb343317052110f80608d4a86696ac5c235d45b', 'message': ""WIP API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-Fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 6, 'created': '2022-08-10 14:55:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c66a65befc90f683d5bf7633e80b1a95eb3f7034', 'message': ""API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-Fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 7, 'created': '2022-09-23 12:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/60143066efbf11bdf0c5afa40a925cda4fb71a79', 'message': ""API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-Fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}, {'number': 8, 'created': '2022-09-23 14:04:13.000000000', 'files': ['manila/api/views/share_networks.py', 'manila/api/views/share_network_subnets.py', 'manila/api/openstack/api_version_request.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b29117ccdd5d00d6bd250faf744e8e58eb4c1b83', 'message': ""API Remove non previleged fields\n\nFields 'segmentation_id' and 'network_type' removed from users\nthat are not admins\n\nPartial-Fix: #1824442\nCo-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>\nChange-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509\n""}]",18,849015,b29117ccdd5d00d6bd250faf744e8e58eb4c1b83,43,2,8,35002,,,0,"API Remove non previleged fields

Fields 'segmentation_id' and 'network_type' removed from users
that are not admins

Partial-Fix: #1824442
Co-authored-by: Lucas de Oliveira <lucasmoliveira059@gmail.com>
Change-Id: Id49a8e8f0e014e2f6ea0bfe41750ebe9a6f96509
",git fetch https://review.opendev.org/openstack/manila refs/changes/15/849015/6 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/views/share_networks.py', 'manila/api/views/share_network_subnets.py']",2,a803c9696b3ba5291a0443fa0939e6c58e7fb037,," context = request.environ['manila.context'] if context.is_admin: sns.update({ 'segmentation_id': share_network_subnet.get('segmentation_id'), 'network_type': share_network_subnet.get('network_type'), }) "," 'segmentation_id': share_network_subnet.get('segmentation_id'), 'network_type': share_network_subnet.get('network_type'),",50,23
openstack%2Foctavia~stable%2Fyoga~I00e327e1d94e46aa13a38120df9865ec34eaa593,openstack/octavia,stable/yoga,I00e327e1d94e46aa13a38120df9865ec34eaa593,Add a newline when writing the server state file,MERGED,2022-12-10 11:40:03.000000000,2023-01-25 13:11:56.000000000,2023-01-25 13:10:34.000000000,"[{'_account_id': 10273}, {'_account_id': 22348}, {'_account_id': 31664}, {'_account_id': 34429}]","[{'number': 1, 'created': '2022-12-10 11:40:03.000000000', 'files': ['octavia/amphorae/backends/utils/haproxy_query.py', 'octavia/tests/unit/amphorae/backends/utils/test_haproxy_query.py', 'releasenotes/notes/fix-corrupted-global-server-state-file-325ab7c62e21ff14.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/3605689ac9048cf1126d337833b5cf12ff37b88d', 'message': 'Add a newline when writing the server state file\n\nBefore restarting haproxy, the amphora-agent dumps the state of the\nservers in a file, so when haproxy reloads, it can recover the operating\nstate of its backends\' members.\nBut with haproxy 2.4 (in Centos 9 Stream), it fails with a ""corrupted\nglobal server state file"" error when reading this file. It seems that\nmost recent haproxy releases have a more strict validation of the format\nof the file and ensure that it is terminated with a newline.\n\nThis commit adds a newline to the file (all the responses to haproxy\nqueries are stripped in the amphora-agent). It fixes the issue on Centos\n9 Stream (and turns off a warning on Ubuntu).\n\nStory: 2010442\nTask: 46873\n\nChange-Id: I00e327e1d94e46aa13a38120df9865ec34eaa593\n'}]",3,867151,3605689ac9048cf1126d337833b5cf12ff37b88d,17,4,1,10273,,,0,"Add a newline when writing the server state file

Before restarting haproxy, the amphora-agent dumps the state of the
servers in a file, so when haproxy reloads, it can recover the operating
state of its backends' members.
But with haproxy 2.4 (in Centos 9 Stream), it fails with a ""corrupted
global server state file"" error when reading this file. It seems that
most recent haproxy releases have a more strict validation of the format
of the file and ensure that it is terminated with a newline.

This commit adds a newline to the file (all the responses to haproxy
queries are stripped in the amphora-agent). It fixes the issue on Centos
9 Stream (and turns off a warning on Ubuntu).

Story: 2010442
Task: 46873

Change-Id: I00e327e1d94e46aa13a38120df9865ec34eaa593
",git fetch https://review.opendev.org/openstack/octavia refs/changes/51/867151/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/utils/haproxy_query.py', 'octavia/tests/unit/amphorae/backends/utils/test_haproxy_query.py', 'releasenotes/notes/fix-corrupted-global-server-state-file-325ab7c62e21ff14.yaml']",3,3605689ac9048cf1126d337833b5cf12ff37b88d,,"--- fixes: - | Fixed a ""corrupted global server state file"" error in Centos 9 Stream when reloading the state of the servers after restarting haproxy. It also fixed the recovering of the operational state of the servers in haproxy after its restart. ",,9,2
openstack%2Fcharm-ceph-mon~stable%2Fquincy.2~I30bc22ae8509367207004b90eb2c38ad0fae9ffe,openstack/charm-ceph-mon,stable/quincy.2,I30bc22ae8509367207004b90eb2c38ad0fae9ffe,Make sure lockfile-progs package is installed,MERGED,2023-01-24 13:48:53.000000000,2023-01-25 13:08:01.000000000,2023-01-25 13:08:01.000000000,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2023-01-24 13:48:53.000000000', 'files': ['src/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/6b643ebffca4fa6dcfc19625337756a63d4c494d', 'message': 'Make sure lockfile-progs package is installed\n\nAlso, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe\nis not enabled any longer. And the python-dbus package is no longer\navailable on jammy either.\n\n    [on focal with systemd]\n    $ ls -1 /etc/nagios/nrpe.d/\n    check_ceph.cfg\n    check_conntrack.cfg\n    check_reboot.cfg\n    check_systemd_scopes.cfg\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit df676a097f780679f73c441d7fb67cdacde634c6)\n'}]",2,871554,6b643ebffca4fa6dcfc19625337756a63d4c494d,8,4,1,8108,,,0,"Make sure lockfile-progs package is installed

Also, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe
is not enabled any longer. And the python-dbus package is no longer
available on jammy either.

    [on focal with systemd]
    $ ls -1 /etc/nagios/nrpe.d/
    check_ceph.cfg
    check_conntrack.cfg
    check_reboot.cfg
    check_systemd_scopes.cfg

Closes-Bug: #1998163
Change-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe
(cherry picked from commit df676a097f780679f73c441d7fb67cdacde634c6)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/54/871554/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py']",2,6b643ebffca4fa6dcfc19625337756a63d4c494d,," mocks[""apt_install""].assert_called_with( ""lockfile-progs"", fatal=True) ""lockfile-progs"", fatal=True)"," mocks[""apt_install""].assert_called_once_with( [""python-dbus"", ""lockfile-progs""]) [""python-dbus"", ""lockfile-progs""])",4,5
openstack%2Fcinder~master~I5c6fad1107608bbc8fdec9ec687a5c48ba43b600,openstack/cinder,master,I5c6fad1107608bbc8fdec9ec687a5c48ba43b600,Use new get_rpc_client API from oslo.messaging,MERGED,2023-01-19 20:28:50.000000000,2023-01-25 12:40:49.000000000,2023-01-23 23:04:36.000000000,"[{'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}]","[{'number': 1, 'created': '2023-01-19 20:28:50.000000000', 'files': ['cinder/rpc.py', 'requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6578a327d8d3e3f8fea7b5c73ee687d09d53f4dd', 'message': 'Use new get_rpc_client API from oslo.messaging\n\nUse the new API that is consistent with\nthe existing API instead of instantiating the client\nclass directly.\n\nThis was introduced in release 14.1.0 here [1] and\nadded into oslo.messaging here [2]\n\n[1] https://review.opendev.org/c/openstack/requirements/+/869340\n[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419\n\nChange-Id: I5c6fad1107608bbc8fdec9ec687a5c48ba43b600\n'}]",4,871158,6578a327d8d3e3f8fea7b5c73ee687d09d53f4dd,48,3,1,16137,,,0,"Use new get_rpc_client API from oslo.messaging

Use the new API that is consistent with
the existing API instead of instantiating the client
class directly.

This was introduced in release 14.1.0 here [1] and
added into oslo.messaging here [2]

[1] https://review.opendev.org/c/openstack/requirements/+/869340
[2] https://review.opendev.org/c/openstack/oslo.messaging/+/862419

Change-Id: I5c6fad1107608bbc8fdec9ec687a5c48ba43b600
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/871158/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/rpc.py', 'requirements.txt']",2,6578a327d8d3e3f8fea7b5c73ee687d09d53f4dd,,oslo.messaging>=14.1.0 # Apache-2.0,oslo.messaging>=12.5.0 # Apache-2.0,4,5
openstack%2Fnova~stable%2Fyoga~I9367b7ed475917bdb05eb3f209ce1a4e646534e2,openstack/nova,stable/yoga,I9367b7ed475917bdb05eb3f209ce1a4e646534e2,Reproduce bug 1981813 in func env,MERGED,2022-09-26 16:52:21.000000000,2023-01-25 12:39:33.000000000,2023-01-25 12:38:05.000000000,"[{'_account_id': 782}, {'_account_id': 7166}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-09-26 16:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a5287d75bf895b13625583bd00c30a44a435fcf6', 'message': 'Reproduce bug 1981813 in func env\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n'}, {'number': 2, 'created': '2022-10-17 16:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ec3abe58ef3b21c37765b9ce4314af625967df5', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n'}, {'number': 3, 'created': '2023-01-09 17:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76bcc21e0a47221ce8fdfa126172af546f7028cc', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n'}, {'number': 4, 'created': '2023-01-11 11:34:26.000000000', 'files': ['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures/libvirt.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4954f993680c75fd9d3d507f2dcd00300c9b3d44', 'message': 'Reproduce bug 1981813 in func env\n\nThere stable/yoga only change in test_pci_sriov_servers.py due to\nunittest.mock switch[1] only happened in zed.\n\n[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova\n\nRelated-Bug: #1981813\nChange-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2\n(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)\n'}]",1,859312,4954f993680c75fd9d3d507f2dcd00300c9b3d44,21,4,4,9708,,,0,"Reproduce bug 1981813 in func env

There stable/yoga only change in test_pci_sriov_servers.py due to
unittest.mock switch[1] only happened in zed.

[1] https://review.opendev.org/q/topic:unittest.mock+status:merged+project:openstack/nova

Related-Bug: #1981813
Change-Id: I9367b7ed475917bdb05eb3f209ce1a4e646534e2
(cherry picked from commit f8c91eb75fc5504a37fc3b4be1d65d33dbc9b511)
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/859312/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/libvirt/test_pci_sriov_servers.py', 'nova/tests/fixtures/libvirt.py']",2,a5287d75bf895b13625583bd00c30a44a435fcf6,bug/1981813," self.mock_get_ifname_by_pci_address = self.useFixture( fixtures.MockPatch( ""nova.pci.utils.get_ifname_by_pci_address"", return_value=""fake_pf_interface_name"", ) ).mock"," self.useFixture(fixtures.MockPatch( 'nova.pci.utils.get_ifname_by_pci_address', return_value='fake_pf_interface_name'))",78,3
openstack%2Fglance~stable%2Fyoga~Idf561f6306cebf756c787d8eefdc452ce44bd5e0,openstack/glance,stable/yoga,Idf561f6306cebf756c787d8eefdc452ce44bd5e0,Enforce image safety during image_conversion,MERGED,2023-01-24 15:02:29.000000000,2023-01-25 12:39:23.000000000,2023-01-25 12:38:00.000000000,"[{'_account_id': 5314}, {'_account_id': 8122}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:02:29.000000000', 'files': ['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b', 'message': ""Enforce image safety during image_conversion\n\nThis does two things:\n\n1. It makes us check that the QCOW backing_file is unset on those\ntypes of images. Nova and Cinder do this already to prevent an\narbitrary (and trivial to accomplish) host file exposure exploit.\n2. It makes us restrict VMDK files to only allowed subtypes. These\nfiles can name arbitrary files on disk as extents, providing the\nsame sort of attack. Default that list to just the types we believe\nare actually useful for openstack, and which are monolithic.\n\nThe configuration option to specify allowed subtypes is added in\nglance's config and not in the import options so that we can extend\nthis check later to image ingest. The format_inspector can tell us\nwhat the type and subtype is, and we could reject those images early\nand even in the case where image_conversion is not enabled.\n\nCloses-Bug: #1996188\nChange-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0\n(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)\n(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)\n""}]",2,871617,dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b,13,7,1,9303,,,0,"Enforce image safety during image_conversion

This does two things:

1. It makes us check that the QCOW backing_file is unset on those
types of images. Nova and Cinder do this already to prevent an
arbitrary (and trivial to accomplish) host file exposure exploit.
2. It makes us restrict VMDK files to only allowed subtypes. These
files can name arbitrary files on disk as extents, providing the
same sort of attack. Default that list to just the types we believe
are actually useful for openstack, and which are monolithic.

The configuration option to specify allowed subtypes is added in
glance's config and not in the import options so that we can extend
this check later to image ingest. The format_inspector can tell us
what the type and subtype is, and we could reject those images early
and even in the case where image_conversion is not enabled.

Closes-Bug: #1996188
Change-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0
(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)
(cherry picked from commit 4967ab6935cfd0274ae801ac943d01909a236a0a)
",git fetch https://review.opendev.org/openstack/glance refs/changes/17/871617/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py']",3,dc8e5a5cc7f5e9d1b697e520a7533cc90516db1b,glance-1996188-yoga.patch," if 'backing-filename' in metadata: LOG.warning('Refusing to process QCOW image with a backing file') raise RuntimeError( 'QCOW images with backing files are not allowed') if metadata.get('format') == 'vmdk': create_type = metadata.get( 'format-specific', {}).get( 'data', {}).get('create-type') allowed = CONF.image_format.vmdk_allowed_types if not create_type: raise RuntimeError(_('Unable to determine VMDK create-type')) if not len(allowed): LOG.warning(_('Refusing to process VMDK file as ' 'vmdk_allowed_types is empty')) raise RuntimeError(_('Image is a VMDK, but no VMDK createType ' 'is specified')) if create_type not in allowed: LOG.warning(_('Refusing to process VMDK file with create-type ' 'of %r which is not in allowed set of: %s'), create_type, ','.join(allowed)) raise RuntimeError(_('Invalid VMDK create-type specified')) ",,82,0
openstack%2Fglance~stable%2Fzed~Idf561f6306cebf756c787d8eefdc452ce44bd5e0,openstack/glance,stable/zed,Idf561f6306cebf756c787d8eefdc452ce44bd5e0,Enforce image safety during image_conversion,MERGED,2023-01-24 15:01:55.000000000,2023-01-25 12:39:13.000000000,2023-01-25 12:37:57.000000000,"[{'_account_id': 5314}, {'_account_id': 8122}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:01:55.000000000', 'files': ['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/4967ab6935cfd0274ae801ac943d01909a236a0a', 'message': ""Enforce image safety during image_conversion\n\nThis does two things:\n\n1. It makes us check that the QCOW backing_file is unset on those\ntypes of images. Nova and Cinder do this already to prevent an\narbitrary (and trivial to accomplish) host file exposure exploit.\n2. It makes us restrict VMDK files to only allowed subtypes. These\nfiles can name arbitrary files on disk as extents, providing the\nsame sort of attack. Default that list to just the types we believe\nare actually useful for openstack, and which are monolithic.\n\nThe configuration option to specify allowed subtypes is added in\nglance's config and not in the import options so that we can extend\nthis check later to image ingest. The format_inspector can tell us\nwhat the type and subtype is, and we could reject those images early\nand even in the case where image_conversion is not enabled.\n\nCloses-Bug: #1996188\nChange-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0\n(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)\n""}]",1,871614,4967ab6935cfd0274ae801ac943d01909a236a0a,11,7,1,9303,,,0,"Enforce image safety during image_conversion

This does two things:

1. It makes us check that the QCOW backing_file is unset on those
types of images. Nova and Cinder do this already to prevent an
arbitrary (and trivial to accomplish) host file exposure exploit.
2. It makes us restrict VMDK files to only allowed subtypes. These
files can name arbitrary files on disk as extents, providing the
same sort of attack. Default that list to just the types we believe
are actually useful for openstack, and which are monolithic.

The configuration option to specify allowed subtypes is added in
glance's config and not in the import options so that we can extend
this check later to image ingest. The format_inspector can tell us
what the type and subtype is, and we could reject those images early
and even in the case where image_conversion is not enabled.

Closes-Bug: #1996188
Change-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0
(cherry picked from commit 0d6282a01691cecc2798f7858b181c4bb30f850c)
",git fetch https://review.opendev.org/openstack/glance refs/changes/14/871614/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py']",3,4967ab6935cfd0274ae801ac943d01909a236a0a,glance-1996188-zed.patch," if 'backing-filename' in metadata: LOG.warning('Refusing to process QCOW image with a backing file') raise RuntimeError( 'QCOW images with backing files are not allowed') if metadata.get('format') == 'vmdk': create_type = metadata.get( 'format-specific', {}).get( 'data', {}).get('create-type') allowed = CONF.image_format.vmdk_allowed_types if not create_type: raise RuntimeError(_('Unable to determine VMDK create-type')) if not len(allowed): LOG.warning(_('Refusing to process VMDK file as ' 'vmdk_allowed_types is empty')) raise RuntimeError(_('Image is a VMDK, but no VMDK createType ' 'is specified')) if create_type not in allowed: LOG.warning(_('Refusing to process VMDK file with create-type ' 'of %r which is not in allowed set of: %s'), create_type, ','.join(allowed)) raise RuntimeError(_('Invalid VMDK create-type specified')) ",,82,0
openstack%2Fkolla-ansible~master~I67bc12cb0a9b9d27c51d9c69a689dc16cd37c757,openstack/kolla-ansible,master,I67bc12cb0a9b9d27c51d9c69a689dc16cd37c757,CI: show coverage report in job,MERGED,2023-01-23 13:14:19.000000000,2023-01-25 11:23:49.000000000,2023-01-25 11:20:28.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2023-01-23 13:14:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/84be732361b82e3c75573618783fed0ff8dd9203', 'message': 'CI: show coverage report in job\n\nChange-Id: I67bc12cb0a9b9d27c51d9c69a689dc16cd37c757\n'}]",1,871471,84be732361b82e3c75573618783fed0ff8dd9203,7,2,1,22629,,,0,"CI: show coverage report in job

Change-Id: I67bc12cb0a9b9d27c51d9c69a689dc16cd37c757
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/71/871471/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,84be732361b82e3c75573618783fed0ff8dd9203,, coverage report --show-missing,,1,0
openstack%2Fkolla-ansible~master~I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb,openstack/kolla-ansible,master,I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb,Add ability to configure rabbitmq,MERGED,2022-11-23 14:17:22.000000000,2023-01-25 11:22:54.000000000,2023-01-25 11:20:23.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}, {'_account_id': 24072}]","[{'number': 1, 'created': '2022-11-23 14:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/83509db9477fc9e3980ea7bed1f05e7335d99b4b', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 2, 'created': '2022-11-24 00:02:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/00484e079893b4c4047a962bee307f2986b77740', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 3, 'created': '2022-11-29 12:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0c5baf85357bf54eb65d2b69423832f27aa9bee5', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 4, 'created': '2022-11-29 12:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c81e85e5298e7e931b1bf3331552f9e5f7abce8c', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 5, 'created': '2023-01-17 21:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2ef930cffc6b6f51526d9879b5f14a9fb0f77ef3', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 6, 'created': '2023-01-17 21:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1f1a3a4394922e1ec5d406337d897147372a6e83', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}, {'number': 7, 'created': '2023-01-17 21:04:08.000000000', 'files': ['ansible/roles/rabbitmq/templates/rabbitmq.conf.j2', 'releasenotes/notes/rabbitmq-configuration-6b100a390734dc29.yaml', 'ansible/roles/rabbitmq/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/701dc20f507bfde6e08e6b77877c55b9335266f0', 'message': ""Add ability to configure rabbitmq\n\nAs rabbitmq's configuration file is not ini or yaml file,\nthere is no option to extend configuration by new config\noptions via merge_configs or merge_yaml.\n\nThis patch moves config options to dictionary\nso it can be overriden in /etc/kolla/globals.yml.\n\nChange-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb\n""}]",17,865434,701dc20f507bfde6e08e6b77877c55b9335266f0,30,5,7,27339,,,0,"Add ability to configure rabbitmq

As rabbitmq's configuration file is not ini or yaml file,
there is no option to extend configuration by new config
options via merge_configs or merge_yaml.

This patch moves config options to dictionary
so it can be overriden in /etc/kolla/globals.yml.

Change-Id: I5cd772f4fb80a0e200fb24d67be735ca81e3fdeb
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/34/865434/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/rabbitmq/templates/rabbitmq.conf.j2', 'releasenotes/notes/rabbitmq-configuration-6b100a390734dc29.yaml', 'ansible/roles/rabbitmq/defaults/main.yml']",3,83509db9477fc9e3980ea7bed1f05e7335d99b4b,rabbitmq-configuration,"rabbitmq_extra_config: cluster_partition_handling: ""{{ rabbitmq_cluster_partition_handling }}"" management.listener.ip: ""{{ api_interface_address }}"" management.listener.port: ""{{ role_rabbitmq_management_port }}"" management.load_definitions: ""/etc/rabbitmq/definitions.json"" cluster_formation.peer_discovery_backend: ""rabbit_peer_discovery_classic_config""",,15,7
openstack%2Fansible-collection-kolla~master~I060285cc18455d071d9a4558ec93f5d3e6ab3277,openstack/ansible-collection-kolla,master,I060285cc18455d071d9a4558ec93f5d3e6ab3277,CI: add aarch64 kolla-ansible job,MERGED,2023-01-24 17:32:24.000000000,2023-01-25 11:22:42.000000000,2023-01-25 11:20:26.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}, {'_account_id': 24072}]","[{'number': 1, 'created': '2023-01-24 17:32:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collection-kolla/commit/bfd1a352a7807dc9b0cd5b0798671fbdad16ee3d', 'message': 'CI: add aarch64 kolla-ansible job\n\nChange-Id: I060285cc18455d071d9a4558ec93f5d3e6ab3277\n'}, {'number': 2, 'created': '2023-01-25 10:02:16.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-collection-kolla/commit/bb43201474b5e6700f0946b260df9734b204bac3', 'message': 'CI: add aarch64 kolla-ansible job\n\nChange-Id: I060285cc18455d071d9a4558ec93f5d3e6ab3277\n'}]",2,871646,bb43201474b5e6700f0946b260df9734b204bac3,14,5,2,22629,,,0,"CI: add aarch64 kolla-ansible job

Change-Id: I060285cc18455d071d9a4558ec93f5d3e6ab3277
",git fetch https://review.opendev.org/openstack/ansible-collection-kolla refs/changes/46/871646/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,bfd1a352a7807dc9b0cd5b0798671fbdad16ee3d,, check-arm64: jobs: - kolla-ansible-debian-aarch64,,3,0
openstack%2Fansible-collection-kolla~master~I0723c77a79ea47272bdbefe4aea04d1b3c179753,openstack/ansible-collection-kolla,master,I0723c77a79ea47272bdbefe4aea04d1b3c179753,CI: Add Kayobe RL9 jobs,MERGED,2023-01-25 07:08:16.000000000,2023-01-25 09:58:32.000000000,2023-01-25 09:56:41.000000000,"[{'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23084}]","[{'number': 1, 'created': '2023-01-25 07:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-collection-kolla/commit/3ee8cd87be476872f27353e773d4cb50d42f172f', 'message': 'CI: Add Kayobe RL9 jobs\n\nChange-Id: I0723c77a79ea47272bdbefe4aea04d1b3c179753\n'}, {'number': 2, 'created': '2023-01-25 07:46:58.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-collection-kolla/commit/9cc41d98b0f06a39e1f1b5e24d35a293b2fcbadb', 'message': 'CI: Add Kayobe RL9 jobs\n\nChange-Id: I0723c77a79ea47272bdbefe4aea04d1b3c179753\n'}]",1,871681,9cc41d98b0f06a39e1f1b5e24d35a293b2fcbadb,9,3,2,22629,,,0,"CI: Add Kayobe RL9 jobs

Change-Id: I0723c77a79ea47272bdbefe4aea04d1b3c179753
",git fetch https://review.opendev.org/openstack/ansible-collection-kolla refs/changes/81/871681/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,3ee8cd87be476872f27353e773d4cb50d42f172f,, - kayobe-overcloud-rocky9 - kayobe-overcloud-host-configure-rocky9 - kayobe-overcloud-rocky9 - kayobe-overcloud-host-configure-rocky9 ,,5,0
openstack%2Fansible-collection-kolla~master~I7456daa2eeb9b031dbc447ab72bada91915c8085,openstack/ansible-collection-kolla,master,I7456daa2eeb9b031dbc447ab72bada91915c8085,CI: Rename source jobs,MERGED,2023-01-24 17:31:48.000000000,2023-01-25 09:57:29.000000000,2023-01-25 09:55:13.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}, {'_account_id': 23084}]","[{'number': 1, 'created': '2023-01-24 17:31:48.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ansible-collection-kolla/commit/42709b07dd6d8688d241de0c81457afc4b56e5fa', 'message': 'CI: Rename source jobs\n\nChange-Id: I7456daa2eeb9b031dbc447ab72bada91915c8085\n'}]",0,871645,42709b07dd6d8688d241de0c81457afc4b56e5fa,8,3,1,22629,,,0,"CI: Rename source jobs

Change-Id: I7456daa2eeb9b031dbc447ab72bada91915c8085
",git fetch https://review.opendev.org/openstack/ansible-collection-kolla refs/changes/45/871645/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,42709b07dd6d8688d241de0c81457afc4b56e5fa,, - kolla-ansible-debian - kolla-ansible-rocky9 - kolla-ansible-ubuntu - kolla-ansible-debian - kolla-ansible-rocky9 - kolla-ansible-ubuntu, - kolla-ansible-debian-source - kolla-ansible-rocky9-source - kolla-ansible-ubuntu-source - kolla-ansible-debian-source - kolla-ansible-rocky9-source - kolla-ansible-ubuntu-source,6,6
openstack%2Fcinder~stable%2Fyoga~I3c60ee4c0795aadf03108ed9b5a46ecd116894af,openstack/cinder,stable/yoga,I3c60ee4c0795aadf03108ed9b5a46ecd116894af,Check VMDK subformat against an allowed list,MERGED,2023-01-24 15:02:44.000000000,2023-01-25 09:12:21.000000000,2023-01-25 02:28:00.000000000,"[{'_account_id': 4523}, {'_account_id': 5314}, {'_account_id': 9236}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-24 15:02:44.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ae5d53526e2b224d81b3259140c59aba97d72c3', 'message': 'Check VMDK subformat against an allowed list\n\nAlso add a more general check to convert_image that the image format\nreported by qemu-img matches what the caller says it is.\n\nChange-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af\nPartial-bug: #1996188\n(cherry picked from commit 930fc93e9fda82a4aa4568ae149c3c80af7379d0)\n(cherry picked from commit ba37dc2ead69c08d7ede242295ff997086e6121d)\nConflicts:\n  cinder/image/image_utils.py\n   - changed type annotations to use implicit Optional to be\n     consistent with cinder yoga mypy usage\n   - removed refs to image_conversion_disable in tests\n'}]",6,871620,2ae5d53526e2b224d81b3259140c59aba97d72c3,29,7,1,5314,,,0,"Check VMDK subformat against an allowed list

Also add a more general check to convert_image that the image format
reported by qemu-img matches what the caller says it is.

Change-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af
Partial-bug: #1996188
(cherry picked from commit 930fc93e9fda82a4aa4568ae149c3c80af7379d0)
(cherry picked from commit ba37dc2ead69c08d7ede242295ff997086e6121d)
Conflicts:
  cinder/image/image_utils.py
   - changed type annotations to use implicit Optional to be
     consistent with cinder yoga mypy usage
   - removed refs to image_conversion_disable in tests
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/871620/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml']",3,2ae5d53526e2b224d81b3259140c59aba97d72c3,CVE-2022-47951,"--- upgrade: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. security: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow in order to prevent exposure of host information by modifying the named extents in a VMDK image. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. - | As part of the fix for `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_, cinder is now more strict in checking that the ``disk_format`` recorded for an image (as revealed by the Image Service API image-show response) matches what cinder detects when it downloads the image. Thus, some requests to create a volume from a source image that had previously succeeded may fail with an ``ImageUnacceptable`` error. fixes: - | `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_: Fixed issue where a VMDK image file whose createType allowed named extents could expose host information. This change introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats. ",,565,47
openstack%2Fpuppet-openstack-integration~master~I9366744d473c535eefa087194bb8e296e736cb36,openstack/puppet-openstack-integration,master,I9366744d473c535eefa087194bb8e296e736cb36,Copy current p-o-i project in PUPPETFILE_DIR,ABANDONED,2022-02-15 10:28:18.000000000,2023-01-25 08:43:52.000000000,,"[{'_account_id': 9816}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-02-15 10:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c94c6e91dd13aae8db72cef3e39cc085e619a234', 'message': 'Copy current p-o-i project in RPM puppet module dir\n\nWhen we don\'t install puppet modules from source\nwe still need to copy the current p-o-i project\n(as we do in [1][2]) in the RPM puppet module dir\nwhich is ""/usr/share/openstack-puppet/modules"" [3].\n\nThis patch doesn\'t change current behavior, as we always\nset $MANAGE_PUPPET_MODULES as true [4], and we don\'t\noverride it in [5].\n\n[1] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L92\n[2] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L77\n[3] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/defaults/main.yml#L54\n[4] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/run_tests.sh#L23\n[5] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/master/tasks/main.yml#L114#L123\n\nChange-Id: I9366744d473c535eefa087194bb8e296e736cb36\n'}, {'number': 2, 'created': '2022-02-15 14:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/bd9027ef6fc3f44044f9b2c6f4251d53c4d6918e', 'message': 'Copy current p-o-i project in RPM puppet module dir\n\nWhen we don\'t install puppet modules from source\nwe still need to copy the current p-o-i project\n(as we do in [1][2]) in the RPM puppet module dir\nwhich is ""/etc/puppet/modules"" [3][4].\nNote that this puppet modules directory is the same\nfor every RDO puppet RPMs from Yoga down to Train.\n\nThis patch doesn\'t change current behavior, as we always\nset $MANAGE_PUPPET_MODULES as true [5], and we don\'t\noverride it in [6].\n\nNote that currently, when we enable puppet modules RPM,\nwe install puppet modules both with RPM and from sources.\nPuppet modules from RPM are first installed in ""/etc/puppet/modules"" [7],\nand then ./install_modules.sh remove them [8] and install them from\nsource [9].\n\n[1] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L92\n[2] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L77\n[3] https://github.com/rdo-common/puppet/blob/b1ae0bcfd2a36da74840ff531cb68924991f5a7c/0001-Fix-puppet-paths.patch#L24\n[4] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/tasks/main.yml#L121\n[5] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/run_tests.sh#L23\n[6] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/master/tasks/main.yml#L114#L123\n[7] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/master/tasks/main.yml#L76#L95\n[8] https://github.com/openstack/puppet-openstack-integration/blob/96b226bf255f532887f185b7fa2e28af753c3365/install_modules.sh#L31\n[9] https://github.com/openstack/puppet-openstack-integration/blob/master/functions#L88#L90\n\nChange-Id: I9366744d473c535eefa087194bb8e296e736cb36\n'}, {'number': 3, 'created': '2022-02-15 14:58:32.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c43ffae00da49119547b90e4c31c8e58dc752911', 'message': 'Copy current p-o-i project in PUPPETFILE_DIR\n\nWhen we don\'t install puppet modules from source\nwe still need to copy the current p-o-i project\n(as we do in [1][2]) in PUPPETFILE_DIR directory\nwhich is ""/etc/puppet/modules"". This dir is in the path\nfor both RPM installation and source installation [3].\n\nThis patch doesn\'t change current behavior, as we always\nset $MANAGE_PUPPET_MODULES as true [4], and we don\'t\noverride it in [5].\n\nNote that currently, when we enable puppet modules RPM, we install\npuppet modules with both RPM and from sources. Puppet modules from\nRPM goes in ""/usr/share/openstack-puppet/modules"", and modules from\nsource goes in /etc/puppet/modules [6]. But as the RPM module dir is\nfirst in modulepath [3] (""earlier directories having priority over\nlater ones"" [7]) we use RPM ones.\n\n[1] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L92\n[2] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L77\n[3] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/defaults/main.yml#L54\n[4] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/run_tests.sh#L23\n[5] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/master/tasks/main.yml#L114#L123\n[6] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/tasks/main.yml#L121\n[7] https://puppet.com/docs/puppet/5.5/dirs_modulepath.html\n\nChange-Id: I9366744d473c535eefa087194bb8e296e736cb36\n'}]",7,829213,c43ffae00da49119547b90e4c31c8e58dc752911,9,3,3,31068,,,0,"Copy current p-o-i project in PUPPETFILE_DIR

When we don't install puppet modules from source
we still need to copy the current p-o-i project
(as we do in [1][2]) in PUPPETFILE_DIR directory
which is ""/etc/puppet/modules"". This dir is in the path
for both RPM installation and source installation [3].

This patch doesn't change current behavior, as we always
set $MANAGE_PUPPET_MODULES as true [4], and we don't
override it in [5].

Note that currently, when we enable puppet modules RPM, we install
puppet modules with both RPM and from sources. Puppet modules from
RPM goes in ""/usr/share/openstack-puppet/modules"", and modules from
source goes in /etc/puppet/modules [6]. But as the RPM module dir is
first in modulepath [3] (""earlier directories having priority over
later ones"" [7]) we use RPM ones.

[1] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L92
[2] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/functions#L77
[3] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/defaults/main.yml#L54
[4] https://github.com/openstack/puppet-openstack-integration/blob/c8175c5b329d6cea0fb127bde2efe0a52805609a/run_tests.sh#L23
[5] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/master/tasks/main.yml#L114#L123
[6] https://github.com/rdo-infra/ansible-role-weirdo-puppet-openstack/blob/4d676307eb52fc33ea8562f57c4d6028ffe1cd02/tasks/main.yml#L121
[7] https://puppet.com/docs/puppet/5.5/dirs_modulepath.html

Change-Id: I9366744d473c535eefa087194bb8e296e736cb36
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/13/829213/3 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,c94c6e91dd13aae8db72cef3e39cc085e619a234,,else $SUDO cp -a ${SCRIPT_DIR} /usr/share/openstack-puppet/modules/openstack_integration,,2,0
openstack%2Fglance~stable%2Fussuri~If36e64b61767dc5c1df0daec2dd176fecd409926,openstack/glance,stable/ussuri,If36e64b61767dc5c1df0daec2dd176fecd409926,[stable-only] Remove glance-code-constants-check,MERGED,2022-11-07 22:12:00.000000000,2023-01-25 06:33:42.000000000,2023-01-25 06:31:47.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 22:12:00.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/7ffbbebd8815893b47958908be79cddc1a677ba0', 'message': ""[stable-only] Remove glance-code-constants-check\n\nThis job is only useful in the development branch; there's no\npoint in running it in the stable branches.\n\nChange-Id: If36e64b61767dc5c1df0daec2dd176fecd409926\n(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)\n(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)\n(cherry picked from commit 3cfbb69c017ed0e2c61f267829a3b79b073832f0)\n(cherry picked from commit 1471384ce93a3abacd02d725eb2938d160f000d2)\n(cherry picked from commit c9a0215e3527e0daad9ff16277811414eab2e07b)\n""}]",0,863946,7ffbbebd8815893b47958908be79cddc1a677ba0,8,3,1,5314,,,0,"[stable-only] Remove glance-code-constants-check

This job is only useful in the development branch; there's no
point in running it in the stable branches.

Change-Id: If36e64b61767dc5c1df0daec2dd176fecd409926
(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)
(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)
(cherry picked from commit 3cfbb69c017ed0e2c61f267829a3b79b073832f0)
(cherry picked from commit 1471384ce93a3abacd02d725eb2938d160f000d2)
(cherry picked from commit c9a0215e3527e0daad9ff16277811414eab2e07b)
",git fetch https://review.opendev.org/openstack/glance refs/changes/46/863946/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7ffbbebd8815893b47958908be79cddc1a677ba0,remove-constants-check-u,, name: glance-code-constants-check parent: tox description: | Tests to catch when code constants have gotten out of sync. vars: tox_envlist: gateonly irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ - ^\.zuul\.yaml$ - job: - glance-code-constants-check,0,19
openstack%2Fglance~stable%2Fvictoria~If36e64b61767dc5c1df0daec2dd176fecd409926,openstack/glance,stable/victoria,If36e64b61767dc5c1df0daec2dd176fecd409926,[stable-only] Remove glance-code-constants-check,MERGED,2022-11-07 22:09:30.000000000,2023-01-25 06:11:10.000000000,2023-01-25 06:09:02.000000000,"[{'_account_id': 8122}, {'_account_id': 9303}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-07 22:09:30.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/glance/commit/c9a0215e3527e0daad9ff16277811414eab2e07b', 'message': ""[stable-only] Remove glance-code-constants-check\n\nThis job is only useful in the development branch; there's no\npoint in running it in the stable branches.\n\nChange-Id: If36e64b61767dc5c1df0daec2dd176fecd409926\n(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)\n(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)\n(cherry picked from commit 3cfbb69c017ed0e2c61f267829a3b79b073832f0)\n(cherry picked from commit 1471384ce93a3abacd02d725eb2938d160f000d2)\n""}]",0,863945,c9a0215e3527e0daad9ff16277811414eab2e07b,8,3,1,5314,,,0,"[stable-only] Remove glance-code-constants-check

This job is only useful in the development branch; there's no
point in running it in the stable branches.

Change-Id: If36e64b61767dc5c1df0daec2dd176fecd409926
(cherry picked from commit 06a9228809d574c4e5b1b722e8238b3c45e58885)
(cherry picked from commit 5fbf47378e70537c73394408e69e94449aba1bec)
(cherry picked from commit 3cfbb69c017ed0e2c61f267829a3b79b073832f0)
(cherry picked from commit 1471384ce93a3abacd02d725eb2938d160f000d2)
",git fetch https://review.opendev.org/openstack/glance refs/changes/45/863945/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,c9a0215e3527e0daad9ff16277811414eab2e07b,remove-constants-check-v,, name: glance-code-constants-check parent: tox description: | Tests to catch when code constants have gotten out of sync. vars: tox_envlist: gateonly irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^api-ref/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tox.ini$ - ^\.zuul\.yaml$ - job: - glance-code-constants-check,0,19
openstack%2Fcharm-ceph-mon~stable%2Fquincy~I30bc22ae8509367207004b90eb2c38ad0fae9ffe,openstack/charm-ceph-mon,stable/quincy,I30bc22ae8509367207004b90eb2c38ad0fae9ffe,Make sure lockfile-progs package is installed,ABANDONED,2023-01-17 09:00:56.000000000,2023-01-25 05:54:36.000000000,,"[{'_account_id': 10366}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 09:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/c7ea6883c55703d058cec4a7068a0d44bb4f1c54', 'message': 'Make sure lockfile-progs package is installed\n\nWhen running the charm on jammy, there is no python-dbus package\navailable so the installation step fails silently. Make sure the\nlockfile-progs package is installed always with nrpe relations.\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit 11fac6832b20fb6b99dfe037ea4c80614ef4bbe5)\n'}, {'number': 2, 'created': '2023-01-17 10:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/10aeb21e43f8e7d68a525ba932d488039e4ff5a8', 'message': 'Make sure lockfile-progs package is installed\n\nWhen running the charm on jammy, there is no python-dbus package\navailable so the installation step fails silently. Make sure the\nlockfile-progs package is installed always with nrpe relations.\n\nAlso, accommodate libffi-dev in bindep.txt by hand from origin/master\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit 11fac6832b20fb6b99dfe037ea4c80614ef4bbe5)\n'}, {'number': 3, 'created': '2023-01-18 01:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/b6e4a24a509d0f7d5c1e3ed5e45a44d9bc682b7f', 'message': 'Make sure lockfile-progs package is installed\n\nAlso, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe\nis not enabled any longer. And the python-dbus package is no longer\navailable on jammy either.\n\n    [on focal with systemd]\n    $ ls -1 /etc/nagios/nrpe.d/\n    check_ceph.cfg\n    check_conntrack.cfg\n    check_reboot.cfg\n    check_systemd_scopes.cfg\n\nAdditionally, accommodate the following changes by hand from\norigin/master:\n- add libffi-dev in bindep.txt\n- update pinning to charm-tools==2.8.4\n  (but not unpinning to be in-sync with origin/master)\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit 97c32bff15f25393b8717a5320d1f11adf8e600e)\n'}, {'number': 4, 'created': '2023-01-18 01:47:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/f4e33fd7be67ff88d1635670cfda8776d9a95b36', 'message': 'Make sure lockfile-progs package is installed\n\nAlso, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe\nis not enabled any longer. And the python-dbus package is no longer\navailable on jammy either.\n\n    [on focal with systemd]\n    $ ls -1 /etc/nagios/nrpe.d/\n    check_ceph.cfg\n    check_conntrack.cfg\n    check_reboot.cfg\n    check_systemd_scopes.cfg\n\nAdditionally, accommodate the following changes by hand from\norigin/master:\n- add libffi-dev in bindep.txt\n- update pinning to charm-tools==2.8.4\n  (but not unpinning to be in-sync with origin/master)\n- update pinning for tempest\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit 97c32bff15f25393b8717a5320d1f11adf8e600e)\n'}, {'number': 5, 'created': '2023-01-19 02:59:35.000000000', 'files': ['hooks/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/82d95b1a1d72bb6db0728f44714062ba0a3019b1', 'message': 'Make sure lockfile-progs package is installed\n\nAlso, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe\nis not enabled any longer. And the python-dbus package is no longer\navailable on jammy either.\n\n    [on focal with systemd]\n    $ ls -1 /etc/nagios/nrpe.d/\n    check_ceph.cfg\n    check_conntrack.cfg\n    check_reboot.cfg\n    check_systemd_scopes.cfg\n\nCloses-Bug: #1998163\nChange-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe\n(cherry picked from commit 97c32bff15f25393b8717a5320d1f11adf8e600e)\n'}]",7,870720,82d95b1a1d72bb6db0728f44714062ba0a3019b1,27,3,5,8108,,,0,"Make sure lockfile-progs package is installed

Also, drop python-dbus for simplicity since ""check_upstart_job"" in nrpe
is not enabled any longer. And the python-dbus package is no longer
available on jammy either.

    [on focal with systemd]
    $ ls -1 /etc/nagios/nrpe.d/
    check_ceph.cfg
    check_conntrack.cfg
    check_reboot.cfg
    check_systemd_scopes.cfg

Closes-Bug: #1998163
Change-Id: I30bc22ae8509367207004b90eb2c38ad0fae9ffe
(cherry picked from commit 97c32bff15f25393b8717a5320d1f11adf8e600e)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/20/870720/4 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/ceph_hooks.py', 'unit_tests/test_ceph_hooks.py']",2,c7ea6883c55703d058cec4a7068a0d44bb4f1c54,," mocks[""apt_install""].assert_has_calls([ call(""python-dbus"", fatal=False), call(""lockfile-progs"", fatal=True)]) mocks[""apt_install""].assert_has_calls([ call(""python-dbus"", fatal=False), call(""lockfile-progs"", fatal=True)])"," mocks[""apt_install""].assert_called_once_with( [""python-dbus"", ""lockfile-progs""]) mocks[""apt_install""].assert_called_with( [""python-dbus"", ""lockfile-progs""])",10,5
openstack%2Fcharm-octavia~stable%2Fussuri~I2cae5f0e307c8cd14f1831f3416d890ad604b705,openstack/charm-octavia,stable/ussuri,I2cae5f0e307c8cd14f1831f3416d890ad604b705,Wait for management interface IP to be assigned,ABANDONED,2022-12-07 02:54:21.000000000,2023-01-25 05:25:45.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-12-07 02:54:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/7b81437defe60282a57985ce4dcba0f3041c93a5', 'message': ""Wait for management interface IP to be assigned\n\nThere can be a delay between the interface being created,\nand an IP address getting assigned,\nwhich previously caused a race condition where\nthe config could be rendered before the IP address was ready\nresulting in the health manager bind_ip to be empty.\n\nThis ensures that the IP address will be ready before continuing,\nwhich will ensure that the config rendering will not happen until ready,\nand the configure-resources action will only return once it's all done.\n\nCloses-Bug: #1961088\nChange-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705\n(cherry picked from commit 4c206672618bd6c7816b16e2ce04c0469d9da14d)\n""}, {'number': 2, 'created': '2022-12-09 03:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/eb7cbb6ad44bfc15c1e2400ef5ea46a30e9df0a3', 'message': ""Wait for management interface IP to be assigned\n\nThere can be a delay between the interface being created,\nand an IP address getting assigned,\nwhich previously caused a race condition where\nthe config could be rendered before the IP address was ready\nresulting in the health manager bind_ip to be empty.\n\nThis ensures that the IP address will be ready before continuing,\nwhich will ensure that the config rendering will not happen until ready,\nand the configure-resources action will only return once it's all done.\n\nAlso: fix issue with tox,\nsee https://github.com/openstack-charmers/release-tools/pull/272\n\nCloses-Bug: #1961088\nChange-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705\n(cherry picked from commit 4c206672618bd6c7816b16e2ce04c0469d9da14d)\n""}, {'number': 3, 'created': '2023-01-23 00:02:36.000000000', 'files': ['src/lib/charm/openstack/octavia.py', 'unit_tests/test_lib_charm_openstack_api_crud.py', 'src/reactive/octavia_handlers.py', 'unit_tests/test_lib_charm_openstack_octavia.py', 'src/lib/charm/openstack/api_crud.py'], 'web_link': 'https://opendev.org/openstack/charm-octavia/commit/5fed3337eba80fb4b779b91c64c49e1ca62ec8ba', 'message': ""Wait for management interface IP to be assigned\n\nThere can be a delay between the interface being created,\nand an IP address getting assigned,\nwhich previously caused a race condition where\nthe config could be rendered before the IP address was ready\nresulting in the health manager bind_ip to be empty.\n\nThis ensures that the IP address will be ready before continuing,\nwhich will ensure that the config rendering will not happen until ready,\nand the configure-resources action will only return once it's all done.\n\nCloses-Bug: #1961088\nChange-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705\n(cherry picked from commit 4c206672618bd6c7816b16e2ce04c0469d9da14d)\n""}]",6,866819,5fed3337eba80fb4b779b91c64c49e1ca62ec8ba,18,2,3,34352,,,0,"Wait for management interface IP to be assigned

There can be a delay between the interface being created,
and an IP address getting assigned,
which previously caused a race condition where
the config could be rendered before the IP address was ready
resulting in the health manager bind_ip to be empty.

This ensures that the IP address will be ready before continuing,
which will ensure that the config rendering will not happen until ready,
and the configure-resources action will only return once it's all done.

Closes-Bug: #1961088
Change-Id: I2cae5f0e307c8cd14f1831f3416d890ad604b705
(cherry picked from commit 4c206672618bd6c7816b16e2ce04c0469d9da14d)
",git fetch https://review.opendev.org/openstack/charm-octavia refs/changes/19/866819/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/octavia.py', 'src/reactive/octavia_handlers.py', 'unit_tests/test_lib_charm_openstack_api_crud.py', 'unit_tests/test_lib_charm_openstack_octavia.py', 'src/lib/charm/openstack/api_crud.py']",5,7b81437defe60282a57985ce4dcba0f3041c93a5,fix-heath-bind-ip-ussuri-test,"import timeclass NoMgmtInterface(Exception): """"""Exception raised when no mgmt interface could not be found."""""" def wait_for_address_on_mgmt_interface(): """""" Poll for an address on the management interface. :returns: True if an address was found before timing out :rtype: bool """""" for _ in range(90): ch_core.hookenv.log('polling for address on mgmt interface', level=ch_core.hookenv.DEBUG) if octavia.get_address_on_mgmt_interface(): ch_core.hookenv.log( 'address found on mgmt interface', level=ch_core.hookenv.INFO ) return True time.sleep(10) # 90 * 10 = 15 minutes ch_core.hookenv.log('timed out waiting for address on mgmt interface', level=ch_core.hookenv.INFO) return False # If there's no mgmt interface, this is a hard error with no simple fix. # So raising an uncaught exception is ok. if not wait_for_address_on_mgmt_interface(): raise NoMgmtInterface() ",,117,19
openstack%2Fpuppet-nova~master~I9d533275d5999fa02b438be1642f61b40a246161,openstack/puppet-nova,master,I9d533275d5999fa02b438be1642f61b40a246161,Fix inconsistent parameter name of wsgi::apache,MERGED,2023-01-23 01:32:59.000000000,2023-01-25 05:10:02.000000000,2023-01-25 05:08:51.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 01:32:59.000000000', 'files': ['manifests/wsgi/apache_api.pp', 'spec/classes/nova_wsgi_apache_metadata_spec.rb', 'manifests/wsgi/apache_metadata.pp', 'releasenotes/notes/fix-inconsistent-wsgi-apache-params-dfc0ecb5cf59efe3.yaml', 'spec/classes/nova_wsgi_apache_api_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a258d3d8c76859d7084129b3e369ac9004fc5c82', 'message': 'Fix inconsistent parameter name of wsgi::apache\n\nThe nova::wsgi::apache class takes the api_port parameter to determine\nthe TCP port number, but this name is not commonly used while the port\nparameter is used in the other modules. This change fixes the parameter\nname so that we can keep the implementation more consistent.\n\nChange-Id: I9d533275d5999fa02b438be1642f61b40a246161\n'}]",3,871404,a258d3d8c76859d7084129b3e369ac9004fc5c82,18,3,1,9816,,,0,"Fix inconsistent parameter name of wsgi::apache

The nova::wsgi::apache class takes the api_port parameter to determine
the TCP port number, but this name is not commonly used while the port
parameter is used in the other modules. This change fixes the parameter
name so that we can keep the implementation more consistent.

Change-Id: I9d533275d5999fa02b438be1642f61b40a246161
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/04/871404/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/wsgi/apache_api.pp', 'spec/classes/nova_wsgi_apache_metadata_spec.rb', 'manifests/wsgi/apache_metadata.pp', 'releasenotes/notes/fix-inconsistent-wsgi-apache-params-dfc0ecb5cf59efe3.yaml', 'spec/classes/nova_wsgi_apache_api_spec.rb']",5,a258d3d8c76859d7084129b3e369ac9004fc5c82,," :port => 12345,"," :api_port => 12345,",37,8
openstack%2Fdesignate-specs~master~Idebd4995b01599990ed930bd07180b2bc90e6611,openstack/designate-specs,master,Idebd4995b01599990ed930bd07180b2bc90e6611,Update tox.ini for tox4,MERGED,2023-01-20 22:30:53.000000000,2023-01-25 04:21:14.000000000,2023-01-25 04:20:09.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}]","[{'number': 1, 'created': '2023-01-20 22:30:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/designate-specs/commit/5dff29616cb428a0e26d3ee63fcbff12d0420488', 'message': 'Update tox.ini for tox4\n\nWith tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace.\n\nChange-Id: Idebd4995b01599990ed930bd07180b2bc90e6611\n'}]",1,871392,5dff29616cb428a0e26d3ee63fcbff12d0420488,8,3,1,11628,,,0,"Update tox.ini for tox4

With tox4, we need to pass the environment variables on separate lines as opposed to separated by whitespace.

Change-Id: Idebd4995b01599990ed930bd07180b2bc90e6611
",git fetch https://review.opendev.org/openstack/designate-specs refs/changes/92/871392/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5dff29616cb428a0e26d3ee63fcbff12d0420488,,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,7,1
openstack%2Fmonasca-ui~master~Ib931f73eaa2a71f49b7a00dad5ab44409c6aab2e,openstack/monasca-ui,master,Ib931f73eaa2a71f49b7a00dad5ab44409c6aab2e,setup.cfg: Replace dashes with underscores,NEW,2022-09-12 08:11:19.000000000,2023-01-25 03:28:03.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32102}]","[{'number': 1, 'created': '2022-09-12 08:11:19.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/6a7b9685145714a93c6badd4af377608f05ec4f3', 'message': ""setup.cfg: Replace dashes with underscores\n\nSetuptools v54.1.0 introduces a warning that the use of\ndash-separated options in 'setup.cfg' will not be supported\nin a future version [1].\nGet ahead of the issue by replacing the dashes with underscores.\nWithout this, we see 'UserWarning' messages\nlike the following on new enough\nversions of setuptools:\n\n  UserWarning: Usage of dash-separated 'description-file' will not be\n  supported in future versions. Please use the underscore name\n  'description_file' instead\n\nChange-Id: Ib931f73eaa2a71f49b7a00dad5ab44409c6aab2e\n""}]",0,857019,6a7b9685145714a93c6badd4af377608f05ec4f3,4,3,1,32921,,,0,"setup.cfg: Replace dashes with underscores

Setuptools v54.1.0 introduces a warning that the use of
dash-separated options in 'setup.cfg' will not be supported
in a future version [1].
Get ahead of the issue by replacing the dashes with underscores.
Without this, we see 'UserWarning' messages
like the following on new enough
versions of setuptools:

  UserWarning: Usage of dash-separated 'description-file' will not be
  supported in future versions. Please use the underscore name
  'description_file' instead

Change-Id: Ib931f73eaa2a71f49b7a00dad5ab44409c6aab2e
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/19/857019/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6a7b9685145714a93c6badd4af377608f05ec4f3,,description_file = README.rstauthor_email = openstack-discuss@lists.openstack.org home_page = https://opendev.org/openstack/monasca-ui python_requires = >=3.6,description-file = README.rstauthor-email = openstack-discuss@lists.openstack.org home-page = https://opendev.org/openstack/monasca-ui python-requires = >=3.6,4,4
openstack%2Fmonasca-ui~master~Ic22c8086ca1cfae7e44979b0a85ada1cf3b82e5b,openstack/monasca-ui,master,Ic22c8086ca1cfae7e44979b0a85ada1cf3b82e5b,Use py3 as the default runtime for tox,NEW,2022-09-12 08:16:33.000000000,2023-01-25 03:27:39.000000000,,"[{'_account_id': 22348}, {'_account_id': 29313}, {'_account_id': 32102}]","[{'number': 1, 'created': '2022-09-12 08:16:33.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/78ec784c31cbec2f5fd1c1f03380e6d747d828da', 'message': 'Use py3 as the default runtime for tox\n\nChange-Id: Ic22c8086ca1cfae7e44979b0a85ada1cf3b82e5b\n'}]",0,857020,78ec784c31cbec2f5fd1c1f03380e6d747d828da,4,3,1,32921,,,0,"Use py3 as the default runtime for tox

Change-Id: Ic22c8086ca1cfae7e44979b0a85ada1cf3b82e5b
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/20/857020/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,78ec784c31cbec2f5fd1c1f03380e6d747d828da,,"envlist = py3,pep8","envlist = py38,pep8",1,1
openstack%2Fswift~stable%2Ftrain~Ie29d9f76b1b0e231a7593277f189c029ff241c02,openstack/swift,stable/train,Ie29d9f76b1b0e231a7593277f189c029ff241c02,DNM: Also attempt to install bcrypt via wheel,ABANDONED,2023-01-24 00:45:11.000000000,2023-01-25 02:51:49.000000000,,[{'_account_id': 7233}],"[{'number': 1, 'created': '2023-01-24 00:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a3191ec0efda0c970332b019ef0b22b86417fe32', 'message': ""DNM: Also attempt to install bcrypt via wheel\n\nbcrypt is a crytography requirement and from bcrypt 4.0+ its now\nwritten in rust. We build cryptography so this in turn needs the rust\ncompiler.\nBut apparently the wheel doesn't, so add bcrypt to requirements before\ncrypograpy with a `--only-binary` in an attempt to force install bcrypt\nvia a wheel and avoid the need of a compiler.\n\n  ...\n  bcrypt --only-binary\n  cryptography>=2.0.2                     # BSD/Apache-2.0\n  ...\n\nChange-Id: Ie29d9f76b1b0e231a7593277f189c029ff241c02\n""}, {'number': 2, 'created': '2023-01-24 04:46:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/0825b5ccd6eda017aeea0ab42801dda9ef3c28cb', 'message': ""DNM: Also attempt to install bcrypt via wheel\n\nbcrypt is a crytography requirement and from bcrypt 4.0+ its now\nwritten in rust. We build cryptography so this in turn needs the rust\ncompiler.\nBut apparently the wheel doesn't, so add bcrypt to requirements before\ncrypograpy with a `--only-binary` in an attempt to force install bcrypt\nvia a wheel and avoid the need of a compiler.\n\n  ...\n  --only-binary=bcrypt\n  cryptography>=2.0.2                     # BSD/Apache-2.0\n  ...\n\nChange-Id: Ie29d9f76b1b0e231a7593277f189c029ff241c02\n""}]",0,871540,0825b5ccd6eda017aeea0ab42801dda9ef3c28cb,4,1,2,7233,,,0,"DNM: Also attempt to install bcrypt via wheel

bcrypt is a crytography requirement and from bcrypt 4.0+ its now
written in rust. We build cryptography so this in turn needs the rust
compiler.
But apparently the wheel doesn't, so add bcrypt to requirements before
crypograpy with a `--only-binary` in an attempt to force install bcrypt
via a wheel and avoid the need of a compiler.

  ...
  --only-binary=bcrypt
  cryptography>=2.0.2                     # BSD/Apache-2.0
  ...

Change-Id: Ie29d9f76b1b0e231a7593277f189c029ff241c02
",git fetch https://review.opendev.org/openstack/swift refs/changes/40/871540/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a3191ec0efda0c970332b019ef0b22b86417fe32,871232-patch1,bcrypt --only-binary,,1,0
openstack%2Fopenstack-ansible-rabbitmq_server~stable%2Fyoga~Iff473a20c4b586acfa11d67a9d6cc73d9518e8e1,openstack/openstack-ansible-rabbitmq_server,stable/yoga,Iff473a20c4b586acfa11d67a9d6cc73d9518e8e1,Bump erlang version to cover CVE-2022-37026,MERGED,2023-01-20 16:42:46.000000000,2023-01-25 02:50:41.000000000,2023-01-25 02:26:41.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2023-01-20 16:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/dc22eb76b11083a55bc7fa5c10214c7ba71c8acc', 'message': 'Bump erlang version to cover CVE-2022-37026\n\nChange-Id: Iff473a20c4b586acfa11d67a9d6cc73d9518e8e1\n'}, {'number': 2, 'created': '2023-01-21 10:46:51.000000000', 'files': ['releasenotes/notes/erlang_cve_37026-bdf6304e7772cf29.yaml', 'vars/redhat.yml', 'vars/debian.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/dffbf793ee0aa19ffc266a16ed0c7ce1f062f1d1', 'message': 'Bump erlang version to cover CVE-2022-37026\n\nChange-Id: Iff473a20c4b586acfa11d67a9d6cc73d9518e8e1\n'}]",2,871304,dffbf793ee0aa19ffc266a16ed0c7ce1f062f1d1,15,3,2,28619,,,0,"Bump erlang version to cover CVE-2022-37026

Change-Id: Iff473a20c4b586acfa11d67a9d6cc73d9518e8e1
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/04/871304/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/erlang_cve_37026-bdf6304e7772cf29.yaml', 'vars/redhat.yml', 'vars/debian.yml']",3,dc22eb76b11083a55bc7fa5c10214c7ba71c8acc,,"_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:24.3.4.7-1', '1:22.*') }}""","_rabbitmq_erlang_version_spec: ""{{ (rabbitmq_install_method == 'external_repo') | ternary('1:24.3.4-1', '1:22.*') }}""",7,2
openstack%2Fnova~master~I5a399f1d3d702bfb76c067893e9c924904c8c360,openstack/nova,master,I5a399f1d3d702bfb76c067893e9c924904c8c360,Check VMDK create-type against an allowed list,MERGED,2023-01-24 15:01:09.000000000,2023-01-25 01:52:35.000000000,2023-01-25 01:51:21.000000000,"[{'_account_id': 7166}, {'_account_id': 11583}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd1537e6142d5ece8c4511237d00aa94a8e4e528', 'message': 'Check VMDK create-type against an allowed list\n\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}, {'number': 2, 'created': '2023-01-24 15:01:44.000000000', 'files': ['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d1d2375c474f74b636cf55efa72c7f86fbf6c156', 'message': 'Check VMDK create-type against an allowed list\n\nRelated-Bug: #1996188\nChange-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360\n'}]",2,871612,d1d2375c474f74b636cf55efa72c7f86fbf6c156,18,4,2,4393,,,0,"Check VMDK create-type against an allowed list

Related-Bug: #1996188
Change-Id: I5a399f1d3d702bfb76c067893e9c924904c8c360
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/871612/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/compute.py', 'nova/tests/unit/virt/test_images.py', 'nova/virt/images.py']",3,fd1537e6142d5ece8c4511237d00aa94a8e4e528,bug/1996188,"def check_vmdk_image(image_id, data): # Check some rules about VMDK files. Specifically we want to make # sure that the ""create-type"" of the image is one that we allow. # Some types of VMDK files can reference files outside the disk # image and we do not want to allow those for obvious reasons. types = CONF.compute.vmdk_allowed_types if not len(types): LOG.warning('Refusing to allow VMDK image as vmdk_allowed_' 'types is empty') msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) try: create_type = data.format_specific['data']['create-type'] except KeyError: msg = _('Unable to determine VMDK create-type') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if create_type not in CONF.compute.vmdk_allowed_types: LOG.warning('Refusing to process VMDK file with create-type of %r ' 'which is not in allowed set of: %s', create_type, ','.join(CONF.compute.vmdk_allowed_types)) msg = _('Invalid VMDK create-type specified') raise exception.ImageUnacceptable(image_id=image_id, reason=msg) if fmt == 'vmdk': check_vmdk_image(image_href, data) ",,86,0
openstack%2Fpuppet-openstack_spec_helper~stable%2Fwallaby~Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,openstack/puppet-openstack_spec_helper,stable/wallaby,Id47cd5cc12a301d19bf0941c8a9dbabd13fab568,Pin concurrent-ruby,MERGED,2023-01-24 03:35:18.000000000,2023-01-25 01:47:21.000000000,2023-01-25 01:47:21.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 03:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/a3c04377cfaf232fb5a403b6ba3ab52dafd97fc5', 'message': ""Pin concurrent-ruby\n\nconcurrent-ruby 1.2.0 dropped the implementation which puppet still\nrelies on. Let's pin it to the older version to fix the broken tests\nwith old and current puppet versions.\n\nBackport note:\nBackport does not require disabling the puppet jobs because the failure\nis caused by the change which is present only in master atm.\n\nCloses-Bug: #2003761\nChange-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568\n(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)\n(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)\n(cherry picked from commit 193a8a69497111d47dfe3969b0964e2eb35f5f2c)\n""}, {'number': 2, 'created': '2023-01-24 08:57:47.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/effb21c271abb4adbbdd097419c567fd9aca3440', 'message': ""Pin concurrent-ruby\n\nconcurrent-ruby 1.2.0 dropped the implementation which puppet still\nrelies on. Let's pin it to the older version to fix the broken tests\nwith old and current puppet versions.\n\nBackport note:\nBackport does not require disabling the puppet jobs because the failure\nis caused by the change which is present only in master atm.\n\nCloses-Bug: #2003761\nChange-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568\n(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)\n(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)\n(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)\n(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)\n""}]",0,871546,effb21c271abb4adbbdd097419c567fd9aca3440,12,3,2,9816,,,0,"Pin concurrent-ruby

concurrent-ruby 1.2.0 dropped the implementation which puppet still
relies on. Let's pin it to the older version to fix the broken tests
with old and current puppet versions.

Backport note:
Backport does not require disabling the puppet jobs because the failure
is caused by the change which is present only in master atm.

Closes-Bug: #2003761
Change-Id: Id47cd5cc12a301d19bf0941c8a9dbabd13fab568
(cherry picked from commit b4633e6f1d7afff5198f9fcd0cd8276f90d845b6)
(cherry picked from commit 9d605e723619cf422a1d40bdb1365e334c58a2ca)
(cherry picked from commit 0d771f97c4a2579211506392cb561f1776efbc58)
(cherry picked from commit 8d8864885e8ba22d541b26bc3ad17bd8421a0633)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/46/871546/2 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,a3c04377cfaf232fb5a403b6ba3ab52dafd97fc5,bug/2003761," # NOTE(tkajinam): concurrent-ruby 1.2.0 dropped RubyThreadLocalVar, which is # still used by puppet as of 7.21.0. spec.add_dependency 'concurrent-ruby', ['< 1.2.0'] ",,4,0
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~Id093613f9d410eb3fe5564a724c0f75275eeb4e8,openstack/tripleo-heat-templates,stable/wallaby,Id093613f9d410eb3fe5564a724c0f75275eeb4e8,Deploy separate glance-api services for OSSN-0090,MERGED,2022-11-28 19:12:09.000000000,2023-01-25 01:06:45.000000000,2023-01-25 01:05:47.000000000,"[{'_account_id': 6796}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-11-28 19:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aafc6bbb0e141cf876b768ee8cdbca8524d33460', 'message': 'Deploy separate glance-api services for OSSN-0090\n\nThis patch adopts the recommendation outlined in  OSSN-0090 [1], in\nwhich two instances of the glance-api service are deployed:\n- A ""user facing"" glance-api service, accessible via the Public\n  keystone endpoint.\n- An ""internal facing only"" service, accessible via the Admin and\n  Internal keystone endpoints.\n\nThe user facing instance is configured so it does not report any image\nlocation information. This is achieved by configuring glance-api.conf\nwith the show_image_direct_url and show_multiple_locations set to False.\n\nThe internal service operates on a separate TCP port (defaults to 9293)\nwith its own glance-api.conf that configures show_image_direct_url and\nshow_multiple_locations set to True.\n\nIn order for cinder and nova to have access to the image location data,\nboth services are configured to access glance via the internal service.\n\n[1] https://wiki.openstack.org/wiki/OSSN/OSSN-0090\n\nstable/wallaby:\n  Minor conflicts were due to using the hiera() versus lookup() functions.\n  The biggest conflict was due to Ibf2e0d183dd51421c4feb7467c3c01fb416d2965,\n  in which the endpoint map is no longer generated from endpoint_data.yaml\n  (as it is in wallaby).\n\nCloses-Bug: #1822540\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/865884\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/865883\nChange-Id: Id093613f9d410eb3fe5564a724c0f75275eeb4e8\n(cherry picked from commit d60969cb55344e9004721dee04ed1d685d95a39f)\n(cherry picked from commit eacdf718fdef063ea5f8f5ec63acb3cf2c50cff8)\n'}, {'number': 2, 'created': '2023-01-23 14:53:43.000000000', 'files': ['ci/environments/scenario010-multinode-containers.yaml', 'roles/ControllerNovaStandalone.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'deployment/haproxy/haproxy-edge-container-puppet.yaml', 'roles_data.yaml', 'roles/ControllerStorageDashboard.yaml', 'network/endpoints/endpoint_map.yaml', 'roles/ControllerAllNovaStandalone.yaml', 'deployment/nova/nova-base-puppet.yaml', 'environments/ssl/tls-everywhere-endpoints-dns.yaml', 'network/endpoints/endpoint_data.yaml', 'roles/Controller.yaml', 'roles/ControllerOpenstack.yaml', 'deployment/glance/glance-api-internal-container-puppet.yaml', 'roles/Standalone.yaml', 'roles/ControllerStorageNfs.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'deployment/glance/glance-api-edge-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'sample-env-generator/ssl.yaml', 'ci/environments/scenario000-standalone.yaml', 'roles/ControllerNoCeph.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'ci/custom_ci_roles_data.yaml', 'releasenotes/notes/glance-internal-service-86274f56712ffaac.yaml', 'roles/ControllerSriov.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3605d45e417a77a1d0f153fbeffcbb283ec85fe6', 'message': 'Deploy separate glance-api services for OSSN-0090\n\nThis patch adopts the recommendation outlined in  OSSN-0090 [1], in\nwhich two instances of the glance-api service are deployed:\n- A ""user facing"" glance-api service, accessible via the Public\n  keystone endpoint.\n- An ""internal facing only"" service, accessible via the Admin and\n  Internal keystone endpoints.\n\nThe user facing instance is configured so it does not report any image\nlocation information. This is achieved by configuring glance-api.conf\nwith the show_image_direct_url and show_multiple_locations set to False.\n\nThe internal service operates on a separate TCP port (defaults to 9293)\nwith its own glance-api.conf that configures show_image_direct_url and\nshow_multiple_locations set to True.\n\nIn order for cinder and nova to have access to the image location data,\nboth services are configured to access glance via the internal service.\n\n[1] https://wiki.openstack.org/wiki/OSSN/OSSN-0090\n\nstable/zed:\n  Backports include I456b4235242cae125f5ad4cd9cc7415f2699462c, which\n  fixed a typo in the original patch.\n\nstable/wallaby:\n  Minor conflicts were due to using the hiera() versus lookup() functions.\n  The biggest conflict was due to Ibf2e0d183dd51421c4feb7467c3c01fb416d2965,\n  in which the endpoint map is no longer generated from endpoint_data.yaml\n  (as it is in wallaby).\n\nCloses-Bug: #1822540\nDepends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/865884\nDepends-On: https://review.opendev.org/c/openstack/tripleo-common/+/865883\nChange-Id: Id093613f9d410eb3fe5564a724c0f75275eeb4e8\n(cherry picked from commit d60969cb55344e9004721dee04ed1d685d95a39f)\n(cherry picked from commit 0ba612d07de84e95c0e11ef090bcd22f1da584e7)\n'}]",4,865885,3605d45e417a77a1d0f153fbeffcbb283ec85fe6,19,5,2,21129,,,0,"Deploy separate glance-api services for OSSN-0090

This patch adopts the recommendation outlined in  OSSN-0090 [1], in
which two instances of the glance-api service are deployed:
- A ""user facing"" glance-api service, accessible via the Public
  keystone endpoint.
- An ""internal facing only"" service, accessible via the Admin and
  Internal keystone endpoints.

The user facing instance is configured so it does not report any image
location information. This is achieved by configuring glance-api.conf
with the show_image_direct_url and show_multiple_locations set to False.

The internal service operates on a separate TCP port (defaults to 9293)
with its own glance-api.conf that configures show_image_direct_url and
show_multiple_locations set to True.

In order for cinder and nova to have access to the image location data,
both services are configured to access glance via the internal service.

[1] https://wiki.openstack.org/wiki/OSSN/OSSN-0090

stable/zed:
  Backports include I456b4235242cae125f5ad4cd9cc7415f2699462c, which
  fixed a typo in the original patch.

stable/wallaby:
  Minor conflicts were due to using the hiera() versus lookup() functions.
  The biggest conflict was due to Ibf2e0d183dd51421c4feb7467c3c01fb416d2965,
  in which the endpoint map is no longer generated from endpoint_data.yaml
  (as it is in wallaby).

Closes-Bug: #1822540
Depends-On: https://review.opendev.org/c/openstack/puppet-tripleo/+/865884
Depends-On: https://review.opendev.org/c/openstack/tripleo-common/+/865883
Change-Id: Id093613f9d410eb3fe5564a724c0f75275eeb4e8
(cherry picked from commit d60969cb55344e9004721dee04ed1d685d95a39f)
(cherry picked from commit 0ba612d07de84e95c0e11ef090bcd22f1da584e7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/865885/2 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario010-multinode-containers.yaml', 'roles/ControllerNovaStandalone.yaml', 'ci/environments/scenario007-multinode-containers.yaml', 'deployment/haproxy/haproxy-edge-container-puppet.yaml', 'roles_data.yaml', 'roles/ControllerStorageDashboard.yaml', 'network/endpoints/endpoint_map.yaml', 'roles/ControllerAllNovaStandalone.yaml', 'deployment/nova/nova-base-puppet.yaml', 'environments/ssl/tls-everywhere-endpoints-dns.yaml', 'network/endpoints/endpoint_data.yaml', 'roles/Controller.yaml', 'roles/ControllerOpenstack.yaml', 'deployment/glance/glance-api-internal-container-puppet.yaml', 'roles/Standalone.yaml', 'roles/ControllerStorageNfs.yaml', 'ci/environments/scenario001-multinode-containers.yaml', 'deployment/glance/glance-api-edge-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'sample-env-generator/ssl.yaml', 'ci/environments/scenario000-standalone.yaml', 'roles/ControllerNoCeph.yaml', 'ci/environments/multinode-containers.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'ci/custom_ci_roles_data.yaml', 'releasenotes/notes/glance-internal-service-86274f56712ffaac.yaml', 'roles/ControllerSriov.yaml']",27,aafc6bbb0e141cf876b768ee8cdbca8524d33460,glance-api-internal, - OS::TripleO::Services::GlanceApiInternal,,278,43
openstack%2Fswift~stable%2Ftrain~I61750a1083a1c97a6222ec9040f90980ee73acc8,openstack/swift,stable/train,I61750a1083a1c97a6222ec9040f90980ee73acc8,Fix stable/train gate,MERGED,2023-01-20 05:35:03.000000000,2023-01-25 00:40:26.000000000,2023-01-25 00:38:41.000000000,"[{'_account_id': 6968}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 05:35:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/00c877fb0691baacc216a14be9beb7553257d9d3', 'message': ""Add attrs to lower-constraints\n\nFuture work: Assuming we're going to keep the l-c job, we should make\nsure it fails if packages get installed that aren't in the constraints\nfile.\n\nChange-Id: I61750a1083a1c97a6222ec9040f90980ee73acc8\n(cherry picked from commit ee12a11e708fce6c982a85b58cd2c3899f13479e)\n""}, {'number': 2, 'created': '2023-01-23 18:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/025b81b9964ca7efc1efe72a84dc928d58c65b7d', 'message': ""Fix stable/train gate\n\nTwo things:\n\n* Add attrs to lower-constraints\n\n  (cherry picked from commit ee12a11e708fce6c982a85b58cd2c3899f13479e)\n\n* Drop tempest and grenade testing\n\n  Recently, these jobs started failing while installing tempest. The\n  trouble seems to be:\n\n  * tempest 26.1.0 depends on paramiko>=2.7.0\n  * paramiko 3.0.0 is selected which in turn depends on\n    cryptography >= 3.3 and bcrypt >= 3.2\n  * cryptography 39.0.0 and bcrypt 4.0.1 are selected, neither of which\n    get installed from binary wheels and both of which require a Rust\n    toolchain to compile\n\n  For some unknown reason, this used to be OK-ish -- the stable/train\n  upper-constraints file would be respected, paramiko==2.6.0 would be\n  installed with cryptography==2.8 and bcrypt==3.1.7, and pip would\n  simply warn\n\n    ERROR: tempest 26.1.0 has requirement paramiko>=2.7.0, but you'll\n    have paramiko 2.6.0 which is incompatible.\n\n  even though everything would still work. It's not at all clear how or\n  why this stopped working -- there haven't been any recent changes to\n  tempest's requirements or the stable/train constraints file, and the\n  version of pip is the same. Given the age of the branch and its\n  extended-maintenance state, dropping the testing seems best.\n\nChange-Id: I61750a1083a1c97a6222ec9040f90980ee73acc8\n""}, {'number': 3, 'created': '2023-01-23 19:47:14.000000000', 'files': ['.zuul.yaml', 'lower-constraints.txt'], 'web_link': 'https://opendev.org/openstack/swift/commit/91144596c670741c2f452c864c026eff5583989c', 'message': ""Fix stable/train gate\n\nTwo things:\n\n* Add attrs to lower-constraints\n\n  (cherry picked from commit ee12a11e708fce6c982a85b58cd2c3899f13479e)\n\n* Drop tempest and grenade testing\n\n  Recently, these jobs started failing while installing tempest. The\n  trouble seems to be:\n\n  * tempest 26.1.0 depends on paramiko>=2.7.0\n  * paramiko 3.0.0 is selected which in turn depends on\n    cryptography >= 3.3 and bcrypt >= 3.2\n  * cryptography 39.0.0 and bcrypt 4.0.1 are selected, neither of which\n    get installed from binary wheels and both of which require a Rust\n    toolchain to compile\n\n  For some unknown reason, this used to be OK-ish -- the stable/train\n  upper-constraints file would be respected, paramiko==2.6.0 would be\n  installed with cryptography==2.8 and bcrypt==3.1.7, and pip would\n  simply warn\n\n    ERROR: tempest 26.1.0 has requirement paramiko>=2.7.0, but you'll\n    have paramiko 2.6.0 which is incompatible.\n\n  even though everything would still work. It's not at all clear how or\n  why this stopped working -- there haven't been any recent changes to\n  tempest's requirements or the stable/train constraints file, and the\n  version of pip is the same. Given the age of the branch and its\n  extended-maintenance state, dropping the testing seems best.\n\nChange-Id: I61750a1083a1c97a6222ec9040f90980ee73acc8\n""}]",8,871232,91144596c670741c2f452c864c026eff5583989c,21,3,3,15343,,,0,"Fix stable/train gate

Two things:

* Add attrs to lower-constraints

  (cherry picked from commit ee12a11e708fce6c982a85b58cd2c3899f13479e)

* Drop tempest and grenade testing

  Recently, these jobs started failing while installing tempest. The
  trouble seems to be:

  * tempest 26.1.0 depends on paramiko>=2.7.0
  * paramiko 3.0.0 is selected which in turn depends on
    cryptography >= 3.3 and bcrypt >= 3.2
  * cryptography 39.0.0 and bcrypt 4.0.1 are selected, neither of which
    get installed from binary wheels and both of which require a Rust
    toolchain to compile

  For some unknown reason, this used to be OK-ish -- the stable/train
  upper-constraints file would be respected, paramiko==2.6.0 would be
  installed with cryptography==2.8 and bcrypt==3.1.7, and pip would
  simply warn

    ERROR: tempest 26.1.0 has requirement paramiko>=2.7.0, but you'll
    have paramiko 2.6.0 which is incompatible.

  even though everything would still work. It's not at all clear how or
  why this stopped working -- there haven't been any recent changes to
  tempest's requirements or the stable/train constraints file, and the
  version of pip is the same. Given the age of the branch and its
  extended-maintenance state, dropping the testing seems best.

Change-Id: I61750a1083a1c97a6222ec9040f90980ee73acc8
",git fetch https://review.opendev.org/openstack/swift refs/changes/32/871232/1 && git format-patch -1 --stdout FETCH_HEAD,['lower-constraints.txt'],1,00c877fb0691baacc216a14be9beb7553257d9d3,,attrs==21.4.0,,1,0
openstack%2Fopenstack-ansible-os_tempest~master~Id7fb7f53c2b099ee6f671350cf3cc896be5bf758,openstack/openstack-ansible-os_tempest,master,Id7fb7f53c2b099ee6f671350cf3cc896be5bf758,Add support for whitebox-neutron-tempest-plugin,MERGED,2023-01-17 14:16:46.000000000,2023-01-25 00:27:08.000000000,2023-01-25 00:26:10.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}, {'_account_id': 29350}, {'_account_id': 33341}]","[{'number': 1, 'created': '2023-01-17 14:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/5fc15ae642b37f43dce20faa08288cb9e3da7865', 'message': 'Add support for whitebox-neutron-tempest-plugin\n\nSigned-off-by: Chandan Kumar <chkumar@redhat.com>\nChange-Id: Id7fb7f53c2b099ee6f671350cf3cc896be5bf758\n'}, {'number': 2, 'created': '2023-01-19 04:52:19.000000000', 'files': ['vars/redhat-9.yml', 'vars/redhat-8.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/d8ddd9fcee7c1a25ceec8a8dc69369c446b21a9f', 'message': 'Add support for whitebox-neutron-tempest-plugin\n\nSigned-off-by: Chandan Kumar <chkumar@redhat.com>\nChange-Id: Id7fb7f53c2b099ee6f671350cf3cc896be5bf758\n'}]",0,870812,d8ddd9fcee7c1a25ceec8a8dc69369c446b21a9f,12,5,2,12393,,,0,"Add support for whitebox-neutron-tempest-plugin

Signed-off-by: Chandan Kumar <chkumar@redhat.com>
Change-Id: Id7fb7f53c2b099ee6f671350cf3cc896be5bf758
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/12/870812/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-9.yml', 'defaults/main.yml']",2,5fc15ae642b37f43dce20faa08288cb9e3da7865,,tempest_service_available_whitebox_neutron: False,,2,0
openstack%2Fansible-role-zookeeper~stable%2Fzed~I678d60f922273ead46ad51360b6b60a1a13e1f60,openstack/ansible-role-zookeeper,stable/zed,I678d60f922273ead46ad51360b6b60a1a13e1f60,Ensure zookeeper is not stopped after role re-run,MERGED,2023-01-24 14:40:51.000000000,2023-01-25 00:20:17.000000000,2023-01-25 00:19:17.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2023-01-24 14:40:51.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-zookeeper/commit/b64f07488c169966a284bd1b78481116a32f2ab2', 'message': 'Ensure zookeeper is not stopped after role re-run\n\nDue to mis-usage of systemd_service role inlcude, zookeeper service\nwas stopped on sequental role runs, when nothing was changed.\n\nChange-Id: I678d60f922273ead46ad51360b6b60a1a13e1f60\n(cherry picked from commit 6c79bd9bb51cf37c69419c930d27595656c579e5)\n'}]",0,871556,b64f07488c169966a284bd1b78481116a32f2ab2,8,3,1,28619,,,0,"Ensure zookeeper is not stopped after role re-run

Due to mis-usage of systemd_service role inlcude, zookeeper service
was stopped on sequental role runs, when nothing was changed.

Change-Id: I678d60f922273ead46ad51360b6b60a1a13e1f60
(cherry picked from commit 6c79bd9bb51cf37c69419c930d27595656c579e5)
",git fetch https://review.opendev.org/openstack/ansible-role-zookeeper refs/changes/56/871556/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,b64f07488c169966a284bd1b78481116a32f2ab2,, restart_changed: false, state: stopped,1,1
openstack%2Fproject-config~master~I23328cbc53b87e1e81d26cc56f99aaad33b415c0,openstack/project-config,master,I23328cbc53b87e1e81d26cc56f99aaad33b415c0,nodepool: fix new linaro provider name in nb04,MERGED,2023-01-24 22:07:41.000000000,2023-01-24 23:47:34.000000000,2023-01-24 23:38:55.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 22:07:41.000000000', 'files': ['nodepool/nb04.opendev.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/bd53b1c2b4324783d2b767784b7d6115b4b313ef', 'message': 'nodepool: fix new linaro provider name in nb04\n\nI have left the -regionone off this, making its naming inconsistent.\nThis adds it.\n\nSince this cloud is in its bringup phase, I will put the builder in\nemergency, clear out the images for the ""linaro"" provider and then\napply this by hand, so that we don\'t have old ZK nodes lying around.\nWe can then merge this to make it consistent.\n\nChange-Id: I23328cbc53b87e1e81d26cc56f99aaad33b415c0\n'}]",1,871666,bd53b1c2b4324783d2b767784b7d6115b4b313ef,8,3,1,7118,,,0,"nodepool: fix new linaro provider name in nb04

I have left the -regionone off this, making its naming inconsistent.
This adds it.

Since this cloud is in its bringup phase, I will put the builder in
emergency, clear out the images for the ""linaro"" provider and then
apply this by hand, so that we don't have old ZK nodes lying around.
We can then merge this to make it consistent.

Change-Id: I23328cbc53b87e1e81d26cc56f99aaad33b415c0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/871666/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nb04.opendev.org.yaml'],1,bd53b1c2b4324783d2b767784b7d6115b4b313ef,linaro-nodepool, - name: linaro-regionone, - name: linaro,1,1
openstack%2Fswift~stable%2Frocky~Ibe514a7ab22d475517b1efc50de676f47d741a4c,openstack/swift,stable/rocky,Ibe514a7ab22d475517b1efc50de676f47d741a4c,s3api: Use constant-time string comparisons in check_signature,MERGED,2023-01-24 20:25:51.000000000,2023-01-24 23:16:37.000000000,2023-01-24 23:16:37.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 20:25:51.000000000', 'files': ['swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/test_s3request.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/5591fa29589f587d7d37bec3a35d9122b57d8dc3', 'message': 's3api: Use constant-time string comparisons in check_signature\n\nChange-Id: Ibe514a7ab22d475517b1efc50de676f47d741a4c\n(cherry picked from commit 6142ce88cc71037ba0cd23113eb6082fa91346ac)\n'}]",1,871660,5591fa29589f587d7d37bec3a35d9122b57d8dc3,6,2,1,15343,,,0,"s3api: Use constant-time string comparisons in check_signature

Change-Id: Ibe514a7ab22d475517b1efc50de676f47d741a4c
(cherry picked from commit 6142ce88cc71037ba0cd23113eb6082fa91346ac)
",git fetch https://review.opendev.org/openstack/swift refs/changes/60/871660/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/s3request.py', 'test/unit/common/middleware/s3api/test_s3request.py']",2,5591fa29589f587d7d37bec3a35d9122b57d8dc3,," secret = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY' self.assertTrue(sigv2_req.check_signature(secret)) with patch('swift.common.middleware.s3api.s3request.streq_const_time', return_value=True) as mock_eq: self.assertTrue(sigv2_req.check_signature(secret)) mock_eq.assert_called_once()", self.assertTrue(sigv2_req.check_signature( 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY')),11,5
openstack%2Fcinder~stable%2Fzed~I3c60ee4c0795aadf03108ed9b5a46ecd116894af,openstack/cinder,stable/zed,I3c60ee4c0795aadf03108ed9b5a46ecd116894af,Check VMDK subformat against an allowed list,MERGED,2023-01-24 15:02:29.000000000,2023-01-24 23:08:20.000000000,2023-01-24 23:07:10.000000000,"[{'_account_id': 4523}, {'_account_id': 9236}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 35075}]","[{'number': 1, 'created': '2023-01-24 15:02:29.000000000', 'files': ['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ba37dc2ead69c08d7ede242295ff997086e6121d', 'message': 'Check VMDK subformat against an allowed list\n\nAlso add a more general check to convert_image that the image format\nreported by qemu-img matches what the caller says it is.\n\nChange-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af\nPartial-bug: #1996188\n(cherry picked from commit 930fc93e9fda82a4aa4568ae149c3c80af7379d0)\n'}]",4,871618,ba37dc2ead69c08d7ede242295ff997086e6121d,26,7,1,5314,,,0,"Check VMDK subformat against an allowed list

Also add a more general check to convert_image that the image format
reported by qemu-img matches what the caller says it is.

Change-Id: I3c60ee4c0795aadf03108ed9b5a46ecd116894af
Partial-bug: #1996188
(cherry picked from commit 930fc93e9fda82a4aa4568ae149c3c80af7379d0)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/18/871618/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/image_utils.py', 'cinder/tests/unit/test_image_utils.py', 'releasenotes/notes/bug-1996188-vmdk-subformat-allow-list-93e6943d9a486d11.yaml']",3,ba37dc2ead69c08d7ede242295ff997086e6121d,CVE-2022-47951,"--- upgrade: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. security: - | This release introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow in order to prevent exposure of host information by modifying the named extents in a VMDK image. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats, which do not use named extents. - | As part of the fix for `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_, cinder is now more strict in checking that the ``disk_format`` recorded for an image (as revealed by the Image Service API image-show response) matches what cinder detects when it downloads the image. Thus, some requests to create a volume from a source image that had previously succeeded may fail with an ``ImageUnacceptable`` error. fixes: - | `Bug #1996188 <https://bugs.launchpad.net/cinder/+bug/1996188>`_: Fixed issue where a VMDK image file whose createType allowed named extents could expose host information. This change introduces a new configuration option, ``vmdk_allowed_types``, that specifies the list of VMDK image subformats that Cinder will allow. The default setting allows only the 'streamOptimized' and 'monolithicSparse' subformats. ",,567,47
openstack%2Fswift~stable%2Fussuri~Ie22aabb0f6bde0d7f5df71de527d3201ba605181,openstack/swift,stable/ussuri,Ie22aabb0f6bde0d7f5df71de527d3201ba605181,Drop tempest and grenade testing,MERGED,2023-01-24 20:10:36.000000000,2023-01-24 23:01:48.000000000,2023-01-24 22:59:57.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 20:10:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/54e6afc9a98aa772a995befd29bc34908a5ea8cc', 'message': ""Drop tempest and grenade testing\n\nRecently, these jobs started failing while installing tempest. The\ntrouble seems to be:\n\n* tempest 26.1.0 depends on paramiko>=2.7.0\n* paramiko 3.0.0 is selected which in turn depends on\n  cryptography >= 3.3 and bcrypt >= 3.2\n* cryptography 39.0.0 and bcrypt 4.0.1 are selected, neither of which\n  get installed from binary wheels and both of which require a Rust\n  toolchain to compile\n\nFor some unknown reason, this used to be OK-ish -- the stable/train\nupper-constraints file would be respected, paramiko==2.6.0 would be\ninstalled with cryptography==2.8 and bcrypt==3.1.7, and pip would\nsimply warn\n\n    ERROR: tempest 26.1.0 has requirement paramiko>=2.7.0, but you'll\n    have paramiko 2.6.0 which is incompatible.\n\neven though everything would still work. Following the paramiko 3.0.0\nrelease, however, it stopped working and it's not entirely clear how to\nfix it. Given the age of the branch and its extended-maintenance state,\ndropping the testing seems best.\n\nChange-Id: Ie22aabb0f6bde0d7f5df71de527d3201ba605181\n""}]",1,871658,54e6afc9a98aa772a995befd29bc34908a5ea8cc,7,2,1,15343,,,0,"Drop tempest and grenade testing

Recently, these jobs started failing while installing tempest. The
trouble seems to be:

* tempest 26.1.0 depends on paramiko>=2.7.0
* paramiko 3.0.0 is selected which in turn depends on
  cryptography >= 3.3 and bcrypt >= 3.2
* cryptography 39.0.0 and bcrypt 4.0.1 are selected, neither of which
  get installed from binary wheels and both of which require a Rust
  toolchain to compile

For some unknown reason, this used to be OK-ish -- the stable/train
upper-constraints file would be respected, paramiko==2.6.0 would be
installed with cryptography==2.8 and bcrypt==3.1.7, and pip would
simply warn

    ERROR: tempest 26.1.0 has requirement paramiko>=2.7.0, but you'll
    have paramiko 2.6.0 which is incompatible.

even though everything would still work. Following the paramiko 3.0.0
release, however, it stopped working and it's not entirely clear how to
fix it. Given the age of the branch and its extended-maintenance state,
dropping the testing seems best.

Change-Id: Ie22aabb0f6bde0d7f5df71de527d3201ba605181
",git fetch https://review.opendev.org/openstack/swift refs/changes/58/871658/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,54e6afc9a98aa772a995befd29bc34908a5ea8cc,,, - integrated-gate-object-storage - tempest-integrated-object-storage: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$ - tempest-ipv6-only: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$ - grenade: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$ - tempest-integrated-object-storage: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$ - tempest-ipv6-only: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$ - grenade: irrelevant-files: - ^(api-ref|doc|releasenotes)/.*$ - ^test/.*$ - ^(.gitreview|.mailmap|AUTHORS|CHANGELOG)$,0,31
openstack%2Fglance~master~Idf561f6306cebf756c787d8eefdc452ce44bd5e0,openstack/glance,master,Idf561f6306cebf756c787d8eefdc452ce44bd5e0,Enforce image safety during image_conversion,MERGED,2023-01-24 15:01:12.000000000,2023-01-24 23:01:40.000000000,2023-01-24 22:59:54.000000000,"[{'_account_id': 8122}, {'_account_id': 9642}, {'_account_id': 11583}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 15:01:12.000000000', 'files': ['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/0d6282a01691cecc2798f7858b181c4bb30f850c', 'message': ""Enforce image safety during image_conversion\n\nThis does two things:\n\n1. It makes us check that the QCOW backing_file is unset on those\ntypes of images. Nova and Cinder do this already to prevent an\narbitrary (and trivial to accomplish) host file exposure exploit.\n2. It makes us restrict VMDK files to only allowed subtypes. These\nfiles can name arbitrary files on disk as extents, providing the\nsame sort of attack. Default that list to just the types we believe\nare actually useful for openstack, and which are monolithic.\n\nThe configuration option to specify allowed subtypes is added in\nglance's config and not in the import options so that we can extend\nthis check later to image ingest. The format_inspector can tell us\nwhat the type and subtype is, and we could reject those images early\nand even in the case where image_conversion is not enabled.\n\nCloses-Bug: #1996188\nChange-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0\n""}]",2,871613,0d6282a01691cecc2798f7858b181c4bb30f850c,15,5,1,9303,,,0,"Enforce image safety during image_conversion

This does two things:

1. It makes us check that the QCOW backing_file is unset on those
types of images. Nova and Cinder do this already to prevent an
arbitrary (and trivial to accomplish) host file exposure exploit.
2. It makes us restrict VMDK files to only allowed subtypes. These
files can name arbitrary files on disk as extents, providing the
same sort of attack. Default that list to just the types we believe
are actually useful for openstack, and which are monolithic.

The configuration option to specify allowed subtypes is added in
glance's config and not in the import options so that we can extend
this check later to image ingest. The format_inspector can tell us
what the type and subtype is, and we could reject those images early
and even in the case where image_conversion is not enabled.

Closes-Bug: #1996188
Change-Id: Idf561f6306cebf756c787d8eefdc452ce44bd5e0
",git fetch https://review.opendev.org/openstack/glance refs/changes/13/871613/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async_/flows/plugins/test_image_conversion.py', 'glance/common/config.py', 'glance/async_/flows/plugins/image_conversion.py']",3,0d6282a01691cecc2798f7858b181c4bb30f850c,glance-1996188," if 'backing-filename' in metadata: LOG.warning('Refusing to process QCOW image with a backing file') raise RuntimeError( 'QCOW images with backing files are not allowed') if metadata.get('format') == 'vmdk': create_type = metadata.get( 'format-specific', {}).get( 'data', {}).get('create-type') allowed = CONF.image_format.vmdk_allowed_types if not create_type: raise RuntimeError(_('Unable to determine VMDK create-type')) if not len(allowed): LOG.warning(_('Refusing to process VMDK file as ' 'vmdk_allowed_types is empty')) raise RuntimeError(_('Image is a VMDK, but no VMDK createType ' 'is specified')) if create_type not in allowed: LOG.warning(_('Refusing to process VMDK file with create-type ' 'of %r which is not in allowed set of: %s'), create_type, ','.join(allowed)) raise RuntimeError(_('Invalid VMDK create-type specified')) ",,82,0
openstack%2Frequirements~master~I29ee8fb08b170bcfa9b57c1a46be49fe673c666f,openstack/requirements,master,I29ee8fb08b170bcfa9b57c1a46be49fe673c666f,Remove anyjson,MERGED,2023-01-06 11:06:39.000000000,2023-01-24 22:58:23.000000000,2023-01-24 22:57:24.000000000,"[{'_account_id': 13252}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-06 11:06:39.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/257ee4c24e462dfa6c14dd4b82cf1bf736c17612', 'message': ""Remove anyjson\n\nNo active project is using this and isn't buildable in recent Python 3\ndue to use of 2to3.\n\nChange-Id: I29ee8fb08b170bcfa9b57c1a46be49fe673c666f\nSigned-off-by: Stephen Finucane <stephenfin@redhat.com>\n""}]",2,869445,257ee4c24e462dfa6c14dd4b82cf1bf736c17612,9,3,1,15334,,,0,"Remove anyjson

No active project is using this and isn't buildable in recent Python 3
due to use of 2to3.

Change-Id: I29ee8fb08b170bcfa9b57c1a46be49fe673c666f
Signed-off-by: Stephen Finucane <stephenfin@redhat.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/869445/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,257ee4c24e462dfa6c14dd4b82cf1bf736c17612,anyjson,,anyjson # BSD,0,1
openstack%2Fproject-config~master~Ia049a2e44d2c4add0346e8262b60cdfb2c976539,openstack/project-config,master,Ia049a2e44d2c4add0346e8262b60cdfb2c976539,nodepool: drop linaro-us,MERGED,2023-01-19 21:55:17.000000000,2023-01-24 22:43:45.000000000,2023-01-24 22:06:36.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-19 21:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7b8cf4c37f19be510329d94e3dccce3ec84ca76b', 'message': 'nodepool: drop linaro-us\n\nDrop the linaro-us cloud from nb04 uploads and launcher; it is\nreplaced by the new linaro cloud.  Region is not running any nodes\nsince I6ef17bb517078de363286ecad9749cb321b4c92c.\n\nnb03 is still in the inventory, but shutdown and in emergency.  We can\nremove the config here and cleanup will follow.\n\nChange-Id: Ia049a2e44d2c4add0346e8262b60cdfb2c976539\n'}, {'number': 2, 'created': '2023-01-20 06:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/18cc824eac936db300d70ec102897e44a1d1a8c3', 'message': 'nodepool: drop linaro-us\n\nDrop the linaro-us cloud from nb04 uploads and launcher; it is\nreplaced by the new linaro cloud.  Region is not running any nodes\nsince I6ef17bb517078de363286ecad9749cb321b4c92c.\n\nnb03 is still in the inventory, but shutdown and in emergency.  We can\nremove the config here and cleanup will follow.\n\nChange-Id: Ia049a2e44d2c4add0346e8262b60cdfb2c976539\n'}, {'number': 3, 'created': '2023-01-23 04:48:44.000000000', 'files': ['nodepool/nb04.opendev.org.yaml', 'nodepool/nl03.opendev.org.yaml', 'nodepool/nb03.opendev.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/212ad67630ddc5e1e81217765d1ac72f41838f39', 'message': 'nodepool: drop linaro-us\n\nDrop the linaro-us cloud from nb04 uploads and launcher; it is\nreplaced by the new linaro cloud.  Region is not running any nodes\nsince I6ef17bb517078de363286ecad9749cb321b4c92c.\n\nnb03 is still in the inventory, but shutdown and in emergency.  We can\nremove the config here and cleanup will follow.\n\nChange-Id: Ia049a2e44d2c4add0346e8262b60cdfb2c976539\n'}]",6,871196,212ad67630ddc5e1e81217765d1ac72f41838f39,16,4,3,7118,,,0,"nodepool: drop linaro-us

Drop the linaro-us cloud from nb04 uploads and launcher; it is
replaced by the new linaro cloud.  Region is not running any nodes
since I6ef17bb517078de363286ecad9749cb321b4c92c.

nb03 is still in the inventory, but shutdown and in emergency.  We can
remove the config here and cleanup will follow.

Change-Id: Ia049a2e44d2c4add0346e8262b60cdfb2c976539
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/871196/3 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nb04.opendev.org.yaml', 'nodepool/nl03.opendev.org.yaml', 'nodepool/nb03.opendev.org.yaml']",3,7b8cf4c37f19be510329d94e3dccce3ec84ca76b,linaro-nodepool,,"elements-dir: /etc/nodepool/elements images-dir: /opt/nodepool_dib # This portion of the config is updated by ansible to use the actual # zookeeper servers. zookeeper-servers: - host: zk01.example.org port: 2281 - host: zk02.example.org port: 2281 - host: zk03.example.org port: 2281 providers: - name: linaro-us-regionone region-name: 'RegionOne' cloud: linaro-us rate: 0.25 diskimages: &arm64_diskimages - name: ubuntu-bionic-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: ubuntu-focal-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: ubuntu-jammy-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: debian-bullseye-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: debian-buster-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: centos-8-stream-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: centos-9-stream-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: openEuler-22-03-LTS-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: rockylinux-9-arm64 pause: false config-drive: true meta: hw_firmware_type: uefi os_command_line: ""console=ttyAMA0"" hw_disk_bus: scsi hw_scsi_model: virtio-scsi - name: osuosl-regionone region-name: 'RegionOne' cloud: osuosl rate: 0.25 diskimages: *arm64_diskimages - name: linaro region-name: 'RegionOne' cloud: linaro rate: 0.25 diskimages: *arm64_diskimages diskimages: - name: base abstract: True elements: - block-device-efi - vm - simple-init - openstack-repos - nodepool-base - cache-devstack - initialize-urandom - growroot - infra-package-needs - journal-to-console env-vars: TMPDIR: /opt/dib_tmp DIB_CHECKSUM: '1' DIB_IMAGE_CACHE: /opt/dib_cache DIB_JOURNAL_SIZE: '512' DIB_GRUB_TIMEOUT: '0' GIT_HTTP_LOW_SPEED_TIME: '300' GIT_HTTP_LOW_SPEED_LIMIT: '1000' DIB_SHOW_IMAGE_USAGE: '1' ZUUL_USER_SSH_PUBLIC_KEY: | ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDh5u0DWNi0d3uqI82izAxVTUTrGl36L3szEqV9WrilGmxaTtp9X7HrktJ5J+rvxQqz39llTf1v7iYA4CNKto/48RBAB0mKEEI4x4iw+fu/BLU7nu7ewSfXLUxHahxaTgIk2KcbegknD5NzMjalyfNfgTPDGv8BjwHeeNdZmJMBvPFGu6fO48M4yK1tiQn0kAkaH4oII/M4pyF8vy9tPTODAD7RvnMvQAb08LZZvE/IPzJAHNXFRb1v+DBa38fOvdyaz/nibrsxiOWZxQVLgjYciUeDy1xvXADaWlqvxmLy+90LHbJFbGxK4AN0mWfwBiUMVyxZjkun39pjTNl2k09OhOq+R52UqnehMc4eBdZCddnCUq4/efbFCJkqe5wY+SE8fYybJjauUL64zyrwf6yfWkXvPVHWa9Y+NCmvH8PCBUcsQnwO7l/Yb4N+8+u6zkODyuc9wLAY+DpnptE3plXtvUs5negC4fvJSnOHpWXuoi9yzp7IlPf6fSjMMDQo0JjCYJwazdzqrIH2VSCcfHAqWF0ECR8IgwZV1bp0xFe0UN0Gjsgkozqf8rvs1AYyTSeD19Wg9j+crTke8E1sfoI/qFzHwzBQFKJ+2l0cs7pZWJBARlhbt1j1IouS2aH+74xwsavRhBz4IsFTPqWiP6JTrgk5cgKRnTqInzNfdaLeUw== zuul-worker@openstack.org - name: base-debuntu abstract: True parent: base env-vars: DIB_APT_LOCAL_CACHE: '0' DIB_DISABLE_APT_CLEANUP: '1' DIB_DEBOOTSTRAP_EXTRA_ARGS: '--no-check-gpg' ############ CentOS and Fedora (and derivatives) ############# - name: centos-7 elements: [] - name: centos-8-stream elements: [] - name: centos-9-stream elements: [] - name: rockylinux-8 elements: [] - name: rockylinux-9 elements: [] - name: fedora-35 elements: [] - name: fedora-36 elements: [] ############ Debian ############# - name: debian-buster elements: [] - name: debian-bullseye elements: [] ############ Gentoo ############# - name: gentoo-17-0-systemd elements: [] ############ openSUSE ############# - name: opensuse-15 elements: [] ############ Ubuntu ############# - name: ubuntu-bionic elements: [] - name: ubuntu-focal elements: [] - name: ubuntu-jammy elements: [] - name: ubuntu-xenial elements: [] ############ openEuler ############# - name: openEuler-22-03-LTS elements: [] ############ arm64 ############# - name: ubuntu-bionic-arm64 parent: base-debuntu elements: - ubuntu-minimal release: bionic env-vars: DIB_DISTRIBUTION_MIRROR: 'http://mirror.regionone.linaro-us.opendev.org/ubuntu-ports' DIB_DEBIAN_COMPONENTS: 'main,universe' - name: ubuntu-focal-arm64 parent: base-debuntu elements: - ubuntu-minimal release: focal env-vars: DIB_DISTRIBUTION_MIRROR: 'http://mirror.regionone.linaro-us.opendev.org/ubuntu-ports' DIB_DEBIAN_COMPONENTS: 'main,universe' - name: ubuntu-jammy-arm64 parent: base-debuntu elements: - ubuntu-minimal release: jammy env-vars: DIB_DISTRIBUTION_MIRROR: 'https://mirror.regionone.linaro-us.opendev.org/ubuntu-ports' DIB_DEBIAN_COMPONENTS: 'main,universe' - name: debian-bullseye-arm64 parent: base-debuntu python-path: /usr/bin/python3 elements: - debian-minimal release: bullseye env-vars: DIB_DISTRIBUTION_MIRROR: 'https://mirror.regionone.linaro-us.opendev.org/debian' - name: debian-buster-arm64 parent: base-debuntu elements: - debian-minimal release: buster env-vars: DIB_DISTRIBUTION_MIRROR: 'https://mirror.regionone.linaro-us.opendev.org/debian' - name: centos-8-stream-arm64 parent: base python-path: /usr/bin/python3 elements: - centos-minimal - epel release: 8-stream env-vars: DIB_EPEL_DISABLED: '1' - name: centos-9-stream-arm64 parent: base python-path: /usr/bin/python3 elements: - centos-minimal - epel release: 9-stream env-vars: DIB_EPEL_DISABLED: '1' - name: openEuler-22-03-LTS-arm64 parent: base python-path: /usr/bin/python3 elements: - openeuler-minimal release: 22.03-LTS env-vars: DIB_DISTRIBUTION_MIRROR: 'http://mirror.regionone.linaro-us.opendev.org/openeuler' - name: rockylinux-9-arm64 parent: base python-path: /usr/bin/python3 elements: - rocky-container - epel release: 9 ",2,370
openstack%2Fswift~master~Iea4f2a15f68bc806925ebd998db4510ee5be4859,openstack/swift,master,Iea4f2a15f68bc806925ebd998db4510ee5be4859,Tolerate ENOENT/ENOTEMPTY on cleanup when walking db data dirs,NEW,2022-02-25 17:58:20.000000000,2023-01-24 21:50:27.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-02-25 17:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/308695b1c4cf8be1d27f42e6f3e20f46c2267587', 'message': 'Tolerate ENOENT/ENOTEMPTY on cleanup when walking db data dirs\n\nChange-Id: Iea4f2a15f68bc806925ebd998db4510ee5be4859\n'}, {'number': 2, 'created': '2023-01-24 17:24:39.000000000', 'files': ['swift/common/db_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/96539712e1e2a393d6f220decd2c873437b0a858', 'message': 'Tolerate ENOENT/ENOTEMPTY on cleanup when walking db data dirs\n\nChange-Id: Iea4f2a15f68bc806925ebd998db4510ee5be4859\n'}]",0,831016,96539712e1e2a393d6f220decd2c873437b0a858,6,1,2,15343,,,0,"Tolerate ENOENT/ENOTEMPTY on cleanup when walking db data dirs

Change-Id: Iea4f2a15f68bc806925ebd998db4510ee5be4859
",git fetch https://review.opendev.org/openstack/swift refs/changes/16/831016/2 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/db_replicator.py'],1,308695b1c4cf8be1d27f42e6f3e20f46c2267587,," parse_db_filename, quote, RateLimitedIterator, remove_directory remove_directory(part_dir) remove_directory(suff_dir) remove_directory(hash_dir)"," parse_db_filename, quote, RateLimitedIterator os.rmdir(part_dir) os.rmdir(suff_dir) try: os.rmdir(hash_dir) except OSError as e: if e.errno != errno.ENOTEMPTY: raise",4,8
openstack%2Ftripleo-quickstart-extras~master~I9032fbebfa3deea52dd3d09e23abf9d578fa4315,openstack/tripleo-quickstart-extras,master,I9032fbebfa3deea52dd3d09e23abf9d578fa4315,Deploy MDS and NFS daemons during Ceph bootstrap,ABANDONED,2022-08-09 12:41:41.000000000,2023-01-24 21:35:46.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-08-09 12:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/eb2b8726b635415fd1ab437b12360b83d354abb3', 'message': ""Deploy MDS and NFS daemons during Ceph bootstrap\n\nDuring the ceph bootstrap phase Tripleo has the ability to define additional\nceph daemons that can be deployed.\nWe only support MDS and NFS at the moment, so we're adding these two\ndaemons in the ceph_daemon definition.\n\nDepends-On: Ida1429f237ec9d85c007c757581ee57a49ac3808\nChange-Id: I9032fbebfa3deea52dd3d09e23abf9d578fa4315\n""}, {'number': 2, 'created': '2022-08-09 16:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/74768c763f63aaed47dcabb5a61c52e78a2c3702', 'message': ""Deploy MDS and NFS daemons during Ceph bootstrap\n\nDuring the ceph bootstrap phase Tripleo has the ability to define additional\nceph daemons that can be deployed.\nWe only support MDS and NFS at the moment, so we're adding these two\ndaemons in the ceph_daemon definition.\n\nDepends-On: Ida1429f237ec9d85c007c757581ee57a49ac3808\nChange-Id: I9032fbebfa3deea52dd3d09e23abf9d578fa4315\n""}, {'number': 3, 'created': '2022-08-10 06:26:25.000000000', 'files': ['roles/standalone/tasks/ceph-install.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d0fbed77b6208c4611012c95dd016661bd61a0b2', 'message': ""Deploy MDS and NFS daemons during Ceph bootstrap\n\nDuring the ceph bootstrap phase Tripleo has the ability to define additional\nceph daemons that can be deployed.\nWe only support MDS and NFS at the moment, so we're adding these two\ndaemons in the ceph_daemon definition.\n\nDepends-On: Ida1429f237ec9d85c007c757581ee57a49ac3808\nChange-Id: I9032fbebfa3deea52dd3d09e23abf9d578fa4315\n""}]",0,852572,d0fbed77b6208c4611012c95dd016661bd61a0b2,18,2,3,25402,,,0,"Deploy MDS and NFS daemons during Ceph bootstrap

During the ceph bootstrap phase Tripleo has the ability to define additional
ceph daemons that can be deployed.
We only support MDS and NFS at the moment, so we're adding these two
daemons in the ceph_daemon definition.

Depends-On: Ida1429f237ec9d85c007c757581ee57a49ac3808
Change-Id: I9032fbebfa3deea52dd3d09e23abf9d578fa4315
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/72/852572/3 && git format-patch -1 --stdout FETCH_HEAD,['roles/standalone/tasks/ceph-install.yml'],1,eb2b8726b635415fd1ab437b12360b83d354abb3,ceph_nfs_deployed_ceph," ceph_daemons: ""{{ working_dir }}/ceph_daemons.yaml""- name: Create additional daemons file copy: dest: ""{{ ceph_daemons }}"" content: | ceph_nfs: cephfs_data: 'manila_data' cephfs_metadata: 'manila_metadata' tripleo_ceph_deploy_skip_ceph_ingress: true tripleo_ceph_deploy_daemons: ""{{ ceph_daemons }}""",,11,0
openstack%2Ftripleo-ansible~master~I02a446652ae0c1ef6de426f9325360d747a68b02,openstack/tripleo-ansible,master,I02a446652ae0c1ef6de426f9325360d747a68b02,Do not deploy ceph-nfs during the overcloud deploy,ABANDONED,2022-04-27 07:19:03.000000000,2023-01-24 21:35:31.000000000,,"[{'_account_id': 6413}, {'_account_id': 6796}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-04-27 07:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/52d1f0ca53bf3ba5da1be15c6c8d7b1bb7d626ae', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}, {'number': 2, 'created': '2022-04-27 07:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/72f6527bc89d7fba6b2795ec9f096be447e67d67', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}, {'number': 3, 'created': '2022-05-23 07:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2742d035521a43e66a82a69dc432ea6b92dcd58e', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}, {'number': 4, 'created': '2022-06-20 07:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cb4b3e0f76e3da11018375a8d062bde56f29584d', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}, {'number': 5, 'created': '2022-08-09 13:46:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/8e4645426f5957f03bf76bb1f2c2f8c30969eda2', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}, {'number': 6, 'created': '2022-08-10 07:05:18.000000000', 'files': ['tripleo_ansible/playbooks/cephadm.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e58bfa9ac3ca7a682f4f44c84c663c20b8089ac2', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: I02a446652ae0c1ef6de426f9325360d747a68b02\n'}]",5,839475,e58bfa9ac3ca7a682f4f44c84c663c20b8089ac2,31,5,6,25402,,,0,"Do not deploy ceph-nfs during the overcloud deploy

The set of patches [1] introduced the ability to deploy ceph-nfs and
the related ingress daemon using ""deployed ceph"".
This patch avoid/skip the deploy of a tripleo managed ganesha if it's
already deployed.

[1] https://review.opendev.org/q/topic:cephadm_ingress

Change-Id: I02a446652ae0c1ef6de426f9325360d747a68b02
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/75/839475/3 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/playbooks/cephadm.yml'],1,52d1f0ca53bf3ba5da1be15c6c8d7b1bb7d626ae,ceph_nfs_deployed_ceph, - not tripleo_cephadm_deployed_ceph | bool,,1,0
openstack%2Ftripleo-heat-templates~master~I80bc534f825d6a9c4e6cff628313ea091c284bb7,openstack/tripleo-heat-templates,master,I80bc534f825d6a9c4e6cff628313ea091c284bb7,Set CephRbdTrashSchedulerEnable default to true,ABANDONED,2022-09-01 06:38:15.000000000,2023-01-24 21:35:17.000000000,,"[{'_account_id': 4523}, {'_account_id': 6796}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2022-09-01 06:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04a71b1a28f8e5db96af32fdd7cc3dd833adcc36', 'message': 'Set CephRbdTrashSchedulerEnable default to true\n\nThis patch changes the boolean default used to enable the trash purge\nschedule interval on the cinder related pools.\n\nChange-Id: I80bc534f825d6a9c4e6cff628313ea091c284bb7\n'}, {'number': 2, 'created': '2022-09-05 05:37:20.000000000', 'files': ['deployment/cephadm/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5a3ad872ac6a29c40f6ba0cc2191947343c3dee9', 'message': 'Set CephRbdTrashSchedulerEnable default to true\n\nThis patch changes the boolean default used to enable the trash purge\nschedule interval on the cinder related pools.\n\nChange-Id: I80bc534f825d6a9c4e6cff628313ea091c284bb7\n'}]",4,855475,5a3ad872ac6a29c40f6ba0cc2191947343c3dee9,16,6,2,25402,,,0,"Set CephRbdTrashSchedulerEnable default to true

This patch changes the boolean default used to enable the trash purge
schedule interval on the cinder related pools.

Change-Id: I80bc534f825d6a9c4e6cff628313ea091c284bb7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/855475/2 && git format-patch -1 --stdout FETCH_HEAD,['deployment/cephadm/ceph-base.yaml'],1,04a71b1a28f8e5db96af32fdd7cc3dd833adcc36,, default: true, default: false,1,1
openstack%2Ftripleo-ansible~master~Ib4c429ae37ba58f33953630494fe230bdc64dfe8,openstack/tripleo-ansible,master,Ib4c429ae37ba58f33953630494fe230bdc64dfe8,WIP - Add Stable Floating VIP to tripleo when ceph_nfs is deployed,ABANDONED,2022-08-24 15:34:35.000000000,2023-01-24 21:35:05.000000000,,"[{'_account_id': 6796}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-08-24 15:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/172dbc735f67f55987b3ef0dfe75286d893b76fb', 'message': 'Import multiple grafana certificates\n\nAs per [1] we should be able to set a different config-key containing\nthe grafana cert/key made per-host.\nThis patch aligns the TripleO behavior to what Ceph expects when the\nmonitoring stack is deployed.\n\n[1] https://github.com/ceph/ceph/pull/47098\nChange-Id: I97878f178e904decdc01d4f2726fd02616e71dc0\n\nChange-Id: Ib4c429ae37ba58f33953630494fe230bdc64dfe8\n'}, {'number': 2, 'created': '2022-08-25 08:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fbc018e002f847aafdc7a641726308809e0ff389', 'message': ""WIP - Add Stable Floating VIP to tripleo when ceph_nfs is deployed\n\nCurrently the Ganesha model with the haproxy layer doesn't work\nproperly due to the issues when client restrictions are applied [0].\nThis patch aligns TripleO with change [1] to be able to support in\nCeph the old Active/Passive model (but using the new Manila driver).\n\n[0] https://tracker.ceph.com/issues/54470\n[1] https://github.com/ceph/ceph/pull/47199\n\nChange-Id: Ib4c429ae37ba58f33953630494fe230bdc64dfe8\n""}, {'number': 3, 'created': '2022-09-08 09:05:33.000000000', 'files': ['tripleo_ansible/roles/tripleo_cephadm/defaults/main.yml', 'tripleo_ansible/roles/tripleo_cephadm/tasks/monitoring.yaml', 'tripleo_ansible/roles/tripleo_cephadm/tasks/ceph_nfs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/a06310c54412950562b0a1807d12e68aa555655a', 'message': ""WIP - Add Stable Floating VIP to tripleo when ceph_nfs is deployed\n\nCurrently the Ganesha model with the haproxy layer doesn't work\nproperly due to the issues when client restrictions are applied [0].\nThis patch aligns TripleO with change [1] to be able to support in\nCeph the old Active/Passive model (but using the new Manila driver).\n\n[0] https://tracker.ceph.com/issues/54470\n[1] https://github.com/ceph/ceph/pull/47199\n\nChange-Id: Ib4c429ae37ba58f33953630494fe230bdc64dfe8\n""}]",0,854430,a06310c54412950562b0a1807d12e68aa555655a,13,4,3,25402,,,0,"WIP - Add Stable Floating VIP to tripleo when ceph_nfs is deployed

Currently the Ganesha model with the haproxy layer doesn't work
properly due to the issues when client restrictions are applied [0].
This patch aligns TripleO with change [1] to be able to support in
Ceph the old Active/Passive model (but using the new Manila driver).

[0] https://tracker.ceph.com/issues/54470
[1] https://github.com/ceph/ceph/pull/47199

Change-Id: Ib4c429ae37ba58f33953630494fe230bdc64dfe8
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/30/854430/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/roles/tripleo_cephadm/tasks/monitoring.yaml', 'tripleo_ansible/roles/tripleo_cephadm/tasks/dashboard/import_grafana_cert.yml']",2,172dbc735f67f55987b3ef0dfe75286d893b76fb,ceph_nfs_deployed_ceph,"--- # Copyright 2022 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. - name: Config ssl cert(s) and key(s) for the exposed components become: true block: - name: Get ceph_cli include_tasks: ceph_cli.yaml vars: mount_certs: true - name: import grafana certificate file command: ""{{ tripleo_cephadm_ceph_cli }} config-key set mgr/cephadm/{{ dashboard_backend }}/grafana_crt -i {{ tripleo_cephadm_grafana_crt }}"" changed_when: false delegate_to: ""{{ dashboard_backend }}"" - name: import grafana certificate key command: ""{{ tripleo_cephadm_ceph_cli }} config-key set mgr/cephadm/{{ dashboard_backend }}/grafana_key -i {{ tripleo_cephadm_grafana_key }}"" changed_when: false delegate_to: ""{{ dashboard_backend }}"" when: tripleo_cephadm_dashboard_protocol == ""https"" and tripleo_cephadm_grafana_crt | length > 0 and tripleo_cephadm_grafana_key | length > 0 ",,39,17
openstack%2Ftripleo-heat-templates~master~Iefbcbb3a55691268eb194253b30db34d767d89cd,openstack/tripleo-heat-templates,master,Iefbcbb3a55691268eb194253b30db34d767d89cd,Do not deploy ceph-nfs during the overcloud deploy,ABANDONED,2022-04-27 07:18:53.000000000,2023-01-24 21:34:38.000000000,,"[{'_account_id': 6796}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2022-04-27 07:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3fb2d0e114199b7586279936f4806ef7343f4845', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 2, 'created': '2022-05-02 13:38:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d1467cfd5caa54120d835fe4885d347c1c47edb8', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 3, 'created': '2022-05-02 16:51:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0448287557275c14eb04b3872cf9415e89403d42', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 4, 'created': '2022-05-09 10:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/daf54f99dc7e606398d2ff3f1d38235decf7baee', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nDepends-On: Ifc9a0a9ac2f13c891ccde826aef2ab7cbdb5d690\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 5, 'created': '2022-05-09 21:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/89a46cfaf86c09e70669c7f48dd076d22e31579a', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nDepends-On: Ifc9a0a9ac2f13c891ccde826aef2ab7cbdb5d690\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 6, 'created': '2022-05-10 06:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5124bd68f4319b5a2a672460e08e11b0447a9761', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 7, 'created': '2022-05-23 07:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/28bb13ddb712083e2b88722dd70edfa17d63dd7d', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 8, 'created': '2022-06-20 07:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e7a01a7f1024ebbc5ae15f30f30d9d38df897af3', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}, {'number': 9, 'created': '2022-08-09 13:47:25.000000000', 'files': ['deployment/cephadm/ceph-nfs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9adc1ae02412237365114d0bb3fe9b1805cee2f1', 'message': 'Do not deploy ceph-nfs during the overcloud deploy\n\nThe set of patches [1] introduced the ability to deploy ceph-nfs and\nthe related ingress daemon using ""deployed ceph"".\nThis patch avoid/skip the deploy of a tripleo managed ganesha if it\'s\nalready deployed.\n\n[1] https://review.opendev.org/q/topic:cephadm_ingress\n\nChange-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd\n'}]",2,839474,9adc1ae02412237365114d0bb3fe9b1805cee2f1,37,4,9,25402,,,0,"Do not deploy ceph-nfs during the overcloud deploy

The set of patches [1] introduced the ability to deploy ceph-nfs and
the related ingress daemon using ""deployed ceph"".
This patch avoid/skip the deploy of a tripleo managed ganesha if it's
already deployed.

[1] https://review.opendev.org/q/topic:cephadm_ingress

Change-Id: Iefbcbb3a55691268eb194253b30db34d767d89cd
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/839474/5 && git format-patch -1 --stdout FETCH_HEAD,['deployment/cephadm/ceph-nfs.yaml'],1,3fb2d0e114199b7586279936f4806ef7343f4845,ceph_nfs_deployed_ceph," DeployedCeph: default: false type: boolean description: | If the Ceph cluster has already been deployed but needs to be configured so that the overcloud can use it (create cephx keys, pools, configure RGW with haproxy, etc), then this parameter should be set to true. Set this parameter to false to have cephadm deploy the ceph cluster during overcloud deployment. DeployedCeph and CephDynamicSpec are mutually exclusive. if: - {get_param: DeployedCeph} - list_concat: - {get_attr: [CephBase, role_data, external_deploy_tasks]} - - name: ceph_nfs_external_deploy_init when: step|int == 1 block: - name: set tripleo-ansible group vars set_fact: ceph_nfs_vars: tripleo_ceph_client_config_home: {get_param: CephConfigPath} tripleo_cephadm_ceph_nfs_bind_addr: {get_param: [EndpointMap, GaneshaInternal, host_nobrackets]} tripleo_cephadm_ceph_nfs_enable_service: false tripleo_cephadm_ceph_nfs_use_pacemaker: true tripleo_cephadm_ceph_nfs_dynamic_exports: true tripleo_cephadm_ceph_nfs_service_suffix: pacemaker tripleo_cephadm_nfs_obj_gw: false tripleo_cephadm_ceph_nfs_rados_backend: true tripleo_cephadm_ceph_nfs_disable_caching: true tripleo_cephadm_ceph_nfs_ceph_user: {get_param: ManilaCephFSCephFSAuthId} tripleo_cephadm_idmap_conf: {get_param: ManilaCephFSNFSIdmapConf} tripleo_cephadm_idmap_overrides: {get_param: ManilaCephFSNFSIdmapOverrides} tripleo_cephadm_ganesha_address_block: list_join: - ',' - get_param: [ServiceData, net_cidr_map, {get_param: [ServiceNetMap, GaneshaNetwork]}]"," list_concat: - {get_attr: [CephBase, role_data, external_deploy_tasks]} - - name: ceph_nfs_external_deploy_init when: step|int == 1 block: - name: set tripleo-ansible group vars set_fact: ceph_nfs_vars: tripleo_ceph_client_config_home: {get_param: CephConfigPath} tripleo_cephadm_ceph_nfs_bind_addr: {get_param: [EndpointMap, GaneshaInternal, host_nobrackets]} tripleo_cephadm_ceph_nfs_enable_service: false tripleo_cephadm_ceph_nfs_use_pacemaker: true tripleo_cephadm_ceph_nfs_dynamic_exports: true tripleo_cephadm_ceph_nfs_service_suffix: pacemaker tripleo_cephadm_nfs_obj_gw: false tripleo_cephadm_ceph_nfs_rados_backend: true tripleo_cephadm_ceph_nfs_disable_caching: true tripleo_cephadm_ceph_nfs_ceph_user: {get_param: ManilaCephFSCephFSAuthId} tripleo_cephadm_idmap_conf: {get_param: ManilaCephFSNFSIdmapConf} tripleo_cephadm_idmap_overrides: {get_param: ManilaCephFSNFSIdmapOverrides} tripleo_cephadm_ganesha_address_block: list_join: - ',' - get_param: [ServiceData, net_cidr_map, {get_param: [ServiceNetMap, GaneshaNetwork]}]",35,24
openstack%2Ftempest~master~I572682254fbc1c69b9425783dca2e591e714082c,openstack/tempest,master,I572682254fbc1c69b9425783dca2e591e714082c,Add check against allowed_digests in temp_url tests,ABANDONED,2022-07-14 13:19:12.000000000,2023-01-24 21:28:32.000000000,,"[{'_account_id': 6968}, {'_account_id': 8367}, {'_account_id': 9976}, {'_account_id': 10459}, {'_account_id': 11075}, {'_account_id': 15343}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 22873}, {'_account_id': 25402}, {'_account_id': 34120}]","[{'number': 1, 'created': '2022-07-14 13:19:12.000000000', 'files': ['tempest/api/object_storage/test_object_temp_url_negative.py', 'tempest/api/object_storage/test_object_temp_url.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d414cf48457ae8413d36b2e1865d93647ea8cd91', 'message': 'Add check against allowed_digests in temp_url tests\n\nThis is so that we continue to use sha1 when sha256 is not available,\nsuch as when testing against Ceph RadosGW or other Swift compatible\nimplementations.\n\nChange-Id: I572682254fbc1c69b9425783dca2e591e714082c\n'}]",13,849857,d414cf48457ae8413d36b2e1865d93647ea8cd91,19,11,1,6796,,,0,"Add check against allowed_digests in temp_url tests

This is so that we continue to use sha1 when sha256 is not available,
such as when testing against Ceph RadosGW or other Swift compatible
implementations.

Change-Id: I572682254fbc1c69b9425783dca2e591e714082c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/849857/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/object_storage/test_object_temp_url_negative.py', 'tempest/api/object_storage/test_object_temp_url.py']",2,d414cf48457ae8413d36b2e1865d93647ea8cd91,," # get capabilities and find supported digest algos capabilities = cls.capabilities_client.list_capabilities() cls.digests = capabilities.get( 'tempurl', {}).get( 'allowed_digests', []) hlib = hashlib.sha256 if 'sha256' in self.digests else hashlib.sha1 key.encode(), hmac_body.encode(), hlib"," key.encode(), hmac_body.encode(), hashlib.sha256",17,2
openstack%2Fopenstack-helm-images~master~I82e25df4ce410b9d238703c6814e492ee619bc8d,openstack/openstack-helm-images,master,I82e25df4ce410b9d238703c6814e492ee619bc8d,Update Focal-based Ceph images to Quincy,MERGED,2023-01-17 20:02:20.000000000,2023-01-24 20:10:51.000000000,2023-01-24 20:09:44.000000000,"[{'_account_id': 8898}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 20:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/30fa197d535599b7c5acac7c55813965ae97ee13', 'message': 'Update Focal-based Ceph images to Quincy\n\nUpdate the Focal Dockerfiles for all Ceph images from the Pacific\n16.2.10 release to Quincy 17.2.5.\n\nChange-Id: I82e25df4ce410b9d238703c6814e492ee619bc8d\n'}, {'number': 2, 'created': '2023-01-17 20:22:59.000000000', 'files': ['ceph-cephfs-provisioner/Dockerfile.ubuntu_focal', 'ceph-config-helper/Dockerfile.ubuntu_focal', 'ceph-daemon/Dockerfile.ubuntu_focal', 'ceph-utility/Dockerfile.ubuntu_focal', 'ceph-rbd-provisioner/Dockerfile.ubuntu_focal', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/3fa2d51130f8946fb91c45b59d81c1ad5deff36d', 'message': 'Update Focal-based Ceph images to Quincy\n\nUpdate the Focal Dockerfiles for all Ceph images from the Pacific\n16.2.10 release to Quincy 17.2.5.\n\nChange-Id: I82e25df4ce410b9d238703c6814e492ee619bc8d\n'}]",0,870864,3fa2d51130f8946fb91c45b59d81c1ad5deff36d,9,3,2,29974,,,0,"Update Focal-based Ceph images to Quincy

Update the Focal Dockerfiles for all Ceph images from the Pacific
16.2.10 release to Quincy 17.2.5.

Change-Id: I82e25df4ce410b9d238703c6814e492ee619bc8d
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/64/870864/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-cephfs-provisioner/Dockerfile.ubuntu_focal', 'ceph-config-helper/Dockerfile.ubuntu_focal', 'ceph-daemon/Dockerfile.ubuntu_focal', 'ceph-utility/Dockerfile.ubuntu_focal', 'ceph-rbd-provisioner/Dockerfile.ubuntu_focal']",5,30fa197d535599b7c5acac7c55813965ae97ee13,,# Quincy 17.2.5 ARG CEPH_RELEASE=quincy ARG CEPH_RELEASE_TAG=17.2.5-1focal ARG CEPH_REPO=https://mirror.mirantis.com/acicd/ceph-quincy/ ARG CEPH_KEY=https://mirror.mirantis.com/acicd/ceph-quincy/release.asc,# Pacific 16.2.10 ARG CEPH_RELEASE=pacific ARG CEPH_RELEASE_TAG=16.2.10-1focal ARG CEPH_REPO=https://mirror.mirantis.com/acicd/ceph-pacific/ ARG CEPH_KEY=https://mirror.mirantis.com/acicd/ceph-pacific/release.asc,25,25
openstack%2Fcharm-trilio-dm-api~stable%2F4.2~Id8562fae4d45f1e9350c1edd0a8f902417630c24,openstack/charm-trilio-dm-api,stable/4.2,Id8562fae4d45f1e9350c1edd0a8f902417630c24,Pin tox to < 4.0.0,NEW,2023-01-20 20:21:01.000000000,2023-01-24 19:54:08.000000000,,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 20:21:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-trilio-dm-api/commit/ff1418106bb2796a03befb553bd82d3b9ce8f5cd', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Id8562fae4d45f1e9350c1edd0a8f902417630c24\n""}]",5,871378,ff1418106bb2796a03befb553bd82d3b9ce8f5cd,11,3,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Id8562fae4d45f1e9350c1edd0a8f902417630c24
",git fetch https://review.opendev.org/openstack/charm-trilio-dm-api refs/changes/78/871378/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ff1418106bb2796a03befb553bd82d3b9ce8f5cd,pin-tox-stable-trilio,requires = tox < 4.0.0,,2,0
openstack%2Fproject-config~master~Icf7b00f88a9de8a91510ee231c47eef207da4ea8,openstack/project-config,master,Icf7b00f88a9de8a91510ee231c47eef207da4ea8,nodepool: empty linaro-us cloud,MERGED,2023-01-20 06:17:08.000000000,2023-01-24 19:52:42.000000000,2023-01-24 19:44:25.000000000,"[{'_account_id': 4146}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 06:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d9a35d881bc871d153062cb6813ed667c85b4038', 'message': ""nodepool: empty linaro-us cloud\n\nThis should remove nodepool's tracking of the diskimages in this\ncloud, in preparation for it's removal.\n\nChange-Id: Icf7b00f88a9de8a91510ee231c47eef207da4ea8\n""}, {'number': 2, 'created': '2023-01-23 04:48:44.000000000', 'files': ['nodepool/nb04.opendev.org.yaml', 'nodepool/nl03.opendev.org.yaml', 'nodepool/nb03.opendev.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0cf9319b0682d1f2228ef6bf8697f01c8056255c', 'message': ""nodepool: empty linaro-us cloud\n\nThis should remove nodepool's tracking of the diskimages in this\ncloud, in preparation for it's removal.\n\nChange-Id: Icf7b00f88a9de8a91510ee231c47eef207da4ea8\n""}]",7,871220,0cf9319b0682d1f2228ef6bf8697f01c8056255c,14,3,2,7118,,,0,"nodepool: empty linaro-us cloud

This should remove nodepool's tracking of the diskimages in this
cloud, in preparation for it's removal.

Change-Id: Icf7b00f88a9de8a91510ee231c47eef207da4ea8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/871220/2 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nb04.opendev.org.yaml', 'nodepool/nl03.opendev.org.yaml', 'nodepool/nb03.opendev.org.yaml']",3,d9a35d881bc871d153062cb6813ed667c85b4038,linaro-nodepool, - name: linaro-regionone cloud: linaro # NOTE(ianw) 2023-01-20 : set to empty to clear out ZK nodes. - name: linaro-us cloud: linaro-us diskimages: [], - name: linaro-us-regionone cloud: linaro-us - name: linaro cloud: linaro diskimages: *arm64_diskimages,13,82
openstack%2Fos-brick~master~I16548244e6c6d019e8adeeb643a4b1544994ae5b,openstack/os-brick,master,I16548244e6c6d019e8adeeb643a4b1544994ae5b,Bump mypy version to 0.982,MERGED,2022-11-15 18:07:56.000000000,2023-01-24 19:42:26.000000000,2023-01-24 19:41:17.000000000,"[{'_account_id': 5314}, {'_account_id': 13425}, {'_account_id': 20813}, {'_account_id': 22348}, {'_account_id': 27615}, {'_account_id': 32074}, {'_account_id': 34201}, {'_account_id': 35075}]","[{'number': 1, 'created': '2022-11-15 18:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/7f026962ee5b3b2c01226633ff43f65210ed704f', 'message': 'Bump mypy version to 0.982\n\nChange-Id: I16548244e6c6d019e8adeeb643a4b1544994ae5b\n'}, {'number': 2, 'created': '2023-01-20 17:55:38.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6ac170cbc11e029b8b4ff400c1b2a35e7e65feb1', 'message': 'Bump mypy version to 0.982\n\nChange-Id: I16548244e6c6d019e8adeeb643a4b1544994ae5b\n'}]",9,864289,6ac170cbc11e029b8b4ff400c1b2a35e7e65feb1,27,8,2,4523,,,0,"Bump mypy version to 0.982

Change-Id: I16548244e6c6d019e8adeeb643a4b1544994ae5b
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/89/864289/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,7f026962ee5b3b2c01226633ff43f65210ed704f,,mypy>=0.982 # MIT,mypy>=0.960 # MIT,1,1
openstack%2Fcinder~master~I9562cc61022aad5bbad12fefbeb6d3f136486c18,openstack/cinder,master,I9562cc61022aad5bbad12fefbeb6d3f136486c18,[SVf] As part of Flashcopy 2.0 adding config parameter to support volumegroup,ABANDONED,2023-01-23 16:26:18.000000000,2023-01-24 19:32:00.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2023-01-23 16:26:18.000000000', 'files': ['releasenotes/notes/ibm-svf-volumegroup-configuration-parameter-44fe67bebe284191.yaml', 'cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/106bba9b121ad54ad92a598e43f181471a67451b', 'message': '[SVf] As part of Flashcopy 2.0 adding config parameter to support volumegroup\n\n[Spectrum Virtualize family] As part of Flashcopy 2.0 implementation,\nadded configuration parameter storwize_volume_group to support volume\ngroup feature.\n\nImplements: blueprint ibm-svf-volumegroup\nChange-Id: I9562cc61022aad5bbad12fefbeb6d3f136486c18\n'}]",1,871256,106bba9b121ad54ad92a598e43f181471a67451b,20,1,1,35679,,,0,"[SVf] As part of Flashcopy 2.0 adding config parameter to support volumegroup

[Spectrum Virtualize family] As part of Flashcopy 2.0 implementation,
added configuration parameter storwize_volume_group to support volume
group feature.

Implements: blueprint ibm-svf-volumegroup
Change-Id: I9562cc61022aad5bbad12fefbeb6d3f136486c18
",git fetch https://review.opendev.org/openstack/cinder refs/changes/56/871256/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ibm-svf-volumegroup-configuration-parameter-44fe67bebe284191.yaml', 'cinder/tests/unit/volume/drivers/ibm/test_storwize_svc.py', 'cinder/volume/drivers/ibm/storwize_svc/storwize_svc_common.py']",3,106bba9b121ad54ad92a598e43f181471a67451b,bp/ibm-svf-volumegroup," cfg.BoolOpt('storwize_volume_group', default=False, help='Parameter to enable or disable Volume Group' '(True/False)'), storwize_volume_group = self.configuration.safe_get( 'storwize_volume_group') LOG.info('CONFIG:value of storwize_volume_group' ' is %s', storwize_volume_group) if volume_utils.is_group_a_type(group, ""volume_group_enabled""): if storwize_volume_group: try: self._helpers.check_codelevel_for_volumegroup( self._state['code_level']) for vol_type_id in group.volume_type_ids: replication_type = self._get_volume_replicated_type( context, None, vol_type_id) if replication_type: # An unsupported configuration LOG.error('Unable to create group: ' 'volume_group_enabled group with ' 'replication volume type is ' 'not supported.') model_update = {'status': fields.GroupStatus.ERROR} return model_update opts = self._get_vdisk_params(vol_type_id) if opts['volume_topology']: # An unsupported configuration LOG.error('Unable to create group: ' 'volume_group_enabled group with a ' 'hyperswap volume type is ' 'not supported.') model_update = {'status': fields.GroupStatus.ERROR} return model_update volumegroup_name = self._get_volumegroup_name(group) self._helpers.create_volumegroup(volumegroup_name) except exception.VolumeBackendAPIException as err: LOG.error(""Failed to create volume group %(volumegroup)s. "" ""Exception: %(exception)s."", {'volumegroup': volumegroup_name, 'exception': err}) model_update = {'status': fields.GroupStatus.ERROR} return model_update else: LOG.error('Unable to create group: create volume group with' ' storwize_volume_group value set to False' ' in the configuration.')"," if volume_utils.is_group_a_type(group, ""volume_group_enabled""): try: self._helpers.check_codelevel_for_volumegroup( self._state['code_level']) volumegroup_name = self._get_volumegroup_name(group) self._helpers.create_volumegroup(volumegroup_name) except exception.VolumeBackendAPIException as err: LOG.error(""Failed to create volume group %(volumegroup)s. "" ""Exception: %(exception)s."", {'volumegroup': volumegroup_name, 'exception': err})",96,9
openstack%2Fpuppet-neutron~master~I2a786201cc6deb28826dc2eb7fe74d321749acb8,openstack/puppet-neutron,master,I2a786201cc6deb28826dc2eb7fe74d321749acb8,Clear [ovs] bridge_mappings by default,MERGED,2023-01-19 10:34:34.000000000,2023-01-24 19:25:27.000000000,2023-01-24 19:25:27.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-19 10:34:34.000000000', 'files': ['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/22dca13f47351e49cdbaf9108185dc2c1a2d601e', 'message': 'Clear [ovs] bridge_mappings by default\n\n... instead of leaving it unmanaged.\n\nChange-Id: I2a786201cc6deb28826dc2eb7fe74d321749acb8\n'}]",3,871078,22dca13f47351e49cdbaf9108185dc2c1a2d601e,15,3,1,9816,,,0,"Clear [ovs] bridge_mappings by default

... instead of leaving it unmanaged.

Change-Id: I2a786201cc6deb28826dc2eb7fe74d321749acb8
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/78/871078/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp']",2,22dca13f47351e49cdbaf9108185dc2c1a2d601e,bug/2003324, } else { neutron_agent_ovs { 'ovs/bridge_mappings': ensure => absent },,5,0
openstack%2Foctavia~master~I2df8a49851feb1445b5128ce99b880ddb77782ad,openstack/octavia,master,I2df8a49851feb1445b5128ce99b880ddb77782ad,Filter out details from taskflow logs with v2+jobboard,MERGED,2023-01-23 12:52:04.000000000,2023-01-24 19:25:11.000000000,2023-01-24 19:23:57.000000000,"[{'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 34429}]","[{'number': 1, 'created': '2023-01-23 12:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/13ae04fa8cbaadfc664d1e1d2a78849acd6313ff', 'message': ""Filter out details from taskflow logs with v2+jobboard\n\nWhen enabling INFO-level logs in taskflow and using jobboard with\namphorav2, taskflow prints the string representation of a job when it is\ncompleted. It includes the parameters of the flow, which might include\nprivate information from TLS-enabled listeners and pools such as\ncertificates, private_key and intermediate certificates.\n\nThis commit filters out the private information from the logs by using\nlogging.Filter, it replaces private attributes with '***'.\n\nStory 2010523\nTask 47125\n\nChange-Id: I2df8a49851feb1445b5128ce99b880ddb77782ad\n""}, {'number': 2, 'created': '2023-01-23 13:48:01.000000000', 'files': ['octavia/common/base_taskflow.py', 'octavia/tests/unit/common/test_base_taskflow.py', 'releasenotes/notes/filter-out-private-information-from-taskflow-logs-0d8697140423b4d5.yaml'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6c731fa2fdcb4f316fbf65b8d89b24f4c4f277bc', 'message': ""Filter out details from taskflow logs with v2+jobboard\n\nWhen enabling INFO-level logs in taskflow and using jobboard with\namphorav2, taskflow prints the string representation of a job when it is\ncompleted. It includes the parameters of the flow, which might include\nprivate information from TLS-enabled listeners and pools such as\ncertificates, private_key and intermediate certificates.\n\nThis commit filters out the private information from the logs by using\nlogging.Filter, it replaces private attributes with '***'.\n\nStory 2010523\nTask 47125\n\nChange-Id: I2df8a49851feb1445b5128ce99b880ddb77782ad\n""}]",5,871468,6c731fa2fdcb4f316fbf65b8d89b24f4c4f277bc,11,3,2,29244,,,0,"Filter out details from taskflow logs with v2+jobboard

When enabling INFO-level logs in taskflow and using jobboard with
amphorav2, taskflow prints the string representation of a job when it is
completed. It includes the parameters of the flow, which might include
private information from TLS-enabled listeners and pools such as
certificates, private_key and intermediate certificates.

This commit filters out the private information from the logs by using
logging.Filter, it replaces private attributes with '***'.

Story 2010523
Task 47125

Change-Id: I2df8a49851feb1445b5128ce99b880ddb77782ad
",git fetch https://review.opendev.org/openstack/octavia refs/changes/68/871468/2 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/base_taskflow.py', 'octavia/tests/unit/common/test_base_taskflow.py', 'releasenotes/notes/filter-out-private-information-from-taskflow-logs-0d8697140423b4d5.yaml']",3,13ae04fa8cbaadfc664d1e1d2a78849acd6313ff,,"--- security: - | Filter out private information from the taskflow logs when ''INFO'' level messages are enabled and when jobboard is enabled. Logs might have included TLS certificates and private_key. By default, in Octavia only WARNING and above messages are enabled in taskflow and jobboard is disabled. fixes: - | The parameters of a taskflow Flow were logged in ''INFO'' level messages by taskflow, it included TLS-enabled listeners and pools parameters, such as certificates and private_key. ",,116,0
openstack%2Fironic~bugfix%2F19.0~Ice764866a08647031d16570860ec384204269501,openstack/ironic,bugfix/19.0,Ice764866a08647031d16570860ec384204269501,Prevent pxe retry when agent token exists,MERGED,2022-12-19 20:03:15.000000000,2023-01-24 19:00:41.000000000,2023-01-24 18:59:07.000000000,"[{'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2022-12-19 20:03:15.000000000', 'files': ['ironic/drivers/modules/pxe_base.py', 'ironic/tests/unit/drivers/modules/test_pxe.py', 'releasenotes/notes/prevent-pxe-retry-when-token-exists-a4f38f7da56c1397.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/7ededc03f5a669008f597a9359ae65f890b2ebd2', 'message': ""Prevent pxe retry when agent token exists\n\nA race condition can be observed in CI under heavy load where the\nconductor triggers are boot of the agent before it is fully online\nbased upon state, but not considering the existence of an agent\ntoken. As a result, agent is never able to check in with Ironic\nand the overall operation fails.\n\nWe now consider agent token's existence before retrying PXE as\nit is the very earliest indicator of a starting agent.\n\nChange-Id: Ice764866a08647031d16570860ec384204269501\nStory: 2010107\nTask: 45674\n(cherry picked from commit d75424b5e5685a9cf04b30a5b0555efd1313e9c3)\n""}]",5,868027,7ededc03f5a669008f597a9359ae65f890b2ebd2,16,2,1,6618,,,0,"Prevent pxe retry when agent token exists

A race condition can be observed in CI under heavy load where the
conductor triggers are boot of the agent before it is fully online
based upon state, but not considering the existence of an agent
token. As a result, agent is never able to check in with Ironic
and the overall operation fails.

We now consider agent token's existence before retrying PXE as
it is the very earliest indicator of a starting agent.

Change-Id: Ice764866a08647031d16570860ec384204269501
Story: 2010107
Task: 45674
(cherry picked from commit d75424b5e5685a9cf04b30a5b0555efd1313e9c3)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/27/868027/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/pxe_base.py', 'ironic/tests/unit/drivers/modules/test_pxe.py', 'releasenotes/notes/prevent-pxe-retry-when-token-exists-a4f38f7da56c1397.yaml']",3,7ededc03f5a669008f597a9359ae65f890b2ebd2,,"--- fixes: - | Fixes a race condition in PXE initialization where logic to retry what we suspect as potentially failed PXE boot operations was not consulting if an ``agent token`` had been established, which is the very first step in agent initialization. ",,25,0
openstack%2Fneutron-lib~master~I9be781d99a08a6a015c3747eb15f20bc356cf08e,openstack/neutron-lib,master,I9be781d99a08a6a015c3747eb15f20bc356cf08e,add DEVICE_OWNER_MANILA_PREFIX to constants,MERGED,2023-01-06 13:41:08.000000000,2023-01-24 18:39:36.000000000,2023-01-24 18:38:23.000000000,"[{'_account_id': 5948}, {'_account_id': 8313}, {'_account_id': 22348}, {'_account_id': 32586}]","[{'number': 1, 'created': '2023-01-06 13:41:08.000000000', 'files': ['neutron_lib/constants.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/9d58d4ac10ad8a1570e2f14d392342712bc9fe41', 'message': ""add DEVICE_OWNER_MANILA_PREFIX to constants\n\nmanila port device owners are prefixed 'manila:' according to the manila\nneutron driver for binding, see\nhttps://review.opendev.org/c/openstack/manila/+/283494/29/manila/network/neutron/neutron_network_plugin.py#141\n\nPartial-Bug: #1580880\nChange-Id: I9be781d99a08a6a015c3747eb15f20bc356cf08e\n""}]",4,869294,9d58d4ac10ad8a1570e2f14d392342712bc9fe41,18,4,1,18816,,,0,"add DEVICE_OWNER_MANILA_PREFIX to constants

manila port device owners are prefixed 'manila:' according to the manila
neutron driver for binding, see
https://review.opendev.org/c/openstack/manila/+/283494/29/manila/network/neutron/neutron_network_plugin.py#141

Partial-Bug: #1580880
Change-Id: I9be781d99a08a6a015c3747eb15f20bc356cf08e
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/94/869294/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lib/constants.py'],1,9d58d4ac10ad8a1570e2f14d392342712bc9fe41,manila-multiple-port-binding,"DEVICE_OWNER_MANILA_PREFIX = ""manila:""",,1,0
openstack%2Fpuppet-keystone~master~Ia91f1558f6f5b77f3fcd77149dc61cafd621308e,openstack/puppet-keystone,master,Ia91f1558f6f5b77f3fcd77149dc61cafd621308e,Expose policy_default_rule,MERGED,2023-01-23 05:26:10.000000000,2023-01-24 18:30:13.000000000,2023-01-24 18:29:01.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 05:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/d6436b4c3e482330fcae2fa3f0b969b7d0070c9e', 'message': 'Expose policy_default_rule\n\nThe option has been managed by the underlying puppet-oslo module but\nhas not bee configurable. This introduces the parameter to customize\nthe option.\n\nChange-Id: Ia91f1558f6f5b77f3fcd77149dc61cafd621308e\n'}, {'number': 2, 'created': '2023-01-23 05:27:33.000000000', 'files': ['spec/classes/keystone_policy_spec.rb', 'releasenotes/notes/policy_default_rule-4600db5f90a7303c.yaml', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/caa8c1a5f6a95ed5ea0fd47bd7a17848bd265a94', 'message': 'Expose policy_default_rule\n\nThe option has been managed by the underlying puppet-oslo module but\nhas not been configurable. This introduces the parameter to customize\nthe option.\n\nChange-Id: Ia91f1558f6f5b77f3fcd77149dc61cafd621308e\n'}]",2,871425,caa8c1a5f6a95ed5ea0fd47bd7a17848bd265a94,15,3,2,9816,,,0,"Expose policy_default_rule

The option has been managed by the underlying puppet-oslo module but
has not been configurable. This introduces the parameter to customize
the option.

Change-Id: Ia91f1558f6f5b77f3fcd77149dc61cafd621308e
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/25/871425/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/keystone_policy_spec.rb', 'releasenotes/notes/policy_default_rule-4600db5f90a7303c.yaml', 'manifests/policy.pp']",3,d6436b4c3e482330fcae2fa3f0b969b7d0070c9e,policy_default_rule,"# [*policy_default_rule*] # (Optional) Default rule. Enforced when a requested rule is not found. # Defaults to $::os_service_default. # $policy_default_rule = $::os_service_default, policy_default_rule => $policy_default_rule,",,12,0
openstack%2Fmasakari-dashboard~master~If36c0a23b96fc0c3c6b8f244c4a73d60ddb4160d,openstack/masakari-dashboard,master,If36c0a23b96fc0c3c6b8f244c4a73d60ddb4160d,Update tox.ini for tox4,MERGED,2023-01-17 18:18:17.000000000,2023-01-24 18:24:29.000000000,2023-01-24 18:23:15.000000000,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2023-01-17 18:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/masakari-dashboard/commit/9a8de719a23ae88eb9cb686cb99b97d913c40953', 'message': 'Update tox.ini for tox4\n\nOpenStack CI now uses tox4 by default. This patch drop\n""skipsdist = True"". When skipsdist=True is specified, a\ntarget application is not installed into a tox env, but\nthere seems no reason to do so. In various other OpenStack\nprojects, a target applicatin needs to be installed into a\ntox vnev, for example, in docs and/or linter jobs and it\ncauses failures with tox4. So dropping it would avoid potential\nfuture failures.\n\nChange-Id: If36c0a23b96fc0c3c6b8f244c4a73d60ddb4160d\n'}, {'number': 2, 'created': '2023-01-24 17:58:45.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/masakari-dashboard/commit/c1928878d0fefa79a080aeb34693b629f9f822fb', 'message': 'Update tox.ini for tox4\n\nOpenStack CI now uses tox4 by default. This patch drop\n""skipsdist = True"". When skipsdist=True is specified, a\ntarget application is not installed into a tox env, but\nthere seems no reason to do so. In various other OpenStack\nprojects, a target applicatin needs to be installed into a\ntox vnev, for example, in docs and/or linter jobs and it\ncauses failures with tox4. So dropping it would avoid potential\nfuture failures.\n\nChange-Id: If36c0a23b96fc0c3c6b8f244c4a73d60ddb4160d\n'}]",6,870852,c1928878d0fefa79a080aeb34693b629f9f822fb,13,2,2,29313,,,0,"Update tox.ini for tox4

OpenStack CI now uses tox4 by default. This patch drop
""skipsdist = True"". When skipsdist=True is specified, a
target application is not installed into a tox env, but
there seems no reason to do so. In various other OpenStack
projects, a target applicatin needs to be installed into a
tox vnev, for example, in docs and/or linter jobs and it
causes failures with tox4. So dropping it would avoid potential
future failures.

Change-Id: If36c0a23b96fc0c3c6b8f244c4a73d60ddb4160d
",git fetch https://review.opendev.org/openstack/masakari-dashboard refs/changes/52/870852/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,9a8de719a23ae88eb9cb686cb99b97d913c40953,,,skipsdist = True,0,1
openstack%2Fmanila-tempest-plugin~master~Iafa8377368e7f37feb3ff756733bd5930fd1040d,openstack/manila-tempest-plugin,master,Iafa8377368e7f37feb3ff756733bd5930fd1040d,[RBAC] Add Tests for list share services,MERGED,2022-12-09 18:38:27.000000000,2023-01-24 18:19:43.000000000,2023-01-24 18:19:43.000000000,"[{'_account_id': 19262}, {'_account_id': 22348}, {'_account_id': 29632}, {'_account_id': 33301}]","[{'number': 1, 'created': '2022-12-09 18:38:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/c9580ff1cdfb633f2211ab819a3135056f736aef', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}, {'number': 2, 'created': '2022-12-17 23:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/457c2bc782752ef72446a29e3fcc01d2811f665e', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}, {'number': 3, 'created': '2022-12-17 23:46:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/3b34cb3830a24f89a9e09dae1daf23d4a64a8f4a', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}, {'number': 4, 'created': '2023-01-23 14:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/9df08791da5a301c5192584aef54cfcca73aa9d0', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}, {'number': 5, 'created': '2023-01-23 15:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/846d3e244c179d450ab0a6fab53b716f1537833a', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}, {'number': 6, 'created': '2023-01-24 11:00:36.000000000', 'files': ['manila_tempest_tests/tests/rbac/test_services.py'], 'web_link': 'https://opendev.org/openstack/manila-tempest-plugin/commit/85bc9c4c1664022f65e37d6c7279b990e7c55267', 'message': '[RBAC] Add Tests for list share services\n\nThe tests validate policy of share services list action\nfor admin, member and reader users in a project scope.\n\nChange-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d\n'}]",19,867134,85bc9c4c1664022f65e37d6c7279b990e7c55267,32,4,6,30025,,,0,"[RBAC] Add Tests for list share services

The tests validate policy of share services list action
for admin, member and reader users in a project scope.

Change-Id: Iafa8377368e7f37feb3ff756733bd5930fd1040d
",git fetch https://review.opendev.org/openstack/manila-tempest-plugin refs/changes/34/867134/4 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/rbac/test_services.py'],1,c9580ff1cdfb633f2211ab819a3135056f736aef,secure-rbac,"# Copyright 2014 Mirantis Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc from tempest import config from tempest.lib import decorators from tempest.lib import exceptions as lib_exc from testtools import testcase as tc from manila_tempest_tests.tests.api import base from manila_tempest_tests.tests.rbac import base as rbac_base CONF = config.CONF class ShareRbacServicesTests(rbac_base.ShareRbacBaseTests, metaclass=abc.ABCMeta): @classmethod def setup_clients(cls): super(ShareRbacServicesTests, cls).setup_clients() cls.persona = getattr(cls, 'os_%s' % cls.credentials[0]) cls.client = cls.persona.share_v2.SharesV2Client() def test_list_services(self): pass class TestProjectAdminTests(ShareRbacServicesTests, base.BaseSharesTest): credentials = ['project_admin'] @decorators.idempotent_id('08ec3a0b-6e4a-4cbf-bd15-3f48f8ddf71f') @tc.attr(base.TAG_POSITIVE, base.TAG_API) def test_list_services(self): self.do_request('list_services', expected_status=200) class TestProjectMemberTests(ShareRbacServicesTests, base.BaseSharesTest): ccredentials = ['project_member', 'project_admin'] @decorators.idempotent_id('7431dca6-9b03-48d3-b97c-41f72f7ed0a3') @tc.attr(base.TAG_NEGATIVE, base.TAG_API) def test_list_services(self): self.do_request('list_services', expected_status=lib_exc.Forbidden) class TestProjectReaderTests(TestProjectMemberTests): credentials = ['project_reader', 'project_admin'] @decorators.idempotent_id('eca71619-d563-4d15-9e49-b661e6da46c0') @tc.attr(base.TAG_NEGATIVE, base.TAG_API) def test_list_services(self): super(TestProjectReaderTests, self).test_list_services() ",,66,0
openstack%2Fironic~master~I2b206670aff6ad3a9f9cc76236453abf42663cad,openstack/ironic,master,I2b206670aff6ad3a9f9cc76236453abf42663cad,Reorganise Inventory Storage,MERGED,2023-01-17 12:41:59.000000000,2023-01-24 18:01:09.000000000,2023-01-24 17:59:31.000000000,"[{'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-17 12:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2c8e0bc6579f3396abf8c2e9ceb3b2135fc94968', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 2, 'created': '2023-01-17 15:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8c6f0a652d6fd6396f84ab865a86580e58a06268', 'message': 'WIP: Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 3, 'created': '2023-01-17 18:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/39569b98ac942d0c1b48fa62372121a827ffb7bf', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 4, 'created': '2023-01-17 18:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/511abcef6984ab4315113ab09c9f8e2e2223e30a', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 5, 'created': '2023-01-19 15:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9ead6e0d553919edc575202dc5508a670229c070', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 6, 'created': '2023-01-19 15:39:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ba41515a06e98f91599f31217a8fd75fe67fd6fa', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 7, 'created': '2023-01-21 11:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2efd702669bc033b2d68f48a6782351dbe55bbad', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}, {'number': 8, 'created': '2023-01-23 14:15:49.000000000', 'files': ['ironic/tests/unit/drivers/modules/test_inspect_utils.py', 'ironic/drivers/modules/inspect_utils.py', 'ironic/tests/unit/drivers/modules/test_inspector.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/drivers/modules/inspector.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/fe69e06c7c1ba400b4714e08860d2e40ba0af0d9', 'message': 'Reorganise Inventory Storage\n\nMove functions storing and obtaining introspection data\nfrom drivers/modules/inspector.py and api/controllers/v1/node.py\nto driver/modules/inspect_utils.py\n\nFollow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a\n\nStory: 2010275\nTask: 46204\nChange-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad\n'}]",18,870799,fe69e06c7c1ba400b4714e08860d2e40ba0af0d9,41,4,8,35099,,,0,"Reorganise Inventory Storage

Move functions storing and obtaining introspection data
from drivers/modules/inspector.py and api/controllers/v1/node.py
to driver/modules/inspect_utils.py

Follow-up to change If50f665da5fbb16f7646f3d6195a6e14e7325b0a

Story: 2010275
Task: 46204
Change-Id: I2b206670aff6ad3a9f9cc76236453abf42663cad
",git fetch https://review.opendev.org/openstack/ironic refs/changes/99/870799/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/inspect_utils.py', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/drivers/modules/inspector.py', 'ironic/api/controllers/v1/node.py']",4,2c8e0bc6579f3396abf8c2e9ceb3b2135fc94968,reorganise_inventory_storage,"from ironic.drivers.modules import inspect_utils return inspect_utils.get_introspection_data(node, api)","from ironic.drivers.modules import inspector as inspector def _node_inventory_convert(self, node_inventory): inventory_data = node_inventory['inventory_data'] plugin_data = node_inventory['plugin_data'] return {""inventory"": inventory_data, ""plugin_data"": plugin_data} store_data = CONF.inventory.data_backend if store_data == 'none': raise exception.NotFound( (_(""Cannot obtain node inventory because it was not stored""))) if store_data == 'database': node_inventory = objects.NodeInventory.get_by_node_id( api.request.context, node.id) return self._node_inventory_convert(node_inventory) if store_data == 'swift': return inspector.get_introspection_data(node.uuid)",93,81
openstack%2Fswift~master~Iab308e8f3b7a243dd0b3132539b6388bc5c89ace,openstack/swift,master,Iab308e8f3b7a243dd0b3132539b6388bc5c89ace,Add Kota's private email address to mailmap,MERGED,2023-01-24 07:27:08.000000000,2023-01-24 17:53:00.000000000,2023-01-24 17:51:41.000000000,"[{'_account_id': 7847}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-24 07:27:08.000000000', 'files': ['.mailmap'], 'web_link': 'https://opendev.org/openstack/swift/commit/5de745c2bc3aa82049424b9c3e8744cda53a4c74', 'message': ""Add Kota's private email address to mailmap\n\nChange-Id: Iab308e8f3b7a243dd0b3132539b6388bc5c89ace\n""}]",0,871571,5de745c2bc3aa82049424b9c3e8744cda53a4c74,9,3,1,4608,,,0,"Add Kota's private email address to mailmap

Change-Id: Iab308e8f3b7a243dd0b3132539b6388bc5c89ace
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/871571/1 && git format-patch -1 --stdout FETCH_HEAD,['.mailmap'],1,5de745c2bc3aa82049424b9c3e8744cda53a4c74,update-kota-mailmap,Kota Tsuyuzaki <bloodeagle40234@gmail.com> <kota.tsuyuzaki.pc@hco.ntt.co.jp> Kota Tsuyuzaki <bloodeagle40234@gmail.com> <tsuyuzaki.kota@lab.ntt.co.jp>,Kota Tsuyuzaki <kota.tsuyuzaki.pc@hco.ntt.co.jp> <tsuyuzaki.kota@lab.ntt.co.jp>,2,1
openstack%2Fcharm-ceph-mon~stable%2Fquincy.2~I76d21ddd9da79535f68490b4231ae13705e27edb,openstack/charm-ceph-mon,stable/quincy.2,I76d21ddd9da79535f68490b4231ae13705e27edb,Ensure crushtool --test called correctly,MERGED,2023-01-23 15:18:09.000000000,2023-01-24 17:52:37.000000000,2023-01-24 17:52:37.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 33717}]","[{'number': 1, 'created': '2023-01-23 15:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/5f5192fd03a69893683abd996ee4b82c32a915a8', 'message': 'Ensure crushtool --test called correctly\n\nLater Ceph releases require that the --test function of crushtool\nis called with replica information for validation.\n\nPass in ""--num-rep 3"" as a basic check plus ""--show-statistics""\nto silence a non-fatal warning message.\n\nThis can be clean cherry-picked back at least as far as\nCeph 12.2.x.\n\nChange-Id: I76d21ddd9da79535f68490b4231ae13705e27edb\nCloses-Bug: 2003690\n(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)\n'}, {'number': 2, 'created': '2023-01-24 01:39:54.000000000', 'files': ['src/ceph_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/cc436d13072824307fe0687f6ae512ce3331591f', 'message': 'Ensure crushtool --test called correctly\n\nLater Ceph releases require that the --test function of crushtool\nis called with replica information for validation.\n\nPass in ""--num-rep 3"" as a basic check plus ""--show-statistics""\nto silence a non-fatal warning message.\n\nThis can be clean cherry-picked back at least as far as\nCeph 12.2.x.\n\nChange-Id: I76d21ddd9da79535f68490b4231ae13705e27edb\nCloses-Bug: 2003690\n(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)\n'}]",3,871486,cc436d13072824307fe0687f6ae512ce3331591f,15,4,2,935,,,0,"Ensure crushtool --test called correctly

Later Ceph releases require that the --test function of crushtool
is called with replica information for validation.

Pass in ""--num-rep 3"" as a basic check plus ""--show-statistics""
to silence a non-fatal warning message.

This can be clean cherry-picked back at least as far as
Ceph 12.2.x.

Change-Id: I76d21ddd9da79535f68490b4231ae13705e27edb
Closes-Bug: 2003690
(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/86/871486/2 && git format-patch -1 --stdout FETCH_HEAD,['src/ceph_hooks.py'],1,5f5192fd03a69893683abd996ee4b82c32a915a8,quincy.2-bug/2003690," ""crushtool -i /tmp/crush.map --test "" ""--num-rep 3 --show-statistics"","," ""crushtool -i /tmp/crush.map --test"",",2,1
openstack%2Fswift~master~Idb6ad04ced20530fe98044690b0d73f3379d0c75,openstack/swift,master,Idb6ad04ced20530fe98044690b0d73f3379d0c75,Take on header parsing ourselves,NEW,2022-12-07 20:05:18.000000000,2023-01-24 17:41:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2022-12-07 20:05:18.000000000', 'files': ['swift/common/http_protocol.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/131739b00258a5e8a415d167fa7fd93b9ce4a17a', 'message': 'Take on header parsing ourselves\n\nChange-Id: Idb6ad04ced20530fe98044690b0d73f3379d0c75\n'}]",18,866934,131739b00258a5e8a415d167fa7fd93b9ce4a17a,7,1,1,15343,,,0,"Take on header parsing ourselves

Change-Id: Idb6ad04ced20530fe98044690b0d73f3379d0c75
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/866934/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/http_protocol.py'],1,131739b00258a5e8a415d167fa7fd93b9ce4a17a,,"class RawHeaders(object): def __init__(self, headers): self.items = headers @property def headers(self): headers = [h + ': ' + v for h, v in self.items] return headers def get(self, header, default=None): for h, v in self.items: if h.lower() == header.lower(): return v return default @property def type(self): return self.get('content-type', '') @classmethod def parse(cls, rfile): headers = [] for line in iter(lambda: rfile.readline(http_client._MAXLINE + 1), None): if line in (b'\n', b'\r\n'): break if len(headers) > http_client._MAXHEADERS: raise http_client.HTTPException(""got more than %d headers"" % http_client._MAXHEADERS) # check for empty string if len(line) > http_client._MAXLINE: raise http_client.LineTooLong(""header line"") if not six.PY2: line = line.decode('latin1') if line.startswith((' ', '\t')): raise ValueError('header line-folding not allowed') if ':' not in line: raise ValueError('header line missing colon ("":"")') h, v = line.split(':', 1) headers.append((h, v.strip(' \t\r\n'))) return cls(headers) def parse_request(self): """"""Parse a request (mostly inlined from cpython@7e293984). try: self.headers = RawHeaders.parse(self.rfile) except http_client.LineTooLong as err: self.send_error( 431, ""Line too long"", str(err)) return False except http_client.HTTPException as err: self.send_error( 431, ""Too many headers"", str(err) ) return False except ValueError as err: self.send_error( 400, ""Bad Request"", str(err) ) return False"," class MessageClass(wsgi.HttpProtocol.MessageClass): '''Subclass to see when the client didn't provide a Content-Type''' # for py2: def parsetype(self): if self.typeheader is None: self.typeheader = '' wsgi.HttpProtocol.MessageClass.parsetype(self) # for py3: def get_default_type(self): '''If the client didn't provide a content type, leave it blank.''' return '' def parse_request(self): """"""Parse a request (inlined from cpython@7e293984). if six.PY2: self.headers = self.MessageClass(self.rfile, 0) else: try: self.headers = http_client.parse_headers( self.rfile, _class=self.MessageClass) except http_client.LineTooLong as err: self.send_error( 431, ""Line too long"", str(err)) return False except http_client.HTTPException as err: self.send_error( 431, ""Too many headers"", str(err) ) return False header_payload = self.headers.get_payload() if isinstance(header_payload, list) and len(header_payload) == 1: header_payload = header_payload[0].get_payload() if header_payload: # This shouldn't be here. We must've bumped up against # https://bugs.python.org/issue37093 for line in header_payload.rstrip('\r\n').split('\n'): if ':' not in line or line[:1] in ' \t': # Well, we're no more broken than we were before... # Should we support line folding? # Should we 400 a bad header line? break header, value = line.split(':', 1) value = value.strip(' \t\n\r') # NB: Eventlet looks at the headers obj to figure out # whether the client said the connection should close; # see https://github.com/eventlet/eventlet/blob/v0.25.0/ # eventlet/wsgi.py#L504 self.headers.add_header(header, value)",65,54
openstack%2Ftripleo-ansible~stable%2Fzed~I4c1090f6d335509051c63f1a1788abd1606cfa4f,openstack/tripleo-ansible,stable/zed,I4c1090f6d335509051c63f1a1788abd1606cfa4f,Adding modules for retrieval of overcloud role info,MERGED,2023-01-03 10:08:53.000000000,2023-01-24 17:39:18.000000000,2023-01-24 17:37:49.000000000,"[{'_account_id': 9816}, {'_account_id': 16515}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}]","[{'number': 1, 'created': '2023-01-03 10:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/7a318433b6205693bfefd3f58230f60dbf19c71c', 'message': 'Adding modules for retrieval of overcloud role info\n\nDocumentation included.\n\nResolves: rhbz#2136519\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f\n(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)\n'}, {'number': 2, 'created': '2023-01-04 10:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/008153a2bdb42e3a0a1180f467f3c02628964c69', 'message': 'Adding modules for retrieval of overcloud role info\n\nDocumentation included.\n\nResolves: rhbz#2136519\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f\n(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)\n'}, {'number': 3, 'created': '2023-01-11 03:40:00.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_show.py', 'doc/source/modules/modules-tripleo-overcloud_role_show.rst', 'doc/source/modules/modules-tripleo_overcloud_role_list.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_list.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/156bf5f696f9502b892f7d818ea7741e005b83e3', 'message': 'Adding modules for retrieval of overcloud role info\n\nDocumentation included.\n\nBackport note:\nThis backport includes change I2b31100c7a547f10ff9f445811c0bf4084fec3cd\nwhich fixed several problems with the original change.\n\nResolves: rhbz#2136519\n\nSigned-off-by: Jiri Podivin <jpodivin@redhat.com>\nChange-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f\n(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)\n'}]",0,869065,156bf5f696f9502b892f7d818ea7741e005b83e3,17,5,3,32926,,,0,"Adding modules for retrieval of overcloud role info

Documentation included.

Backport note:
This backport includes change I2b31100c7a547f10ff9f445811c0bf4084fec3cd
which fixed several problems with the original change.

Resolves: rhbz#2136519

Signed-off-by: Jiri Podivin <jpodivin@redhat.com>
Change-Id: I4c1090f6d335509051c63f1a1788abd1606cfa4f
(cherry picked from commit 0e6c1b2650f53b99b592714220a1022873dd5094)
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/65/869065/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_show.py', 'doc/source/modules/modules-tripleo-overcloud_role_show.rst', 'doc/source/modules/modules-tripleo_overcloud_role_list.rst', 'tripleo_ansible/ansible_plugins/modules/tripleo_overcloud_role_list.py']",4,7a318433b6205693bfefd3f58230f60dbf19c71c,,"#!/usr/bin/python # -*- coding: utf-8 -*- # Copyright (c) 2022 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import yaml from ansible.module_utils.basic import AnsibleModule from ansible_collections.openstack.cloud.plugins.module_utils.openstack import openstack_full_argument_spec from ansible_collections.openstack.cloud.plugins.module_utils.openstack import openstack_module_kwargs from tripleo_common.utils import roles as rolesutils ROLES_PATH_DEFAULT = ""/usr/share/openstack-tripleo-heat-templates/roles"" ANSIBLE_METADATA = { 'metadata_version': '1.1', 'status': ['preview'], 'supported_by': 'community' } DOCUMENTATION = f''' --- module: tripleo_overcloud_role_list short_description: Retrieve list of overcloud roles version_added: ""4.2"" description: - ""Retrieve list of overcloud roles"" options: roles_path: description: - Path to the tripleo heat templates roles directory default: {ROLES_PATH_DEFAULT} author: - Jiri Podivin <jpodivin@redhat.com> ''' RETURN = ''' role_list: description: Overcloud roles list returned: always type: list elements: string sample: [ ""BlockStorage"", ""CellController"", ""CephAll"", ""NetworkerSriov"", ""NovaManager"", ""Novacontrol"", ""ObjectStorage"", ""Standalone"", ""Telemetry"", ""Undercloud"" ] ''' EXAMPLES = ''' - name: Get Overcloud roles list tripleo_overcloud_role_list: register: overcloud_role_list - name: Write data to output file copy: content: ""{{ overcloud_role_list.role_list | to_yaml }}"" dest: /path/exported-overcloud_role_list.yaml ''' def run_module(): result = dict( success=False, changed=False, error="""", role_list=list() ) argument_spec = openstack_full_argument_spec( **yaml.safe_load(DOCUMENTATION)['options'] ) module = AnsibleModule( argument_spec, supports_check_mode=True, **openstack_module_kwargs() ) try: roles_path = module.params[ROLES_PATH_DEFAULT] result['role_list'] = rolesutils.get_roles_list_from_directory(roles_path) result['changed'] = bool(result['role_list']) module.exit_json(**result) except Exception as err: result['error'] = str(err) result['msg'] = (""Error getting role list: %{error}"".format(error=err)) module.fail_json(**result) def main(): run_module() if __name__ == '__main__': main() ",,337,0
openstack%2Ftripleo-heat-templates~stable%2Fwallaby~I3ec4703f61fbfd1133d28aa327b7f2374670b613,openstack/tripleo-heat-templates,stable/wallaby,I3ec4703f61fbfd1133d28aa327b7f2374670b613,Allow customizing policy rules for Placement Api,MERGED,2022-07-04 23:22:01.000000000,2023-01-24 17:39:06.000000000,2023-01-24 17:37:43.000000000,"[{'_account_id': 6926}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2022-07-04 23:22:01.000000000', 'files': ['releasenotes/notes/placement-policies-db2704ea63d0bdad.yaml', 'deployment/placement/placement-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/08b3921d9f5356799944ad6dab60a36ee86e98b6', 'message': 'Allow customizing policy rules for Placement Api\n\nConflicts:\n\tdeployment/placement/placement-api-container-puppet.yaml\n\nDepends-on: https://review.opendev.org/801246\nChange-Id: I3ec4703f61fbfd1133d28aa327b7f2374670b613\n(cherry picked from commit cbd2842dbcd72a696aa0a4677365dd5e7db6f691)\n'}]",2,848675,08b3921d9f5356799944ad6dab60a36ee86e98b6,11,5,1,9816,,,0,"Allow customizing policy rules for Placement Api

Conflicts:
	deployment/placement/placement-api-container-puppet.yaml

Depends-on: https://review.opendev.org/801246
Change-Id: I3ec4703f61fbfd1133d28aa327b7f2374670b613
(cherry picked from commit cbd2842dbcd72a696aa0a4677365dd5e7db6f691)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/848675/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/placement-policies-db2704ea63d0bdad.yaml', 'deployment/placement/placement-api-container-puppet.yaml']",2,08b3921d9f5356799944ad6dab60a36ee86e98b6,," PlacementPolicies: description: | A hash of policies to configure for Placement API. e.g. { nova-context_is_admin: { key: context_is_admin, value: 'role:admin' } } default: {} type: json placement::policy::policies: {get_param: PlacementPolicies}",,11,0
openstack%2Fvalidations-common~master~Icd320a82543e503be3d08c6cebab1ec1eff7eccb,openstack/validations-common,master,Icd320a82543e503be3d08c6cebab1ec1eff7eccb,bump tox minversion to 4.0.0 for master,MERGED,2023-01-06 14:20:12.000000000,2023-01-24 17:37:46.000000000,2023-01-24 17:37:46.000000000,"[{'_account_id': 22348}, {'_account_id': 27427}, {'_account_id': 32926}, {'_account_id': 35199}]","[{'number': 1, 'created': '2023-01-06 14:20:12.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/validations-common/commit/d0ef0be278d1004b3752b19fe796699b09369e08', 'message': 'bump tox minversion to 4.0.0 for master\n\nChange-Id: Icd320a82543e503be3d08c6cebab1ec1eff7eccb\n'}]",1,869476,d0ef0be278d1004b3752b19fe796699b09369e08,8,4,1,16515,,,0,"bump tox minversion to 4.0.0 for master

Change-Id: Icd320a82543e503be3d08c6cebab1ec1eff7eccb
",git fetch https://review.opendev.org/openstack/validations-common refs/changes/76/869476/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d0ef0be278d1004b3752b19fe796699b09369e08,tox/4,minversion = 4.0.0,minversion = 3.2.0,1,1
openstack%2Fcharm-ceph-mon~stable%2Fquincy~I76d21ddd9da79535f68490b4231ae13705e27edb,openstack/charm-ceph-mon,stable/quincy,I76d21ddd9da79535f68490b4231ae13705e27edb,Ensure crushtool --test called correctly,ABANDONED,2023-01-23 15:16:17.000000000,2023-01-24 17:24:49.000000000,,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 15:16:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/1c40787a69085563630de7a6bdaee406618eccd1', 'message': 'Ensure crushtool --test called correctly\n\nLater Ceph releases require that the --test function of crushtool\nis called with replica information for validation.\n\nPass in ""--num-rep 3"" as a basic check plus ""--show-statistics""\nto silence a non-fatal warning message.\n\nThis can be clean cherry-picked back at least as far as\nCeph 12.2.x.\n\nChange-Id: I76d21ddd9da79535f68490b4231ae13705e27edb\nCloses-Bug: 2003690\n(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)\n'}, {'number': 2, 'created': '2023-01-23 23:01:44.000000000', 'files': ['hooks/ceph_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/465e2adb2c2b5f222339d5c1146f169cd4485d42', 'message': 'Ensure crushtool --test called correctly\n\nLater Ceph releases require that the --test function of crushtool\nis called with replica information for validation.\n\nPass in ""--num-rep 3"" as a basic check plus ""--show-statistics""\nto silence a non-fatal warning message.\n\nThis can be clean cherry-picked back at least as far as\nCeph 12.2.x.\n\nChange-Id: I76d21ddd9da79535f68490b4231ae13705e27edb\nCloses-Bug: 2003690\n(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)\n'}]",0,871484,465e2adb2c2b5f222339d5c1146f169cd4485d42,8,3,2,935,,,0,"Ensure crushtool --test called correctly

Later Ceph releases require that the --test function of crushtool
is called with replica information for validation.

Pass in ""--num-rep 3"" as a basic check plus ""--show-statistics""
to silence a non-fatal warning message.

This can be clean cherry-picked back at least as far as
Ceph 12.2.x.

Change-Id: I76d21ddd9da79535f68490b4231ae13705e27edb
Closes-Bug: 2003690
(cherry picked from commit 58fc48ebbe8945ef28806da7b8a6cac7be9a3a09)
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/84/871484/2 && git format-patch -1 --stdout FETCH_HEAD,['hooks/ceph_hooks.py'],1,1c40787a69085563630de7a6bdaee406618eccd1,quincy-bug/2003690," ""crushtool -i /tmp/crush.map --test "" ""--num-rep 3 --show-statistics"","," ""crushtool -i /tmp/crush.map --test"",",2,1
openstack%2Fcharm-trilio-data-mover~stable%2F4.2~Ib20d9d677c47012198160ec47d8cee136953e2e8,openstack/charm-trilio-data-mover,stable/4.2,Ib20d9d677c47012198160ec47d8cee136953e2e8,Pin tox to < 4.0.0,NEW,2023-01-20 20:20:57.000000000,2023-01-24 17:01:22.000000000,,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-20 20:20:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-trilio-data-mover/commit/c9de4ca793c704071a6236368402c42d8efbb4d2', 'message': ""Pin tox to < 4.0.0\n\nTox 4.0.0 was recently released and it has several breaking changes.\nWe pin to < 4.0.0 here. We are planning to move forward only on the\nmaster charm branches.\n\nTox is also pinned to < 4.0.0 for stable branches in upstream\nopenstack-zuul-jobs as well as in zosci-config. However, the\nrequires= section in the charm's tox.ini file ends up installing\ntox>4, wiping out the zuul-pinned tox<4 that was already installed\ninstalled. This patch fixes that.\n\nRelated-Bug: #2002788\nChange-Id: Ib20d9d677c47012198160ec47d8cee136953e2e8\n""}]",4,871377,c9de4ca793c704071a6236368402c42d8efbb4d2,9,3,1,11805,,,0,"Pin tox to < 4.0.0

Tox 4.0.0 was recently released and it has several breaking changes.
We pin to < 4.0.0 here. We are planning to move forward only on the
master charm branches.

Tox is also pinned to < 4.0.0 for stable branches in upstream
openstack-zuul-jobs as well as in zosci-config. However, the
requires= section in the charm's tox.ini file ends up installing
tox>4, wiping out the zuul-pinned tox<4 that was already installed
installed. This patch fixes that.

Related-Bug: #2002788
Change-Id: Ib20d9d677c47012198160ec47d8cee136953e2e8
",git fetch https://review.opendev.org/openstack/charm-trilio-data-mover refs/changes/77/871377/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c9de4ca793c704071a6236368402c42d8efbb4d2,pin-tox-stable-trilio,requires = tox < 4.0.0,,2,0
openstack%2Fnova~master~I1097d948f8c10ff99c54e8c369a7058ea14e6934,openstack/nova,master,I1097d948f8c10ff99c54e8c369a7058ea14e6934,Make tenant network policy default to PROJECT_READER_OR_ADMIN,MERGED,2022-11-19 22:13:31.000000000,2023-01-24 16:49:01.000000000,2023-01-24 16:47:38.000000000,"[{'_account_id': 4393}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2022-11-19 22:13:31.000000000', 'files': ['nova/policies/tenant_networks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/95244e089fcae38c036201ed69e6305a08addf80', 'message': 'Make tenant network policy default to PROJECT_READER_OR_ADMIN\n\nThis policy is missed to default to legacy admin in\n- https://review.opendev.org/c/openstack/nova/+/849209\n\nMaking tenant network policy also default to PROJECT_READER_OR_ADMIN.\n\nChange-Id: I1097d948f8c10ff99c54e8c369a7058ea14e6934\n'}]",1,865071,95244e089fcae38c036201ed69e6305a08addf80,10,3,1,8556,,,0,"Make tenant network policy default to PROJECT_READER_OR_ADMIN

This policy is missed to default to legacy admin in
- https://review.opendev.org/c/openstack/nova/+/849209

Making tenant network policy also default to PROJECT_READER_OR_ADMIN.

Change-Id: I1097d948f8c10ff99c54e8c369a7058ea14e6934
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/865071/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/policies/tenant_networks.py'],1,95244e089fcae38c036201ed69e6305a08addf80,," check_str=base.PROJECT_READER_OR_ADMIN, check_str=base.PROJECT_READER_OR_ADMIN,"," check_str=base.PROJECT_READER, check_str=base.PROJECT_READER,",2,2
openstack%2Fopenstack-helm-infra~master~Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c,openstack/openstack-helm-infra,master,Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c,[helm-toolkit] Added a random delay to remote backup operations,MERGED,2023-01-23 17:21:06.000000000,2023-01-24 16:33:39.000000000,2023-01-24 16:32:20.000000000,"[{'_account_id': 8898}, {'_account_id': 22348}, {'_account_id': 29974}, {'_account_id': 32433}]","[{'number': 1, 'created': '2023-01-23 17:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/af5ecf8541df1c1a67b1149060c7c0f93ec3bfec', 'message': '[helm-toolkit] Added a random delay to remote backup operations\n\nThis PS adds a random delay up to 300 seconds to remote backup upload and download actions to spread the network load in time. Backup process failure may happen if many sites are pushing their backups at the same time. It was OK previously but now with added remote bakup sha256 checksum verification we need to download the backup we just uploaded. So the network load already doubled. And this PS mitigates the impact of that.\n\nChange-Id: Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c\n'}, {'number': 2, 'created': '2023-01-23 17:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e210db395d360ff37162ada274c69e6132b5bc70', 'message': '[helm-toolkit] Added a random delay to remote backup operations\n\nThis PS adds a random delay up to 300 seconds to remote backup upload and download actions to spread the network load in time. Backup process failure may happen if many sites are pushing their backups at the same time. It was OK previously but now with added remote bakup sha256 checksum verification we need to download the backup we just uploaded. So the network load already doubled. And this PS mitigates the impact of that.\n\nChange-Id: Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c\n'}, {'number': 3, 'created': '2023-01-23 22:52:54.000000000', 'files': ['helm-toolkit/templates/scripts/db-backup-restore/_backup_main.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fa8916f5bcc8cbf064a387569e2630b7bbf0b49b', 'message': '[helm-toolkit] Added a random delay to remote backup operations\n\nThis PS adds a random delay up to 300 seconds to remote backup upload\nand download actions to spread the network load in time. Backup process\nfailure may happen if many sites are pushing their backups at the same\ntime. It was OK previously but now with added remote bakup sha256\nchecksum verification we need to download the backup we just uploaded.\nSo the network load already doubled. And this PS mitigates the impact\nof that.\n\nChange-Id: Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c\n'}]",2,871521,fa8916f5bcc8cbf064a387569e2630b7bbf0b49b,14,4,3,34520,,,0,"[helm-toolkit] Added a random delay to remote backup operations

This PS adds a random delay up to 300 seconds to remote backup upload
and download actions to spread the network load in time. Backup process
failure may happen if many sites are pushing their backups at the same
time. It was OK previously but now with added remote bakup sha256
checksum verification we need to download the backup we just uploaded.
So the network load already doubled. And this PS mitigates the impact
of that.

Change-Id: Ibc2a8f8287e20aeb56ad1f9c604b47db2d0eb06c
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/21/871521/1 && git format-patch -1 --stdout FETCH_HEAD,"['helm-toolkit/templates/scripts/db-backup-restore/_backup_main.sh.tpl', 'helm-toolkit/Chart.yaml', 'releasenotes/notes/helm-toolkit.yaml']",3,af5ecf8541df1c1a67b1149060c7c0f93ec3bfec,, - 0.2.51 Added a random delay up to 300 seconds to remote backup upload/download for load spreading purpose,,12,1
openstack%2Fpuppet-nova~master~I55f8d48063543b8f16c55c2d1626a1dbba084681,openstack/puppet-nova,master,I55f8d48063543b8f16c55c2d1626a1dbba084681,Expose policy_default_rule,MERGED,2023-01-23 05:39:40.000000000,2023-01-24 16:14:37.000000000,2023-01-24 16:13:21.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 05:39:40.000000000', 'files': ['spec/classes/nova_policy_spec.rb', 'releasenotes/notes/policy_default_rule-1d34663bc7bcfa52.yaml', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1016af81c3c6807a06dd408caf1b94a7cdc35950', 'message': 'Expose policy_default_rule\n\nThe option has been managed by the underlying puppet-oslo module but\nhas not been configurable. This introduces the parameter to customize\nthe option.\n\nChange-Id: I55f8d48063543b8f16c55c2d1626a1dbba084681\n'}]",2,871432,1016af81c3c6807a06dd408caf1b94a7cdc35950,16,3,1,9816,,,0,"Expose policy_default_rule

The option has been managed by the underlying puppet-oslo module but
has not been configurable. This introduces the parameter to customize
the option.

Change-Id: I55f8d48063543b8f16c55c2d1626a1dbba084681
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/32/871432/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/nova_policy_spec.rb', 'releasenotes/notes/policy_default_rule-1d34663bc7bcfa52.yaml', 'manifests/policy.pp']",3,1016af81c3c6807a06dd408caf1b94a7cdc35950,policy_default_rule,"# [*policy_default_rule*] # (Optional) Default rule. Enforced when a requested rule is not found. # Defaults to $::os_service_default. # $policy_default_rule = $::os_service_default, policy_default_rule => $policy_default_rule,",,12,0
openstack%2Fpuppet-magnum~master~Id4cb6d9a840ea4f649c6a4ed3007422c1c0b630f,openstack/puppet-magnum,master,Id4cb6d9a840ea4f649c6a4ed3007422c1c0b630f,Expose policy_default_rule,MERGED,2023-01-23 05:30:54.000000000,2023-01-24 16:02:40.000000000,2023-01-24 16:01:33.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2023-01-23 05:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/6199f7ae4b1c7d3a3d165dbdce43c9215efaa5dd', 'message': 'Expose policy_default_rule\n\nThe option has been managed by the underlying puppet-oslo module but\nhas not been configurable. This introduces the parameter to customize\nthe option.\n\nChange-Id: Id4cb6d9a840ea4f649c6a4ed3007422c1c0b630f\n'}, {'number': 2, 'created': '2023-01-23 05:32:36.000000000', 'files': ['releasenotes/notes/policy_default_rule-5950529d7abaddd6.yaml', 'spec/classes/magnum_policy_spec.rb', 'manifests/policy.pp'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/b8137be3b0871e6d28efdf94d7b42f7b11a80b12', 'message': 'Expose policy_default_rule\n\nThe option has been managed by the underlying puppet-oslo module but\nhas not been configurable. This introduces the parameter to customize\nthe option.\n\nChange-Id: Id4cb6d9a840ea4f649c6a4ed3007422c1c0b630f\n'}]",2,871427,b8137be3b0871e6d28efdf94d7b42f7b11a80b12,18,3,2,9816,,,0,"Expose policy_default_rule

The option has been managed by the underlying puppet-oslo module but
has not been configurable. This introduces the parameter to customize
the option.

Change-Id: Id4cb6d9a840ea4f649c6a4ed3007422c1c0b630f
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/27/871427/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/magnum_policy_spec.rb', 'releasenotes/notes/policy_default_rule-a584b71f8a236e21.yaml', 'manifests/policy.pp']",3,6199f7ae4b1c7d3a3d165dbdce43c9215efaa5dd,policy_default_rule,"# == Class: glance::policy# Configure the glance policies# (Optional) Set of policies to configure for glance# 'glance-context_is_admin' => {# 'glance-default' => {# (Optional) Path to the glance policy.yaml file # Defaults to /etc/glance/policy.yaml # # [*policy_default_rule*] # (Optional) Default rule. Enforced when a requested rule is not found. # Defaults to $::os_service_default.# (Optional) Path to the glance policy folderclass glance::policy ( $policy_path = '/etc/glance/policy.yaml', $policy_default_rule = $::os_service_default, include glance::deps include glance::params file_group => $::glance::params::group, oslo::policy { 'glance_config': policy_default_rule => $policy_default_rule,","# == Class: magnum::policy# Configure the magnum policies# (Optional) Set of policies to configure for magnum# 'magnum-context_is_admin' => {# 'magnum-default' => {# (Optional) Path to the magnum policy.yaml file # Defaults to /etc/magnum/policy.yaml# (Optional) Path to the magnum policy folderclass magnum::policy ( $policy_path = '/etc/magnum/policy.yaml', include magnum::deps include magnum::params file_group => $::magnum::params::group, oslo::policy { 'magnum_config':",43,31
