id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fnetworking-ovn~master~I549e23135ead0332e4e92c1044d20f64e20d1106,openstack/networking-ovn,master,I549e23135ead0332e4e92c1044d20f64e20d1106,Make networking-ovn-migration-mtu output less confusing,MERGED,2019-02-05 21:15:31.000000000,2019-02-12 23:10:40.000000000,2019-02-12 23:10:40.000000000,"[{'_account_id': 6773}, {'_account_id': 10237}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-05 21:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/913849240b0ee5f90061912a68573bc2b5d39f6f', 'message': 'Make networking-ovn-migration-mtu output less confusing\n\nWhen called fron ovn_migration.sh the output seems confusing and\nmakes it look like the admin still has to go and do something on the\ncommand line, while in fact ovn_migration.sh will handle it.\n\nCloses-Bug: 1814824\n\nChange-Id: I549e23135ead0332e4e92c1044d20f64e20d1106\n'}, {'number': 2, 'created': '2019-02-12 09:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5e2aaf7d25b7d792ae3b9ae64b9f2d694d0adf50', 'message': 'Make networking-ovn-migration-mtu output less confusing\n\nWhen called fron ovn_migration.sh the output seems confusing and\nmakes it look like the admin still has to go and do something on the\ncommand line, while in fact ovn_migration.sh will handle it.\n\nCloses-Bug: 1814824\n\nChange-Id: I549e23135ead0332e4e92c1044d20f64e20d1106\n'}, {'number': 3, 'created': '2019-02-12 09:39:01.000000000', 'files': ['networking_ovn/cmd/migration_mtu.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b6a9d3d5a3717411ee2c9e939cd28b4952cc2b57', 'message': 'Make networking-ovn-migration-mtu output less confusing\n\nWhen called fron ovn_migration.sh the output seems confusing and\nmakes it look like the admin still has to go and do something on the\ncommand line, while in fact ovn_migration.sh will handle it.\n\nCloses-Bug: 1814824\n\nChange-Id: I549e23135ead0332e4e92c1044d20f64e20d1106\n'}]",3,635042,b6a9d3d5a3717411ee2c9e939cd28b4952cc2b57,15,4,3,8788,,,0,"Make networking-ovn-migration-mtu output less confusing

When called fron ovn_migration.sh the output seems confusing and
makes it look like the admin still has to go and do something on the
command line, while in fact ovn_migration.sh will handle it.

Closes-Bug: 1814824

Change-Id: I549e23135ead0332e4e92c1044d20f64e20d1106
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/42/635042/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/cmd/migration_mtu.py'],1,913849240b0ee5f90061912a68573bc2b5d39f6f,bug/1814824," print(""Some tenant networks need to be handled with update mtu"")"," print(""Please run : \""%s update mtu\"" before starting the migration "" ""migration to OVN"" % sys.argv[0])",1,2
openstack%2Ftempest~master~I522a15ba3dbfee5d8ef417e43288a12319abf6ff,openstack/tempest,master,I522a15ba3dbfee5d8ef417e43288a12319abf6ff,Enable volume multiattach tests in tempest-full/slow jobs,MERGED,2018-10-01 15:36:19.000000000,2019-02-12 22:53:13.000000000,2019-02-09 04:52:08.000000000,"[{'_account_id': 2243}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 28950}]","[{'number': 1, 'created': '2018-10-01 15:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0d3a7f44b2adee7d3559be5eee60ab2e605321ce', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 2, 'created': '2018-10-01 15:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b25df5b2424fd33317971e11e7f27dac51c7d2e9', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nTempest will continue to run the nova-multiattach job, defined in\nthe nova repo, on stable/queens and stable/rocky branches.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 3, 'created': '2018-12-07 19:34:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c46b054dc0feb39f3514c9fab7a95509376df03f', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 4, 'created': '2018-12-07 19:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/db8b896f7c495cb20ee9cef79792b544ff08f15c', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 5, 'created': '2018-12-10 19:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e343d0148e5ca1e21e5e8f2f552821768fd497d3', 'message': 'WIP: Enable volume multiattach tests in tempest-full/slow jobs\n\nDepends-On: https://review.openstack.org/#/c/624181/\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 6, 'created': '2018-12-11 20:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4e292c1983c2440d1a93fd224bfb820521e5cf68', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 7, 'created': '2019-02-05 14:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/53255df27c2b91f12af53f263b462df5ec6fe77d', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nDue to intermittent bug 1807723 when running the\ntest_volume_swap_with_multiattach test with two compute services,\nthat test is conditionally skipped if there is more than one compute.\nThis is probably no great loss in test coverage for now given\nswapping multiattach volumes is likely rarely used (see bug 1775418).\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}, {'number': 8, 'created': '2019-02-05 16:50:37.000000000', 'files': ['.zuul.yaml', 'tempest/api/compute/admin/test_volume_swap.py', 'releasenotes/notes/enable-volume-multiattach-fd5e9bf0e96b56ce.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7581e99a057c3ec5390cd26bcda48a4785d8d476', 'message': 'Enable volume multiattach tests in tempest-full/slow jobs\n\nThe volume multiattach tests originally required special\ndevstack configuration in Queens for the Ubuntu Cloud Archive,\nbut that is no longer necessary. This change enables the volume\nmultiattach tests in the tempest-full(-py3) and tempest-slow jobs\nso we can drop the nova-multiattach job, which is mostly redundant\ncoverage of the tempest.api.compute.* tests, and reduce the total\nnumber of jobs we run against nova/cinder/tempest changes.\n\nDue to intermittent bug 1807723 when running the\ntest_volume_swap_with_multiattach test with two compute services,\nthat test is conditionally skipped if there is more than one compute.\nThis is probably no great loss in test coverage for now given\nswapping multiattach volumes is likely rarely used (see bug 1775418).\n\nRelated ML thread:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html\n\nDepends-On: https://review.openstack.org/634977\n\nChange-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff\n'}]",18,606978,7581e99a057c3ec5390cd26bcda48a4785d8d476,79,11,8,6873,,,0,"Enable volume multiattach tests in tempest-full/slow jobs

The volume multiattach tests originally required special
devstack configuration in Queens for the Ubuntu Cloud Archive,
but that is no longer necessary. This change enables the volume
multiattach tests in the tempest-full(-py3) and tempest-slow jobs
so we can drop the nova-multiattach job, which is mostly redundant
coverage of the tempest.api.compute.* tests, and reduce the total
number of jobs we run against nova/cinder/tempest changes.

Due to intermittent bug 1807723 when running the
test_volume_swap_with_multiattach test with two compute services,
that test is conditionally skipped if there is more than one compute.
This is probably no great loss in test coverage for now given
swapping multiattach volumes is likely rarely used (see bug 1775418).

Related ML thread:

http://lists.openstack.org/pipermail/openstack-dev/2018-October/135299.html

Depends-On: https://review.openstack.org/634977

Change-Id: I522a15ba3dbfee5d8ef417e43288a12319abf6ff
",git fetch https://review.opendev.org/openstack/tempest refs/changes/78/606978/7 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0d3a7f44b2adee7d3559be5eee60ab2e605321ce,drop-multiattach-job, # NOTE(mriedem): The nova-multiattach job tests multiattach in # Queens and Rocky. ENABLE_VOLUME_MULTIATTACH: true # NOTE(mriedem): The nova-multiattach job tests multiattach in # Queens and Rocky. ENABLE_VOLUME_MULTIATTACH: true,,6,0
openstack%2Fopenstack-ansible-os_magnum~master~I1c0296886a7cc37089233f241f79c92696ebac3a,openstack/openstack-ansible-os_magnum,master,I1c0296886a7cc37089233f241f79c92696ebac3a,Correct notification driver,MERGED,2019-02-07 22:38:15.000000000,2019-02-12 22:50:30.000000000,2019-02-12 22:50:30.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:38:15.000000000', 'files': ['templates/magnum.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/33b192bfd986e4e166ef13af994d0ecf5acf47ce', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: I1c0296886a7cc37089233f241f79c92696ebac3a\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635680,33b192bfd986e4e166ef13af994d0ecf5acf47ce,9,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: I1c0296886a7cc37089233f241f79c92696ebac3a
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/80/635680/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/magnum.conf.j2'],1,33b192bfd986e4e166ef13af994d0ecf5acf47ce,bug/1794320,"driver = {{ (magnum_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if magnum_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fmonasca-agent~master~I6c06d50404e570db8e791da89a0f95f98597798e,openstack/monasca-agent,master,I6c06d50404e570db8e791da89a0f95f98597798e,docs: Be consistent with config options in the init_config paragraph,MERGED,2019-02-06 10:09:41.000000000,2019-02-12 22:46:12.000000000,2019-02-12 22:46:12.000000000,"[{'_account_id': 7102}, {'_account_id': 10311}, {'_account_id': 14123}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 10:09:41.000000000', 'files': ['docs/Plugins.md'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/e68c8391eaee77db31fb5ec0a2f7b00c02d80f81', 'message': 'docs: Be consistent with config options in the init_config paragraph\n\nCurrently this paragraph is not very readable due to a lot of variable\nnames which are sometimes written with "", and sometimes without.\nMark these variables now as inline code (with backticks) to make the\nparagraph more readable.\n\nChange-Id: I6c06d50404e570db8e791da89a0f95f98597798e\n'}]",0,635119,e68c8391eaee77db31fb5ec0a2f7b00c02d80f81,9,4,1,7102,,,0,"docs: Be consistent with config options in the init_config paragraph

Currently this paragraph is not very readable due to a lot of variable
names which are sometimes written with "", and sometimes without.
Mark these variables now as inline code (with backticks) to make the
paragraph more readable.

Change-Id: I6c06d50404e570db8e791da89a0f95f98597798e
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/19/635119/1 && git format-patch -1 --stdout FETCH_HEAD,['docs/Plugins.md'],1,e68c8391eaee77db31fb5ec0a2f7b00c02d80f81,,"In the `init_config` section you can specify an arbitrary number of global name:value pairs that will be available on every run of the check in `self.init_config`. Here you can specify a collection frequency specific to the plugin by setting `collect_period`. The global frequency at which all plugins are run is specified by the variable `check_frequency` defined in https://github.com/openstack/monasca-agent/blob/master/docs/Agent.md. Under normal and default conditions when a plugin runs all the metrics are collected and sent. For example, if `check_frequency=30`, by default the plugin will be run every 30 seconds and the metrics will be sent. The variable `collect_period` allows each plugins collect period to be further adjusted to a value greater than the frequency at which the plugin is run specified by `check_frequency`, such that when the collection run starts, the plugin might not be called. For example, if `check_frequency=30` and `collect_period=600`, the plugin will be called and metrics sent every 600 seconds. This allows fewer metrics to be sent. The `collect_period` should be evenly divisible by the `check_frequency`. For example, if you want the plugin to collect and send metrics every 600 seconds (10 minutes), and the global `check_frequency=30`, then the `collect_period` should be set to 600. If the `collect_period` is not evenly divisible by the `check_frequency` then the `collect_period` will get rounded up to the nearest multiple of the `check_frequency`. For example, if the `collect_period=45` and the global `check_frequency=30`, then the `collect_period` will get rounded up to 60 and the plugin will get called and send metrics every 60 seconds.","In the init_config section you can specify an arbitrary number of global name:value pairs that will be available on every run of the check in self.init_config. Here you can specify a collection frequency specific to the plugin by setting collect_period. The global frequency at which all plugins are run is specified by the variable ""check_frequency"" defined in https://github.com/openstack/monasca-agent/blob/master/docs/Agent.md. Under normal and default conditions when a plugin runs all the metrics are collected and sent. For example, if check_frequency=30, by default the plugin will be run every 30 seconds and the metrics will be sent. The variable ""collect_period"" allows each plugins collect period to be further adjusted to a value greater than the frequency at which the plugin is run specified by ""check_frequency"", such that when the collection run starts, the plugin might not be called. For example, if check_frequency=30 and collect_period=600, the plugin will be called and metrics sent every 600 seconds. This allows fewer metrics to be sent. The ""collect_period"" should be evenly divisible by the ""check_frequency"". For example, if you want the plugin to collect and send metrics every 600 seconds (10 minutes), and the global check_frequency=30, then the collect_period should be set to 600. If the ""collect_period"" is not evenly divisible by the ""check_frequency"" then the ""collect_period"" will get rounded up to the nearest multiple of the ""check_frequency"". For example, if the collect_period=45 and the global check_frequency=30, then the ""collect_period"" will get rounded up to 60 and the plugin will get called and send metrics every 60 seconds.",7,7
openstack%2Fopenstack-ansible-os_cinder~master~I94899d14906a0a4e51137dd066f25f8f0e0a2334,openstack/openstack-ansible-os_cinder,master,I94899d14906a0a4e51137dd066f25f8f0e0a2334,Correct notification driver,MERGED,2019-02-07 22:32:45.000000000,2019-02-12 22:38:19.000000000,2019-02-12 22:38:19.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:32:45.000000000', 'files': ['templates/cinder.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/38807bc2c7a81c18e556a4ff7696f7c28ad7ae02', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: I94899d14906a0a4e51137dd066f25f8f0e0a2334\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635674,38807bc2c7a81c18e556a4ff7696f7c28ad7ae02,8,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: I94899d14906a0a4e51137dd066f25f8f0e0a2334
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/74/635674/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/cinder.conf.j2'],1,38807bc2c7a81c18e556a4ff7696f7c28ad7ae02,bug/1794320,"driver = {{ (cinder_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if cinder_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fneutron-interconnection~master~I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68,openstack/neutron-interconnection,master,I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68,Define default policies in code,MERGED,2019-01-28 15:46:52.000000000,2019-02-12 22:25:36.000000000,2019-02-12 22:23:42.000000000,"[{'_account_id': 841}, {'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 19990}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-28 15:46:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-interconnection/commit/8cc055b723279d1b186be0a3914314953d37f150', 'message': 'Define default policies in code\n\nNew role ``neutron_interconnection_peer`` must be added for\nneutron-interconnection specific user used for interconnection refresh and\nparameters exchange.\n\nThis patch adds policies in code and corresponding documentation.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nSigned-off-by: Thomas Morin <thomas.morin@orange.com>\nSubmitted on behalf of a third-party: Orange\n\nChange-Id: I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68\n'}, {'number': 2, 'created': '2019-01-28 16:35:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-interconnection/commit/544230525140b8a8b3eec28386425313045eb860', 'message': 'Define default policies in code\n\nNew role ``neutron_interconnection_peer`` must be added for\nneutron-interconnection specific user used for interconnection refresh and\nparameters exchange.\n\nThis patch adds policies in code and corresponding documentation.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nSigned-off-by: Thomas Morin <thomas.morin@orange.com>\nSubmitted on behalf of a third-party: Orange\n\nChange-Id: I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68\n'}, {'number': 3, 'created': '2019-01-30 09:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-interconnection/commit/c6b31614f25cbebf68a7bab0740aaad2c8e44c32', 'message': 'Define default policies in code\n\nNew role ``neutron_interconnection_peer`` must be added for\nneutron-interconnection specific user used for interconnection refresh and\nparameters exchange.\n\nThis patch adds policies in code and corresponding documentation.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nSigned-off-by: Thomas Morin <thomas.morin@orange.com>\nSubmitted on behalf of a third-party: Orange\n\nChange-Id: I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68\n'}, {'number': 4, 'created': '2019-01-31 09:10:04.000000000', 'files': ['doc/source/configuration/index.rst', 'requirements.txt', 'neutron_interconnection/policies/base.py', 'doc/source/configuration/policy-sample.rst', 'neutron_interconnection/policies/__init__.py', 'doc/source/conf.py', 'neutron_interconnection/policies/interconnection.py', 'etc/oslo-policy-generator/policy.conf', 'doc/source/configuration/policy.rst', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-interconnection/commit/74e6ae9831bb104880b0dad1906657f56715f1d4', 'message': 'Define default policies in code\n\nNew role ``neutron_interconnection_peer`` must be added for\nneutron-interconnection specific user used for interconnection refresh and\nparameters exchange.\n\nThis patch adds policies in code and corresponding documentation.\n\nPartially Implements: blueprint neutron-policy-in-code\n\nSigned-off-by: Thomas Morin <thomas.morin@orange.com>\nSubmitted on behalf of a third-party: Orange\n\nChange-Id: I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68\n'}]",10,633534,74e6ae9831bb104880b0dad1906657f56715f1d4,17,5,4,19990,,,0,"Define default policies in code

New role ``neutron_interconnection_peer`` must be added for
neutron-interconnection specific user used for interconnection refresh and
parameters exchange.

This patch adds policies in code and corresponding documentation.

Partially Implements: blueprint neutron-policy-in-code

Signed-off-by: Thomas Morin <thomas.morin@orange.com>
Submitted on behalf of a third-party: Orange

Change-Id: I235e79e2c165ba2d5d2d6b3c976f6fda16f19a68
",git fetch https://review.opendev.org/openstack/neutron-interconnection refs/changes/34/633534/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_interconnection/policies/base.py', 'doc/source/configuration/policy-sample.rst', 'doc/source/conf.py', 'etc/oslo-policy-generator/policy.conf', 'doc/source/configuration/index.rst', 'requirements.txt', 'etc/policy.yaml.sample', 'neutron_interconnection/policies/__init__.py', 'neutron_interconnection/policies/interconnection.py', 'doc/source/configuration/policy.rst', 'setup.cfg', 'tox.ini']",12,8cc055b723279d1b186be0a3914314953d37f150,bp/neutron-policy-in-code,install_command = pip install {opts} {packages}deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txtdeps = {[testenv]deps} commands = flake8 {posargs} {[testenv:genpolicy]commands}[testenv:genpolicy] commands = oslopolicy-sample-generator --config-file=etc/oslo-policy-generator/policy.conf ,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages}deps = -r{toxinidir}/test-requirements.txtcommands = flake8 {posargs},271,10
openstack%2Fironic~master~I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289,openstack/ironic,master,I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289,Expose conductors: api-ref,MERGED,2018-12-05 07:36:26.000000000,2019-02-12 22:22:45.000000000,2019-02-12 22:22:45.000000000,"[{'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10379}, {'_account_id': 11655}, {'_account_id': 13689}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 18320}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 25547}, {'_account_id': 28429}]","[{'number': 1, 'created': '2018-12-05 07:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1133890a7c4d9d43680737ecf231b6f53b9b4fe0', 'message': 'Expose conductors: api-ref\n\nThis patch update API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 2, 'created': '2018-12-10 05:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/efec4cd12756a7bd53eef07a5df043c09e6a3cab', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nAlso fixed some incorrect microversion in docstring/test.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 3, 'created': '2018-12-10 22:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/535291112eb6778b9c2828fd611e7b7bf16091ef', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nAlso fixed some incorrect microversion in docstring/test.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 4, 'created': '2018-12-17 03:32:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/03a453cc64920928d4575d7f171a7c89807d1779', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 5, 'created': '2018-12-18 09:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1801b750169e4ea2ec49b5bddc06234a622e9869', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 6, 'created': '2019-01-09 06:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/40c51291389803c5c0f0e07b2d45d940c5dd413e', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 7, 'created': '2019-01-28 07:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/67e1c9d74868114a4e6356d11a4d84aa4f6110d3', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 8, 'created': '2019-02-12 15:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/96197a5470300733cd88334c3d2aadc1c76ebd47', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}, {'number': 9, 'created': '2019-02-12 15:02:15.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/baremetal-api-v1-conductors.inc', 'api-ref/source/samples/conductor-show-response.json', 'api-ref/source/samples/node-update-driver-info-response.json', 'api-ref/source/index.rst', 'ironic/api/controllers/v1/versions.py', 'api-ref/source/baremetal-api-v1-nodes.inc', 'api-ref/source/samples/nodes-list-details-response.json', 'api-ref/source/samples/node-show-response.json', 'api-ref/source/samples/conductor-list-details-response.json', 'api-ref/source/samples/conductor-list-response.json'], 'web_link': 'https://opendev.org/openstack/ironic/commit/d4233e52a9df250043d253944a1fa89ece736b47', 'message': 'Expose conductors: api-ref\n\nThis patch updates API reference to contain the changes made\nby the feature of exposing conductors.\n\nStory: 1724474\nTask: 28064\n\nChange-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289\n'}]",33,622862,d4233e52a9df250043d253944a1fa89ece736b47,105,16,9,24828,,,0,"Expose conductors: api-ref

This patch updates API reference to contain the changes made
by the feature of exposing conductors.

Story: 1724474
Task: 28064

Change-Id: I47dbea2cda1cc0ad73786fe3fe9b80850e1cf289
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/622862/8 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/baremetal-api-v1-conductors.inc', 'api-ref/source/parameters.yaml', 'api-ref/source/samples/conductor-show-response.json', 'api-ref/source/samples/node-update-driver-info-response.json', 'api-ref/source/index.rst', 'api-ref/source/baremetal-api-v1-nodes.inc', 'api-ref/source/samples/nodes-list-details-response.json', 'api-ref/source/samples/node-show-response.json', 'api-ref/source/samples/conductor-list-details-response.json', 'api-ref/source/samples/conductor-list-response.json']",10,1133890a7c4d9d43680737ecf231b6f53b9b4fe0,1724474,"{ ""conductors"": [ { ""hostname"": ""compute1.localdomain"", ""conductor_group"": """", ""links"": [ { ""href"": ""http://127.0.0.1:6385/v1/conductors/compute1.localdomain"", ""rel"": ""self"" }, { ""href"": ""http://127.0.0.1:6385/conductors/compute1.localdomain"", ""rel"": ""bookmark"" } ], ""alive"": false }, { ""hostname"": ""compute2.localdomain"", ""conductor_group"": """", ""links"": [ { ""href"": ""http://127.0.0.1:6385/v1/conductors/compute2.localdomain"", ""rel"": ""self"" }, { ""href"": ""http://127.0.0.1:6385/conductors/compute2.localdomain"", ""rel"": ""bookmark"" } ], ""alive"": true } ] }",,274,3
openstack%2Fcharm-nova-compute-proxy~master~I16017474e85fbb7c476ed5c0585e86b4accbc340,openstack/charm-nova-compute-proxy,master,I16017474e85fbb7c476ed5c0585e86b4accbc340,Update pre-install hooks to fail on error,MERGED,2019-02-08 22:11:01.000000000,2019-02-12 22:20:28.000000000,2019-02-12 22:20:28.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-02-08 22:11:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-proxy/commit/0f489a0118063d3d46c9f5f45625158da85aab0f', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I16017474e85fbb7c476ed5c0585e86b4accbc340\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}, {'number': 2, 'created': '2019-02-12 18:41:33.000000000', 'files': ['hooks/install'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute-proxy/commit/e9cb83136c857dad080347f2c6dec6983437ac1a', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I16017474e85fbb7c476ed5c0585e86b4accbc340\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}]",0,635971,e9cb83136c857dad080347f2c6dec6983437ac1a,12,5,2,20805,,,0,"Update pre-install hooks to fail on error

The pre-install operations may fail, yet that failure is not
elevated to the user. This masks the failure and makes early
package install issues difficult to troubleshoot.

If the basic pre-install script fails, the charm should not
proceed to later hooks as the requirements may not be met.

Hashbangs for bash should specify -e (errexit) on all of the
pre-install bash scripts.

Change-Id: I16017474e85fbb7c476ed5c0585e86b4accbc340
Closes-bug: #1815243
Partial-bug: #1815231
",git fetch https://review.opendev.org/openstack/charm-nova-compute-proxy refs/changes/71/635971/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/install'],1,0f489a0118063d3d46c9f5f45625158da85aab0f,bug/1815243,#!/bin/bash -e,#!/bin/bash,1,1
openstack%2Fopenstack-ansible-os_designate~master~I2645beb3eed1948f66f76fc7eb45e14923abfa78,openstack/openstack-ansible-os_designate,master,I2645beb3eed1948f66f76fc7eb45e14923abfa78,Correct notification driver,MERGED,2019-02-07 22:32:46.000000000,2019-02-12 22:20:19.000000000,2019-02-12 22:20:19.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:32:46.000000000', 'files': ['templates/designate.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_designate/commit/bceb008249c0c2dbdf6d5bdc43b8a3a6a7c8bb09', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: I2645beb3eed1948f66f76fc7eb45e14923abfa78\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635675,bceb008249c0c2dbdf6d5bdc43b8a3a6a7c8bb09,8,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: I2645beb3eed1948f66f76fc7eb45e14923abfa78
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_designate refs/changes/75/635675/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/designate.conf.j2'],1,bceb008249c0c2dbdf6d5bdc43b8a3a6a7c8bb09,bug/1794320,"driver = {{ (designate_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if designate_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fcharm-tempest~master~I3a404f8a4d1be24e3a16e8240ebe72371579f528,openstack/charm-tempest,master,I3a404f8a4d1be24e3a16e8240ebe72371579f528,Update pre-install hooks to fail on error,MERGED,2019-02-08 22:09:30.000000000,2019-02-12 22:19:34.000000000,2019-02-12 22:19:33.000000000,"[{'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-02-08 22:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-tempest/commit/f26b2553e012d1a80d3ac0bdce5a26044f7a09ea', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I3a404f8a4d1be24e3a16e8240ebe72371579f528\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}, {'number': 2, 'created': '2019-02-12 19:06:57.000000000', 'files': ['src/hooks/install'], 'web_link': 'https://opendev.org/openstack/charm-tempest/commit/d889d2ef265514dba48c580a3e6879ffe35bcdf5', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I3a404f8a4d1be24e3a16e8240ebe72371579f528\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}]",0,635970,d889d2ef265514dba48c580a3e6879ffe35bcdf5,12,5,2,20805,,,0,"Update pre-install hooks to fail on error

The pre-install operations may fail, yet that failure is not
elevated to the user. This masks the failure and makes early
package install issues difficult to troubleshoot.

If the basic pre-install script fails, the charm should not
proceed to later hooks as the requirements may not be met.

Hashbangs for bash should specify -e (errexit) on all of the
pre-install bash scripts.

Change-Id: I3a404f8a4d1be24e3a16e8240ebe72371579f528
Closes-bug: #1815243
Partial-bug: #1815231
",git fetch https://review.opendev.org/openstack/charm-tempest refs/changes/70/635970/2 && git format-patch -1 --stdout FETCH_HEAD,['src/hooks/install'],1,f26b2553e012d1a80d3ac0bdce5a26044f7a09ea,bug/1815243,#!/bin/bash -e,#!/bin/bash,1,1
openstack%2Ftripleo-quickstart-extras~master~I090d37a5836f09711a489fea24e5e66f7d1fe4b7,openstack/tripleo-quickstart-extras,master,I090d37a5836f09711a489fea24e5e66f7d1fe4b7,Add inventory and repos to freeipa playbook,MERGED,2019-02-11 07:02:09.000000000,2019-02-12 22:18:45.000000000,2019-02-12 22:18:45.000000000,"[{'_account_id': 9592}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 11589}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 07:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/95e58a41a8d627741ca6a80ea7373a331e99352d', 'message': 'Add inventory to freeipa playbook\n\nDepends-On: https://review.openstack.org/636094\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 2, 'created': '2019-02-12 10:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2e7472ba604ddb09cc7d39e8f0009de80780b179', 'message': 'Add inventory to freeipa playbook\n\nDepends-On: https://review.openstack.org/636094\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 3, 'created': '2019-02-12 10:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b62ece94d35898334204a925a6337a7ccc0cb073', 'message': 'Add inventory to freeipa playbook\n\nDepends-On: https://review.openstack.org/636094\nDepends-On: https://review.openstack.org/636294 \nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 4, 'created': '2019-02-12 10:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0b661e5936e76c78ec910fa081d2aaf4141aa25f', 'message': 'Add inventory to freeipa playbook\n\nDepends-On: https://review.openstack.org/636094\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 5, 'created': '2019-02-12 11:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/51ff4b8c76196464f8f1f6f717a281e036e56db2', 'message': 'Add inventory to freeipa playbook\n\nDepends-On: https://review.openstack.org/636094\nDepends-On: https://review.openstack.org/636294\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 6, 'created': '2019-02-12 12:19:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/29aa71cbbfbd9bc8553a288e2b144210ec8494e2', 'message': 'Add inventory and repos to freeipa playbook\n\nAdd inventory and repo-setup roles to freeipa playbook\nDepends-On: https://review.openstack.org/636094\nDepends-On: https://review.openstack.org/636294\n\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}, {'number': 7, 'created': '2019-02-12 15:02:03.000000000', 'files': ['playbooks/baremetal-full-freeipa.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1f07118c84b3998959dc44751773405ded5418ca', 'message': 'Add inventory and repos to freeipa playbook\n\nAdd inventory and repo-setup roles to freeipa playbook\nDepends-On: https://review.openstack.org/636094\nDepends-On: https://review.openstack.org/636294\n\nChange-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7\n'}]",0,636097,1f07118c84b3998959dc44751773405ded5418ca,37,7,7,10969,,,0,"Add inventory and repos to freeipa playbook

Add inventory and repo-setup roles to freeipa playbook
Depends-On: https://review.openstack.org/636094
Depends-On: https://review.openstack.org/636294

Change-Id: I090d37a5836f09711a489fea24e5e66f7d1fe4b7
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/97/636097/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/baremetal-full-freeipa.yml'],1,95e58a41a8d627741ca6a80ea7373a331e99352d,freeipa, vars: inventory: extra_node,,2,0
openstack%2Ftripleo-quickstart~master~Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4,openstack/tripleo-quickstart,master,Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4,Add supplemental node to inventory,MERGED,2019-02-11 06:49:40.000000000,2019-02-12 22:18:44.000000000,2019-02-12 22:18:43.000000000,"[{'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 11589}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 06:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2686a608bd8fc6200b7cf521ab9a2040bbf4a474', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 2, 'created': '2019-02-11 09:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/b0be1d942e8066998aba6f8898837e17c3f8eaa6', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 3, 'created': '2019-02-11 17:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/d76679db5b2910455c919f012a348ca52271b2d2', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 4, 'created': '2019-02-11 21:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/eb8061dfbf173c5a9a438273104e7a6a360a041f', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 5, 'created': '2019-02-12 06:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c3cadb46221dbaa113626cc8d879702ccd2b42cf', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 6, 'created': '2019-02-12 10:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f42e6032fb17956a5994026117e234e5ba92cfc8', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 7, 'created': '2019-02-12 10:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/83284ef1de93f0dd34651e82193f43dfccea8a87', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}, {'number': 8, 'created': '2019-02-12 15:01:39.000000000', 'files': ['config/general_config/featureset039.yml', 'roles/tripleo-inventory/templates/ssh_config.j2', 'roles/tripleo-inventory/tasks/main.yml', 'roles/tripleo-inventory/defaults/main.yml', 'roles/tripleo-inventory/files/get_extra_node.py', 'roles/tripleo-inventory/tasks/inventory.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a9ab51f8d537f1a19f9f0b3a8e8e501ee5cc2c20', 'message': 'Add supplemental node to inventory\n\nChange-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4\n'}]",2,636094,a9ab51f8d537f1a19f9f0b3a8e8e501ee5cc2c20,44,6,8,10969,,,0,"Add supplemental node to inventory

Change-Id: Id431120ab8d84fe7c05b008c9b3b1be6e4dd4af4
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/94/636094/8 && git format-patch -1 --stdout FETCH_HEAD,"['roles/tripleo-inventory/tasks/main.yml', 'roles/tripleo-inventory/defaults/main.yml', 'roles/tripleo-inventory/files/get_extra_node.py', 'roles/tripleo-inventory/tasks/inventory.yml']",4,2686a608bd8fc6200b7cf521ab9a2040bbf4a474,freeipa,"- when: inventory == 'extra_node' block: - name: Get IP of extra node in OVB stack script: get_extra_node.py {{ working_dir }} args: executable: python3 register: node_ip - name: set_fact for supplemental ip set_fact: supplemental_node_ip: ""{{ node_ip.stdout | replace('\n', '') }}"" cacheable: true when: node_ip.stdout - name: Add supplemental node vm to inventory add_host: name: supplemental groups: supplemental ansible_host: supplemental ansible_fqdn: supplemental ansible_user: '{{ supplemental_user }}' ansible_private_key_file: '{{ extra_node_key }}' ansible_ssh_extra_args: '-F ""{{ local_working_dir }}/ssh.config.ansible""' supplemental_node_ip: ""{{ supplemental_node_ip }}"" when: supplemental_node_ip is defined","# Add the supplemental to the in-memory inventory. - name: Add supplemental node vm to inventory add_host: name: supplemental groups: supplemental ansible_host: supplemental ansible_fqdn: supplemental ansible_user: '{{ supplemental_user }}' ansible_private_key_file: '{{ local_working_dir }}/id_rsa_supplemental' ansible_ssh_extra_args: '-F ""{{ local_working_dir }}/ssh.config.ansible""' supplemental_node_ip: ""{{ supplemental_node_ip }}"" when: supplemental_node_ip is defined - name: set_fact for supplemental ip set_fact: supplemental_node_ip: ""{{ hostvars['supplemental'].supplemental_node_ip }}"" cacheable: true when: hostvars['supplemental'] is defined and hostvars['supplemental'].supplemental_node_ip is defined",62,18
openstack%2Fpython-tripleoclient~master~If5d784af413decc72afe8ba3bdc8a20f0c4fb290,openstack/python-tripleoclient,master,If5d784af413decc72afe8ba3bdc8a20f0c4fb290,Use cliff autodoc generation,MERGED,2017-11-28 19:29:59.000000000,2019-02-12 22:18:43.000000000,2019-02-12 22:18:43.000000000,"[{'_account_id': 3153}, {'_account_id': 9061}, {'_account_id': 10239}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-11-28 19:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b39ad0be8dd5771d96c6ee3e737ad39f7ac68275', 'message': ""[WIP] Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 2, 'created': '2017-11-28 20:14:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6e875ba523d769f9a672959905e73327b17a4b62', 'message': ""[WIP] Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 3, 'created': '2017-11-28 20:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a48f29d4d645bbded350e05b748bb45e686fec36', 'message': ""[WIP] Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\nDepends-On: Ia74c4fe74baf0e33bf1e002679e8e6b7d4879a3d\n""}, {'number': 4, 'created': '2018-03-07 14:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4f53db087a49bb3c1cc6cfd4ad596c6809384163', 'message': ""[WIP] Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\nDepends-On: Ia74c4fe74baf0e33bf1e002679e8e6b7d4879a3d\n""}, {'number': 5, 'created': '2019-01-02 14:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1e819428d8539ed2aa62e7ecf0f3572a8dd0e548', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\nDepends-On: Ia74c4fe74baf0e33bf1e002679e8e6b7d4879a3d\n""}, {'number': 6, 'created': '2019-01-02 14:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d6db503bfe8bdb283c8c332c5977b6ae3a99e0ea', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\nDepends-On: Ia74c4fe74baf0e33bf1e002679e8e6b7d4879a3d\n""}, {'number': 7, 'created': '2019-01-02 15:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6e8445b130e1c0385e4bc718413b3af8d2c4dea6', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\nDepends-On: Ia74c4fe74baf0e33bf1e002679e8e6b7d4879a3d\n""}, {'number': 8, 'created': '2019-01-02 16:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/be5470678ccb17c47fb0ec431bc6f6522be1b01e', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 9, 'created': '2019-01-02 19:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5c0115692f66d3680441e62009887b7014683f38', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 10, 'created': '2019-01-02 20:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c2b2a56e14a9903633bcffdbe115de0638a461d5', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 11, 'created': '2019-01-03 14:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/91864cb33df42bd2b433ed858be05fb237c50d12', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 12, 'created': '2019-01-14 22:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/46e203a8035ceb72cb6d43472dd5c9cfcf112e2f', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 13, 'created': '2019-01-16 16:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ba32f945597d0446d88c2f9810214c7b46dec25b', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}, {'number': 14, 'created': '2019-02-01 20:39:58.000000000', 'files': ['doc/source/command-objects/baremetal.rst', 'tripleoclient/constants.py', 'doc/source/command-list.rst', 'doc/source/commands.rst', 'doc/source/index.rst', 'doc/source/command-objects/overcloud.rst', 'doc/source/conf.py', 'doc/source/command-objects/undercloud.rst'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4b6633bf9bebfe7e4a04647de26286dce722c9ac', 'message': ""Use cliff autodoc generation\n\nCurrently, there is an issue with the 'overcloud container image prepare'\ncommand.\n\nChange-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290\n""}]",3,523510,4b6633bf9bebfe7e4a04647de26286dce722c9ac,45,7,14,7065,,,0,"Use cliff autodoc generation

Currently, there is an issue with the 'overcloud container image prepare'
command.

Change-Id: If5d784af413decc72afe8ba3bdc8a20f0c4fb290
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/10/523510/10 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/command-objects/baremetal.rst', 'doc/source/command-list.rst', 'doc/source/commands.rst', 'doc/source/index.rst', 'test-requirements.txt', 'doc/source/command-objects/overcloud.rst', 'doc/source/command-objects/undercloud.rst', 'doc/source/conf.py']",8,b39ad0be8dd5771d96c6ee3e737ad39f7ac68275,cliff-autodocs,"import os, sys import sphinx_rtd_theme 'cliff.sphinxext', 'oslosphinx',copyright = u'2017 Red Hat, Inc.' autoprogram_cliff_application = 'openstack'","import os import sys #'sphinx.ext.intersphinx', # 'oslo.sphinx'copyright = u'2015 Red Hat, Inc.'",26,252
openstack%2Fcharm-ceilometer-agent~master~I40fedc011933cbce6215dd124019d251b6dafd61,openstack/charm-ceilometer-agent,master,I40fedc011933cbce6215dd124019d251b6dafd61,Update pre-install hooks to fail on error,MERGED,2019-02-08 21:47:03.000000000,2019-02-12 22:15:36.000000000,2019-02-12 22:15:35.000000000,"[{'_account_id': 11805}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 26040}]","[{'number': 1, 'created': '2019-02-08 21:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/8c3b4d3ce1d3724781ec436ff65b8b56018c1748', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I40fedc011933cbce6215dd124019d251b6dafd61\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}, {'number': 2, 'created': '2019-02-09 00:25:20.000000000', 'files': ['tests/basic_deployment.py', 'hooks/install'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer-agent/commit/058cd81d400cf443070043a55802d3e8684291b8', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: I40fedc011933cbce6215dd124019d251b6dafd61\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}]",0,635948,058cd81d400cf443070043a55802d3e8684291b8,17,6,2,20635,,,0,"Update pre-install hooks to fail on error

The pre-install operations may fail, yet that failure is not
elevated to the user. This masks the failure and makes early
package install issues difficult to troubleshoot.

If the basic pre-install script fails, the charm should not
proceed to later hooks as the requirements may not be met.

Hashbangs for bash should specify -e (errexit) on all of the
pre-install bash scripts.

Change-Id: I40fedc011933cbce6215dd124019d251b6dafd61
Closes-bug: #1815243
Partial-bug: #1815231
",git fetch https://review.opendev.org/openstack/charm-ceilometer-agent refs/changes/48/635948/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/install'],1,8c3b4d3ce1d3724781ec436ff65b8b56018c1748,bug/1815243,#!/bin/bash -e,#!/bin/bash,1,1
openstack%2Fopenstack-ansible-os_nova~master~Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235,openstack/openstack-ansible-os_nova,master,Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235,Cleanup files and templates using smart sources,MERGED,2018-08-05 02:43:20.000000000,2019-02-12 22:14:34.000000000,2019-02-12 22:14:34.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2018-08-05 02:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/81ce6e4705a69efba9c24b5167245d14e77d7a6e', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2018-08-05 03:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/29a10aa9fdf85acb261008873ae64b754372bf06', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2018-08-08 19:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/99e082a75b0884b9be8ad35d33a0dea939ee1383', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2018-08-11 17:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/89a1b25af01af162ea6f269657020d41ab067796', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2018-08-13 17:11:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/fab216e3ed709e75a084f105ab60abba1f54e87d', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2018-09-21 16:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/fe64c6bf254065f1ed7d1f5b3a5e068824d78bc4', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2019-01-09 02:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/306b0e7447414a65547dd558d8787837159abf1f', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2019-01-09 02:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/53c54c3a880963c8dcfabc23598d27b1c61ca7a5', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}, {'number': 9, 'created': '2019-01-11 14:31:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8380bfeb042effa6b9558150b0ba769be78337c5', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}, {'number': 10, 'created': '2019-01-11 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/f4ab59fe714caa9a055932013867558bbb9e980b', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}, {'number': 11, 'created': '2019-01-20 01:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/d0a8ee696c1864c13184f229ad88a73e3d424539', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}, {'number': 12, 'created': '2019-02-12 10:21:12.000000000', 'files': ['files/rootwrap.d/compute.filters', 'tasks/nova_pre_install.yml', 'files/rootwrap.d/api-metadata.filters', 'templates/rootwrap.conf.j2', 'files/rootwrap.d/network.filters', 'templates/api-paste.ini.j2', 'templates/policy.json.j2', 'handlers/main.yml', 'tasks/nova_post_install.yml', 'vars/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/874c8df029029ec1180c9c64b05931acff6be0f5', 'message': 'Cleanup files and templates using smart sources\n\nThe files and templates we carry are almost always in a state of\nmaintenance. The upstream services are maintaining these files and\nthere\'s really no reason we need to carry duplicate copies of them. This\nchange removes all of the files we expect to get from the upstream\nservice. while the focus of this change is to remove configuration file\nmaintenance burdens it also allows the role to execute faster.\n\n  * Source installs have the configuration files within the venv at\n    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the\n    default configuration path to this directory. When the service is\n    upgraded the link will move to the new venv path.\n  * Distro installs package all of the required configuration files.\n\nTo maintain our current capabilities to override configuration the\nrole will fetch files from the disk whenever an override is provided and\nthen push the fetched file back to the target using `config_template`.\n\nDepends-On: https://review.openstack.org/636162\nChange-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}]",2,588951,874c8df029029ec1180c9c64b05931acff6be0f5,72,6,12,7353,,,0,"Cleanup files and templates using smart sources

The files and templates we carry are almost always in a state of
maintenance. The upstream services are maintaining these files and
there's really no reason we need to carry duplicate copies of them. This
change removes all of the files we expect to get from the upstream
service. while the focus of this change is to remove configuration file
maintenance burdens it also allows the role to execute faster.

  * Source installs have the configuration files within the venv at
    ""<<VENV_PATH>>/etc/<<SERVICE_NAME>>"". The role will now link the
    default configuration path to this directory. When the service is
    upgraded the link will move to the new venv path.
  * Distro installs package all of the required configuration files.

To maintain our current capabilities to override configuration the
role will fetch files from the disk whenever an override is provided and
then push the fetched file back to the target using `config_template`.

Depends-On: https://review.openstack.org/636162
Change-Id: Ib7d8039513bc2581cf7bc0e2e73aa8ab5da82235
Signed-off-by: Kevin Carter <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/51/588951/7 && git format-patch -1 --stdout FETCH_HEAD,"['files/rootwrap.d/compute.filters', 'tasks/nova_pre_install.yml', 'files/rootwrap.d/api-metadata.filters', 'templates/rootwrap.conf.j2', 'files/rootwrap.d/network.filters', 'templates/api-paste.ini.j2', 'templates/policy.json.j2', 'tasks/nova_post_install.yml', 'defaults/main.yml']",9,81ce6e4705a69efba9c24b5167245d14e77d7a6e,smart-sources,"# Provide a list of access controls to update the default policy.json with. # These changes will be merged # with the access controls in the default policy.json. E.g. #nova_rootwrap_conf_overrides: # ""create_subnet"": ""rule:admin_or_network_owner"" # ""get_subnet"": ""rule:admin_or_owner or rule:shared""_nova_rootwrap_conf_overrides: DEFAULT: filters_path: ""/etc/nova/rootwrap.d,/usr/share/nova/rootwrap"" exec_dirs: ""{{ nova_bin }},/sbin,/usr/sbin,/bin,/usr/bin,/usr/local/bin,/usr/local/sbin"" ",,174,424
openstack%2Fopenstack-ansible-os_nova~master~Iefd5ed5aa5b7cfb07b129784ae1706efd036e291,openstack/openstack-ansible-os_nova,master,Iefd5ed5aa5b7cfb07b129784ae1706efd036e291,Fix default init config override for nova-compute,MERGED,2019-01-25 03:05:56.000000000,2019-02-12 22:13:04.000000000,2019-02-12 22:13:04.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 29574}]","[{'number': 1, 'created': '2019-01-25 03:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/895644020d751169aae583eb1966bee48c90fc96', 'message': 'Fix default init config override for nova-compute\n\nThe config_template overrides for nova compute were loading units in that\nwere supposed to force nova compute to start after several over services\nhowever this was rendering several unit entries for things service\nproperties that don\'t exist. This change converts the config_template\noverride into an ""after_targets"" list fixes the service config so that it\nstarts nova-compute in the order we\'re expecting. This will also put the\nconfig_template overrides back into the user space allowing folks to do\nwhat they need with the override options without having to know about our\nset defaults.\n\nChange-Id: Iefd5ed5aa5b7cfb07b129784ae1706efd036e291\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}, {'number': 2, 'created': '2019-01-31 07:12:34.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/8f7f9ab8c1d8235ac1acf74addd8a23f0fcf54d0', 'message': 'Fix default init config override for nova-compute\n\nThe config_template overrides for nova compute were loading units in that\nwere supposed to force nova compute to start after several over services\nhowever this was rendering several unit entries for things service\nproperties that don\'t exist. This change converts the config_template\noverride into an ""after_targets"" list fixes the service config so that it\nstarts nova-compute in the order we\'re expecting. This will also put the\nconfig_template overrides back into the user space allowing folks to do\nwhat they need with the override options without having to know about our\nset defaults.\n\nDepends-On: https://review.openstack.org/634057\nChange-Id: Iefd5ed5aa5b7cfb07b129784ae1706efd036e291\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}]",0,633104,8f7f9ab8c1d8235ac1acf74addd8a23f0fcf54d0,19,5,2,7353,,,0,"Fix default init config override for nova-compute

The config_template overrides for nova compute were loading units in that
were supposed to force nova compute to start after several over services
however this was rendering several unit entries for things service
properties that don't exist. This change converts the config_template
override into an ""after_targets"" list fixes the service config so that it
starts nova-compute in the order we're expecting. This will also put the
config_template overrides back into the user space allowing folks to do
what they need with the override options without having to know about our
set defaults.

Depends-On: https://review.openstack.org/634057
Change-Id: Iefd5ed5aa5b7cfb07b129784ae1706efd036e291
Signed-off-by: Kevin Carter <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/04/633104/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,895644020d751169aae583eb1966bee48c90fc96,,nova_compute_init_overrides: {} after_targets: - libvirtd.service - syslog.target - network.target,nova_compute_init_overrides: Unit: ? libvirtd.service ? syslog.target ? network.target,5,5
openstack%2Fopenstack-ansible-os_nova~master~Icf0f9ca274c31c76d877e79b6a1ad54c34b811e4,openstack/openstack-ansible-os_nova,master,Icf0f9ca274c31c76d877e79b6a1ad54c34b811e4,remove duplicate pci section,MERGED,2019-02-12 17:02:31.000000000,2019-02-12 22:13:03.000000000,2019-02-12 22:13:03.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-12 17:02:31.000000000', 'files': ['templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/0cb8b7bc038585587dadb564e99635a04065d07d', 'message': ""remove duplicate pci section\n\nNot sure how it got in, but it's not needed.\n\nChange-Id: Icf0f9ca274c31c76d877e79b6a1ad54c34b811e4\n""}]",0,636388,0cb8b7bc038585587dadb564e99635a04065d07d,9,3,1,14288,,,0,"remove duplicate pci section

Not sure how it got in, but it's not needed.

Change-Id: Icf0f9ca274c31c76d877e79b6a1ad54c34b811e4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/88/636388/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/nova.conf.j2'],1,0cb8b7bc038585587dadb564e99635a04065d07d,,,"{% if nova_pci_passthrough_whitelist %} # PCI Passthrough [pci] passthrough_whitelist = ""{{ nova_pci_passthrough_whitelist }}"" {% endif %} ",0,6
openstack%2Fneutron~master~Ia1ccfd5c933257cebe2fff39e5c4c581a5557a46,openstack/neutron,master,Ia1ccfd5c933257cebe2fff39e5c4c581a5557a46,Remove the rally-jobs plugins,ABANDONED,2019-02-12 22:08:02.000000000,2019-02-12 22:12:25.000000000,,[],"[{'number': 1, 'created': '2019-02-12 22:08:02.000000000', 'files': ['rally-jobs/plugins/trunk_scenario.py', 'rally-jobs/plugins/README.rst', 'rally-jobs/plugins/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6e14dd8d5271bca49a5cc746810aadeabb515f46', 'message': 'Remove the rally-jobs plugins\n\nThe custom plugin can now be safely removed from neutron tree  as it\nexists in the rally-openstack tree.\n\nChange-Id: Ia1ccfd5c933257cebe2fff39e5c4c581a5557a46\n'}]",0,636448,6e14dd8d5271bca49a5cc746810aadeabb515f46,2,0,1,16845,,,0,"Remove the rally-jobs plugins

The custom plugin can now be safely removed from neutron tree  as it
exists in the rally-openstack tree.

Change-Id: Ia1ccfd5c933257cebe2fff39e5c4c581a5557a46
",git fetch https://review.opendev.org/openstack/neutron refs/changes/48/636448/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally-jobs/plugins/trunk_scenario.py', 'rally-jobs/plugins/README.rst', 'rally-jobs/plugins/__init__.py']",3,6e14dd8d5271bca49a5cc746810aadeabb515f46,,,,0,70
openstack%2Fopenstack-ansible-os_trove~master~Iefcec440db0e61adf8c6ce3a8b8ae9a4125a802d,openstack/openstack-ansible-os_trove,master,Iefcec440db0e61adf8c6ce3a8b8ae9a4125a802d,Correct notification driver,MERGED,2019-02-07 22:39:45.000000000,2019-02-12 22:05:53.000000000,2019-02-12 22:05:53.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:39:45.000000000', 'files': ['templates/trove-conductor.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/b58811d7da09ef6bcbd24ceec8e4bb1c998c7c6a', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: Iefcec440db0e61adf8c6ce3a8b8ae9a4125a802d\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635683,b58811d7da09ef6bcbd24ceec8e4bb1c998c7c6a,8,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: Iefcec440db0e61adf8c6ce3a8b8ae9a4125a802d
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/83/635683/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/trove-conductor.conf.j2'],1,b58811d7da09ef6bcbd24ceec8e4bb1c998c7c6a,bug/1794320,"driver = {{ (trove_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if trove_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fopenstack-ansible-os_glance~master~If361de5d4112a9e7235972dc7bc5e857c68fef06,openstack/openstack-ansible-os_glance,master,If361de5d4112a9e7235972dc7bc5e857c68fef06,Correct notification driver,MERGED,2019-02-07 22:32:48.000000000,2019-02-12 22:04:20.000000000,2019-02-12 22:04:20.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:32:48.000000000', 'files': ['templates/glance-api.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/2edb1b1a4d5aa8e63a506e2a9506c42c75f51379', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: If361de5d4112a9e7235972dc7bc5e857c68fef06\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635676,2edb1b1a4d5aa8e63a506e2a9506c42c75f51379,8,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: If361de5d4112a9e7235972dc7bc5e857c68fef06
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/76/635676/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/glance-api.conf.j2'],1,2edb1b1a4d5aa8e63a506e2a9506c42c75f51379,bug/1794320,"driver = {{ (glance_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if glance_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fopenstack-ansible-os_keystone~master~I78293b35a30ea12da25fc11d7a5c33cdf2982e2d,openstack/openstack-ansible-os_keystone,master,I78293b35a30ea12da25fc11d7a5c33cdf2982e2d,Correct notification driver,MERGED,2019-02-07 22:38:05.000000000,2019-02-12 22:03:39.000000000,2019-02-12 22:03:39.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-07 22:38:05.000000000', 'files': ['templates/keystone.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/b40f4b5e1aa2f26384a35424c27cb0a363538ebf', 'message': 'Correct notification driver\n\nThe notification driver setup was resulting in the driver and connection string\non the same line. This is caused by the case statement and how jinja formats\nthe template when a case statement is present. This change modifies how the\ndriver string is created using a ternary, which will eliminate the case\nstatement and render the value of the diver correctly.\n\nChange-Id: I78293b35a30ea12da25fc11d7a5c33cdf2982e2d\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,635679,b40f4b5e1aa2f26384a35424c27cb0a363538ebf,8,3,1,7353,,,0,"Correct notification driver

The notification driver setup was resulting in the driver and connection string
on the same line. This is caused by the case statement and how jinja formats
the template when a case statement is present. This change modifies how the
driver string is created using a ternary, which will eliminate the case
statement and render the value of the diver correctly.

Change-Id: I78293b35a30ea12da25fc11d7a5c33cdf2982e2d
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/79/635679/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/keystone.conf.j2'],1,b40f4b5e1aa2f26384a35424c27cb0a363538ebf,bug/1794320,"driver = {{ (keystone_ceilometer_enabled | bool) | ternary('messagingv2', 'noop') }}",driver = {% if keystone_ceilometer_enabled %}messagingv2{% else %}noop{% endif %},1,1
openstack%2Fhorizon~master~I575ae9697783c36fdae5dd397d6783b979d0c4a6,openstack/horizon,master,I575ae9697783c36fdae5dd397d6783b979d0c4a6,Show domain info in project and user detail panel,MERGED,2018-12-20 17:08:49.000000000,2019-02-12 21:54:18.000000000,2019-02-12 21:54:18.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-20 17:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b6374d495c80b67772f3300f7ffec64f52402b2', 'message': 'Show domain info in project and user detail panel\n\nDomain info in the user detail panel was previously displayed\nbut it has been broken after the user detail panel was tabbified.\nThis commit fixes the handling of context data. This covers\ndomain_name, project_name and extras.\nSimilar change is applied to the project detail panel too.\n\nChange-Id: I575ae9697783c36fdae5dd397d6783b979d0c4a6\nCloses-Bug: #1809284\n'}, {'number': 2, 'created': '2018-12-25 07:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3813274a8335e27ebae3fc74d1b2833779d6d02d', 'message': 'Show domain info in project and user detail panel\n\nDomain info in the user detail panel was previously displayed\nbut it has been broken after the user detail panel was tabbified.\nThis commit fixes the handling of context data. This covers\ndomain_name, project_name and extras.\nSimilar change is applied to the project detail panel too.\n\nChange-Id: I575ae9697783c36fdae5dd397d6783b979d0c4a6\nCloses-Bug: #1809284\n'}, {'number': 3, 'created': '2018-12-27 00:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/50e8d7c78794637b83a8c0b8b6ff9da5c83c2938', 'message': 'Show domain info in project and user detail panel\n\nDomain info in the user detail panel was previously displayed\nbut it has been broken after the user detail panel was tabbified.\nThis commit fixes the handling of context data. This covers\ndomain_name, project_name and extras.\nSimilar change is applied to the project detail panel too.\n\nChange-Id: I575ae9697783c36fdae5dd397d6783b979d0c4a6\nCloses-Bug: #1809284\n'}, {'number': 4, 'created': '2019-01-12 17:59:06.000000000', 'files': ['openstack_dashboard/dashboards/identity/users/tests.py', 'openstack_dashboard/dashboards/identity/users/views.py', 'openstack_dashboard/dashboards/identity/projects/tabs.py', 'openstack_dashboard/dashboards/identity/users/templates/users/_detail_overview.html', 'openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/identity/projects/templates/projects/_detail_overview.html', 'openstack_dashboard/dashboards/identity/users/tabs.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3a584a90c1ba8f5b06f3dd04747f193d9b003bdd', 'message': 'Show domain info in project and user detail panel\n\nDomain info in the user detail panel was previously displayed\nbut it has been broken after the user detail panel was tabbified.\nThis commit fixes the handling of context data. This covers\ndomain_name, project_name and extras.\nSimilar change is applied to the project detail panel too.\n\nChange-Id: I575ae9697783c36fdae5dd397d6783b979d0c4a6\nCloses-Bug: #1809284\n'}]",0,626622,3a584a90c1ba8f5b06f3dd04747f193d9b003bdd,14,4,4,841,,,0,"Show domain info in project and user detail panel

Domain info in the user detail panel was previously displayed
but it has been broken after the user detail panel was tabbified.
This commit fixes the handling of context data. This covers
domain_name, project_name and extras.
Similar change is applied to the project detail panel too.

Change-Id: I575ae9697783c36fdae5dd397d6783b979d0c4a6
Closes-Bug: #1809284
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/626622/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/projects/tabs.py', 'openstack_dashboard/dashboards/identity/users/views.py', 'openstack_dashboard/dashboards/identity/users/templates/users/_detail_overview.html', 'openstack_dashboard/dashboards/identity/projects/templates/projects/_detail_overview.html', 'openstack_dashboard/dashboards/identity/users/tabs.py']",5,1b6374d495c80b67772f3300f7ffec64f52402b2,bug/1809284,"import logging from django.conf import settingsfrom horizon import exceptionsfrom openstack_dashboard import api from openstack_dashboard import policy LOG = logging.getLogger(__name__) def _get_domain_name(self, user): domain_name = '' if api.keystone.VERSIONS.active >= 3: try: if policy.check(((""identity"", ""identity:get_domain""),), self.request): domain = api.keystone.domain_get( self.request, user.domain_id) domain_name = domain.name else: domain = api.keystone.get_default_domain(self.request) domain_name = domain.get('name') except Exception: exceptions.handle(self.request, _('Unable to retrieve user domain.')) return domain_name def _get_project_name(self, user): project_id = user.project_id if not project_id: return try: tenant = api.keystone.tenant_get(self.request, project_id) return tenant.name except Exception as e: LOG.error('Failed to get tenant %(project_id)s: %(reason)s', {'project_id': project_id, 'reason': e}) def _get_extras(self, user): if api.keystone.VERSIONS.active >= 3: extra_info = getattr(settings, 'USER_TABLE_EXTRA_INFO', {}) return dict((display_key, getattr(user, key, '')) for key, display_key in extra_info.items()) else: return {} def get_context_data(self, request): user = self.tab_group.kwargs['user'] return { ""user"": user, ""domain_name"": self._get_domain_name(user), 'extras': self._get_extras(user), 'project_name': self._get_project_name(user), }"," def get_context_data(self, request): return {""user"": self.tab_group.kwargs['user']}",104,64
openstack%2Fhorizon~master~Ic1dc6029ce2a1cf54d313e8320b7ca206f5dfaea,openstack/horizon,master,Ic1dc6029ce2a1cf54d313e8320b7ca206f5dfaea,Document horizon policies,MERGED,2018-12-26 18:37:15.000000000,2019-02-12 21:50:33.000000000,2019-02-12 21:50:33.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2018-12-26 18:37:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1382c639c8f639e8c46faf3d09f0739d1ba01c57', 'message': 'Document horizon policies\n\nThis commit tries to capture basic policies on back-end feature\nsupports and so on that have not documented so far.\n\nChange-Id: Ic1dc6029ce2a1cf54d313e8320b7ca206f5dfaea\n'}, {'number': 2, 'created': '2019-01-15 07:19:40.000000000', 'files': ['doc/source/contributor/index.rst', 'doc/source/install/system-requirements.rst', 'doc/source/contributor/policy.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8f39950a0ee66116a803fc5b2b2d4d194b0c10be', 'message': 'Document horizon policies\n\nThis commit tries to capture basic policies on back-end feature\nsupports and so on that have not documented so far.\n\nChange-Id: Ic1dc6029ce2a1cf54d313e8320b7ca206f5dfaea\n'}]",3,627416,8f39950a0ee66116a803fc5b2b2d4d194b0c10be,14,6,2,841,,,0,"Document horizon policies

This commit tries to capture basic policies on back-end feature
supports and so on that have not documented so far.

Change-Id: Ic1dc6029ce2a1cf54d313e8320b7ca206f5dfaea
",git fetch https://review.opendev.org/openstack/horizon refs/changes/16/627416/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/index.rst', 'doc/source/install/system-requirements.rst', 'doc/source/contributor/policy.rst']",3,1382c639c8f639e8c46faf3d09f0739d1ba01c57,stein-deprecations,"================ Project policies ================ This page collects basic policies on horizon development. Back-end service support ------------------------ * ``N`` release of horizon supports ``N`` and ``N-1`` releases of back-end OpenStack services (like nova, cinder, neutron and so on). This allows operators to upgrade horizon separately from other OpenStack services. * Horizon should check features in back-end services through APIs as much as possible by using micro-versioning for nova, cinder and so on and API extensions for neutron (and others if any). * Related to the previous item, features available in ``N-3`` releases (which means the recent four releases including the development version) are assumed without checking the availability of features to simplify the implementation. * Removals and deprecations of back-end feature supports basically follows `the standard deprecation policy <https://governance.openstack.org/tc/reference/tags/assert_follows-standard-deprecation.html>`__ defined by the technical committee, but there are some notes. Deprecations in back-end services are applied to corresponding horizon features and there is a case where some feature is dropped from horizon without an explicit deprecation in favor of a corresponding feature removal in a back-end service depending on a situation. Django support -------------- * Horizon usually syncs with `Django's Roadmap <https://www.djangoproject.com/weblog/2015/jun/25/roadmap/>`__ and supports LTS (long term support) versions of Django as of the feature freeze of each OpenStack release. Supports for other maintained Django versions are optional and best-effort. ",,43,5
openstack%2Fhorizon~master~I1c4578ec5a7f70a59c6348d76ad0c12956a18573,openstack/horizon,master,I1c4578ec5a7f70a59c6348d76ad0c12956a18573,Change the default SESSION_ENGINE to use cached sessions,MERGED,2019-01-14 23:08:34.000000000,2019-02-12 21:50:31.000000000,2019-02-12 21:50:31.000000000,"[{'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-14 23:08:34.000000000', 'files': ['releasenotes/notes/session-engine-bc6305bfb74a9beb.yaml', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a98468bef6b1bd8b3e762d4e22c8b83d27a8aa6a', 'message': 'Change the default SESSION_ENGINE to use cached sessions\n\nThis commit changes the default SESSION_ENGINE to the cached\nsessions and the default cached backend to memcached.\n\nThe cached sessions with memcahced is our current recommendation, but\nwe do not use it in our default settings and do not test it in our CI\n(horizon-dsvm-tempest-plugin). It is better to use the recommended\nconfigurations in our CI.\nThe previous default SESSION_ENGINE, the signed cookies, has\na limitation on the length o cookies and using keystone3 can hit this\neasily. It is not ready for production for most cases.\n\nFor a cache backend, considering multi-process web server deployments,\nmemcahced is recommended rather than a local memory backend.\n\nNote for developers: If you use ""tox -e runserver"" for developments,\nSESSION_ENGINE = \'django.contrib.sessions.backends.cache\' might not\nwork expectedly. From my testing, I was forced to log-in frequently\nwhen moving pages. If you hit this, my suggestion is to configure\nSESSION_ENGINE to django.contrib.sessions.backends.signed_cookies.\n\nChange-Id: I1c4578ec5a7f70a59c6348d76ad0c12956a18573\nCloses-Bug: #1736021\n'}]",0,630790,a98468bef6b1bd8b3e762d4e22c8b83d27a8aa6a,7,3,1,841,,,0,"Change the default SESSION_ENGINE to use cached sessions

This commit changes the default SESSION_ENGINE to the cached
sessions and the default cached backend to memcached.

The cached sessions with memcahced is our current recommendation, but
we do not use it in our default settings and do not test it in our CI
(horizon-dsvm-tempest-plugin). It is better to use the recommended
configurations in our CI.
The previous default SESSION_ENGINE, the signed cookies, has
a limitation on the length o cookies and using keystone3 can hit this
easily. It is not ready for production for most cases.

For a cache backend, considering multi-process web server deployments,
memcahced is recommended rather than a local memory backend.

Note for developers: If you use ""tox -e runserver"" for developments,
SESSION_ENGINE = 'django.contrib.sessions.backends.cache' might not
work expectedly. From my testing, I was forced to log-in frequently
when moving pages. If you hit this, my suggestion is to configure
SESSION_ENGINE to django.contrib.sessions.backends.signed_cookies.

Change-Id: I1c4578ec5a7f70a59c6348d76ad0c12956a18573
Closes-Bug: #1736021
",git fetch https://review.opendev.org/openstack/horizon refs/changes/90/630790/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/session-engine-bc6305bfb74a9beb.yaml', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py']",3,a98468bef6b1bd8b3e762d4e22c8b83d27a8aa6a,bug/1736021,"SESSION_ENGINE = 'django.contrib.sessions.backends.cache' CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': '127.0.0.1:11211', }, } ",SESSION_ENGINE = 'django.contrib.sessions.backends.signed_cookies',33,8
openstack%2Fhorizon~master~I378e58c7a80e2d00481a582eb3fa449f51c3612a,openstack/horizon,master,I378e58c7a80e2d00481a582eb3fa449f51c3612a,api.cinder: refactor microversioning logic,MERGED,2019-01-14 21:33:53.000000000,2019-02-12 21:50:28.000000000,2019-02-12 21:50:28.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-14 21:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8ff0fddbaf18738f2790a66d687ec91cc8954760', 'message': 'api.cinder: refactor microversioning logic\n\nThere are sevral similar logics to handle microversioning\nin Cinder API wrapper. This commit refactors them and\nintroduces _cinderclient_with_features() function.\n\nThe parent commit to fix bug 1810309 does not introduce\nthis logic to make it easy to backport the fix.\n\nChange-Id: I378e58c7a80e2d00481a582eb3fa449f51c3612a\nRelated-Bug: #1810309\n'}, {'number': 2, 'created': '2019-01-14 23:32:44.000000000', 'files': ['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/000da0f8fc2c0f6b69d9c6f8d32518c36794b19c', 'message': 'api.cinder: refactor microversioning logic\n\nThere are sevral similar logics to handle microversioning\nin Cinder API wrapper. This commit refactors them and\nintroduces _cinderclient_with_features() function.\n\nThe parent commit to fix bug 1810309 does not introduce\nthis logic to make it easy to backport the fix.\n\nChange-Id: I378e58c7a80e2d00481a582eb3fa449f51c3612a\nRelated-Bug: #1810309\n'}]",3,630775,000da0f8fc2c0f6b69d9c6f8d32518c36794b19c,12,5,2,841,,,0,"api.cinder: refactor microversioning logic

There are sevral similar logics to handle microversioning
in Cinder API wrapper. This commit refactors them and
introduces _cinderclient_with_features() function.

The parent commit to fix bug 1810309 does not introduce
this logic to make it easy to backport the fix.

Change-Id: I378e58c7a80e2d00481a582eb3fa449f51c3612a
Related-Bug: #1810309
",git fetch https://review.opendev.org/openstack/horizon refs/changes/75/630775/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/cinder.py', 'openstack_dashboard/api/microversions.py', 'openstack_dashboard/test/unit/api/test_cinder.py']",3,8ff0fddbaf18738f2790a66d687ec91cc8954760,bug/1810309," @mock.patch.object(api.cinder, '_cinderclient_with_features') mock_cinderclient.assert_called_once_with( self.request, ['limits_project_id_query'], message=test.IsA(str))"," @mock.patch.object(api.cinder, '_cinderclient_with_limits_project_id_query') mock_cinderclient.assert_called_once_with(self.request)",56,28
openstack%2Fansible-role-systemd_service~master~I6751765131f32393a1605eb2100bec46199d980a,openstack/ansible-role-systemd_service,master,I6751765131f32393a1605eb2100bec46199d980a,Build out the PrivateNetwork function for services,MERGED,2019-02-07 03:34:40.000000000,2019-02-12 21:44:59.000000000,2019-02-12 21:44:59.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 03:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/7a38367db7be3b88bbbcdcb03301afc44bcc38ce', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n""}, {'number': 2, 'created': '2019-02-07 03:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/eef1b9841d5ba6a47e2c0f312e4b5c3bf1900f10', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n""}, {'number': 3, 'created': '2019-02-07 03:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/ce4e079fab86f64fe8457c4c4951862a71d054e9', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n""}, {'number': 4, 'created': '2019-02-08 15:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/41d6e477d189a83cdca4e6b01f567d04b1d76822', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n""}, {'number': 5, 'created': '2019-02-08 18:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/f5c0e7483e1539f22349ea5daa4ecc0a06033f46', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n""}, {'number': 6, 'created': '2019-02-09 04:06:56.000000000', 'files': ['tasks/main.yml', 'templates/systemd-dhcp.network.j2', 'templates/systemd-service.j2', 'templates/systemd-netns@.service.j2', 'handlers/main.yml', 'tests/test.yml', 'templates/systemd-netns-access@.service.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/6285b6c6389134c53a5a98a0392b016a594bab16', 'message': ""Build out the PrivateNetwork function for services\n\nThis change adds the ability to effectively use the PrivateNetwork\nfunctionality systemd provides for services. Now, if enabled, services\ncan be created in a network namespace which isolates it from the reset\nof the host. Additional options have been added allowing access into the\nnetwork namespace over ephemeral devices as needed.\n\nHighlights:\n* Isolated private networking for services will sandbox using a stand\n  alone namespace which has no access to anything via the network.\n* Access into a private namespace can be provided over a single network\n  interface which can be IP'd via local DHCP + NAT or using an upstream\n  DHCP server.\n* Tests have been added to exercise the new functionality.\n\nAll of the funcality has been documented in the defaults of this role.\n\nChange-Id: I6751765131f32393a1605eb2100bec46199d980a\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n""}]",0,635396,6285b6c6389134c53a5a98a0392b016a594bab16,14,2,6,7353,,,0,"Build out the PrivateNetwork function for services

This change adds the ability to effectively use the PrivateNetwork
functionality systemd provides for services. Now, if enabled, services
can be created in a network namespace which isolates it from the reset
of the host. Additional options have been added allowing access into the
network namespace over ephemeral devices as needed.

Highlights:
* Isolated private networking for services will sandbox using a stand
  alone namespace which has no access to anything via the network.
* Access into a private namespace can be provided over a single network
  interface which can be IP'd via local DHCP + NAT or using an upstream
  DHCP server.
* Tests have been added to exercise the new functionality.

All of the funcality has been documented in the defaults of this role.

Change-Id: I6751765131f32393a1605eb2100bec46199d980a
Signed-off-by: Kevin Carter <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/96/635396/6 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'templates/systemd-dhcp.network.j2', 'templates/systemd-service.j2', 'templates/systemd-netns@.service.j2', 'handlers/main.yml', 'tests/test.yml', 'templates/systemd-netns-access@.service.j2', 'defaults/main.yml']",8,7a38367db7be3b88bbbcdcb03301afc44bcc38ce,serive-netns-macv,"# Systemd provides for the ability to start a given service in a network # namespace. When `systemd_PrivateNetwork` is `true` a service will be # started within a namepsace created using the name of the service unit. systemd_PrivateNetwork: false # When `systemd_PrivateNetwork` is enabled, it may be desirable to add a # specific link into the service namespace using the MACVLAN interface. # The option `systemd_PrivateNetworkIsolated`, when set to `false`, will # create a MACVLAN interface which binds to the host interface defined # by the option `systemd_PrivateNetworkInterface`; uses the gateway # interface by default. The MODE used by the MACVLAN interface can be # changed using the option `systemd_PrivateNetworkMode`. systemd_PrivateNetworkIsolated: true systemd_PrivateNetworkInterface: ""{{ ansible_default_ipv4['interface'] }}"" systemd_PrivateNetworkMode: bridge # When `systemd_PrivateNetworkIsolated` is disabled, an interface is # created on the host and within the service namespace. If this interface # needs an IP address DHCP can be enabled which will, by default, send # DHCP requests through the interface defined by the option # `systemd_PrivateNetworkInterface`. systemd_PrivateNetworkDHCP: false # DHCP can be localized to only the physical host using option # `systemd_PrivateNetworkLocalDHCP`. Setting this option to `true`, will # create a networkd configuration for DHCPServer using the MACVLAN interface # defined by `systemd_PrivateNetworkInterface`. The gateway set within the # service namespace will be set using `systemd_PrivateNetworkLocalDHCPGateway`. systemd_PrivateNetworkLocalDHCP: false systemd_PrivateNetworkLocalDHCPGateway: ""10.0.5.1/24"" ",systemd_PrivateNetwork: false,268,4
openstack%2Fopenstack-ansible-tests~master~Iaf5ee20e534a8279b5b563c820518bb176f0f4bb,openstack/openstack-ansible-tests,master,Iaf5ee20e534a8279b5b563c820518bb176f0f4bb,Clone the correct plugins repo for role tests,MERGED,2019-02-12 19:22:34.000000000,2019-02-12 21:38:58.000000000,2019-02-12 21:38:58.000000000,"[{'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 19:22:34.000000000', 'files': ['test-ansible-env-prep.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/bb9d690eb09360fe03bf16bcfa0ffa2e2e8f5826', 'message': 'Clone the correct plugins repo for role tests\n\nCurrently the role tests always clone the plugins repo without\nspecifying a branch. The tests also always use a git clone, even\nthough in zuul the repo is already cloned.\n\nThis patch ensures that the branch is specified when doing the\nclone, and also will just symlink to the existing zuul clone if\nit is present.\n\nChange-Id: Iaf5ee20e534a8279b5b563c820518bb176f0f4bb\n'}]",0,636426,bb9d690eb09360fe03bf16bcfa0ffa2e2e8f5826,8,3,1,6816,,,0,"Clone the correct plugins repo for role tests

Currently the role tests always clone the plugins repo without
specifying a branch. The tests also always use a git clone, even
though in zuul the repo is already cloned.

This patch ensures that the branch is specified when doing the
clone, and also will just symlink to the existing zuul clone if
it is present.

Change-Id: Iaf5ee20e534a8279b5b563c820518bb176f0f4bb
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/26/636426/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-env-prep.sh'],1,bb9d690eb09360fe03bf16bcfa0ffa2e2e8f5826,,"# The place where zuul clones dependent repositories to ZUUL_PLUGINS_CLONE_LOCATION=""/home/zuul/src/git.openstack.org/openstack/openstack-ansible-plugins"" # Use .gitreview as the key to determine the appropriate # branch to clone for tests. TESTING_BRANCH=$(awk -F'=' '/defaultbranch/ {print $2}' ""${WORKING_DIR}/.gitreview"") if [[ ""${TESTING_BRANCH}"" == """" ]]; then TESTING_BRANCH=""master"" fi # In zuul v3 any dependent repository is placed into # /home/zuul/src/git.openstack.org, so we check to see # if there is a tests checkout there already. If so, we # symlink that and use it. elif [[ -d ""${ZUUL_PLUGINS_CLONE_LOCATION}"" ]]; then ln -s ""${ZUUL_PLUGINS_CLONE_LOCATION}"" ""${ANSIBLE_PLUGIN_DIR}"" # Otherwise we're clearly not in zuul or using a previously setup # repo in some way, so just clone it from upstream. git clone -b ""${TESTING_BRANCH}"" \", git clone \,21,1
openstack%2Freleases~master~I08b3767c4419fa106f60861342bc5981c50100ec,openstack/releases,master,I08b3767c4419fa106f60861342bc5981c50100ec,Release cinder 10.0.9,ABANDONED,2019-02-12 17:51:11.000000000,2019-02-12 21:33:45.000000000,,"[{'_account_id': 7198}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 17:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/883988baccaadaf7c123b393c501b0d5e630210c', 'message': 'Release cinder 10.0.9\n\nRelease from stable/ocata.\n\nChange-Id: I08b3767c4419fa106f60861342bc5981c50100ec\n'}, {'number': 2, 'created': '2019-02-12 17:58:46.000000000', 'files': ['deliverables/ocata/cinder.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ef1e5726d9477fee09c9b3549812b7288d72bd44', 'message': 'Release cinder 10.0.9\n\nRelease from stable/ocata.\n\nChange-Id: I08b3767c4419fa106f60861342bc5981c50100ec\n'}]",1,636400,ef1e5726d9477fee09c9b3549812b7288d72bd44,6,2,2,5314,,,0,"Release cinder 10.0.9

Release from stable/ocata.

Change-Id: I08b3767c4419fa106f60861342bc5981c50100ec
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/636400/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/cinder.yaml'],1,883988baccaadaf7c123b393c501b0d5e630210c,release-cinder-10.0.9, - projects: - hash: 9dbcb24f0313c1187bc6269e61421bef4c45b3c9 repo: openstack/cinder version: 10.0.9,,4,0
openstack%2Fansible-role-systemd_networkd~master~I059eb00da5052e13ed6f178ff6ddb7508ae645e2,openstack/ansible-role-systemd_networkd,master,I059eb00da5052e13ed6f178ff6ddb7508ae645e2,Update home-page,MERGED,2019-01-12 09:43:18.000000000,2019-02-12 21:32:31.000000000,2019-02-12 21:32:31.000000000,"[{'_account_id': 7353}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-01-12 09:43:18.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/14c535f88d08a516115be4d80a7e674c9e732718', 'message': 'Update home-page\n\nChange-Id: I059eb00da5052e13ed6f178ff6ddb7508ae645e2\n'}]",0,630435,14c535f88d08a516115be4d80a7e674c9e732718,9,5,1,26297,,,0,"Update home-page

Change-Id: I059eb00da5052e13ed6f178ff6ddb7508ae645e2
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_networkd refs/changes/35/630435/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,14c535f88d08a516115be4d80a7e674c9e732718,,home-page = https://docs.openstack.org/ansible-role-systemd_networkd/latest/,home-page = http://docs.openstack.org/developer/ansible-systemd_networkd/,1,1
openstack%2Fgovernance~master~I48841570ff19b779b2e35de8218a8f56b408df92,openstack/governance,master,I48841570ff19b779b2e35de8218a8f56b408df92,apply 7 day rule to formal-vote items,MERGED,2019-02-12 18:46:44.000000000,2019-02-12 21:15:05.000000000,2019-02-12 21:15:05.000000000,"[{'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 18:46:44.000000000', 'files': ['tools/check_review_status.py'], 'web_link': 'https://opendev.org/openstack/governance/commit/f4d8b7ff5df8ee819de6b18a3d479e6100b24a71', 'message': 'apply 7 day rule to formal-vote items\n\nEnsure that the charter rule that formal-vote items stay open at least\n7 days is applied. This change interprets that rule to mean that if\nthe majority votes in favor of a change within the 7 day period, the 3\nday waiting period will include any of the remaining 7 days. So if the\nmajority is reached on day 1, the patch must stay open 7 days and if\nthe majority is reached on day 7 the patch must stay open an\nadditional 3 days.\n\nChange-Id: I48841570ff19b779b2e35de8218a8f56b408df92\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,636418,f4d8b7ff5df8ee819de6b18a3d479e6100b24a71,12,4,1,2472,,,0,"apply 7 day rule to formal-vote items

Ensure that the charter rule that formal-vote items stay open at least
7 days is applied. This change interprets that rule to mean that if
the majority votes in favor of a change within the 7 day period, the 3
day waiting period will include any of the remaining 7 days. So if the
majority is reached on day 1, the patch must stay open 7 days and if
the majority is reached on day 7 the patch must stay open an
additional 3 days.

Change-Id: I48841570ff19b779b2e35de8218a8f56b408df92
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/governance refs/changes/18/636418/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/check_review_status.py'],1,f4d8b7ff5df8ee819de6b18a3d479e6100b24a71,code-change, parts.append('last change on {}'.format(latest_created.date())) # At least 7 days old. if age < datetime.timedelta(8): time_to_approve = False parts.append('has not been open 7 days') earliest = str(latest_created.date() + datetime.timedelta(8)) elif reached_majority: # Wait at least 3 days after reaching majority., # Wait at least 3 days after reaching majority. if reached_majority:,10,3
openstack%2Fopenstack-ansible-tests~stable%2Frocky~Iaf5ee20e534a8279b5b563c820518bb176f0f4bb,openstack/openstack-ansible-tests,stable/rocky,Iaf5ee20e534a8279b5b563c820518bb176f0f4bb,Clone the correct plugins repo for role tests,MERGED,2019-02-12 19:23:49.000000000,2019-02-12 21:11:06.000000000,2019-02-12 21:11:06.000000000,"[{'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 19:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/d5b33dff0a1e5d492d3dd1a30bef85d9deffc504', 'message': 'Clone the correct plugins repo for role tests\n\nCurrently the role tests always clone the plugins repo without\nspecifying a branch. The tests also always use a git clone, even\nthough in zuul the repo is already cloned.\n\nThis patch ensures that the branch is specified when doing the\nclone, and also will just symlink to the existing zuul clone if\nit is present.\n\nChange-Id: Iaf5ee20e534a8279b5b563c820518bb176f0f4bb\n'}, {'number': 2, 'created': '2019-02-12 19:28:00.000000000', 'files': ['test-ansible-env-prep.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/20946d1e73805fbdb97c4fea3a1678cc408d4eac', 'message': 'Clone the correct plugins repo for role tests\n\nCurrently the role tests always clone the plugins repo without\nspecifying a branch. The tests also always use a git clone, even\nthough in zuul the repo is already cloned.\n\nThis patch ensures that the branch is specified when doing the\nclone, and also will just symlink to the existing zuul clone if\nit is present.\n\nChange-Id: Iaf5ee20e534a8279b5b563c820518bb176f0f4bb\n(cherry picked from commit bb9d690eb09360fe03bf16bcfa0ffa2e2e8f5826)\n'}]",0,636427,20946d1e73805fbdb97c4fea3a1678cc408d4eac,8,3,2,6816,,,0,"Clone the correct plugins repo for role tests

Currently the role tests always clone the plugins repo without
specifying a branch. The tests also always use a git clone, even
though in zuul the repo is already cloned.

This patch ensures that the branch is specified when doing the
clone, and also will just symlink to the existing zuul clone if
it is present.

Change-Id: Iaf5ee20e534a8279b5b563c820518bb176f0f4bb
(cherry picked from commit bb9d690eb09360fe03bf16bcfa0ffa2e2e8f5826)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/27/636427/2 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-env-prep.sh'],1,d5b33dff0a1e5d492d3dd1a30bef85d9deffc504,,"# The place where zuul clones dependent repositories to ZUUL_PLUGINS_CLONE_LOCATION=""/home/zuul/src/git.openstack.org/openstack/openstack-ansible-plugins"" # Use .gitreview as the key to determine the appropriate # branch to clone for tests. TESTING_BRANCH=$(awk -F'=' '/defaultbranch/ {print $2}' ""${WORKING_DIR}/.gitreview"") if [[ ""${TESTING_BRANCH}"" == """" ]]; then TESTING_BRANCH=""master"" fi # In zuul v3 any dependent repository is placed into # /home/zuul/src/git.openstack.org, so we check to see # if there is a tests checkout there already. If so, we # symlink that and use it. elif [[ -d ""${ZUUL_PLUGINS_CLONE_LOCATION}"" ]]; then ln -s ""${ZUUL_PLUGINS_CLONE_LOCATION}"" ""${ANSIBLE_PLUGIN_DIR}"" # Otherwise we're clearly not in zuul or using a previously setup # repo in some way, so just clone it from upstream. git clone -b ""${TESTING_BRANCH}"" \", git clone \,21,1
openstack%2Fopenstack-helm-images~master~I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02,openstack/openstack-helm-images,master,I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02,[CEPH] Add perccli utility to ceph-daemon image,MERGED,2019-02-07 16:02:58.000000000,2019-02-12 21:02:27.000000000,2019-02-12 21:02:27.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28372}, {'_account_id': 29132}]","[{'number': 1, 'created': '2019-02-07 16:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/0bc910e90498f7a964002fe41bd6867db13586ff', 'message': '[CEPH] Add vendor utilities to ceph-daemon image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n'}, {'number': 2, 'created': '2019-02-07 18:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f6db8437c95d766ddc332fbef62622c249fae695', 'message': ""[CEPH] Add perccli utility to ceph-daemon image\n\nAdd Dell's perccli utility to the ceph-daemon docker image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n""}, {'number': 3, 'created': '2019-02-07 18:45:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/5e4c57b7fe84da956ad02b0967158592113bcbe4', 'message': ""[CEPH] Add perccli utility to ceph-daemon image\n\nAdd Dell's perccli utility to the ceph-daemon docker image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n""}, {'number': 4, 'created': '2019-02-07 18:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/565536705570cebca5d1d60d9aea78c8e208079a', 'message': ""[CEPH] Add perccli utility to ceph-daemon image\n\nAdd Dell's perccli utility to the ceph-daemon docker image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n""}, {'number': 5, 'created': '2019-02-07 20:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/ff28e04b7b7f77e1b7dd73e9d6a8326e69da59ac', 'message': ""[CEPH] Add perccli utility to ceph-daemon image\n\nAdd Dell's perccli utility to the ceph-daemon docker image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n""}, {'number': 6, 'created': '2019-02-08 11:41:25.000000000', 'files': ['ceph-daemon/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/45e907799b7859c379e36a3c6ff3422635529ea6', 'message': ""[CEPH] Add perccli utility to ceph-daemon image\n\nAdd Dell's perccli utility to the ceph-daemon docker image\n\nChange-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02\n""}]",1,635553,45e907799b7859c379e36a3c6ff3422635529ea6,22,6,6,29268,,,0,"[CEPH] Add perccli utility to ceph-daemon image

Add Dell's perccli utility to the ceph-daemon docker image

Change-Id: I0ae167b2fadd6ef19f220f35dd4ea1ca5f728e02
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/53/635553/5 && git format-patch -1 --stdout FETCH_HEAD,['ceph-daemon/Dockerfile.ubuntu_xenial'],1,0bc910e90498f7a964002fe41bd6867db13586ff,megacli," apt-key adv --fetch-keys http://hwraid.le-vert.net/debian/hwraid.le-vert.net.gpg.key ;\ echo ""deb http://hwraid.le-vert.net/ubuntu xenial main"" | tee /etc/apt/sources.list.d/hwraid.list ;\ jq \ megactl \ hpacucli \ lsiutil ;\", jq ;\,6,1
openstack%2Fopenstack-ansible-os_tempest~master~I698f76a00c626cdf4fc01f3b3ad09be6ed1006be,openstack/openstack-ansible-os_tempest,master,I698f76a00c626cdf4fc01f3b3ad09be6ed1006be,Add option to disable router ping,MERGED,2019-02-11 20:12:06.000000000,2019-02-12 20:51:35.000000000,2019-02-12 20:51:35.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12393}, {'_account_id': 16011}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 20:12:06.000000000', 'files': ['tasks/tempest_resources.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/de400ffc2d0aa59390d487b96bacc42ab32a51c3', 'message': 'Add option to disable router ping\n\nIn some of the os_neutron gates there is no route to ping the tempest\nrouter ip from localhost.  The router is validated by the neutron\ntempest tests so there is no need to ping it in this scenario.\n\nChange-Id: I698f76a00c626cdf4fc01f3b3ad09be6ed1006be\n'}]",0,636211,de400ffc2d0aa59390d487b96bacc42ab32a51c3,9,5,1,28665,,,0,"Add option to disable router ping

In some of the os_neutron gates there is no route to ping the tempest
router ip from localhost.  The router is validated by the neutron
tempest tests so there is no need to ping it in this scenario.

Change-Id: I698f76a00c626cdf4fc01f3b3ad09be6ed1006be
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/11/636211/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/tempest_resources.yml', 'defaults/main.yml']",2,de400ffc2d0aa59390d487b96bacc42ab32a51c3,router_ping,tempest_network_ping_gateway: True,,2,0
openstack%2Fnova-powervm~master~I86c273bf1d1c5753ce68ab51f6922c323d720cb2,openstack/nova-powervm,master,I86c273bf1d1c5753ce68ab51f6922c323d720cb2,Add the device_id parameter to discover_hdisk,MERGED,2019-01-15 17:33:05.000000000,2019-02-12 20:50:17.000000000,2019-02-12 20:50:17.000000000,"[{'_account_id': 10608}, {'_account_id': 13557}, {'_account_id': 14581}, {'_account_id': 16128}, {'_account_id': 16551}, {'_account_id': 22348}, {'_account_id': 28222}]","[{'number': 1, 'created': '2019-01-15 17:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/e92080602f23e0a19fafb370296fccd91421f5d7', 'message': 'Add the device_id parameter to discover_hdisk\n\nChange-Id: I86c273bf1d1c5753ce68ab51f6922c323d720cb2\n'}, {'number': 2, 'created': '2019-01-29 22:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0a44ae4741909d4bc8bd063479913313185d5365', 'message': 'Add the device_id parameter to discover_hdisk\n\nLUA recovery, the job that tells the VIOS to discover a specific\nhdisk, may find multiple disks at the same ITL. Without the device ID\nLUA recovery will return an error when this happens.\n\nFor most volume backed storages the device ID is the base 64 encoded\nvalue of the pg83 identifier. This change enables the passing of the\ndeviceID to discover_hdisk to avoid the multiple hdisks at the same\nITL error.\n\nChange-Id: I86c273bf1d1c5753ce68ab51f6922c323d720cb2\n'}, {'number': 3, 'created': '2019-02-01 15:57:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/3a7a2b9c2418c64090de01a754d49e08192e5829', 'message': 'Add the device_id parameter to discover_hdisk\n\nLUA recovery, the job that tells the VIOS to discover a specific\nhdisk, may find multiple disks at the same ITL. Without the device ID\nLUA recovery will return an error when this happens.\n\nFor most volume backed storages the device ID is the base 64 encoded\nvalue of the pg83 identifier. This change enables the passing of the\ndeviceID to discover_hdisk to avoid the multiple hdisks at the same\nITL error. It also bumps the pypowervm version for the device_id\nsupport in discover_hdisk.\n\nChange-Id: I86c273bf1d1c5753ce68ab51f6922c323d720cb2\n'}, {'number': 4, 'created': '2019-02-01 16:58:23.000000000', 'files': ['requirements.txt', 'lower-constraints.txt', 'nova_powervm/tests/virt/powervm/volume/test_vscsi.py', 'nova_powervm/virt/powervm/volume/vscsi.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b3f9b9a5c290fb39c02c507da3739e832c7fc9cf', 'message': 'Add the device_id parameter to discover_hdisk\n\nLUA recovery, the job that tells the VIOS to discover a specific\nhdisk, may find multiple disks at the same ITL. Without the device ID\nLUA recovery will return an error when this happens.\n\nFor most volume backed storages the device ID is the base 64 encoded\nvalue of the pg83 identifier. This change enables the passing of the\ndeviceID to discover_hdisk to avoid the multiple hdisks at the same\nITL error. It also bumps the pypowervm version for the device_id\nsupport in discover_hdisk.\n\nChange-Id: I86c273bf1d1c5753ce68ab51f6922c323d720cb2\n'}]",5,631031,b3f9b9a5c290fb39c02c507da3739e832c7fc9cf,37,7,4,13557,,,0,"Add the device_id parameter to discover_hdisk

LUA recovery, the job that tells the VIOS to discover a specific
hdisk, may find multiple disks at the same ITL. Without the device ID
LUA recovery will return an error when this happens.

For most volume backed storages the device ID is the base 64 encoded
value of the pg83 identifier. This change enables the passing of the
deviceID to discover_hdisk to avoid the multiple hdisks at the same
ITL error. It also bumps the pypowervm version for the device_id
support in discover_hdisk.

Change-Id: I86c273bf1d1c5753ce68ab51f6922c323d720cb2
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/31/631031/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/virt/powervm/volume/vscsi.py'],1,e92080602f23e0a19fafb370296fccd91421f5d7,lua_uid_param,"import base64 device_id = self.connection_info.get('data', {}).get('pg83NAA') if device_id: device_id = base64.b64encode(device_id) vios_w.uuid, itls, device_id=device_id)"," vios_w.uuid, itls)",7,2
openstack%2Fnova~master~I064a52ebd17488334f4ecb88eaae69703a101ae6,openstack/nova,master,I064a52ebd17488334f4ecb88eaae69703a101ae6,Trivial: reorder hashes according to object_hashes.txt,MERGED,2019-02-12 03:48:33.000000000,2019-02-12 20:43:19.000000000,2019-02-12 16:37:09.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-12 03:48:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8caea0c8b521976d0bf05053bddc3294263b0aab', 'message': ""Trivial: reorder hashes according to object_hashes.txt\n\nThis is really because I wanted to be able to copy/paste from\nobject_hashes.txt in the subsequent patch and didn't want to introduce\nunrelated ordering changes.\n\nChange-Id: I064a52ebd17488334f4ecb88eaae69703a101ae6\n""}, {'number': 2, 'created': '2019-02-12 03:50:33.000000000', 'files': ['nova/tests/unit/objects/test_objects.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7856a861634cfbdc55e923c6bd228b5059648fa8', 'message': ""Trivial: reorder hashes according to object_hashes.txt\n\nThis is really because I wanted to be able to copy/paste from\nobject_hashes.txt in a subsequent patch and didn't want to introduce\nunrelated ordering changes.\n\nChange-Id: I064a52ebd17488334f4ecb88eaae69703a101ae6\n""}]",0,636261,7856a861634cfbdc55e923c6bd228b5059648fa8,14,8,2,8864,,,0,"Trivial: reorder hashes according to object_hashes.txt

This is really because I wanted to be able to copy/paste from
object_hashes.txt in a subsequent patch and didn't want to introduce
unrelated ordering changes.

Change-Id: I064a52ebd17488334f4ecb88eaae69703a101ae6
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/636261/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/objects/test_objects.py'],1,8caea0c8b521976d0bf05053bddc3294263b0aab,bp/numa-aware-live-migration," 'CpuDiagnostics': '1.0-d256f2e442d1b837735fd17dfe8e3d47', 'HVSpec': '1.2-de06bcec472a2f04966b855a49c46b41', 'LibvirtLiveMigrateBDMInfo': '1.1-5f4a68873560b6f834b74e7861d71aaf', 'LibvirtLiveMigrateData': '1.9-7082cc7dd48ca49df71fe3846521b2f3', 'NicDiagnostics': '1.0-895e9ad50e0f56d5258585e3e066aea5', 'PciDevice': '1.6-2a2612baaa1786679e52084e82ca7e66', 'SCSIDeviceBus': '1.0-61c1e89a00901069ab1cf2991681533b', 'TaskLog': '1.0-78b0534366f29aa3eebb01860fbe18fe', 'TaskLogList': '1.0-cc8cce1af8a283b9d28b55fcd682e777', 'VMwareLiveMigrateData': '1.0-a3cc858a2bf1d3806d6f57cfaa1fb98a', 'XenapiLiveMigrateData': '1.4-7dc9417e921b2953faa6751f18785f3f'"," 'CpuDiagnostics': '1.0-d256f2e442d1b837735fd17dfe8e3d47', 'HVSpec': '1.2-de06bcec472a2f04966b855a49c46b41', 'LibvirtLiveMigrateBDMInfo': '1.1-5f4a68873560b6f834b74e7861d71aaf', 'LibvirtLiveMigrateData': '1.9-7082cc7dd48ca49df71fe3846521b2f3', 'NicDiagnostics': '1.0-895e9ad50e0f56d5258585e3e066aea5', 'PciDevice': '1.6-2a2612baaa1786679e52084e82ca7e66', 'SCSIDeviceBus': '1.0-61c1e89a00901069ab1cf2991681533b', 'TaskLog': '1.0-78b0534366f29aa3eebb01860fbe18fe', 'TaskLogList': '1.0-cc8cce1af8a283b9d28b55fcd682e777', 'VMwareLiveMigrateData': '1.0-a3cc858a2bf1d3806d6f57cfaa1fb98a', 'XenapiLiveMigrateData': '1.4-7dc9417e921b2953faa6751f18785f3f',",11,11
openstack%2Fneutron~master~I8d0321487e4b406ead7a237156ef2f221fb512b9,openstack/neutron,master,I8d0321487e4b406ead7a237156ef2f221fb512b9,Remove redundant event listening logic from neutron/db/api,MERGED,2019-02-08 23:14:44.000000000,2019-02-12 20:37:15.000000000,2019-02-12 08:42:08.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11816}, {'_account_id': 11975}, {'_account_id': 14258}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27546}]","[{'number': 1, 'created': '2019-02-08 23:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58dee20f6ab4b08052d3208ae10c871754c1b4a6', 'message': 'Remove redundant event listening logic from neutron/db/api\n\nIn I3e702b99fd5084e8090f93c384aa1f704edceaff, the event listening\nfeatures which handle expiration of relationships was ""rehomed""\nto neutron-lib.   In fact it was duplicated, so that these events\nrun twice.    This patch removes the events from neutron as it is\na very bad idea for this much complexity to be running twice.\n\nChange-Id: I8d0321487e4b406ead7a237156ef2f221fb512b9\n'}, {'number': 2, 'created': '2019-02-09 17:58:56.000000000', 'files': ['neutron/common/utils.py', 'neutron/db/api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d83b3d3468d42ab37ce3c79f0d7a00696e84013c', 'message': 'Remove redundant event listening logic from neutron/db/api\n\nIn I3e702b99fd5084e8090f93c384aa1f704edceaff, the event listening\nfeatures which handle expiration of relationships was ""rehomed""\nto neutron-lib.   In fact it was duplicated, so that these events\nrun twice.    This patch removes the events from neutron as it is\na very bad idea for this much complexity to be running twice.\n\nChange-Id: I8d0321487e4b406ead7a237156ef2f221fb512b9\n'}]",0,635978,d83b3d3468d42ab37ce3c79f0d7a00696e84013c,24,12,2,11816,,,0,"Remove redundant event listening logic from neutron/db/api

In I3e702b99fd5084e8090f93c384aa1f704edceaff, the event listening
features which handle expiration of relationships was ""rehomed""
to neutron-lib.   In fact it was duplicated, so that these events
run twice.    This patch removes the events from neutron as it is
a very bad idea for this much complexity to be running twice.

Change-Id: I8d0321487e4b406ead7a237156ef2f221fb512b9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/78/635978/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/api.py'],1,58dee20f6ab4b08052d3208ae10c871754c1b4a6,remove_db_api, ,"import weakref from neutron_lib.db import model_base import sqlalchemy from sqlalchemy import event # noqa from sqlalchemy import orm # Expire relationships when foreign key changes. # # NOTE(ihrachys) Arguably, it's a sqlalchemy anti-pattern to access child # models directly and through parent relationships in the same session. But # since OVO mechanism is built around synthetic fields that assume this mixed # access is possible, we keep it here until we find a way to migrate OVO # synthetic fields to better mechanism that would update child models via # parents. Even with that, there are multiple places in plugin code where we # mix access when using models directly; those occurrences would need to be # fixed too to be able to remove this hook and explicit expire() calls. # # Adopted from the following recipe: # https://bitbucket.org/zzzeek/sqlalchemy/wiki/UsageRecipes # /ExpireRelationshipOnFKChange # # ...then massively changed to actually work for all neutron backref cases. # # TODO(ihrachys) at some point these event handlers should be extended to also # automatically refresh values for expired attributes def _expire_for_fk_change(target, fk_value, relationship_prop, column_attr): """"""Expire relationship attributes when a many-to-one column changes."""""" sess = orm.object_session(target) # subnets and network's many-to-one relationship is used as example in the # comments in this function if sess is not None: # optional behavior #1 - expire the ""Network.subnets"" # collection on the existing ""network"" object if relationship_prop.back_populates and \ relationship_prop.key in target.__dict__: obj = getattr(target, relationship_prop.key) if obj is not None and sqlalchemy.inspect(obj).persistent: sess.expire(obj, [relationship_prop.back_populates]) # optional behavior #2 - expire the ""Subnet.network"" if sqlalchemy.inspect(target).persistent: sess.expire(target, [relationship_prop.key]) # optional behavior #3 - ""trick"" the ORM by actually # setting the value ahead of time, then emitting a load # for the attribute so that the *new* Subnet.network # is loaded. Then, expire Network.subnets on *that*. # Other techniques here including looking in the identity # map for ""value"", if this is a simple many-to-one get. if relationship_prop.back_populates: target.__dict__[column_attr] = fk_value new = getattr(target, relationship_prop.key) if new is not None: if sqlalchemy.inspect(new).persistent: sess.expire(new, [relationship_prop.back_populates]) else: # no Session yet, do it later. This path is reached from the 'expire' # listener setup by '_expire_prop_on_col' below, when a foreign key # is directly assigned to in the many to one side of a relationship. # i.e. assigning directly to Subnet.network_id before Subnet is added # to the session if target not in _emit_on_pending: _emit_on_pending[target] = [] _emit_on_pending[target].append( (fk_value, relationship_prop, column_attr)) _emit_on_pending = weakref.WeakKeyDictionary() @event.listens_for(orm.session.Session, ""pending_to_persistent"") def _pending_callables(session, obj): """"""Expire relationships when a new object w/ a foreign key becomes persistent """""" if obj is None: return args = _emit_on_pending.pop(obj, []) for a in args: if a is not None: _expire_for_fk_change(obj, *a) @event.listens_for(orm.session.Session, ""persistent_to_deleted"") def _persistent_to_deleted(session, obj): """"""Expire relationships when an object w/ a foreign key becomes deleted"""""" mapper = sqlalchemy.inspect(obj).mapper for prop in mapper.relationships: if prop.direction is orm.interfaces.MANYTOONE: for col in prop.local_columns: colkey = mapper.get_property_by_column(col).key _expire_for_fk_change(obj, None, prop, colkey) @event.listens_for(model_base.BASEV2, ""attribute_instrument"", propagate=True) def _listen_for_changes(cls, key, inst): mapper = sqlalchemy.inspect(cls) if key not in mapper.relationships: return prop = inst.property if prop.direction is orm.interfaces.MANYTOONE: for col in prop.local_columns: colkey = mapper.get_property_by_column(col).key _expire_prop_on_col(cls, prop, colkey) elif prop.direction is orm.interfaces.ONETOMANY: remote_mapper = prop.mapper # the collection *has* to have a MANYTOONE backref so we # can look up the parent. so here we make one if it doesn't # have it already, as is the case in this example if not prop.back_populates: name = ""_%s_backref"" % prop.key backref_prop = orm.relationship( prop.parent, back_populates=prop.key) remote_mapper.add_property(name, backref_prop) prop.back_populates = name def _expire_prop_on_col(cls, prop, colkey): @event.listens_for(getattr(cls, colkey), ""set"") def expire(target, value, oldvalue, initiator): """"""Expire relationships when the foreign key attribute on an object changes """""" _expire_for_fk_change(target, value, prop, colkey)",0,128
openstack%2Ftripleo-ci~master~Ib5b23d826f055f511f1de19555ea7d382865f51d,openstack/tripleo-ci,master,Ib5b23d826f055f511f1de19555ea7d382865f51d,Add collecting files for hosts without zuul user,MERGED,2019-02-12 10:03:45.000000000,2019-02-12 20:36:53.000000000,2019-02-12 20:36:52.000000000,"[{'_account_id': 9592}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-12 10:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fd2ffce024bd23ad89dbc6642b3617a30b1d0a6f', 'message': 'Add collecting files for freeipa job\n\nChange-Id: Ib5b23d826f055f511f1de19555ea7d382865f51d\n'}, {'number': 2, 'created': '2019-02-12 14:09:11.000000000', 'files': ['toci-quickstart/config/collect-logs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ea96669860a1447ac889621add0b117c9c1a8032', 'message': 'Add collecting files for hosts without zuul user\n\nSet collecting files vars as independent on user names,\nit will allow to collect logs from nodes without zuul user\nChange-Id: Ib5b23d826f055f511f1de19555ea7d382865f51d\n'}]",0,636294,ea96669860a1447ac889621add0b117c9c1a8032,13,6,2,10969,,,0,"Add collecting files for hosts without zuul user

Set collecting files vars as independent on user names,
it will allow to collect logs from nodes without zuul user
Change-Id: Ib5b23d826f055f511f1de19555ea7d382865f51d
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/94/636294/2 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/collect-logs.yml'],1,fd2ffce024bd23ad89dbc6642b3617a30b1d0a6f,fipalog, - /home/*/*.log - /home/*/*.sh,,2,0
openstack%2Foctavia~master~I41ce6843fb53fa21ab84e5b1d0734e70380d716a,openstack/octavia,master,I41ce6843fb53fa21ab84e5b1d0734e70380d716a,Add amphora agent configuration update admin API,MERGED,2019-01-24 01:41:31.000000000,2019-02-12 20:29:02.000000000,2019-02-12 20:29:02.000000000,"[{'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 29621}]","[{'number': 1, 'created': '2019-01-24 01:41:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/35c62f07a2c7873a9978a66573620c3bc91b72af', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 2, 'created': '2019-01-24 01:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0a85892d18654f08c3f21a9b4547d1e94576060c', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 3, 'created': '2019-01-24 02:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d549104625a528c2875982468a645c8cf4c0b75b', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 4, 'created': '2019-01-25 00:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fcac2abd2be7f5d2e608eb34fdf6a5dc7897b7ad', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 5, 'created': '2019-01-25 00:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fe0d6342197f93b5eb32945b2d31a5f47a54faba', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 6, 'created': '2019-01-25 22:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a028da8a4e1c5a90f6db11fc0f8bf00b731d5615', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 7, 'created': '2019-01-31 21:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/733ba28c19b380aadd15bf596eda61a9a8af92d0', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}, {'number': 8, 'created': '2019-02-12 01:30:54.000000000', 'files': ['octavia/tests/unit/controller/worker/test_controller_worker.py', 'octavia/controller/worker/flows/amphora_flows.py', 'api-ref/source/v2/examples/amphora-config-curl', 'octavia/tests/functional/api/test_root_controller.py', 'octavia/tests/functional/api/v2/test_amphora.py', 'releasenotes/notes/Add-amphora-agent-config-update-API-298b31e6c0cd715c.yaml', 'octavia/tests/unit/controller/worker/flows/test_amphora_flows.py', 'octavia/tests/functional/api/v2/base.py', 'octavia/common/constants.py', 'api-ref/source/v2/amphora.inc', 'octavia/api/root_controller.py', 'octavia/controller/queue/endpoint.py', 'octavia/api/v2/controllers/amphora.py', 'octavia/policies/amphora.py', 'octavia/tests/unit/controller/queue/test_endpoint.py', 'octavia/controller/worker/controller_worker.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/52ffdd16a6d734361a3d6f71b1869809d36678cc', 'message': ""Add amphora agent configuration update admin API\n\nThis patch adds a new admin API that updates an amphora's agent\nconfiguration.\n\nChange-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a\n""}]",3,632842,52ffdd16a6d734361a3d6f71b1869809d36678cc,30,6,8,11628,,,0,"Add amphora agent configuration update admin API

This patch adds a new admin API that updates an amphora's agent
configuration.

Change-Id: I41ce6843fb53fa21ab84e5b1d0734e70380d716a
",git fetch https://review.opendev.org/openstack/octavia refs/changes/42/632842/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/unit/controller/worker/test_controller_worker.py', 'octavia/controller/worker/flows/amphora_flows.py', 'octavia/common/constants.py', 'api-ref/source/v2/examples/amphora-config-curl', 'api-ref/source/v2/amphora.inc', 'releasenotes/notes/Add-amphora-agent-config-update-API-298b31e6c0cd715c.yaml', 'octavia/controller/queue/endpoint.py', 'octavia/api/v2/controllers/amphora.py', 'octavia/policies/amphora.py', 'octavia/controller/worker/controller_worker.py']",10,35c62f07a2c7873a9978a66573620c3bc91b72af,amp-update-api," def update_amphora_agent_config(self, amphora_id): """"""Update the amphora agent configuration. Note: This will update the amphora agent configuration file and update the running configuration for mutatable configuration items. :param amphora_id: ID of the amphora to update. :returns: None """""" LOG.info(""Start amphora agent configuration update, amphora's id "" ""is: %s"", amphora_id) amp = self._amphora_repo.get(db_apis.get_session(), id=amphora_id) lb = self._amphora_repo.get_lb_for_amphora(db_apis.get_session(), amphora_id) flavor = {} if lb.flavor_id: flavor = self._flavor_repo.get_flavor_metadata_dict( db_apis.get_session(), lb.flavor_id) update_amphora_tf = self._taskflow_load( self._amphora_flows.update_amphora_config_flow(), store={constants.AMPHORA: amp, constants.FLAVOR: flavor}) with tf_logging.DynamicLoggingListener(update_amphora_tf, log=LOG): update_amphora_tf.run()",,162,1
openstack%2Fopenstack-virtual-baremetal~master~I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1,openstack/openstack-virtual-baremetal,master,I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1,Import auth with try/except,MERGED,2019-01-29 09:10:41.000000000,2019-02-12 20:17:45.000000000,2019-02-12 20:17:45.000000000,"[{'_account_id': 6928}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-01-29 09:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/ebf7793f0f1a5286546d6c1c41de2a35f6bf85bc', 'message': 'WIP: Import auth with try/except\n\nChange-Id: I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1\n'}, {'number': 2, 'created': '2019-01-30 10:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/027aeab55b6bd0eda5f1dd90e21ae62a4efabe0a', 'message': 'WIP: Import auth with try/except\n\nChange-Id: I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1\n'}, {'number': 3, 'created': '2019-01-30 10:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/0a03c9e6c0065dd2cd88a565855678c82504895a', 'message': 'Import auth with try/except\n\nTo make it pass python2/3 linters and fix OVB stack creating.\n\nChange-Id: I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1\n'}, {'number': 4, 'created': '2019-02-12 19:33:32.000000000', 'files': ['openstack_virtual_baremetal/deploy.py'], 'web_link': 'https://opendev.org/openstack/openstack-virtual-baremetal/commit/53c6fe95a8e31093ced0056c104ef6174e475390', 'message': 'Import auth with try/except\n\nTo make it pass python2/3 linters and fix OVB stack creating.\n\nChange-Id: I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1\nRelated-Bug: 1815660\n'}]",4,633681,53c6fe95a8e31093ced0056c104ef6174e475390,25,5,4,10969,,,0,"Import auth with try/except

To make it pass python2/3 linters and fix OVB stack creating.

Change-Id: I6994f2f31cf16b9ccd73e8d92c029ff0789c54c1
Related-Bug: 1815660
",git fetch https://review.opendev.org/openstack/openstack-virtual-baremetal refs/changes/81/633681/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_virtual_baremetal/deploy.py'],1,ebf7793f0f1a5286546d6c1c41de2a35f6bf85bc,fovb,try: from openstack_virtual_baremetal import auth except ImportError: import auth,from openstack_virtual_baremetal import auth,4,1
openstack%2Fcinder~master~I47fe1ff2dd5e24fffd5118aeab9473774eb58a61,openstack/cinder,master,I47fe1ff2dd5e24fffd5118aeab9473774eb58a61,Fix for HPE MSA 2050 login failures,MERGED,2019-01-18 03:20:17.000000000,2019-02-12 20:03:56.000000000,2019-02-01 21:24:53.000000000,"[{'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-01-18 03:20:17.000000000', 'files': ['cinder/volume/drivers/dothill/dothill_client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0565732a161ccc8bbef729019f7a24f2d862e606', 'message': ""Fix for HPE MSA 2050 login failures\n\nWhen authenticating to the array, use the 'response-type-numeric'\nvalue to determine success, rather than doing a string match against the\n'response-type' string, which is not guaranteed to be consistent.\n\nChange-Id: I47fe1ff2dd5e24fffd5118aeab9473774eb58a61\nCloses-Bug: #1808968\n""}]",0,631699,0565732a161ccc8bbef729019f7a24f2d862e606,40,31,1,17042,,,0,"Fix for HPE MSA 2050 login failures

When authenticating to the array, use the 'response-type-numeric'
value to determine success, rather than doing a string match against the
'response-type' string, which is not guaranteed to be consistent.

Change-Id: I47fe1ff2dd5e24fffd5118aeab9473774eb58a61
Closes-Bug: #1808968
",git fetch https://review.opendev.org/openstack/cinder refs/changes/99/631699/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/dothill/dothill_client.py'],1,0565732a161ccc8bbef729019f7a24f2d862e606,bug/1808968," # The 'return-code' property is not valid in this context, so we # we check value of 'response-type-numeric' (0 => Success) rtn = tree.findtext("".//PROPERTY[@name='response-type-numeric']"") session_key = tree.findtext("".//PROPERTY[@name='response']"") if rtn == '0': self._session_key = session_key"," if (tree.findtext("".//PROPERTY[@name='response-type']"") == ""success""): self._session_key = ( tree.findtext("".//PROPERTY[@name='response']""))",6,4
openstack%2Fhorizon~master~I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b,openstack/horizon,master,I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b,Add a prompt on the Create Volume form,MERGED,2019-01-23 08:44:45.000000000,2019-02-12 19:58:04.000000000,2019-02-12 19:58:04.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 5623}, {'_account_id': 8648}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-01-23 08:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/518a73f1af2829927ce7009e88769ba60f58588c', 'message': 'Add a prompt on the Create Volume page\n\non the image page, create a volume,\ndo not enter the volume size, no error message\n\nChange-Id: I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b\nCloses-Bug: #1812965\n'}, {'number': 2, 'created': '2019-01-25 02:03:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9783fb3ca822e40dd6da5f9766f4f9fc14324b87', 'message': 'Add a prompt on the Create Volume form\n\non create volume form,\ndo not enter the volume size and no error message shown\n\nChange-Id: I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b\nCloses-Bug: #1812965\n'}, {'number': 3, 'created': '2019-02-12 01:28:03.000000000', 'files': ['openstack_dashboard/static/app/core/images/steps/create-volume/create-volume.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/07ec6deb591b0820de702aec709f7162532e1c79', 'message': 'Add a prompt on the Create Volume form\n\non create volume form,\ndo not enter the volume size and no error message shown\n\nChange-Id: I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b\nCloses-Bug: #1812965\n'}]",2,632650,07ec6deb591b0820de702aec709f7162532e1c79,16,6,3,27822,,,0,"Add a prompt on the Create Volume form

on create volume form,
do not enter the volume size and no error message shown

Change-Id: I1b3c0d2cdddb77d5a3797d1af8e23299ed8f131b
Closes-Bug: #1812965
",git fetch https://review.opendev.org/openstack/horizon refs/changes/50/632650/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/app/core/images/steps/create-volume/create-volume.html'],1,518a73f1af2829927ce7009e88769ba60f58588c,bug/1812965," <div class=""form-group"" ng-class=""{'has-error':volumeForm['volume-size'].$invalid && volumeForm['volume-size'].$dirty}""> <p class=""help-block alert alert-danger"" ng-show=""volumeForm['volume-size'].$invalid && volumeForm['volume-size'].$dirty""> <translate> Volume size is required and at least 1 </translate> </p>"," <div class=""form-group"">",7,1
openstack%2Fopenstack-helm-addons~master~I2dd9a667c6b33575324c179a8c10c394bf07ab47,openstack/openstack-helm-addons,master,I2dd9a667c6b33575324c179a8c10c394bf07ab47,Fixed ranger/ranger-agent helm charts main deployment scripts to include $USER,MERGED,2019-02-11 23:16:14.000000000,2019-02-12 19:54:00.000000000,2019-02-12 19:53:59.000000000,"[{'_account_id': 17591}, {'_account_id': 19391}, {'_account_id': 21111}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 24999}, {'_account_id': 26365}]","[{'number': 1, 'created': '2019-02-11 23:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/4fe5c30cb0e31682df2ddf3f4643e6d0cf698781', 'message': 'Fixed ranger helm chart main script to include $USER\n\nThe ""ranger"" user is hard coded in the helm ranger-services script.  This\nprevents overriding it.  Changed script to use $USER instead of hard-coded\nvalue.\n\nChange-Id: I2dd9a667c6b33575324c179a8c10c394bf07ab47\n'}, {'number': 2, 'created': '2019-02-12 17:03:51.000000000', 'files': ['ranger-agent/templates/bin/_ranger-agent-engine.sh.tpl', 'ranger/templates/bin/_ranger-services.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/5fa68b90dfafbde1a011929cbb1f7df78ae93978', 'message': 'Fixed ranger/ranger-agent helm charts main deployment scripts to include $USER\n\nThe ""ranger"" and ""ranger-agent"" user ids are hard coded in the helm\nservices scripts.  This prevents overriding them.  Changed both scripts\nto use $USER instead of hard-coded values.\n\nChange-Id: I2dd9a667c6b33575324c179a8c10c394bf07ab47\n'}]",0,636234,5fa68b90dfafbde1a011929cbb1f7df78ae93978,16,7,2,13493,,,0,"Fixed ranger/ranger-agent helm charts main deployment scripts to include $USER

The ""ranger"" and ""ranger-agent"" user ids are hard coded in the helm
services scripts.  This prevents overriding them.  Changed both scripts
to use $USER instead of hard-coded values.

Change-Id: I2dd9a667c6b33575324c179a8c10c394bf07ab47
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/34/636234/2 && git format-patch -1 --stdout FETCH_HEAD,['ranger/templates/bin/_ranger-services.sh.tpl'],1,4fe5c30cb0e31682df2ddf3f4643e6d0cf698781,, chown ${USER}: ${USER_HOME}/.ssh$COMMAND , chown ranger: ${USER_HOME}/.ssh$COMMAND,2,2
openstack%2Fopenstack-ansible-os_heat~master~I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9,openstack/openstack-ansible-os_heat,master,I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9,Fixed the egg name of heat to openstack_heat,MERGED,2019-02-07 14:22:48.000000000,2019-02-12 19:53:56.000000000,2019-02-12 19:53:56.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 21314}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-07 14:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/48a4b970aac83e500f873d905b7c4b01ccb077cc', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 2, 'created': '2019-02-08 02:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/1d2fac4854e2e4c3abbd71ac0d17dc4071271d62', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 3, 'created': '2019-02-08 05:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/2f49c061ba16b2f21e51aa9ace0470b967a07ea9', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 4, 'created': '2019-02-08 11:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/c5ff72d4e42a252d7ba9029ddce2e2d2bc6e7e29', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nAdded mpich-devel distro packages as it is need for building mpi4py.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 5, 'created': '2019-02-11 07:28:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/4bb2e7727814cbfa6d7c8caa0e80adb532aabf8a', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nAdded openmpi-devel distro packages as it is need for building mpi4py.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 6, 'created': '2019-02-11 15:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/790c44d2ba6eb122f9a917f7b4c61e06e1a909c7', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nAdded openmpi-devel distro packages as it is need for building mpi4py.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 7, 'created': '2019-02-11 19:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/c01fe478755b167e571f117aabe0d357243d9df9', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nAdded openmpi-devel distro packages as it is need for building mpi4py.\n\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}, {'number': 8, 'created': '2019-02-12 10:24:39.000000000', 'files': ['vars/redhat-7.yml', 'vars/ubuntu.yml', 'defaults/main.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/0acb9001bf23bf83688c4e3eb9ee51dc143552e7', 'message': ""Fixed the egg name of heat to openstack_heat\n\nhttps://review.openstack.org/606160 changes the change the dist name\nto 'openstack-heat' and it needs to be fixed in the os_heat role\notherwise it will fails while installing it.\n\nAdded openmpi-devel distro packages as it is need for building mpi4py.\n\nDepends-On: https://review.openstack.org/636297\nChange-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9\n""}]",1,635518,0acb9001bf23bf83688c4e3eb9ee51dc143552e7,26,6,8,12393,,,0,"Fixed the egg name of heat to openstack_heat

https://review.openstack.org/606160 changes the change the dist name
to 'openstack-heat' and it needs to be fixed in the os_heat role
otherwise it will fails while installing it.

Added openmpi-devel distro packages as it is need for building mpi4py.

Depends-On: https://review.openstack.org/636297
Change-Id: I2fbb2465f9b4765a87011dfb2c2f65bd27e7b2c9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/18/635518/8 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,48a4b970aac83e500f873d905b7c4b01ccb077cc,egg_fix," - ""git+{{ heat_git_repo }}@{{ heat_git_install_branch }}#egg=openstack_heat"""," - ""git+{{ heat_git_repo }}@{{ heat_git_install_branch }}#egg=heat""",1,1
openstack%2Fneutron~master~I0782599a4f0ffe48c2dd4fa2abc9fe5111715c0c,openstack/neutron,master,I0782599a4f0ffe48c2dd4fa2abc9fe5111715c0c,Change SR-IOV agent to log message after failure,MERGED,2019-01-24 22:22:02.000000000,2019-02-12 19:53:33.000000000,2019-02-12 19:53:33.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 25618}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-01-24 22:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c6879951eafc8a229f4c52b72e27103d22c58da', 'message': 'Change SR-IOV agent to log message after failure\n\nIf the SR-IOV agent fails to send its report_state\nto the server, it logs an exception:\n\n   Failed reporting state!: MessagingTimeout: Timed out...\n\nIf it then tries a second time and succeeds it just\ngoes on happily. It would be nice if it logged that\nit had success on the subsequent attempt so someone\nlooking at the logs know it recovered.\n\nChange-Id: I0782599a4f0ffe48c2dd4fa2abc9fe5111715c0c\n'}, {'number': 2, 'created': '2019-02-12 14:19:22.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2147c70745e231b4b1d5af35eb81ff4128b594c7', 'message': 'Change SR-IOV agent to log message after failure\n\nIf the SR-IOV agent fails to send its report_state\nto the server, it logs an exception:\n\n   Failed reporting state!: MessagingTimeout: Timed out...\n\nIf it then tries a second time and succeeds it just\ngoes on happily. It would be nice if it logged that\nit had success on the subsequent attempt so someone\nlooking at the logs know it recovered.\n\nChange-Id: I0782599a4f0ffe48c2dd4fa2abc9fe5111715c0c\n'}]",0,633080,2147c70745e231b4b1d5af35eb81ff4128b594c7,17,9,2,1131,,,0,"Change SR-IOV agent to log message after failure

If the SR-IOV agent fails to send its report_state
to the server, it logs an exception:

   Failed reporting state!: MessagingTimeout: Timed out...

If it then tries a second time and succeeds it just
goes on happily. It would be nice if it logged that
it had success on the subsequent attempt so someone
looking at the logs know it recovered.

Change-Id: I0782599a4f0ffe48c2dd4fa2abc9fe5111715c0c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/633080/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/mech_sriov/agent/sriov_nic_agent.py'],1,4c6879951eafc8a229f4c52b72e27103d22c58da,agent-failed-report-state," self.failed_report_state = False self.failed_report_state = True return if self.failed_report_state: self.failed_report_state = False LOG.info(""Successfully reported state after a previous failure."")",,6,0
openstack%2Fopenstack-ansible-os_mistral~master~I2390533690cd2c4511a272cc0834e240bb554696,openstack/openstack-ansible-os_mistral,master,I2390533690cd2c4511a272cc0834e240bb554696,Add initial Mistral role,MERGED,2019-02-05 17:24:27.000000000,2019-02-12 19:33:35.000000000,2019-02-12 19:33:35.000000000,"[{'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-05 17:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/8bb0ca86d5dd4200146b574110110c9aa3894e7b', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 2, 'created': '2019-02-05 18:01:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/63ca3e6d86b86b4c85a77264e61d2fd9fb0af21f', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 3, 'created': '2019-02-05 19:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/2b2ecf8e5537419c402c9ab43095b4b2b15296b5', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 4, 'created': '2019-02-05 20:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/f90fe927c53acba8249171ba48bd7b254862b3dc', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 5, 'created': '2019-02-05 21:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/9ff280ac27d50af672d1b2c3e2dfba5ef64ffadf', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 6, 'created': '2019-02-06 13:33:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/ce3763137731038efc3671f1111fb9340fdde59d', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 7, 'created': '2019-02-06 15:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/080a8050f4629a7a22af699f5e748bcf0bdecc9b', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}, {'number': 8, 'created': '2019-02-06 20:42:42.000000000', 'files': ['tasks/main.yml', 'vars/distro_install.yml', '.gitignore', 'tasks/mistral_install.yml', 'tasks/mistral_install_source.yml', 'README.rst', 'setup.py', 'releasenotes/source/_templates/.placeholder', 'templates/mistral.conf.j2', 'defaults/main.yml', 'releasenotes/notes/.placeholder', 'tasks/mistral_post_install.yml', 'CONTRIBUTING.rst', 'bindep.txt', 'tests/ansible-role-requirements.yml', 'tasks/mistral_db_setup.yml', 'tasks/mistral_service_setup.yml', 'Vagrantfile', 'vars/redhat-7.yml', 'releasenotes/source/_static/.placeholder', 'tests/group_vars/all_containers.yml', 'LICENSE', 'tests/host_vars/localhost.yml', 'tests/inventory', 'vars/source_install.yml', 'tasks/mq_setup.yml', 'tests/host_vars/infra1.yml', 'tests/os_mistral-overrides.yml', 'doc/source/conf.py', 'manual-test.rc', 'handlers/main.yml', 'releasenotes/source/index.rst', 'tests/test.yml', 'tests/test-install-mistral.yml', 'vars/main.yml', 'releasenotes/source/unreleased.rst', 'run_tests.sh', 'doc/source/index.rst', 'vars/ubuntu.yml', 'tests/host_vars/openstack1.yml', 'zuul.d/project.yaml', 'doc/requirements.txt', 'setup.cfg', 'templates/mistral-uwsgi.ini.j2', 'tox.ini', 'releasenotes/source/conf.py', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_mistral/commit/b6f83caabf6269d6dff4412687711430c22898e6', 'message': 'Add initial Mistral role\n\nThis role allows the installation of Mistral alongside running\nall of the API tests.\n\nDepends-On: I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537\nDepends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa\nChange-Id: I2390533690cd2c4511a272cc0834e240bb554696\n'}]",1,634991,b6f83caabf6269d6dff4412687711430c22898e6,21,5,8,1004,,,0,"Add initial Mistral role

This role allows the installation of Mistral alongside running
all of the API tests.

Depends-On: I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537
Depends-On: Ie3d8fb921dfedff0852b630a0a0af17b97c1bffa
Change-Id: I2390533690cd2c4511a272cc0834e240bb554696
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_mistral refs/changes/91/634991/8 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'vars/distro_install.yml', '.gitignore', 'tasks/mistral_install.yml', 'tasks/mistral_install_source.yml', 'README.rst', 'setup.py', 'templates/mistral.conf.j2', 'defaults/main.yml', 'tasks/mistral_post_install.yml', 'CONTRIBUTING.rst', 'bindep.txt', 'tests/ansible-role-requirements.yml', 'tasks/mistral_db_setup.yml', 'tasks/mistral_service_setup.yml', 'Vagrantfile', 'vars/redhat-7.yml', 'tests/group_vars/all_containers.yml', 'LICENSE', 'tests/host_vars/localhost.yml', 'tests/inventory', 'vars/source_install.yml', 'tasks/mq_setup.yml', 'tests/host_vars/infra1.yml', 'tests/os_mistral-overrides.yml', 'manual-test.rc', 'handlers/main.yml', 'tests/test.yml', 'tests/test-install-mistral.yml', 'vars/main.yml', 'run_tests.sh', 'vars/ubuntu.yml', 'tests/host_vars/openstack1.yml', 'zuul.d/project.yaml', 'setup.cfg', 'templates/mistral-uwsgi.ini.j2', 'tox.ini', 'vars/suse.yml']",38,8bb0ca86d5dd4200146b574110110c9aa3894e7b,,"--- # Copyright 2019, VEXXHOST, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. mistral_devel_distro_packages: - git mistral_distro_packages: [] mistral_oslomsg_amqp1_distro_packages: - cyrus-sasl - cyrus-sasl-plain - cyrus-sasl-digestmd5 mistral_uwsgi_bin: '/usr/sbin'",,2082,0
openstack%2Ftripleo-quickstart~master~I21d0c1cfc40229a64659b15c4f0473462ec200b5,openstack/tripleo-quickstart,master,I21d0c1cfc40229a64659b15c4f0473462ec200b5,Ensure the latest rpms versions are installed,MERGED,2019-02-11 22:30:16.000000000,2019-02-12 19:23:29.000000000,2019-02-12 19:23:29.000000000,"[{'_account_id': 9592}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-11 22:30:16.000000000', 'files': ['bindep.txt', 'install-deps.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ffa9341b07350dbbf36bcd784cb46ccb71df51aa', 'message': 'Ensure the latest rpms versions are installed\n\nbindep installs all the deps in one transaction.\nThis can leave some deps at an unsupported version.\nRun through the deps after the install with an update.\n\nChange-Id: I21d0c1cfc40229a64659b15c4f0473462ec200b5\n'}]",1,636230,ffa9341b07350dbbf36bcd784cb46ccb71df51aa,10,5,1,9592,,,0,"Ensure the latest rpms versions are installed

bindep installs all the deps in one transaction.
This can leave some deps at an unsupported version.
Run through the deps after the install with an update.

Change-Id: I21d0c1cfc40229a64659b15c4f0473462ec200b5
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/30/636230/1 && git format-patch -1 --stdout FETCH_HEAD,"['bindep.txt', 'install-deps.sh']",2,ffa9341b07350dbbf36bcd784cb46ccb71df51aa,, # EPEL will NOT be installed on any nodepool nodes. # EPEL could be installed in the same transaction as other packages on CentOS/RHEL # This can leave the system with an older ansible version. Ansible 2.7+ required # Run through the deps and update them yum-config-manager enable epel || true sudo $(package_manager) -y update `bindep -b -l newline -f bindep.txt`,,8,1
openstack%2Ftripleo-quickstart~master~Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7,openstack/tripleo-quickstart,master,Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7,Add centos7-rt repository,MERGED,2019-02-06 13:47:57.000000000,2019-02-12 19:23:25.000000000,2019-02-12 19:23:25.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 18575}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-06 13:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/fd76a2568adef4155f46865973242c770c17b750', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper repo now with nodepool mirrors and it will get copied to\novercloud image.\n\nRelated-Bug: #635144\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 2, 'created': '2019-02-06 13:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/601e4b500aa5979627e9804717508fe93364c813', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper repo now with nodepool mirrors and it will get copied to\novercloud image.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 3, 'created': '2019-02-07 12:07:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/dbc40e4cc2d60048ba2a500e4b2472af2792e741', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 4, 'created': '2019-02-07 13:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/aa526340ddbe25869129704fc72088d1325b086c', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 5, 'created': '2019-02-07 13:56:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7f3fe4e77ed2511c6973ab3425ce939c567c92ab', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 6, 'created': '2019-02-08 09:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/a7cb883e38ca7f27d7572612ba27b8a43f230edd', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 7, 'created': '2019-02-11 07:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7e0565e0fbb1984fb7bcb3b0632c626386c90e24', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #1814872\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 8, 'created': '2019-02-11 13:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3aed75e4cfdef422080ea1820861732c6674e5d0', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it.\n\nCloses-Bug: #635144\n\nDepends-On: https://review.openstack.org/635135\n\n[1] https://review.openstack.org/#/c/454732/,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 9, 'created': '2019-02-12 09:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/55ded69e550e75f150c043ed18760e3f0cc3e9ef', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it, the element for\nmaster is merged [2]\n\nCloses-Bug: #1814872\n\n[1] https://review.openstack.org/454732,\n[2] https://review.openstack.org/635135\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 10, 'created': '2019-02-12 09:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/5640840a2ae7b0ad6b85e64a65057e9f74ae8b72', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it, the element for\nmaster is merged [2]\n\nCloses-Bug: #1814872\n\n[1] https://review.openstack.org/454732,\n[2] https://review.openstack.org/635135\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 11, 'created': '2019-02-12 09:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/94738056dc3fff17e6031b2da815b957f3f2ad53', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it\nmaster is merged [2]\n\nNot added as depend on since this review works without them\ntripleo-puppet-element changes\n\nmaster: https://review.openstack.org/635135\nrocky: https://review.openstack.org/#/c/636277/\nqueens: https://review.openstack.org/#/c/636278/\npike: https://review.openstack.org/#/c/636289/\nocata: https://review.openstack.org/#/c/636290/\n\nCloses-Bug: #1814872\n\n[1] https://review.openstack.org/454732,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}, {'number': 12, 'created': '2019-02-12 10:09:49.000000000', 'files': ['config/release/tripleo-ci/CentOS-7/consistent-rocky.yml', 'config/release/tripleo-ci/CentOS-7/master.yml', 'config/release/tripleo-ci/CentOS-7/ocata.yml', 'config/release/tripleo-ci/CentOS-7/promotion-testing-hash-ocata.yml', 'config/release/tripleo-ci/CentOS-7/queens-undercloud-pike-overcloud.yml', 'config/release/tripleo-ci/CentOS-7/master-undercloud-queens-overcloud.yml', 'config/release/tripleo-ci/CentOS-7/consistent-queens.yml', 'config/release/tripleo-ci/CentOS-7/promotion-testing-hash-pike.yml', 'config/release/tripleo-ci/CentOS-7/consistent-master.yml', 'config/release/tripleo-ci/CentOS-7/consistent-ocata.yml', 'config/release/tripleo-ci/CentOS-7/promotion-testing-hash-rocky.yml', 'config/release/tripleo-ci/CentOS-7/pike-undercloud-ocata-overcloud.yml', 'config/release/tripleo-ci/CentOS-7/pike.yml', 'config/release/tripleo-ci/CentOS-7/queens-undercloud-newton-overcloud.yml', 'config/release/tripleo-ci/CentOS-7/rocky.yml', 'config/release/tripleo-ci/CentOS-7/master-undercloud-rocky-overcloud.yml', 'config/release/tripleo-ci/CentOS-7/queens.yml', 'config/release/tripleo-ci/CentOS-7/consistent-pike.yml', 'config/release/tripleo-ci/CentOS-7/promotion-testing-hash-queens.yml', 'config/release/tripleo-ci/CentOS-7/rocky-undercloud-queens-overcloud.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/331fa892fa5a050c42bdd2edd299fdd343367615', 'message': 'Add centos7-rt repository\n\nThe centos-rt was added for tuned profile cpu-partitioning as part of [1] now\none of the package is installed in the default image so we generate the\nproper disabled repo now with nodepool mirrors and it will get copied to\novercloud image, then the dib element will enable it\nmaster is merged [2]\n\nNot added as depend on since this review works without them\ntripleo-puppet-element changes\n\nmaster: https://review.openstack.org/635135\nrocky: https://review.openstack.org/#/c/636277/\nqueens: https://review.openstack.org/#/c/636278/\npike: https://review.openstack.org/#/c/636289/\nocata: https://review.openstack.org/#/c/636290/\n\nCloses-Bug: #1814872\n\n[1] https://review.openstack.org/454732,\n\nChange-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7\n'}]",7,635157,331fa892fa5a050c42bdd2edd299fdd343367615,66,16,12,27898,,,0,"Add centos7-rt repository

The centos-rt was added for tuned profile cpu-partitioning as part of [1] now
one of the package is installed in the default image so we generate the
proper disabled repo now with nodepool mirrors and it will get copied to
overcloud image, then the dib element will enable it
master is merged [2]

Not added as depend on since this review works without them
tripleo-puppet-element changes

master: https://review.openstack.org/635135
rocky: https://review.openstack.org/#/c/636277/
queens: https://review.openstack.org/#/c/636278/
pike: https://review.openstack.org/#/c/636289/
ocata: https://review.openstack.org/#/c/636290/

Closes-Bug: #1814872

[1] https://review.openstack.org/454732,

Change-Id: Ie2ef9b836d8bc3a701dbb1bad907263d17d2b5d7
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/57/635157/4 && git format-patch -1 --stdout FETCH_HEAD,['config/release/tripleo-ci/CentOS-7/master.yml'],1,fd76a2568adef4155f46865973242c770c17b750,bug/635144, - type: generic reponame: centos7-rt filename: centos7-rt.repo baseurl: ${NODEPOOL_CENTOS_MIRROR}/7/rt/x86_64/ ,,5,0
openstack%2Fansible-hardening~stable%2Fqueens~I72fd18d36ab139d7140281374b5c2b89f7cb460a,openstack/ansible-hardening,stable/queens,I72fd18d36ab139d7140281374b5c2b89f7cb460a,Switch to rtcsync for chrony,MERGED,2019-01-24 03:29:38.000000000,2019-02-12 19:18:11.000000000,2019-02-12 19:18:11.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-24 03:29:38.000000000', 'files': ['templates/chrony.conf.j2'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/642044801bba778f8b10a773caa6fbcd363e48ef', 'message': ""Switch to rtcsync for chrony\n\nwhen setting security_ntp_sync_rtc to true, chrony will sync rtc every\n11 minutes.\n\nusing rtcfile + rtcautotrim locks access to rtc clock for other tools,\nlike hwclock or timedatectl so it's hard to validate that the clock is\nreally synced.\n\nChange-Id: I72fd18d36ab139d7140281374b5c2b89f7cb460a\n(cherry picked from commit ef1b4170328391d55c3ca94e8183fdd56a229c34)\n""}]",0,632908,642044801bba778f8b10a773caa6fbcd363e48ef,7,3,1,13095,,,0,"Switch to rtcsync for chrony

when setting security_ntp_sync_rtc to true, chrony will sync rtc every
11 minutes.

using rtcfile + rtcautotrim locks access to rtc clock for other tools,
like hwclock or timedatectl so it's hard to validate that the clock is
really synced.

Change-Id: I72fd18d36ab139d7140281374b5c2b89f7cb460a
(cherry picked from commit ef1b4170328391d55c3ca94e8183fdd56a229c34)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/08/632908/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/chrony.conf.j2'],1,642044801bba778f8b10a773caa6fbcd363e48ef,rtcsync-stable/queens,"# The rtcsync directive enables a mode where the system time is periodically # copied to the real time clock (RTC). # On Linux the RTC copy is performed by the kernel every 11 minutes. This # directive cannot be used when the normal RTC tracking is enabled, i.e. when # the rtcfile directive is used. rtcsync",# This directive tells chrony to regulate the real-time clock and tells it # Where to store related data. It may not work on some newer motherboards # that use the HPET real-time clock. It requires enhanced real-time # support in the kernel. It is disabled by default because with certain # combinations of motherboard and kernel it is reported to cause lockups. rtcfile /var/lib/chrony/chrony.rtc rtcautotrim 10,6,8
openstack%2Fansible-hardening~stable%2Frocky~I72fd18d36ab139d7140281374b5c2b89f7cb460a,openstack/ansible-hardening,stable/rocky,I72fd18d36ab139d7140281374b5c2b89f7cb460a,Switch to rtcsync for chrony,MERGED,2019-01-24 03:29:23.000000000,2019-02-12 19:18:10.000000000,2019-02-12 19:18:09.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-01-24 03:29:23.000000000', 'files': ['templates/chrony.conf.j2'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/56fd6b335ed5529eef99c2ce2ca4a03c9414c732', 'message': ""Switch to rtcsync for chrony\n\nwhen setting security_ntp_sync_rtc to true, chrony will sync rtc every\n11 minutes.\n\nusing rtcfile + rtcautotrim locks access to rtc clock for other tools,\nlike hwclock or timedatectl so it's hard to validate that the clock is\nreally synced.\n\nChange-Id: I72fd18d36ab139d7140281374b5c2b89f7cb460a\n(cherry picked from commit ef1b4170328391d55c3ca94e8183fdd56a229c34)\n""}]",0,632907,56fd6b335ed5529eef99c2ce2ca4a03c9414c732,7,3,1,13095,,,0,"Switch to rtcsync for chrony

when setting security_ntp_sync_rtc to true, chrony will sync rtc every
11 minutes.

using rtcfile + rtcautotrim locks access to rtc clock for other tools,
like hwclock or timedatectl so it's hard to validate that the clock is
really synced.

Change-Id: I72fd18d36ab139d7140281374b5c2b89f7cb460a
(cherry picked from commit ef1b4170328391d55c3ca94e8183fdd56a229c34)
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/07/632907/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/chrony.conf.j2'],1,56fd6b335ed5529eef99c2ce2ca4a03c9414c732,rtcsync-stable/rocky,"# The rtcsync directive enables a mode where the system time is periodically # copied to the real time clock (RTC). # On Linux the RTC copy is performed by the kernel every 11 minutes. This # directive cannot be used when the normal RTC tracking is enabled, i.e. when # the rtcfile directive is used. rtcsync",# This directive tells chrony to regulate the real-time clock and tells it # Where to store related data. It may not work on some newer motherboards # that use the HPET real-time clock. It requires enhanced real-time # support in the kernel. It is disabled by default because with certain # combinations of motherboard and kernel it is reported to cause lockups. rtcfile /var/lib/chrony/chrony.rtc rtcautotrim 10,6,8
openstack%2Fnova~master~Idffaa6d206cda3f507e6be095356537f22302ad7,openstack/nova,master,Idffaa6d206cda3f507e6be095356537f22302ad7,Follow up (#2) for the bw resource provider series,MERGED,2019-02-04 18:10:57.000000000,2019-02-12 19:00:02.000000000,2019-02-12 18:30:27.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 18:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/965fec7e320640c610444305a0809c33dddd8fc1', 'message': 'Follow up (#2) for the bw resource provider series\n\nThis addresses review comments from the following changes:\n\n  I61a3e8902a891bac36911812e4e7c080570e3850\n\n  I48e6db9693e470b177bf4c75211d8b883c768433\n\n  Ic70d2bb781b6a844849a5cf2fe4d271b5a81093d\n\n  I5a956513f3485074023e027430cc52ee7a3f92e4\n\n  Ica6152ccb97dce805969d964d6ed032bfe22a33f\n\nPart of blueprint bandwidth-resource-provider\n\nChange-Id: Idffaa6d206cda3f507e6be095356537f22302ad7\n'}, {'number': 2, 'created': '2019-02-08 22:48:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a2b6fef7142f58594e4dc8c8bf326ee19310fc4', 'message': 'Follow up (#2) for the bw resource provider series\n\nThis addresses review comments from the following changes:\n\n  I61a3e8902a891bac36911812e4e7c080570e3850\n\n  I48e6db9693e470b177bf4c75211d8b883c768433\n\n  Ic70d2bb781b6a844849a5cf2fe4d271b5a81093d\n\n  I5a956513f3485074023e027430cc52ee7a3f92e4\n\n  Ica6152ccb97dce805969d964d6ed032bfe22a33f\n\nPart of blueprint bandwidth-resource-provider\n\nChange-Id: Idffaa6d206cda3f507e6be095356537f22302ad7\n'}, {'number': 3, 'created': '2019-02-11 19:35:42.000000000', 'files': ['nova/api/openstack/compute/shelve.py', 'nova/tests/functional/integrated_helpers.py', 'nova/api/openstack/compute/evacuate.py', 'nova/api/openstack/common.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/api/openstack/compute/servers.py', 'nova/tests/fixtures.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/functional/test_servers.py', 'nova/tests/unit/api/openstack/compute/test_evacuate.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2ed304e9cc6cab74b5ef33403f23e5447c831b04', 'message': 'Follow up (#2) for the bw resource provider series\n\nThis addresses review comments from the following changes:\n\n  I61a3e8902a891bac36911812e4e7c080570e3850\n\n  I48e6db9693e470b177bf4c75211d8b883c768433\n\n  Ic70d2bb781b6a844849a5cf2fe4d271b5a81093d\n\n  I5a956513f3485074023e027430cc52ee7a3f92e4\n\n  Ica6152ccb97dce805969d964d6ed032bfe22a33f\n\nPart of blueprint bandwidth-resource-provider\n\nChange-Id: Idffaa6d206cda3f507e6be095356537f22302ad7\n'}]",2,634767,2ed304e9cc6cab74b5ef33403f23e5447c831b04,49,12,3,6873,,,0,"Follow up (#2) for the bw resource provider series

This addresses review comments from the following changes:

  I61a3e8902a891bac36911812e4e7c080570e3850

  I48e6db9693e470b177bf4c75211d8b883c768433

  Ic70d2bb781b6a844849a5cf2fe4d271b5a81093d

  I5a956513f3485074023e027430cc52ee7a3f92e4

  Ica6152ccb97dce805969d964d6ed032bfe22a33f

Part of blueprint bandwidth-resource-provider

Change-Id: Idffaa6d206cda3f507e6be095356537f22302ad7
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/634767/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/shelve.py', 'nova/tests/functional/integrated_helpers.py', 'nova/api/openstack/compute/evacuate.py', 'nova/api/openstack/common.py', 'nova/tests/unit/api/openstack/compute/test_server_actions.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/api/openstack/compute/servers.py', 'nova/tests/fixtures.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/functional/test_servers.py', 'nova/tests/unit/api/openstack/compute/test_evacuate.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py']",12,965fec7e320640c610444305a0809c33dddd8fc1,bp/bandwidth-resource-provider,," def test_migrate_with_port_resource_request_old_microversion(self): self.mock_list_port.return_value = {'ports': [ {'resource_request': { ""resources"": {'CUSTOM_FOO': 1}}}] } method_translations = {'_migrate': 'resize', '_migrate_live': 'live_migrate'} body_map = {'_migrate_live': self._get_migration_body(host='hostname')} args_map = {'_migrate_live': ((False, self.disk_over_commit, 'hostname', self.force, self.async_), {}), '_migrate': ((), {'host_name': self.host_name})} ex = self.assertRaises( webob.exc.HTTPBadRequest, self._test_actions, ['_migrate', '_migrate_live'], body_map=body_map, method_translations=method_translations, args_map=args_map) self.assertIn( 'The migrate server operation with port having QoS policy is not ' 'supported.', six.text_type(ex)) def test_migrate_with_port_resource_request_old_microversion(self): self.mock_list_port.return_value = {'ports': [ {'resource_request': { ""resources"": {'CUSTOM_FOO': 1}}}] } ex = self.assertRaises( webob.exc.HTTPBadRequest, self._test_actions, ['_migrate'], body_map=self.body_map, method_translations=self.method_translations, args_map=self.args_map) self.assertIn( 'The migrate server operation with port having QoS policy is not ' 'supported.', six.text_type(ex)) ",121,193
openstack%2Fcharm-keystone~master~Ib97cbea15c746ac93a6cf6056da2e8d6eb28af3c,openstack/charm-keystone,master,Ib97cbea15c746ac93a6cf6056da2e8d6eb28af3c,Update pre-install hooks to fail on error,MERGED,2019-02-08 21:51:40.000000000,2019-02-12 18:55:16.000000000,2019-02-12 18:55:16.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 21:51:40.000000000', 'files': ['hooks/install'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/6f7c61c488f1f8d886c3579bde0c950da18f3508', 'message': 'Update pre-install hooks to fail on error\n\nThe pre-install operations may fail, yet that failure is not\nelevated to the user. This masks the failure and makes early\npackage install issues difficult to troubleshoot.\n\nIf the basic pre-install script fails, the charm should not\nproceed to later hooks as the requirements may not be met.\n\nHashbangs for bash should specify -e (errexit) on all of the\npre-install bash scripts.\n\nChange-Id: Ib97cbea15c746ac93a6cf6056da2e8d6eb28af3c\nCloses-bug: #1815243\nPartial-bug: #1815231\n'}]",0,635957,6f7c61c488f1f8d886c3579bde0c950da18f3508,10,3,1,20635,,,0,"Update pre-install hooks to fail on error

The pre-install operations may fail, yet that failure is not
elevated to the user. This masks the failure and makes early
package install issues difficult to troubleshoot.

If the basic pre-install script fails, the charm should not
proceed to later hooks as the requirements may not be met.

Hashbangs for bash should specify -e (errexit) on all of the
pre-install bash scripts.

Change-Id: Ib97cbea15c746ac93a6cf6056da2e8d6eb28af3c
Closes-bug: #1815243
Partial-bug: #1815231
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/57/635957/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/install'],1,6f7c61c488f1f8d886c3579bde0c950da18f3508,bug/1815243,#!/bin/bash -e,#!/bin/bash,1,1
openstack%2Fgovernance~master~I82d372d7b93e87c41531f6483473ed223b2058f8,openstack/governance,master,I82d372d7b93e87c41531f6483473ed223b2058f8,Add os_mistral role to OpenStack-Ansible,MERGED,2019-02-04 21:41:19.000000000,2019-02-12 18:51:10.000000000,2019-02-12 18:51:09.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 8556}, {'_account_id': 11564}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 21:41:19.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/016fb7ac55384aba7bcbb53c4680b683959d164f', 'message': 'Add os_mistral role to OpenStack-Ansible\n\nThis patch aims to add os_mistral to the OpenStack-Ansible\nproject.\n\nDepends-On: Ic5cab9cfbdc7b396d23d836224e38ffb5e3af3ba\nChange-Id: I82d372d7b93e87c41531f6483473ed223b2058f8\n'}]",0,634817,016fb7ac55384aba7bcbb53c4680b683959d164f,18,8,1,1004,,,0,"Add os_mistral role to OpenStack-Ansible

This patch aims to add os_mistral to the OpenStack-Ansible
project.

Depends-On: Ic5cab9cfbdc7b396d23d836224e38ffb5e3af3ba
Change-Id: I82d372d7b93e87c41531f6483473ed223b2058f8
",git fetch https://review.opendev.org/openstack/governance refs/changes/17/634817/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,016fb7ac55384aba7bcbb53c4680b683959d164f,project-update, - openstack/openstack-ansible-os_mistral,,1,0
openstack%2Fopenstack-ansible-tests~master~Idbf2bbbdfb0d2c5c3b440ad37004f5768328e7a6,openstack/openstack-ansible-tests,master,Idbf2bbbdfb0d2c5c3b440ad37004f5768328e7a6,Ensure ipforward is set on all test bridges,MERGED,2019-02-11 15:54:43.000000000,2019-02-12 18:51:08.000000000,2019-02-12 18:51:08.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-11 15:54:43.000000000', 'files': ['test-prepare-host.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/4931471eee824c7074c7ddda4273ddb70ad91918', 'message': 'Ensure ipforward is set on all test bridges\n\nStatically set ipforward: true for all test bridges to fix centos7 gate\nwhere forwarding is disabled by default.  Ubuntu is defaulting\nforwarding enabled for all bridges so this will align the forwarding\nconfiguration of centos and ubuntu.\n\nChange-Id: Idbf2bbbdfb0d2c5c3b440ad37004f5768328e7a6\n'}]",0,636162,4931471eee824c7074c7ddda4273ddb70ad91918,7,3,1,28665,,,0,"Ensure ipforward is set on all test bridges

Statically set ipforward: true for all test bridges to fix centos7 gate
where forwarding is disabled by default.  Ubuntu is defaulting
forwarding enabled for all bridges so this will align the forwarding
configuration of centos and ubuntu.

Change-Id: Idbf2bbbdfb0d2c5c3b440ad37004f5768328e7a6
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/62/636162/1 && git format-patch -1 --stdout FETCH_HEAD,['test-prepare-host.yml'],1,4931471eee824c7074c7ddda4273ddb70ad91918,forwarding," {% set _ = systemd_network_networks.append({'interface': interface_name, 'address': (interface.ip_addr | default('10.1.0.1')), 'netmask': (interface.netmask | default('255.255.255.0')), 'ipforward': true}) %}"," {% set _ = systemd_network_networks.append({'interface': interface_name, 'address': (interface.ip_addr | default('10.1.0.1')), 'netmask': (interface.netmask | default('255.255.255.0'))}) %}",1,1
openstack%2Fopenstack-ansible~master~Ida55bc030800c512d64bb715f704697875cd5738,openstack/openstack-ansible,master,Ida55bc030800c512d64bb715f704697875cd5738,Update the heat service egg name to openstack_heat,MERGED,2019-02-12 10:24:24.000000000,2019-02-12 18:40:43.000000000,2019-02-12 18:40:43.000000000,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-12 10:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/56d5cfc4512082b77f2a80fa44cf97455406d2fe', 'message': ""Update the heat service egg name to openstack_heat\n\nIn https://review.openstack.org/606160 the dist name was changed\nfrom 'heat' to 'openstack-heat'. The egg name needs to be updated\nor the package will fail to install or be usable.\n\nChange-Id: Ida55bc030800c512d64bb715f704697875cd5738\nRelated: https://review.openstack.org/635518\n""}, {'number': 2, 'created': '2019-02-12 12:43:29.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3621ce76b706a1707cc986859f4c7b5eaa0b1f23', 'message': ""Update the heat service egg name to openstack_heat\n\nIn https://review.openstack.org/606160 the dist name was changed\nfrom 'heat' to 'openstack-heat'. The egg name needs to be updated\nor the package will fail to install or be usable.\n\nRelated: https://review.openstack.org/635518\nChange-Id: Ida55bc030800c512d64bb715f704697875cd5738\n""}]",0,636297,3621ce76b706a1707cc986859f4c7b5eaa0b1f23,12,5,2,6816,,,0,"Update the heat service egg name to openstack_heat

In https://review.openstack.org/606160 the dist name was changed
from 'heat' to 'openstack-heat'. The egg name needs to be updated
or the package will fail to install or be usable.

Related: https://review.openstack.org/635518
Change-Id: Ida55bc030800c512d64bb715f704697875cd5738
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/97/636297/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,56d5cfc4512082b77f2a80fa44cf97455406d2fe,egg_fix,heat_git_repo: https://git.openstack.org/openstack/heat#egg=openstack-heat,heat_git_repo: https://git.openstack.org/openstack/heat,1,1
openstack%2Fkayobe~stable%2Fqueens~Ic36faaff37333f5af03a130dd97d31b26b7ff97f,openstack/kayobe,stable/queens,Ic36faaff37333f5af03a130dd97d31b26b7ff97f,Fix generation of globals.yml,MERGED,2019-02-08 15:32:12.000000000,2019-02-12 18:39:34.000000000,2019-02-12 18:39:34.000000000,"[{'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-02-08 15:32:12.000000000', 'files': ['ansible/roles/kolla-ansible/templates/globals.yml.j2'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/bd9e86c5d2163a853519701a3821042c66386b97', 'message': 'Fix generation of globals.yml\n\nkolla_inspector_* variables are identified by Jinja as empty strings\nrather than none, so globals.yml is generated with a syntax error:\n\nironic_dnsmasq_dhcp_range: ,\n                           ^ here\n\nChange-Id: Ic36faaff37333f5af03a130dd97d31b26b7ff97f\n(cherry picked from commit 68c50520b3625376882ee63d68a6407f9f7a9004)\n'}]",0,635862,bd9e86c5d2163a853519701a3821042c66386b97,7,3,1,14826,,,0,"Fix generation of globals.yml

kolla_inspector_* variables are identified by Jinja as empty strings
rather than none, so globals.yml is generated with a syntax error:

ironic_dnsmasq_dhcp_range: ,
                           ^ here

Change-Id: Ic36faaff37333f5af03a130dd97d31b26b7ff97f
(cherry picked from commit 68c50520b3625376882ee63d68a6407f9f7a9004)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/62/635862/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/kolla-ansible/templates/globals.yml.j2'],1,bd9e86c5d2163a853519701a3821042c66386b97,globals-fix-stable-queens,{% if kolla_inspector_dhcp_pool_start and kolla_inspector_dhcp_pool_end %},{% if kolla_inspector_dhcp_pool_start is not none and kolla_inspector_dhcp_pool_end is not none %},1,1
openstack%2Fopenstack-ansible~master~I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08,openstack/openstack-ansible,master,I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08,Use the config_template module from the dedicated repo,MERGED,2019-02-11 17:32:54.000000000,2019-02-12 18:33:27.000000000,2019-02-12 18:33:27.000000000,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-11 17:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9c782c13d3ccb8c312cda6c4e878ba769b18154e', 'message': 'Use the config_template module from the dedicated repo\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nThis implements the changes necessary to ensure that all integrated\nbuild tests now make use of the new git repository, rather than the\nold location in the openstack-ansible-plugins repository. The\nconfig_template repo is placed first in the list of library/action\nplugin locations to use to ensure that any other version of the plugin\n(eg: ceph) is not used.\n\nRelated-Bug: 1791258\nChange-Id: I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08\n'}, {'number': 2, 'created': '2019-02-11 17:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a9e2dd0297611d29b143d69e5c7a80ed2b2fdbc1', 'message': 'Use the config_template module from the dedicated repo\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nThis implements the changes necessary to ensure that all integrated\nbuild tests now make use of the new git repository, rather than the\nold location in the openstack-ansible-plugins repository. The\nconfig_template repo is placed first in the list of library/action\nplugin locations to use to ensure that any other version of the plugin\n(eg: ceph) is not used.\n\nRelated-Bug: 1791258\nDepends-On: https://review.openstack.org/635838\nChange-Id: I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08\n'}, {'number': 3, 'created': '2019-02-12 10:25:59.000000000', 'files': ['scripts/openstack-ansible.rc', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0ee07525ed2b9bd07024487ef78c1fae2a432a69', 'message': 'Use the config_template module from the dedicated repo\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nThis implements the changes necessary to ensure that all integrated\nbuild tests now make use of the new git repository, rather than the\nold location in the openstack-ansible-plugins repository. The\nconfig_template repo is placed first in the list of library/action\nplugin locations to use to ensure that any other version of the plugin\n(eg: ceph) is not used.\n\nRelated-Bug: 1791258\nDepends-On: https://review.openstack.org/635838\nChange-Id: I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08\n'}]",0,636182,0ee07525ed2b9bd07024487ef78c1fae2a432a69,14,4,3,6816,,,0,"Use the config_template module from the dedicated repo

The config_template action module has now been moved into its own git
repository (openstack/ansible-config_template). This has been done to
simplify the ability to use the plugin in other non OpenStack-Ansible
projects.

This implements the changes necessary to ensure that all integrated
build tests now make use of the new git repository, rather than the
old location in the openstack-ansible-plugins repository. The
config_template repo is placed first in the list of library/action
plugin locations to use to ensure that any other version of the plugin
(eg: ceph) is not used.

Related-Bug: 1791258
Depends-On: https://review.openstack.org/635838
Change-Id: I22fd0ef19b32ff8d949effcfe7fd7f4a653d8e08
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/82/636182/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/openstack-ansible.rc', 'ansible-role-requirements.yml']",2,9c782c13d3ccb8c312cda6c4e878ba769b18154e,bug/1791258,- name: config_template scm: git src: https://git.openstack.org/openstack/ansible-config_template version: master,,6,2
openstack%2Fneutron~stable%2Fpike~Ib675d7bf399f2aa7eba9d343fa0f06281d33089a,openstack/neutron,stable/pike,Ib675d7bf399f2aa7eba9d343fa0f06281d33089a,Add lock_path in installation guide,MERGED,2019-02-12 10:05:45.000000000,2019-02-12 18:30:39.000000000,2019-02-12 18:30:39.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-12 10:05:45.000000000', 'files': ['doc/source/install/controller-install-option1-ubuntu.rst', 'doc/source/install/controller-install-option2-ubuntu.rst', 'doc/source/install/controller-install-option1-obs.rst', 'doc/source/install/compute-install-obs.rst', 'doc/source/install/controller-install-option2-obs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6098f54722d849d1635436272a87146a273531ec', 'message': 'Add lock_path in installation guide\n\nOslo_concurrency needs lock_path option, make it consistent in\ndocumentation for Suse, Redhat and Ubuntu installation guides.\n\nChange-Id: Ib675d7bf399f2aa7eba9d343fa0f06281d33089a\nRelated-Bug: #1796976\nCloses-Bug: #1812497\n(cherry picked from commit 534e85039271d91647173527cd4c4905b9532537)\n(cherry picked from commit 573b0be3e86905853b104647ff237fae191eed0b)\n(cherry picked from commit de9f813928d11b9048d0201caa3cbff60ccbf37b)\n'}]",0,636295,6098f54722d849d1635436272a87146a273531ec,8,5,1,17685,,,0,"Add lock_path in installation guide

Oslo_concurrency needs lock_path option, make it consistent in
documentation for Suse, Redhat and Ubuntu installation guides.

Change-Id: Ib675d7bf399f2aa7eba9d343fa0f06281d33089a
Related-Bug: #1796976
Closes-Bug: #1812497
(cherry picked from commit 534e85039271d91647173527cd4c4905b9532537)
(cherry picked from commit 573b0be3e86905853b104647ff237fae191eed0b)
(cherry picked from commit de9f813928d11b9048d0201caa3cbff60ccbf37b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/636295/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/controller-install-option1-ubuntu.rst', 'doc/source/install/controller-install-option2-ubuntu.rst', 'doc/source/install/controller-install-option1-obs.rst', 'doc/source/install/compute-install-obs.rst', 'doc/source/install/controller-install-option2-obs.rst']",5,6098f54722d849d1635436272a87146a273531ec,bug/1812497," * In the ``[oslo_concurrency]`` section, configure the lock path: .. path /etc/neutron/neutron.conf .. code-block:: ini [oslo_concurrency] # ... lock_path = /var/lib/neutron/tmp .. end ",,60,0
openstack%2Fnetworking-ovn~master~I08ced959d27e09c8483cc9c793c1ecff26bb8d36,openstack/networking-ovn,master,I08ced959d27e09c8483cc9c793c1ecff26bb8d36,stop using common db mixin,MERGED,2019-02-11 16:02:51.000000000,2019-02-12 18:08:21.000000000,2019-02-12 18:08:21.000000000,"[{'_account_id': 6773}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 16:02:51.000000000', 'files': ['networking_ovn/l3/l3_ovn.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5d23fbad0766c46f2d0dc3a8484eb8ea643fd4d2', 'message': ""stop using common db mixin\n\nAll of the methods of common db mixin are available via neutron-lib\nand the mixin will be removed before long.\nThis patch switches the code over to use neutron-lib's APIs rather\nthan those of the mixin as well as top using the mixin as a parent\nclass.\n\nChange-Id: I08ced959d27e09c8483cc9c793c1ecff26bb8d36\n""}]",0,636164,5d23fbad0766c46f2d0dc3a8484eb8ea643fd4d2,7,2,1,5367,,,0,"stop using common db mixin

All of the methods of common db mixin are available via neutron-lib
and the mixin will be removed before long.
This patch switches the code over to use neutron-lib's APIs rather
than those of the mixin as well as top using the mixin as a parent
class.

Change-Id: I08ced959d27e09c8483cc9c793c1ecff26bb8d36
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/64/636164/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/l3/l3_ovn.py'],1,5d23fbad0766c46f2d0dc3a8484eb8ea643fd4d2,bp/neutronlib-decouple-db,,"from neutron.db import common_db_mixin common_db_mixin.CommonDbMixin,",0,2
openstack%2Fnetworking-ovn~master~I44c616b94031d611e43c58c32894ae9d54662bcd,openstack/networking-ovn,master,I44c616b94031d611e43c58c32894ae9d54662bcd,Target proper Chassis events for agent liveness,MERGED,2019-02-06 23:27:18.000000000,2019-02-12 18:08:20.000000000,2019-02-12 18:08:19.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-06 23:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b66185e08789ade04cd2be027dee101d0a2e579c', 'message': ""Target proper Chassis events for agent liveness\n\nAgent stats for the ovn-controller are updated any time there is\nany CREATE/UPDATE event happens on a Chassis. This includes things\nlike external_ids updates for metadata agent liveness. So as long\nas the metadata agent is running, ovn-controller agent shows up\nas 'alive'. This patch makes sure we only update the ovn-controller\nagent status when nb_cfg is incremented.\n\nChange-Id: I44c616b94031d611e43c58c32894ae9d54662bcd\nCloses-Bug: #1814975\n""}, {'number': 2, 'created': '2019-02-06 23:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c023d0ed890259c5495704429b8f39907ec1944d', 'message': ""Target proper Chassis events for agent liveness\n\nAgent stats for the ovn-controller are updated any time there is\nany CREATE/UPDATE event happens on a Chassis. This includes things\nlike external_ids updates for metadata agent liveness. So as long\nas the metadata agent is running, ovn-controller agent shows up\nas 'alive'. This patch makes sure we only update the ovn-controller\nagent status when nb_cfg is incremented.\n\nChange-Id: I44c616b94031d611e43c58c32894ae9d54662bcd\nCloses-Bug: #1814975\n""}, {'number': 3, 'created': '2019-02-06 23:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f49d27e869dd488adab6c83a564577e737e5ac47', 'message': ""Target proper Chassis events for agent liveness\n\nAgent stats for the ovn-controller are updated any time there is\nany CREATE/UPDATE event happens on a Chassis. This includes things\nlike external_ids updates for metadata agent liveness. So as long\nas the metadata agent is running, ovn-controller agent shows up\nas 'alive'. This patch makes sure we only update the ovn-controller\nagent status when nb_cfg is incremented.\n\nChange-Id: I44c616b94031d611e43c58c32894ae9d54662bcd\nCloses-Bug: #1814975\n""}, {'number': 4, 'created': '2019-02-07 00:43:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3984501fd1a07ac252a68ef05bd3d44d92b98fd9', 'message': ""Target proper Chassis events for agent liveness\n\nAgent stats for the ovn-controller are updated any time there is\nany CREATE/UPDATE event happens on a Chassis. This includes things\nlike external_ids updates for metadata agent liveness. So as long\nas the metadata agent is running, ovn-controller agent shows up\nas 'alive'. This patch makes sure we only update the ovn-controller\nagent status when nb_cfg is incremented.\n\nChange-Id: I44c616b94031d611e43c58c32894ae9d54662bcd\nCloses-Bug: #1814975\n""}, {'number': 5, 'created': '2019-02-07 16:51:18.000000000', 'files': ['networking_ovn/ovsdb/ovsdb_monitor.py', 'networking_ovn/tests/functional/test_metadata_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/dd53505c6418888ff74b383a7a824d04b20b6354', 'message': ""Target proper Chassis events for agent liveness\n\nAgent stats for the ovn-controller are updated any time there is\nany CREATE/UPDATE event happens on a Chassis. This includes things\nlike external_ids updates for metadata agent liveness. So as long\nas the metadata agent is running, ovn-controller agent shows up\nas 'alive'. This patch makes sure we only update the ovn-controller\nagent status when nb_cfg is incremented.\n\nChange-Id: I44c616b94031d611e43c58c32894ae9d54662bcd\nCloses-Bug: #1814975\n""}]",9,635354,dd53505c6418888ff74b383a7a824d04b20b6354,20,4,5,5756,,,0,"Target proper Chassis events for agent liveness

Agent stats for the ovn-controller are updated any time there is
any CREATE/UPDATE event happens on a Chassis. This includes things
like external_ids updates for metadata agent liveness. So as long
as the metadata agent is running, ovn-controller agent shows up
as 'alive'. This patch makes sure we only update the ovn-controller
agent status when nb_cfg is incremented.

Change-Id: I44c616b94031d611e43c58c32894ae9d54662bcd
Closes-Bug: #1814975
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/54/635354/5 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/ovsdb/ovsdb_monitor.py'],1,b66185e08789ade04cd2be027dee101d0a2e579c,bug/1814975,"class BaseEvent(row_event.RowEvent): table = None events = tuple() def __init__(self): super(BaseEvent, self).__init__(self.events, self.table, None) self.event_name == self.__class__.__name__ def match_fn(self, event, row, old=None): raise NotImplementedError def matches(self, event, row, old=None): if row._table.name != self.table or event not in self.events: return False if not self.match_fn(event, row, old): return False LOG.debug(""%s : Matched %s, %s, %s %s"", self.event_name, self.table, self.events, self.conditions, self.old_conditions) return True class ChassisAgentDeleteEvent(BaseEvent): table = 'Chassis' events = (BaseEvent.ROW_DELETE,) stat.AgentStats.del_agent(row.uuid) stat.AgentStats.del_agent(utils.ovn_metadata_name(row.uuid)) def match_fn(self, event, row, old=None): return True class ChassisGatewayAgentEvent(BaseEvent): table = 'Chassis' events = (BaseEvent.ROW_CREATE, BaseEvent.ROW_UPDATE) def match_fn(self, event, row, old=None): if event == self.ROW_CREATE or getattr(old, 'nb_cfg', False): return True return False def run(self, event, row, old): stats.AgentStats.add_stat(row.uuid, row.nb_cfg) class ChassisMetadataAgentEvent(BaseEvent): table = 'Chassis' events = (BaseEvent.ROW_CREATE, BaseEvent.ROW_UPDATE) @staticmethod def _metadata_nb_cfg(row): return int(row.external_ids[ovn_const.OVN_AGENT_METADATA_SB_CFG_KEY]) def match_fn(self, event, row, old=None): if event == self.ROW_CREATE: return True try: if self._metadata_nb_cfg(row) == self._metadata_nb_cfg(old): return False except (AttributeError, KeyError): return False return True def run(self, event, row, old): stats.AgentStats.add_stat(utils.ovn_metadata_name(row.uuid), self._metadata_nb_cfg(row)) self.notify_handler.watch_events([ ChassisAgentDeleteEvent(), ChassisMetadataAgentEvent(), ChassisGatewayAgentEvent()])","class ChassisAgentEvent(row_event.RowEvent): def __init__(self): table = 'Chassis' events = (self.ROW_CREATE, self.ROW_UPDATE, self.ROW_DELETE) super(ChassisAgentEvent, self).__init__(events, table, None) self.event_name = 'ChassisAgentEvent' if event != self.ROW_DELETE: stats.AgentStats.add_stat(row.uuid, row.nb_cfg) # Update the metadata agent stats metadata_nb_cfg = row.external_ids.get( ovn_const.OVN_AGENT_METADATA_SB_CFG_KEY, None) if event == self.ROW_UPDATE and metadata_nb_cfg: try: old_metadata_nb_cfg = old.external_ids.get( ovn_const.OVN_AGENT_METADATA_SB_CFG_KEY, None) except AttributeError: return if metadata_nb_cfg != old_metadata_nb_cfg: stats.AgentStats.add_stat( utils.ovn_metadata_name(row.uuid), int(metadata_nb_cfg)) else: stats.AgentStats.del_agent(row.uuid) stats.AgentStats.del_agent(utils.ovn_metadata_name(row.uuid)) self.notify_handler.watch_event(ChassisAgentEvent())",65,24
openstack%2Fsenlin~master~I7a2923cb1bd18812991a310084b1b35592767b9c,openstack/senlin,master,I7a2923cb1bd18812991a310084b1b35592767b9c,Catch DBDuplicateEntry when locking cluster,MERGED,2019-01-29 22:54:12.000000000,2019-02-12 18:04:08.000000000,2019-02-12 18:04:08.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-01-29 22:54:12.000000000', 'files': ['senlin/engine/senlin_lock.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8b7c41171e0d323c415f2f47bc220bd63f709f86', 'message': 'Catch DBDuplicateEntry when locking cluster\n\nCatch and log DBDuplicateEntry exception when acquiring cluster lock.\nThis exception is not fatal so we should let the engine try to acquire\nthe lock again at a later time.\n\nChange-Id: I7a2923cb1bd18812991a310084b1b35592767b9c\n'}]",0,633844,8b7c41171e0d323c415f2f47bc220bd63f709f86,8,4,1,27224,,,0,"Catch DBDuplicateEntry when locking cluster

Catch and log DBDuplicateEntry exception when acquiring cluster lock.
This exception is not fatal so we should let the engine try to acquire
the lock again at a later time.

Change-Id: I7a2923cb1bd18812991a310084b1b35592767b9c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/633844/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/engine/senlin_lock.py'],1,8b7c41171e0d323c415f2f47bc220bd63f709f86,misc_fixes,"from oslo_db import exception try: owners = cl_obj.ClusterLock.acquire(cluster_id, action_id, scope) if action_id in owners: return True except exception.DBDuplicateEntry: LOG.info('Duplicate entry in cluster_lock table for %(c)s. ' 'Retrying cluster lock.', {'c': cluster_id})"," owners = cl_obj.ClusterLock.acquire(cluster_id, action_id, scope) if action_id in owners: return True",9,3
openstack%2Ftripleo-puppet-elements~stable%2Fpike~I630a399d95752b1fb1e30220a582ace8d7b97f18,openstack/tripleo-puppet-elements,stable/pike,I630a399d95752b1fb1e30220a582ace8d7b97f18,Use external centos7-rt if present,MERGED,2019-02-12 09:38:52.000000000,2019-02-12 18:03:39.000000000,2019-02-12 18:03:39.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-12 09:38:52.000000000', 'files': ['elements/overcloud-compute/pre-install.d/03-centos-rt-for-tuned-only'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/5a6f6dbb8d3199888cc124e5fe6c7a4e0a3b5502', 'message': ""Use external centos7-rt if present\n\nDepending on the environment we execute this we need different\nconfiguration for the centos7-rt repo, like at RDO zuul ci we have to\nuse nodepool mirrors, this patch check for a centos7-rt repo and enables\nit if it's not present just creates a default one\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)\n""}]",0,636289,5a6f6dbb8d3199888cc124e5fe6c7a4e0a3b5502,9,4,1,27898,,,0,"Use external centos7-rt if present

Depending on the environment we execute this we need different
configuration for the centos7-rt repo, like at RDO zuul ci we have to
use nodepool mirrors, this patch check for a centos7-rt repo and enables
it if it's not present just creates a default one

Change-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18
Related-Bug: #1814872
(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/89/636289/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/overcloud-compute/pre-install.d/03-centos-rt-for-tuned-only'],1,5a6f6dbb8d3199888cc124e5fe6c7a4e0a3b5502,bug/1814872,"#!/bin/bash -x current_rt_repo=$(yum repolist all|grep ""centos7-rt"" |awk '{print $1}'| head -n 1 || true) if [[ ""$current_rt_repo"" == """" ]]; then else yum-config-manager --enable $current_rt_repo fi fi ",#!/bin/bashfi,7,2
openstack%2Ftripleo-puppet-elements~stable%2Fqueens~I630a399d95752b1fb1e30220a582ace8d7b97f18,openstack/tripleo-puppet-elements,stable/queens,I630a399d95752b1fb1e30220a582ace8d7b97f18,Use external centos7-rt if present,MERGED,2019-02-12 07:40:35.000000000,2019-02-12 18:03:38.000000000,2019-02-12 18:03:38.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-12 07:40:35.000000000', 'files': ['elements/overcloud-compute/pre-install.d/03-centos-rt'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/c6dc9fbbc6189d2c1113de830da45650f6951cc7', 'message': ""Use external centos7-rt if present\n\nDepending on the environment we execute this we need different\nconfiguration for the centos7-rt repo, like at RDO zuul ci we have to\nuse nodepool mirrors, this patch check for a centos7-rt repo and enables\nit if it's not present just creates a default one\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)\n""}]",0,636278,c6dc9fbbc6189d2c1113de830da45650f6951cc7,8,3,1,27898,,,0,"Use external centos7-rt if present

Depending on the environment we execute this we need different
configuration for the centos7-rt repo, like at RDO zuul ci we have to
use nodepool mirrors, this patch check for a centos7-rt repo and enables
it if it's not present just creates a default one

Change-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18
Related-Bug: #1814872
(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/78/636278/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/overcloud-compute/pre-install.d/03-centos-rt'],1,c6dc9fbbc6189d2c1113de830da45650f6951cc7,bug/1814872,"#!/bin/bash -x current_rt_repo=$(yum repolist all|grep ""centos7-rt"" |awk '{print $1}'| head -n 1 || true) if [[ ""$current_rt_repo"" == """" ]]; then else yum-config-manager --enable $current_rt_repo fi",#!/bin/bash,6,1
openstack%2Ftripleo-puppet-elements~stable%2Frocky~I630a399d95752b1fb1e30220a582ace8d7b97f18,openstack/tripleo-puppet-elements,stable/rocky,I630a399d95752b1fb1e30220a582ace8d7b97f18,Use external centos7-rt if present,MERGED,2019-02-12 07:40:14.000000000,2019-02-12 18:03:37.000000000,2019-02-12 18:03:37.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-12 07:40:14.000000000', 'files': ['elements/overcloud-compute/pre-install.d/03-centos-rt'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/90370d4c943616d1f3f976b5257f48caff1f55af', 'message': ""Use external centos7-rt if present\n\nDepending on the environment we execute this we need different\nconfiguration for the centos7-rt repo, like at RDO zuul ci we have to\nuse nodepool mirrors, this patch check for a centos7-rt repo and enables\nit if it's not present just creates a default one\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)\n""}]",0,636277,90370d4c943616d1f3f976b5257f48caff1f55af,8,6,1,27898,,,0,"Use external centos7-rt if present

Depending on the environment we execute this we need different
configuration for the centos7-rt repo, like at RDO zuul ci we have to
use nodepool mirrors, this patch check for a centos7-rt repo and enables
it if it's not present just creates a default one

Change-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18
Related-Bug: #1814872
(cherry picked from commit d313a060c80f5d97c49092eb695c335be102b473)
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/77/636277/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/overcloud-compute/pre-install.d/03-centos-rt'],1,90370d4c943616d1f3f976b5257f48caff1f55af,bug/1814872,"#!/bin/bash -x current_rt_repo=$(yum repolist all|grep ""centos7-rt"" |awk '{print $1}'| head -n 1 || true) if [[ ""$current_rt_repo"" == """" ]]; then else yum-config-manager --enable $current_rt_repo fi",#!/bin/bash,6,1
openstack%2Fsenlin~master~I5f06b4fba7b8f6efc4c36f3397d94e3ccc1abc55,openstack/senlin,master,I5f06b4fba7b8f6efc4c36f3397d94e3ccc1abc55,Do not set parent action status if stop node failed,MERGED,2019-01-17 01:33:04.000000000,2019-02-12 18:00:05.000000000,2019-02-12 18:00:05.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}, {'_account_id': 27224}, {'_account_id': 28321}]","[{'number': 1, 'created': '2019-01-17 01:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1227fda942e520e45a711ce71052624b7b6bfc58', 'message': ""Do not set parent action status if stop node failed\n\n- Add new action input key 'update_parent_status' to skip setting the\n  parent action status if an action fails.\n- When stopping a node before delete, 'update_parent_status' is set to\n False to avoid setting the parent action status if the stop action\nfails.\n\nChange-Id: I5f06b4fba7b8f6efc4c36f3397d94e3ccc1abc55\nCloses-Bug: #1812112\n""}, {'number': 2, 'created': '2019-01-29 01:03:37.000000000', 'files': ['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_delete.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/0367baa1451c1ed02f8b5af44187097127abc1b6', 'message': ""Do not set parent action status if stop node failed\n\n- Add new action input key 'update_parent_status' to skip setting the\n  parent action status if an action fails.\n- When stopping a node before delete, 'update_parent_status' is set to\n False to avoid setting the parent action status if the stop action\nfails.\n\nChange-Id: I5f06b4fba7b8f6efc4c36f3397d94e3ccc1abc55\nCloses-Bug: #1812112\n""}]",5,631365,0367baa1451c1ed02f8b5af44187097127abc1b6,14,5,2,27224,,,0,"Do not set parent action status if stop node failed

- Add new action input key 'update_parent_status' to skip setting the
  parent action status if an action fails.
- When stopping a node before delete, 'update_parent_status' is set to
 False to avoid setting the parent action status if the stop action
fails.

Change-Id: I5f06b4fba7b8f6efc4c36f3397d94e3ccc1abc55
Closes-Bug: #1812112
",git fetch https://review.opendev.org/openstack/senlin refs/changes/65/631365/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/actions/cluster_action.py', 'senlin/db/sqlalchemy/api.py']",2,1227fda942e520e45a711ce71052624b7b6bfc58,bug/1812112," action = query.all() if parent_status_update_needed(action): for d in dependents: _mark_failed(d, timestamp) action = query.all() if parent_status_update_needed(action): for d in dependents: _mark_cancelled(session, d, timestamp) action = query.all() if dependents and parent_status_update_needed(action): def parent_status_update_needed(action): """"""Return if the status of the parent action needs to be updated Return value for update_parent_status key in action inputs """""" return len(action) > 0 and action[0].inputs.get( 'update_parent_status', True)"," for d in dependents: _mark_failed(d, timestamp) for d in dependents: _mark_cancelled(session, d, timestamp) if dependents:",26,7
openstack%2Fneutron-lib~master~I26d9e748cdf1425d206d3e63056986011a518d6f,openstack/neutron-lib,master,I26d9e748cdf1425d206d3e63056986011a518d6f,rehome trunk related callback resource names,MERGED,2019-02-06 16:31:06.000000000,2019-02-12 17:57:45.000000000,2019-02-12 17:57:45.000000000,"[{'_account_id': 4187}, {'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 27546}]","[{'number': 1, 'created': '2019-02-06 16:31:06.000000000', 'files': ['neutron_lib/callbacks/resources.py', 'releasenotes/notes/rehome-trunk-callback-resources-be40f8382490ef0d.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/5cbfecc7bc7d184e484163c549b723e5976dc320', 'message': 'rehome trunk related callback resource names\n\nThis patch rehomes the SUBPORTS, TRUNK and TRUNK_PLUGIN constants\nfrom neutron.services.trunk.constants into the neutron-lib callback\nresources as they are used in callbacks today [1].\n\n[1] http://codesearch.openstack.org/?q=%5C.(SUBPORTS%7CTRUNK%7CTRUNK_PLUGIN)%2C\n\nChange-Id: I26d9e748cdf1425d206d3e63056986011a518d6f\n'}]",0,635209,5cbfecc7bc7d184e484163c549b723e5976dc320,9,5,1,5367,,,0,"rehome trunk related callback resource names

This patch rehomes the SUBPORTS, TRUNK and TRUNK_PLUGIN constants
from neutron.services.trunk.constants into the neutron-lib callback
resources as they are used in callbacks today [1].

[1] http://codesearch.openstack.org/?q=%5C.(SUBPORTS%7CTRUNK%7CTRUNK_PLUGIN)%2C

Change-Id: I26d9e748cdf1425d206d3e63056986011a518d6f
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/09/635209/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lib/callbacks/resources.py', 'releasenotes/notes/rehome-trunk-callback-resources-be40f8382490ef0d.yaml']",2,5cbfecc7bc7d184e484163c549b723e5976dc320,use-callback-payloads,"--- features: - The ``SUBPORTS``, ``TRUNK`` and ``TRUNK_PLUGIN`` constants are now available in ``neutron_lib.callbacks.resources`` for defining Trunk related callback resources. ",,8,0
openstack%2Ftripleo-heat-templates~master~I0fbaccfea8f583101b03c6ee645ff01dac11b7af,openstack/tripleo-heat-templates,master,I0fbaccfea8f583101b03c6ee645ff01dac11b7af,Remove RoleConfig,MERGED,2019-01-24 10:02:36.000000000,2019-02-12 17:54:42.000000000,2019-02-12 17:54:42.000000000,"[{'_account_id': 360}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-24 10:02:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6bfb65590af03e0d23f24800d18f64b1a12c674', 'message': 'Remove RoleConfig\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n'}, {'number': 2, 'created': '2019-01-24 13:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b13f16efb412b239d8975a12d90fd39205e0af05', 'message': 'Remove RoleConfig\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n'}, {'number': 3, 'created': '2019-01-24 13:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/17c82db26be2c6cd0d950ba6a0cb7f37cd792cae', 'message': 'Remove RoleConfig\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n'}, {'number': 4, 'created': '2019-01-24 13:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/af6a627e2f6f6b4711df95018b0af76a9769a317', 'message': 'Remove RoleConfig\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n'}, {'number': 5, 'created': '2019-01-29 09:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/db758458d4ff9d1c6aac44ab54e2640597a3ee77', 'message': 'Remove RoleConfig\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n'}, {'number': 6, 'created': '2019-01-29 09:35:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a0696d8ebe333e3a6f918ebbd1cf80d109994a71', 'message': ""Remove RoleConfig\n\nNow that config-download is the default, RoleConfig and the associated\ndeployment isn't used anymore, let's remove it.\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n""}, {'number': 7, 'created': '2019-02-11 23:20:07.000000000', 'files': ['overcloud.j2.yaml', 'common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c95f315ef00d6029c7e9e721ad0d99f5f249e88c', 'message': ""Remove RoleConfig\n\nNow that config-download is the default, RoleConfig and the associated\ndeployment isn't used anymore, let's remove it.\n\nChange-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af\n""}]",0,632974,c95f315ef00d6029c7e9e721ad0d99f5f249e88c,25,6,7,7385,,,0,"Remove RoleConfig

Now that config-download is the default, RoleConfig and the associated
deployment isn't used anymore, let's remove it.

Change-Id: I0fbaccfea8f583101b03c6ee645ff01dac11b7af
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/632974/7 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps.j2'],1,e6bfb65590af03e0d23f24800d18f64b1a12c674,remove-role-config,," RoleConfig: type: OS::Heat::SoftwareConfig properties: group: ansible options: modulepath: /usr/share/ansible-modules inputs: - name: step - name: tripleo_role_name - name: deploy_identifier - name: bootstrap_server_id - name: enable_debug - name: enable_puppet - name: docker_puppet_debug - name: container_cli - name: docker_puppet_process_count - name: docker_puppet_mount_host_puppet - name: role_data_step_config - name: role_data_puppet_config type: Json - name: role_data_docker_config_scripts type: Json - name: role_data_docker_puppet_tasks type: Json - name: role_data_docker_config type: Json - name: role_data_kolla_config type: Json - name: ansible_python_interpreter description: Python interpreter to use for the ansible execution default: {get_param: PythonInterpreter} config: str_replace: template: | - hosts: localhost connection: local tasks: _TASKS params: _TASKS: {get_file: deploy-steps-tasks.yaml} {%- else %} {%- for dep in enabled_roles %} - {{dep.name}}Deployment_Step{{step -1}} {%- endfor %} # Deployment steps for {{role.name}} # A single config is re-applied with an incrementing step number {% for step in range(1, deploy_steps_max) %} {{role.name}}Deployment_Step{{step}}: type: OS::TripleO::DeploymentSteps condition: {{role.name}}NonZero depends_on: - WorkflowTasks_Step{{step}}_Execution # TODO(gfidente): the following if/else condition # replicates what is already defined for the # WorkflowTasks_StepX resource and can be remove # if https://bugs.launchpad.net/heat/+bug/1700569 # is fixed. {%- if step == 1 %} {%- for dep in enabled_roles %} - {{dep.name}}ArtifactsDeploy {%- endfor %} {%- else %} {%- for dep in enabled_roles %} - {{dep.name}}Deployment_Step{{step -1}} {%- endfor %} {%- endif %} properties: name: {{role.name}}Deployment_Step{{step}} servers: {get_param: [servers, {{role.name}}]} config: {get_resource: RoleConfig} input_values: step: {{step}} tripleo_role_name: {{role.name}} deploy_identifier: {get_param: DeployIdentifier} bootstrap_server_id: {get_attr: [BootstrapServerId, value]} enable_debug: {get_param: ConfigDebug} enable_puppet: {get_param: EnablePuppet} docker_puppet_debug: {get_param: DockerPuppetDebug} container_cli: {get_param: ContainerCli} docker_puppet_process_count: {get_param: DockerPuppetProcessCount} docker_puppet_mount_host_puppet: {get_param: DockerPuppetMountHostPuppet} role_data_step_config: {get_param: [role_data, {{role.name}}, step_config]} role_data_puppet_config: {get_param: [role_data, {{role.name}}, puppet_config]} role_data_docker_config_scripts: {get_param: [role_data, {{role.name}}, docker_config_scripts]} role_data_docker_puppet_tasks: {get_param: [role_data, {{role.name}}, docker_puppet_tasks]} role_data_docker_config: {get_param: [role_data, {{role.name}}, docker_config]} role_data_kolla_config: {get_param: [role_data, {{role.name}}, kolla_config]} deploy_steps_max: {{deploy_steps_max}} {% endfor %} # END CONFIG STEPS depends_on: {%- for dep in enabled_roles %} - {{dep.name}}Deployment_Step{{deploy_steps_max - 1}} {%- endfor %} ",0,100
openstack%2Ftripleo-common~master~Ic08ff58b10d4fa7116163be1f7fce57879cee8c5,openstack/tripleo-common,master,Ic08ff58b10d4fa7116163be1f7fce57879cee8c5,Fixes OVN docker image prep with Neutron,MERGED,2018-08-27 19:22:49.000000000,2019-02-12 17:45:34.000000000,2019-02-12 17:45:34.000000000,"[{'_account_id': 6773}, {'_account_id': 6926}, {'_account_id': 8871}, {'_account_id': 10237}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 19999}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-27 19:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7f4ecf0dd6898b7fa21d9e6d7100ec38a3f63f94', 'message': 'Fixes OVN docker image prep with Neutron\n\nCurrently if one passes the OVN env file to generate the SDN docker\nimages, neutron server will not be generated because OVN service is\nmissing in the service list. This patch addresses that and brings it\ninline with the behavior of other SDNs (like ODL) where the Neutron\nServer image is specific to that SDN and requires generating.\n\nChange-Id: Ic08ff58b10d4fa7116163be1f7fce57879cee8c5\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}, {'number': 2, 'created': '2018-10-17 14:08:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8e53870f1e7190b231e3586f72b8747f833db760', 'message': 'Fixes OVN docker image prep with Neutron\n\nCurrently if one passes the OVN env file to generate the SDN docker\nimages, neutron server will not be generated because OVN service is\nmissing in the service list. This patch addresses that and brings it\ninline with the behavior of other SDNs (like ODL) where the Neutron\nServer image is specific to that SDN and requires generating.\n\nChange-Id: Ic08ff58b10d4fa7116163be1f7fce57879cee8c5\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}, {'number': 3, 'created': '2019-02-11 22:29:15.000000000', 'files': ['releasenotes/notes/ovn-image-prepare-neutron-server-abb60292341b5782.yaml', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0fd1b98b3cf65b1b715f10ce91dc8283be3bb86d', 'message': 'Fixes OVN docker image prep with Neutron\n\nCurrently if one passes the OVN env file to generate the SDN docker\nimages, neutron server will not be generated because OVN service is\nmissing in the service list. This patch addresses that and brings it\ninline with the behavior of other SDNs (like ODL) where the Neutron\nServer image is specific to that SDN and requires generating.\n\nChange-Id: Ic08ff58b10d4fa7116163be1f7fce57879cee8c5\nSigned-off-by: Tim Rozet <trozet@redhat.com>\n'}]",0,596871,0fd1b98b3cf65b1b715f10ce91dc8283be3bb86d,20,10,3,17280,,,0,"Fixes OVN docker image prep with Neutron

Currently if one passes the OVN env file to generate the SDN docker
images, neutron server will not be generated because OVN service is
missing in the service list. This patch addresses that and brings it
inline with the behavior of other SDNs (like ODL) where the Neutron
Server image is specific to that SDN and requires generating.

Change-Id: Ic08ff58b10d4fa7116163be1f7fce57879cee8c5
Signed-off-by: Tim Rozet <trozet@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/71/596871/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/ovn-image-prepare-neutron-server-abb60292341b5782.yaml', 'container-images/overcloud_containers.yaml.j2']",2,7f4ecf0dd6898b7fa21d9e6d7100ec38a3f63f94,ovn_prep_neutron_docker, - OS::TripleO::Services::OVNController,,6,0
openstack%2Fopenstack-ansible~master~I75657c6dae2c6246ec2513f4ec452a4c354d638b,openstack/openstack-ansible,master,I75657c6dae2c6246ec2513f4ec452a4c354d638b,Use an env lookup to determine the OSA version,MERGED,2019-01-29 15:43:11.000000000,2019-02-12 17:29:08.000000000,2019-02-12 17:29:08.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 15:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8999415984db41e99617339d11b7eb95ca6a03e9', 'message': ""Use an env lookup to determine the OSA version\n\nThis is about as fast as the current static code, and doesn't\nrequire bumping at every release.\n\nChange-Id: I75657c6dae2c6246ec2513f4ec452a4c354d638b\n""}, {'number': 2, 'created': '2019-01-29 15:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aa062b604730222898cb875928b3897e6b16dd52', 'message': ""Use an env lookup to determine the OSA version\n\nThis is about as fast as the current static code, and doesn't\nrequire bumping at every release.\n\nChange-Id: I75657c6dae2c6246ec2513f4ec452a4c354d638b\n""}, {'number': 3, 'created': '2019-02-12 10:16:02.000000000', 'files': ['inventory/group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7e0d2e5e5c9cad5be2091d7a973dc2b5abf4d561', 'message': ""Use an env lookup to determine the OSA version\n\nThis is about as fast as the current static code, and doesn't\nrequire bumping at every release.\n\nChange-Id: I75657c6dae2c6246ec2513f4ec452a4c354d638b\n""}]",0,633763,7e0d2e5e5c9cad5be2091d7a973dc2b5abf4d561,18,3,3,17068,,,0,"Use an env lookup to determine the OSA version

This is about as fast as the current static code, and doesn't
require bumping at every release.

Change-Id: I75657c6dae2c6246ec2513f4ec452a4c354d638b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/63/633763/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/all.yml'],1,8999415984db41e99617339d11b7eb95ca6a03e9,easier_osa_releases,"openstack_release: ""{{ lookup('env', 'OSA_VERSION' | default('undefined', true) }}""",openstack_release: 19.0.0.0b1,1,1
openstack%2Fnetworking-ovn~stable%2Frocky~I1ef35242e2d1427d96320c47aff22e86bc035ada,openstack/networking-ovn,stable/rocky,I1ef35242e2d1427d96320c47aff22e86bc035ada,Fix Ansible lint errors,MERGED,2019-01-30 10:42:22.000000000,2019-02-12 17:08:12.000000000,2019-02-12 17:08:12.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 16615}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-01-30 10:42:22.000000000', 'files': ['migration/tripleo_environment/playbooks/roles/delete-neutron-resources/tasks/main.yml', 'migration/infrared/tripleo-ovn-migration/roles/create-resources/tasks/main.yml', 'migration/tripleo_environment/playbooks/roles/tripleo-update/tasks/main.yml', 'migration/infrared/tripleo-ovn-migration/main.yml', 'migration/migrate-to-ovn.yml', 'migration/infrared/tripleo-ovn-migration/roles/prepare-migration/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8c44e717efe9e8d4d8c11a70320fa4655493250f', 'message': 'Fix Ansible lint errors\n\nFixed Ansible lint errors ANSIBLE0012 and ANSIBLE0013\nwhich address the usage of shell and command modules properly.\n\n* When a shell/command task creates a file, it should explictly\n  specify it with a \'creates\' argument.\n* When shell is not required, use the command module.\n* If a task is not changing anything (e.g. cat <file>)\n  it should be marked as ""changed_when: false"".\n\nAlso, fixed lines with \'ignore_error\' to be \'ignore_errors\'.\n\nChange-Id: I1ef35242e2d1427d96320c47aff22e86bc035ada\n(cherry picked from commit b2a38c21cc6ef2f93f4f4f35688e037254e4f399)\n'}]",0,633909,8c44e717efe9e8d4d8c11a70320fa4655493250f,12,6,1,8788,,,0,"Fix Ansible lint errors

Fixed Ansible lint errors ANSIBLE0012 and ANSIBLE0013
which address the usage of shell and command modules properly.

* When a shell/command task creates a file, it should explictly
  specify it with a 'creates' argument.
* When shell is not required, use the command module.
* If a task is not changing anything (e.g. cat <file>)
  it should be marked as ""changed_when: false"".

Also, fixed lines with 'ignore_error' to be 'ignore_errors'.

Change-Id: I1ef35242e2d1427d96320c47aff22e86bc035ada
(cherry picked from commit b2a38c21cc6ef2f93f4f4f35688e037254e4f399)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/09/633909/1 && git format-patch -1 --stdout FETCH_HEAD,"['migration/tripleo_environment/playbooks/roles/delete-neutron-resources/tasks/main.yml', 'migration/infrared/tripleo-ovn-migration/roles/create-resources/tasks/main.yml', 'migration/tripleo_environment/playbooks/roles/tripleo-update/tasks/main.yml', 'migration/infrared/tripleo-ovn-migration/main.yml', 'migration/migrate-to-ovn.yml', 'migration/infrared/tripleo-ovn-migration/roles/prepare-migration/tasks/main.yml']",6,8c44e717efe9e8d4d8c11a70320fa4655493250f,rocky, command: cp -f {{ overcloud_deploy_script }} ~/overcloud-deploy-ovn.sh ignore_errors: True ignore_errors: True args: creates: ~/ovn_container_images.yaml changed_when: False command: cat /tmp/_reg_namespace changed_when: False, shell: cp -f {{ overcloud_deploy_script }} ~/overcloud-deploy-ovn.sh ignore_error: True ignore_error: True shell: cat /tmp/_reg_namespace,34,7
openstack%2Fnova-specs~master~I3088cbba44009ff42ec710b402bab28c7dbfeef9,openstack/nova-specs,master,I3088cbba44009ff42ec710b402bab28c7dbfeef9,Spec to add per instance timeout for LM - Stein,ABANDONED,2018-09-07 02:18:53.000000000,2019-02-12 16:41:20.000000000,,"[{'_account_id': 782}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 8768}, {'_account_id': 10135}, {'_account_id': 20722}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-07 02:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/abf940801d9b8b2fbd99ef1bdd4a630f6611d59e', 'message': 'Spec to add per instance timeout for LM - Stein\n\nAdd a new microversion to live-migrate API to abort\nor force complete any libvirt live-migration\noperation after a given timeout.\n\nThis spec was priviously approved in Pike:\nI7265d1b8d3e293d34f295e995e514c5ef102874b\nbut did not have an owner, repropose for Stein.\n\nCo-Authored-By: Sarafraj Singh <Sarafraj.Singh@intel.com>\nCo-Authored-By: John Garbutt <john@johngarbutt.com>\n\nAPIImpact\n\nblueprint live-migration-per-instance-timeout\n\nChange-Id: I3088cbba44009ff42ec710b402bab28c7dbfeef9\n'}, {'number': 2, 'created': '2018-09-07 06:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b7365bf56fc3261778c7d8829a5976b36193e1c9', 'message': 'Spec to add per instance timeout for LM - Stein\n\nAdd a new microversion to live-migrate API to abort\nor force complete any libvirt live-migration\noperation after a given timeout.\n\nPreviously-approved: Pike\n\nCo-Authored-By: Sarafraj Singh <Sarafraj.Singh@intel.com>\nCo-Authored-By: John Garbutt <john@johngarbutt.com>\n\nAPIImpact\n\nblueprint live-migration-per-instance-timeout\n\nChange-Id: I3088cbba44009ff42ec710b402bab28c7dbfeef9\n'}, {'number': 3, 'created': '2018-09-07 19:56:40.000000000', 'files': ['specs/stein/approved/live-migration-per-instance-timeout.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/df2baec3e26a8f288abf53c69f9e0036cc134055', 'message': 'Spec to add per instance timeout for LM - Stein\n\nAdd a new microversion to live-migrate API to abort\nor force complete any libvirt live-migration\noperation after a given timeout.\n\nPreviously-approved: Pike\n\nCo-Authored-By: Sarafraj Singh <Sarafraj.Singh@intel.com>\nCo-Authored-By: John Garbutt <john@johngarbutt.com>\n\nAPIImpact\n\nblueprint live-migration-per-instance-timeout\n\nChange-Id: I3088cbba44009ff42ec710b402bab28c7dbfeef9\n'}]",35,600613,df2baec3e26a8f288abf53c69f9e0036cc134055,19,7,3,15888,,,0,"Spec to add per instance timeout for LM - Stein

Add a new microversion to live-migrate API to abort
or force complete any libvirt live-migration
operation after a given timeout.

Previously-approved: Pike

Co-Authored-By: Sarafraj Singh <Sarafraj.Singh@intel.com>
Co-Authored-By: John Garbutt <john@johngarbutt.com>

APIImpact

blueprint live-migration-per-instance-timeout

Change-Id: I3088cbba44009ff42ec710b402bab28c7dbfeef9
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/13/600613/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/approved/live-migration-per-instance-timeout-stein.rst'],1,abf940801d9b8b2fbd99ef1bdd4a630f6611d59e,bp/live-migration-per-instance-timeout,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =================================== Live-Migration per instance timeout =================================== https://blueprints.launchpad.net/nova/+spec/live-migration-per-instance-timeout Add a new microversion to live-migrate API to abort or force complete any libvirt live-migration operation after a given timeout. Problem description =================== Nova currently optimizes for limited guest downtime, over ensuring the live-migration operation always succeeds. This can make live-migration in Nova look much less ""reliable"" than live-migration offered in other cloud and server virt systems. A key observation is that the trade off between guest liveness and how long you are willing to wait for a live-migration to complete is not the same for every instance, nor for each live-migration API call made on the same instance. If a failed live-migration means the guest now has to stay on the host you are in the process of patching and rebooting, the guest will have significantly more downtime than if you had a small increase in the downtime the VM would experience during live-migration. With current live-migrate API and config options, operators do not have fine-grained control over per instance live-migrate operations. If they want to treat any particular instance live-migrate operation different then they have to change the related config value to better fit and restart compute services which makes live-migration experience very unpleasant. Given the recent removal of the progress timeout, we have discussed with operators that they would like to customize the timeout per live-migration operation. Based on the VM involved and the cost of not moving the VM, they can make the call of how long to wait. In a similar way, they want to decide if they should abort after that timeout (avoiding the VM having any more downtime than ``libvirt.live_migration_downtime``), or force the live-migration to move (allowing more downtime than ``libvirt.live_migration_downtime`` to ensure the VM moves). If we give operators the ability to set a custom timeout per live-migration operation, this causes some conflict with some other configuration options. Nova tells libvirt only to allow a live-migration to complete if there will be no more than ``libvirt.live_migration_downtime`` milliseconds of downtime. To further reduce the impact of live-migration on the guest VM, Nova slowly ramps up the amount of allowed downtime up to that maximum value. Nova uses the config options ``libvirt.live_migration_downtime_steps`` and ``libvirt.live_migration_downtime_delay`` to decide how long to take before reaching ``libvirt.live_migration_downtime`` milliseconds of allowed VM downtime. Currently these configuration values must be carefully changed to match the value of ``libvirt.live_migration_completion_timeout``, meaning not spend all the time ramping up and not allowing enough time for a VM to move before completion timeout expires. If we allow operators to specify their own timeout value per live-migration operation, we must find a way to reconcile this with logic that ramps up the amount of allowed downtime before the live-migration is allowed to complete. Use Cases --------- * Operators want to patch a host and want to move all the VM's out of that host. In this case they want to force a VM to move when timeout is reached because they find the risk of possible needing to reboot the VM less acceptable than pausing the VM to make it move. * Operators want to move the busy VM out of a host to balance out their cluster. In this case they want flexibility to kick off live-migration operation with an option to cancel the operation when the timer expires. Proposed change =============== Add a new microversion to Live-Migrate Server API to add support for following two optional parameters: * ``timeout_seconds`` - Optional parameter to specify time in seconds after which nova will take actions on the given live-migration operation. This will override the config option ``libvirt.live_migration_completion_timeout``. Note, unlike the configuration this is an absolute timeout, not one scaled up to match the size of the VM. * ``on_timeout`` - This optional parameter can be set to ``force_complete`` or ``abort``. This will override the config option: ``libvirt.live_migration_action_on_timeout``, that defaults to ``abort``. To help upgrades, we return 400 for any requests containing either of the new timeout paramter and before all compute nodes have been upgraded to report at least the service version that matches when this feature was added. To address issue with ramp up time, we propose to spend half of the specified completion timeout ramping up to maximum downtime as normal. After that, we jump up to ``libvirt.live_migration_downtime``. This will ensure VM will spend half of the specified timeout with the best chance of letting live-migration complete without having to abort or force-complete. Alternatives ------------ Operators can call either the ``delete`` migration API to abort a running live-migration or call ``force-complete`` to trigger post-copy or pause the VM being live-migrated. However this is far from convenient, and can lead to races in timeouts happening just before calling ``force-complete``. There are many other ways we could modify the downtime ramp up logic. Given the discussions on re-working that logic we just do the minimum to ensure ``libvirt.live_migration_downtime`` is reached before we hit the timeout specified by the operator. Data model impact ----------------- The Migration object takes two new params for live-migrate API: * timeout_seconds - integer attribute. * on_timeout - enum of ([""force_complete"", ""abort""]). REST API impact --------------- * URL: POST /v2.1/servers/{server_id}/action JSON request body:: { ""os-migrateLive"": { ""host"": ""target-host"", ""block_migration"": ""auto"", ""timeout_seconds"": 60, ""on_timeout"": ""force_complete"" } } A new microversion will be introduced to os-migrateLive API, which will take two additional and optional parameters ``timeout_seconds`` and ``on_timeout``. * JSON schema for ``timeout_seconds``:: { ""timeout_seconds"": { ""type"": ""integer"", ""minimum"": 0 } } * JSON schema for ``on_timeout``:: { ""on_timeout"": { ""type"": ""string"", ""enum"": [ ""force_complete"", ""abort"" ] } } Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Add support for API in python-novaclient. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Kevin Zheng Other contributors: Yikun Jiang Work Items ---------- * Add logic in libvirt to make use of these new parameters. * Add API to expose per operation force-timeout and actions. Dependencies ============ We first need the configuration added for the default timeout action: https://blueprints.launchpad.net/nova/+spec/live-migration-force-after-timeout Testing ======= Need new tempest tests for the new API. Look into busy workloads inside VMs to test the above API in the gate's live-migration job. Documentation Impact ==================== Need to update api-ref with details of the new API. Should also update the API concept guide to cover how best to use live-migration with all these new APIs we have added. References ========== None History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Pike - Introduced * - Stein - Reproposed ",,250,0
openstack%2Fnova~stable%2Fpike~I1f4b3540dd453650f94333b36d7504ba164192f7,openstack/nova,stable/pike,I1f4b3540dd453650f94333b36d7504ba164192f7,Fix InstanceNotFound during _destroy_evacuated_instances,MERGED,2018-12-07 00:40:37.000000000,2019-02-12 16:37:01.000000000,2019-02-12 16:37:00.000000000,"[{'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-07 00:40:37.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1794996.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb61e864b98dde4955ab29f7a39c9935fbd5ffd0', 'message': ""Fix InstanceNotFound during _destroy_evacuated_instances\n\nThe _destroy_evacuated_instances method on compute\nstartup tries to cleanup guests on the hypervisor and\nallocations held against that compute node resource\nprovider by evacuated instances, but doesn't take into\naccount that those evacuated instances could have been\ndeleted in the meantime which leads to a lazy-load\nInstanceNotFound error that kills the startup of the\ncompute service.\n\nThis change does two things in the _destroy_evacuated_instances\nmethod:\n\n1. Loads the evacuated instances with a read_deleted='yes'\n   context when calling _get_instances_on_driver(). This\n   should be fine since _get_instances_on_driver() is already\n   returning deleted instances anyway (InstanceList.get_by_filters\n   defaults to read deleted instances unless the filters tell\n   it otherwise - which we don't in this case). This is needed\n   so that things like driver.destroy() don't raise\n   InstanceNotFound while lazy-loading fields on the instance.\n\n2. Skips the call to remove_allocation_from_compute() if the\n   evacuated instance is already deleted. If the instance is\n   already deleted, its allocations should have been cleaned\n   up by its hosting compute service (or the API).\n\nThe functional regression test is updated to show the bug is\nnow fixed.\n\nConflicts:\n      nova/compute/manager.py\n\nNOTE(mriedem): The conflict is due to not having change\nI1073faca6760bff3da0aaf3e8357bd8e64854be3 in Pike.\n\nChange-Id: I1f4b3540dd453650f94333b36d7504ba164192f7\nCloses-Bug: #1794996\n(cherry picked from commit 05cd8d128211adbbfb3cf5d626034ccd0f75a452)\n(cherry picked from commit 0208d64397731afa829bc08cd7b3b6494f0f05d5)\n(cherry picked from commit 6c7e53e21059f80325d728cf7dee2766da7a9471)\n""}]",0,623359,fb61e864b98dde4955ab29f7a39c9935fbd5ffd0,12,8,1,6873,,,0,"Fix InstanceNotFound during _destroy_evacuated_instances

The _destroy_evacuated_instances method on compute
startup tries to cleanup guests on the hypervisor and
allocations held against that compute node resource
provider by evacuated instances, but doesn't take into
account that those evacuated instances could have been
deleted in the meantime which leads to a lazy-load
InstanceNotFound error that kills the startup of the
compute service.

This change does two things in the _destroy_evacuated_instances
method:

1. Loads the evacuated instances with a read_deleted='yes'
   context when calling _get_instances_on_driver(). This
   should be fine since _get_instances_on_driver() is already
   returning deleted instances anyway (InstanceList.get_by_filters
   defaults to read deleted instances unless the filters tell
   it otherwise - which we don't in this case). This is needed
   so that things like driver.destroy() don't raise
   InstanceNotFound while lazy-loading fields on the instance.

2. Skips the call to remove_allocation_from_compute() if the
   evacuated instance is already deleted. If the instance is
   already deleted, its allocations should have been cleaned
   up by its hosting compute service (or the API).

The functional regression test is updated to show the bug is
now fixed.

Conflicts:
      nova/compute/manager.py

NOTE(mriedem): The conflict is due to not having change
I1073faca6760bff3da0aaf3e8357bd8e64854be3 in Pike.

Change-Id: I1f4b3540dd453650f94333b36d7504ba164192f7
Closes-Bug: #1794996
(cherry picked from commit 05cd8d128211adbbfb3cf5d626034ccd0f75a452)
(cherry picked from commit 0208d64397731afa829bc08cd7b3b6494f0f05d5)
(cherry picked from commit 6c7e53e21059f80325d728cf7dee2766da7a9471)
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/623359/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1794996.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py']",4,fb61e864b98dde4955ab29f7a39c9935fbd5ffd0,bug/1550919," # The instances might be deleted in which case we need to avoid # InstanceNotFound being raised from lazy-loading fields on the # instances while cleaning up this host. read_deleted_context = context.elevated(read_deleted='yes') # TODO(mriedem): We could optimize by pre-loading the joined fields # we know we'll use, like info_cache and flavor. We can also replace # this with a generic solution: https://review.openstack.org/575190/ local_instances = self._get_instances_on_driver(read_deleted_context) # If the instance was deleted in the interim, assume its # allocations were properly cleaned up (either by its hosting # compute service or the API). if not instance.deleted: my_resources = scheduler_utils.resources_from_flavor( instance, instance.flavor) res = self.reportclient.\ remove_provider_from_instance_allocation( instance.uuid, cn_uuid, instance.user_id, instance.project_id, my_resources) if not res: LOG.error(""Failed to clean allocation of evacuated "" ""instance on the source node %s"", cn_uuid, instance=instance)"," local_instances = self._get_instances_on_driver(context) my_resources = scheduler_utils.resources_from_flavor( instance, instance.flavor) res = self.reportclient.remove_provider_from_instance_allocation( instance.uuid, cn_uuid, instance.user_id, instance.project_id, my_resources) if not res: LOG.error(""Failed to clean allocation of evacuated instance "" ""on the source node %s"", cn_uuid, instance=instance)",48,25
openstack%2Fneutron~master~Iaf9b6f9cc7a068ecfae30d307fb6a688cbc45d3c,openstack/neutron,master,Iaf9b6f9cc7a068ecfae30d307fb6a688cbc45d3c,Remove redundant if condition check,MERGED,2019-02-07 23:04:06.000000000,2019-02-12 16:36:47.000000000,2019-02-12 16:36:47.000000000,"[{'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-07 23:04:06.000000000', 'files': ['neutron/db/l3_dvr_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c4e755daa9ce4e250965e5039e8a4e13e08c84af', 'message': 'Remove redundant if condition check\n\nThe check for an empty list is redundant, the remainder\nof the code will simply not do anything on an empty list.\n\nChange-Id: Iaf9b6f9cc7a068ecfae30d307fb6a688cbc45d3c\n'}]",0,635691,c4e755daa9ce4e250965e5039e8a4e13e08c84af,15,6,1,6593,,,0,"Remove redundant if condition check

The check for an empty list is redundant, the remainder
of the code will simply not do anything on an empty list.

Change-Id: Iaf9b6f9cc7a068ecfae30d307fb6a688cbc45d3c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/635691/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_dvr_db.py'],1,c4e755daa9ce4e250965e5039e8a4e13e08c84af,cleanup,, if not routers: return [],0,2
openstack%2Ftripleo-quickstart-extras~master~Ibb066535f7358a8857732e3f7e13bed87e6057e3,openstack/tripleo-quickstart-extras,master,Ibb066535f7358a8857732e3f7e13bed87e6057e3,warnings should be first and in red,MERGED,2019-02-09 18:16:06.000000000,2019-02-12 16:21:52.000000000,2019-02-12 16:21:52.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-09 18:16:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1b8d0947a6500a87186eda0da307f80c3b4fa3d4', 'message': 'WIP: warnings should be first and in red\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}, {'number': 2, 'created': '2019-02-11 18:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c23196412b5fc4012b63d44ef6f5e9509178e2d4', 'message': 'warnings should be first and in red\n\nMove the checks and warnings where possible\nto the top of the script. Use the color red\nto indicate an action is required by the user.\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}, {'number': 3, 'created': '2019-02-11 18:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/826166439a11a01c5fe8812ee2a5881665128733', 'message': 'warnings should be first and in red\n\nMove the checks and warnings where possible\nto the top of the script. Use the color red\nto indicate an action is required by the user.\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}, {'number': 4, 'created': '2019-02-11 23:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/26c3f9027c0c974374fca34ad6f2536de893e085', 'message': 'warnings should be first and in red\n\nMove the checks and warnings where possible\nto the top of the script. Use the color red\nto indicate an action is required by the user.\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}, {'number': 5, 'created': '2019-02-11 23:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/320e91f7db7ef4fd6f34242b8cbd83524162a488', 'message': 'warnings should be first and in red\n\n* Move the checks and warnings where possible\nto the top of the script. Use the color red\nto indicate an action is required by the user.\n* Handle centos docker install w/ dockerroot\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}, {'number': 6, 'created': '2019-02-12 01:51:52.000000000', 'files': ['roles/create-zuul-based-reproducer/templates/reproducer-zuul-based-quickstart.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ed75738ae7daf8dd7df396fd9b96c3e18f6f2c78', 'message': 'warnings should be first and in red\n\n* Move the checks and warnings where possible\nto the top of the script. Use the color red\nto indicate an action is required by the user.\n* Handle centos docker install w/ dockerroot\n\nChange-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3\n'}]",5,636028,ed75738ae7daf8dd7df396fd9b96c3e18f6f2c78,30,7,6,9592,,,0,"warnings should be first and in red

* Move the checks and warnings where possible
to the top of the script. Use the color red
to indicate an action is required by the user.
* Handle centos docker install w/ dockerroot

Change-Id: Ibb066535f7358a8857732e3f7e13bed87e6057e3
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/28/636028/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/create-zuul-based-reproducer/templates/reproducer-zuul-based-quickstart.sh.j2'],1,1b8d0947a6500a87186eda0da307f80c3b4fa3d4,Ibb066535f7358a8857732e3f7e13bed87e6057e3," echo -e ""\e[31m WARNING: Add user immediately to the docker group. \ This will exit the script, please re-execute. \e[0m"""," echo ""Add user immediately to the docker group."" echo ""This will exit the script, please re-execute.""",2,2
openstack%2Fopenstack-ansible-os_neutron~master~Ie4e97730304fb8a52e3ab933a202d79ec6e71585,openstack/openstack-ansible-os_neutron,master,Ie4e97730304fb8a52e3ab933a202d79ec6e71585,Add support for dns_domain_ports api extension,MERGED,2018-12-10 14:33:22.000000000,2019-02-12 16:15:57.000000000,2018-12-21 17:16:03.000000000,"[{'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-10 14:33:22.000000000', 'files': ['templates/neutron.conf.j2', 'templates/plugins/ml2/ml2_conf.ini.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/9af5fe6aa6b58e62ed4377deb52848e5bced50b6', 'message': 'Add support for dns_domain_ports api extension\n\nSee https://docs.openstack.org/neutron/rocky/admin/config-dns-int.html\n\nChange-Id: Ie4e97730304fb8a52e3ab933a202d79ec6e71585\n'}]",0,624097,9af5fe6aa6b58e62ed4377deb52848e5bced50b6,8,3,1,25023,,,0,"Add support for dns_domain_ports api extension

See https://docs.openstack.org/neutron/rocky/admin/config-dns-int.html

Change-Id: Ie4e97730304fb8a52e3ab933a202d79ec6e71585
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/97/624097/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/neutron.conf.j2', 'templates/plugins/ml2/ml2_conf.ini.j2']",2,9af5fe6aa6b58e62ed4377deb52848e5bced50b6,,"extension_drivers = port_security{% if 'qos' in neutron_plugin_base %},qos{% endif %}{% if 'dns' in neutron_plugin_base %},dns{% endif %}{% if 'dns_domain_ports' in neutron_plugin_base %},dns_domain_ports{% endif %}","extension_drivers = port_security{% if 'qos' in neutron_plugin_base %},qos{% endif %}{% if 'dns' in neutron_plugin_base %},dns{% endif %}",2,2
openstack%2Fnova~master~Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af,openstack/nova,master,Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af,WIP: Base _ContextAuthPlugin on BaseIdentityPlugin,ABANDONED,2017-08-05 23:07:12.000000000,2019-02-12 16:15:06.000000000,,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-08-05 23:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c89d4d6c0482c6e52336d2ce701c444351c0f774', 'message': ""WIP: Base _ContextAuthPlugin on BaseIdentityPlugin\n\nAuth plugins in keystoneauth1 got new methods for discovery, including\nget_endpoint_data, which we'd like to use.  This change makes\n_ContextAuthPlugin's base class\nkeystoneauth1.identity.base.BaseIdentityPlugin instead of\nkeystoneauth1.plugin.BaseAuthPlugin so it'll have that method.\n\nThis is experimental.\n\nChange-Id: Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af\n""}, {'number': 2, 'created': '2017-08-07 20:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe3fe3371e60ddbd056567c853c74e4bca796f2d', 'message': ""WIP: Base _ContextAuthPlugin on BaseIdentityPlugin\n\nAuth plugins in keystoneauth1 got new methods for discovery, including\nget_endpoint_data, which we'd like to use.  This change makes\n_ContextAuthPlugin's base class\nkeystoneauth1.identity.base.BaseIdentityPlugin instead of\nkeystoneauth1.plugin.BaseAuthPlugin so it'll have that method.\n\nThis is experimental.\n\nChange-Id: Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af\n""}, {'number': 3, 'created': '2017-08-07 22:09:28.000000000', 'files': ['nova/image/glance.py', 'nova/context.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d175372e81319bba2cb646748ec4ef613921761', 'message': ""WIP: Base _ContextAuthPlugin on BaseIdentityPlugin\n\nAuth plugins in keystoneauth1 got new methods for discovery, including\nget_endpoint_data, which we'd like to use.  This change makes\n_ContextAuthPlugin's base class\nkeystoneauth1.identity.base.BaseIdentityPlugin instead of\nkeystoneauth1.plugin.BaseAuthPlugin so it'll have that method.\n\nThis is experimental.\n\nChange-Id: Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af\n""}]",0,491203,6d175372e81319bba2cb646748ec4ef613921761,28,9,3,14070,,,0,"WIP: Base _ContextAuthPlugin on BaseIdentityPlugin

Auth plugins in keystoneauth1 got new methods for discovery, including
get_endpoint_data, which we'd like to use.  This change makes
_ContextAuthPlugin's base class
keystoneauth1.identity.base.BaseIdentityPlugin instead of
keystoneauth1.plugin.BaseAuthPlugin so it'll have that method.

This is experimental.

Change-Id: Iacd4405d9a98f0aeba2eaaefe6ad4b5fc7c1a8af
",git fetch https://review.opendev.org/openstack/nova refs/changes/03/491203/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/image/glance.py', 'nova/context.py']",2,c89d4d6c0482c6e52336d2ce701c444351c0f774,rebase_context_auth_plugin,from keystoneauth1.identity import baseclass _ContextAuthPlugin(base.BaseIdentityPlugin):,from keystoneauth1 import pluginclass _ContextAuthPlugin(plugin.BaseAuthPlugin):,4,10
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ib57c2a3980214a9a7d19b4b7144dc48d06f240dc,openstack/tripleo-heat-templates,stable/rocky,Ib57c2a3980214a9a7d19b4b7144dc48d06f240dc,DNM: Ensure all upgrade tasks depend on a step.,ABANDONED,2019-01-22 11:04:05.000000000,2019-02-12 16:14:11.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-01-22 11:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e30a2047abd0c66b27b65bef9c6b9177d56e03f9', 'message': ""DNM: Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\n(cherry picked from commit c0adbef2ffb8dd958294472c56ceda78dd24eb38)\nChange-Id: Ib57c2a3980214a9a7d19b4b7144dc48d06f240dc\n""}, {'number': 2, 'created': '2019-01-22 11:06:00.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'puppet/services/opendaylight-ovs.yaml', 'docker/services/opendaylight-api.yaml', 'tools/yaml-validate.py', 'docker/services/pacemaker/ovn-dbs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21bc110829dcc13b8cfe28d72a919474d93bad3e', 'message': ""DNM: Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\n(cherry picked from commit c0adbef2ffb8dd958294472c56ceda78dd24eb38)\nChange-Id: Ib57c2a3980214a9a7d19b4b7144dc48d06f240dc\n""}]",0,632414,21bc110829dcc13b8cfe28d72a919474d93bad3e,7,3,2,26343,,,0,"DNM: Ensure all upgrade tasks depend on a step.

This patch refactors some of the upgrade tasks which were missing
a task condition to run depending on the variable step. Grouping
them in blocks when possible.

Besides, an extra check has been added for the upgrade_tasks validation
function inside tools/yaml-validate.py which ensures that every upgrade
task will contain a 'when' condition. This check could be disabled by
passing the variable 'check_when' to false.

(cherry picked from commit c0adbef2ffb8dd958294472c56ceda78dd24eb38)
Change-Id: Ib57c2a3980214a9a7d19b4b7144dc48d06f240dc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/632414/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'puppet/services/opendaylight-ovs.yaml', 'docker/services/opendaylight-api.yaml', 'tools/yaml-validate.py', 'docker/services/pacemaker/ovn-dbs.yaml']",6,e30a2047abd0c66b27b65bef9c6b9177d56e03f9,," - when: step|int == 0 block: - name: Check for ovn-dbs log file stat: path: /var/log/containers/openvswitch/ovsdb-server-nb.log register: ovn_dbs_log_file - name: Check if ovn-dbs is already containerized set_fact: ovn_dbs_containerized: ""{{ovn_dbs_log_file.stat.exists | default(false)}}"" - name: Get docker ovn-dbs image set_fact: ovn_dbs_docker_image: {get_param: DockerOvnDbsImage} ovn_dbs_docker_image_latest: *ovn_dbs_image_pcmklatest - name: get bootstrap nodeid command: hiera -c /etc/puppet/hiera.yaml bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Prepare the switch to new ovn-dbs container image name in pacemaker when: ovn_dbs_containerized|bool block: - name: Get ovn-dbs image id currently used by pacemaker shell: ""docker images | awk '/ovn.* pcmklatest/{print $3}' | uniq"" register: ovn_dbs_current_pcmklatest_id - name: Temporarily tag the current ovn-dbs pcmklatest image id with the upgraded image name shell: ""docker tag {{ovn_dbs_current_pcmklatest_id.stdout}} {{ovn_dbs_docker_image_latest}}"" when: ovn_dbs_current_pcmklatest_id.stdout != '' # If ovn-dbs image is not tagged with pcmklatest, then create a new # tag. This could happen if the stack is upgraded without updating the stack before. # In the next step, the block 'ovn_dbs_update_bundle_with_new_image' # will update the ovn-dbs-bundle resource to use the tagged image. # And in step 3, we will fetch the latest image. - block: - name: Get the present image used by ovn-dbs-bundle shell: ""pcs resource show ovn-dbs-bundle | grep image | awk '{ split($2, image, \""=\""); print image[2] }'"" register: ovn_dbs_current_image - name: Tag the current image with pcmklatest tag shell: ""docker tag {{ovn_dbs_current_image.stdout}} {{ovn_dbs_docker_image_latest}}"" when: ovn_dbs_current_pcmklatest_id.stdout == '' - when: step|int == 1 block: - name: Check ovn-dbs-bundle cluster resource status pacemaker_resource: resource: ovn-dbs-bundle state: show check_mode: false ignore_errors: true register: ovndbs_pcs_res - name: Stop and disable ovn-northd service service: name=ovn-northd state=stopped enabled=no ignore_errors: true - name: Update ovn-bundle pcs resource bundle for new container image when: - ovn_dbs_containerized|bool - is_bootstrap_node - ovndbs_pcs_res|succeeded block: *ovn_dbs_update_bundle_with_new_image"," - name: Stop and disable ovn-northd service when: step|int == 1 service: name=ovn-northd state=stopped enabled=no ignore_errors: true - name: Check for ovn-dbs log file stat: path: /var/log/containers/openvswitch/ovsdb-server-nb.log register: ovn_dbs_log_file - name: Check if ovn-dbs is already containerized set_fact: ovn_dbs_containerized: ""{{ovn_dbs_log_file.stat.exists | default(false)}}"" - name: Get docker ovn-dbs image set_fact: ovn_dbs_docker_image: {get_param: DockerOvnDbsImage} ovn_dbs_docker_image_latest: *ovn_dbs_image_pcmklatest - name: get bootstrap nodeid command: hiera -c /etc/puppet/hiera.yaml bootstrap_nodeid register: bootstrap_node - name: set is_bootstrap_node fact set_fact: is_bootstrap_node={{bootstrap_node.stdout|lower == ansible_hostname|lower}} - name: Prepare the switch to new ovn-dbs container image name in pacemaker when: - step|int == 0 - ovn_dbs_containerized|bool block: - name: Get ovn-dbs image id currently used by pacemaker shell: ""docker images | awk '/ovn.* pcmklatest/{print $3}' | uniq"" register: ovn_dbs_current_pcmklatest_id - name: Temporarily tag the current ovn-dbs pcmklatest image id with the upgraded image name shell: ""docker tag {{ovn_dbs_current_pcmklatest_id.stdout}} {{ovn_dbs_docker_image_latest}}"" when: ovn_dbs_current_pcmklatest_id.stdout != '' # If ovn-dbs image is not tagged with pcmklatest, then create a new # tag. This could happen if the stack is upgraded without updating the stack before. # In the next step, the block 'ovn_dbs_update_bundle_with_new_image' # will update the ovn-dbs-bundle resource to use the tagged image. # And in step 3, we will fetch the latest image. - block: - name: Get the present image used by ovn-dbs-bundle shell: ""pcs resource show ovn-dbs-bundle | grep image | awk '{ split($2, image, \""=\""); print image[2] }'"" register: ovn_dbs_current_image - name: Tag the current image with pcmklatest tag shell: ""docker tag {{ovn_dbs_current_image.stdout}} {{ovn_dbs_docker_image_latest}}"" when: - ovn_dbs_current_pcmklatest_id.stdout == '' - name: Check ovn-dbs-bundle cluster resource status pacemaker_resource: resource: ovn-dbs-bundle state: show check_mode: false ignore_errors: true register: ovndbs_pcs_res - name: Update ovn-bundle pcs resource bundle for new container image when: - step|int == 1 - ovn_dbs_containerized|bool - is_bootstrap_node - ovndbs_pcs_res|succeeded block: *ovn_dbs_update_bundle_with_new_image",271,256
openstack%2Fvitrage~master~I494e5749adc1d3845f793a941f970a944457d992,openstack/vitrage,master,I494e5749adc1d3845f793a941f970a944457d992,add a new service list api,MERGED,2019-02-03 16:10:33.000000000,2019-02-12 16:05:43.000000000,2019-02-12 16:05:43.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}, {'_account_id': 26339}]","[{'number': 1, 'created': '2019-02-03 16:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/e0ea64d0659252735076ac0d053996ff1d18b066', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 2, 'created': '2019-02-04 14:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b60d8770667c5d91753a204ac94aadacc9833ac5', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 3, 'created': '2019-02-04 14:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/f055b318375c86f3abd73c92908a1780b5049601', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 4, 'created': '2019-02-05 11:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/0b9cf9ad032ce384e1729c132ac938516bac9d7c', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 5, 'created': '2019-02-05 11:09:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/44a6f2071fcb455a8576e19ae0134238b00c19a5', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 6, 'created': '2019-02-05 13:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/8c569f9d14b9f177be4eb0758d360cd3b5cd6483', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 7, 'created': '2019-02-05 13:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/43ea384071e12c26198c24b19694ccd5da25ee99', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 8, 'created': '2019-02-06 07:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/e6f0eb977a604ea255a4427a7eb4a01aa4b5542b', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 9, 'created': '2019-02-06 08:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a7aabe8e04309586ecb93fc6d2fe931c0473672a', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 10, 'created': '2019-02-06 09:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/3d9a2d00936b8bdebc3f321b1c080487d3d2ff9d', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 11, 'created': '2019-02-06 10:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/48915c2862ce720fbd6b4065e69cd5b2242d54d4', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 12, 'created': '2019-02-06 15:41:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/6fb22b2a5b6e3e6c789ecb2dfaffce87082eb2e1', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 13, 'created': '2019-02-06 15:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/2f44cf7162908a7f501be0c37c02cc92d3008777', 'message': 'WIP: add a new service list api\n\n\nStory: 2004897\nTask: 29204\nTask: 29207\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 14, 'created': '2019-02-07 07:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/22cf61c6d9cbfb7a234a331e6dedc74c3a20323d', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 15, 'created': '2019-02-07 13:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/5c885764e9d9d31372d3496f577e6765c2a52c55', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On:  I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 16, 'created': '2019-02-07 13:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/8023b56b819d58816552a247911a933ec8d35df5', 'message': 'WIP: add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On:  I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 17, 'created': '2019-02-07 13:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/29c8b223d1c827fb937a0318d5672f0772809ce3', 'message': 'WIP: add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 18, 'created': '2019-02-10 12:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/13b09752379b2e868ef46da993612956eb0829b4', 'message': 'add a new service list api\n\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 19, 'created': '2019-02-10 12:26:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/138ede616e534a5252472ae61f270c3f5d73b888', 'message': 'WIP: add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 20, 'created': '2019-02-10 12:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/272a1f72860f33a11b35f1f2e3f86014ea638038', 'message': 'WIP: add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 21, 'created': '2019-02-11 07:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/64d6974d57a9126016154396613c98c64900ba7e', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 22, 'created': '2019-02-11 12:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/4f98878bb2ceb726f0dbcb82f59aded5bc845434', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 23, 'created': '2019-02-11 13:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/83fa607d8fc9440a68a7ee7af868d4a003f50b31', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 24, 'created': '2019-02-11 14:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/8777fa114d0790d88f85704864fd924a8754b038', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}, {'number': 25, 'created': '2019-02-12 07:11:45.000000000', 'files': ['vitrage/coordination/__init__.py', 'test-requirements.txt', 'vitrage/tests/unit/datasources/prometheus/test_prometheus_driver.py', 'vitrage/tests/functional/api/v1/test_service.py', 'vitrage/machine_learning/service.py', 'vitrage/tests/functional/api/v1/test_keycloak.py', 'vitrage/snmp_parsing/service.py', 'requirements.txt', 'vitrage/tests/functional/api/v1/test_basic.py', 'vitrage/common/policies/service.py', 'vitrage/api/app.py', 'openstack-common.conf', 'vitrage/opts.py', 'vitrage/tests/unit/snmp_parsing/test_snmp_parsing.py', 'doc/source/contributor/vitrage-api.rst', 'vitrage/entity_graph/workers.py', 'vitrage/coordination/service.py', 'releasenotes/notes/add_service_list-d8e28adabc26f1cf.yaml', 'vitrage/api/hooks.py', 'devstack/plugin.sh', 'lower-constraints.txt', 'vitrage/notifier/service.py', 'vitrage/api/controllers/v1/service.py', 'vitrage/common/policies/__init__.py', 'vitrage/persistency/service.py', 'vitrage/api/controllers/v1/root.py', 'vitrage/coordination/coordination.py', 'vitrage/tests/functional/api/v1/test_auth.py', 'vitrage/tests/functional/api/v1/test_noauth.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/12f70b9ada4234b19245898932bd5cfba17184b0', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29204\nTask: 29207\nDepends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6\nChange-Id: I494e5749adc1d3845f793a941f970a944457d992\n'}]",14,634607,12f70b9ada4234b19245898932bd5cfba17184b0,83,5,25,19134,,,0,"add a new service list api

Story: 2004897
Task: 29204
Task: 29207
Depends-On: I2996afcd4f05c87847db1f9be64a362a2593f5b6
Change-Id: I494e5749adc1d3845f793a941f970a944457d992
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/07/634607/14 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/common/policies/__init__.py', 'vitrage/coordination/__init__.py', 'vitrage/api/controllers/v1/root.py', 'vitrage/common/policies/service.py', 'vitrage/coordination/coordination.py', 'vitrage/api/app.py', 'vitrage/tests/functional/api/v1/test_service.py', 'openstack-common.conf', 'vitrage/api/hooks.py', 'vitrage/api/controllers/v1/service.py']",10,e0ea64d0659252735076ac0d053996ff1d18b066,eyalb/services,"# Copyright 2019 - Nokia Corporation # # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # # http://www.apache.org/licenses/LICENSE-2.0 # # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import pecan from oslo_log import log from pecan.core import abort from vitrage.api.policy import enforce LOG = log.getLogger(__name__) # noinspection PyBroadException class ServiceController(object): @pecan.expose('json') def index(self): return self.get() @pecan.expose('json') def get(self): enforce(""get service list"", pecan.request.headers, pecan.request.enforcer, {}) LOG.info('received get service list') try: return pecan.request.coordinator.get_services() except Exception: LOG.exception('failed to get service list.') abort(404, 'Failed to get service list.') ",,143,8
openstack%2Ftripleo-ci~master~I58917eb84217958afd5cba1fa77ce0032aac4255,openstack/tripleo-ci,master,I58917eb84217958afd5cba1fa77ce0032aac4255,add 1.1.1.1 to multinode dns,MERGED,2019-02-10 23:42:43.000000000,2019-02-12 15:48:23.000000000,2019-02-12 15:48:23.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-10 23:42:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2ee8b098654e10c4ae615dea0efdd73efbf246d5', 'message': 'WIP: add 1.1.1.1 to multinode dns\n\nChange-Id: I58917eb84217958afd5cba1fa77ce0032aac4255\n'}, {'number': 2, 'created': '2019-02-11 13:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e13fd97f3735a35ed3c86495276da5624504504d', 'message': 'add 1.1.1.1 to multinode dns\n\nThis using just 127.0.0.1 seems to work just fine\nin upstream and rdo jobs w/ unbound.  When users need\nto replicate the job in their own infra they may run\ninto issues.\n\nThe standalone jobs update the dns server as part\nof the standalone deployment.  Add a redundant dns\nserver is the only way to ensure both upstream and private\nworkflows will work consistently. \n\nChange-Id: I58917eb84217958afd5cba1fa77ce0032aac4255\n'}, {'number': 3, 'created': '2019-02-11 17:09:58.000000000', 'files': ['toci-quickstart/config/testenv/multinode.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/eab4a7b7c5983cba940643300f392ff23ea7ba42', 'message': 'add 1.1.1.1 to multinode dns\n\nThis using just 127.0.0.1 seems to work just fine\nin upstream and rdo jobs w/ unbound.  When users need\nto replicate the job in their own infra they may run\ninto issues.\n\nThe standalone jobs update the dns server as part\nof the standalone deployment.  Add a redundant dns\nserver is the only way to ensure both upstream and private\nworkflows will work consistently. \n\nRelated-Review that introduced unbound and localhost\nhttps://review.openstack.org/#/c/494545/\n\nIn the case of local reproducers using libvirt the \nimage does NOT have unbound cache.\n\nChange-Id: I58917eb84217958afd5cba1fa77ce0032aac4255\n'}]",0,636073,eab4a7b7c5983cba940643300f392ff23ea7ba42,17,5,3,9592,,,0,"add 1.1.1.1 to multinode dns

This using just 127.0.0.1 seems to work just fine
in upstream and rdo jobs w/ unbound.  When users need
to replicate the job in their own infra they may run
into issues.

The standalone jobs update the dns server as part
of the standalone deployment.  Add a redundant dns
server is the only way to ensure both upstream and private
workflows will work consistently. 

Related-Review that introduced unbound and localhost
https://review.openstack.org/#/c/494545/

In the case of local reproducers using libvirt the 
image does NOT have unbound cache.

Change-Id: I58917eb84217958afd5cba1fa77ce0032aac4255
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/73/636073/3 && git format-patch -1 --stdout FETCH_HEAD,['toci-quickstart/config/testenv/multinode.yml'],1,2ee8b098654e10c4ae615dea0efdd73efbf246d5,, - 1.1.1.1,,1,0
openstack%2Fpuppet-nova~master~Iddba31b559f6d30052b827967de33e0c9003b6b9,openstack/puppet-nova,master,Iddba31b559f6d30052b827967de33e0c9003b6b9,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:22:02.000000000,2019-02-12 15:44:38.000000000,2019-02-12 15:44:38.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:22:02.000000000', 'files': ['metadata.json', 'manifests/db/mysql_placement.pp', 'releasenotes/notes/puppet4-mysql-func-cb910313316f65ed.yaml', 'manifests/db/mysql_api.pp', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/23dc492a940209ee17397fd9eee2445bb9a9d7eb', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Iddba31b559f6d30052b827967de33e0c9003b6b9\n'}]",0,635803,23dc492a940209ee17397fd9eee2445bb9a9d7eb,15,5,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Iddba31b559f6d30052b827967de33e0c9003b6b9
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/03/635803/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/db/mysql_placement.pp', 'releasenotes/notes/puppet4-mysql-func-cb910313316f65ed.yaml', 'manifests/db/mysql_api.pp', 'manifests/db/mysql.pp']",5,23dc492a940209ee17397fd9eee2445bb9a9d7eb,mysql-func," password_hash => mysql::password($password), password_hash => mysql::password($password),"," password_hash => mysql_password($password), password_hash => mysql_password($password),",12,4
openstack%2Fpuppet-openstack-integration~master~Ic0090a9950552c33a79018ebf40a2c0d0260c667,openstack/puppet-openstack-integration,master,Ic0090a9950552c33a79018ebf40a2c0d0260c667,Install libibverbs,MERGED,2018-12-11 11:52:36.000000000,2019-02-12 15:41:38.000000000,2018-12-12 16:39:01.000000000,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-12-11 11:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/79e830f94a68a597964eaa2a8c1bd7dfa9ef9661', 'message': 'Install libiverbs\n\nNeeded to fix the beaker tests issue where the\nOVS output shows errors.\n\nChange-Id: Ic0090a9950552c33a79018ebf40a2c0d0260c667\n'}, {'number': 2, 'created': '2018-12-11 14:26:42.000000000', 'files': ['manifests/repos.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/e375da24b9bfa1fe073a4bd1b309edc570902e4f', 'message': 'Install libibverbs\n\nNeeded to fix the beaker tests issue where the\nOVS output shows errors. See comment in code\nfor more details.\n\nReported upstream:\nhttps://bugzilla.redhat.com/show_bug.cgi?id=1658141\n\nChange-Id: Ic0090a9950552c33a79018ebf40a2c0d0260c667\n'}]",1,624368,e375da24b9bfa1fe073a4bd1b309edc570902e4f,15,5,2,16137,,,0,"Install libibverbs

Needed to fix the beaker tests issue where the
OVS output shows errors. See comment in code
for more details.

Reported upstream:
https://bugzilla.redhat.com/show_bug.cgi?id=1658141

Change-Id: Ic0090a9950552c33a79018ebf40a2c0d0260c667
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/68/624368/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/repos.pp'],1,79e830f94a68a597964eaa2a8c1bd7dfa9ef9661,ovs-fix," if $::osfamily == 'RedHat' { # NOTE(tobias-urdin): The python-requests RPM package has a package dependency # which upstream requests package does not support so it outputs a warning which # messes up output (warning is printed to stdout) an causes some providers that # rely on the stdout output to fail. If you upgrade the python-chardet dependency # to a newer version you are fine, is reported upstream: # https://bugzilla.redhat.com/show_bug.cgi?id=1620221 # This is added here so we have the latest of this package in both integration and # beaker testing. # NOTE(tobias-urdin): Install libiverbs to fix an issue where OVS outputs errors # that causes the puppet-openvswitch module to fail parsing the output. # Reported upstream: https://bugzilla.redhat.com/show_bug.cgi?id=1658141 package { 'libiverbs': ensure => 'present', }"," # NOTE(tobias-urdin): The python-requests RPM package has a package dependency # which upstream requests package does not support so it outputs a warning which # messes up output (warning is printed to stdout) an causes some providers that # rely on the stdout output to fail. If you upgrade the python-chardet dependency # to a newer version you are fine, is reported upstream: # https://bugzilla.redhat.com/show_bug.cgi?id=1620221 # This is added here so we have the latest of this package in both integration and # beaker testing. if $::osfamily == 'RedHat' {",15,8
openstack%2Ftripleo-heat-templates~master~I98bb38078be84cbda3e9a9e338af0d054dc53420,openstack/tripleo-heat-templates,master,I98bb38078be84cbda3e9a9e338af0d054dc53420,Make ceph-ansible working dir owned by tripleo-admin,MERGED,2019-02-11 04:33:36.000000000,2019-02-12 15:39:19.000000000,2019-02-12 15:39:19.000000000,"[{'_account_id': 4571}, {'_account_id': 6796}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-11 04:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/02eea7d74faa1fdc6ce6320e2cc820252cfa15b0', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\nRelated-Bug: #1813832\n""}, {'number': 2, 'created': '2019-02-11 09:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1f6faf36626a5e0cd9cd0c3850b1919cc46b9c9', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\nRelated-Bug: #1813832\n""}, {'number': 3, 'created': '2019-02-11 12:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2daa9fae85bd054cd744c42e7c3fc5660d8d055f', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\nRelated-Bug: #1813832\n""}, {'number': 4, 'created': '2019-02-11 15:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d2cbe7e64337b97a6d7e5827792b306cf5cd6fd9', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\nRelated-Bug: #1813832\n""}, {'number': 5, 'created': '2019-02-11 20:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc075f2147b855b860b10bb7675ac0981e0627fe', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\nRelated-Bug: #1813832\n""}, {'number': 6, 'created': '2019-02-11 22:40:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ab3ba3fb74838fbf6bc122308a06cf292f59dc8e', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nRelated-Bug: #1813832\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\n""}, {'number': 7, 'created': '2019-02-11 22:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3f5a624ca7fa3e712e8b33eb83d6a4fc0df9f322', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nRelated-Bug: #1813832\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\n""}, {'number': 8, 'created': '2019-02-12 03:43:49.000000000', 'files': ['extraconfig/services/kubernetes-master.yaml', 'zuul.d/layout.yaml', 'docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5ceb3c5ec7d3e2100fc74e86660c59b090e41d31', 'message': ""Make ceph-ansible working dir owned by tripleo-admin\n\nThe ceph-ansible tasks are now invoked with the tripleo-admin user,\nwhich doesn't by default have write access to /var/lib/mistral, but it\ndoes have sudo access.\n\nThis change makes /var/lib/mistral/overcloud/ceph-ansible be owned by\nthe tripleo-admin user so that subsequent tasks can write to that\ndirectory.\n\nRelated-Bug: #1813832\nChange-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420\n""}]",13,636086,5ceb3c5ec7d3e2100fc74e86660c59b090e41d31,37,9,8,4571,,,0,"Make ceph-ansible working dir owned by tripleo-admin

The ceph-ansible tasks are now invoked with the tripleo-admin user,
which doesn't by default have write access to /var/lib/mistral, but it
does have sudo access.

This change makes /var/lib/mistral/overcloud/ceph-ansible be owned by
the tripleo-admin user so that subsequent tasks can write to that
directory.

Related-Bug: #1813832
Change-Id: I98bb38078be84cbda3e9a9e338af0d054dc53420
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/86/636086/8 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,02eea7d74faa1fdc6ce6320e2cc820252cfa15b0,bug/1813832," - name: set current_user set_fact: current_user: ""{{ lookup('env', 'USER') }}"" - name: create ceph-ansible working directory become: true file: path: ""{{playbook_dir}}/ceph-ansible"" state: directory owner: ""{{ current_user }}""",,9,0
openstack%2Fdragonflow~master~I13e88997f6043162c5feeaa339820f4efa37ee03,openstack/dragonflow,master,I13e88997f6043162c5feeaa339820f4efa37ee03,stop using common db mixin,MERGED,2019-02-11 15:30:14.000000000,2019-02-12 15:37:14.000000000,2019-02-12 15:37:14.000000000,"[{'_account_id': 17880}, {'_account_id': 20229}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 15:30:14.000000000', 'files': ['dragonflow/neutron/services/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5bb32a58aeff2473864d7b894e550ee05f6ef242', 'message': ""stop using common db mixin\n\nAll of the methods of common db mixin are available via neutron-lib\nand the mixin will be removed before long.\nThis patch switches the code over to use neutron-lib's APIs rather\nthan those of the mixin and stops using common_db_mix for parent\nclasses.\n\nChange-Id: I13e88997f6043162c5feeaa339820f4efa37ee03\n""}]",0,636153,5bb32a58aeff2473864d7b894e550ee05f6ef242,7,3,1,5367,,,0,"stop using common db mixin

All of the methods of common db mixin are available via neutron-lib
and the mixin will be removed before long.
This patch switches the code over to use neutron-lib's APIs rather
than those of the mixin and stops using common_db_mix for parent
classes.

Change-Id: I13e88997f6043162c5feeaa339820f4efa37ee03
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/53/636153/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/services/l3_router_plugin.py'],1,5bb32a58aeff2473864d7b894e550ee05f6ef242,bp/neutronlib-decouple-db,,"from neutron.db import common_db_mixin common_db_mixin.CommonDbMixin,",0,2
openstack%2Fopenstack-ansible-plugins~master~I3a7d8c0c248febc4223029e076062ca68312b104,openstack/openstack-ansible-plugins,master,I3a7d8c0c248febc4223029e076062ca68312b104,Remove the config_template module,MERGED,2019-02-08 13:31:43.000000000,2019-02-12 15:36:41.000000000,2019-02-12 15:36:41.000000000,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-08 13:31:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/9f14beb24934e7f13c00017b8a65aa6629fcc239', 'message': 'Remove the config_template module\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nRelated-Bug: 1791258\nChange-Id: I3a7d8c0c248febc4223029e076062ca68312b104\n'}, {'number': 2, 'created': '2019-02-08 13:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/edcb719179a999b07fbf5e4c5871ebdc1ec62825', 'message': 'Remove the config_template module\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nRelated-Bug: 1791258\nDepends-On: https://review.openstack.org/635841\nChange-Id: I3a7d8c0c248febc4223029e076062ca68312b104\n'}, {'number': 3, 'created': '2019-02-11 16:44:50.000000000', 'files': ['releasenotes/notes/config-template-move-a0f08aff8e54f62f.yaml', 'library/config_template', 'action/config_template.py', 'doc/source/actions/config_template.rst', 'tests/test.yml', 'tox.ini', 'tests/test-config_template.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/b28590f5bd683d71446f30d0994db839e289cafe', 'message': 'Remove the config_template module\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nAs part of this, we now need to remove the environment settings given\nto ansible so that the common tests repo settings in ansible.cfg take\neffect.\n\nRelated-Bug: 1791258\nDepends-On: https://review.openstack.org/635841\nChange-Id: I3a7d8c0c248febc4223029e076062ca68312b104\n'}]",0,635838,b28590f5bd683d71446f30d0994db839e289cafe,15,4,3,6816,,,0,"Remove the config_template module

The config_template action module has now been moved into its own git
repository (openstack/ansible-config_template). This has been done to
simplify the ability to use the plugin in other non OpenStack-Ansible
projects.

As part of this, we now need to remove the environment settings given
to ansible so that the common tests repo settings in ansible.cfg take
effect.

Related-Bug: 1791258
Depends-On: https://review.openstack.org/635841
Change-Id: I3a7d8c0c248febc4223029e076062ca68312b104
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/38/635838/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/config-template-move-a0f08aff8e54f62f.yaml', 'library/config_template', 'action/config_template.py', 'doc/source/actions/config_template.rst', 'tests/test.yml', 'tests/test-config_template.yml']",6,9f14beb24934e7f13c00017b8a65aa6629fcc239,bug/1791258,,"--- # Copyright 2016, Comcast Corp. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Test config_template hosts: localhost connection: local gather_facts: yes tasks: # Test basic function of config_template - name: Template test INI template config_template: src: ""{{ playbook_dir }}/templates/test.ini"" dest: ""/tmp/test.ini"" config_overrides: ""{{ test_config_ini_overrides }}"" config_type: ""ini"" - name: Read test.ini slurp: src: /tmp/test.ini register: ini_file - debug: msg: ""ini - {{ ini_file.content | b64decode }}"" - name: Validate output assert: that: - ""(lookup('ini', 'new_key section=DEFAULT file=/tmp/test.ini')) == 'new_value'"" - ""(lookup('ini', 'baz section=foo file=/tmp/test.ini')) == 'bar'"" # Test basic function of config_template with content instead of src - name: Template test INI template config_template: content: ""{{ lookup('file', playbook_dir + '/templates/test.ini') }}"" dest: ""/tmp/test_with_content.ini"" config_overrides: ""{{ test_config_ini_overrides }}"" config_type: ""ini"" - name: Read test.ini slurp: src: /tmp/test_with_content.ini register: ini_file_with_content - debug: msg: ""ini - {{ ini_file_with_content.content | b64decode }}"" - name: Validate output assert: that: - ""(lookup('ini', 'new_key section=DEFAULT file=/tmp/test_with_content.ini')) == 'new_value'"" - ""(lookup('ini', 'baz section=foo file=/tmp/test_with_content.ini')) == 'bar'"" # Test list additions in config_template - name: Template test YML template config_template: src: ""{{ playbook_dir }}/templates/test.yml"" dest: ""/tmp/test_extend.yml"" config_overrides: ""{{ test_config_yml_overrides }}"" config_type: ""yaml"" list_extend: True - name: Read test_extend.yml slurp: src: /tmp/test_extend.yml register: extend_file - name: Read expected test_extend.yml slurp: src: ""{{ playbook_dir }}/files/test_extend.yml.expected"" register: extend_file_expected - debug: msg: ""extend - {{ extend_file.content | b64decode }}"" - debug: msg: ""extend.expected - {{ extend_file_expected.content | b64decode }}"" - name: Compare files assert: that: - ""(extend_file.content | b64decode) == (extend_file_expected.content | b64decode)"" # Test list replacement in config_template - name: Template test YML template config_template: src: ""{{ playbook_dir }}/templates/test.yml"" dest: ""/tmp/test_no_extend.yml"" config_overrides: ""{{ test_config_yml_overrides }}"" config_type: ""yaml"" list_extend: False - name: Read test_no_extend.yml slurp: src: /tmp/test_no_extend.yml register: no_extend_file - name: Read expected test_no_extend.yml slurp: src: ""{{ playbook_dir }}/files/test_no_extend.yml.expected"" register: no_extend_file_expected - debug: msg: ""no_extend - {{ no_extend_file.content | b64decode }}"" - debug: msg: ""no_extend.expected - {{ no_extend_file_expected.content | b64decode }}"" - name: Compare files assert: that: - ""(no_extend_file.content | b64decode) == (no_extend_file_expected.content | b64decode)"" # Test dumping hostvars using config overrides - name: Template test YML template with hostvars override config_template: src: ""{{ playbook_dir }}/templates/test.yml"" dest: ""/tmp/test_hostvars.yml"" config_overrides: ""{{ test_config_yml_hostvars_overrides }}"" config_type: ""yaml"" - name: Read test_hostvars.yml slurp: src: /tmp/test_hostvars.yml register: hostvars_file - debug: msg: ""hostvars - {{ (hostvars_file.content | b64decode | from_yaml).test_hostvar }}"" - debug: msg: ""hostvars.expected - {{ test_config_yml_hostvars_overrides.test_hostvar }}"" - name: Compare files assert: that: - ""((hostvars_file.content | b64decode | from_yaml).test_hostvar) == (test_config_yml_hostvars_overrides.test_hostvar)"" # Test multistropt ordering - name: Template MultiStrOpts using overrides config_template: src: test_multistropts.ini dest: /tmp/test_multistropts.ini config_overrides: testsection: test: output config_type: ini - name: Read test_multistropts.ini slurp: src: /tmp/test_multistropts.ini register: multistropts_file - name: Read test_multistropts.ini.expected slurp: src: files/test_multistropts.ini.expected register: multistropts_expected_file - debug: msg: ""multistropts rendered - {{ multistropts_file.content | b64decode }}"" - debug: msg: ""multistropts expected - {{ multistropts_expected_file.content | b64decode }}"" - name: Compare files assert: that: - ""multistropts_file.content == multistropts_expected_file.content"" # Test content attribute with a dictionary input and config_type equal to 'json' - name: Template test JSON template with content attribute config_template: dest: ""/tmp/test_content_no_overrides.json"" config_overrides: {} config_type: ""json"" content: ""{{ lookup('file', playbook_dir ~ '/templates/test.json') | from_json }}"" - name: Read test_content_no_overrides.json slurp: src: /tmp/test_content_no_overrides.json register: content_no_overrides_file - name: Read expected test_content_no_overrides.json slurp: src: ""{{ playbook_dir }}/files/test_content_no_overrides.json.expected"" register: content_no_overrides_file_expected - debug: msg: ""content_no_overrides.json - {{ content_no_overrides_file.content | b64decode | from_json }}"" - debug: msg: ""content_no_overrides.json.expected - {{ content_no_overrides_file_expected.content | b64decode | from_json }}"" # NOTE (alextricity25): The config_template module doesn't use ordered dicts when reading and writing json # data, so we can't guarantee that the string literal of both file's content will be the same. Instead, we compare # the content after transforming it into a dictionary. - name: Compare file content assert: that: - ""(content_no_overrides_file.content | b64decode | from_json) == (content_no_overrides_file_expected.content | b64decode | from_json)"" # Test the ignore_none_type attribute when set to False - name: Template test with ignore_none_type set to false config_template: src: ""{{ playbook_dir }}/templates/test_ignore_none_type.ini"" dest: ""/tmp/test_ignore_none_type.ini"" config_overrides: ""{{ test_config_ini_overrides }}"" config_type: ""ini"" ignore_none_type: False - name: Read test_ignore_none_type.ini slurp: src: /tmp/test_ignore_none_type.ini register: test_ignore_none_type - debug: msg: ""test_ignore_none_type.ini - {{ test_ignore_none_type.content | b64decode }}"" - name: Validate output has valueless options printed out assert: that: - ""{{ test_ignore_none_type.content | b64decode | search('(?m)^india$') }}"" - ""{{ test_ignore_none_type.content | b64decode | search('(?m)^juliett kilo$') }}"" # Test basic function of config_template - name: Template test INI comments config_template: src: ""{{ playbook_dir }}/templates/test_with_comments.ini"" dest: ""/tmp/test_with_comments.ini"" config_overrides: ""{{ test_config_ini_overrides }}"" config_type: ""ini"" tags: test - name: Read test.ini slurp: src: /tmp/test_with_comments.ini register: ini_file tags: test - debug: msg: ""ini - {{ ini_file.content | b64decode }}"" - name: Validate output tags: test assert: that: - ""(lookup('ini', 'new_key section=DEFAULT file=/tmp/test_with_comments.ini')) == 'new_value'"" - ""(lookup('ini', 'baz section=foo file=/tmp/test_with_comments.ini')) == 'bar'"" - ""{{ ini_file.content | b64decode | search('#This is a comment')}}"" - ""{{ ini_file.content | b64decode | search('# A default section comment\n# broken into multiple lines\n\\[DEFAULT\\]')}}"" - name: Template multiple times to assert no changes config_template: src: ""{{ playbook_dir }}/templates/test_with_comments.ini"" dest: ""/tmp/test_with_comments.ini"" config_type: ""ini"" config_overrides: ""{{ item[1] }}"" register: template_changed failed_when: template_changed is changed with_nested: - [ 0, 1, 2 ] - [ ""{{ test_config_ini_overrides }}"" ] vars: test_config_ini_overrides: DEFAULT: new_key: ""new_value"" foo: baz: ""bar"" section1: key1: ""value1"" key2: ""value2"" key3: ""value3"" key4: ""value4"" key5: ""value5"" key6: ""value6"" key7: ""value7"" key8: ""value8"" key9: ""value9"" key10: ""value10"" key11: ""value11"" section2: key1: ""value1"" section3: key1: ""value1"" section4: key1: ""value1"" section5: key1: ""value1"" section6: key1: ""value1"" section7: key1: ""value1"" section8: key1: ""value1"" section9: key1: ""value1"" section10: key1: ""value1"" section11: key1: ""value1"" test_config_yml_overrides: list_one: - four test_config_yml_hostvars_overrides: test_hostvar: ""{{ ansible_default_ipv4.address }}"" ",7,1066
openstack%2Fopenstack-zuul-jobs~master~I6105e584aee852672b96bd2b3ad4424a6d332e76,openstack/openstack-zuul-jobs,master,I6105e584aee852672b96bd2b3ad4424a6d332e76,Replace deprecated docs job in docs-on-readthedocs template,MERGED,2019-02-07 01:19:22.000000000,2019-02-12 15:16:46.000000000,2019-02-12 15:16:46.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7118}, {'_account_id': 22348}, {'_account_id': 28208}]","[{'number': 1, 'created': '2019-02-07 01:19:22.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/ce022af9c0ff748ae709b4b952aebda9ef2403e0', 'message': 'Replace deprecated docs job in docs-on-readthedocs template\n\nChange docs-on-readthedocs project template from using deprecated\nbuild-openstack-sphinx-docs job for check and gate to openstack-tox-docs\njob.\n\nChange-Id: I6105e584aee852672b96bd2b3ad4424a6d332e76\n'}]",0,635381,ce022af9c0ff748ae709b4b952aebda9ef2403e0,8,6,1,28208,,,0,"Replace deprecated docs job in docs-on-readthedocs template

Change docs-on-readthedocs project template from using deprecated
build-openstack-sphinx-docs job for check and gate to openstack-tox-docs
job.

Change-Id: I6105e584aee852672b96bd2b3ad4424a6d332e76
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/81/635381/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,ce022af9c0ff748ae709b4b952aebda9ef2403e0,docsCheckJob, - openstack-tox-docs - openstack-tox-docs, - build-openstack-sphinx-docs - build-openstack-sphinx-docs,2,2
openstack%2Fopenstack-zuul-jobs~master~Ie52d2793779a858d9b848127d479756dab245e6a,openstack/openstack-zuul-jobs,master,Ie52d2793779a858d9b848127d479756dab245e6a,Add opendev/base-jobs to openstack-zuul-linters,MERGED,2019-02-12 07:13:06.000000000,2019-02-12 15:16:45.000000000,2019-02-12 15:16:45.000000000,"[{'_account_id': 4146}, {'_account_id': 7069}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 07:13:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/68e162e99783eec6ef19c66fe35af3414a7f8e6f', 'message': 'Add opendev/base-jobs to openstack-zuul-linters\n\nAdd the new opendev/base-jobs repos to the linters so that we include\nit in our tests of playbooks and roles.\n\nChange-Id: Ie52d2793779a858d9b848127d479756dab245e6a\n'}, {'number': 2, 'created': '2019-02-12 09:32:48.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/27eaa275d5aeb3313e4f727bf940e935e280cbe3', 'message': 'Add opendev/base-jobs to openstack-zuul-linters\n\nAdd the new opendev/base-jobs repos to the linters so that we include\nit in our tests of playbooks and roles.\n\nChange-Id: Ie52d2793779a858d9b848127d479756dab245e6a\n'}]",1,636274,27eaa275d5aeb3313e4f727bf940e935e280cbe3,10,4,2,6547,,,0,"Add opendev/base-jobs to openstack-zuul-linters

Add the new opendev/base-jobs repos to the linters so that we include
it in our tests of playbooks and roles.

Change-Id: Ie52d2793779a858d9b848127d479756dab245e6a
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/74/636274/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,68e162e99783eec6ef19c66fe35af3414a7f8e6f,fix-opendev," This job runs against base-job, project-config, openstack-zuul-jobs and zuul-jobs so we can properly lint our ansible playbooks / roles. required-projects: - opendev/base-jobs ANSIBLE_ROLES_PATH: ~/src/git.openstack.org/opendev/base-jobs/roles:~/src/git.openstack.org/openstack-infra/zuul-jobs/roles:~/src/git.openstack.org/openstack-infra/openstack-zuul-jobs/roles:~/src/git.openstack.org/openstack-infra/project-config/roles:~/src/git.openstack.org/openstack-infra/system-config/roles"," This job runs against project-config, openstack-zuul-jobs and zuul-jobs so we can properly lint our ansible playbooks / roles required-projects: ANSIBLE_ROLES_PATH: ~/src/git.openstack.org/openstack-infra/zuul-jobs/roles:~/src/git.openstack.org/openstack-infra/openstack-zuul-jobs/roles:~/src/git.openstack.org/openstack-infra/project-config/roles:~/src/git.openstack.org/openstack-infra/system-config/roles",4,3
openstack%2Fopenstack-ansible~master~I5cf97d964a162d6406501b941c08ae7dfb134e09,openstack/openstack-ansible,master,I5cf97d964a162d6406501b941c08ae7dfb134e09,nspawn: use correct network range for tempest,MERGED,2019-02-05 22:14:00.000000000,2019-02-12 15:11:54.000000000,2019-02-12 15:11:54.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-05 22:14:00.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bae0da54adae5f077b49464e224f7cc3ae5de948', 'message': 'nspawn: use correct network range for tempest\n\nThe network range used for the flat network is incorrect and it leads\nto an unreachable scenario.  This patch fixes it and a follow-up patch\nwill converge both configs in the future.\n\nChange-Id: I5cf97d964a162d6406501b941c08ae7dfb134e09\n'}]",0,635059,bae0da54adae5f077b49464e224f7cc3ae5de948,16,4,1,1004,,,0,"nspawn: use correct network range for tempest

The network range used for the flat network is incorrect and it leads
to an unreachable scenario.  This patch fixes it and a follow-up patch
will converge both configs in the future.

Change-Id: I5cf97d964a162d6406501b941c08ae7dfb134e09
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/59/635059/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2'],1,bae0da54adae5f077b49464e224f7cc3ae5de948,nspawn,"tempest_public_subnet_cidr: ""172.29.240.0/22"" tempest_public_subnet_allocation_pools: ""172.29.243.110-172.29.243.200""","tempest_public_subnet_cidr: ""172.29.236.0/22"" tempest_public_subnet_allocation_pools: ""172.29.239.110-172.29.239.200""",2,2
openstack%2Fpython-tripleoclient~master~Icf672cc0db50ea6daa57d3c5abe131c82553fc5a,openstack/python-tripleoclient,master,Icf672cc0db50ea6daa57d3c5abe131c82553fc5a,Support '--tags' for 'overcloud upgrade run',MERGED,2019-01-15 13:04:15.000000000,2019-02-12 15:05:10.000000000,2019-02-12 15:05:10.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11082}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-01-15 13:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ffc535c5a44cfa3f14cb9340f957b6e5a4eb88de', 'message': ""Support '--tags' for 'overcloud upgrade run'\n\nThis will allow more specialized usage of upgrade run command, similar\nto patterns used with 'external-upgrade run', e.g. during\nreprovisioning of nodes.\n\nAlso, validation on '--skip-tags' is removed because we should no\nlonger assume what tags are defined by the upgrade tasks, and we\nshould allow more free-form usage.\n\nChange-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a\nImplements: blueprint upgrades-with-os\n""}, {'number': 2, 'created': '2019-01-21 13:53:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e9bd3d0d9a178e6fd03e5832f5c42e5b414c33df', 'message': ""Support '--tags' for 'overcloud upgrade run'\n\nThis will allow more specialized usage of upgrade run command, similar\nto patterns used with 'external-upgrade run', e.g. during\nreprovisioning of nodes.\n\nAlso, validation on '--skip-tags' is removed because we should no\nlonger assume what tags are defined by the upgrade tasks, and we\nshould allow more free-form usage.\n\nChange-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a\nImplements: blueprint upgrades-with-os\n""}, {'number': 3, 'created': '2019-02-06 13:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d3dc902cb552976c6730013c94cee8b9d0daf72a', 'message': ""Support '--tags' for 'overcloud upgrade run'\n\nThis will allow more specialized usage of upgrade run command, similar\nto patterns used with 'external-upgrade run', e.g. during\nreprovisioning of nodes.\n\nAlso, validation on '--skip-tags' is removed because we should no\nlonger assume what tags are defined by the upgrade tasks, and we\nshould allow more free-form usage.\n\nChange-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a\nImplements: blueprint upgrades-with-os\n""}, {'number': 4, 'created': '2019-02-08 15:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/368cd1d80f11e98e588eababed41311c093cd27a', 'message': ""Support '--tags' for 'overcloud upgrade run'\n\nThis will allow more specialized usage of upgrade run command, similar\nto patterns used with 'external-upgrade run', e.g. during\nreprovisioning of nodes.\n\nAlso, validation on '--skip-tags' is removed because we should no\nlonger assume what tags are defined by the upgrade tasks, and we\nshould allow more free-form usage.\n\nChange-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a\nImplements: blueprint upgrades-with-os\n""}, {'number': 5, 'created': '2019-02-08 16:11:42.000000000', 'files': ['tripleoclient/v1/overcloud_upgrade.py', 'tripleoclient/tests/v1/overcloud_upgrade/test_overcloud_upgrade.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/78bf55c8efe9156c52b5ed88659b3c28afd8a8f5', 'message': ""Support '--tags' for 'overcloud upgrade run'\n\nThis will allow more specialized usage of upgrade run command, similar\nto patterns used with 'external-upgrade run', e.g. during\nreprovisioning of nodes.\n\nAlso, validation on '--skip-tags' is removed because we should no\nlonger assume what tags are defined by the upgrade tasks, and we\nshould allow more free-form usage.\n\nChange-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a\nImplements: blueprint upgrades-with-os\n""}]",4,630967,78bf55c8efe9156c52b5ed88659b3c28afd8a8f5,32,7,5,8042,,,0,"Support '--tags' for 'overcloud upgrade run'

This will allow more specialized usage of upgrade run command, similar
to patterns used with 'external-upgrade run', e.g. during
reprovisioning of nodes.

Also, validation on '--skip-tags' is removed because we should no
longer assume what tags are defined by the upgrade tasks, and we
should allow more free-form usage.

Change-Id: Icf672cc0db50ea6daa57d3c5abe131c82553fc5a
Implements: blueprint upgrades-with-os
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/67/630967/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/constants.py', 'tripleoclient/v1/overcloud_upgrade.py', 'tripleoclient/tests/v1/overcloud_upgrade/test_overcloud_upgrade.py']",3,ffc535c5a44cfa3f14cb9340f957b6e5a4eb88de,bp/upgrades-with-os," def test_upgrade_role_all_playbooks_only_validation( self, mock_open, mock_execute, mock_expanduser, upgrade_ansible): mock_expanduser.return_value = '/home/fake/' argslist = ['--roles', 'Compute', '--playbook', 'all', '--tags', 'validation'] verifylist = [ ('roles', 'Compute'), ('static_inventory', None), ('playbook', 'all'), ('tags', 'validation') ] parsed_args = self.check_parser(self.cmd, argslist, verifylist) with mock.patch('os.path.exists') as mock_exists: mock_exists.return_value = True self.cmd.take_action(parsed_args) for book in constants.MAJOR_UPGRADE_PLAYBOOKS: upgrade_ansible.assert_any_call( self.app.client_manager, nodes='Compute', inventory_file=mock_open().read(), playbook=book, ansible_queue_name=constants.UPGRADE_QUEUE, node_user='tripleo-admin', tags='validation', skip_tags='', ) @mock.patch('tripleoclient.workflows.package_update.update_ansible', autospec=True) @mock.patch('os.path.expanduser') @mock.patch('oslo_concurrency.processutils.execute') @mock.patch('six.moves.builtins.open')"," @mock.patch('tripleoclient.workflows.package_update.update_ansible', autospec=True) @mock.patch('os.path.expanduser') @mock.patch('oslo_concurrency.processutils.execute') @mock.patch('six.moves.builtins.open') # it is 'validation' not 'validations' def test_upgrade_skip_tags_validations(self, mock_open, mock_execute, mock_expanduser, upgrade_ansible): mock_expanduser.return_value = '/home/fake/' argslist = ['--nodes', 'overcloud-compute-1', '--skip-tags', 'validations'] verifylist = [ ('nodes', 'overcloud-compute-1'), ('static_inventory', None), ('playbook', 'all'), ('skip_tags', 'validations'), ] parsed_args = self.check_parser(self.cmd, argslist, verifylist) with mock.patch('os.path.exists') as mock_exists: mock_exists.return_value = True self.assertRaises(exceptions.InvalidConfiguration, lambda: self.cmd.take_action(parsed_args)) @mock.patch('tripleoclient.workflows.package_update.update_ansible', autospec=True) @mock.patch('os.path.expanduser') @mock.patch('oslo_concurrency.processutils.execute') @mock.patch('six.moves.builtins.open') # should only support the constants.MAJOR_UPGRADE_SKIP_TAGS def test_upgrade_skip_tags_unsupported_validation_anything_else( self, mock_open, mock_execute, mock_expanduser, upgrade_ansible): mock_expanduser.return_value = '/home/fake/' argslist = ['--nodes', 'overcloud-compute-1', '--skip-tags', 'validation,anything-else'] verifylist = [ ('nodes', 'overcloud-compute-1'), ('static_inventory', None), ('playbook', 'all'), ('skip_tags', 'validation,anything-else'), ] parsed_args = self.check_parser(self.cmd, argslist, verifylist) with mock.patch('os.path.exists') as mock_exists: mock_exists.return_value = True self.assertRaises(exceptions.InvalidConfiguration, lambda: self.cmd.take_action(parsed_args)) @mock.patch('tripleoclient.workflows.package_update.update_ansible', autospec=True) @mock.patch('os.path.expanduser') @mock.patch('oslo_concurrency.processutils.execute') @mock.patch('six.moves.builtins.open') # should only support the constants.MAJOR_UPGRADE_SKIP_TAGS def test_upgrade_skip_tags_unsupported_pre_upgrade_anything_else( self, mock_open, mock_execute, mock_expanduser, upgrade_ansible): mock_expanduser.return_value = '/home/fake/' argslist = ['--nodes', 'overcloud-compute-1', '--skip-tags', 'pre-upgrade,anything-else'] verifylist = [ ('nodes', 'overcloud-compute-1'), ('static_inventory', None), ('playbook', 'all'), ('skip_tags', 'pre-upgrade,anything-else'), ] parsed_args = self.check_parser(self.cmd, argslist, verifylist) with mock.patch('os.path.exists') as mock_exists: mock_exists.return_value = True self.assertRaises(exceptions.InvalidConfiguration, lambda: self.cmd.take_action(parsed_args))",44,90
openstack%2Fcharm-tempest~master~I3f87ddc8df76631655ad00956d57c856efdeeaab,openstack/charm-tempest,master,I3f87ddc8df76631655ad00956d57c856efdeeaab,Remove deprecated functional test targets,ABANDONED,2018-05-09 21:38:14.000000000,2019-02-12 15:00:02.000000000,,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-09 21:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-tempest/commit/417b9fa85d2a37a0c59fee24ab01eef0a12566b7', 'message': 'Remove deprecated functional test targets\n\nChange-Id: I3f87ddc8df76631655ad00956d57c856efdeeaab\n'}, {'number': 2, 'created': '2019-02-12 14:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-tempest/commit/945d88e4f199957b1b38c010b6e46e9ad6924cdb', 'message': 'Remove deprecated functional test targets\n\nChange-Id: I3f87ddc8df76631655ad00956d57c856efdeeaab\n'}]",0,567426,945d88e4f199957b1b38c010b6e46e9ad6924cdb,9,3,2,20635,,,0,"Remove deprecated functional test targets

Change-Id: I3f87ddc8df76631655ad00956d57c856efdeeaab
",git fetch https://review.opendev.org/openstack/charm-tempest refs/changes/26/567426/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/gate-basic-xenial-newton', 'src/tests/gate-basic-trusty-kilo']",2,417b9fa85d2a37a0c59fee24ab01eef0a12566b7,update-amulet-defs-rm-deprecated,,"#!/usr/bin/env python """"""Amulet tests on a basic tempest deployment on trusty-kilo."""""" from basic_deployment import TempestBasicDeployment if __name__ == '__main__': # Tempest is installed through pip so cloud archive is not needed here deployment = TempestBasicDeployment(series='trusty', openstack='cloud:trusty-kilo', source='cloud:trusty-updates/kilo') deployment.run_tests() ",0,24
openstack%2Fcharm-aodh~master~I83056afccdfceae08bd53705ddac14120b090839,openstack/charm-aodh,master,I83056afccdfceae08bd53705ddac14120b090839,Remove deprecated functional test targets,ABANDONED,2018-05-09 21:32:55.000000000,2019-02-12 14:59:35.000000000,,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-05-09 21:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/2424b40c71f92af63624bdc6692e356fa5fcdec2', 'message': 'Remove deprecated functional test targets\n\nChange-Id: I83056afccdfceae08bd53705ddac14120b090839\n'}, {'number': 2, 'created': '2019-02-12 14:59:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/06795046c34ddefdd7be37e43c658501982a0067', 'message': 'Remove deprecated functional test targets\n\nChange-Id: I83056afccdfceae08bd53705ddac14120b090839\n'}]",0,567393,06795046c34ddefdd7be37e43c658501982a0067,6,3,2,20635,,,0,"Remove deprecated functional test targets

Change-Id: I83056afccdfceae08bd53705ddac14120b090839
",git fetch https://review.opendev.org/openstack/charm-aodh refs/changes/93/567393/2 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/gate-basic-xenial-newton'],1,2424b40c71f92af63624bdc6692e356fa5fcdec2,update-amulet-defs-rm-deprecated,,"#!/usr/bin/env python """"""Amulet tests on a basic aodh deployment on xenial-newton."""""" from basic_deployment import AodhBasicDeployment if __name__ == '__main__': deployment = AodhBasicDeployment(series='xenial', openstack='cloud:xenial-newton', source='cloud:xenial-updates/newton') deployment.run_tests() ",0,11
openstack%2Frpm-packaging~stable%2Frocky~I53a5b225533081035fb45da5e98c57ddb1aea08b,openstack/rpm-packaging,stable/rocky,I53a5b225533081035fb45da5e98c57ddb1aea08b,Add octavia-tempest-plugin,MERGED,2019-02-12 13:58:00.000000000,2019-02-12 14:58:48.000000000,2019-02-12 14:58:48.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-12 13:58:00.000000000', 'files': ['openstack/octavia-tempest-plugin/octavia-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/05a0b0ac14ca3ef2df49fb6abf7447e7903b5340', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}]",0,636335,05a0b0ac14ca3ef2df49fb6abf7447e7903b5340,10,6,1,7102,,,0,"Add octavia-tempest-plugin

Change-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/35/636335/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/octavia-tempest-plugin/octavia-tempest-plugin.spec.j2'],1,05a0b0ac14ca3ef2df49fb6abf7447e7903b5340,636138-stable/rocky,"{% set pypi_name = 'octavia-tempest-plugin' %} {% set source=fetch_source('https://tarballs.openstack.org/octavia-tempest-plugin/octavia-tempest-plugin-0.2.0.tar.gz') %} {% set upstream_version = upstream_version() %} {% set rpm_release = '1' %} Name: {{ py2pkg('octavia-tempest-plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for the Octavia project License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/{{ pypi_name }} Source0: {{ source|basename }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('Tempest') }} Requires: {{ py2pkg('cryptography') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('oslo.log') }} Requires: {{ py2pkg('oslo.utils') }} Requires: {{ py2pkg('oslotest') }} Requires: {{ py2pkg('pbr') }} Requires: {{ py2pkg('python-dateutil') }} Requires: {{ py2pkg('requests') }} Requires: {{ py2pkg('six') }} Requires: {{ py2pkg('tenacity') }} %if 0%{?suse_version} BuildRequires: golang-packaging %else BuildRequires: golang %endif %python_subpackages %description This project contains the Tempest plugin for the Octavia project for OpenStack Load Balancing. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build pushd octavia_tempest_plugin/contrib/httpd # we don't want to ship a binary blob that we didn't build ourself rm -f httpd.bin go build -ldflags '-linkmode=external' -o httpd.bin httpd.go popd %{python_build} %install %{python_install} %files %{python_files} %license LICENSE %doc README.rst %{python_sitelib}/octavia_tempest_plugin %{python_sitelib}/*.egg-info %changelog ",,60,0
openstack%2Ftripleo-heat-templates~master~I9d0733e78acdd896303750d8bd8b3358f8ceb0f8,openstack/tripleo-heat-templates,master,I9d0733e78acdd896303750d8bd8b3358f8ceb0f8,Use overlay2 storage driver for podman,ABANDONED,2019-02-12 12:02:55.000000000,2019-02-12 14:57:58.000000000,,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-02-12 12:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/594198dd3e174167dc2d9241db6e7ec93fe2916a', 'message': 'WIP: Use overlay2 storage driver for podman\n\nChange-Id: I9d0733e78acdd896303750d8bd8b3358f8ceb0f8\n'}, {'number': 2, 'created': '2019-02-12 12:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/91742a30ee19d68659b57b3d66d9651c2792bbcd', 'message': 'WIP: Use overlay2 storage driver for podman\n\nRelated-Bug: #1815576\n\nChange-Id: I9d0733e78acdd896303750d8bd8b3358f8ceb0f8\n'}, {'number': 3, 'created': '2019-02-12 12:26:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f14d9db5d40241dd9d265b437438781d7b9d134c', 'message': 'Use overlay2 storage driver for podman\n\nWe have found that docker is configured with overlay2 but podman with\noverlay and we are getting some MANIFEST_BLOB_UNKNOWN errors, this\nreview just try to see if using overlay2 can help with that.\n\nRelated-Bug: #1815576\n\nDepends-On: https://review.openstack.org/636323\n\nChange-Id: I9d0733e78acdd896303750d8bd8b3358f8ceb0f8\n'}, {'number': 4, 'created': '2019-02-12 13:46:52.000000000', 'files': ['deployment/podman/podman-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4f77d9a9f2da0969d9362bc205688ebd59a2631', 'message': 'Use overlay2 storage driver for podman\n\nWe have found that docker is configured with overlay2 but podman with\noverlay and we are getting some MANIFEST_BLOB_UNKNOWN errors, this\nreview just try to see if using overlay2 can help with that.\n\nRelated-Bug: #1815576\n\nDepends-On: https://review.openstack.org/636323\n\nChange-Id: I9d0733e78acdd896303750d8bd8b3358f8ceb0f8\n'}]",1,636317,b4f77d9a9f2da0969d9362bc205688ebd59a2631,8,12,4,27898,,,0,"Use overlay2 storage driver for podman

We have found that docker is configured with overlay2 but podman with
overlay and we are getting some MANIFEST_BLOB_UNKNOWN errors, this
review just try to see if using overlay2 can help with that.

Related-Bug: #1815576

Depends-On: https://review.openstack.org/636323

Change-Id: I9d0733e78acdd896303750d8bd8b3358f8ceb0f8
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/636317/4 && git format-patch -1 --stdout FETCH_HEAD,['deployment/podman/podman-baremetal-ansible.yaml'],1,594198dd3e174167dc2d9241db6e7ec93fe2916a,bug/1815576, - name: select overlay2 storage driver ini_file: path: /etc/containers/storage.conf section: 'storage' option: driver value: overlay2 ,,7,0
openstack%2Fopenstack-ansible~master~I3b5563118f9e27222d21d3f2aedc42f275ca9e26,openstack/openstack-ansible,master,I3b5563118f9e27222d21d3f2aedc42f275ca9e26,Remove an extra comment about Tempest settings,MERGED,2019-02-11 15:11:17.000000000,2019-02-12 14:57:35.000000000,2019-02-12 14:57:35.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-11 15:11:17.000000000', 'files': ['tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b6f7fa6c71c44e40a3b75428011a0cfccfc1016a', 'message': ""Remove an extra comment about Tempest settings\n\nIt's above the if, including it in the else yields two comments.\n\nChange-Id: I3b5563118f9e27222d21d3f2aedc42f275ca9e26\n""}]",0,636148,b6f7fa6c71c44e40a3b75428011a0cfccfc1016a,9,4,1,9061,,,0,"Remove an extra comment about Tempest settings

It's above the if, including it in the else yields two comments.

Change-Id: I3b5563118f9e27222d21d3f2aedc42f275ca9e26
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/48/636148/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2'],1,b6f7fa6c71c44e40a3b75428011a0cfccfc1016a,,,## Tempest settings,0,1
openstack%2Fkolla-ansible~master~I07e4e563538b4a47d9b1707b4e660531ccce7b9b,openstack/kolla-ansible,master,I07e4e563538b4a47d9b1707b4e660531ccce7b9b,hinese quotes,MERGED,2018-12-24 01:35:58.000000000,2019-02-12 14:32:11.000000000,2019-02-12 14:32:11.000000000,"[{'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 25747}, {'_account_id': 27507}, {'_account_id': 27549}, {'_account_id': 28563}]","[{'number': 1, 'created': '2018-12-24 01:35:58.000000000', 'files': ['releasenotes/notes/onos-support-2ea385cceb8104d6.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7ace98d9753f466a0de811246cbca27437b873a6', 'message': 'hinese quotes\n\nChange-Id: I07e4e563538b4a47d9b1707b4e660531ccce7b9b\n'}]",2,627089,7ace98d9753f466a0de811246cbca27437b873a6,14,8,1,29558,,,0,"hinese quotes

Change-Id: I07e4e563538b4a47d9b1707b4e660531ccce7b9b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/89/627089/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/onos-support-2ea385cceb8104d6.yaml'],1,7ace98d9753f466a0de811246cbca27437b873a6,," Add onos support, Networking-onos is Neutron's sub-project to provide connectivity between Neutron/Neutron's sub-project's and ONOS."," Add onos support, Networking-onos is Neutrons sub-project to provide connectivity between Neutron/Neutrons sub-projects and ONOS.",2,2
openstack%2Ftripleo-heat-templates~master~Ib04b051e8f4275e06be0cafa81e2111c9cced9b7,openstack/tripleo-heat-templates,master,Ib04b051e8f4275e06be0cafa81e2111c9cced9b7,Ensure all upgrade tasks depend on a step.,ABANDONED,2019-01-03 11:05:11.000000000,2019-02-12 14:30:19.000000000,,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 8833}, {'_account_id': 11166}, {'_account_id': 20775}, {'_account_id': 20778}, {'_account_id': 20866}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-01-03 11:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/45ca26f1d1cfebd82e4b988d1302a4fd22f8a4ff', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 2, 'created': '2019-01-03 11:36:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7a2eddff28fb10c19c0f1d228917b4aaa69e3ada', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 3, 'created': '2019-01-08 11:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a423cff1ed27b7f5e8d1a137561fb50f3f9ec7b7', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 4, 'created': '2019-01-08 11:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7fd27fc8b25720c9ce2ba67250a3f76c990be2d', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 5, 'created': '2019-01-14 08:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/720d8778a941de3b69eaab5896c5ee9d56fb14ff', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 6, 'created': '2019-01-16 10:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eea4e59d46a0a6e92c1d01f42cef2fe551e38f10', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 7, 'created': '2019-01-16 10:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0adbef2ffb8dd958294472c56ceda78dd24eb38', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 8, 'created': '2019-01-30 10:09:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3ec298d8bd5bcb92602b7e3acf676d96148a6c34', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 9, 'created': '2019-02-04 11:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/41fad1149f64dbd08acd0ef2f059a3bfec030de2', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 10, 'created': '2019-02-05 09:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9efa8b346ebd67fb6a31ac2416a474d2a3d3b2a2', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 11, 'created': '2019-02-05 13:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a56288e128c7e564b83bdd80e58b9cd37e0a5d38', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}, {'number': 12, 'created': '2019-02-12 09:55:00.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml', 'puppet/services/opendaylight-ovs.yaml', 'docker/services/opendaylight-api.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'tools/yaml-validate.py', 'deployment/podman/podman-baremetal-ansible.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml', 'docker/services/pacemaker/ovn-dbs.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/86149d341284e742b2ad7b46490c8073aa0e4dd5', 'message': ""Ensure all upgrade tasks depend on a step.\n\nThis patch refactors some of the upgrade tasks which were missing\na task condition to run depending on the variable step. Grouping\nthem in blocks when possible.\n\nBesides, an extra check has been added for the upgrade_tasks validation\nfunction inside tools/yaml-validate.py which ensures that every upgrade\ntask will contain a 'when' condition. This check could be disabled by\npassing the variable 'check_when' to false.\n\nChange-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7\n""}]",5,628154,86149d341284e742b2ad7b46490c8073aa0e4dd5,40,10,12,26343,,,0,"Ensure all upgrade tasks depend on a step.

This patch refactors some of the upgrade tasks which were missing
a task condition to run depending on the variable step. Grouping
them in blocks when possible.

Besides, an extra check has been added for the upgrade_tasks validation
function inside tools/yaml-validate.py which ensures that every upgrade
task will contain a 'when' condition. This check could be disabled by
passing the variable 'check_when' to false.

Change-Id: Ib04b051e8f4275e06be0cafa81e2111c9cced9b7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/54/628154/12 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'puppet/services/opendaylight-ovs.yaml', 'docker/services/opendaylight-api.yaml', 'tools/yaml-validate.py', 'puppet/services/tripleo-packages.yaml', 'docker/services/pacemaker/ovn-dbs.yaml']",7,45ca26f1d1cfebd82e4b988d1302a4fd22f8a4ff,refactor_upgrades_workflow," - when: step|int == 0 block: - name: Check for ovn-dbs log file stat: path: /var/log/containers/openvswitch/ovsdb-server-nb.log register: ovn_dbs_log_file - name: Check if ovn-dbs is already containerized set_fact: ovn_dbs_containerized: ""{{ovn_dbs_log_file.stat.exists | default(false)}}"" - name: Get docker ovn-dbs image set_fact: ovn_dbs_docker_image: {get_param: DockerOvnDbsImage} ovn_dbs_docker_image_latest: *ovn_dbs_image_pcmklatest - name: set is_bootstrap_node fact set_fact: is_bootstrap_node={{ovn_dbs_short_bootstrap_node_name|lower == ansible_hostname|lower}} - name: Prepare the switch to new ovn-dbs container image name in pacemaker when: - ovn_dbs_containerized|bool block: - name: Get ovn-dbs image id currently used by pacemaker shell: ""{{container_cli}} images | awk '/ovn.* pcmklatest/{print $3}' | uniq"" register: ovn_dbs_current_pcmklatest_id - name: Temporarily tag the current ovn-dbs pcmklatest image id with the upgraded image name import_role: name: tripleo-container-tag vars: container_image: ""{{ovn_dbs_current_pcmklatest_id.stdout}}"" container_image_latest: ""{{ovn_dbs_docker_image_latest}}"" when: ovn_dbs_current_pcmklatest_id.stdout != '' # If ovn-dbs image is not tagged with pcmklatest, then create a new # tag. This could happen if the stack is upgraded without updating the stack before. # In the next step, the block 'ovn_dbs_update_bundle_with_new_image' # will update the ovn-dbs-bundle resource to use the tagged image. # And in step 3, we will fetch the latest image. - block: - name: Get the present image used by ovn-dbs-bundle shell: ""pcs resource show ovn-dbs-bundle | grep image | awk '{ split($2, image, \""=\""); print image[2] }'"" register: ovn_dbs_current_image - name: Tag the current image with pcmklatest tag import_role: name: tripleo-container-tag vars: container_image: ""{{ovn_dbs_current_image.stdout}}"" container_image_latest: ""{{ovn_dbs_docker_image_latest}}"" when: - ovn_dbs_current_pcmklatest_id.stdout == '' - name: Check ovn-dbs-bundle cluster resource status pacemaker_resource: resource: ovn-dbs-bundle state: show check_mode: false ignore_errors: true register: ovndbs_pcs_res"," - name: Check for ovn-dbs log file stat: path: /var/log/containers/openvswitch/ovsdb-server-nb.log register: ovn_dbs_log_file - name: Check if ovn-dbs is already containerized set_fact: ovn_dbs_containerized: ""{{ovn_dbs_log_file.stat.exists | default(false)}}"" - name: Get docker ovn-dbs image set_fact: ovn_dbs_docker_image: {get_param: DockerOvnDbsImage} ovn_dbs_docker_image_latest: *ovn_dbs_image_pcmklatest - name: set is_bootstrap_node fact set_fact: is_bootstrap_node={{ovn_dbs_short_bootstrap_node_name|lower == ansible_hostname|lower}} - name: Prepare the switch to new ovn-dbs container image name in pacemaker when: - step|int == 0 - ovn_dbs_containerized|bool block: - name: Get ovn-dbs image id currently used by pacemaker shell: ""{{container_cli}} images | awk '/ovn.* pcmklatest/{print $3}' | uniq"" register: ovn_dbs_current_pcmklatest_id - name: Temporarily tag the current ovn-dbs pcmklatest image id with the upgraded image name import_role: name: tripleo-container-tag vars: container_image: ""{{ovn_dbs_current_pcmklatest_id.stdout}}"" container_image_latest: ""{{ovn_dbs_docker_image_latest}}"" when: ovn_dbs_current_pcmklatest_id.stdout != '' # If ovn-dbs image is not tagged with pcmklatest, then create a new # tag. This could happen if the stack is upgraded without updating the stack before. # In the next step, the block 'ovn_dbs_update_bundle_with_new_image' # will update the ovn-dbs-bundle resource to use the tagged image. # And in step 3, we will fetch the latest image. - block: - name: Get the present image used by ovn-dbs-bundle shell: ""pcs resource show ovn-dbs-bundle | grep image | awk '{ split($2, image, \""=\""); print image[2] }'"" register: ovn_dbs_current_image - name: Tag the current image with pcmklatest tag import_role: name: tripleo-container-tag vars: container_image: ""{{ovn_dbs_current_image.stdout}}"" container_image_latest: ""{{ovn_dbs_docker_image_latest}}"" when: - ovn_dbs_current_pcmklatest_id.stdout == '' - name: Check ovn-dbs-bundle cluster resource status pacemaker_resource: resource: ovn-dbs-bundle state: show check_mode: false ignore_errors: true register: ovndbs_pcs_res",280,266
openstack%2Fopenstack-ansible-tests~master~Ia8030424eabecef3c5217907757d921f45e329f8,openstack/openstack-ansible-tests,master,Ia8030424eabecef3c5217907757d921f45e329f8,Use the config_template module from the dedicated repo,MERGED,2019-02-08 13:46:26.000000000,2019-02-12 14:28:29.000000000,2019-02-12 14:28:28.000000000,"[{'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-08 13:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/0888ecf395a62e4c5784602d6ba42316c61fb292', 'message': 'Use the config_template module from the dedicated repo\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nThis implements the changes necessary to ensure that all role tests\nnow make use of the new git repository, rather than the old location\nin the openstack-ansible-plugins repository.\n\nRelated-Bug: 1791258\nDepends-On: https://review.openstack.org/635838\nChange-Id: Ia8030424eabecef3c5217907757d921f45e329f8\n'}, {'number': 2, 'created': '2019-02-08 13:53:44.000000000', 'files': ['test-ansible.cfg', 'test-ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/2462fa482031190474a98764d27675c7bcb8b753', 'message': 'Use the config_template module from the dedicated repo\n\nThe config_template action module has now been moved into its own git\nrepository (openstack/ansible-config_template). This has been done to\nsimplify the ability to use the plugin in other non OpenStack-Ansible\nprojects.\n\nThis implements the changes necessary to ensure that all role tests\nnow make use of the new git repository, rather than the old location\nin the openstack-ansible-plugins repository. The config_template\nrepo is placed first in the list of library/action plugin locations\nto use to ensure that any other version of the plugin (eg: ceph) is\nnot used.\n\nRelated-Bug: 1791258\nChange-Id: Ia8030424eabecef3c5217907757d921f45e329f8\n'}]",0,635841,2462fa482031190474a98764d27675c7bcb8b753,11,4,2,6816,,,0,"Use the config_template module from the dedicated repo

The config_template action module has now been moved into its own git
repository (openstack/ansible-config_template). This has been done to
simplify the ability to use the plugin in other non OpenStack-Ansible
projects.

This implements the changes necessary to ensure that all role tests
now make use of the new git repository, rather than the old location
in the openstack-ansible-plugins repository. The config_template
repo is placed first in the list of library/action plugin locations
to use to ensure that any other version of the plugin (eg: ceph) is
not used.

Related-Bug: 1791258
Change-Id: Ia8030424eabecef3c5217907757d921f45e329f8
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/41/635841/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-ansible.cfg', 'test-ansible-role-requirements.yml']",2,0888ecf395a62e4c5784602d6ba42316c61fb292,bug/1791258,- name: config_template scm: git src: https://git.openstack.org/openstack/ansible-config_template version: master,,6,2
openstack%2Fnova~stable%2Fpike~I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a,openstack/nova,stable/pike,I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a,Handle IndexError in _populate_neutron_binding_profile,MERGED,2019-02-08 19:29:28.000000000,2019-02-12 14:26:25.000000000,2019-02-12 14:26:24.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-08 19:29:28.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8049e9595bfcf041cd81a4dd353f6285a9806100', 'message': ""Handle IndexError in _populate_neutron_binding_profile\n\nThis fixes the code that was blindly pop'ing an entry\nfrom an empty list of PCI devices claimed by the instance.\nIt's not exactly clear how we can get into this situation,\npresumably there was a failure in the actual PCI device\nclaim logic in the ResourceTracker - maybe related to the\nconfigured PCI passthrough whitelist. Regardless, we should\nhandle the empty PCI device list in this method and raise\nan appropriate exception to fail the build on this host.\n\nConflicts:\n\tnova/network/neutronv2/api.py\n\nNote(elod.illes): conflict caused by two change not part of\nbranch stable/pike: Id847949b4761d51a14e5c2f39552f60a47889aa9\nand Ie3a83fef0dc689b9d37ac43e047ce5d48f567adc\n\nChange-Id: I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a\nCloses-Bug: #1795064\n(cherry picked from commit 035708c37d587e4c5ede7fe80270bdbff98016ac)\n(cherry picked from commit dfbcf5e40bb51813f56f983e4f75e29a6034a830)\n(cherry picked from commit 8369a78af07b224f109586de398c702db342b49d)\n""}]",0,635921,8049e9595bfcf041cd81a4dd353f6285a9806100,16,10,1,17685,,,0,"Handle IndexError in _populate_neutron_binding_profile

This fixes the code that was blindly pop'ing an entry
from an empty list of PCI devices claimed by the instance.
It's not exactly clear how we can get into this situation,
presumably there was a failure in the actual PCI device
claim logic in the ResourceTracker - maybe related to the
configured PCI passthrough whitelist. Regardless, we should
handle the empty PCI device list in this method and raise
an appropriate exception to fail the build on this host.

Conflicts:
	nova/network/neutronv2/api.py

Note(elod.illes): conflict caused by two change not part of
branch stable/pike: Id847949b4761d51a14e5c2f39552f60a47889aa9
and Ie3a83fef0dc689b9d37ac43e047ce5d48f567adc

Change-Id: I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a
Closes-Bug: #1795064
(cherry picked from commit 035708c37d587e4c5ede7fe80270bdbff98016ac)
(cherry picked from commit dfbcf5e40bb51813f56f983e4f75e29a6034a830)
(cherry picked from commit 8369a78af07b224f109586de398c702db342b49d)
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/635921/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,8049e9595bfcf041cd81a4dd353f6285a9806100,bug/1795064," @mock.patch.object(pci_manager, 'get_instance_pci_devs', return_value=[]) def test_populate_neutron_binding_profile_pci_dev_not_found( self, mock_get_instance_pci_devs): api = neutronapi.API() instance = objects.Instance(pci_devices=objects.PciDeviceList()) port_req_body = {'port': {}} pci_req_id = 'my_req_id' self.assertRaises(exception.PciDeviceNotFound, api._populate_neutron_binding_profile, instance, pci_req_id, port_req_body) mock_get_instance_pci_devs.assert_called_once_with( instance, pci_req_id) ",,31,2
openstack%2Fnetworking-ovn~stable%2Fqueens~I450482c542f10c21f210be570df9ec7c9a617c94,openstack/networking-ovn,stable/queens,I450482c542f10c21f210be570df9ec7c9a617c94,Extend ml2 plugin to notify nova of port status,MERGED,2019-02-06 12:08:07.000000000,2019-02-12 14:24:21.000000000,2019-02-12 14:24:21.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 11604}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 12:08:07.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0b67677f993bdc4e52556b83a2e6ec249fbd36de', 'message': 'Extend ml2 plugin to notify nova of port status\n\n- This change modifies the ovn ml2 driver to notify\n  nova on port status changes.\n\n- This will help enable faster migration when using\n  ml2/ovn in the future by notifying nova once ovn\n  has completed wireing up the interface.\n\nCloses-Bug: #1804407\nCo-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>\nChange-Id: I450482c542f10c21f210be570df9ec7c9a617c94\n(cherry picked from commit 9fc6b5d205b1ccf24541e64042af63bb993afd0e)\n(cherry picked from commit 424c6a6c0bee404ee55ca0ae53c131a64170ded3)\n'}]",0,635140,0b67677f993bdc4e52556b83a2e6ec249fbd36de,16,5,1,11604,,,0,"Extend ml2 plugin to notify nova of port status

- This change modifies the ovn ml2 driver to notify
  nova on port status changes.

- This will help enable faster migration when using
  ml2/ovn in the future by notifying nova once ovn
  has completed wireing up the interface.

Closes-Bug: #1804407
Co-Authored-By: Lucas Alvares Gomes <lucasagomes@gmail.com>
Change-Id: I450482c542f10c21f210be570df9ec7c9a617c94
(cherry picked from commit 9fc6b5d205b1ccf24541e64042af63bb993afd0e)
(cherry picked from commit 424c6a6c0bee404ee55ca0ae53c131a64170ded3)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/40/635140/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_mech_driver.py', 'networking_ovn/ml2/mech_driver.py']",2,0b67677f993bdc4e52556b83a2e6ec249fbd36de,bug/1804407,"from neutron.plugins.ml2 import db as ml2_db self._insert_port_provisioning_block(context._plugin_context, port['id']) def _insert_port_provisioning_block(self, context, port_id): context, port_id, resources.PORT, self._insert_port_provisioning_block(context._plugin_context, port['id']) db_port = ml2_db.get_port(admin_context, port_id) if not db_port: return if db_port.device_owner in (const.DEVICE_OWNER_ROUTER_INTF, const.DEVICE_OWNER_DVR_INTERFACE, const.DEVICE_OWNER_ROUTER_HA_INTF): elif db_port.device_owner.startswith( const.DEVICE_OWNER_COMPUTE_PREFIX): self._plugin.nova_notifier.notify_port_active_direct(db_port) db_port = ml2_db.get_port(admin_context, port_id) if not db_port: return self._insert_port_provisioning_block(admin_context, port_id) self._plugin.update_port_status(admin_context, port_id, if db_port.device_owner.startswith( const.DEVICE_OWNER_COMPUTE_PREFIX): self._plugin.nova_notifier.record_port_status_changed( db_port, const.PORT_STATUS_ACTIVE, const.PORT_STATUS_DOWN, None) self._plugin.nova_notifier.send_port_status( None, None, db_port)"," self._insert_port_provisioning_block(context._plugin_context, port) def _insert_port_provisioning_block(self, context, port): context, port['id'], resources.PORT, self._insert_port_provisioning_block(context._plugin_context, port) port = self._plugin.get_port(admin_context, port_id) if port.get('device_owner') in (const.DEVICE_OWNER_ROUTER_INTF, const.DEVICE_OWNER_DVR_INTERFACE, const.DEVICE_OWNER_ROUTER_HA_INTF): port = self._plugin.get_port(admin_context, port_id) self._insert_port_provisioning_block(admin_context, port) self._plugin.update_port_status(admin_context, port['id'],",79,17
openstack%2Fvitrage-tempest-plugin~master~I2996afcd4f05c87847db1f9be64a362a2593f5b6,openstack/vitrage-tempest-plugin,master,I2996afcd4f05c87847db1f9be64a362a2593f5b6,add a new service list api tests,MERGED,2019-02-07 11:53:50.000000000,2019-02-12 14:17:14.000000000,2019-02-12 14:17:14.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 11:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/84aeb1ad2bc219c85b75cb74e62bd3cf09bc5f0b', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 2, 'created': '2019-02-07 12:02:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/4fe1036858542f52684e0217ca0078d3464b54ea', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 3, 'created': '2019-02-07 12:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/3e0404f92ec6a446fa5358090b2c8bd1604aed9b', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 4, 'created': '2019-02-07 12:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/c70f6f5dd17aadaf148a8a24870188b088647e76', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 5, 'created': '2019-02-07 12:25:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d43b51b04883b8200ed8931b1585aba8eed2dff2', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 6, 'created': '2019-02-07 12:28:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/d74d13e58535368d58e54555e144f5e4a8309b05', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 7, 'created': '2019-02-07 12:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/80b15df2a228c08bff39659e43842a071c8cf8ff', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 8, 'created': '2019-02-07 12:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/4fe1a665150fff48cbd0d83b842ec197807e94a2', 'message': 'WIP: add a new service list api tests\n\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 9, 'created': '2019-02-07 13:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/94205219a936d9cf9cd8ffa36126f8fd5a1d5dba', 'message': 'WIP: add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 10, 'created': '2019-02-07 14:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/77c76c678b4a3deb7baf6cdf9a8f4eee354305fa', 'message': 'WIP: add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 11, 'created': '2019-02-07 15:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/45a9333a7682882bf1a1afe54eece33139bd558a', 'message': 'WIP: add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 12, 'created': '2019-02-10 12:33:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/a4b2517c500cfd8e1335187f95925028cf68a181', 'message': 'WIP: add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 13, 'created': '2019-02-11 08:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/a76a34a758499a8002900c5d7860a8c51d4c70a1', 'message': 'add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 14, 'created': '2019-02-11 13:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/3230b8c973ebdfc8081a1d2475ec8e1b78f190c0', 'message': 'WIP: add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}, {'number': 15, 'created': '2019-02-11 13:13:41.000000000', 'files': ['vitrage_tempest_plugin/tests/api/services/__init__.py', 'devstack/post_test_hook.sh', 'vitrage_tempest_plugin/tests/api/services/test_service.py', 'vitrage_tempest_plugin/tests/base.py'], 'web_link': 'https://opendev.org/openstack/vitrage-tempest-plugin/commit/11fd7859ba4394f7c0951e2c74c7221e32d7dcb2', 'message': 'add a new service list api tests\n\nDepends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\nChange-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6\n'}]",0,635488,11fd7859ba4394f7c0951e2c74c7221e32d7dcb2,43,4,15,19134,,,0,"add a new service list api tests

Depends-On: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178
Change-Id: I2996afcd4f05c87847db1f9be64a362a2593f5b6
",git fetch https://review.opendev.org/openstack/vitrage-tempest-plugin refs/changes/88/635488/6 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_plugin/tests/api/services/__init__.py', 'vitrage_tempest_plugin/tests/api/services/test_service.py', 'vitrage_tempest_plugin/tests/base.py']",3,84aeb1ad2bc219c85b75cb74e62bd3cf09bc5f0b,eyalb/service," def assert_set_equal(self, s1, s2, message): self.assertSetEqual(s1, s2, message) ",,68,0
openstack%2Fneutron~master~I7a54c77073cf2a648d32320b3dd8cb46d34f7c34,openstack/neutron,master,I7a54c77073cf2a648d32320b3dd8cb46d34f7c34,Change OVS agent to log message after failure,MERGED,2019-01-24 22:22:02.000000000,2019-02-12 14:14:47.000000000,2019-02-12 14:14:47.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 25618}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-01-24 22:22:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56a6f52232f6249d7c08f27030f9802b4ee5e716', 'message': 'Change OVS agent to log message after failure\n\nIf the OVS agent fails to send its report_state\nto the server, it logs an exception:\n\n   Failed reporting state!: MessagingTimeout: Timed out...\n\nIf it then tries a second time and succeeds it just\ngoes on happily. It would be nice if it logged that\nit had success on the subsequent attempt so someone\nlooking at the logs know it recovered.\n\nChange-Id: I7a54c77073cf2a648d32320b3dd8cb46d34f7c34\n'}, {'number': 2, 'created': '2019-02-11 16:21:52.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9926410886b485348f608c339fe48c27e430ea56', 'message': 'Change OVS agent to log message after failure\n\nIf the OVS agent fails to send its report_state\nto the server, it logs an exception:\n\n   Failed reporting state!: MessagingTimeout: Timed out...\n\nIf it then tries a second time and succeeds it just\ngoes on happily. It would be nice if it logged that\nit had success on the subsequent attempt so someone\nlooking at the logs know it recovered.\n\nChange-Id: I7a54c77073cf2a648d32320b3dd8cb46d34f7c34\n'}]",0,633079,9926410886b485348f608c339fe48c27e430ea56,25,7,2,1131,,,0,"Change OVS agent to log message after failure

If the OVS agent fails to send its report_state
to the server, it logs an exception:

   Failed reporting state!: MessagingTimeout: Timed out...

If it then tries a second time and succeeds it just
goes on happily. It would be nice if it logged that
it had success on the subsequent attempt so someone
looking at the logs know it recovered.

Change-Id: I7a54c77073cf2a648d32320b3dd8cb46d34f7c34
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/633079/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py'],1,56a6f52232f6249d7c08f27030f9802b4ee5e716,agent-failed-report-state," self.failed_report_state = False self.failed_report_state = True return if self.failed_report_state: self.failed_report_state = False LOG.info(""Successfully reported state after a previous failure."")",,6,0
openstack%2Fpuppet-nova~master~I086c0fe53b95f6c9de962d108c9447564da2cc3e,openstack/puppet-nova,master,I086c0fe53b95f6c9de962d108c9447564da2cc3e,WIP placement: Configure service using puppet-placement,ABANDONED,2018-11-05 14:08:12.000000000,2019-02-12 14:14:23.000000000,,"[{'_account_id': 10135}, {'_account_id': 11564}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-05 14:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8a9aef74952ef4b5f97375a5eabe12ade538d8db', 'message': 'WIP Remove Placement service from puppet-nova\n\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}, {'number': 2, 'created': '2018-12-06 13:12:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/fa0c3ebae4a4139cef748010e9b03c8895a289e2', 'message': 'Remove Placement service from puppet-nova\n\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}, {'number': 3, 'created': '2019-01-31 12:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/64ba754f8fae7728a357f860f070c89199d75723', 'message': 'WIP Configure placement using puppet-placement\n\nDepends-On: https://review.openstack.org/#/c/615568/\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}, {'number': 4, 'created': '2019-02-01 20:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/285f495184bfa0c0e1b2e655478ea4cdee227a4b', 'message': 'WIP placement: Configure service using puppet-placement\n\nDepends-On: https://review.openstack.org/#/c/615568/\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}, {'number': 5, 'created': '2019-02-01 20:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c73d187b9a0ea9d5f8f8ec8128e75cef06532334', 'message': 'WIP placement: Configure service using puppet-placement\n\nDepends-On: https://review.openstack.org/#/c/615568/\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}, {'number': 6, 'created': '2019-02-01 21:31:00.000000000', 'files': ['manifests/placement/service.pp', 'manifests/keystone/auth_placement.pp', 'manifests/db/mysql_placement.pp', 'manifests/wsgi/apache_placement.pp', 'manifests/db.pp', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d8282e4c51d5b7a90941e5fa81a4827e7cd88c33', 'message': 'WIP placement: Configure service using puppet-placement\n\nDepends-On: https://review.openstack.org/#/c/615568/\nChange-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e\n'}]",1,615569,d8282e4c51d5b7a90941e5fa81a4827e7cd88c33,26,5,6,10135,,,0,"WIP placement: Configure service using puppet-placement

Depends-On: https://review.openstack.org/#/c/615568/
Change-Id: I086c0fe53b95f6c9de962d108c9447564da2cc3e
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/69/615569/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/keystone/auth_placement.pp', 'manifests/db/mysql_placement.pp', 'spec/classes/nova_db_mysql_placement_spec.rb', 'manifests/placement.pp', 'manifests/wsgi/apache_placement.pp', 'manifests/db.pp', 'manifests/init.pp', 'spec/classes/nova_placement_spec.rb', 'spec/classes/nova_keystone_auth_placement_spec.rb', 'spec/classes/nova_wsgi_apache_placement_spec.rb', 'manifests/params.pp']",11,8a9aef74952ef4b5f97375a5eabe12ade538d8db,puppet-placement-extraction,, $placement_package_name = 'openstack-nova-placement-api' $placement_service_name = 'httpd' $placement_public_url = 'http://127.0.0.1/placement' $placement_internal_url = 'http://127.0.0.1/placement' $placement_admin_url = 'http://127.0.0.1/placement' $placement_wsgi_script_source = '/usr/bin/nova-placement-api' $placement_httpd_config_file = '/etc/httpd/conf.d/00-nova-placement-api.conf' $placement_package_name = 'nova-placement-api' $placement_wsgi_script_source = '/usr/bin/nova-placement-api' $placement_httpd_config_file = '/etc/apache2/sites-available/nova-placement-api.conf' $placement_service_name = 'nova-placement-api' $placement_public_url = 'http://127.0.0.1' $placement_internal_url = 'http://127.0.0.1' $placement_admin_url = 'http://127.0.0.1' $placement_service_name = 'httpd' $placement_public_url = 'http://127.0.0.1/placement' $placement_internal_url = 'http://127.0.0.1/placement' $placement_admin_url = 'http://127.0.0.1/placement',0,1071
openstack%2Fopenstack-ansible~master~Idd3a842f94eb30dec2afa6da84615a8605ef9e78,openstack/openstack-ansible,master,Idd3a842f94eb30dec2afa6da84615a8605ef9e78,Mark OSA version in the wrapper script,MERGED,2019-01-29 15:43:11.000000000,2019-02-12 14:13:43.000000000,2019-02-12 14:13:43.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 15:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cc71894fbeb3d227b4074216a32dfd79ea5ed5cd', 'message': 'Mark OSA version in the wrapper script\n\nBy doing that, we compute (every bootstrap ansible) the version\nof OSA, which can then be used in playbooks using a lookup.\n\nThis would be faster than doing the lookup in the variable, as\nthis would be computed once, gaining around 0.4s per playbook.\n\nChange-Id: Idd3a842f94eb30dec2afa6da84615a8605ef9e78\n'}, {'number': 2, 'created': '2019-02-12 10:15:54.000000000', 'files': ['scripts/openstack-ansible.sh', 'scripts/bootstrap-ansible.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c44fbcbbe3b6d88e9393503e92ac670f9e811148', 'message': 'Mark OSA version in the wrapper script\n\nBy doing that, we compute (every bootstrap ansible) the version\nof OSA, which can then be used in playbooks using a lookup.\n\nThis would be faster than doing the lookup in the variable, as\nthis would be computed once, gaining around 0.4s per playbook.\n\nChange-Id: Idd3a842f94eb30dec2afa6da84615a8605ef9e78\n'}]",0,633762,c44fbcbbe3b6d88e9393503e92ac670f9e811148,26,4,2,17068,,,0,"Mark OSA version in the wrapper script

By doing that, we compute (every bootstrap ansible) the version
of OSA, which can then be used in playbooks using a lookup.

This would be faster than doing the lookup in the variable, as
this would be computed once, gaining around 0.4s per playbook.

Change-Id: Idd3a842f94eb30dec2afa6da84615a8605ef9e78
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/62/633762/2 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/openstack-ansible.sh', 'scripts/bootstrap-ansible.sh']",2,cc71894fbeb3d227b4074216a32dfd79ea5ed5cd,easier_osa_releases,"# Get current code version (this runs at the root of OSA clone) CURRENT_OSA_VERSION=$(cd ${OSA_CLONE_DIR}; ${PYTHON_EXEC_PATH} setup.py --version) # Mark the current OSA version in the wrapper, so we don't need to compute it everytime. sed -i ""s|CURRENT_OSA_VERSION|${CURRENT_OSA_VERSION}|g"" /usr/local/bin/openstack-ansible",,6,0
openstack%2Ftripleo-heat-templates~master~I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d,openstack/tripleo-heat-templates,master,I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d,FFWD: Introduce workaround for neutron cisco plugin,MERGED,2018-11-22 09:06:27.000000000,2019-02-12 14:08:04.000000000,2019-02-12 14:08:04.000000000,"[{'_account_id': 8042}, {'_account_id': 11166}, {'_account_id': 18575}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-11-22 09:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4e8c2faf36d94257760b5d07195e1d90fefbc2c4', 'message': 'FFWD: Introduce workaround for neutron cisco plugin\n\nNeutron cisco plugin package update is not triggered by update of\nneutron package. If this plugin is enabled the neutron db sync\nwill fail unless we update python-networking-cisco package.\n\nChange-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d\nResolves: rhbz#1652209\nCloses-bug: #1804494\n'}, {'number': 2, 'created': '2019-02-11 11:36:03.000000000', 'files': ['deployment/neutron/neutron-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/17d8c985b794dad2e1491df15ba90a21bbe8e752', 'message': 'FFWD: Introduce workaround for neutron cisco plugin\n\nNeutron cisco plugin package update is not triggered by update of\nneutron package. If this plugin is enabled the neutron db sync\nwill fail unless we update python-networking-cisco package.\n\nChange-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d\nResolves: rhbz#1652209\nCloses-bug: #1804494\n'}]",4,619482,17d8c985b794dad2e1491df15ba90a21bbe8e752,18,6,2,11166,,,0,"FFWD: Introduce workaround for neutron cisco plugin

Neutron cisco plugin package update is not triggered by update of
neutron package. If this plugin is enabled the neutron db sync
will fail unless we update python-networking-cisco package.

Change-Id: I3ac3d9baf51c7a9e13d20985fbe47cd5404eb88d
Resolves: rhbz#1652209
Closes-bug: #1804494
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/82/619482/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/neutron-api.yaml'],1,4e8c2faf36d94257760b5d07195e1d90fefbc2c4,bug/1804494, - name: Networking cisco db sync workaround package: name=python-networking-cisco state=latest,,2,0
openstack%2Fopenstack-ansible-os_tempest~master~I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537,openstack/openstack-ansible-os_tempest,master,I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537,Add tempest_service_available_mistral with distro packages,MERGED,2019-02-06 15:01:51.000000000,2019-02-12 14:05:45.000000000,2019-02-12 14:05:45.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}]","[{'number': 1, 'created': '2019-02-06 15:01:51.000000000', 'files': ['vars/redhat-7.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/c26b65ed0e95239546309d80c7b71c496a07ef78', 'message': 'Add tempest_service_available_mistral with distro packages\n\nThis patch adds support for tempest_service_available_mistral and\nthe ability to install the needed packages to run tests under\nthe distro.\n\nChange-Id: I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537\n'}]",0,635180,c26b65ed0e95239546309d80c7b71c496a07ef78,15,5,1,1004,,,0,"Add tempest_service_available_mistral with distro packages

This patch adds support for tempest_service_available_mistral and
the ability to install the needed packages to run tests under
the distro.

Change-Id: I2e19efd5fdcb0bdbb3d1cd5ee44f20e4807ea537
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/80/635180/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/redhat-7.yml', 'defaults/main.yml']",2,c26b65ed0e95239546309d80c7b71c496a07ef78,,"tempest_service_available_mistral: ""{{ groups['mistral_all'] is defined and groups['mistral_all'] | length > 0 }}""",,2,0
openstack%2Fmanila~stable%2Fqueens~Ica698b6a70a128522c2c2de76a69e59207fd60ac,openstack/manila,stable/queens,Ica698b6a70a128522c2c2de76a69e59207fd60ac,Fix ganesha for 0.0.0.0/0 access,MERGED,2018-12-21 10:33:01.000000000,2019-02-12 14:04:50.000000000,2019-02-12 14:04:50.000000000,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 25243}, {'_account_id': 26968}, {'_account_id': 27740}]","[{'number': 1, 'created': '2018-12-21 10:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/65e69f8e2e7c01f669224c8dd511bc581ca9168c', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nCloses-bug: #1800627\n\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}, {'number': 3, 'created': '2018-12-21 14:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9b0c72df362aba413c5de8a76b6453266ef5e60a', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nCloses-bug: #1800627\n\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}, {'number': 4, 'created': '2019-01-28 17:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/8c005eb218d7f62e0bc7e6f9c753de9c15a6aedd', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nCloses-bug: #1800627\n\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}, {'number': 5, 'created': '2019-01-28 19:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f0a7088f2b35d4e2e8de72b759cc964a58b3eb43', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nDepends-on: https://review.openstack.org/633584\nCloses-bug: #1800627\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}, {'number': 6, 'created': '2019-02-08 00:27:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e325ed3f08da7493021337386a520923825241d2', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nCloses-bug: #1800627\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}, {'number': 7, 'created': '2019-02-08 11:01:57.000000000', 'files': ['releasenotes/notes/fix-ganesha-allow-access-for-all-ips-09773a79dc76ad44.yaml', 'manila/share/drivers/ganesha/__init__.py', 'manila/share/drivers/ganesha/utils.py', 'manila/tests/share/drivers/ganesha/test_utils.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/40792c69a78b208ad74108f79d51d56fcc1f5e0e', 'message': ""Fix ganesha for 0.0.0.0/0 access\n\nTranslate '0.0.0.0/0' to '0.0.0.0' when allowing IP\naccess with the ganesha driver since the ganesha back end\ncannot handle the former expression and the latter has\nthe desired effect of allowing access to all IPs.\n\nDepends-on: https://review.openstack.org/#/c/626879/\nCloses-bug: #1800627\nChange-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac\n(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)\n(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)\n""}]",0,626865,40792c69a78b208ad74108f79d51d56fcc1f5e0e,51,10,6,9003,,,0,"Fix ganesha for 0.0.0.0/0 access

Translate '0.0.0.0/0' to '0.0.0.0' when allowing IP
access with the ganesha driver since the ganesha back end
cannot handle the former expression and the latter has
the desired effect of allowing access to all IPs.

Depends-on: https://review.openstack.org/#/c/626879/
Closes-bug: #1800627
Change-Id: Ica698b6a70a128522c2c2de76a69e59207fd60ac
(cherry picked from commit 67f2f61395158008381229479377f67322fab11a)
(cherry picked from commit a65c2b09746fe95d31c102d99c8e7674cddc82be)
",git fetch https://review.opendev.org/openstack/manila refs/changes/65/626865/6 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-ganesha-allow-access-for-all-ips-09773a79dc76ad44.yaml', 'manila/share/drivers/ganesha/__init__.py', 'manila/share/drivers/ganesha/utils.py', 'manila/tests/share/drivers/ganesha/test_utils.py']",4,65e69f8e2e7c01f669224c8dd511bc581ca9168c,bug/1800627-stable/rocky-stable/queens," @ddt.data({'rule': {'access_type': 'ip', 'access_level': 'rw', 'access_to': '10.10.10.12'}, 'result': {'access_type': 'ip', 'access_level': 'rw', 'access_to': '10.10.10.12'}, }, {'rule': {'access_type': 'ip', 'access_level': 'rw', 'access_to': '0.0.0.0/0'}, 'result': {'access_type': 'ip', 'access_level': 'rw', 'access_to': '0.0.0.0'}, }, ) @ddt.unpack def test_fixup_access_rules(self, rule, result): self.assertEqual(result, ganesha_utils.fixup_access_rule(rule)) ",,43,0
openstack%2Frpm-packaging~master~I53a5b225533081035fb45da5e98c57ddb1aea08b,openstack/rpm-packaging,master,I53a5b225533081035fb45da5e98c57ddb1aea08b,Add octavia-tempest-plugin,MERGED,2019-02-11 14:40:48.000000000,2019-02-12 14:01:46.000000000,2019-02-12 14:01:45.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 14:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1a05ea1131259f97e271bf2da35ed55a85a5c94f', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}, {'number': 2, 'created': '2019-02-12 10:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8e640d180b08436f6dac370b7c7f9e3656458173', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}, {'number': 3, 'created': '2019-02-12 11:15:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9ccea4f856a17d50960bc184d0f2166cd737cffc', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}, {'number': 4, 'created': '2019-02-12 12:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/46a471d7b12923d42adb6a44306c43d8379d055f', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}, {'number': 5, 'created': '2019-02-12 12:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f36da3e5c7fc4da2783109839aa2dae38b3e03f7', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}, {'number': 6, 'created': '2019-02-12 12:30:29.000000000', 'files': ['openstack/octavia-tempest-plugin/octavia-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0850adbaecfffa696afcfc0bc60f08dd6fa309a9', 'message': 'Add octavia-tempest-plugin\n\nChange-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b\n'}]",5,636138,0850adbaecfffa696afcfc0bc60f08dd6fa309a9,30,6,6,7102,,,0,"Add octavia-tempest-plugin

Change-Id: I53a5b225533081035fb45da5e98c57ddb1aea08b
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/38/636138/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/octavia-tempest-plugin/octavia-tempest-plugin.spec.j2'],1,1a05ea1131259f97e271bf2da35ed55a85a5c94f,636138,"{% set pypi_name = 'octavia-tempest-plugin' %} {% set source=fetch_source('https://tarballs.openstack.org/octavia-tempest-plugin/octavia-tempest-plugin-0.2.0.tar.gz') %} {% set upstream_version = upstream_version() %} {% set rpm_release = '1' %} Name: {{ py2pkg('octavia-tempest-plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for the Octavia project License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/{{ pypi_name }} Source0: {{ source|basename }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('Tempest') }} Requires: {{ py2pkg('cryptography') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('oslo.log') }} Requires: {{ py2pkg('oslo.utils') }} Requires: {{ py2pkg('oslotest') }} Requires: {{ py2pkg('pbr') }} Requires: {{ py2pkg('python-dateutil') }} Requires: {{ py2pkg('requests') }} Requires: {{ py2pkg('six') }} Requires: {{ py2pkg('tenacity') }} BuildArch: noarch %python_subpackages %description This project contains the Tempest plugin for the Octavia project for OpenStack Load Balancing. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{python_build} %install %{python_install} %files %{python_files} %license LICENSE %doc README.rst %{python2_sitelib}/octavia_tempest_plugin %{python2_sitelib}/*.egg-info %changelog ",,51,0
openstack%2Fnova~master~I54675f701d313cd65c51387e7a68671ba3a0240a,openstack/nova,master,I54675f701d313cd65c51387e7a68671ba3a0240a,Don't change volume status to `in-use` when attach to shelved vm.,NEW,2018-12-24 03:33:11.000000000,2019-02-12 13:51:50.000000000,,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-24 03:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8679d9a4f0ae2603b328c1f3aa6ef22f08f54ed5', 'message': ""WIP Don't change volume status to `in-use` when attach to shelved vm.\n\nChange-Id: I54675f701d313cd65c51387e7a68671ba3a0240a\nCloses-bug: #1809623\n""}, {'number': 2, 'created': '2019-01-31 09:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09ab457746da1292c4ff5083359b01837c57d0ca', 'message': ""WIP Don't change volume status to `in-use` when attach to shelved vm.\n\nChange-Id: I54675f701d313cd65c51387e7a68671ba3a0240a\nCloses-bug: #1809623\n""}, {'number': 3, 'created': '2019-02-01 02:24:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8ca55b4ecd93ea85e79409f52fc30e23c7a6cc1f', 'message': ""Don't change volume status to `in-use` when attach to shelved vm.\n\nWhen attach volume to a shelved instance,\nthe volume should be kept in ``reserved``\nstatus to be consistant to the behavior\nof shelving instances.\n\nChange-Id: I54675f701d313cd65c51387e7a68671ba3a0240a\nCloses-bug: #1809623\n""}, {'number': 4, 'created': '2019-02-11 01:51:21.000000000', 'files': ['nova/tests/unit/compute/test_compute.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1d5ca68fc0002f9134a9b4caf99a5061c2a433dc', 'message': ""Don't change volume status to `in-use` when attach to shelved vm.\n\nWhen attach volume to a shelved instance,\nthe volume should be kept in ``reserved``\nstatus to be consistant to the behavior\nof shelving instances.\n\nChange-Id: I54675f701d313cd65c51387e7a68671ba3a0240a\nCloses-bug: #1809623\n""}]",0,627096,1d5ca68fc0002f9134a9b4caf99a5061c2a433dc,63,12,4,15888,,,0,"Don't change volume status to `in-use` when attach to shelved vm.

When attach volume to a shelved instance,
the volume should be kept in ``reserved``
status to be consistant to the behavior
of shelving instances.

Change-Id: I54675f701d313cd65c51387e7a68671ba3a0240a
Closes-bug: #1809623
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/627096/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,8679d9a4f0ae2603b328c1f3aa6ef22f08f54ed5,bug/1809623, if not attachment_id:," if attachment_id: # Normally we wouldn't complete an attachment without a host # connector, but we do this to make the volume status change # to ""in-use"" to maintain the API semantics with the old flow. # When unshelving the instance, the compute service will deal # with this disconnected attachment. self.volume_api.attachment_complete(context, attachment_id) else:",1,8
openstack%2Ftripleo-heat-templates~master~I453c65844f262b4544e47b721962604eb976f056,openstack/tripleo-heat-templates,master,I453c65844f262b4544e47b721962604eb976f056,Validate that a detected ceph-disk is member of a cluster before considering that we need ceph-osd package,ABANDONED,2018-09-28 15:00:35.000000000,2019-02-12 13:45:02.000000000,,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10873}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27419}]","[{'number': 1, 'created': '2018-09-28 15:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3899b87fd0b5ec8e46233e4adb2f80802b61da76', 'message': 'Validate that a detected ceph-disk is member of a cluster\nbefore considering that we need ceph-osd package\n\nChange-Id: I453c65844f262b4544e47b721962604eb976f056\nCloses-Bug: bug/1795011\n'}, {'number': 2, 'created': '2018-09-28 21:02:13.000000000', 'files': ['extraconfig/tasks/pacemaker_common_functions.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/46fc25b2dc5d50b9be897c59a057f2e75ae37e4f', 'message': 'Validate that a detected ceph-disk is member of a cluster\nbefore considering that we need ceph-osd package\n\nChange-Id: I453c65844f262b4544e47b721962604eb976f056\nCloses-Bug: #1795011\n'}]",2,606105,46fc25b2dc5d50b9be897c59a057f2e75ae37e4f,15,10,2,27419,,,0,"Validate that a detected ceph-disk is member of a cluster
before considering that we need ceph-osd package

Change-Id: I453c65844f262b4544e47b721962604eb976f056
Closes-Bug: #1795011
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/05/606105/2 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/pacemaker_common_functions.sh'],1,3899b87fd0b5ec8e46233e4adb2f80802b61da76,bug/1795011, if ceph-disk list |& grep -qP 'ceph data((?!unknown cluster).)*$'; then," if ceph-disk list |& grep -q ""ceph data""; then",1,1
openstack%2Fcharm-ceph-radosgw~master~I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21,openstack/charm-ceph-radosgw,master,I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21,Add support for radosgw upgrades,MERGED,2019-02-12 12:00:58.000000000,2019-02-12 13:44:10.000000000,2019-02-12 13:44:09.000000000,"[{'_account_id': 13686}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 12:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/464e39948fabc480b1fcf7ad726462ecbd3314b6', 'message': 'Add support for radosgw upgrades\n\nSync charms.ceph and use helper functions to determine\nwhether any changes in the source configuration option\nare a supported upgrade path.\n\nIf an upgrade path is detected then upgrade via apt_install\nwith the full list of required packages for the radosgw to\nforce an upgrade.\n\nChange-Id: I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21\nCloses-Bug: 1539335\n'}, {'number': 2, 'created': '2019-02-12 12:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/6519163b0db5ac62b4e2e8dbc4b94fda3166e27c', 'message': 'Add support for radosgw upgrades\n\nSync charms.ceph and use helper functions to determine\nwhether any changes in the source configuration option\nare a supported upgrade path.\n\nIf an upgrade path is detected then upgrade via apt_install\nwith the full list of required packages for the radosgw to\nforce an upgrade.\n\nChange-Id: I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21\nCloses-Bug: 1539335\n'}, {'number': 3, 'created': '2019-02-12 12:32:33.000000000', 'files': ['hooks/hooks.py', 'lib/.keep', 'lib/ceph/broker.py', 'Makefile', 'lib/ceph/utils.py', 'unit_tests/test_ceph.py', 'unit_tests/test_hooks.py', 'lib/ceph/__init__.py', 'hooks/ceph_rgw.py', 'lib/ceph/crush_utils.py', '.pydevproject', 'hooks/install_deps'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/0f3203b18cb62af15ea394fe7f80ef68b1b578da', 'message': 'Add support for radosgw upgrades\n\nSync charms.ceph and use helper functions to determine\nwhether any changes in the source configuration option\nare a supported upgrade path.\n\nIf an upgrade path is detected then upgrade via apt_install\nwith the full list of required packages for the radosgw to\nforce an upgrade.\n\nChange-Id: I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21\nCloses-Bug: 1539335\n'}]",0,636316,0f3203b18cb62af15ea394fe7f80ef68b1b578da,12,4,3,935,,,0,"Add support for radosgw upgrades

Sync charms.ceph and use helper functions to determine
whether any changes in the source configuration option
are a supported upgrade path.

If an upgrade path is detected then upgrade via apt_install
with the full list of required packages for the radosgw to
force an upgrade.

Change-Id: I48a8b5d14ad6ac11af57ddf0260a4a41744e7e21
Closes-Bug: 1539335
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/16/636316/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'lib/.keep', 'lib/ceph/broker.py', 'unit_tests/test_hooks.py', 'Makefile', 'lib/ceph/__init__.py', 'hooks/ceph_rgw.py', 'lib/ceph/crush_utils.py', 'lib/ceph/utils.py', '.pydevproject', 'unit_tests/test_ceph.py']",11,464e39948fabc480b1fcf7ad726462ecbd3314b6,bug/1666880,import ceph_rgw as ceph # noqa,import ceph # noqa,3877,23
openstack%2Fproject-config~master~I758d718cdf468a3b9c9b78d86403ca2b64966433,openstack/project-config,master,I758d718cdf468a3b9c9b78d86403ca2b64966433,swift: gerritbot alert on all the branches,MERGED,2019-02-08 18:03:26.000000000,2019-02-12 13:32:15.000000000,2019-02-12 13:32:15.000000000,"[{'_account_id': 6547}, {'_account_id': 7069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 18:03:26.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c2fb07de589d00a812e6aa1fd4d87069f54ae7c9', 'message': 'swift: gerritbot alert on all the branches\n\nChange-Id: I758d718cdf468a3b9c9b78d86403ca2b64966433\n'}]",0,635905,c2fb07de589d00a812e6aa1fd4d87069f54ae7c9,7,3,1,330,,,0,"swift: gerritbot alert on all the branches

Change-Id: I758d718cdf468a3b9c9b78d86403ca2b64966433
",git fetch https://review.opendev.org/openstack/project-config refs/changes/05/635905/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,c2fb07de589d00a812e6aa1fd4d87069f54ae7c9,all_the_branches, - ^.*, - master - feature/deep - feature/deep-review,1,3
openstack%2Fvitrage-specs~master~Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c,openstack/vitrage-specs,master,Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c,add a new service list api,MERGED,2019-01-30 13:52:14.000000000,2019-02-12 13:25:13.000000000,2019-02-12 13:25:13.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}, {'_account_id': 26339}]","[{'number': 1, 'created': '2019-01-30 13:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/24f9fead1a1ee42243ce147b1ea1698a4c032946', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 2, 'created': '2019-01-30 14:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/1d6da021fd90da5a025a2c87c43057868331404b', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 3, 'created': '2019-01-31 08:27:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/da01823e72e459fde03ed61bb3721081defe42a2', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 4, 'created': '2019-02-03 07:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/7aa086eb6de4f454ea2581891fee689b9d0540c0', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 5, 'created': '2019-02-03 09:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/8b4ea7024b578e58e3f5084b831376d6bab26345', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 6, 'created': '2019-02-11 08:54:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/1f98c0357dd4ef469112bb5fb5041d37e71130d2', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}, {'number': 7, 'created': '2019-02-12 12:32:30.000000000', 'files': ['specs/stein/approved/services_list_and_statuses.rst'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/d1e2cf07fb979ab07a03c0cbfe6550730dc77a7c', 'message': 'add a new service list api\n\nChange-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c\n'}]",16,633946,d1e2cf07fb979ab07a03c0cbfe6550730dc77a7c,28,6,7,19134,,,0,"add a new service list api

Change-Id: Ib5fb86fd1f94c66604e233bfd1f56bb339b8331c
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/46/633946/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/approved/services_list_and_statuses.rst'],1,24f9fead1a1ee42243ce147b1ea1698a4c032946,eyalb/services,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ===================== Parametrized Template ===================== StoryBoard link: https://storyboard.openstack.org/#!/story/2004897 This spec adds a new api for listing all vitrage services and their status. Problem description =================== In an enterprise cloud environment , Vitrage will have multiple services deployed on multiple hosts. This will enable an admin to find these services and get details like: * what is the node on which vitrage service is running, * what is the running status of vitrage service. * How long the vitrage services are running successfully. Proposed change =============== A new api command ``vitrage service list`` will be added that will list all the vitrage service that are currently running where are they running, their status and how long are they running. Example of a response --------------------- .. code-block:: json { ""services"": [ { ""name"": ""vitrage-graph"", ""hostname"": ""controller-1"", ""updated"": ""2019-01-30T12:34:14"", ""status"": ""up"" }, { ""name"": ""vitrage-api"", ""hostname"": ""controller-1"", ""updated"": ""2019-01-30T12:34:05"", ""status"": ""up"" }, { ""name"": ""vitrage-notifier"", ""hostname"": ""controller-1"", ""updated"": ""2019-01-30T12:34:10"", ""status"": ""up"" } ] } CLI Example ----------- .. code-block:: console +---------------------------------+---------------------+--------+ | Name | Hostname | Updated At | Status | +---------------------------------+---------------------+--------+ | controller-1 | vitrage-graph | 2019-01-30T12:34:14 | up | | controller-1 | vitrage-api | 2019-01-30T12:34:05 | up | | controller-1 | vitrage-notifier | 2019-01-30T12:34:10 | up | +--------------+------------------+---------------------+--------+ **Note:** The Service list API feature is optional. The cloud operator must pre-install zookeeper or other tooz backend component. Otherwise, an exception will be raised when users call the service REST API. Alternatives ------------ If vitrage is running in k8s cluster then this api might be redundant. Since k8s handles pods health and topology. We might make the service api communicate with the k8s api in this case to get all vitrage services and their statuses. Data model impact ----------------- None. REST API impact --------------- New api will be added to vitrage to list the services Versioning impact ----------------- None Other end user impact --------------------- In order to support the api we will need a backend to store the information. We will use the tooz library that supports multiple backends see Tooz_. .. _Tooz: https://docs.openstack.org/tooz/latest/ Deployer impact --------------- The deployer must pre-install zookeeper or other tooz backend component In order to support the API. When deploying a container then hostname must be changed so api will be readable Developer impact ---------------- We need to think what to do in case of a container deployment. docker by default has a hostname of the container id but it can be changed. We might use an optional environment variable (e.g HOST_HOSTNAME) for host name if exist in case of a container that can be passed to the container. Horizon impact -------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: Eyal Work Items ---------- * add tooz support * add new API to vitrage * add `service list` to vitrage client * Documentation and tests Dependencies ============ Depends on the tooz library with a backend configured. Testing ======= Unit tests, functional tests and tempest tests Documentation Impact ==================== The new api will be documented References ========== None ",,170,0
openstack%2Fpython-vitrageclient~master~Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178,openstack/python-vitrageclient,master,Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178,add a new service list api,MERGED,2019-02-03 13:08:22.000000000,2019-02-12 13:24:55.000000000,2019-02-12 13:24:54.000000000,"[{'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}, {'_account_id': 26339}]","[{'number': 1, 'created': '2019-02-03 13:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/69c12fc4d6d84f7ef929e2ccb3b4c6b486aa0004', 'message': 'add a new service list api\n\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 2, 'created': '2019-02-03 13:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/182d2466b134065d03f1411c5d695dc23a6151fe', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 3, 'created': '2019-02-03 13:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/ddf2dc8ba40f5d8ede1f62564937a2eb8ac66aa2', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 4, 'created': '2019-02-03 13:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/c3021757a31dfc71d137f2759e551005e4307e2e', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 5, 'created': '2019-02-06 12:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/ade6b708181f2d3c02dc6148b269e9cecbe71e88', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 6, 'created': '2019-02-06 15:45:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/b1db0a8e62e34c5371b059802348ff93e6f9f8c8', 'message': 'WIP: add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 7, 'created': '2019-02-10 12:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/3507f9408c1e4f30bfd76ec04de11c3a09857975', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}, {'number': 8, 'created': '2019-02-12 12:31:40.000000000', 'files': ['doc/source/contributor/cli.rst', 'vitrageclient/shell.py', 'releasenotes/notes/add_service_list-0d0720c6bd41e10e.yaml', 'tools/vitrage.bash_completion', 'vitrageclient/v1/client.py', 'openstack-common.conf', 'vitrageclient/v1/cli/service.py', 'setup.cfg', 'vitrageclient/v1/service.py'], 'web_link': 'https://opendev.org/openstack/python-vitrageclient/commit/c293cbd2d5f680b2edc1920deeb950fde65ad062', 'message': 'add a new service list api\n\nStory: 2004897\nTask: 29205\nChange-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178\n'}]",9,634599,c293cbd2d5f680b2edc1920deeb950fde65ad062,33,5,8,19134,,,0,"add a new service list api

Story: 2004897
Task: 29205
Change-Id: Iecb2ae810dd2a6a6b544c2ed7dbfe6288f393178
",git fetch https://review.opendev.org/openstack/python-vitrageclient refs/changes/99/634599/8 && git format-patch -1 --stdout FETCH_HEAD,"['vitrageclient/shell.py', 'vitrageclient/v1/client.py', 'openstack-common.conf', 'vitrageclient/v1/cli/service.py', 'setup.cfg', 'vitrageclient/v1/service.py']",6,69c12fc4d6d84f7ef929e2ccb3b4c6b486aa0004,eyalb/services,"# Copyright 2019 - Nokia Corporation # # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # # http://www.apache.org/licenses/LICENSE-2.0 # # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class Service(object): url = 'v1/service/' def __init__(self, api): self.api = api def list(self): """"""Get service list"""""" return self.api.get(self.url).json() ",,63,7
openstack%2Fkarbor-dashboard~master~Ic56eabcd3b353178ccbbd8cc7f69dee7ccd2b9ce,openstack/karbor-dashboard,master,Ic56eabcd3b353178ccbbd8cc7f69dee7ccd2b9ce,Add icalendar to requirements.txt,NEW,2018-08-24 09:19:19.000000000,2019-02-12 12:58:13.000000000,,"[{'_account_id': 1736}, {'_account_id': 21224}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-24 09:19:19.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/karbor-dashboard/commit/ddd5948c28921affc75e2b6151a564bb217231d4', 'message': 'Add icalendar to requirements.txt\n\nkolla deploy karbor-dashboard failed due to:\n""No module named icalendar.cal"". we need to add icalendar into\nrequirements.txt file.\n\nChange-Id: Ic56eabcd3b353178ccbbd8cc7f69dee7ccd2b9ce\nCloses-Bug: #1787040\n'}]",0,596259,ddd5948c28921affc75e2b6151a564bb217231d4,5,3,1,19779,,,0,"Add icalendar to requirements.txt

kolla deploy karbor-dashboard failed due to:
""No module named icalendar.cal"". we need to add icalendar into
requirements.txt file.

Change-Id: Ic56eabcd3b353178ccbbd8cc7f69dee7ccd2b9ce
Closes-Bug: #1787040
",git fetch https://review.opendev.org/openstack/karbor-dashboard refs/changes/59/596259/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,ddd5948c28921affc75e2b6151a564bb217231d4,bug/1787040,icalendar>=4.0.2,,1,0
openstack%2Fmonasca-tempest-plugin~master~I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f,openstack/monasca-tempest-plugin,master,I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f,Recognize config options from [service_available],MERGED,2019-02-01 09:45:49.000000000,2019-02-12 12:53:41.000000000,2019-02-12 12:53:41.000000000,"[{'_account_id': 7102}, {'_account_id': 10311}, {'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-01 09:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/e0679f5086c8e3a0eeb831d822de75d4c34c4701', 'message': 'Recognize config option [service_available]monasca\n\nCurrently, setting [service_available]monasca in tempest.conf does not\nhave any effect. That can lead to the situation where the\nmonasca-tempest-plugin is installed but monasca is not configured\nwhich results in all monasca tempest tests failing.\nWith this patch, setting [service_available]monasca to False will skip\nall available tests for monasca.\n\nChange-Id: I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f\nStory: 2004917\nTask: 29277\n'}, {'number': 2, 'created': '2019-02-04 09:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/0c36f44ccae4640662350705115bbe10dbaf42f6', 'message': 'Recognize config options from [service_available]\n\nCurrently, settings in [service_available] for Monasca in tempest.conf\ndo not have any effect. That can lead to the situation where the\nmonasca-tempest-plugin is installed but monasca is not configured\nwhich results in all monasca tempest tests failing.\nWith this patch, setting:\n\n- [service_available]monasca\n- [service_available]logs\n- [service_available]logs-search\n\nto ""False"" will skip all available tests for monasca.\nIf only monasca-api is available (no monasca-log-api and/or\nelasticsearch), [service_available]monasca can be set to ""True"" and\nthe other 2 options (""logs"" and ""logs-search"") to ""False"" so only the\nmonasca-api tempest tests are executed.\n\nChange-Id: I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f\nStory: 2004917\nTask: 29277\n'}, {'number': 3, 'created': '2019-02-04 12:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/e27acd715ecf758a0cf61aa9298d2c98a10ca63e', 'message': 'Recognize config options from [service_available]\n\nCurrently, settings in [service_available] for Monasca in tempest.conf\ndo not have any effect. That can lead to the situation where the\nmonasca-tempest-plugin is installed but monasca is not configured\nwhich results in all monasca tempest tests failing.\nWith this patch, setting:\n\n- [service_available]monasca\n- [service_available]logs\n- [service_available]logs-search\n\nto ""False"" will skip all available tests for monasca.\nIf only monasca-api is available (no monasca-log-api and/or\nelasticsearch), [service_available]monasca can be set to ""True"" and\nthe other 2 options (""logs"" and ""logs-search"") to ""False"" so only the\nmonasca-api tempest tests are executed.\n\nDepends-On: https://review.openstack.org/634308\nChange-Id: I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f\nStory: 2004917\nTask: 29277\n'}, {'number': 4, 'created': '2019-02-11 05:41:22.000000000', 'files': ['monasca_tempest_tests/tests/api/base.py', 'monasca_tempest_tests/tests/log_api/test_unicode.py', 'monasca_tempest_tests/tests/log_api/base.py', 'monasca_tempest_tests/tests/log_api/test_single.py'], 'web_link': 'https://opendev.org/openstack/monasca-tempest-plugin/commit/2bb88453ed7e18a812e7e4c17256ea92de8ffe9c', 'message': 'Recognize config options from [service_available]\n\nCurrently, settings in [service_available] for Monasca in tempest.conf\ndo not have any effect. That can lead to the situation where the\nmonasca-tempest-plugin is installed but monasca is not configured\nwhich results in all monasca tempest tests failing.\nWith this patch, setting:\n\n- [service_available]monasca\n- [service_available]logs\n- [service_available]logs-search\n\nto ""False"" will skip all available tests for monasca.\nIf only monasca-api is available (no monasca-log-api and/or\nelasticsearch), [service_available]monasca can be set to ""True"" and\nthe other 2 options (""logs"" and ""logs-search"") to ""False"" so only the\nmonasca-api tempest tests are executed.\n\nDepends-On: https://review.openstack.org/634308\nChange-Id: I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f\nStory: 2004917\nTask: 29277\n'}]",0,634386,2bb88453ed7e18a812e7e4c17256ea92de8ffe9c,26,4,4,7102,,,0,"Recognize config options from [service_available]

Currently, settings in [service_available] for Monasca in tempest.conf
do not have any effect. That can lead to the situation where the
monasca-tempest-plugin is installed but monasca is not configured
which results in all monasca tempest tests failing.
With this patch, setting:

- [service_available]monasca
- [service_available]logs
- [service_available]logs-search

to ""False"" will skip all available tests for monasca.
If only monasca-api is available (no monasca-log-api and/or
elasticsearch), [service_available]monasca can be set to ""True"" and
the other 2 options (""logs"" and ""logs-search"") to ""False"" so only the
monasca-api tempest tests are executed.

Depends-On: https://review.openstack.org/634308
Change-Id: I1f0cbb95765ae5fc6dca0da7af8ab56d2daf9a7f
Story: 2004917
Task: 29277
",git fetch https://review.opendev.org/openstack/monasca-tempest-plugin refs/changes/86/634386/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_tempest_tests/tests/api/base.py'],1,e0679f5086c8e3a0eeb831d822de75d4c34c4701,634386," if not CONF.service_available.monasca: raise cls.skipException(""Monasca support is required"")",,2,0
openstack%2Fcharm-aodh~master~Ia1c6e2f817b95a831550dfde89ecb54b13026fbc,openstack/charm-aodh,master,Ia1c6e2f817b95a831550dfde89ecb54b13026fbc,Add package version for stein,MERGED,2019-01-28 15:45:39.000000000,2019-02-12 12:52:54.000000000,2019-02-12 12:52:54.000000000,"[{'_account_id': 11805}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-28 15:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/b00865bc16ad7db3201a9b5e520f42460c93767f', 'message': 'Add package version for stein\n\nChange-Id: Ia1c6e2f817b95a831550dfde89ecb54b13026fbc\n'}, {'number': 2, 'created': '2019-02-08 21:42:07.000000000', 'files': ['src/lib/charm/openstack/aodh.py'], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/afb54b422dc037113d24e84dbcec7accf904f3b1', 'message': 'Add package version for stein\n\nChange-Id: Ia1c6e2f817b95a831550dfde89ecb54b13026fbc\n'}]",0,633533,afb54b422dc037113d24e84dbcec7accf904f3b1,28,4,2,11805,,,0,"Add package version for stein

Change-Id: Ia1c6e2f817b95a831550dfde89ecb54b13026fbc
",git fetch https://review.opendev.org/openstack/charm-aodh refs/changes/33/633533/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/aodh.py'],1,b00865bc16ad7db3201a9b5e520f42460c93767f,charms-stein," ('8', 'stein'),",,1,0
openstack%2Fblazar~master~I0e089c764e81894f065872e7b44a4ea8cfa49bd6,openstack/blazar,master,I0e089c764e81894f065872e7b44a4ea8cfa49bd6,Use hypervisor_hostname for host name,MERGED,2019-02-06 07:37:40.000000000,2019-02-12 12:49:56.000000000,2019-02-12 12:49:55.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 07:37:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/51a0335ee5cb77d8be29b7b3d9c8d129ce498881', 'message': 'Use hypervisor_hostname for host name\n\nIn Nova, ""service host"" is where nova-compute is running and\n""hypervisor_hostname"" represent each physical node that the virt\ndriver reports. They can be different in some of the hypervisor\nbackends where one nova-compute corresponds to multiple physical\nnodes. Blazar holds the values separately as ""service_name"" and\n""hypervisor_hostname"".\n\nSince Nova aggreate is associated to nova-compute service, we used\n""service_name"" with aggregate solution for reservation. However, now\nwe can use ""hypervisor_hostname"" with placement api solution for\nreservation. This patch switches it.\n\nChange-Id: I0e089c764e81894f065872e7b44a4ea8cfa49bd6\nCloses-Bug: #1814594\n'}, {'number': 2, 'created': '2019-02-12 10:55:47.000000000', 'files': ['blazar/plugins/oshosts/host_plugin.py', 'blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/plugins/instances/instance_plugin.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/7dc9a6a7bfe35ffb204a24ab4ad8e32d4e3496ea', 'message': 'Use hypervisor_hostname for host name\n\nIn Nova, ""service host"" is where nova-compute is running and\n""hypervisor_hostname"" represent each physical node that the virt\ndriver reports. They can be different in some of the hypervisor\nbackends where one nova-compute corresponds to multiple physical\nnodes. Blazar holds the values separately as ""service_name"" and\n""hypervisor_hostname"".\n\nSince Nova aggreate is associated to nova-compute service, we used\n""service_name"" with aggregate solution for reservation. However, now\nwe can use ""hypervisor_hostname"" with placement api solution for\nreservation. This patch switches it.\n\nChange-Id: I0e089c764e81894f065872e7b44a4ea8cfa49bd6\nCloses-Bug: #1814594\n'}]",0,635106,7dc9a6a7bfe35ffb204a24ab4ad8e32d4e3496ea,13,3,2,25625,,,0,"Use hypervisor_hostname for host name

In Nova, ""service host"" is where nova-compute is running and
""hypervisor_hostname"" represent each physical node that the virt
driver reports. They can be different in some of the hypervisor
backends where one nova-compute corresponds to multiple physical
nodes. Blazar holds the values separately as ""service_name"" and
""hypervisor_hostname"".

Since Nova aggreate is associated to nova-compute service, we used
""service_name"" with aggregate solution for reservation. However, now
we can use ""hypervisor_hostname"" with placement api solution for
reservation. This patch switches it.

Change-Id: I0e089c764e81894f065872e7b44a4ea8cfa49bd6
Closes-Bug: #1814594
",git fetch https://review.opendev.org/openstack/blazar refs/changes/06/635106/2 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/plugins/oshosts/host_plugin.py', 'blazar/tests/plugins/instances/test_instance_plugin.py', 'blazar/plugins/instances/instance_plugin.py']",3,51a0335ee5cb77d8be29b7b3d9c8d129ce498881,bug/1814594," host['hypervisor_hostname'], reservation['id'], 1) host['hypervisor_hostname'], reservation_id, 1) host['hypervisor_hostname'], reservation_id) host['hypervisor_hostname'], reservation['id']) new_host['hypervisor_hostname'], reservation['id'], 1)"," host['service_name'], reservation['id'], 1) host['service_name'], reservation_id, 1) host['service_name'], reservation_id) host['service_name'], reservation['id']) new_host['service_name'], reservation['id'], 1)",18,13
openstack%2Fcharm-designate~master~Idf48d36581fad1b5c1e3e92a4085e5519558c36b,openstack/charm-designate,master,Idf48d36581fad1b5c1e3e92a4085e5519558c36b,Add package version for stein,MERGED,2019-01-29 16:11:40.000000000,2019-02-12 12:46:48.000000000,2019-02-12 12:46:48.000000000,"[{'_account_id': 11805}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-29 16:11:40.000000000', 'files': ['src/lib/charm/openstack/designate.py'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/7b2dfd95d01e56a394687a470b0cf83484f3efad', 'message': 'Add package version for stein\n\nChange-Id: Idf48d36581fad1b5c1e3e92a4085e5519558c36b\n'}]",0,633773,7b2dfd95d01e56a394687a470b0cf83484f3efad,12,4,1,11805,,,0,"Add package version for stein

Change-Id: Idf48d36581fad1b5c1e3e92a4085e5519558c36b
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/73/633773/1 && git format-patch -1 --stdout FETCH_HEAD,['src/lib/charm/openstack/designate.py'],1,7b2dfd95d01e56a394687a470b0cf83484f3efad,charms-stein," ('8', 'stein'),",,1,0
openstack%2Fcharm-glance-simplestreams-sync~master~Ibb46dfa766b12aedea90f823d3964c569bdfcb01,openstack/charm-glance-simplestreams-sync,master,Ibb46dfa766b12aedea90f823d3964c569bdfcb01,Migrate charm to Python3,MERGED,2019-02-04 19:18:11.000000000,2019-02-12 12:45:37.000000000,2019-02-12 12:45:37.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 19:18:11.000000000', 'files': ['hooks/hooks.py', 'unit_tests/test_utils.py', 'unit_tests/test_hooks.py', '.zuul.yaml', 'unit_tests/__init__.py', 'hooks/install', 'hooks/charmhelpers', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-glance-simplestreams-sync/commit/6aa32f2d67496dd4337c90c94613617ebae3f54a', 'message': 'Migrate charm to Python3\n\nChange-Id: Ibb46dfa766b12aedea90f823d3964c569bdfcb01\n'}]",0,634781,6aa32f2d67496dd4337c90c94613617ebae3f54a,9,4,1,20870,,,0,"Migrate charm to Python3

Change-Id: Ibb46dfa766b12aedea90f823d3964c569bdfcb01
",git fetch https://review.opendev.org/openstack/charm-glance-simplestreams-sync refs/changes/81/634781/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/hooks.py', 'unit_tests/test_utils.py', 'unit_tests/test_hooks.py', '.zuul.yaml', 'unit_tests/__init__.py', 'hooks/install', 'hooks/charmhelpers', 'tox.ini']",8,6aa32f2d67496dd4337c90c94613617ebae3f54a,ensure-py3,"envlist = pep8,py3{5,6}# charm is NOT PY27 compatible commands = /bin/true","envlist = pep8,py27# charm is NOT Py3 compatible commands = /bin/true",48,22
openstack%2Fcharm-cinder~master~I35599bae8a94724869a36c555ebfc6bf94384bd4,openstack/charm-cinder,master,I35599bae8a94724869a36c555ebfc6bf94384bd4,Add policy to allow owner to force delete volumes,MERGED,2019-02-07 19:43:21.000000000,2019-02-12 12:44:31.000000000,2019-02-12 12:44:31.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 19:43:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/0032d6f2a12bba9661181441c29522479c33cffc', 'message': 'Add policy to allow owner to force delete volumes\n\nThe default in cinder is to only allow the admin to\nforce delete a volume; this change allows the\nadmin_or_owner to force delete a volume.\n\nThis was previously authored by Chris MacNaughton in change\nI703a21b68186059a63f0d06d88cd2528e821f3d3\nAnd then reverted in change\nI77f9351da8516e5af40fea57400101e6dd16b528\n\nThis change includes gating on the OpenStack version.\n\nChange-Id: I35599bae8a94724869a36c555ebfc6bf94384bd4\nCo-Authored-By: Chris MacNaughton <chris.macnaughton@canonical.com>\nCloses-Bug: #1782008\n'}, {'number': 2, 'created': '2019-02-07 23:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/7140f7331ce102234e2cb16df7363784aed29366', 'message': 'Add policy to allow owner to force delete volumes\n\nThe default in cinder is to only allow the admin to\nforce delete a volume; this change allows the\nadmin_or_owner to force delete a volume.\n\nThis was previously authored by Chris MacNaughton in change\nI703a21b68186059a63f0d06d88cd2528e821f3d3\nAnd then reverted in change\nI77f9351da8516e5af40fea57400101e6dd16b528\n\nThis change includes gating on the OpenStack version.\n\nChange-Id: I35599bae8a94724869a36c555ebfc6bf94384bd4\nCo-Authored-By: Chris MacNaughton <chris.macnaughton@canonical.com>\nCloses-Bug: #1782008\n'}, {'number': 3, 'created': '2019-02-08 15:32:25.000000000', 'files': ['templates/queens/policy.json', 'tests/basic_deployment.py', 'hooks/cinder_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/26c0dec5f325c2117ff878c8052a6014771055ec', 'message': 'Add policy to allow owner to force delete volumes\n\nThe default in cinder is to only allow the admin to\nforce delete a volume; this change allows the\nadmin_or_owner to force delete a volume.\n\nThis was previously authored by Chris MacNaughton in change\nI703a21b68186059a63f0d06d88cd2528e821f3d3\nAnd then reverted in change\nI77f9351da8516e5af40fea57400101e6dd16b528\n\nThis change includes gating on the OpenStack version.\n\nChange-Id: I35599bae8a94724869a36c555ebfc6bf94384bd4\nCo-Authored-By: Chris MacNaughton <chris.macnaughton@canonical.com>\nCloses-Bug: #1782008\n'}]",1,635616,26c0dec5f325c2117ff878c8052a6014771055ec,21,4,3,20805,,,0,"Add policy to allow owner to force delete volumes

The default in cinder is to only allow the admin to
force delete a volume; this change allows the
admin_or_owner to force delete a volume.

This was previously authored by Chris MacNaughton in change
I703a21b68186059a63f0d06d88cd2528e821f3d3
And then reverted in change
I77f9351da8516e5af40fea57400101e6dd16b528

This change includes gating on the OpenStack version.

Change-Id: I35599bae8a94724869a36c555ebfc6bf94384bd4
Co-Authored-By: Chris MacNaughton <chris.macnaughton@canonical.com>
Closes-Bug: #1782008
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/16/635616/3 && git format-patch -1 --stdout FETCH_HEAD,"['templates/queens/policy.json', 'tests/basic_deployment.py', 'hooks/cinder_utils.py']",3,0032d6f2a12bba9661181441c29522479c33cffc,bug/1782008,"CINDER_POLICY_JSON = '%s/policy.json' % CINDER_CONF_DIR (CINDER_POLICY_JSON, { 'contexts': [], 'services': ['cinder-api'] }), release = release or os_release('cinder-common', base='icehouse') if release and CompareOpenStackReleases(release) < 'queens': resource_map.pop(CINDER_POLICY_JSON) ",,168,0
openstack%2Fvitrage~master~Ibed548118473902ed4bf7028aad854ebd1cb84bf,openstack/vitrage,master,Ibed548118473902ed4bf7028aad854ebd1cb84bf,Document version 3 template format,MERGED,2019-02-07 14:31:13.000000000,2019-02-12 12:44:10.000000000,2019-02-12 12:44:10.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 14:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/d937464279b09a2427c2b734041055b586d02545', 'message': 'Document version 3 template format\n\n - Added vitrage-templates.rst and renamed the previous file to v2.\n - Release notes\n\nChange-Id: Ibed548118473902ed4bf7028aad854ebd1cb84bf\nStory: 2004871\nTask: 29128\n'}, {'number': 2, 'created': '2019-02-07 15:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/b36b0a98992bd39551437d15856c2ec70d42610d', 'message': 'Document version 3 template format\n\n - Added vitrage-templates.rst and renamed the previous file to v2.\n - Release notes\n\nChange-Id: Ibed548118473902ed4bf7028aad854ebd1cb84bf\nStory: 2004871\nTask: 29128\n'}, {'number': 3, 'created': '2019-02-12 08:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/d6ede7c749646fac7f3423b76230d280d64f20a2', 'message': 'Document version 3 template format\n\n - Added vitrage-templates.rst and renamed the previous file to v2.\n - Release notes\n\nChange-Id: Ibed548118473902ed4bf7028aad854ebd1cb84bf\nStory: 2004871\nTask: 29128\n'}, {'number': 4, 'created': '2019-02-12 12:00:13.000000000', 'files': ['doc/source/contributor/templates-loading.rst', 'doc/source/contributor/nova-notifier.rst', 'doc/source/index.rst', 'doc/source/contributor/scenario-evaluator.rst', 'doc/source/contributor/vitrage-templates.rst', 'doc/source/contributor/vitrage-template-format-v2.rst', 'doc/source/contributor/vitrage-first_steps.rst', 'releasenotes/notes/template_version_3-cd8a0775b2f2e7cd.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a2ce45c3c6c56f9105347617a4f99d13c064ff45', 'message': 'Document version 3 template format\n\n - Added vitrage-templates.rst and renamed the previous file to v2.\n - Release notes\n\nChange-Id: Ibed548118473902ed4bf7028aad854ebd1cb84bf\nStory: 2004871\nTask: 29128\n'}]",45,635521,a2ce45c3c6c56f9105347617a4f99d13c064ff45,20,5,4,19184,,,0,"Document version 3 template format

 - Added vitrage-templates.rst and renamed the previous file to v2.
 - Release notes

Change-Id: Ibed548118473902ed4bf7028aad854ebd1cb84bf
Story: 2004871
Task: 29128
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/21/635521/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/templates-loading.rst', 'doc/source/contributor/nova-notifier.rst', 'doc/source/index.rst', 'doc/source/contributor/scenario-evaluator.rst', 'doc/source/contributor/vitrage-templates.rst', 'doc/source/contributor/vitrage-template-format-v2.rst', 'doc/source/contributor/vitrage-first_steps.rst', 'releasenotes/notes/template_version_3-cd8a0775b2f2e7cd.yaml']",8,d937464279b09a2427c2b734041055b586d02545,idan_hefetz/short_template_format,"--- features: - Introduced template version 3, a shorter, more fluent template language. Overall template yaml appeareance improvment. `condition` definitions were revised, `relationships` declarations removed. ",,521,8
openstack%2Fcharm-neutron-api~master~I26db4433359cf8c9d23158d553c4805fd0526a1a,openstack/charm-neutron-api,master,I26db4433359cf8c9d23158d553c4805fd0526a1a,Use dns_domain_ports extension driver for >= queens,MERGED,2019-02-07 22:03:37.000000000,2019-02-12 12:40:14.000000000,2019-02-12 12:40:14.000000000,"[{'_account_id': 6737}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 22:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/df3d908c84c971660b3e4ec681fab37e9d4bad8e', 'message': 'Use dns_domain_ports extension driver for >= queens\n\nThe dns_domain_ports extension driver was introduced in Queens\nto allow setting a dns_domain on ports and having that\noverride the network dns_domain value. The new extension driver\ninherits from the old dns extension driver so it is safe to\nsimply replace it.\n\nChange-Id: I26db4433359cf8c9d23158d553c4805fd0526a1a\nCloses-Bug: #1815138\n'}, {'number': 2, 'created': '2019-02-08 09:08:24.000000000', 'files': ['hooks/neutron_api_context.py', 'tests/basic_deployment.py', 'unit_tests/test_neutron_api_context.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/4c842b134601a7ba077e9b8445ca297ab946f5d6', 'message': 'Use dns_domain_ports extension driver for >= queens\n\nThe dns_domain_ports extension driver was introduced in Queens\nto allow setting a dns_domain on ports and having that\noverride the network dns_domain value. The new extension driver\ninherits from the old dns extension driver so it is safe to\nsimply replace it.\n\nChange-Id: I26db4433359cf8c9d23158d553c4805fd0526a1a\nCloses-Bug: #1815138\n'}]",0,635667,4c842b134601a7ba077e9b8445ca297ab946f5d6,14,4,2,6737,,,0,"Use dns_domain_ports extension driver for >= queens

The dns_domain_ports extension driver was introduced in Queens
to allow setting a dns_domain on ports and having that
override the network dns_domain value. The new extension driver
inherits from the old dns extension driver so it is safe to
simply replace it.

Change-Id: I26db4433359cf8c9d23158d553c4805fd0526a1a
Closes-Bug: #1815138
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/67/635667/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/neutron_api_context.py', 'unit_tests/test_neutron_api_context.py']",2,df3d908c84c971660b3e4ec681fab37e9d4bad8e,bug/1815138," self.os_release.return_value = 'queens' with patch.object(napi_ctxt, '_ensure_packages'): ctxt = napi_ctxt() self.assertEqual('example.org.', ctxt['dns_domain']) self.assertEqual('port_security,dns_domain_ports', ctxt['extension_drivers']) ",,13,1
openstack%2Ftripleo-heat-templates~master~I3a1424f5e3f7e52256829c35e3a092f783e18479,openstack/tripleo-heat-templates,master,I3a1424f5e3f7e52256829c35e3a092f783e18479,Add support for transferring MariaDB data between nodes,MERGED,2019-01-17 12:21:59.000000000,2019-02-12 12:36:22.000000000,2019-02-12 12:36:22.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 18575}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-17 12:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/28d905de77e3485a18816497d6360c90687fdb43', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 2, 'created': '2019-01-17 12:51:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ce9fd3f32044ab36ebf89a7607373ec34c5275b1', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 3, 'created': '2019-01-17 17:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb492a515f6fe8eef596275df0d6ed40afb990ae', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 4, 'created': '2019-01-17 17:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7076f90d5a2944109de42ec593af3850d9887f19', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 5, 'created': '2019-01-18 15:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/70fc92f1b3cfbbc38b0a5246a506fd1ac5a776bb', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 6, 'created': '2019-01-22 13:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c4849e4be5ce87704d64b34714d3e14d102a4bc', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}, {'number': 7, 'created': '2019-02-06 13:16:17.000000000', 'files': ['docker/services/pacemaker/database/mysql.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9d115a3595f3ad89ce52a97c350418cab950272a', 'message': 'Add support for transferring MariaDB data between nodes\n\nChange-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479\nImplements: blueprint upgrades-with-os\n'}]",2,631478,9d115a3595f3ad89ce52a97c350418cab950272a,26,6,7,8042,,,0,"Add support for transferring MariaDB data between nodes

Change-Id: I3a1424f5e3f7e52256829c35e3a092f783e18479
Implements: blueprint upgrades-with-os
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/631478/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/pacemaker/database/mysql.yaml'],1,28d905de77e3485a18816497d6360c90687fdb43,bp/upgrades-with-os," MysqlUpgradeTransfer: type: boolean default: false external_upgrade_tasks: - when: - step|int == 1 - get_param: MysqlUpgradeTransfer tags: - never - system_upgrade_transfer_data block: - name: Transfer mysql data include_role: name: tripleo-transfer vars: tripleo_transfer_src_dir: /var/lib/mysql tripleo_transfer_src_host: ""{{hostvars[groups['overcloud'][0]]['mysql_short_node_names'][1]}}"" tripleo_transfer_dest_dir: /var/lib/mysql tripleo_transfer_dest_host: ""{{hostvars[groups['overcloud'][0]]['mysql_short_bootstrap_node_name']}}""",,19,0
openstack%2Fcharm-interface-ceph-client~master~I8a7f0bf47c39509eec71a286bd51ec53c58d7e0d,openstack/charm-interface-ceph-client,master,I8a7f0bf47c39509eec71a286bd51ec53c58d7e0d,Add request_access_to_group method,MERGED,2019-01-08 14:01:05.000000000,2019-02-12 12:31:13.000000000,2019-02-12 12:31:13.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 14:01:05.000000000', 'files': ['requires.py', 'unit_tests/test_requires.py'], 'web_link': 'https://opendev.org/openstack/charm-interface-ceph-client/commit/288bab66dd45a722622aa9d36d9cb02705eda546', 'message': 'Add request_access_to_group method\n\nAdd request_access_to_group method to allow a client to request\nceph permissions.\n\nChange-Id: I8a7f0bf47c39509eec71a286bd51ec53c58d7e0d\n'}]",0,629192,288bab66dd45a722622aa9d36d9cb02705eda546,7,3,1,12549,,,0,"Add request_access_to_group method

Add request_access_to_group method to allow a client to request
ceph permissions.

Change-Id: I8a7f0bf47c39509eec71a286bd51ec53c58d7e0d
",git fetch https://review.opendev.org/openstack/charm-interface-ceph-client refs/changes/92/629192/1 && git format-patch -1 --stdout FETCH_HEAD,"['requires.py', 'unit_tests/test_requires.py']",2,288bab66dd45a722622aa9d36d9cb02705eda546,feature/support-perm-reqs," def test_request_access_to_group_new_request(self): self.patch_kr('get_local', '{""ops"": []}') self.patch_kr('set_local') self.cr.request_access_to_group( 'volumes', key_name='cinder', object_prefix_permissions={'class-read': ['rbd_children']}, permission='rwx') ceph_broker_rq = self.send_request_if_needed.mock_calls[0][1][0] self.assertEqual( ceph_broker_rq.ops, [{ 'group': 'volumes', 'group-permission': 'rwx', 'name': 'cinder', 'namespace': None, 'object-prefix-permissions': {'class-read': ['rbd_children']}, 'op': 'add-permissions-to-key'}]) def test_request_access_to_group_existing_request(self): req = ( '{""api-version"": 1, ' '""ops"": [{""op"": ""create-pool"", ""name"": ""volumes"", ""replicas"": 3, ' '""pg_num"": null, ""weight"": null, ""group"": null, ' '""group-namespace"": null}], ' '""request-id"": ""9e34123e-fa0c-11e8-ad9c-fa163ed1cc55""}') self.patch_kr('get_local', req) self.cr.request_access_to_group( 'volumes', key_name='cinder', object_prefix_permissions={'class-read': ['rbd_children']}, permission='rwx') ceph_broker_rq = self.send_request_if_needed.mock_calls[0][1][0] self.assertEqual( ceph_broker_rq.ops, [ { 'op': 'create-pool', 'name': 'volumes', 'replicas': 3, 'group': None, 'group-namespace': None, 'pg_num': None, 'weight': None}, { 'group': 'volumes', 'group-permission': 'rwx', 'name': 'cinder', 'namespace': None, 'object-prefix-permissions': { 'class-read': ['rbd_children']}, 'op': 'add-permissions-to-key'}]) ",,82,0
openstack%2Fos-net-config~master~I9ac95b6d6d6c0fbd6417575a6c44309e857c1b25,openstack/os-net-config,master,I9ac95b6d6d6c0fbd6417575a6c44309e857c1b25,Update hacking version to latest,MERGED,2019-01-04 16:43:05.000000000,2019-02-12 12:25:11.000000000,2019-02-12 12:25:11.000000000,"[{'_account_id': 360}, {'_account_id': 18575}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 28614}]","[{'number': 1, 'created': '2019-01-04 16:43:05.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/1204fc5239f257b236bc3a5b4f911c5d7475fc06', 'message': 'Update hacking version to latest\n\nChange-Id: I9ac95b6d6d6c0fbd6417575a6c44309e857c1b25\n'}]",0,628605,1204fc5239f257b236bc3a5b4f911c5d7475fc06,10,6,1,21691,,,0,"Update hacking version to latest

Change-Id: I9ac95b6d6d6c0fbd6417575a6c44309e857c1b25
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/05/628605/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1204fc5239f257b236bc3a5b4f911c5d7475fc06,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking<0.11,>=0.10.2 # Apache-2.0",1,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~I9cc725c77fd9a2f9e55c4878cd2125f99f35c06d,openstack/tripleo-heat-templates,stable/rocky,I9cc725c77fd9a2f9e55c4878cd2125f99f35c06d,mysql: sync credentials in running container on password change,MERGED,2019-02-08 22:54:39.000000000,2019-02-12 12:25:08.000000000,2019-02-12 12:25:08.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 22:54:39.000000000', 'files': ['docker/services/database/mysql.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b476c1e9a58639b4510820b35964c4973fc7e984', 'message': ""mysql: sync credentials in running container on password change\n\nSince 8e67ec833173920ac60b5548a711885a4d28e16f, docker-puppet doesn't\nchange mysql password config file on password update. It only notifies\nof config change and paunch restarts some containers accordingly.\n\nIn non-HA mysql service, when a stack update changes the mysql password,\na docker-puppet task updates the root password config file at step 2.\n\nHowever, the mysql container is started before the docker-puppet task,\nwhich means that it gets the old root password config file from kolla\nand it is never updated afterwards.\n\nThis discrepancy between the updated password and the password config\nfile in the mysql container makes it impossible to connect to mysql\nwithout using a password at command line. This also breaks mysql's\npost upgrade tasks which require the proper root credentials in the file.\n\nFix that discrepancy by adding a synchronization action at step3, which\nwill be triggered by paunch whenever a config change happens, and make\nthe docker-puppet task modify the config file shared with the mysql\ncontainer (from /var/lib/config-data/puppet-generated)\n\nNote: this discrepancy does not happen for the HA version of the mysql\nservice, because we already have a container that is in charge of\nrestarting mysql on config change (mysql_restart_bundle).\n\nChange-Id: I9cc725c77fd9a2f9e55c4878cd2125f99f35c06d\nCloses-Bug: #1814514\n(cherry picked from commit dd54e32d1106bac0a94f7ee48395e87ad63bcb9f)\n""}]",0,635976,b476c1e9a58639b4510820b35964c4973fc7e984,12,5,1,20778,,,0,"mysql: sync credentials in running container on password change

Since 8e67ec833173920ac60b5548a711885a4d28e16f, docker-puppet doesn't
change mysql password config file on password update. It only notifies
of config change and paunch restarts some containers accordingly.

In non-HA mysql service, when a stack update changes the mysql password,
a docker-puppet task updates the root password config file at step 2.

However, the mysql container is started before the docker-puppet task,
which means that it gets the old root password config file from kolla
and it is never updated afterwards.

This discrepancy between the updated password and the password config
file in the mysql container makes it impossible to connect to mysql
without using a password at command line. This also breaks mysql's
post upgrade tasks which require the proper root credentials in the file.

Fix that discrepancy by adding a synchronization action at step3, which
will be triggered by paunch whenever a config change happens, and make
the docker-puppet task modify the config file shared with the mysql
container (from /var/lib/config-data/puppet-generated)

Note: this discrepancy does not happen for the HA version of the mysql
service, because we already have a container that is in charge of
restarting mysql on config change (mysql_restart_bundle).

Change-Id: I9cc725c77fd9a2f9e55c4878cd2125f99f35c06d
Closes-Bug: #1814514
(cherry picked from commit dd54e32d1106bac0a94f7ee48395e87ad63bcb9f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/76/635976/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/database/mysql.yaml'],1,b476c1e9a58639b4510820b35964c4973fc7e984,bug/1814514," step_3: # sync credentials config on the running container if it was # changed by the docker_puppet_task during step 2 mysql_sync_credentials: config_volume: mysql start_order: 1 action: exec user: root command: [ 'mysql', '/bin/bash', '-c', 'cp /var/lib/kolla/config_files/src/root/.my.cnf /root' ] - /var/lib/config-data/puppet-generated/mysql/root:/root:rw #provides .my.cnf for puppet, changed on password update"," - /var/lib/config-data/mysql/root:/root:rw #provides .my.cnf for puppet, changed on password update",11,1
openstack%2Ftripleo-heat-templates~master~Ie358cce307420b5ec76bb95f90bc1ca7b97fe83b,openstack/tripleo-heat-templates,master,Ie358cce307420b5ec76bb95f90bc1ca7b97fe83b,Enable glance image cache's cleaner and pruner,MERGED,2019-02-11 17:33:37.000000000,2019-02-12 12:25:05.000000000,2019-02-12 12:25:05.000000000,"[{'_account_id': 5202}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 19138}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 17:33:37.000000000', 'files': ['deployment/glance/glance-api-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/07709c44f3615a8241e02ba4561f5dc39a2d88a3', 'message': 'Enable glance image cache\'s cleaner and pruner\n\nWhen glance\'s image cache is enabled, configure the cron jobs to\nperiodically run the image cache\'s ""cleaner"" and ""pruner"". This ensures\nthe cache contents is properly maintained, and does not exceed the\nsize limit.\n\nblueprint: split-controlplane-glance-cache\nChange-Id: Ie358cce307420b5ec76bb95f90bc1ca7b97fe83b\n'}]",0,636184,07709c44f3615a8241e02ba4561f5dc39a2d88a3,8,6,1,21129,,,0,"Enable glance image cache's cleaner and pruner

When glance's image cache is enabled, configure the cron jobs to
periodically run the image cache's ""cleaner"" and ""pruner"". This ensures
the cache contents is properly maintained, and does not exceed the
size limit.

blueprint: split-controlplane-glance-cache
Change-Id: Ie358cce307420b5ec76bb95f90bc1ca7b97fe83b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/84/636184/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/glance/glance-api-container-puppet.yaml'],1,07709c44f3615a8241e02ba4561f5dc39a2d88a3,bp/split-controlplane-glance-cache, - if: - glance_cache_enabled - | include ::glance::cache::cleaner include ::glance::cache::pruner - '',,6,0
openstack%2Ftripleo-heat-templates~master~Ib60de9b0df451273d1d81ba049b46b5214e09080,openstack/tripleo-heat-templates,master,Ib60de9b0df451273d1d81ba049b46b5214e09080,Fix with_items indentation in logs readme ec2-api.,MERGED,2019-02-08 10:18:10.000000000,2019-02-12 12:25:01.000000000,2019-02-12 12:25:01.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 11082}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 16515}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-08 10:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5608f9a34d558bb40de22447a3b994943030efd2', 'message': ""Fix with_items indentation in logs readme ec2-api.\n\nWrongly indented with_items parameter for task 'ec2 logs readme' is\nfailing, however it wasn't catch because the task includes the\nignore_errors param.\n\nChange-Id: Ib60de9b0df451273d1d81ba049b46b5214e09080\n""}, {'number': 2, 'created': '2019-02-08 10:21:34.000000000', 'files': ['docker/services/ec2-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2e5de85cef4a8c4f8876f6019f5599ee2856ec74', 'message': ""Fix with_items indentation in logs readme ec2-api.\n\nWrongly indented with_items parameter for task 'ec2 logs readme' is\nfailing, however it wasn't caught because the task includes the\nignore_errors param.\n\nChange-Id: Ib60de9b0df451273d1d81ba049b46b5214e09080\n""}]",2,635737,2e5de85cef4a8c4f8876f6019f5599ee2856ec74,12,10,2,26343,,,0,"Fix with_items indentation in logs readme ec2-api.

Wrongly indented with_items parameter for task 'ec2 logs readme' is
failing, however it wasn't caught because the task includes the
ignore_errors param.

Change-Id: Ib60de9b0df451273d1d81ba049b46b5214e09080
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/635737/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ec2-api.yaml'],1,5608f9a34d558bb40de22447a3b994943030efd2,, with_items: - ec2api - ec2api-metadata, with_items: - ec2api - ec2api-metadata,3,3
openstack%2Ftripleo-heat-templates~master~I132465a32cd9f5e094ed184a92549d6521ad4e64,openstack/tripleo-heat-templates,master,I132465a32cd9f5e094ed184a92549d6521ad4e64,flatten the horizon service configurations,MERGED,2019-02-04 17:29:37.000000000,2019-02-12 12:24:58.000000000,2019-02-12 12:24:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 17:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d82c731fd487acb05bcb3cbc4f6a44b4589ea45c', 'message': 'flatten the horizon service configurations\n\nThis change combines the previous puppet and docker files into a single\nfile that performs the docker service installation and configuration\nfor the horizon service.\n\nWith this patch the baremetal version of each respective horizon service\nhas been removed.\n\nChange-Id: I132465a32cd9f5e094ed184a92549d6521ad4e64\nRelated-Blueprint: services-yaml-flattening\n'}, {'number': 2, 'created': '2019-02-04 19:24:06.000000000', 'files': ['puppet/services/horizon.yaml', 'sample-env-generator/ssl.yaml', 'docker/services/horizon.yaml', 'deployment/horizon/horizon-container-puppet.yaml', 'sample-env-generator/openidc.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'environments/baremetal-services.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3238e547a63efa9ba7a27ba9dedc181c4454e501', 'message': 'flatten the horizon service configurations\n\nThis change combines the previous puppet and docker files into a single\nfile that performs the docker service installation and configuration\nfor the horizon service.\n\nWith this patch the baremetal version of each respective horizon service\nhas been removed.\n\nChange-Id: I132465a32cd9f5e094ed184a92549d6521ad4e64\nRelated-Blueprint: services-yaml-flattening\n'}]",0,634752,3238e547a63efa9ba7a27ba9dedc181c4454e501,8,3,2,360,,,0,"flatten the horizon service configurations

This change combines the previous puppet and docker files into a single
file that performs the docker service installation and configuration
for the horizon service.

With this patch the baremetal version of each respective horizon service
has been removed.

Change-Id: I132465a32cd9f5e094ed184a92549d6521ad4e64
Related-Blueprint: services-yaml-flattening
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/52/634752/2 && git format-patch -1 --stdout FETCH_HEAD,"['sample-env-generator/ssl.yaml', 'docker/services/horizon.yaml', 'deployment/horizon/horizon-container-puppet.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'sample-env-generator/openidc.yaml', 'environments/baremetal-services.yaml']",6,d82c731fd487acb05bcb3cbc4f6a44b4589ea45c,bp/services-yaml-flattening, OS::TripleO::Services::Horizon: ../deployment/horizon/horizon-container-puppet.yaml, OS::TripleO::Services::Horizon: ../puppet/services/horizon.yaml,373,234
openstack%2Ftripleo-heat-templates~master~Ia71a653d9c73b5f7a4d26b76aaf1cb29b29aab5c,openstack/tripleo-heat-templates,master,Ia71a653d9c73b5f7a4d26b76aaf1cb29b29aab5c,Do not mount ceph-ansible and octavia playbook within mistral container,MERGED,2019-02-11 09:59:30.000000000,2019-02-12 12:24:55.000000000,2019-02-12 12:24:55.000000000,"[{'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-11 09:59:30.000000000', 'files': ['environments/undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/01a8651306082e0c7fddcebc932c420c7cb10487', 'message': 'Do not mount ceph-ansible and octavia playbook within mistral container\n\nThis is not necessary anymore given the mistral-executor container is\nexecuting the playbook from the node hosting the container itself.\n\nChange-Id: Ia71a653d9c73b5f7a4d26b76aaf1cb29b29aab5c\nRelated-Bug: 1813832\n'}]",0,636107,01a8651306082e0c7fddcebc932c420c7cb10487,10,7,1,6796,,,0,"Do not mount ceph-ansible and octavia playbook within mistral container

This is not necessary anymore given the mistral-executor container is
executing the playbook from the node hosting the container itself.

Change-Id: Ia71a653d9c73b5f7a4d26b76aaf1cb29b29aab5c
Related-Bug: 1813832
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/07/636107/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/undercloud.yaml'],1,01a8651306082e0c7fddcebc932c420c7cb10487,bug/1813832,, MistralExecutorExtraVolumes: - /usr/share/ceph-ansible:/usr/share/ceph-ansible:ro - /usr/share/openstack-octavia-amphora-images:/usr/share/openstack-octavia-amphora-images:ro,0,3
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ib5e2dab1e94810ac02e5d64859d2e84f749f3994,openstack/tripleo-heat-templates,stable/rocky,Ib5e2dab1e94810ac02e5d64859d2e84f749f3994,Disable stack check and cancel update for undercloud,MERGED,2019-02-11 10:01:48.000000000,2019-02-12 12:24:53.000000000,2019-02-12 12:24:53.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 10:01:48.000000000', 'files': ['releasenotes/notes/disable-heat-non-lifecycle-actions-d551fe4551d71770.yaml', 'environments/undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0b42fb17ff155a0a857ef208288bdf26b16284a5', 'message': ""Disable stack check and cancel update for undercloud\n\n'overcloud update abort' command had been dropped since few\nreleases. However, users can still use heat commands to cancel\nan update which is not recommended.\n\nUndercloud now uses heat convergence architecture and stack check\nhas not been migrated to convergence yet.\n\nlet's add heat policy to disable both on undercloud.\n\nChange-Id: Ib5e2dab1e94810ac02e5d64859d2e84f749f3994\n(cherry picked from commit 18f4e11773bba8f2e4e5d4e2e175e713669f549f)\n""}]",0,636108,0b42fb17ff155a0a857ef208288bdf26b16284a5,9,4,1,8833,,,0,"Disable stack check and cancel update for undercloud

'overcloud update abort' command had been dropped since few
releases. However, users can still use heat commands to cancel
an update which is not recommended.

Undercloud now uses heat convergence architecture and stack check
has not been migrated to convergence yet.

let's add heat policy to disable both on undercloud.

Change-Id: Ib5e2dab1e94810ac02e5d64859d2e84f749f3994
(cherry picked from commit 18f4e11773bba8f2e4e5d4e2e175e713669f549f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/636108/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/disable-heat-non-lifecycle-actions-d551fe4551d71770.yaml', 'environments/undercloud.yaml']",2,0b42fb17ff155a0a857ef208288bdf26b16284a5,," # Disable non-lifecycle stack actions like # snapshot, resume, cancel update and stack check. HeatApiPolicies: heat-deny-action: key: 'actions:action' value: 'rule:deny_everybody'",,16,0
openstack%2Fpython-tripleoclient~master~I4cbcfe4aa5596969ee501a41645b9b29e9a7236d,openstack/python-tripleoclient,master,I4cbcfe4aa5596969ee501a41645b9b29e9a7236d,Add overcloud admin ssh authorize command.,MERGED,2019-01-28 18:19:24.000000000,2019-02-12 12:23:45.000000000,2019-02-12 12:23:44.000000000,"[{'_account_id': 7144}, {'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-01-28 18:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3249cbabecbcdea26655f05e4975d416224d974c', 'message': 'Add overcloud admin ssh authorize command.\n\nThis is needed in reprovisioning upgrade to be able to deploy new keys\nwithout having to run an entire deployment.\n\nTODO: The split stack part (--host) may not be needed as that kind of\nfile\nhttp://logs.openstack.org/86/633486/1/check/tripleo-ci-centos-7-containers-multinode/09a19eb/logs/undercloud/home/zuul/config-download.yaml.txt.gz\nmay have to be created for all split stack stuff.\n\nChange-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d\n'}, {'number': 2, 'created': '2019-01-28 18:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4d3b73451aa715a2b5f3f95f7046b7e62e46be51', 'message': 'Add overcloud admin ssh authorize command.\n\nThis is needed in reprovisioning upgrade to be able to deploy new keys\nwithout having to run an entire deployment.\n\nTODO: The split stack part (--host) may not be needed as that kind of\nfile\nhttp://logs.openstack.org/86/633486/1/check/tripleo-ci-centos-7-containers-multinode/09a19eb/logs/undercloud/home/zuul/config-download.yaml.txt.gz\nmay have to be created for all split stack stuff.\n\nChange-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d\nImplements: blueprint upgrades-with-os\n'}, {'number': 3, 'created': '2019-01-28 18:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e028da8f3a70bbe3bf44de2eac5c291ce89768fa', 'message': 'Add overcloud admin ssh authorize command.\n\nThis is needed in reprovisioning upgrade to be able to deploy new keys\nwithout having to run an entire deployment.\n\nTODO: The split stack part (--host) may not be needed as that kind of\nfile\nhttp://logs.openstack.org/86/633486/1/check/tripleo-ci-centos-7-containers-multinode/09a19eb/logs/undercloud/home/zuul/config-download.yaml.txt.gz\nmay have to be created for all split stack stuff.\n\nChange-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d\nImplements: blueprint upgrades-with-os\n'}, {'number': 4, 'created': '2019-01-31 15:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/27969af7d796590606eec07190a9732092c0e233', 'message': 'Add overcloud admin ssh authorize command.\n\nThis is needed in reprovisioning upgrade to be able to deploy new keys\nwithout having to run an entire deployment.\n\nWe add some error handling:\n - raise an error if no host is found;\n - display a message if ssh connection fails\n\nChange-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d\nImplements: blueprint upgrades-with-os\n'}, {'number': 5, 'created': '2019-02-08 13:44:03.000000000', 'files': ['tripleoclient/v1/overcloud_admin.py', 'tripleoclient/workflows/deployment.py', 'tripleoclient/tests/v1/test_overcloud_admin.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/db2841890195af982632f1ce9f7bbf21cc738a21', 'message': 'Add overcloud admin ssh authorize command.\n\nThis is needed in reprovisioning upgrade to be able to deploy new keys\nwithout having to run an entire deployment.\n\nWe add some error handling:\n - raise an error if no host is found;\n - display a message if ssh connection fails\n\nChange-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d\nImplements: blueprint upgrades-with-os\n'}]",10,633574,db2841890195af982632f1ce9f7bbf21cc738a21,23,6,5,8297,,,0,"Add overcloud admin ssh authorize command.

This is needed in reprovisioning upgrade to be able to deploy new keys
without having to run an entire deployment.

We add some error handling:
 - raise an error if no host is found;
 - display a message if ssh connection fails

Change-Id: I4cbcfe4aa5596969ee501a41645b9b29e9a7236d
Implements: blueprint upgrades-with-os
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/74/633574/3 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_admin.py', 'tripleoclient/workflows/deployment.py', 'setup.cfg']",3,3249cbabecbcdea26655f05e4975d416224d974c,bp/upgrades-with-os, overcloud_admin_authorize = tripleoclient.v1.overcloud_admin:Authorize,,101,2
openstack%2Ftripleo-common-tempest-plugin~master~Ia2402137dccbe8434c64f3f3fc8588ba3ff02347,openstack/tripleo-common-tempest-plugin,master,Ia2402137dccbe8434c64f3f3fc8588ba3ff02347,Update hacking version to latest,MERGED,2019-01-09 02:21:23.000000000,2019-02-12 12:23:45.000000000,2019-02-12 12:23:45.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2019-01-09 02:21:23.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-common-tempest-plugin/commit/57e019b3fffcfdb4335330deac1f840d7e2743cc', 'message': 'Update hacking version to latest\n\nChange-Id: Ia2402137dccbe8434c64f3f3fc8588ba3ff02347\n'}]",0,629362,57e019b3fffcfdb4335330deac1f840d7e2743cc,10,4,1,27565,,,0,"Update hacking version to latest

Change-Id: Ia2402137dccbe8434c64f3f3fc8588ba3ff02347
",git fetch https://review.opendev.org/openstack/tripleo-common-tempest-plugin refs/changes/62/629362/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,57e019b3fffcfdb4335330deac1f840d7e2743cc,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Ftripleo-heat-templates~master~I333b0be365a6824a7f0f802f6b72229cb0f8c9f1,openstack/tripleo-heat-templates,master,I333b0be365a6824a7f0f802f6b72229cb0f8c9f1,Set Ironic default interface when using networking-ansible,MERGED,2019-02-07 08:23:25.000000000,2019-02-12 12:13:05.000000000,2019-02-11 23:18:16.000000000,"[{'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 5792}, {'_account_id': 6994}, {'_account_id': 8655}, {'_account_id': 8833}, {'_account_id': 8873}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26787}]","[{'number': 1, 'created': '2019-02-07 08:23:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3da5c9eb778ccde4c7290ab33a370aa2923cb0e2', 'message': ""Set Ironic default interface when using networking-ansible\n\nWhen networking-ansible is used, Ironic default interface must be set to\nNeutron, otherwise Neutron ports for baremetal hosts won't get populated\nwith local link information.\n\nCloses-bug: 1815015\n\nChange-Id: I333b0be365a6824a7f0f802f6b72229cb0f8c9f1\n""}, {'number': 2, 'created': '2019-02-07 13:57:00.000000000', 'files': ['environments/neutron-ml2-ansible.yaml', 'environments/services/neutron-ml2-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b026b860c81960baace2b1ae9c603d5705f3c88e', 'message': ""Set Ironic default interface when using networking-ansible\n\nWhen networking-ansible is used, Ironic default interface must be set to\nNeutron, otherwise Neutron ports for baremetal hosts won't get populated\nwith local link information.\n\nCloses-bug: 1815015\n\nChange-Id: I333b0be365a6824a7f0f802f6b72229cb0f8c9f1\n""}]",8,635451,b026b860c81960baace2b1ae9c603d5705f3c88e,25,13,2,8655,,,0,"Set Ironic default interface when using networking-ansible

When networking-ansible is used, Ironic default interface must be set to
Neutron, otherwise Neutron ports for baremetal hosts won't get populated
with local link information.

Closes-bug: 1815015

Change-Id: I333b0be365a6824a7f0f802f6b72229cb0f8c9f1
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/635451/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-ml2-ansible.yaml', 'environments/services/neutron-ml2-ansible.yaml']",2,3da5c9eb778ccde4c7290ab33a370aa2923cb0e2,bug/1815015," IronicDefaultNetworkInterface: neutron IronicEnabledNetworkInterfaces: flat,noop,neutron",,4,0
openstack%2Fnetworking-ovn~master~I316215d33a47a34839114fd41401f7c701c4ff21,openstack/networking-ovn,master,I316215d33a47a34839114fd41401f7c701c4ff21,Fix instances of events as strings instead of tuples,MERGED,2019-02-07 17:06:40.000000000,2019-02-12 12:01:03.000000000,2019-02-12 12:01:03.000000000,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-02-07 17:06:40.000000000', 'files': ['networking_ovn/agent/metadata/agent.py', 'networking_ovn/tests/functional/test_ovsdb_monitor.py', 'networking_ovn/ovsdb/ovsdb_monitor.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/10ff6726d128758931788490c4226d01f1b33017', 'message': ""Fix instances of events as strings instead of tuples\n\nAlthough it technically works because the match use 'in' and events\nare non-overlapping strings, the clear intent is for these to be\ntuples and (x) is not a tuple, while (x,) is.\n\nChange-Id: I316215d33a47a34839114fd41401f7c701c4ff21\n""}]",1,635572,10ff6726d128758931788490c4226d01f1b33017,9,4,1,5756,,,0,"Fix instances of events as strings instead of tuples

Although it technically works because the match use 'in' and events
are non-overlapping strings, the clear intent is for these to be
tuples and (x) is not a tuple, while (x,) is.

Change-Id: I316215d33a47a34839114fd41401f7c701c4ff21
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/72/635572/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/agent/metadata/agent.py', 'networking_ovn/tests/functional/test_ovsdb_monitor.py', 'networking_ovn/ovsdb/ovsdb_monitor.py']",3,10ff6726d128758931788490c4226d01f1b33017,," events = (self.ROW_UPDATE,) events = (self.ROW_CREATE,) events = (self.ROW_CREATE,) events = (self.ROW_UPDATE,) events = (self.ROW_UPDATE,)", events = (self.ROW_UPDATE) events = (self.ROW_CREATE) events = (self.ROW_CREATE) events = (self.ROW_UPDATE) events = (self.ROW_UPDATE),9,9
openstack%2Fopenstack-ansible~master~Ifaa92f9faecfffde95498c4198fe89ecdede04f4,openstack/openstack-ansible,master,Ifaa92f9faecfffde95498c4198fe89ecdede04f4,Bump SHAs for master,MERGED,2019-02-09 08:42:53.000000000,2019-02-12 11:59:20.000000000,2019-02-12 11:59:20.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 08:42:53.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/826a032a87903dea8c4cdac31f4ec902bc2ff17b', 'message': 'Bump SHAs for master\n\nChange-Id: Ifaa92f9faecfffde95498c4198fe89ecdede04f4\n'}]",0,636002,826a032a87903dea8c4cdac31f4ec902bc2ff17b,10,3,1,17068,,,0,"Bump SHAs for master

Change-Id: Ifaa92f9faecfffde95498c4198fe89ecdede04f4
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/02/636002/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml']",4,826a032a87903dea8c4cdac31f4ec902bc2ff17b,bump_osa,tempest_git_install_branch: 30cfcf8478f6d2e440c657048d97828ff4a5e2da # HEAD as of 09.02.2019,tempest_git_install_branch: ccdd729aaf092db21977b46530ab454de25c8ece # HEAD as of 26.01.2019,47,47
openstack%2Ftripleo-common~stable%2Fqueens~I6e2457984cf098195b5c71dccaf420448a75a4a1,openstack/tripleo-common,stable/queens,I6e2457984cf098195b5c71dccaf420448a75a4a1,Publish a better failure message for Update Ansible,MERGED,2019-01-31 10:25:15.000000000,2019-02-12 11:58:16.000000000,2019-02-12 11:58:15.000000000,"[{'_account_id': 14985}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-31 10:25:15.000000000', 'files': ['workbooks/package_update.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4f13a4baf7b2d55ea58c4799a336b4e87f8abb8c', 'message': 'Publish a better failure message for Update Ansible\n\nThis review return and publish a better failling message\nback to the client with the log path in order to make\nthe debuging easy.\n\nChange-Id: I6e2457984cf098195b5c71dccaf420448a75a4a1\n(cherry picked from commit 93113e73e88eee09974110ea0a93bf01e5ed5b3d)\n'}]",0,634195,4f13a4baf7b2d55ea58c4799a336b4e87f8abb8c,9,4,1,16515,,,0,"Publish a better failure message for Update Ansible

This review return and publish a better failling message
back to the client with the log path in order to make
the debuging easy.

Change-Id: I6e2457984cf098195b5c71dccaf420448a75a4a1
(cherry picked from commit 93113e73e88eee09974110ea0a93bf01e5ed5b3d)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/95/634195/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/package_update.yaml'],1,4f13a4baf7b2d55ea58c4799a336b4e87f8abb8c,update/ansible/run," reproduce_command: true work_dir: <% $.work_dir %>/<% execution().id %> publish-on-error: status: FAILED message: Ansible failed, check log at <% $.work_dir %>/<% execution().id %>/ansible.log. publish: log_path: <% task().result.get('log_path') %> message: Ansible failed, check log at <% $.get('work_dir') %>/<% execution().id %>/ansible.log."," publish: output: <% task().result %> message: Failed to update nodes - <% $.nodes %>, please see the logs.",7,2
openstack%2Ftripleo-quickstart-extras~master~If4f777b990099b67db631102d8f8be418b97b46b,openstack/tripleo-quickstart-extras,master,If4f777b990099b67db631102d8f8be418b97b46b,Change headless chrome port to 4444,MERGED,2019-01-28 12:17:40.000000000,2019-02-12 11:58:15.000000000,2019-02-12 11:58:15.000000000,"[{'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-28 12:17:40.000000000', 'files': ['roles/validate-tempest/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/55df6235f470c5276e23b117d67fa1241cb7677b', 'message': 'Change headless chrome port to 4444\n\nThe browser is running on that port inside the container.\n\nChange-Id: If4f777b990099b67db631102d8f8be418b97b46b\n'}]",0,633489,55df6235f470c5276e23b117d67fa1241cb7677b,10,5,1,20970,,,0,"Change headless chrome port to 4444

The browser is running on that port inside the container.

Change-Id: If4f777b990099b67db631102d8f8be418b97b46b
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/89/633489/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/defaults/main.yml'],1,55df6235f470c5276e23b117d67fa1241cb7677b,headless-port,tempest_headless_chrome_port: 4444,tempest_headless_chrome_port: 9999,1,1
openstack%2Ftripleo-quickstart-extras~master~I690191f9abbad5f35063f57d53eb209332f30f15,openstack/tripleo-quickstart-extras,master,I690191f9abbad5f35063f57d53eb209332f30f15,Remove double quote from tempestconf,MERGED,2019-01-25 17:21:42.000000000,2019-02-12 11:55:17.000000000,2019-02-12 11:55:17.000000000,"[{'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-25 17:21:42.000000000', 'files': ['roles/validate-tempest/tasks/tempest-venv.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c39655fe070f328320466ed743f9faab4033d9c2', 'message': 'Remove double quote from tempestconf\n\nIn tempest-venv, there is a space in the tempestconf command which results in a\ndouble spacing issue in the final tempest-setup.sh file.\n\nIt looks like this:\n\nexport TEMPESTCONF=""""/home/zuul/tempest_git/tools/with_venv.sh discover-tempest-config""\n""\n\nThis patch removes the outer quote.\n\nChange-Id: I690191f9abbad5f35063f57d53eb209332f30f15\n'}]",0,633247,c39655fe070f328320466ed743f9faab4033d9c2,11,5,1,20970,,,0,"Remove double quote from tempestconf

In tempest-venv, there is a space in the tempestconf command which results in a
double spacing issue in the final tempest-setup.sh file.

It looks like this:

export TEMPESTCONF=""""/home/zuul/tempest_git/tools/with_venv.sh discover-tempest-config""
""

This patch removes the outer quote.

Change-Id: I690191f9abbad5f35063f57d53eb209332f30f15
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/47/633247/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/tasks/tempest-venv.yml'],1,c39655fe070f328320466ed743f9faab4033d9c2,tempestconf-doublequote, {% if release == 'newton' %}{{ working_dir }}/tools/config_tempest.py{% else %}{{ working_dir }}/tempest_git/tools/with_venv.sh discover-tempest-config{% endif %}," ""{% if release == 'newton' %}{{ working_dir }}/tools/config_tempest.py{% else %}{{ working_dir }}/tempest_git/tools/with_venv.sh discover-tempest-config{% endif %}""",1,1
openstack%2Frpm-packaging~stable%2Frocky~I6f5bb1ff56219df46116a47b00064f718085d256,openstack/rpm-packaging,stable/rocky,I6f5bb1ff56219df46116a47b00064f718085d256,Set BuildArch for watcher-doc.,MERGED,2019-02-12 11:16:08.000000000,2019-02-12 11:48:11.000000000,2019-02-12 11:48:10.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 12542}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-12 11:16:08.000000000', 'files': ['openstack/watcher/watcher.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8dabf4e2ae455dc8432a5f00d85969885a533cee', 'message': 'Set BuildArch for watcher-doc.\n\nChange-Id: I6f5bb1ff56219df46116a47b00064f718085d256\n(cherry picked from commit 2020ad08decc5256be364747adb7166068fb5b14)\n'}]",0,636304,8dabf4e2ae455dc8432a5f00d85969885a533cee,10,6,1,7102,,,0,"Set BuildArch for watcher-doc.

Change-Id: I6f5bb1ff56219df46116a47b00064f718085d256
(cherry picked from commit 2020ad08decc5256be364747adb7166068fb5b14)
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/04/636304/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/watcher/watcher.spec.j2'],1,8dabf4e2ae455dc8432a5f00d85969885a533cee,watcher-doc-buildarch-stable/rocky,BuildArch: noarch,,1,0
openstack%2Ftacker~master~I3c57b4206b6f732b401701172edc3dbfe9c5a3ea,openstack/tacker,master,I3c57b4206b6f732b401701172edc3dbfe9c5a3ea,Improve code coverage of plugin module,MERGED,2019-02-12 04:28:57.000000000,2019-02-12 11:36:20.000000000,2019-02-12 11:36:19.000000000,"[{'_account_id': 2874}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26222}]","[{'number': 1, 'created': '2019-02-12 04:28:57.000000000', 'files': ['tacker/tests/unit/vnfm/test_plugin.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/e8b42ca4ddb06271613b3d9f4ce2b1470e1e8f38', 'message': 'Improve code coverage of plugin module\n\nAdded new unit tests to improve code coverage for create_vnf,\ncreate_vnf_scale and create_vnf_trigger methods.\n\nChange-Id: I3c57b4206b6f732b401701172edc3dbfe9c5a3ea\n'}]",0,636264,e8b42ca4ddb06271613b3d9f4ce2b1470e1e8f38,7,4,1,29236,,,0,"Improve code coverage of plugin module

Added new unit tests to improve code coverage for create_vnf,
create_vnf_scale and create_vnf_trigger methods.

Change-Id: I3c57b4206b6f732b401701172edc3dbfe9c5a3ea
",git fetch https://review.opendev.org/openstack/tacker refs/changes/64/636264/1 && git format-patch -1 --stdout FETCH_HEAD,['tacker/tests/unit/vnfm/test_plugin.py'],1,e8b42ca4ddb06271613b3d9f4ce2b1470e1e8f38,code_coverage_plugin_module," 'openstack.OpenStack.delete').start() self.scale = mock.patch('tacker.vnfm.infra_drivers.openstack.' 'openstack.OpenStack.scale', return_value=uuidutils.generate_uuid()).start() self.scale_wait = mock.patch('tacker.vnfm.infra_drivers.openstack.' 'openstack.OpenStack.scale_wait', return_value=uuidutils.generate_uuid()).start() def _insert_scaling_attributes_vnfd(self, invalid_policy_type=False): if invalid_policy_type: vnfd_template = yaml.safe_load(vnfd_attributes.value) vnfd_template['topology_template']['policies'][0]['SP1']['type'] \ = ""test_invalid_policy_type"" vnfd_attributes.value = yaml.dump(vnfd_template) def test_create_vnf_fail_with_invalid_infra_driver_exception(self): self.vim_client.get_vim.return_value['vim_type'] = 'test_invalid_vim' self._insert_dummy_vnf_template() vnf_obj = utils.get_dummy_vnf_obj() self.assertRaises(vnfm.InvalidInfraDriver, self.vnfm_plugin.create_vnf, self.context, vnf_obj) def _get_scaling_vnf(self, type, invalid_policy_type=False): self._insert_scaling_attributes_vnfd(invalid_policy_type) return dummy_vnf_obj, vnf_scale def _test_scale_vnf(self, type): dummy_vnf_obj, vnf_scale = self._get_scaling_vnf(type) self.scale.assert_called_once_with( self.scale_wait.assert_called_once_with(plugin=self.vnfm_plugin, context=self.context, auth_attr=mock.ANY, policy=mock.ANY, region_name=mock.ANY, last_event_id=mock.ANY) self._test_scale_vnf('out') self._test_scale_vnf('in') @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb._update_vnf_scaling_status') @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb.set_vnf_error_status_reason') def test_scale_vnf_with_vnf_policy_action_exception(self, mock_set_vnf_error_status_reason, mock_update_vnf_scaling_status): dummy_vnf_obj, vnf_scale = self._get_scaling_vnf('in') self.scale.side_effect = FakeException self.assertRaises(FakeException, self.vnfm_plugin.create_vnf_scale, self.context, dummy_vnf_obj['id'], vnf_scale) mock_update_vnf_scaling_status.assert_called_with( self.context, mock.ANY, [constants.PENDING_SCALE_IN], constants.ERROR, mock.ANY) mock_set_vnf_error_status_reason.assert_called_with( self.context, dummy_vnf_obj['id'], mock.ANY) @mock.patch('tacker.vnfm.plugin.VNFMPlugin.get_vnf_policies') def test_scale_vnf_with_policy_not_found_exception(self, mock_get_vnf_policies): dummy_vnf_obj, vnf_scale = self._get_scaling_vnf('in') mock_get_vnf_policies.return_value = None self.assertRaises(exceptions.VnfPolicyNotFound, self.vnfm_plugin.create_vnf_scale, self.context, dummy_vnf_obj['id'], vnf_scale) def test_scale_vnf_with_invalid_policy_type(self): dummy_vnf_obj, vnf_scale = self._get_scaling_vnf('in', invalid_policy_type=True) self.assertRaises(exceptions.VnfPolicyTypeInvalid, self.vnfm_plugin.create_vnf_scale, self.context, dummy_vnf_obj['id'], vnf_scale) def test_scale_vnf_with_invalid_policy_action(self): dummy_vnf_obj, vnf_scale = \ self._get_scaling_vnf('test_invalid_policy_action') self.assertRaises(exceptions.VnfPolicyActionInvalid, self.vnfm_plugin.create_vnf_scale, self.context, dummy_vnf_obj['id'], vnf_scale) def test_scale_vnf_scale_wait_failed_exception(self): dummy_vnf_obj, vnf_scale = \ self._get_scaling_vnf('in') self.scale_wait.side_effect = vnfm.VNFScaleWaitFailed( reason='test') self.assertRaises(vnfm.VNFScaleWaitFailed, self.vnfm_plugin.create_vnf_scale, self.context, dummy_vnf_obj['id'], vnf_scale) def _create_vnf_trigger_data(self, policy_name, action_value): return vnf_id, trigger_request, expected_result @patch('tacker.vnfm.policy_actions.autoscaling.autoscaling.' 'VNFActionAutoscaling.execute_action') def _test_create_vnf_trigger(self, mock_execute_action, policy_name, action_value): vnf_id, trigger_request, expected_result = self.\ _create_vnf_trigger_data(policy_name, action_value) trigger_result = self.vnfm_plugin.create_vnf_trigger(self.context, vnf_id, trigger_request) def test_create_vnf_trigger_without_policy_actions(self, mock_get_vnf): dummy_vnf = self._get_dummy_vnf( utils.vnfd_alarm_multi_actions_tosca_template) mock_get_vnf.return_value = dummy_vnf vnf_id, trigger_request, _ = self._create_vnf_trigger_data( ""mon_policy_multi_actions"", ""respawn&log"") self._vnf_alarm_monitor.process_alarm_for_vnf.return_value = False self.assertRaises(exceptions.AlarmUrlInvalid, self.vnfm_plugin.create_vnf_trigger, self.context, vnf_id, trigger_request) @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb.get_vnf') def test_create_vnf_trigger_with_invalid_policy_name(self, mock_get_vnf): dummy_vnf = self._get_dummy_vnf( utils.vnfd_alarm_multi_actions_tosca_template) mock_get_vnf.return_value = dummy_vnf vnf_id, trigger_request, _ = self._create_vnf_trigger_data( ""invalid_policy_name"", ""respawn&log"") self.assertRaises(exceptions.TriggerNotFound, self.vnfm_plugin.create_vnf_trigger, self.context, vnf_id, trigger_request) @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb.get_vnf') @patch('tacker.vnfm.plugin.LOG') def test_create_vnf_trigger_scale_with_invalid_vnf_status(self, mock_log, mock_get_vnf): dummy_vnf = self._get_dummy_vnf(utils.vnfd_alarm_scale_tosca_template) dummy_vnf['status'] = ""PENDING_CREATE"" mock_get_vnf.return_value = dummy_vnf vnf_id, trigger_request, expected_result = self. \ _create_vnf_trigger_data(""vdu_hcpu_usage_scaling_out"", ""SP1-out"") expected_error_msg = (_(""Scaling Policy action skipped due to status"" ' %(status)s for vnf %(vnfid)s') % {'status': dummy_vnf['status'], 'vnfid': dummy_vnf['id']}) self._vnf_alarm_monitor.process_alarm_for_vnf.return_value = True trigger_result = self.vnfm_plugin.create_vnf_trigger(self.context, vnf_id, trigger_request) mock_log.info.assert_called_with(expected_error_msg) self.assertEqual(expected_result, trigger_result) @patch('tacker.db.vnfm.vnfm_db.VNFMPluginDb.get_vnf')"," 'openstack.OpenStack.delete', return_value=uuidutils.generate_uuid()).start() def _insert_scaling_attributes_vnfd(self): @patch('tacker.vnfm.infra_drivers.openstack.openstack.OpenStack.scale') @patch('tacker.vnfm.infra_drivers.openstack.openstack.OpenStack.' 'scale_wait') def _test_scale_vnf(self, type, scale_state, mock_scale_wait, mock_scale): mock_scale_wait.return_value = uuidutils.generate_uuid() self._insert_scaling_attributes_vnfd() mock_scale.assert_called_once_with( self._test_scale_vnf('out', constants.PENDING_SCALE_OUT) self._test_scale_vnf('in', constants.PENDING_SCALE_IN) @patch('tacker.vnfm.policy_actions.autoscaling.autoscaling.' 'VNFActionAutoscaling.execute_action') def _test_create_vnf_trigger(self, mock_execute_action, policy_name, action_value): trigger_result = self.vnfm_plugin.create_vnf_trigger( self.context, vnf_id, trigger_request)",142,20
openstack%2Ftacker~master~I8ddde20203e25ba49867465e5b476c62372beda0,openstack/tacker,master,I8ddde20203e25ba49867465e5b476c62372beda0,[TrivialFix]: Improve exception handling.,ABANDONED,2019-01-31 12:32:38.000000000,2019-02-12 11:31:52.000000000,,"[{'_account_id': 2874}, {'_account_id': 18955}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 26222}]","[{'number': 1, 'created': '2019-01-31 12:32:38.000000000', 'files': ['tacker/nfvo/nfvo_plugin.py', 'tacker/nfvo/workflows/vim_monitor/vim_ping_action.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/8bcc0caef83b61186fe7d5c07f1e110bf0f168d6', 'message': '[TrivialFix]: Improve exception handling.\n\nIn some cases we needs to log exception with actual error message,\nthis will we required while debugging some code.\n\nChange-Id: I8ddde20203e25ba49867465e5b476c62372beda0\n'}]",2,634217,8bcc0caef83b61186fe7d5c07f1e110bf0f168d6,5,5,1,18955,,,0,"[TrivialFix]: Improve exception handling.

In some cases we needs to log exception with actual error message,
this will we required while debugging some code.

Change-Id: I8ddde20203e25ba49867465e5b476c62372beda0
",git fetch https://review.opendev.org/openstack/tacker refs/changes/17/634217/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/nfvo/nfvo_plugin.py', 'tacker/nfvo/workflows/vim_monitor/vim_ping_action.py']",2,8bcc0caef83b61186fe7d5c07f1e110bf0f168d6,," except Exception as ex: LOG.exception('failed to start rpc in vim action: %s', ex) except Exception as ex: LOG.exception('failed to run mistral action for vim %s: %s', self.vim_id, ex) except Exception as ex: 'failed to stop rpc connection for vim %s: %s', self.vim_id, ex)"," except Exception: LOG.exception('failed to start rpc in vim action') except Exception: LOG.exception('failed to run mistral action for vim %s', self.vim_id) except Exception: 'failed to stop rpc connection for vim %s', self.vim_id)",12,12
openstack%2Fnova~master~I7dcef20aed0178c81d6580aa9534288eaa383dab,openstack/nova,master,I7dcef20aed0178c81d6580aa9534288eaa383dab,Plumbing for allowing the all-tenants filter with down cells,MERGED,2019-02-06 12:41:52.000000000,2019-02-12 11:30:12.000000000,2019-02-12 02:01:19.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-06 12:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fc1f74cd2ec2f42b227086e87bd247059804064', 'message': 'Plumbing for allowing the all-tenants filter\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter. It also modifies the logic in\nthe construction of the instance.avz to\n\na) check whether it is set by the user  during boot time\n   and use that value if it is set.\nb) if its not set during boot time return ""UNKNOWN"".\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}, {'number': 2, 'created': '2019-02-07 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bea8e84671185d873b2d164c6c9a75825c925374', 'message': 'Plumbing for allowing the all-tenants filter with down cells\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}, {'number': 3, 'created': '2019-02-07 12:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/12c38291b85a373905bd754bd210c7d1cac53662', 'message': 'Plumbing for allowing the all-tenants filter with down cells\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}, {'number': 4, 'created': '2019-02-08 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f84c1dcde17ffd54294eb318f4e010f33f498c3d', 'message': 'Plumbing for allowing the all-tenants filter with down cells\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}, {'number': 5, 'created': '2019-02-08 21:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e2bc9fd5c02a16e081251552fad2d6c066b944a3', 'message': 'Plumbing for allowing the all-tenants filter with down cells\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}, {'number': 6, 'created': '2019-02-08 21:29:07.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/tests/unit/api/openstack/fakes.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0c8824b44d2f841d610296893f9a316f4f083d43', 'message': 'Plumbing for allowing the all-tenants filter with down cells\n\nThis patch lays the underground work for supporting the\n``all-tenants`` filter.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab\n'}]",19,635145,0c8824b44d2f841d610296893f9a316f4f083d43,88,11,6,26936,,,0,"Plumbing for allowing the all-tenants filter with down cells

This patch lays the underground work for supporting the
``all-tenants`` filter.

Related to blueprint handling-down-cell

Change-Id: I7dcef20aed0178c81d6580aa9534288eaa383dab
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/635145/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",2,5fc1f74cd2ec2f42b227086e87bd247059804064,bp/handling-down-cell," # NOTE(tssurya): Will be enabled after bumping the microversion. cell_down_support = False # if it's present unless we support handling down cells in which case # we need to know further down the stack whether the 'all-tenants' # filter was passed with the true value or not. We pop this option in # the compute API if its value is true. if not cell_down_support: search_opts.pop('all_tenants', None) else: if not all_tenants: search_opts.pop('all_tenants', None) sort_dirs=sort_dirs, cell_down_support=cell_down_support)"," # if it's present search_opts.pop('all_tenants', None) sort_dirs=sort_dirs, cell_down_support=False)",29,5
openstack%2Fkuryr-kubernetes~master~I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202,openstack/kuryr-kubernetes,master,I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202,Pools support with Network Policies,MERGED,2019-02-04 11:42:57.000000000,2019-02-12 11:29:54.000000000,2019-02-12 11:29:53.000000000,"[{'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-02-04 11:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5ee222487f2880a407765eca65ac3f59bcdf3e08', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem\n\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 2, 'created': '2019-02-05 10:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8b0270a10958ac4a2df4bb94c14ae0d524609fb8', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 3, 'created': '2019-02-05 13:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/a974f39ad3bea01776d86aaced762826c2fa78a4', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 4, 'created': '2019-02-05 15:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/8e7c309ac92ba11bf4af79f0c69e17ea410c83e9', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 5, 'created': '2019-02-05 17:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/cda15b3f0ae5707a5f3c47172c17b945a629717b', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 6, 'created': '2019-02-07 07:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/05df4d9c9544f32c4723c8078d3bdb4a4b14a940', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem)\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}, {'number': 7, 'created': '2019-02-08 16:18:55.000000000', 'files': ['kuryr_kubernetes/controller/drivers/vif_pool.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_vif_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e8c418c196cb2297b226be6830275e13563c08a4', 'message': ""Pools support with Network Policies\n\nThis patch adapts the pools support to the use of Network Policies.\nUnlike with the other drivers, when Network Policies are applied the\npods' ports changes their security groups while being used. That means\ntheir original pool will not fit them anymore with the next two\nconsequences:\n1.- Ports will have their original SG reapplied when pods are deleted,\nwith the consequent performance impact do to increasing the number of\ncalls to neutron\n2.- Original pools may become useless, as different SGs are being used,\ntherefore wasting neutron ports\n\nTo accomodate for network policies, this patch removes the SG ids from\nthe pool key, merging all the pools with same network/project/host ids\nbut with different security groups into the same pool. This will not\nchange the behavior of the other drivers as there was a unique pool per\nnetwork/project/host ids already, i.e., the same SG ids were being used.\nHowever, this will helps to avoid problem 1) as it is no longer\nre-applying the SG, but simply putting the port back into its current\npool. And it will fix problem 2) as it will pick a port for an existing\npool that matches network/project/host ids. First it will search for one\nwith already matching SGs, and if not found, it will recycle one of the\nothers by reapplying the needed SGs (note it picks a port from one of\nthe pools that are less frequently used -- assumes they may belong to\na deleted NP that it is not needed anymore, thus removing the port\nwastage problem)\n\nPartially Implements: blueprint k8s-network-policies\nChange-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202\n""}]",16,634674,e8c418c196cb2297b226be6830275e13563c08a4,35,6,7,23567,,,0,"Pools support with Network Policies

This patch adapts the pools support to the use of Network Policies.
Unlike with the other drivers, when Network Policies are applied the
pods' ports changes their security groups while being used. That means
their original pool will not fit them anymore with the next two
consequences:
1.- Ports will have their original SG reapplied when pods are deleted,
with the consequent performance impact do to increasing the number of
calls to neutron
2.- Original pools may become useless, as different SGs are being used,
therefore wasting neutron ports

To accomodate for network policies, this patch removes the SG ids from
the pool key, merging all the pools with same network/project/host ids
but with different security groups into the same pool. This will not
change the behavior of the other drivers as there was a unique pool per
network/project/host ids already, i.e., the same SG ids were being used.
However, this will helps to avoid problem 1) as it is no longer
re-applying the SG, but simply putting the port back into its current
pool. And it will fix problem 2) as it will pick a port for an existing
pool that matches network/project/host ids. First it will search for one
with already matching SGs, and if not found, it will recycle one of the
others by reapplying the needed SGs (note it picks a port from one of
the pools that are less frequently used -- assumes they may belong to
a deleted NP that it is not needed anymore, thus removing the port
wastage problem)

Partially Implements: blueprint k8s-network-policies
Change-Id: I2c1e47fd5112c64b8e9984e5ac5d8572d91ac202
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/74/634674/7 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/vif_pool.py'],1,5ee222487f2880a407765eca65ac3f59bcdf3e08,bp/k8s-network-policies," def _get_pool_key(self, host, project_id, net_id=None, subnets=None): pool_key = (host, project_id, net_id) return pool_key[2] pool_key = self._get_pool_key(host_addr, project_id, None, subnets) return self._get_port_from_pool(pool_key, pod, subnets, tuple(sorted(security_groups))) eventlet.spawn(self._populate_pool, pool_key, pod, subnets, tuple(sorted(security_groups))) def _get_port_from_pool(self, pool_key, pod, subnets, security_groups): def _populate_pool(self, pool_key, pod, subnets, security_groups): pool_updates = self._last_update.get(pool_key) if pool_updates: last_update = pool_updates.get(security_groups, 0) try: if (now - oslo_cfg.CONF.vif_pool.ports_pool_update_frequency < last_update): LOG.info(""Not enough time since the last pool update"") return except AttributeError: LOG.info(""Kuryr-controller not yet ready to populate pools"") self._last_update[pool_key] = {security_groups: now} security_groups=security_groups, self._available_ports_pools.setdefault( pool_key, {}).setdefault( security_groups, []).append(vif.id) pool_key = self._get_pool_key(host_addr, project_id, vif.network.id, None) def _get_port_from_pool(self, pool_key, pod, subnets, security_groups): try: pool_ports = self._available_ports_pools[pool_key] try: port_id = pool_ports[security_groups].pop() except IndexError: # Get another port from the pool and update the SG to the # appropriate one. It uses a port from the group that was updated # longer ago pool_updates = self._last_update.get(pool_key) min_date = 0 for sg_group, date in pool_updates.items(): if date < min_date or min_date == 0: min_date = date min_sg_group = sg_group port_id = pool_ports[min_sg_group].pop() neutron = clients.get_neutron_client() neutron.update_port( port_id, { ""port"": { 'security_groups': list(security_groups) } }) eventlet.spawn(self._populate_pool, pool_key, pod, subnets, security_groups) sg_current[port['id']] = tuple(sorted( port['security_groups'])) if config.CONF.kubernetes.port_debug: 'device_id': '' LOG.warning(""Error changing name for port %s to be "" pool_key, {}).setdefault( sg_current.get(port_id), []).append(port_id) pool_key, {}).setdefault( tuple(sorted(port['security_groups'])), []).append( port['id']) for pool_key, ports in self._available_ports_pools.items(): ports_id = [p_id for sg_ports in ports.values() for p_id in sg_ports] def _get_port_from_pool(self, pool_key, pod, subnets, security_groups): try: pool_ports = self._available_ports_pools[pool_key].pop() try: port_id = pool_ports[security_groups].pop() except IndexError: # Get another port from the pool and update the SG to the # appropriate one. It uses a port from the group that was updated # longer ago pool_updates = self._last_update.get(pool_key) min_date = 0 for sg_group, date in pool_updates.items(): if date < min_date or min_date == 0: min_date = date min_sg_group = sg_group port_id = pool_ports[min_sg_group].pop() neutron = clients.get_neutron_client() neutron.update_port( port_id, { ""port"": { 'security_groups': list(security_groups) } }) eventlet.spawn(self._populate_pool, pool_key, pod, subnets, security_groups) sg_current[subport['id']] = tuple(sorted( subport['security_groups'])) if config.CONF.kubernetes.port_debug: LOG.warning(""Error changing name for port %s to be "" pool_key, {}).setdefault( sg_current.get(port_id), []).append(port_id) pool_key, {}).setdefault(tuple(sorted( kuryr_subport['security_groups'])), []).append(kuryr_subport['id']) self._available_ports_pools[pool_key][ tuple(sorted(kuryr_subport['security_groups'] ))].remove(kuryr_subport['id']) pool_key = self._get_pool_key(trunk_ip, project_id, None, subnets) self._available_ports_pools.setdefault(pool_key, {}).setdefault( tuple(sorted(security_groups)), []).append(vif.id) for pool_key, ports in self._available_ports_pools.items(): ports_id = [p_id for sg_ports in ports.values() for p_id in sg_ports] try: self._drv_vif._remove_subports(neutron, trunk_id, ports_id) for port_id in ports_id:"," def _get_pool_key(self, host, project_id, security_groups, net_id=None, subnets=None): pool_key = (host, project_id, tuple(sorted(security_groups)), net_id) return pool_key[3] pool_key = self._get_pool_key(host_addr, project_id, security_groups, None, subnets) return self._get_port_from_pool(pool_key, pod, subnets) eventlet.spawn(self._populate_pool, pool_key, pod, subnets) def _get_port_from_pool(self, pool_key, pod, subnets): def _populate_pool(self, pool_key, pod, subnets): try: if (now - oslo_cfg.CONF.vif_pool.ports_pool_update_frequency < self._last_update.get(pool_key, 0)): LOG.info(""Not enough time since the last pool update"") except AttributeError: LOG.info(""Kuryr-controller not yet ready to populate pools"") return self._last_update[pool_key] = now security_groups=list(pool_key[2]), self._available_ports_pools.setdefault(pool_key, []).append(vif.id) pool_key = self._get_pool_key(host_addr, project_id, security_groups, vif.network.id, None) def _get_port_from_pool(self, pool_key, pod, subnets): try: port_id = self._available_ports_pools[pool_key].pop() eventlet.spawn(self._populate_pool, pool_key, pod, subnets) sg_current[port['id']] = port['security_groups'] if (config.CONF.kubernetes.port_debug or list(pool_key[2]) != sg_current.get(port_id)): 'device_id': '', 'security_groups': list(pool_key[2]) LOG.warning(""Error preparing port %s to be "" pool_key, []).append(port_id) port['security_groups'], pool_key, []).append(port['id']) for pool_key, ports_id in self._available_ports_pools.items(): def _get_port_from_pool(self, pool_key, pod, subnets): try: port_id = self._available_ports_pools[pool_key].pop() eventlet.spawn(self._populate_pool, pool_key, pod, subnets) sg_current[subport['id']] = subport['security_groups'] if (config.CONF.kubernetes.port_debug or list(pool_key[2]) != sg_current.get(port_id)): 'security_groups': list(pool_key[2]) LOG.warning(""Error preparing port %s to be "" pool_key, []).append(port_id) kuryr_subport[ 'security_groups'], pool_key, []).append(kuryr_subport['id']) self._available_ports_pools[pool_key].remove( kuryr_subport['id']) pool_key = self._get_pool_key(trunk_ip, project_id, security_groups, None, subnets) self._available_ports_pools.setdefault(pool_key, []).append(vif.id) for pool_key, ports_ids in self._available_ports_pools.items(): try: self._drv_vif._remove_subports(neutron, trunk_id, ports_ids) for port_id in ports_ids:",110,58
openstack%2Fdiskimage-builder~master~Ib6c8305bee74c9dd783355686629cdb7c789a129,openstack/diskimage-builder,master,Ib6c8305bee74c9dd783355686629cdb7c789a129,Install pyliblzma with pip instead of distro packages,NEW,2019-02-08 17:27:04.000000000,2019-02-12 11:23:26.000000000,,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 17:27:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/d5521525f92a183f968a53dc345c06566cd22d08', 'message': ""Install pyliblzma with pip instead of distro packages\n\nWe're currently installing pyliblzma from distro pacakges. This is\nproblematic for using the opendevorg/python-builder builder image\nfor making docker images, as that uses the python:slim base image\nwhich has an upstream install of python directly from source, so\npython packages installed from distro confuse things. (it also\ndoesn't handle python2/python3 as well)\n\nSwitch to installing it from requirements.txt like everything else.\n\nChange-Id: Ib6c8305bee74c9dd783355686629cdb7c789a129\nDepends-On: https://review.openstack.org/635891\n""}, {'number': 2, 'created': '2019-02-12 07:54:58.000000000', 'files': ['requirements.txt', 'bindep.txt'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/564b5bc74f28513c4208623973626d4093937637', 'message': ""Install pyliblzma with pip instead of distro packages\n\nWe're currently installing pyliblzma from distro pacakges. This is\nproblematic for using the opendevorg/python-builder builder image\nfor making docker images, as that uses the python:slim base image\nwhich has an upstream install of python directly from source, so\npython packages installed from distro confuse things. (it also\ndoesn't handle python2/python3 as well)\n\nSwitch to installing it from requirements.txt like everything else.\nNote it is only python2 compatible, Python 3 has an inbuilt lzma\nlibrary in stdlib.\n\nChange-Id: Ib6c8305bee74c9dd783355686629cdb7c789a129\nDepends-On: https://review.openstack.org/635891\n""}]",1,635892,564b5bc74f28513c4208623973626d4093937637,14,4,2,2,,,0,"Install pyliblzma with pip instead of distro packages

We're currently installing pyliblzma from distro pacakges. This is
problematic for using the opendevorg/python-builder builder image
for making docker images, as that uses the python:slim base image
which has an upstream install of python directly from source, so
python packages installed from distro confuse things. (it also
doesn't handle python2/python3 as well)

Switch to installing it from requirements.txt like everything else.
Note it is only python2 compatible, Python 3 has an inbuilt lzma
library in stdlib.

Change-Id: Ib6c8305bee74c9dd783355686629cdb7c789a129
Depends-On: https://review.openstack.org/635891
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/92/635892/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'bindep.txt']",2,d5521525f92a183f968a53dc345c06566cd22d08,635892,liblzma-dev [compile test platform:dpkg]lzma-devel [compile test platform:redhat]lzma-devel [compile test platform:suse],python-lzma [platform:dpkg]python-pyliblzma [platform:suse],4,2
openstack%2Fnova~master~Icbe27c941c9b934f8f1894e9b9da1d34f047e942,openstack/nova,master,Icbe27c941c9b934f8f1894e9b9da1d34f047e942,Plumbing for ignoring list_records_by_skipping_down_cells,MERGED,2019-02-06 10:10:33.000000000,2019-02-12 11:23:04.000000000,2019-02-09 07:08:16.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-06 10:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4899bf30fd1794629de6d06a6eee74d90732f16b', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}, {'number': 2, 'created': '2019-02-06 12:41:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8bf886744941a564d9522fe98658640473c44c0a', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}, {'number': 3, 'created': '2019-02-07 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d9bd5b1377acf4468c89422fa471de6c8325d775', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}, {'number': 4, 'created': '2019-02-08 14:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecd0d0c3572f77b844e5dd9657204d23ada12318', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}, {'number': 5, 'created': '2019-02-08 21:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a798d1f81b3fedd783273cef0b2f8d763b1f83f', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nThe description of list_records_by_skipping_down_cells is updated\nin Id9f12532897912b39093f63e9286540d9029edeb when the microversion\nis added.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}, {'number': 6, 'created': '2019-02-08 21:29:07.000000000', 'files': ['nova/compute/instance_list.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_instance_list.py', 'nova/compute/api.py', 'nova/compute/multi_cell_list.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/646d5757441a4dd80a2962847ef81e25d5506968', 'message': 'Plumbing for ignoring list_records_by_skipping_down_cells\n\nThis patch adds the plumbing required to ignore the value of the\n``[api]/list_records_by_skipping_down_cells`` config from the new\nmicroversion if cell_down_support is True. This config will be\nconsidered only if cell_down_support is False in which case we\nlook at the [api]/list_records_by_skipping_down_cells and\naccordingly skip the records from the down cells or generate an\nAPI exception as the response.\n\nThe description of list_records_by_skipping_down_cells is updated\nin Id9f12532897912b39093f63e9286540d9029edeb when the microversion\nis added.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942\n'}]",14,635121,646d5757441a4dd80a2962847ef81e25d5506968,49,11,6,26936,,,0,"Plumbing for ignoring list_records_by_skipping_down_cells

This patch adds the plumbing required to ignore the value of the
``[api]/list_records_by_skipping_down_cells`` config from the new
microversion if cell_down_support is True. This config will be
considered only if cell_down_support is False in which case we
look at the [api]/list_records_by_skipping_down_cells and
accordingly skip the records from the down cells or generate an
API exception as the response.

The description of list_records_by_skipping_down_cells is updated
in Id9f12532897912b39093f63e9286540d9029edeb when the microversion
is added.

Related to blueprint handling-down-cell

Change-Id: Icbe27c941c9b934f8f1894e9b9da1d34f047e942
",git fetch https://review.opendev.org/openstack/nova refs/changes/21/635121/5 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/instance_list.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/conf/api.py', 'nova/tests/unit/compute/test_instance_list.py', 'nova/compute/api.py', 'nova/compute/multi_cell_list.py']",6,4899bf30fd1794629de6d06a6eee74d90732f16b,bp/handling-down-cell," :param cell_down_support: True if the API (and caller) support returning a minimal instance construct if the relevant cell is down. If its True, then the value of CONF.api.list_records_by_skipping_down_cells is ignored and if its False, results are either skipped or erred based on the value of CONF.api.list_records_by_skipping_down_cells. cell_down_support = kwargs.pop('cell_down_support', False) if (not CONF.api.list_records_by_skipping_down_cells and not cell_down_support): # Value the config # ``CONF.api.list_records_by_skipping_down_cells`` only if # cell_down_support is False and generate the exception # if CONF.api.list_records_by_skipping_down_cells is False. # In all other cases the results from the down cell should # be skipped now to either construct minimal constructs # later if cell_down_support is True or to simply return # the skipped results if cell_down_support is False. raise exception.NovaException( _('Cell %s is not responding but configuration ' 'indicates that we should fail.') % item.cell_uuid)", if not CONF.api.list_records_by_skipping_down_cells: raise exception.NovaException( _('Cell %s is not responding but configuration ' 'indicates that we should fail.') % item.cell_uuid),55,23
openstack%2Fnova~master~Id1461c444f0f67b29e0a6a10181267ef1d1d8bc0,openstack/nova,master,Id1461c444f0f67b29e0a6a10181267ef1d1d8bc0,Convert CPU_TRAITS_MAPPING to use os_traits,MERGED,2019-02-08 19:26:13.000000000,2019-02-12 11:20:03.000000000,2019-02-09 07:54:43.000000000,"[{'_account_id': 7}, {'_account_id': 4690}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-08 19:26:13.000000000', 'files': ['nova/virt/libvirt/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c5761f6544675ba854eaa998787780e32025dec4', 'message': ""Convert CPU_TRAITS_MAPPING to use os_traits\n\nNow that os_traits provides symbols for each trait, we can refer to\ntraits by symbol rather than by string.  This gives us compile-time\nchecking for free, in order to ensure that nova's use of traits lines\nup with what os_traits provides.\n\nChange-Id: Id1461c444f0f67b29e0a6a10181267ef1d1d8bc0\n""}]",0,635919,c5761f6544675ba854eaa998787780e32025dec4,20,12,1,2394,,,0,"Convert CPU_TRAITS_MAPPING to use os_traits

Now that os_traits provides symbols for each trait, we can refer to
traits by symbol rather than by string.  This gives us compile-time
checking for free, in order to ensure that nova's use of traits lines
up with what os_traits provides.

Change-Id: Id1461c444f0f67b29e0a6a10181267ef1d1d8bc0
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/635919/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/utils.py'],1,c5761f6544675ba854eaa998787780e32025dec4,use-os-trait-consts,"import os_traits '3dnow': os_traits.HW_CPU_X86_3DNOW, 'abm': os_traits.HW_CPU_X86_ABM, 'aes': os_traits.HW_CPU_X86_AESNI, 'avx': os_traits.HW_CPU_X86_AVX, 'avx2': os_traits.HW_CPU_X86_AVX2, 'avx512bw': os_traits.HW_CPU_X86_AVX512BW, 'avx512cd': os_traits.HW_CPU_X86_AVX512CD, 'avx512dq': os_traits.HW_CPU_X86_AVX512DQ, 'avx512er': os_traits.HW_CPU_X86_AVX512ER, 'avx512f': os_traits.HW_CPU_X86_AVX512F, 'avx512pf': os_traits.HW_CPU_X86_AVX512PF, 'avx512vl': os_traits.HW_CPU_X86_AVX512VL, 'bmi1': os_traits.HW_CPU_X86_BMI, 'bmi2': os_traits.HW_CPU_X86_BMI2, 'pclmuldq': os_traits.HW_CPU_X86_CLMUL, 'f16c': os_traits.HW_CPU_X86_F16C, 'fma': os_traits.HW_CPU_X86_FMA3, 'fma4': os_traits.HW_CPU_X86_FMA4, 'mmx': os_traits.HW_CPU_X86_MMX, 'mpx': os_traits.HW_CPU_X86_MPX, 'sha-ni': os_traits.HW_CPU_X86_SHA, 'sse': os_traits.HW_CPU_X86_SSE, 'sse2': os_traits.HW_CPU_X86_SSE2, 'sse3': os_traits.HW_CPU_X86_SSE3, 'sse4.1': os_traits.HW_CPU_X86_SSE41, 'sse4.2': os_traits.HW_CPU_X86_SSE42, 'sse4a': os_traits.HW_CPU_X86_SSE4A, 'ssse3': os_traits.HW_CPU_X86_SSSE3, 'svm': os_traits.HW_CPU_X86_SVM, 'tbm': os_traits.HW_CPU_X86_TBM, 'vmx': os_traits.HW_CPU_X86_VMX, 'xop': os_traits.HW_CPU_X86_XOP"," '3dnow': 'HW_CPU_X86_3DNOW', 'abm': 'HW_CPU_X86_ABM', 'aes': 'HW_CPU_X86_AESNI', 'avx': 'HW_CPU_X86_AVX', 'avx2': 'HW_CPU_X86_AVX2', 'avx512bw': 'HW_CPU_X86_AVX512BW', 'avx512cd': 'HW_CPU_X86_AVX512CD', 'avx512dq': 'HW_CPU_X86_AVX512DQ', 'avx512er': 'HW_CPU_X86_AVX512ER', 'avx512f': 'HW_CPU_X86_AVX512F', 'avx512pf': 'HW_CPU_X86_AVX512PF', 'avx512vl': 'HW_CPU_X86_AVX512VL', 'bmi1': 'HW_CPU_X86_BMI', 'bmi2': 'HW_CPU_X86_BMI2', 'pclmuldq': 'HW_CPU_X86_CLMUL', 'f16c': 'HW_CPU_X86_F16C', 'fma': 'HW_CPU_X86_FMA3', 'fma4': 'HW_CPU_X86_FMA4', 'mmx': 'HW_CPU_X86_MMX', 'mpx': 'HW_CPU_X86_MPX', 'sha-ni': 'HW_CPU_X86_SHA', 'sse': 'HW_CPU_X86_SSE', 'sse2': 'HW_CPU_X86_SSE2', 'sse3': 'HW_CPU_X86_SSE3', 'sse4.1': 'HW_CPU_X86_SSE41', 'sse4.2': 'HW_CPU_X86_SSE42', 'sse4a': 'HW_CPU_X86_SSE4A', 'ssse3': 'HW_CPU_X86_SSSE3', 'svm': 'HW_CPU_X86_SVM', 'tbm': 'HW_CPU_X86_TBM', 'vmx': 'HW_CPU_X86_VMX', 'xop': 'HW_CPU_X86_XOP'",33,32
openstack%2Frpm-packaging~master~I6f5bb1ff56219df46116a47b00064f718085d256,openstack/rpm-packaging,master,I6f5bb1ff56219df46116a47b00064f718085d256,Set BuildArch for watcher-doc.,MERGED,2019-02-12 10:46:45.000000000,2019-02-12 11:16:08.000000000,2019-02-12 11:15:31.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-12 10:46:45.000000000', 'files': ['openstack/watcher/watcher.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/2020ad08decc5256be364747adb7166068fb5b14', 'message': 'Set BuildArch for watcher-doc.\n\nChange-Id: I6f5bb1ff56219df46116a47b00064f718085d256\n'}]",0,636302,2020ad08decc5256be364747adb7166068fb5b14,11,6,1,12542,,,0,"Set BuildArch for watcher-doc.

Change-Id: I6f5bb1ff56219df46116a47b00064f718085d256
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/02/636302/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/watcher/watcher.spec.j2'],1,2020ad08decc5256be364747adb7166068fb5b14,watcher-doc-buildarch,BuildArch: noarch,,1,0
openstack%2Fmanila~master~Ia9d10bb808faeb788a179de332fc1eccf75ee9e4,openstack/manila,master,Ia9d10bb808faeb788a179de332fc1eccf75ee9e4,Increase lvm job timeout,ABANDONED,2019-02-11 10:10:28.000000000,2019-02-12 10:55:28.000000000,,"[{'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 26968}]","[{'number': 1, 'created': '2019-02-11 10:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/13bae3cd904cf565e53c11214d0d4c35349279ee', 'message': 'Increase lvm job timeout\n\nThis job often times out, e.g. [1] and we use a\nlot more resources rechecking than we would just giving\nit more time to complete.\n\nChange-Id: Ia9d10bb808faeb788a179de332fc1eccf75ee9e4\n'}, {'number': 2, 'created': '2019-02-11 12:26:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/77c6159cc2035a3c524e68263d78d1cf8b7efa5f', 'message': 'Increase lvm job timeout\n\nThis job often times out, e.g. [1] and we use a\nlot more resources rechecking than we would just giving\nit more time to complete.\n\n[1] http://logs.openstack.org/04/633904/2/check/manila-tempest-minimal-dsvm-lvm-centos-7/8340a27/job-output.txt.gz#_2019-02-11_07_05_38_823525\n\nChange-Id: Ia9d10bb808faeb788a179de332fc1eccf75ee9e4\n'}]",0,636109,77c6159cc2035a3c524e68263d78d1cf8b7efa5f,23,13,2,9003,,,0,"Increase lvm job timeout

This job often times out, e.g. [1] and we use a
lot more resources rechecking than we would just giving
it more time to complete.

[1] http://logs.openstack.org/04/633904/2/check/manila-tempest-minimal-dsvm-lvm-centos-7/8340a27/job-output.txt.gz#_2019-02-11_07_05_38_823525

Change-Id: Ia9d10bb808faeb788a179de332fc1eccf75ee9e4
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/636109/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,13bae3cd904cf565e53c11214d0d4c35349279ee,, timeout: 10800, timeout: 5400,1,1
openstack%2Fnova~master~I80a65bc026e26a272a9dc041b27f9839511db765,openstack/nova,master,I80a65bc026e26a272a9dc041b27f9839511db765,Modify InstanceMappingList.get_not_deleted_by_cell_and_project(),MERGED,2019-02-06 10:10:33.000000000,2019-02-12 10:44:53.000000000,2019-02-09 06:56:18.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-06 10:10:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1cc6525996cc2e2b98d449c790320f131f097c96', 'message': 'Modify InstanceMappingList.get_not_deleted_by_cell_and_project()\n\n1) Change it to accommodate querying it for \'None\' project_ids\n   in the ""--all-tenats"" case.\n2) Because of the way we did the data migration for queued_for_delete\n   new records will be NULL while the ones that were migrated will be\n   false(). We need to accommodate both of these while returning\n   non-deleted instance_mappigns.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I80a65bc026e26a272a9dc041b27f9839511db765\n'}, {'number': 2, 'created': '2019-02-07 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b0eb4c5f8c7768b2c5cefdb6c5b3e8688f65b1ba', 'message': 'Modify InstanceMappingList.get_not_deleted_by_cell_and_project()\n\n1) Change it to accommodate querying it for \'None\' project_ids\n   in the ""--all-tenats"" case.\n2) If the online data migration for populating queued_for_delete\n   has not been run for some reason, the the values could be NULL\n   in the database for instance_mapping.queued_for_delete. Under\n   such circumstances, we assume that such mappings with NULL\n   queued_for_delete have *not* being queued_for_deletion.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I80a65bc026e26a272a9dc041b27f9839511db765\n'}, {'number': 3, 'created': '2019-02-08 21:29:07.000000000', 'files': ['nova/tests/functional/db/test_instance_mapping.py', 'nova/objects/instance_mapping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5c6c816d8c83e892c6dba4b5edb318d6c288ec7a', 'message': 'Modify InstanceMappingList.get_not_deleted_by_cell_and_project()\n\n1) Change it to accommodate querying it for \'None\' project_ids\n   in the ""--all-tenats"" case.\n2) If the online data migration for populating queued_for_delete\n   has not been run for some reason, the the values could be NULL\n   in the database for instance_mapping.queued_for_delete. Under\n   such circumstances, we assume that such mappings with NULL\n   queued_for_delete have *not* being queued_for_deletion.\n\nRelated to blueprint handling-down-cell\n\nChange-Id: I80a65bc026e26a272a9dc041b27f9839511db765\n'}]",11,635120,5c6c816d8c83e892c6dba4b5edb318d6c288ec7a,47,11,3,26936,,,0,"Modify InstanceMappingList.get_not_deleted_by_cell_and_project()

1) Change it to accommodate querying it for 'None' project_ids
   in the ""--all-tenats"" case.
2) If the online data migration for populating queued_for_delete
   has not been run for some reason, the the values could be NULL
   in the database for instance_mapping.queued_for_delete. Under
   such circumstances, we assume that such mappings with NULL
   queued_for_delete have *not* being queued_for_deletion.

Related to blueprint handling-down-cell

Change-Id: I80a65bc026e26a272a9dc041b27f9839511db765
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/635120/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/db/test_instance_mapping.py', 'nova/objects/instance_mapping.py']",2,1cc6525996cc2e2b98d449c790320f131f097c96,bp/handling-down-cell,"from sqlalchemy.sql import or_ query = context.session.query(api_models.InstanceMapping) if project_id is not None: # Note that the project_id can be None in case # instances are being listed for the all-tenants case. query = query.filter_by(project_id=project_id) # Both the values NULL (for newer instances) and # False (for the older instances) mean that the instance # is not queued for deletion. query = (query.filter(or_( api_models.InstanceMapping.queued_for_delete == false(), api_models.InstanceMapping.queued_for_delete.is_(None)))", query = ( context.session.query(api_models.InstanceMapping) .filter_by(project_id=project_id) .filter_by(queued_for_delete=false()),38,4
openstack%2Ftripleo-quickstart-extras~master~I6665540e139efb027bd28f629152da09f0340685,openstack/tripleo-quickstart-extras,master,I6665540e139efb027bd28f629152da09f0340685,Fix tempest init path in tempest-venv,MERGED,2019-01-25 14:26:01.000000000,2019-02-12 10:37:34.000000000,2019-02-12 10:37:34.000000000,"[{'_account_id': 8367}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-25 14:26:01.000000000', 'files': ['roles/validate-tempest/tasks/tempest-venv.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8cfab9f86b1f2f080b46286bd69bd75eb41efa99', 'message': 'Fix tempest init path in tempest-venv\n\nChange-Id: I6665540e139efb027bd28f629152da09f0340685\n'}]",0,633215,8cfab9f86b1f2f080b46286bd69bd75eb41efa99,12,7,1,20970,,,0,"Fix tempest init path in tempest-venv

Change-Id: I6665540e139efb027bd28f629152da09f0340685
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/15/633215/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/tasks/tempest-venv.yml'],1,8cfab9f86b1f2f080b46286bd69bd75eb41efa99,tempest-venv-cmd," tempest_init: ""{{ working_dir }}/tempest_git/tools/{% if release == 'newton' %}configure-tempest-directory{% else %}with_venv.sh tempest init{% endif %}"""," tempest_init: ""{{ working_dir }}/tempest_git/tools/{% if release == 'newton' %}configure-tempest-directory{% else %}with_env.sh tempest init{% endif %}""",1,1
openstack%2Fneutron~master~I388391cf697dade1a163d15ab568b33134f7b2d9,openstack/neutron,master,I388391cf697dade1a163d15ab568b33134f7b2d9,Switch isolated metadata proxy to bind to 169.254.169.254,MERGED,2018-09-06 11:59:32.000000000,2019-02-12 10:30:47.000000000,2019-02-05 13:51:37.000000000,"[{'_account_id': 1131}, {'_account_id': 4187}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2018-09-06 11:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/46726e9867f7e76ca753e5b10fa4ce0c236d2428', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n'}, {'number': 2, 'created': '2018-09-06 13:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0fb73934daf7a5a891a8550198a26003cb7065ce', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n'}, {'number': 3, 'created': '2019-01-29 00:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d411489f6ec39728837a4027aa4eafb170c0f236', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChanged set_ip_nonlocal_bind_for_namespace() to support setting the\nvalue in both the given and root namespace correctly, since it was\nonly used from inside the neutron codebase according to codesearch.\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n'}, {'number': 4, 'created': '2019-01-29 22:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/322678719cd18933481d78b69fcd8be3864abb34', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChanged set_ip_nonlocal_bind_for_namespace() to support setting the\nvalue in both the given and root namespace correctly, since it was\nonly used from inside the neutron codebase according to codesearch.\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n'}, {'number': 5, 'created': '2019-01-30 14:17:43.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/agent/l3/dvr_fip_ns.py', 'neutron/agent/l3/ha_router.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/linux/ip_lib.py', 'neutron/agent/metadata/driver.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/dhcp.py', 'neutron/agent/l3/dvr_snat_ns.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6124f6029729c3c800287f3f02329901d93ea021', 'message': 'Switch isolated metadata proxy to bind to 169.254.169.254\n\nCurrently the metadata proxy binds to default 0.0.0.0, which does not\nadd any advantage (metadata requests are not sent to random IP\naddresses), and may allow access to cloud information from\nthird parties.\n\nThis changes the generated configuration to bind to METADATA_DEFAULT_IP\naddress instead.\n\nThis is not enabled in other metadata proxy configuration (in the L3\nagent), as this would require net.ipv4.ip_nonlocal_bind everywhere\n(currently only enabled for DVR) or transparent mode in haproxy (which\nrequires net.ipv4.ip_nonlocal_bind anyway)\n\nChanged set_ip_nonlocal_bind_for_namespace() to support setting the\nvalue in both the given and root namespace correctly, since it was\nonly used from inside the neutron codebase according to codesearch.\n\nChange-Id: I388391cf697dade1a163d15ab568b33134f7b2d9\nCo-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>\nCloses-Bug: #1745618\n'}]",3,600421,6124f6029729c3c800287f3f02329901d93ea021,37,10,5,21798,,,0,"Switch isolated metadata proxy to bind to 169.254.169.254

Currently the metadata proxy binds to default 0.0.0.0, which does not
add any advantage (metadata requests are not sent to random IP
addresses), and may allow access to cloud information from
third parties.

This changes the generated configuration to bind to METADATA_DEFAULT_IP
address instead.

This is not enabled in other metadata proxy configuration (in the L3
agent), as this would require net.ipv4.ip_nonlocal_bind everywhere
(currently only enabled for DVR) or transparent mode in haproxy (which
requires net.ipv4.ip_nonlocal_bind anyway)

Changed set_ip_nonlocal_bind_for_namespace() to support setting the
value in both the given and root namespace correctly, since it was
only used from inside the neutron codebase according to codesearch.

Change-Id: I388391cf697dade1a163d15ab568b33134f7b2d9
Co-Authored-By: Andrey Arapov <andrey.arapov@nixaid.com>
Closes-Bug: #1745618
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/600421/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/tests/unit/agent/metadata/test_driver.py', 'neutron/agent/metadata/driver.py']",3,46726e9867f7e76ca753e5b10fa4ce0c236d2428,bug/1745618," bind %(host)s:%(port)s def __init__(self, network_id, router_id, unix_socket_path, host, port, user, group, state_path, pid_file): self.host = host 'host': self.host, def _get_metadata_proxy_callback(cls, bind_address, port, conf, network_id=None, bind_address, bind_address=""0.0.0.0"", network_id=None, router_id=None): bind_address, port, conf, network_id=network_id, router_id=router_id) proxy.metadata_access_mark):"," bind 0.0.0.0:%(port)s def __init__(self, network_id, router_id, unix_socket_path, port, user, group, state_path, pid_file): def _get_metadata_proxy_callback(cls, port, conf, network_id=None, network_id=None, router_id=None): port, conf, network_id=network_id, router_id=router_id) proxy.metadata_access_mark):",18,10
openstack%2Fnova~master~I201efac7199db6331809d018ec6780a7c4993764,openstack/nova,master,I201efac7199db6331809d018ec6780a7c4993764,WIP scheduler: check request_spec.instance_group before updating,ABANDONED,2018-08-10 09:59:17.000000000,2019-02-12 10:27:36.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-08-10 09:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1dea5ec938896e10113861b04c6f61a127f5344', 'message': 'WIP scheduler: check request_spec.instance_group before updating\n\nChange-Id: I201efac7199db6331809d018ec6780a7c4993764\n'}, {'number': 2, 'created': '2018-08-13 08:34:15.000000000', 'files': ['nova/scheduler/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d136dfd437b4203c11b67d6dc19e403f24a6d55f', 'message': 'WIP scheduler: check request_spec.instance_group before updating\n\nWIP until I understand how this can happen.\n\nCloses-Bug: #1786451\nChange-Id: I201efac7199db6331809d018ec6780a7c4993764\n'}]",0,590733,d136dfd437b4203c11b67d6dc19e403f24a6d55f,26,12,2,10135,,,0,"WIP scheduler: check request_spec.instance_group before updating

WIP until I understand how this can happen.

Closes-Bug: #1786451
Change-Id: I201efac7199db6331809d018ec6780a7c4993764
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/590733/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/utils.py'],1,e1dea5ec938896e10113861b04c6f61a127f5344,bug/1786451, if request_spec.instance_group and group_info is not None:, if group_info is not None:,1,1
openstack%2Fblazar~master~Id9a23a3fd92597c87dcdfba7b8e73e720b0ab656,openstack/blazar,master,Id9a23a3fd92597c87dcdfba7b8e73e720b0ab656,Raise error if resource provider is not found,MERGED,2019-02-05 10:29:15.000000000,2019-02-12 09:58:33.000000000,2019-02-12 09:58:33.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-05 10:29:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/4895ac610036ccfdf22dad6e68a567b603720f8d', 'message': 'WIP: Fail first if resource provider is not found\n\nChange-Id: Id9a23a3fd92597c87dcdfba7b8e73e720b0ab656\nRelated-Bug: #1814594\n'}, {'number': 2, 'created': '2019-02-06 08:04:35.000000000', 'files': ['blazar/utils/openstack/placement.py', 'blazar/tests/utils/openstack/test_placement.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/41efc33338064f349890e7ee3528eb95a9804b8b', 'message': 'Raise error if resource provider is not found\n\nOn reservation provider creation, dict key error occurred if the host\nresource provider is not found, which is difficult to debug. This\npatch changes it to raise a more understandable one,\nResourceProviderNotFound error.\n\nChange-Id: Id9a23a3fd92597c87dcdfba7b8e73e720b0ab656\nRelated-Bug: #1814594\n'}]",0,634906,41efc33338064f349890e7ee3528eb95a9804b8b,9,3,2,25625,,,0,"Raise error if resource provider is not found

On reservation provider creation, dict key error occurred if the host
resource provider is not found, which is difficult to debug. This
patch changes it to raise a more understandable one,
ResourceProviderNotFound error.

Change-Id: Id9a23a3fd92597c87dcdfba7b8e73e720b0ab656
Related-Bug: #1814594
",git fetch https://review.opendev.org/openstack/blazar refs/changes/06/634906/2 && git format-patch -1 --stdout FETCH_HEAD,['blazar/utils/openstack/placement.py'],1,4895ac610036ccfdf22dad6e68a567b603720f8d,bug/1814594," msg = (""No such resource provider %(name)s."") args = {'name': rp_name} LOG.error(msg, args) raise exceptions.ResourceProviderRetrievalFailed(name=rp_name)", return None,4,1
openstack%2Fkolla-ansible~master~I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27,openstack/kolla-ansible,master,I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27,Add a configuration about docker runtime directory,MERGED,2018-01-17 14:57:10.000000000,2019-02-12 09:53:36.000000000,2018-03-14 07:14:46.000000000,"[{'_account_id': 1390}, {'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 19930}, {'_account_id': 22348}, {'_account_id': 25113}, {'_account_id': 25167}]","[{'number': 1, 'created': '2018-01-17 14:57:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0ffb0a1a62ddd7a6d84d3b0e10c300adacd14c16', 'message': 'Add a configuration about docker runtime directory\n\nSometimes,control the disk space used fo Docker images, containers and\nvolumes is important for us.\n\nChange-Id: I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27\nSigned-off-by: pengdake <19921207pq@gmail.com>\n'}, {'number': 2, 'created': '2018-01-18 03:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3df83316c72596eae8278194cf134fce571f14eb', 'message': 'Add a configuration about docker runtime directory\n\nControl the disk space used fo Docker images, containers and\nvolumes is important for us.We can add configuration of docker daemon\nto control.\n\nChange-Id: I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27\nSigned-off-by: pengdake <19921207pq@gmail.com>\n'}, {'number': 3, 'created': '2018-01-18 06:27:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6f84ca53776731bbe9ed5dbc35057e49bbb9948f', 'message': 'Add a configuration about docker runtime directory\n\nControl the disk space used for Docker images, containers and\nvolumes is important for us.We need add configuration of\ndocker daemon to control the disk spaces used for docker images,\ncontainers and volumes.\n\nChange-Id: I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27\nSigned-off-by: pengdake <19921207pq@gmail.com>\n'}, {'number': 4, 'created': '2018-01-18 10:10:31.000000000', 'files': ['releasenotes/notes/support-docker-runtime-directory-set-da7e77a70626c0d1.yaml', 'ansible/roles/baremetal/templates/docker_systemd_service.j2', 'ansible/roles/baremetal/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f3e19ecf7bcdb94f82e3ef6356dadf96b255d7c6', 'message': 'Add a configuration about docker runtime directory\n\nControl the disk space used for Docker images, containers and\nvolumes is important for us.We need add configuration of\ndocker daemon to control the disk spaces used for docker images,\ncontainers and volumes.\n\nChange-Id: I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27\nSigned-off-by: pengdake <19921207pq@gmail.com>\n'}]",2,534778,f3e19ecf7bcdb94f82e3ef6356dadf96b255d7c6,26,7,4,25167,,,0,"Add a configuration about docker runtime directory

Control the disk space used for Docker images, containers and
volumes is important for us.We need add configuration of
docker daemon to control the disk spaces used for docker images,
containers and volumes.

Change-Id: I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27
Signed-off-by: pengdake <19921207pq@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/78/534778/4 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/baremetal/templates/docker_systemd_service.j2', 'ansible/roles/baremetal/defaults/main.yml']",2,0ffb0a1a62ddd7a6d84d3b0e10c300adacd14c16,I3cf99f4e3f62c8406d37201b1cc24a83c68e3b27,"docker_runtime_directory: """" ",,3,1
openstack%2Fcharm-ceph-osd~stable%2F18.11~I17fab658511275f1dde15683ef296d4c72e7980e,openstack/charm-ceph-osd,stable/18.11,I17fab658511275f1dde15683ef296d4c72e7980e,Ensure we populate osd-devices with existing devices,MERGED,2019-02-11 07:19:09.000000000,2019-02-12 09:46:52.000000000,2019-02-12 09:46:52.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 07:19:09.000000000', 'files': ['lib/ceph/utils.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/326f366cc7f97612d5f25df26f4f0ba9c3a286e4', 'message': 'Ensure we populate osd-devices with existing devices\n\nIf an older version of ceph-osd is deployed and then\nupgraded to a version that keeps track of bootstrapped\nOSDs, then the list of osd-devices never gets updated\nwith the pre-existing devices.\n\nThis change allows us to add existing, mounted Ceph OSDs\nto the osd-devices entry in the local KV storage.\n\nChange-Id: I17fab658511275f1dde15683ef296d4c72e7980e\nCloses-Bug: #1814597\n(cherry picked from commit 9bc5abab555a77d746da221a3bbeae8e81b53fcc)\n'}]",0,636099,326f366cc7f97612d5f25df26f4f0ba9c3a286e4,11,4,1,935,,,0,"Ensure we populate osd-devices with existing devices

If an older version of ceph-osd is deployed and then
upgraded to a version that keeps track of bootstrapped
OSDs, then the list of osd-devices never gets updated
with the pre-existing devices.

This change allows us to add existing, mounted Ceph OSDs
to the osd-devices entry in the local KV storage.

Change-Id: I17fab658511275f1dde15683ef296d4c72e7980e
Closes-Bug: #1814597
(cherry picked from commit 9bc5abab555a77d746da221a3bbeae8e81b53fcc)
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/99/636099/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/utils.py'],1,326f366cc7f97612d5f25df26f4f0ba9c3a286e4,bug/1814597," try: if dev in osd_devices: log('Device {} already processed by charm,' ' skipping'.format(dev)) return if not os.path.exists(dev): log('Path {} does not exist - bailing'.format(dev)) return if not is_block_device(dev): log('Path {} is not a block device - bailing'.format(dev)) return if is_osd_disk(dev): log('Looks like {} is already an' ' OSD data or journal, skipping.'.format(dev)) if is_device_mounted(dev): osd_devices.append(dev) return if is_device_mounted(dev): log('Looks like {} is in use, skipping.'.format(dev)) return if is_active_bluestore_device(dev): log('{} is in use as an active bluestore block device,' ' skipping.'.format(dev)) osd_devices.append(dev) return if is_mapped_luks_device(dev): log('{} is a mapped LUKS device,' ' skipping.'.format(dev)) return if cmp_pkgrevno('ceph', '12.2.4') >= 0: cmd = _ceph_volume(dev, osd_journal, encrypt, bluestore, key_manager) else: cmd = _ceph_disk(dev, osd_format, osd_journal, encrypt, bluestore) try: status_set('maintenance', 'Initializing device {}'.format(dev)) log(""osdize cmd: {}"".format(cmd)) subprocess.check_call(cmd) except subprocess.CalledProcessError: try: lsblk_output = subprocess.check_output( ['lsblk', '-P']).decode('UTF-8') except subprocess.CalledProcessError as e: log(""Couldn't get lsblk output: {}"".format(e), ERROR) if ignore_errors: log('Unable to initialize device: {}'.format(dev), WARNING) if lsblk_output: log('lsblk output: {}'.format(lsblk_output), DEBUG) else: log('Unable to initialize device: {}'.format(dev), ERROR) if lsblk_output: log('lsblk output: {}'.format(lsblk_output), WARNING) raise # NOTE: Record processing of device only on success to ensure that # the charm only tries to initialize a device of OSD usage # once during its lifetime. osd_devices.append(dev) finally: db.set('osd-devices', osd_devices) db.flush()"," if dev in osd_devices: log('Device {} already processed by charm,' ' skipping'.format(dev)) return if not os.path.exists(dev): log('Path {} does not exist - bailing'.format(dev)) return if not is_block_device(dev): log('Path {} is not a block device - bailing'.format(dev)) return if is_osd_disk(dev): log('Looks like {} is already an' ' OSD data or journal, skipping.'.format(dev)) return if is_device_mounted(dev): log('Looks like {} is in use, skipping.'.format(dev)) return if is_active_bluestore_device(dev): log('{} is in use as an active bluestore block device,' ' skipping.'.format(dev)) return if is_mapped_luks_device(dev): log('{} is a mapped LUKS device,' ' skipping.'.format(dev)) return if cmp_pkgrevno('ceph', '12.2.4') >= 0: cmd = _ceph_volume(dev, osd_journal, encrypt, bluestore, key_manager) else: cmd = _ceph_disk(dev, osd_format, osd_journal, encrypt, bluestore) try: status_set('maintenance', 'Initializing device {}'.format(dev)) log(""osdize cmd: {}"".format(cmd)) subprocess.check_call(cmd) except subprocess.CalledProcessError: try: lsblk_output = subprocess.check_output( ['lsblk', '-P']).decode('UTF-8') except subprocess.CalledProcessError as e: log(""Couldn't get lsblk output: {}"".format(e), ERROR) if ignore_errors: log('Unable to initialize device: {}'.format(dev), WARNING) if lsblk_output: log('lsblk output: {}'.format(lsblk_output), DEBUG) else: log('Unable to initialize device: {}'.format(dev), ERROR) if lsblk_output: log('lsblk output: {}'.format(lsblk_output), WARNING) raise # NOTE: Record processing of device only on success to ensure that # the charm only tries to initialize a device of OSD usage # once during its lifetime. osd_devices.append(dev) db.set('osd-devices', osd_devices) db.flush()",74,69
openstack%2Fpuppet-glance~stable%2Frocky~I474806d74c2815ca8899b74ee619e5107d81cc24,openstack/puppet-glance,stable/rocky,I474806d74c2815ca8899b74ee619e5107d81cc24,Add missing glance cinder store settings,MERGED,2019-01-24 05:27:10.000000000,2019-02-12 09:27:11.000000000,2019-02-04 09:09:49.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 19138}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-24 05:27:10.000000000', 'files': ['manifests/backend/cinder.pp', 'spec/classes/glance_backend_cinder_spec.rb', 'releasenotes/notes/add-missing-cinder-store-settings-f7aef33ec122a39a.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/db0b4b8d20aa0becc5bd78fc7d2593bd2d2228d1', 'message': 'Add missing glance cinder store settings\n\nIn case of cinder backend of glance, for public images,\ncinder should have dedicated tenant for glance.\n\nSo adding below conf params for cinder backend,\n\n- cinder_store_project_name\n- cinder_store_user_name\n- cinder_store_password\n\nCloses-Bug: #1809104\nChange-Id: I474806d74c2815ca8899b74ee619e5107d81cc24\n(cherry picked from commit 57f5853a4e64c6064b0d8aada6362bdf8bcb9290)\n'}]",0,632928,db0b4b8d20aa0becc5bd78fc7d2593bd2d2228d1,15,5,1,19138,,,0,"Add missing glance cinder store settings

In case of cinder backend of glance, for public images,
cinder should have dedicated tenant for glance.

So adding below conf params for cinder backend,

- cinder_store_project_name
- cinder_store_user_name
- cinder_store_password

Closes-Bug: #1809104
Change-Id: I474806d74c2815ca8899b74ee619e5107d81cc24
(cherry picked from commit 57f5853a4e64c6064b0d8aada6362bdf8bcb9290)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/28/632928/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/backend/cinder.pp', 'spec/classes/glance_backend_cinder_spec.rb', 'releasenotes/notes/add-missing-cinder-store-settings-f7aef33ec122a39a.yaml']",3,db0b4b8d20aa0becc5bd78fc7d2593bd2d2228d1,bug/1809104-stable/rocky,"--- features: - | Add new parameter 'cinder_store_project_name', for project name where the image volume is stored in cinder. Add new parameter 'cinder_store_user_name', for user name to authenticate against cinder. Add new parameter 'cinder_store_password', for valid password for the user specified by 'cinder_store_user_name' ",,47,0
openstack%2Fnetworking-ovn~master~I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20,openstack/networking-ovn,master,I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20,Add debug info to devstack to capture NAT related details.,ABANDONED,2018-09-13 22:49:44.000000000,2019-02-12 09:17:43.000000000,,"[{'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 8871}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-09-13 22:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/6abd784e22d95975bf6c0bebeb8e3fa5814d946d', 'message': 'Add debug info to devstack to capture NAT related details.\n\nThe purpose of this patch is to periodically dump the NAT entries\nand related lflows in a way that it will help us debug bug\n1735154.\n\nChange-Id: I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20\nRelated-Bug: 1735154\n'}, {'number': 2, 'created': '2018-09-14 03:36:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4850efe367a08cf4a85aaaf0596130766e900163', 'message': 'Add debug info to devstack to capture NAT related details.\n\nThe purpose of this patch is to periodically dump the NAT entries\nand related lflows in a way that it will help us debug bug\n1735154.\n\nChange-Id: I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20\nRelated-Bug: 1735154\n'}, {'number': 3, 'created': '2018-10-08 14:17:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/31f0f378e0794fb33f088201d2acb8c0e10aa974', 'message': 'Add debug info to devstack to capture NAT related details.\n\nThe purpose of this patch is to periodically dump the NAT entries\nand related lflows in a way that it will help us debug bug\n1735154.\n\nChange-Id: I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20\nRelated-Bug: 1735154\n'}, {'number': 4, 'created': '2018-10-08 14:18:04.000000000', 'files': ['devstack/devstackgaterc', 'devstack/lib/networking-ovn'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/719c994e6408766ebc3b48769b8c777d61f17597', 'message': 'Add debug info to devstack to capture NAT related details.\n\nThe purpose of this patch is to periodically dump the NAT entries\nand related lflows in a way that it will help us debug bug\n1735154.\n\nChange-Id: I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20\nRelated-Bug: 1735154\n'}]",2,602490,719c994e6408766ebc3b48769b8c777d61f17597,40,6,4,8788,,,0,"Add debug info to devstack to capture NAT related details.

The purpose of this patch is to periodically dump the NAT entries
and related lflows in a way that it will help us debug bug
1735154.

Change-Id: I4fa6b53ece2142d04532dcb3e0b4df9b02e96a20
Related-Bug: 1735154
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/90/602490/1 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/devstackgaterc', 'devstack/lib/networking-ovn']",2,6abd784e22d95975bf6c0bebeb8e3fa5814d946d,bug/1735154," run_process br-int-flows ""/bin/sh -c \""set +e; while true; do echo ovs-ofctl dump-flows br-int; ovs-ofctl dump-flows br-int ; sleep 10; done; \"""" $STACK_USER root if is_service_enabled ovn-lflows ; then run_process ovn-lflows ""/bin/sh -c \""set +e; while true; do echo ovn-sbctl lflow-list; ovn-sbctl lflow-list ; sleep 10; done; \"""" $STACK_USER root fi if is_service_enabled ovn-nat-entries; then run_process ovn-nat-entries ""/bin/sh -c \""set +e; while true; do echo ovn-nbctl list NAT; ovn-nbctl list NAT; ; sleep 10; done; \"""" $STACK_USER root fi if is_service_enabled ovn-nbctl-show ; then run_process ovn-nbctl-show ""/bin/sh -c \""set +e; while true; do echo ovn-nbctl show; ovn-nbctl show; sleep 10; done; \"""" $STACK_USER root fi "," run_process br-int-flows ""/bin/sh -c \""set +e; while true; do echo ovs-ofctl dump-flows br-int; ovs-ofctl dump-flows br-int ; sleep 30; done; \"""" $STACK_USER root",15,2
openstack%2Fnetworking-ovn~master~I4d9c9e93a9fa24177edf4991c919b352b3442eea,openstack/networking-ovn,master,I4d9c9e93a9fa24177edf4991c919b352b3442eea,Add a lot of debug logging to floating ip operations,ABANDONED,2018-09-13 17:05:59.000000000,2019-02-12 09:16:49.000000000,,"[{'_account_id': 8788}, {'_account_id': 17776}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-09-13 17:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b5681395f04a39144b5482f4daa3fa105a0157bb', 'message': ""Add a lot of debug logging to floating ip operations\n\nThe messages are inteded to help us figure out why sometimes\nfloating IP entries are not inserted into the NAT table\nof the northbound database, we suspect that due to a race\ncondition.\n\nThis commit can be reverted later in the cycle when we have\nfigured out what's going on.\n\nChange-Id: I4d9c9e93a9fa24177edf4991c919b352b3442eea\nRelated-Bug: 1735154\n""}, {'number': 2, 'created': '2018-09-13 18:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c1c7b30ad494aef1da3bf3f1bd750b0c6ca04971', 'message': ""Add a lot of debug logging to floating ip operations\n\nThe messages are inteded to help us figure out why sometimes\nfloating IP entries are not inserted into the NAT table\nof the northbound database, we suspect that due to a race\ncondition.\n\nThis commit can be reverted later in the cycle when we have\nfigured out what's going on.\n\nChange-Id: I4d9c9e93a9fa24177edf4991c919b352b3442eea\nRelated-Bug: 1735154\n""}, {'number': 3, 'created': '2018-09-14 21:08:36.000000000', 'files': ['networking_ovn/common/ovn_client.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/ce893a5d616afd9ef6a512d7e2972212badb6edd', 'message': ""Add a lot of debug logging to floating ip operations\n\nThe messages are inteded to help us figure out why sometimes\nfloating IP entries are not inserted into the NAT table\nof the northbound database, we suspect that due to a race\ncondition.\n\nThis commit can be reverted later in the cycle when we have\nfigured out what's going on.\n\nChange-Id: I4d9c9e93a9fa24177edf4991c919b352b3442eea\nRelated-Bug: 1735154\n""}]",5,602397,ce893a5d616afd9ef6a512d7e2972212badb6edd,19,4,3,8788,,,0,"Add a lot of debug logging to floating ip operations

The messages are inteded to help us figure out why sometimes
floating IP entries are not inserted into the NAT table
of the northbound database, we suspect that due to a race
condition.

This commit can be reverted later in the cycle when we have
figured out what's going on.

Change-Id: I4d9c9e93a9fa24177edf4991c919b352b3442eea
Related-Bug: 1735154
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/97/602397/3 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/common/ovn_client.py'],1,b5681395f04a39144b5482f4daa3fa105a0157bb,bug/1735154,"from oslo_log import helpers as log_helpers @log_helpers.log_method_call LOG.debug(""floating ip processing skipped, no router_id, "" ""floatingip=%s"", floatingip) func = log_helpers.log_method_call( self._nb_idl.add_nat_rule_in_lrouter) func = log_helpers.log_method_call( self._nb_idl.set_nat_rule_in_lrouter) LOG.debug(""existing NAT entry found to be updated: %s"", nat_rule) LOG.debug(""Updating/setting floating ip with %s(%s, %s)"", func, nat_rule_args, columns) @log_helpers.log_method_call @log_helpers.log_method_call @log_helpers.log_method_call @log_helpers.log_method_call LOG.debug(""ovn_fip not found, looking up via IP address for "" ""backwards compatibility."") LOG.debug(""The existing FIP nat entry changed (%s != %s), so,"" ""deleting the existing one first"", floatingip, ovn_fip) LOG.debug(""floatingip has port_id, so calling "" ""_create_or_update_floatingip"") LOG.debug(""Updating FIP %s status to %s"", floatingip['id'], fip_status) @log_helpers.log_method_call @log_helpers.log_method_call", func = self._nb_idl.add_nat_rule_in_lrouter func = self._nb_idl.set_nat_rule_in_lrouter,28,2
openstack%2Fironic-specs~master~Icfd2eed61ac80128fb374137c5cbb6b7fe04c982,openstack/ironic-specs,master,Icfd2eed61ac80128fb374137c5cbb6b7fe04c982,Add synchronize-events-with-neutron spec,MERGED,2016-07-18 14:49:15.000000000,2019-02-12 09:08:30.000000000,2018-11-29 09:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 7711}, {'_account_id': 10239}, {'_account_id': 10917}, {'_account_id': 11655}, {'_account_id': 12171}, {'_account_id': 12356}, {'_account_id': 13295}, {'_account_id': 14525}, {'_account_id': 14760}, {'_account_id': 22223}, {'_account_id': 22348}, {'_account_id': 23375}, {'_account_id': 24245}]","[{'number': 1, 'created': '2016-07-18 14:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4c9171afff4747eeb284bca8251eaa28866300cb', 'message': 'WIP: Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port status change\nsynchronization.\n\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 2, 'created': '2016-08-08 08:15:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c80feb29f741fa00cc19c8c8de66d657c8937e31', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port status change\nsynchronization with Ironic.\n\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 3, 'created': '2016-08-08 08:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/c25349ae979e9bdcb598ed637193414f47ce46c0', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port status change\nsynchronization with Ironic.\n\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 4, 'created': '2016-08-09 03:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/21b40402075086578f139333b061f31519310606', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port status change\nsynchronization with Ironic.\n\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 5, 'created': '2017-02-14 15:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4fc2c869884b1c0413bc63c4a56bc63e494dd51c', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 6, 'created': '2017-03-17 15:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2badb5129fe566e5822c22d227de1ba726bd0cba', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 7, 'created': '2017-03-17 16:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/e2397860f678038719c96d39510ad28da17ae2c8', 'message': 'Add synchronize-events-with-neutron spec.\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 8, 'created': '2017-03-22 19:02:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/739b44b44e98564e5276781a1350f84d0098dbdc', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 9, 'created': '2017-10-13 15:18:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a159ab2fb0bfad31e189cf1e64539fc0a3ffd933', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 10, 'created': '2017-11-13 18:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9f7bc7ca4ba9f9292d9a51d42727c7886fa750c1', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 11, 'created': '2018-06-18 15:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/55d5cf241c2eb94a3705daedfb2d43060129ceec', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 12, 'created': '2018-06-18 15:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/9f6224871b711165d08c31520e8e711760c857d4', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nStory: 1304673\nTask: 22150\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 13, 'created': '2018-06-20 14:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/fc8184fdee1d4e0951ba5eecb6a0220a4d865bde', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nStory: 1304673\nTask: 22150\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 14, 'created': '2018-07-17 13:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/72b4c2213aabffea6b3e045c0b95574320429eab', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nStory: 1304673\nTask: 22150\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 15, 'created': '2018-08-01 12:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/a0981d5f1359441c6da3dce83bb7b3d29f3fe53b', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nStory: 1304673\nTask: 22150\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}, {'number': 16, 'created': '2018-11-05 06:10:11.000000000', 'files': ['specs/not-implemented/synchronize-events-with-neutron.rst', 'specs/approved/synchronize-events-with-neutron.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/2724f04a89bd3344d7f326a1f9ea6bbbb9a7a4a0', 'message': 'Add synchronize-events-with-neutron spec\n\nThe spec describes implementation of Neutron port changes\nsynchronization with Ironic.\n\nStory: 1304673\nTask: 22150\nCo-Authored-By: Vladyslav Drok <vdrok@mirantis.com>\nChange-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982\n'}]",364,343684,2724f04a89bd3344d7f326a1f9ea6bbbb9a7a4a0,82,15,16,14525,,,0,"Add synchronize-events-with-neutron spec

The spec describes implementation of Neutron port changes
synchronization with Ironic.

Story: 1304673
Task: 22150
Co-Authored-By: Vladyslav Drok <vdrok@mirantis.com>
Change-Id: Icfd2eed61ac80128fb374137c5cbb6b7fe04c982
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/84/343684/16 && git format-patch -1 --stdout FETCH_HEAD,"['specs/not-implemented/synchronize-events-with-neutron.rst', 'specs/approved/synchronize-events-with-neutron.rst']",2,4c9171afff4747eeb284bca8251eaa28866300cb,story/1304673-patch10,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =============================== Synchronize events with Neutron =============================== https://bugs.launchpad.net/ironic/+bug/1304673 Updates to Neutron resources via its API are processed asynchronously on its backend. This exposes potential races with Ironic. Example: an API request from Ironic to update a port's DHCP settings will return successfully long before the associated dnsmasq config has been updated and the server restarted. There is a small potential for a race condition where Ironic will boot a machine before its DHCP has been properly configured, especially if the machine boots very quickly (ie a local VM). Another possible issue is if Neutron failed to setup port, user need to wait ``deploy_callback_timeout``. Problem description =================== Neutron operations are completely asynchronous. There is no mechanism to track for Neutron operation status at the moment. Furthermore Neutron ports remain unbound and in DOWN state due to: https://bugs.launchpad.net/neutron/+bug/1599836. Ironic should be able to receive an call-backs from Neutron when port state is changed. Only Ironic related ports should trigger notification event. Proposed change =============== When Ironic change Neutron port information (update dhcp options) or creates a port (multitenancy integration). Ironic node should go into a new state ``wait-for-network``. The node remain in ``wait-for-network`` until Ironic received an call-back from neutron with ``ACTIVE`` port state or ``wait_for_network`` timeout is reached. The call-back should be received on dedicated API endpoint ``v1/externalevents``. A JSON example of event is the followining: {""event"": { 'port_id': ""VIF UUID"", 'mac_address': ""VIF MAC address"", 'status': ""VIF port status"", 'device_id': ""VIF device ID"" } } Alternatives ------------ * Use Nuetron port status polling. * Do not synchronize events with Neutron. Data model impact ----------------- None. State Machine Impact -------------------- A new state ``wait-for-network`` is required. The node goes to ``wait-for-network`` state after change request to Neutron is done. The node will remain in ``wait-for-network`` state until call-back with ACTIVE port status is received or ``wait_for_network`` timeout is reached. In this case node goes to ``deploy failed`` state. The node can go to ``wait-for-network`` state from ``deploying`` on ``wait_network`` event, and to ``deploying`` on ``resume``. REST API impact --------------- The new endpoint ``/v1//externaevents`` needs to be created. Only authenticated POST requests are allowed to this endpoint with the following message format: {""event"": { 'port_id': ""VIF UUID"", 'mac_address': ""VIF MAC address"", 'status': ""VIF port status"", 'device_id': ""VIF device ID"" } } Once event is received Ironic will do lookup of node by ``mac_address``. When node is found and the node is in ``wait-for-network`` state we perform and RPC API call ``process_network_event``. If the node is not found we just ignoring the event. Client (CLI) impact ------------------- Client will be updated to support sending an external notification. TBD. RPC API impact -------------- A new method ``process_network_event`` is going to be added. Received external event is processed here. If port status became ``ACTIVE`` we resuming deployment of node. In case of failure (port status ``DOWN``) we do nothing, and still waiting for ``wait_for_network`` timeout. Assuming that port status may be changed. Driver API impact ----------------- DHCP provider ``update_dhcp_opts`` method will return a new state of a node ``wait_for_network``. Nova driver impact ------------------ Nova driver should set ``vnic_type=baremetal`` for Ironic instances. https://review.openstack.org/339143/ Security impact --------------- None. Other end user impact --------------------- None. Scalability impact ------------------ None. Performance Impact ------------------ TBD. Other deployer impact --------------------- None. Developer impact ---------------- TBD. Implementation ============== TBD. Assignee(s) ----------- Primary assignee: vsaienko Work Items ---------- TBD. Dependencies ============ * Ironic should be switch to use FLAT Neutron network at the gates: https://review.openstack.org/#/c/334382/ https://review.openstack.org/#/c/340695 * Neutron ML2 driver should be developed, to fix the case when Neutron ports remain in DOWN state. https://bugs.launchpad.net/neutron/+bug/1599836 The driver will perform 'fake' port binding for FLAT network. It is an Ironic pre-requirement that hardware server is pre-plugged to network. For multitenancy case nothing to be done. Existed ML2 drivers should already perform port binding. * Add new endpoint on Ironic side. Testing ======= The change will be tested at the gates. Upgrades and Backwards Compatibility ==================================== TBD. Documentation Impact ==================== TBD References ========== Discussions on the topic include: * https://bugs.launchpad.net/neutron/+bug/1599836 * https://review.openstack.org/339143 * https://review.openstack.org/334382 * https://review.openstack.org/338117 * https://review.openstack.org/340695 * https://review.openstack.org/339129 ",,218,0
openstack%2Fironic~master~Ia3de56e97f63ef06a1115ae6328a626e327a64af,openstack/ironic,master,Ia3de56e97f63ef06a1115ae6328a626e327a64af,Allocation API: fix a small inconsistency,MERGED,2019-02-11 10:17:38.000000000,2019-02-12 09:01:49.000000000,2019-02-12 09:01:49.000000000,"[{'_account_id': 10118}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 15519}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 26340}, {'_account_id': 28429}, {'_account_id': 29209}]","[{'number': 1, 'created': '2019-02-11 10:17:38.000000000', 'files': ['ironic/api/controllers/v1/allocation.py', 'ironic/tests/unit/api/controllers/v1/test_allocation.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/9741aed7be42aad3e9032e58087741dd8dcf9a3d', 'message': 'Allocation API: fix a small inconsistency\n\nCurrently the POST API returns ""null"" values for unspecified traits\nor candidate_nodes fields, while the subsequent GET API will return\nempty lists. This patch fixes it to always return empty lists.\n\nChange-Id: Ia3de56e97f63ef06a1115ae6328a626e327a64af\nStory: #2004341\n'}]",0,636110,9741aed7be42aad3e9032e58087741dd8dcf9a3d,23,12,1,10239,,,0,"Allocation API: fix a small inconsistency

Currently the POST API returns ""null"" values for unspecified traits
or candidate_nodes fields, while the subsequent GET API will return
empty lists. This patch fixes it to always return empty lists.

Change-Id: Ia3de56e97f63ef06a1115ae6328a626e327a64af
Story: #2004341
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/636110/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/allocation.py', 'ironic/tests/unit/api/controllers/v1/test_allocation.py']",2,9741aed7be42aad3e9032e58087741dd8dcf9a3d,story/2004341," self.assertEqual([], response.json['candidate_nodes']) self.assertEqual([], response.json['traits']) self.assertEqual([], result['candidate_nodes']) self.assertEqual([], result['traits'])",,10,0
openstack%2Fneutron~master~Ie53a5498e1a2152157d5b2a56abb97ba36cbf86c,openstack/neutron,master,Ie53a5498e1a2152157d5b2a56abb97ba36cbf86c,doc: replace nova security_group_api option with use_neutron,MERGED,2019-02-04 16:03:33.000000000,2019-02-12 08:50:26.000000000,2019-02-12 08:50:26.000000000,"[{'_account_id': 841}, {'_account_id': 6873}, {'_account_id': 11975}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-04 16:03:33.000000000', 'files': ['doc/source/admin/archives/use.rst', 'doc/source/admin/archives/adv-features.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a721e6d7b91c6837a65d3e43992b64d29871e8c3', 'message': 'doc: replace nova security_group_api option with use_neutron\n\nThe ""security_group_api"" config option in nova was deleted\nin the Newton release:\n\n  I921650d8730201c2f14deb7e679647a892dbe48a\n\nThe use_neutron option should be used instead. This updates\nthe docs where the security_group_api option was mentioned.\n\nChange-Id: Ie53a5498e1a2152157d5b2a56abb97ba36cbf86c\n'}]",1,634729,a721e6d7b91c6837a65d3e43992b64d29871e8c3,9,5,1,6873,,,0,"doc: replace nova security_group_api option with use_neutron

The ""security_group_api"" config option in nova was deleted
in the Newton release:

  I921650d8730201c2f14deb7e679647a892dbe48a

The use_neutron option should be used instead. This updates
the docs where the security_group_api option was mentioned.

Change-Id: Ie53a5498e1a2152157d5b2a56abb97ba36cbf86c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/634729/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/archives/use.rst', 'doc/source/admin/archives/adv-features.rst']",2,a721e6d7b91c6837a65d3e43992b64d29871e8c3,security_group_api,"``/etc/nova/nova.conf`` file and set the ``use_neutron=True`` option on every node that runs nova-compute, nova-conductor and nova-api. After you make this change, restart those nova services to pick up this change.","``/etc/nova/nova.conf`` file and set the ``security_group_api=neutron`` option on every node that runs nova-compute and nova-api. After you make this change, restart nova-api and nova-compute to pick up this change.",4,4
openstack%2Ftempest~master~Ifc9f23d150992cdcf415293439c2f51f3d75aeb3,openstack/tempest,master,Ifc9f23d150992cdcf415293439c2f51f3d75aeb3,Update v3 project tests to work w/ pre-prov,MERGED,2019-01-04 23:22:09.000000000,2019-02-12 08:46:51.000000000,2019-02-12 08:46:51.000000000,"[{'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 20378}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 23625}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-01-04 23:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/de9b2e9d149fa3d17db084edd8f4a53598ea73b3', 'message': ""Move v3 project tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for these tests:\n\n* test_project_create_with_domain\n* test_project_create_with_parent\n* test_create_is_domain_project\n* test_project_get_equals_list\n\nNote that these tests aren't interop tests [0] so can\nbe safely moved.\n\nBy setting force_tenant_isolation=False these tests now be\ncan executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nThe following tests are not moved because they are interop\ntests [0]:\n\n* test_project_create_with_description\n* test_associate_user_to_project\n* test_project_create_enabled\n* test_project_create_not_enabled\n* test_project_update_name\n* test_project_update_desc\n* test_project_update_enable\n\n[0] http://codesearch.openstack.org/?q=admin.v3.test_projects&i=nope&files=&repos=interop\n\nChange-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3\n""}, {'number': 2, 'created': '2019-01-07 13:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/afdf14d6b99f5ac85c5e3698bb64db7e6ce4bab2', 'message': ""Move v3 project tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for these tests:\n\n* test_project_create_with_domain\n* test_project_create_with_parent\n* test_create_is_domain_project\n* test_project_get_equals_list\n\nNote that these tests aren't interop tests [0] so can\nbe safely moved.\n\nBy setting force_tenant_isolation=False these tests now be\ncan executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nThe following tests are not moved because they are interop\ntests [0]:\n\n* test_project_create_with_description\n* test_associate_user_to_project\n* test_project_create_enabled\n* test_project_create_not_enabled\n* test_project_update_name\n* test_project_update_desc\n* test_project_update_enable\n\n[0] http://codesearch.openstack.org/?q=admin.v3.test_projects&i=nope&files=&repos=interop\n\nChange-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3\n""}, {'number': 3, 'created': '2019-01-17 16:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4385fbcb19b207a78b8649361dfade30473b472f', 'message': ""Move v3 project tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for these tests:\n\n* test_project_create_with_domain\n* test_project_create_with_parent\n* test_create_is_domain_project\n* test_project_get_equals_list\n* test_project_create_with_description\n* test_associate_user_to_project\n* test_project_create_enabled\n* test_project_create_not_enabled\n* test_project_update_name\n* test_project_update_desc\n* test_project_update_enable\n\nBy setting force_tenant_isolation=False these tests now be\ncan executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nChange-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3\n""}, {'number': 4, 'created': '2019-01-17 16:43:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6d454069e75e0305382746df5103cf15af277d90', 'message': ""Update v3 project tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for these tests:\n\n* test_project_create_with_domain\n* test_project_create_with_parent\n* test_create_is_domain_project\n* test_project_get_equals_list\n* test_project_create_with_description\n* test_associate_user_to_project\n* test_project_create_enabled\n* test_project_create_not_enabled\n* test_project_update_name\n* test_project_update_desc\n* test_project_update_enable\n\nBy setting force_tenant_isolation=False these tests now be\ncan executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nChange-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3\n""}, {'number': 5, 'created': '2019-02-08 21:57:58.000000000', 'files': ['tempest/api/identity/admin/v3/test_projects.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5639a970c159456396c06e122d045fb9f0d987ad', 'message': ""Update v3 project tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for these tests:\n\n* test_project_create_with_domain\n* test_project_create_with_parent\n* test_create_is_domain_project\n* test_project_get_equals_list\n* test_project_create_with_description\n* test_associate_user_to_project\n* test_project_create_enabled\n* test_project_create_not_enabled\n* test_project_update_name\n* test_project_update_desc\n* test_project_update_enable\n\nBy setting force_tenant_isolation=False these tests now be\ncan executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nChange-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3\n""}]",5,628706,5639a970c159456396c06e122d045fb9f0d987ad,34,15,5,20378,,,0,"Update v3 project tests to work w/ pre-prov

I don't see any limitations by using pre-provisioned
credentials for these tests:

* test_project_create_with_domain
* test_project_create_with_parent
* test_create_is_domain_project
* test_project_get_equals_list
* test_project_create_with_description
* test_associate_user_to_project
* test_project_create_enabled
* test_project_create_not_enabled
* test_project_update_name
* test_project_update_desc
* test_project_update_enable

By setting force_tenant_isolation=False these tests now be
can executed with backends that don't allow user creation
(immutable user source) like LDAP.

Change-Id: Ifc9f23d150992cdcf415293439c2f51f3d75aeb3
",git fetch https://review.opendev.org/openstack/tempest refs/changes/06/628706/5 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_projects.py'],1,de9b2e9d149fa3d17db084edd8f4a53598ea73b3,bug/1714277," class ProjectsStaticTestJSON(base.BaseIdentityV3AdminTest): # NOTE: force_tenant_isolation is true in the base class by default but # overridden to false here to allow test execution for clouds using the # pre-provisioned credentials provider. force_tenant_isolation = False @decorators.idempotent_id('5f50fe07-8166-430b-a882-3b2ee0abe26f') def test_project_create_with_domain(self): # Create project with a domain domain = self.setup_test_domain() project_name = data_utils.rand_name('project') project = self.setup_test_project( name=project_name, domain_id=domain['id']) project_id = project['id'] self.assertEqual(project_name, project['name']) self.assertEqual(domain['id'], project['domain_id']) body = self.projects_client.show_project(project_id)['project'] self.assertEqual(project_name, body['name']) self.assertEqual(domain['id'], body['domain_id']) @decorators.idempotent_id('1854f9c0-70bc-4d11-a08a-1c789d339e3d') def test_project_create_with_parent(self): # Create root project without providing a parent_id domain = self.setup_test_domain() domain_id = domain['id'] root_project_name = data_utils.rand_name('root_project') root_project = self.setup_test_project( name=root_project_name, domain_id=domain_id) root_project_id = root_project['id'] parent_id = root_project['parent_id'] self.assertEqual(root_project_name, root_project['name']) # If not provided, the parent_id must point to the top level # project in the hierarchy, i.e. its domain self.assertEqual(domain_id, parent_id) @decorators.idempotent_id('a7eb9416-6f9b-4dbb-b71b-7f73aaef59d5') def test_create_is_domain_project(self): project = self.setup_test_project(domain_id=None, is_domain=True) # To delete a domain, we need to disable it first self.addCleanup(self.projects_client.update_project, project['id'], enabled=False) # Check if the is_domain project is correctly returned by both # project and domain APIs projects_list = self.projects_client.list_projects( params={'is_domain': True})['projects'] project_ids = [p['id'] for p in projects_list] self.assertIn(project['id'], project_ids) # The domains API return different attributes for the entity, so we # compare the entities IDs domains_ids = [d['id'] for d in self.domains_client.list_domains()[ 'domains']] self.assertIn(project['id'], domains_ids) "," @decorators.idempotent_id('5f50fe07-8166-430b-a882-3b2ee0abe26f') def test_project_create_with_domain(self): # Create project with a domain domain = self.setup_test_domain() project_name = data_utils.rand_name('project') project = self.setup_test_project( name=project_name, domain_id=domain['id']) project_id = project['id'] self.assertEqual(project_name, project['name']) self.assertEqual(domain['id'], project['domain_id']) body = self.projects_client.show_project(project_id)['project'] self.assertEqual(project_name, body['name']) self.assertEqual(domain['id'], body['domain_id']) @decorators.idempotent_id('1854f9c0-70bc-4d11-a08a-1c789d339e3d') def test_project_create_with_parent(self): # Create root project without providing a parent_id domain = self.setup_test_domain() domain_id = domain['id'] root_project_name = data_utils.rand_name('root_project') root_project = self.setup_test_project( name=root_project_name, domain_id=domain_id) root_project_id = root_project['id'] parent_id = root_project['parent_id'] self.assertEqual(root_project_name, root_project['name']) # If not provided, the parent_id must point to the top level # project in the hierarchy, i.e. its domain self.assertEqual(domain_id, parent_id) # Create a project using root_project_id as parent_id project_name = data_utils.rand_name('project') project = self.setup_test_project( name=project_name, domain_id=domain_id, parent_id=root_project_id) parent_id = project['parent_id'] self.assertEqual(project_name, project['name']) self.assertEqual(root_project_id, parent_id) @decorators.idempotent_id('a7eb9416-6f9b-4dbb-b71b-7f73aaef59d5') def test_create_is_domain_project(self): project = self.setup_test_project(domain_id=None, is_domain=True) # To delete a domain, we need to disable it first self.addCleanup(self.projects_client.update_project, project['id'], enabled=False) # Check if the is_domain project is correctly returned by both # project and domain APIs projects_list = self.projects_client.list_projects( params={'is_domain': True})['projects'] project_ids = [p['id'] for p in projects_list] self.assertIn(project['id'], project_ids) # The domains API return different attributes for the entity, so we # compare the entities IDs domains_ids = [d['id'] for d in self.domains_client.list_domains()[ 'domains']] self.assertIn(project['id'], domains_ids) ",58,59
openstack%2Fnova~stable%2Fqueens~I1f4b3540dd453650f94333b36d7504ba164192f7,openstack/nova,stable/queens,I1f4b3540dd453650f94333b36d7504ba164192f7,Fix InstanceNotFound during _destroy_evacuated_instances,MERGED,2018-12-06 23:59:15.000000000,2019-02-12 08:42:26.000000000,2019-02-12 08:42:26.000000000,"[{'_account_id': 7166}, {'_account_id': 9373}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 28885}]","[{'number': 1, 'created': '2018-12-06 23:59:15.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1794996.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6c7e53e21059f80325d728cf7dee2766da7a9471', 'message': ""Fix InstanceNotFound during _destroy_evacuated_instances\n\nThe _destroy_evacuated_instances method on compute\nstartup tries to cleanup guests on the hypervisor and\nallocations held against that compute node resource\nprovider by evacuated instances, but doesn't take into\naccount that those evacuated instances could have been\ndeleted in the meantime which leads to a lazy-load\nInstanceNotFound error that kills the startup of the\ncompute service.\n\nThis change does two things in the _destroy_evacuated_instances\nmethod:\n\n1. Loads the evacuated instances with a read_deleted='yes'\n   context when calling _get_instances_on_driver(). This\n   should be fine since _get_instances_on_driver() is already\n   returning deleted instances anyway (InstanceList.get_by_filters\n   defaults to read deleted instances unless the filters tell\n   it otherwise - which we don't in this case). This is needed\n   so that things like driver.destroy() don't raise\n   InstanceNotFound while lazy-loading fields on the instance.\n\n2. Skips the call to remove_allocation_from_compute() if the\n   evacuated instance is already deleted. If the instance is\n   already deleted, its allocations should have been cleaned\n   up by its hosting compute service (or the API).\n\nThe functional regression test is updated to show the bug is\nnow fixed.\n\nChange-Id: I1f4b3540dd453650f94333b36d7504ba164192f7\nCloses-Bug: #1794996\n(cherry picked from commit 05cd8d128211adbbfb3cf5d626034ccd0f75a452)\n(cherry picked from commit 0208d64397731afa829bc08cd7b3b6494f0f05d5)\n""}]",0,623355,6c7e53e21059f80325d728cf7dee2766da7a9471,22,12,1,6873,,,0,"Fix InstanceNotFound during _destroy_evacuated_instances

The _destroy_evacuated_instances method on compute
startup tries to cleanup guests on the hypervisor and
allocations held against that compute node resource
provider by evacuated instances, but doesn't take into
account that those evacuated instances could have been
deleted in the meantime which leads to a lazy-load
InstanceNotFound error that kills the startup of the
compute service.

This change does two things in the _destroy_evacuated_instances
method:

1. Loads the evacuated instances with a read_deleted='yes'
   context when calling _get_instances_on_driver(). This
   should be fine since _get_instances_on_driver() is already
   returning deleted instances anyway (InstanceList.get_by_filters
   defaults to read deleted instances unless the filters tell
   it otherwise - which we don't in this case). This is needed
   so that things like driver.destroy() don't raise
   InstanceNotFound while lazy-loading fields on the instance.

2. Skips the call to remove_allocation_from_compute() if the
   evacuated instance is already deleted. If the instance is
   already deleted, its allocations should have been cleaned
   up by its hosting compute service (or the API).

The functional regression test is updated to show the bug is
now fixed.

Change-Id: I1f4b3540dd453650f94333b36d7504ba164192f7
Closes-Bug: #1794996
(cherry picked from commit 05cd8d128211adbbfb3cf5d626034ccd0f75a452)
(cherry picked from commit 0208d64397731afa829bc08cd7b3b6494f0f05d5)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/623355/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/functional/regressions/test_bug_1794996.py', 'nova/tests/unit/compute/test_compute.py', 'nova/compute/manager.py']",4,6c7e53e21059f80325d728cf7dee2766da7a9471,bug/1550919," # The instances might be deleted in which case we need to avoid # InstanceNotFound being raised from lazy-loading fields on the # instances while cleaning up this host. read_deleted_context = context.elevated(read_deleted='yes') # TODO(mriedem): We could optimize by pre-loading the joined fields # we know we'll use, like info_cache and flavor. We can also replace # this with a generic solution: https://review.openstack.org/575190/ local_instances = self._get_instances_on_driver(read_deleted_context) # If the instance was deleted in the interim, assume its # allocations were properly cleaned up (either by its hosting # compute service or the API). if (not instance.deleted and not scheduler_utils.remove_allocation_from_compute( context, instance, cn_uuid, self.reportclient)):"," local_instances = self._get_instances_on_driver(context) if not scheduler_utils.remove_allocation_from_compute( context, instance, cn_uuid, self.reportclient):",40,18
openstack%2Fkeystone~master~Id3f6159af505fbe81ff83cfaa346f2178f2d8e77,openstack/keystone,master,Id3f6159af505fbe81ff83cfaa346f2178f2d8e77,Update limit policies for system admin,MERGED,2018-11-29 21:34:28.000000000,2019-02-12 08:42:20.000000000,2019-02-12 08:42:20.000000000,"[{'_account_id': 5046}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-11-29 21:34:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/177558ee1c7c26c6761536ae767c8befc6ddd8e6', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain users\n - project users\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 2, 'created': '2018-11-30 23:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7984ffb6de85dd2f4ca027acfb714e16558d9809', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 3, 'created': '2018-12-07 17:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d3fdfe7bec5a405cfb201e274b60c521623d3821', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 4, 'created': '2018-12-11 09:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d6378ae22a6c562e0684816c579b553cc4aec1f0', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 5, 'created': '2018-12-18 22:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/afc022ed364b536758f0a3ea19a1d25f98e835d2', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 6, 'created': '2018-12-19 23:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/c446acc6949b162aee49b04ee4ecbaa4f59cea5e', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 7, 'created': '2019-01-08 18:24:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4403b9864bb2cc6a29b977b28ee4e811e71ff24b', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}, {'number': 8, 'created': '2019-01-09 14:59:44.000000000', 'files': ['keystone/tests/unit/protection/v3/test_limits.py', 'keystone/tests/unit/test_limits.py', 'keystone/tests/unit/test_v3_resource.py', 'releasenotes/notes/bug-1805372-af4ebf4b19500b72.yaml', 'keystone/common/policies/limit.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1d4e40252884f054d692e82e170d3f69228ef7ee', 'message': 'Update limit policies for system admin\n\nThis change makes the policy definitions for admin limit\noperations consistent with the other limit\npolicies. Subsequent patches will incorporate:\n\n - domain user test coverage\n - project user test coverage\n\nChange-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77\nCloses-Bug: 1805372\nRelated-Bug: 1805880\n'}]",1,621022,1d4e40252884f054d692e82e170d3f69228ef7ee,29,5,8,5046,,,0,"Update limit policies for system admin

This change makes the policy definitions for admin limit
operations consistent with the other limit
policies. Subsequent patches will incorporate:

 - domain user test coverage
 - project user test coverage

Change-Id: Id3f6159af505fbe81ff83cfaa346f2178f2d8e77
Closes-Bug: 1805372
Related-Bug: 1805880
",git fetch https://review.opendev.org/openstack/keystone refs/changes/22/621022/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/protection/v3/test_limits.py', 'releasenotes/notes/bug-1805372-af4ebf4b19500b72.yaml', 'keystone/common/policies/limit.py']",3,177558ee1c7c26c6761536ae767c8befc6ddd8e6,implement-default-roles,"deprecated_create_limit = policy.DeprecatedRule( name=base.IDENTITY % 'create_limit', check_str=base.RULE_ADMIN_REQUIRED ) deprecated_delete_limit = policy.DeprecatedRule( name=base.IDENTITY % 'delete_limit', check_str=base.RULE_ADMIN_REQUIRED ) check_str='role:admin', 'method': 'POST'}], deprecated_rule=deprecated_create_limit, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.STEIN), check_str='role:admin', 'method': 'DELETE'}], deprecated_rule=deprecated_delete_limit, deprecated_reason=DEPRECATED_REASON, deprecated_since=versionutils.deprecated.STEIN)"," check_str=base.RULE_ADMIN_REQUIRED, 'method': 'POST'}]), check_str=base.RULE_ADMIN_REQUIRED, 'method': 'DELETE'}])",108,15
openstack%2Fkeystone~master~I3cee870e0eb0d0a796b8e08d73d8965b31126d73,openstack/keystone,master,I3cee870e0eb0d0a796b8e08d73d8965b31126d73,Add tests for project users interacting with endpoints,MERGED,2018-11-21 15:49:23.000000000,2019-02-12 08:42:17.000000000,2019-02-12 08:42:16.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 28032}]","[{'number': 1, 'created': '2018-11-21 15:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bb16797ee4c05d3cac24e0de6155b31ae4eef43c', 'message': 'Add tests for project users interacting with services\n\nThis commit introduces some tests that show how project users\nare expected to behave with the services API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804462\n'}, {'number': 2, 'created': '2018-11-21 17:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6b936c640385ab2260849fd45cb2dc31ee5d7f87', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 3, 'created': '2018-11-28 14:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/837d773b3c0fbf2783f4404c4592e0ce0bf7d55b', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 4, 'created': '2018-11-30 22:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/681b23b04d8fa703bea56c5eed6296fc8bf04f68', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 5, 'created': '2018-12-07 17:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7c6ab8105a9528a18c683866b65e3f855be09963', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 6, 'created': '2018-12-18 21:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/14f80c9f45c32260aa3842f1d1c2cb3a88b1cf5d', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 7, 'created': '2018-12-18 21:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/77f213eeb599cd76f01a10134164a68d24cb9d28', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}, {'number': 8, 'created': '2019-01-08 22:33:06.000000000', 'files': ['keystone/tests/unit/protection/v3/test_endpoints.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1be7e4b426fbb2d2aa111269777c452a131c7106', 'message': 'Add tests for project users interacting with endpoints\n\nThis commit introduces some tests that show how project users\nare expected to behave with the endpoints API. A subsequent patch\nwill clean up the new obsolete policies in the\npolicy.v3cloudsample.json file.\n\nChange-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73\nRelated-Bug: 1804482\n'}]",0,619281,1be7e4b426fbb2d2aa111269777c452a131c7106,24,5,8,5046,,,0,"Add tests for project users interacting with endpoints

This commit introduces some tests that show how project users
are expected to behave with the endpoints API. A subsequent patch
will clean up the new obsolete policies in the
policy.v3cloudsample.json file.

Change-Id: I3cee870e0eb0d0a796b8e08d73d8965b31126d73
Related-Bug: 1804482
",git fetch https://review.opendev.org/openstack/keystone refs/changes/81/619281/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/protection/v3/test_services.py'],1,bb16797ee4c05d3cac24e0de6155b31ae4eef43c,implement-default-roles," class ProjectUserTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin, _DomainAndProjectUserServiceTests): def setUp(self): super(ProjectUserTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) self.user_id = self.bootstrapper.admin_user_id auth = self.build_authentication_request( user_id=self.user_id, password=self.bootstrapper.admin_password, project_id=self.bootstrapper.project_id ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id}",,25,0
openstack%2Fkeystone~master~If3186c6fc1cba68426eedf83f31ae87cbe2060da,openstack/keystone,master,If3186c6fc1cba68426eedf83f31ae87cbe2060da,Add tests for domain users interacting with endpoints,MERGED,2018-11-21 17:51:21.000000000,2019-02-12 08:42:14.000000000,2019-02-12 08:42:13.000000000,"[{'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-21 17:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/88fe8d833ebb6e7903f5715767140f2917fcfc00', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 2, 'created': '2018-11-28 14:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e0bf224aa0e5e7f2a7658001d434337be4a4b0e', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 3, 'created': '2018-11-30 22:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2adf0fbd1cbf4aaa2815d739a7ba0bb864c9852d', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 4, 'created': '2018-12-07 17:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1ccb8c0286ef48717a6af4551b2cc565056912f5', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 5, 'created': '2018-12-18 21:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6043edd9701a4b44cca8ffd7bfa2227ffc9faaad', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 6, 'created': '2018-12-18 21:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/535e50c8b7a3a4cff553054073c46e61347129a1', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}, {'number': 7, 'created': '2019-01-08 22:33:06.000000000', 'files': ['keystone/tests/unit/protection/v3/test_endpoints.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/56f9a218e5d552889a5e50d383fe82c2cda39b56', 'message': 'Add tests for domain users interacting with endpoints\n\nThis commit introduces some tests that show how domain users are\nexpected to behave with the endpoints API. A subsequent patch will do\nthe same for project users.\n\nChange-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da\nRelated-Bug: 1804482\n'}]",0,619332,56f9a218e5d552889a5e50d383fe82c2cda39b56,20,3,7,5046,,,0,"Add tests for domain users interacting with endpoints

This commit introduces some tests that show how domain users are
expected to behave with the endpoints API. A subsequent patch will do
the same for project users.

Change-Id: If3186c6fc1cba68426eedf83f31ae87cbe2060da
Related-Bug: 1804482
",git fetch https://review.opendev.org/openstack/keystone refs/changes/32/619332/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/protection/v3/test_endpoints.py'],1,88fe8d833ebb6e7903f5715767140f2917fcfc00,implement-default-roles,"class _DomainAndProjectUserEndpointTests(object): def test_user_cannot_create_endpoints(self): create = { 'endpoint': { 'interface': 'public', 'service_id': uuid.uuid4().hex, 'url': 'https://' + uuid.uuid4().hex + '.com' } } with self.test_client() as c: c.post( '/v3/endpoints', json=create, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_list_endpoints(self): # Domain and project users should access this information through the # token response they get when they authenticate for or validate a # token. service = PROVIDERS.catalog_api.create_service( uuid.uuid4().hex, unit.new_service_ref() ) endpoint = unit.new_endpoint_ref(service['id'], region_id=None) endpoint = PROVIDERS.catalog_api.create_endpoint( endpoint['id'], endpoint ) with self.test_client() as c: c.get( '/v3/endpoints', headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_get_an_endpoint(self): service = PROVIDERS.catalog_api.create_service( uuid.uuid4().hex, unit.new_service_ref() ) endpoint = unit.new_endpoint_ref(service['id'], region_id=None) endpoint = PROVIDERS.catalog_api.create_endpoint( endpoint['id'], endpoint ) with self.test_client() as c: c.get( '/v3/endpoints/%s' % endpoint['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_update_endpoints(self): service = PROVIDERS.catalog_api.create_service( uuid.uuid4().hex, unit.new_service_ref() ) endpoint = unit.new_endpoint_ref(service['id'], region_id=None) endpoint = PROVIDERS.catalog_api.create_endpoint( endpoint['id'], endpoint ) update = {'endpoint': {'interface': 'internal'}} with self.test_client() as c: c.patch( '/v3/endpoints/%s' % endpoint['id'], json=update, headers=self.headers, expected_status_code=http_client.FORBIDDEN ) def test_user_cannot_delete_endpoints(self): service = PROVIDERS.catalog_api.create_service( uuid.uuid4().hex, unit.new_service_ref() ) endpoint = unit.new_endpoint_ref(service['id'], region_id=None) endpoint = PROVIDERS.catalog_api.create_endpoint( endpoint['id'], endpoint ) with self.test_client() as c: c.delete( '/v3/endpoints/%s' % endpoint['id'], headers=self.headers, expected_status_code=http_client.FORBIDDEN ) class DomainUserTests(base_classes.TestCaseWithBootstrap, common_auth.AuthTestMixin, _DomainAndProjectUserEndpointTests): def setUp(self): super(DomainUserTests, self).setUp() self.loadapp() self.useFixture(ksfixtures.Policy(self.config_fixture)) self.config_fixture.config(group='oslo_policy', enforce_scope=True) domain = PROVIDERS.resource_api.create_domain( uuid.uuid4().hex, unit.new_domain_ref() ) self.domain_id = domain['id'] domain_admin = unit.new_user_ref(domain_id=self.domain_id) self.user_id = PROVIDERS.identity_api.create_user(domain_admin)['id'] PROVIDERS.assignment_api.create_grant( self.bootstrapper.admin_role_id, user_id=self.user_id, domain_id=self.domain_id ) auth = self.build_authentication_request( user_id=self.user_id, password=domain_admin['password'], domain_id=self.domain_id ) # Grab a token using the persona we're testing and prepare headers # for requests we'll be making in the tests. with self.test_client() as c: r = c.post('/v3/auth/tokens', json=auth) self.token_id = r.headers['X-Subject-Token'] self.headers = {'X-Auth-Token': self.token_id}",,119,0
openstack%2Fswift~master~Ide9d44cc18575306363126a93d91f662c6ee23e0,openstack/swift,master,Ide9d44cc18575306363126a93d91f662c6ee23e0,encryption: Stop being cutesy with os.path.join(),MERGED,2019-02-07 00:51:58.000000000,2019-02-12 08:42:12.000000000,2019-02-12 08:42:11.000000000,"[{'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 00:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/df028ebbddc8e84d6c9651f030efad3189a29b83', 'message': ""encryption: Stop being cutesy with os.path.join()\n\nTurns out, we *care* about the path, and object paths *don't follow\nfilesystem semantics*!\n\nBe explicit: /<account>/<container>/<object>\n\nChange-Id: Ide9d44cc18575306363126a93d91f662c6ee23e0\nRelated-Bug: 1813725\n""}, {'number': 2, 'created': '2019-02-07 21:50:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6efc6e550193eece5f0bbc45a0e6cdcc0df8abfd', 'message': ""encryption: Stop being cutesy with os.path.join()\n\nTurns out, we *care* about the path, and object paths *don't follow\nfilesystem semantics*!\n\nBe explicit: /<account>/<container>/<object>\n\nBump the key version number so we know whether we can trust the full path\nor not.\n\nChange-Id: Ide9d44cc18575306363126a93d91f662c6ee23e0\nRelated-Bug: 1813725\n""}, {'number': 3, 'created': '2019-02-08 01:41:02.000000000', 'files': ['swift/common/middleware/crypto/keymaster.py', 'test/unit/common/middleware/crypto/test_encryption.py', 'test/unit/common/middleware/crypto/test_keymaster.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/43103319d0aa27f24e6520c0962bd19e55568ad4', 'message': ""encryption: Stop being cutesy with os.path.join()\n\nTurns out, we *care* about the path, and object paths *don't follow\nfilesystem semantics*!\n\nBe explicit: /<account>/<container>/<object>\n\nBump the key version number so we know whether we can trust the full path\nor not.\n\nChange-Id: Ide9d44cc18575306363126a93d91f662c6ee23e0\nRelated-Bug: 1813725\n""}]",4,635380,43103319d0aa27f24e6520c0962bd19e55568ad4,29,4,3,15343,,,0,"encryption: Stop being cutesy with os.path.join()

Turns out, we *care* about the path, and object paths *don't follow
filesystem semantics*!

Be explicit: /<account>/<container>/<object>

Bump the key version number so we know whether we can trust the full path
or not.

Change-Id: Ide9d44cc18575306363126a93d91f662c6ee23e0
Related-Bug: 1813725
",git fetch https://review.opendev.org/openstack/swift refs/changes/80/635380/2 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/crypto/keymaster.py', 'test/unit/common/middleware/crypto/test_keymaster.py']",2,df028ebbddc8e84d6c9651f030efad3189a29b83,encyption-badness," self.verify_keys_for_path( '/a/c//o', expected_keys=('object', 'container'))",,5,4
openstack%2Fpython-tackerclient~master~I20aee4ecb66643dfa5fad490956d898f7e851411,openstack/python-tackerclient,master,I20aee4ecb66643dfa5fad490956d898f7e851411,Adds support force delete resources,MERGED,2018-11-27 18:22:41.000000000,2019-02-12 08:35:42.000000000,2019-02-12 08:35:41.000000000,"[{'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-11-27 18:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/1ee047d7c0658cea18717e10d070cc828a5aa20a', 'message': ""Adds support force delete resources\n\nThis patch adds '--force' parameter to vnf delete command,\nto force delete VNF instances.\n\ne.g: openstack vnf delete --force VNF1\n\nblueprint force-delete-resources\n\nChange-Id: I20aee4ecb66643dfa5fad490956d898f7e851411\n""}, {'number': 2, 'created': '2018-11-28 01:25:54.000000000', 'files': ['tackerclient/tacker/v1_0/__init__.py', 'tackerclient/tacker/v1_0/vnfm/vnf.py', 'tackerclient/tests/unit/test_cli10.py', 'tackerclient/v1_0/client.py', 'tackerclient/osc/v1/vnfm/vnf.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py'], 'web_link': 'https://opendev.org/openstack/python-tackerclient/commit/66794e007bcefdb7ee2017fcc3a65f1d277b38e3', 'message': ""Adds support force delete resources\n\nThis patch adds '--force' parameter to vnf delete command,\nto force delete VNF instances.\n\ne.g: openstack vnf delete --force VNF1\n\nblueprint force-delete-resources\n\nChange-Id: I20aee4ecb66643dfa5fad490956d898f7e851411\n""}]",0,620381,66794e007bcefdb7ee2017fcc3a65f1d277b38e3,11,3,2,26222,,,0,"Adds support force delete resources

This patch adds '--force' parameter to vnf delete command,
to force delete VNF instances.

e.g: openstack vnf delete --force VNF1

blueprint force-delete-resources

Change-Id: I20aee4ecb66643dfa5fad490956d898f7e851411
",git fetch https://review.opendev.org/openstack/python-tackerclient refs/changes/81/620381/1 && git format-patch -1 --stdout FETCH_HEAD,"['tackerclient/tacker/v1_0/__init__.py', 'tackerclient/tacker/v1_0/vnfm/vnf.py', 'tackerclient/tests/unit/test_cli10.py', 'tackerclient/v1_0/client.py', 'tackerclient/osc/v1/vnfm/vnf.py', 'tackerclient/tests/unit/vm/test_cli10_vnf.py']",6,1ee047d7c0658cea18717e10d070cc828a5aa20a,bp/force-delete-resources," def test_delete_vnf_without_force(self): def test_delete_vnf_with_force(self): cmd = vnf.DeleteVNF(test_cli10.MyApp(sys.stdout), None) my_id = 'my-id' args = [my_id, '--force'] self._test_delete_resource(self._RESOURCE, cmd, my_id, args) ", def test_delete_vnf(self):,57,9
openstack%2Fneutron~master~Ia98752a6038c7428c66ffb21279a8ba1c3876f78,openstack/neutron,master,Ia98752a6038c7428c66ffb21279a8ba1c3876f78,Fix the way how upgrade checks are loaded,MERGED,2019-02-07 17:58:17.000000000,2019-02-12 08:34:33.000000000,2019-02-12 08:34:33.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10980}, {'_account_id': 13995}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-02-07 17:58:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1ca88d0b5e0c322d70bfaf37a3d3759425b2923', 'message': 'Fix the way how upgrade checks are loaded\n\nUpgrade checker tool is now adding checks returned\nby checks classes properly, adding them one by one to\nlist instead of adding returned tuple as one element\nalways.\n\nChange-Id: Ia98752a6038c7428c66ffb21279a8ba1c3876f78\n'}, {'number': 2, 'created': '2019-02-07 18:43:49.000000000', 'files': ['neutron/cmd/upgrade_checks/checks.py', 'neutron/cmd/status.py', 'neutron/tests/unit/cmd/upgrade_checks/test_checks.py', 'neutron/tests/unit/cmd/test_status.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9d5fb2fa778801e9689613f943aab364f8c4cb47', 'message': 'Fix the way how upgrade checks are loaded\n\nUpgrade checker tool is now adding checks returned\nby checks classes properly, adding them one by one to\nlist instead of adding returned tuple as one element\nalways.\n\nChange-Id: Ia98752a6038c7428c66ffb21279a8ba1c3876f78\n'}]",0,635588,9d5fb2fa778801e9689613f943aab364f8c4cb47,15,10,2,11975,,,0,"Fix the way how upgrade checks are loaded

Upgrade checker tool is now adding checks returned
by checks classes properly, adding them one by one to
list instead of adding returned tuple as one element
always.

Change-Id: Ia98752a6038c7428c66ffb21279a8ba1c3876f78
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/635588/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/cmd/upgrade_checks/checks.py', 'neutron/cmd/status.py']",2,d1ca88d0b5e0c322d70bfaf37a3d3759425b2923,upgrade_checker_bug_fix, checks += project_checks, checks.append(project_checks),3,3
openstack%2Floci~master~I15fe76e0e3b027dd207010473e35a55b288c46e6,openstack/loci,master,I15fe76e0e3b027dd207010473e35a55b288c46e6,Fix Loci build by temporarily pinning virtualenv,MERGED,2019-02-12 01:02:47.000000000,2019-02-12 08:21:10.000000000,2019-02-12 08:21:10.000000000,"[{'_account_id': 17068}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-02-12 01:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/loci/commit/ad1e913d5ba488c225cbd92ed7c5e7d6d1e55b52', 'message': 'Fix Loci build by temporarily pinning virtualenv\n\nThe 16.4.0 release of virtualenv[1] breaks Loci builds by changing the\nhandling of symlinks[2]. This patch pins the virtualenv version until\na more robust and permanent fix can be implemented\n\n[1] https://virtualenv.pypa.io/en/stable/changes/#v16-4-0-2019-02-09\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2019-February/002592.html\n\nChange-Id: I15fe76e0e3b027dd207010473e35a55b288c46e6\n'}, {'number': 2, 'created': '2019-02-12 01:05:22.000000000', 'files': ['scripts/setup_pip.sh'], 'web_link': 'https://opendev.org/openstack/loci/commit/432503259f5e624afdabd9dacc9d9b367dd95e96', 'message': 'Fix Loci build by temporarily pinning virtualenv\n\nThe 16.4.0 release of virtualenv[1] breaks Loci builds by changing the\nhandling of symlinks[2]. This patch pins the virtualenv version until\na more robust and permanent fix can be implemented\n\n[1] https://virtualenv.pypa.io/en/stable/changes/#v16-4-0-2019-02-09\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2019-February/002592.html\n\nChange-Id: I15fe76e0e3b027dd207010473e35a55b288c46e6\n'}]",0,636252,432503259f5e624afdabd9dacc9d9b367dd95e96,10,4,2,7822,,,0,"Fix Loci build by temporarily pinning virtualenv

The 16.4.0 release of virtualenv[1] breaks Loci builds by changing the
handling of symlinks[2]. This patch pins the virtualenv version until
a more robust and permanent fix can be implemented

[1] https://virtualenv.pypa.io/en/stable/changes/#v16-4-0-2019-02-09
[2] http://lists.openstack.org/pipermail/openstack-discuss/2019-February/002592.html

Change-Id: I15fe76e0e3b027dd207010473e35a55b288c46e6
",git fetch https://review.opendev.org/openstack/loci refs/changes/52/636252/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/setup_pip.sh'],1,ad1e913d5ba488c225cbd92ed7c5e7d6d1e55b52,pin-virtualenv,pip install --upgrade ${PIP_ARGS} virtualenv==16.3.0,pip install --upgrade ${PIP_ARGS} virtualenv,1,1
openstack%2Fdiskimage-builder~master~Ibdd6d6fb9afa25f60145f1ca12de9e2c821ef0de,openstack/diskimage-builder,master,Ibdd6d6fb9afa25f60145f1ca12de9e2c821ef0de,Remove python-lzma,NEW,2019-02-08 17:35:26.000000000,2019-02-12 08:10:02.000000000,,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 17:35:26.000000000', 'files': ['requirements.txt', 'diskimage_builder/elements/fedora-minimal/README.rst', 'bindep.txt'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/0358144fc767e57b4952a38cd92b9277706a110c', 'message': ""Remove python-lzma\n\nThere is a note in the fedora-minimal element that python-lzma is\nneeded everywhere. However, pyliblzma isn't python3 compat, so\nperhaps this is historical and not actually a thing that is needed.\n\nLet's find out.\n\nChange-Id: Ibdd6d6fb9afa25f60145f1ca12de9e2c821ef0de\n""}]",1,635896,0358144fc767e57b4952a38cd92b9277706a110c,6,4,1,2,,,0,"Remove python-lzma

There is a note in the fedora-minimal element that python-lzma is
needed everywhere. However, pyliblzma isn't python3 compat, so
perhaps this is historical and not actually a thing that is needed.

Let's find out.

Change-Id: Ibdd6d6fb9afa25f60145f1ca12de9e2c821ef0de
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/96/635896/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'bindep.txt', 'diskimage_builder/elements/fedora-minimal/README.rst']",3,0358144fc767e57b4952a38cd92b9277706a110c,,Ubuntu and Debian. Nothing additional is needed on Fedora or CentOS.,Ubuntu and Debian. Nothing additional is needed on Fedora or CentOS. The element will need `python-lzma` everywhere.,1,6
openstack%2Fnova~master~I5952a2dd590407b1ce56805df6f90a472cc878bf,openstack/nova,master,I5952a2dd590407b1ce56805df6f90a472cc878bf,doc: link admin/configuration from admin home page,MERGED,2019-02-04 16:02:32.000000000,2019-02-12 08:07:00.000000000,2019-02-12 08:07:00.000000000,"[{'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 16:02:32.000000000', 'files': ['doc/source/admin/index.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/b768496f10931104e89b067d838678105d4a469d', 'message': ""doc: link admin/configuration from admin home page\n\nThere is some important stuff in the admin/configuration\ndocs sub-tree like information about configuring hypervisor\ndrivers and scheduler filters/weighers but it wasn't easily\nfound since it wasn't in the admin toc tree. This adds it\nto the overall admin home page and adds a TODO that we need\nto organize that admin page into sections somehow.\n\nChange-Id: I5952a2dd590407b1ce56805df6f90a472cc878bf\n""}]",0,634728,b768496f10931104e89b067d838678105d4a469d,14,8,1,6873,,,0,"doc: link admin/configuration from admin home page

There is some important stuff in the admin/configuration
docs sub-tree like information about configuring hypervisor
drivers and scheduler filters/weighers but it wasn't easily
found since it wasn't in the admin toc tree. This adds it
to the overall admin home page and adds a TODO that we need
to organize that admin page into sections somehow.

Change-Id: I5952a2dd590407b1ce56805df6f90a472cc878bf
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/634728/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/index.rst'],1,b768496f10931104e89b067d838678105d4a469d,admin-configuration-toc,".. TODO(mriedem): This index page has a lot of content which should be organized into groups for things like configuration, operations, troubleshooting, etc. configuration/index.rst",,5,0
openstack%2Fnova~master~Ifd23424ac14bacf4bf7a0716c268f48ec869a41e,openstack/nova,master,Ifd23424ac14bacf4bf7a0716c268f48ec869a41e,doc: update the security groups admin doc,MERGED,2019-02-04 16:33:05.000000000,2019-02-12 08:06:51.000000000,2019-02-12 08:06:51.000000000,"[{'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 16:33:05.000000000', 'files': ['doc/source/admin/security-groups.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/14b45dce61da9296bd8ca49fe4449335d6cab7f2', 'message': ""doc: update the security groups admin doc\n\nThis makes the following changes:\n\n* re-orders the page to move the nova-network\n  specific information to the bottom\n* creates two sections: one for CLI and one for\n  nova-network\n* mentions at the top that by default neutron\n  manages security groups and their quota and\n  links to the neutron docs\n* drops the mention of the 'nova' CLI since there\n  are no examples in this doc using that CLI\n\nChange-Id: Ifd23424ac14bacf4bf7a0716c268f48ec869a41e\n""}]",3,634735,14b45dce61da9296bd8ca49fe4449335d6cab7f2,13,8,1,6873,,,0,"doc: update the security groups admin doc

This makes the following changes:

* re-orders the page to move the nova-network
  specific information to the bottom
* creates two sections: one for CLI and one for
  nova-network
* mentions at the top that by default neutron
  manages security groups and their quota and
  links to the neutron docs
* drops the mention of the 'nova' CLI since there
  are no examples in this doc using that CLI

Change-Id: Ifd23424ac14bacf4bf7a0716c268f48ec869a41e
",git fetch https://review.opendev.org/openstack/nova refs/changes/35/634735/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/security-groups.rst'],1,14b45dce61da9296bd8ca49fe4449335d6cab7f2,doc-security-groups-admin,"By default, security groups (and their quota) are managed by the :neutron-doc:`Neutron networking service </admin/archives/adv-features.html#security-groups>`. Working with security groups ~~~~~~~~~~~~~~~~~~~~~~~~~~~~using the :command:`openstack` commands. List and view current security groups ----------------------------------------------------------------------------------------------------------------------------------------- nova-network configuration (deprecated) ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ You can use the :oslo.config:option:`allow_same_net_traffic` option in the ``/etc/nova/nova.conf`` file to globally control whether the rules apply to hosts which share a network. There are two possible values: ``True`` (default) Hosts on the same subnet are not filtered and are allowed to pass all types of traffic between them. On a flat network, this allows all instances from all projects unfiltered communication. With VLAN networking, this allows access between instances within the same project. You can also simulate this setting by configuring the default security group to allow all traffic from the subnet. ``False`` Security groups are enforced for all connections. Additionally, the number of maximum rules per security group is controlled by the ``security_group_rules`` and the number of allowed security groups per project is controlled by the ``security_groups`` quota (see :ref:`manage-quotas`).","You can use the ``allow_same_net_traffic`` option in the ``/etc/nova/nova.conf`` file to globally control whether the rules apply to hosts which share a network. There are two possible values: ``True`` (default) Hosts on the same subnet are not filtered and are allowed to pass all types of traffic between them. On a flat network, this allows all instances from all projects unfiltered communication. With VLAN networking, this allows access between instances within the same project. You can also simulate this setting by configuring the default security group to allow all traffic from the subnet. ``False`` Security groups are enforced for all connections. Additionally, the number of maximum rules per security group is controlled by the ``security_group_rules`` and the number of allowed security groups per project is controlled by the ``security_groups`` quota (see :ref:`manage-quotas`). List and view current security groups ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~using the :command:`openstack` and :command:`nova` commands:~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~",35,25
openstack%2Fneutron~stable%2Fqueens~Ib675d7bf399f2aa7eba9d343fa0f06281d33089a,openstack/neutron,stable/queens,Ib675d7bf399f2aa7eba9d343fa0f06281d33089a,Add lock_path in installation guide,MERGED,2019-02-04 12:43:05.000000000,2019-02-12 08:06:45.000000000,2019-02-12 08:06:45.000000000,"[{'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-04 12:43:05.000000000', 'files': ['doc/source/install/controller-install-option1-ubuntu.rst', 'doc/source/install/controller-install-option2-ubuntu.rst', 'doc/source/install/controller-install-option1-obs.rst', 'doc/source/install/compute-install-obs.rst', 'doc/source/install/controller-install-option2-obs.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/de9f813928d11b9048d0201caa3cbff60ccbf37b', 'message': 'Add lock_path in installation guide\n\nOslo_concurrency needs lock_path option, make it consistent in\ndocumentation for Suse, Redhat and Ubuntu installation guides.\n\nChange-Id: Ib675d7bf399f2aa7eba9d343fa0f06281d33089a\nRelated-Bug: #1796976\nCloses-Bug: #1812497\n(cherry picked from commit 534e85039271d91647173527cd4c4905b9532537)\n(cherry picked from commit 573b0be3e86905853b104647ff237fae191eed0b)\n'}]",0,634680,de9f813928d11b9048d0201caa3cbff60ccbf37b,11,5,1,17685,,,0,"Add lock_path in installation guide

Oslo_concurrency needs lock_path option, make it consistent in
documentation for Suse, Redhat and Ubuntu installation guides.

Change-Id: Ib675d7bf399f2aa7eba9d343fa0f06281d33089a
Related-Bug: #1796976
Closes-Bug: #1812497
(cherry picked from commit 534e85039271d91647173527cd4c4905b9532537)
(cherry picked from commit 573b0be3e86905853b104647ff237fae191eed0b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/634680/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/controller-install-option1-ubuntu.rst', 'doc/source/install/controller-install-option2-ubuntu.rst', 'doc/source/install/controller-install-option1-obs.rst', 'doc/source/install/compute-install-obs.rst', 'doc/source/install/controller-install-option2-obs.rst']",5,de9f813928d11b9048d0201caa3cbff60ccbf37b,bug/1812497," * In the ``[oslo_concurrency]`` section, configure the lock path: .. path /etc/neutron/neutron.conf .. code-block:: ini [oslo_concurrency] # ... lock_path = /var/lib/neutron/tmp .. end ",,60,0
openstack%2Fneutron~stable%2Fpike~Ie619516c07fb3dc9d025f64c0e1e59d5d808cb6f,openstack/neutron,stable/pike,Ie619516c07fb3dc9d025f64c0e1e59d5d808cb6f,Block port update from unbound DHCP agent,MERGED,2019-02-05 12:53:05.000000000,2019-02-12 08:06:42.000000000,2019-02-12 08:06:42.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 16688}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 28373}]","[{'number': 1, 'created': '2019-02-05 12:53:05.000000000', 'files': ['neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/tests/unit/api/rpc/handlers/test_dhcp_rpc.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b2418bc248f7fe189e0a944735f0321ad5f0149c', 'message': ""Block port update from unbound DHCP agent\n\nCurrent DHCP port management in Neutron makes the server to clear the\ndevice_id while the agent is responsible for setting it.\n\nThis may cause a potential race condition, for example during network\nrescheduling. The server aims to clear the device_id on a DHCP port and\nassign the network to another agent while the old agent might just be\ntaking possession of the port. If the DHCP agent takes possession of the\nport (i.e., update port...set the device_id) before the server clears\nit, then there is no issue. However, if this happens after the clear\noperation by server then the DHCP port would be updated/marked to be\nowned by the old agent.\n\nWhen the new agent takes over the network scheduled to it, it won't be\nable to find a port to reuse so that an extra port might need to be\ncreated. This leads to two issues:\n1) an extra port is created and never deleted;\n2) the extra port creation may fail if there are no available IP\naddresses.\n\nThis patch proposes a validation check to prevent an agent from updating\na DHCP port unless the network is bound to that agent.\n\nCo-authored-by: Allain Legacy <Allain.legacy@windriver.com>\n\nConflicts:\n\tneutron/api/rpc/handlers/dhcp_rpc.py\n\nNote(elod.illes): Conflict caused by missing patch (that consumes\nconstants from neutron_lib), which should not be backported:\nIe4bcffccf626a6e1de84af01f3487feb825f8b65\n\nCloses-Bug: #1795126\nStory: 2003919\nChange-Id: Ie619516c07fb3dc9d025f64c0e1e59d5d808cb6f\n(cherry picked from commit b70ee4df885d8ca18cb3dbfbec9691ecc0321f09)\n(cherry picked from commit b9f9c021c9692855cae30b6be1481058b3474112)\n""}]",1,634926,b2418bc248f7fe189e0a944735f0321ad5f0149c,17,7,1,17685,,,0,"Block port update from unbound DHCP agent

Current DHCP port management in Neutron makes the server to clear the
device_id while the agent is responsible for setting it.

This may cause a potential race condition, for example during network
rescheduling. The server aims to clear the device_id on a DHCP port and
assign the network to another agent while the old agent might just be
taking possession of the port. If the DHCP agent takes possession of the
port (i.e., update port...set the device_id) before the server clears
it, then there is no issue. However, if this happens after the clear
operation by server then the DHCP port would be updated/marked to be
owned by the old agent.

When the new agent takes over the network scheduled to it, it won't be
able to find a port to reuse so that an extra port might need to be
created. This leads to two issues:
1) an extra port is created and never deleted;
2) the extra port creation may fail if there are no available IP
addresses.

This patch proposes a validation check to prevent an agent from updating
a DHCP port unless the network is bound to that agent.

Co-authored-by: Allain Legacy <Allain.legacy@windriver.com>

Conflicts:
	neutron/api/rpc/handlers/dhcp_rpc.py

Note(elod.illes): Conflict caused by missing patch (that consumes
constants from neutron_lib), which should not be backported:
Ie4bcffccf626a6e1de84af01f3487feb825f8b65

Closes-Bug: #1795126
Story: 2003919
Change-Id: Ie619516c07fb3dc9d025f64c0e1e59d5d808cb6f
(cherry picked from commit b70ee4df885d8ca18cb3dbfbec9691ecc0321f09)
(cherry picked from commit b9f9c021c9692855cae30b6be1481058b3474112)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/634926/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/rpc/handlers/dhcp_rpc.py', 'neutron/tests/unit/api/rpc/handlers/test_dhcp_rpc.py']",2,b2418bc248f7fe189e0a944735f0321ad5f0149c,bug/1795126," self.agent_hosting_network_p = mock.patch.object(self.callbacks, '_is_dhcp_agent_hosting_network') self.mock_agent_hosting_network = self.agent_hosting_network_p.start() self.mock_agent_hosting_network.return_value = True def test_update_dhcp_port_with_agent_not_hosting_network(self): port = {'port': {'network_id': 'foo_network_id', 'device_owner': constants.DEVICE_OWNER_DHCP, 'fixed_ips': [{'subnet_id': 'foo_subnet_id'}]} } self.plugin.get_port.return_value = { 'device_id': constants.DEVICE_ID_RESERVED_DHCP_PORT} self.mock_agent_hosting_network.return_value = False self.assertRaises(exceptions.DhcpPortInUse, self.callbacks.update_dhcp_port, mock.Mock(), host='foo_host', port_id='foo_port_id', port=port) def test__is_dhcp_agent_hosting_network(self): self.agent_hosting_network_p.stop() agent = mock.Mock() with mock.patch.object(self.plugin, 'get_dhcp_agents_hosting_networks', return_value=[agent]): ret = self.callbacks._is_dhcp_agent_hosting_network(self.plugin, mock.Mock(), host='foo_host', network_id='foo_network_id') self.assertTrue(ret) def test__is_dhcp_agent_hosting_network_false(self): self.agent_hosting_network_p.stop() with mock.patch.object(self.plugin, 'get_dhcp_agents_hosting_networks', return_value=[]): ret = self.callbacks._is_dhcp_agent_hosting_network(self.plugin, mock.Mock(), host='foo_host', network_id='foo_network_id') self.assertFalse(ret) ",,47,2
openstack%2Fnova~master~Ic4735f92542e5e0ca36b459874dc486f6b360317,openstack/nova,master,Ic4735f92542e5e0ca36b459874dc486f6b360317,Extend RequestGroup object for mapping,MERGED,2018-11-22 11:46:23.000000000,2019-02-12 08:02:38.000000000,2019-02-09 08:04:28.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15554}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28885}]","[{'number': 1, 'created': '2018-11-22 11:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2dd4916e528e7ccffdf2fb6030fe0109a579655', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 2, 'created': '2018-11-22 12:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03ce0b44e191b46533b047a0e6a536694c1a3dfa', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 3, 'created': '2018-11-23 15:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67e2d32f000ea5db511eb00c27eadfaaf9283a16', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 4, 'created': '2018-12-10 09:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/495a149da6d8941a5f6ca5e26e1a92647834832a', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 5, 'created': '2018-12-14 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc12b8953d24dc822a6c5c5ebbe4d2c016f58c6e', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 6, 'created': '2018-12-18 15:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0aee053eaef86e134713d4a0a9d066a767dacd99', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 7, 'created': '2018-12-19 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2316ce19a817225cf63d20bfa102e97a5bfd62a1', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 8, 'created': '2018-12-20 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e9e4270d3b4139f105d013a00ced0849f54dba08', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 9, 'created': '2018-12-20 16:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/06e4c3de2dacecaa976dcc6c3e90111cde51382b', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 10, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9bdf296b5a523e30fe15af96c4208a196bd82c25', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 11, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/36b8dbed3833fa6609df79a50d726ffc9f696080', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 12, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ba28fccf7388ec673e609c628cb0f267eb2eb04e', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 13, 'created': '2019-01-28 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/135889d8b5991ec249a31767f5a11fd89908e38f', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new field to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are need to be able to hold and\ncommunity the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can be fulfill the request hence\nprovider_uuids is a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 14, 'created': '2019-02-04 18:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fd76038bc0d2713823d31d90fc5451528646c8f', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new fields to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are needed to be able to hold and\ncommunicate the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can fulfill the request hence provider_uuids\nis a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 15, 'created': '2019-02-06 15:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9145a11e607e4caf98917d98cde6334596e7f7a4', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new fields to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are needed to be able to hold and\ncommunicate the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can fulfill the request hence provider_uuids\nis a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}, {'number': 16, 'created': '2019-02-08 01:07:13.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/objects/request_spec.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_request_spec.py', 'nova/objects/fields.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b2a995f19867bb2eedcb615d7f7431bdbef73c8e', 'message': 'Extend RequestGroup object for mapping\n\nThis patch adds two new fields to the RequestGroup ovo, requester_id and\nprovider_uuids. These two fields are needed to be able to hold and\ncommunicate the mapping between the requester of the RequestGroup (e.g.\nNeutron port) and the resource providers that are fulfilling the request\n(e.g. network device RPs). If the RequestGroup represents the un-numbered\ngroup then more than one RP can fulfill the request hence provider_uuids\nis a list.\n\nThese new fields later in the series will be populated based on some\nlogic in the nova-conductor. However in the long run we expect that\nthese fields will be populated from the Placement allocation\ncandidates response.\n\nblueprint bandwidth-resource-provider\n\nChange-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317\n'}]",24,619527,b2a995f19867bb2eedcb615d7f7431bdbef73c8e,222,19,16,9708,,,0,"Extend RequestGroup object for mapping

This patch adds two new fields to the RequestGroup ovo, requester_id and
provider_uuids. These two fields are needed to be able to hold and
communicate the mapping between the requester of the RequestGroup (e.g.
Neutron port) and the resource providers that are fulfilling the request
(e.g. network device RPs). If the RequestGroup represents the un-numbered
group then more than one RP can fulfill the request hence provider_uuids
is a list.

These new fields later in the series will be populated based on some
logic in the nova-conductor. However in the long run we expect that
these fields will be populated from the Placement allocation
candidates response.

blueprint bandwidth-resource-provider

Change-Id: Ic4735f92542e5e0ca36b459874dc486f6b360317
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/619527/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/objects/request_spec.py', 'nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_request_spec.py']",4,d2dd4916e528e7ccffdf2fb6030fe0109a579655,bp/bandwidth-resource-provider," self.assertIsNone(None, rg.requester_id) self.assertEqual([], rg.provider_uuids) self.context, uuids.port_id, port_resource_request) self.assertEqual(uuids.port_id, rg.requester_id) self.assertEqual([], rg.provider_uuids) self.context, uuids.port_id, port_resource_request) self.assertEqual(uuids.port_id, rg.requester_id) self.assertEqual([], rg.provider_uuids) def test_compat_requester_and_provider(self): req_obj = objects.RequestGroup( requester_id=uuids.requester, provider_uuids=[uuids.rp1]) versions = ovo_base.obj_tree_get_versions('RequestGroup') primitive = req_obj.obj_to_primitive(target_version='1.0', version_manifest=versions) self.assertNotIn('requester_id', primitive) self.assertNotIn('provider_uuids', primitive)"," self.context, port_resource_request) self.context, port_resource_request)",42,7
openstack%2Fneutron~stable%2Focata~I7b621157fe85945acd99e4f08b6370d2f9c3d44d,openstack/neutron,stable/ocata,I7b621157fe85945acd99e4f08b6370d2f9c3d44d,Change the way to distinguish the port type,MERGED,2019-02-04 20:04:02.000000000,2019-02-12 07:58:19.000000000,2019-02-12 07:58:19.000000000,"[{'_account_id': 4694}, {'_account_id': 17685}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24978}, {'_account_id': 26622}, {'_account_id': 27546}]","[{'number': 1, 'created': '2019-02-04 20:04:02.000000000', 'files': ['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a512af877cf9e27d79fc846f3a805ba4c3a44b5', 'message': ""Change the way to distinguish the port type\n\nIn delete_port_postcommit, a DVR port (port['device_owner'] =\nDEVICE_OWNER_ROUTER_SNAT) can match on l2pop_db.HA_ROUTER_PORTS[1],\nbut can not get any fdb entries by _get_ha_port_agents_fdb. Then,\nthe fdb_entries[network_id]['ports'] is been overwritten by {}. So\nthe associated flow entries will not be deleted.\n\nCloses-Bug: #1668277\nChange-Id: I7b621157fe85945acd99e4f08b6370d2f9c3d44d\n(cherry picked from commit 3593620faa37322a1aaf1ce0c0ae3065ec623c2f)\n""}]",0,634794,1a512af877cf9e27d79fc846f3a805ba4c3a44b5,15,7,1,6593,,,0,"Change the way to distinguish the port type

In delete_port_postcommit, a DVR port (port['device_owner'] =
DEVICE_OWNER_ROUTER_SNAT) can match on l2pop_db.HA_ROUTER_PORTS[1],
but can not get any fdb entries by _get_ha_port_agents_fdb. Then,
the fdb_entries[network_id]['ports'] is been overwritten by {}. So
the associated flow entries will not be deleted.

Closes-Bug: #1668277
Change-Id: I7b621157fe85945acd99e4f08b6370d2f9c3d44d
(cherry picked from commit 3593620faa37322a1aaf1ce0c0ae3065ec623c2f)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/634794/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/l2pop/mech_driver.py', 'neutron/tests/unit/plugins/ml2/drivers/l2pop/test_mech_driver.py']",2,1a512af877cf9e27d79fc846f3a805ba4c3a44b5,bug/1795126,"from neutron.plugins.ml2 import db as ml2_db def test_delete_dvr_snat_port_fdb_entries(self): l2pop_mech = l2pop_mech_driver.L2populationMechanismDriver() l2pop_mech.initialize() self._setup_l3() with self.subnet(network=self._network, enable_dhcp=False) as snet: host_arg = {portbindings.HOST_ID: HOST, 'admin_state_up': True} with self.port(subnet=snet, device_owner=constants.DEVICE_OWNER_ROUTER_SNAT, arg_list=(portbindings.HOST_ID,), **host_arg) as p: device = 'tap' + p['port']['id'] self.callbacks.update_device_up(self.adminContext, agent_id=HOST, device=device) dvr_snat_port = ml2_db.get_port(self.adminContext, p['port']['id']) self.mock_fanout.reset_mock() context = mock.Mock() context.current = dvr_snat_port context.host = HOST segment = {'network_type': 'vxlan', 'segmentation_id': 1} context.bottom_bound_segment = segment expected = {self._network['network']['id']: {'segment_id': segment['segmentation_id'], 'network_type': segment['network_type'], 'ports': {'20.0.0.1': [l2pop_rpc.PortInfo( mac_address=p['port']['mac_address'], ip_address=p['port']['fixed_ips'][0] ['ip_address'])]}}} l2pop_mech.delete_port_postcommit(context) self.mock_fanout.assert_called_with( mock.ANY, 'remove_fdb_entries', expected) ",,41,1
openstack%2Fpaunch~master~I7ac10a9b42ecae73a77b624f5350c424d4c3030a,openstack/paunch,master,I7ac10a9b42ecae73a77b624f5350c424d4c3030a,Inject log-driver for podman containers,MERGED,2019-02-07 06:24:06.000000000,2019-02-12 07:41:37.000000000,2019-02-11 11:18:51.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-07 06:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/b0ae90232ea47e2373bd85457fe96bff6cfc9ef8', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nDepends-On: Ia613fc3812aa34376c3fe64c21abfed51cfc9cab\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 2, 'created': '2019-02-07 06:50:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/75acd14c39a4f1550ddc2ce34ec2184bee8ef9e2', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nDepends-On: Ia613fc3812aa34376c3fe64c21abfed51cfc9cab\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 3, 'created': '2019-02-07 07:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/32bb01a3f7fb375ba24eb457e54ebf32c19a2dfe', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nDepends-On: Ia613fc3812aa34376c3fe64c21abfed51cfc9cab\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 4, 'created': '2019-02-07 12:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/055fbc4990bbeef7aa02f0d16582140c10dbd05e', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 5, 'created': '2019-02-07 12:31:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/456d9394af221d82f34764e01df543a3a5c1ab7f', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 6, 'created': '2019-02-07 15:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/4fb266c25435a86db11285dd6be1dcfd62ba18c1', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 7, 'created': '2019-02-07 16:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/5083ecb8e61aab12e880e2ad3d7158f3d3d015d3', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 8, 'created': '2019-02-08 05:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/3ccc68a2bc5f6e57cf01b901195a9915147ee00a', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}, {'number': 9, 'created': '2019-02-08 07:18:44.000000000', 'files': ['releasenotes/notes/podman-logging-91a1962a7aaacc0b.yaml', 'paunch/builder/podman.py', 'paunch/cmd.py', 'paunch/runner.py', 'paunch/builder/base.py', 'paunch/tests/test_paunch.py', 'paunch/__init__.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/fba5e04fdd1fa9ed85f02f1dab0794e1f4828739', 'message': 'Inject log-driver for podman containers\n\nCurrently, docker daemon runtime has a default --log-driver set\nto journald.\n\nPodman lack of daemon prevent such a global application, meaning\nwe have to set that driver for each and every container when we\neither create or run them.\n\nNotes:\n- podman only supports ""json-file"", and it\'s not even a json.\n- docker json-file doesn\'t support ""path"" option, making this output\n  unusable in the end: logs end in\n  /var/lib/docker/containers/ID/ID-json.log\n\nRelated-Bug: #1814897\nChange-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a\n'}]",10,635438,fba5e04fdd1fa9ed85f02f1dab0794e1f4828739,37,14,9,28223,,,0,"Inject log-driver for podman containers

Currently, docker daemon runtime has a default --log-driver set
to journald.

Podman lack of daemon prevent such a global application, meaning
we have to set that driver for each and every container when we
either create or run them.

Notes:
- podman only supports ""json-file"", and it's not even a json.
- docker json-file doesn't support ""path"" option, making this output
  unusable in the end: logs end in
  /var/lib/docker/containers/ID/ID-json.log

Related-Bug: #1814897
Change-Id: I7ac10a9b42ecae73a77b624f5350c424d4c3030a
",git fetch https://review.opendev.org/openstack/paunch refs/changes/38/635438/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/builder/base.py'],1,b0ae90232ea47e2373bd85457fe96bff6cfc9ef8,bug/1814897," container_name, if self.runner.cont_cmd == 'podman': logging = ['--log-driver', 'json-file', '--log-opt', 'path=/var/log/containers/stdouts/%s.log' % container_name] cmd.append(logging) ", container_name,8,1
openstack%2Ftripleo-puppet-elements~master~I630a399d95752b1fb1e30220a582ace8d7b97f18,openstack/tripleo-puppet-elements,master,I630a399d95752b1fb1e30220a582ace8d7b97f18,Use external centos7-rt if present,MERGED,2019-02-06 11:40:50.000000000,2019-02-12 07:40:35.000000000,2019-02-12 02:34:57.000000000,"[{'_account_id': 3153}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-06 11:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/a33700026dcd8f7517aabef4597fdedab72dd99f', 'message': 'Parameterize centos7-rt repo url\n\nDepending on the environment this is executed a mirror to centos7-rt has\nto be used, an example of that is at RDO zuul jobs it has to use\nnodepool mirrors.\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n'}, {'number': 2, 'created': '2019-02-06 12:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/a84c6faa68101ad15742722c3efc777b57d4c96d', 'message': 'Parameterize centos7-rt repo url\n\nDepending on the environment this is executed a mirror to centos7-rt has\nto be used, an example of that is at RDO zuul jobs it has to use\nnodepool mirrors.\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n'}, {'number': 3, 'created': '2019-02-06 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/404f41e8ec7bbba807a79773cfbb9830e33580c7', 'message': 'Use external centos7-rt if present\n\nDepending on the environment we execute this we need different\nconfiguration for the centos7-rt repo, like at RDO zuul ci we have to\nuse nodepool mirrors to prevent stuff like DNS returning IPv6.\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n'}, {'number': 4, 'created': '2019-02-07 13:53:01.000000000', 'files': ['elements/overcloud-compute/pre-install.d/03-centos-rt'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/d313a060c80f5d97c49092eb695c335be102b473', 'message': ""Use external centos7-rt if present\n\nDepending on the environment we execute this we need different\nconfiguration for the centos7-rt repo, like at RDO zuul ci we have to\nuse nodepool mirrors, this patch check for a centos7-rt repo and enables\nit if it's not present just creates a default one\n\nChange-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18\nRelated-Bug: #1814872\n""}]",2,635135,d313a060c80f5d97c49092eb695c335be102b473,24,16,4,27898,,,0,"Use external centos7-rt if present

Depending on the environment we execute this we need different
configuration for the centos7-rt repo, like at RDO zuul ci we have to
use nodepool mirrors, this patch check for a centos7-rt repo and enables
it if it's not present just creates a default one

Change-Id: I630a399d95752b1fb1e30220a582ace8d7b97f18
Related-Bug: #1814872
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/35/635135/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/overcloud-compute/README.md', 'elements/overcloud-compute/environment.d/01-centos-rt-envs.bash', 'elements/overcloud-compute/pre-install.d/03-centos-rt']",3,a33700026dcd8f7517aabef4597fdedab72dd99f,bug/1814872,baseurl=${DIB_CENTOSRT_repo_url},baseurl=http://mirror.centos.org/centos/7/rt/x86_64/,9,1
openstack%2Fnova~master~Ica6152ccb97dce805969d964d6ed032bfe22a33f,openstack/nova,master,Ica6152ccb97dce805969d964d6ed032bfe22a33f,Transfer port.resource_request to the scheduler,MERGED,2018-05-09 15:52:24.000000000,2019-02-12 07:36:12.000000000,2019-02-08 12:22:41.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 8313}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15554}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27076}]","[{'number': 1, 'created': '2018-05-09 15:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/66317dbf425636c4eaea8d98166d49d1c6088361', 'message': 'transfer port.resource_request to the scheduler\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 2, 'created': '2018-05-16 13:06:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca06b2682177aec54c3c666e8b346c82bb72c378', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 3, 'created': '2018-05-16 13:27:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16f81ffcc6c63b667ffae35a78b28a59ba177ebb', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 4, 'created': '2018-05-16 15:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2d3d0bf423c0e39892cdae72168b47ab9e32e337', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 5, 'created': '2018-05-17 12:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ebeadfa39b366826905df155847ab3edafb7349a', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 6, 'created': '2018-05-22 18:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/78f59d30a8ec866b24af21664cb0e7550d818dab', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 7, 'created': '2018-05-24 22:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0924b5ea3eb98693c86ab3677ffa2c7e6db91b2d', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 8, 'created': '2018-05-29 07:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21de54bdc644f48860a16e42b81cde5834ed877b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 9, 'created': '2018-05-29 15:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7baf05f727e34aa85b0ac5f28e2b2933b48db0e1', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code pathes need to be implemented. That implementation will be\npart of a subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 10, 'created': '2018-06-01 15:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3819a7767573c38084dea0f593e96debe1d17481', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts the each request to\na RequestGroup object and includes them into the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code pathes need to be implemented. That implementation will be\npart of a subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 11, 'created': '2018-06-06 10:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/00239331127c6071d239f74d0c125050627bcca1', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 12, 'created': '2018-06-06 11:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/028ad5e5f0bd21485f3504069d7774781193b52a', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 13, 'created': '2018-06-06 14:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11fee50feed8090697b416f6f0affc484dfffe91', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 14, 'created': '2018-06-08 15:13:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb5b37b9c1bfdf99631e1a55b4f70e27fbcd6229', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 15, 'created': '2018-06-11 07:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b9eb46d96edf3d46d8a96fa1b86376edfb05af2a', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 16, 'created': '2018-06-11 14:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/804543afdd38b96c38d09ff3ae522ab87e0d67c8', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 17, 'created': '2018-06-12 13:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/972ea2ae2c2382eedc8b5af1af01bb361641118f', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 18, 'created': '2018-06-13 10:52:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5858fcd7cccf4b6a52342095f82f7999470c86eb', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 19, 'created': '2018-06-13 12:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/795c91b22f646b04834e6ae6511830446c298105', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 20, 'created': '2018-06-14 11:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11cafe615d0e62ddd510baaa9e8b0457ae3a868d', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 21, 'created': '2018-06-21 14:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcef1593186026cc43f461b546dbcf13fcca41e2', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 22, 'created': '2018-06-28 08:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f326bd979b14677376c07b4ee75070505e52ae5b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 23, 'created': '2018-06-28 09:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30c9223dbc754aa1d0a2106c5251abab4e5a6f6c', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 24, 'created': '2018-07-04 15:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9827986e676583a65c6c252cb473af7a665866b5', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 25, 'created': '2018-07-04 15:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c79ca1c382dc31117751ffe4b36e4a8afac9e72', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 26, 'created': '2018-08-13 14:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9560a3f9c401e2e129a266035803aab21737c7bc', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 27, 'created': '2018-08-13 15:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4158c6afafd4fa2602a138f2bc410c4a4cbd29a0', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 28, 'created': '2018-09-17 10:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f330a3921a9d92901dc16e881fb39b57e3e67aa9', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 29, 'created': '2018-09-26 14:44:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/661f2eb2b8608857bd71e1d8873d3ad5c82adc6a', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 30, 'created': '2018-10-25 14:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e964abcec5d6f7b12166c5793c10cf5cb79fc7b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 31, 'created': '2018-10-30 13:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f10a9c9095a93c3d7bb39dc8c78f528807dae08', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 32, 'created': '2018-11-05 22:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3563e73f928938b98b89c85d953f71a0f9e4f39', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 33, 'created': '2018-11-07 11:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/346db33d7d3185efc2c86dfd7d20984000404a94', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 34, 'created': '2018-11-22 12:00:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8518dfef56259f5ee1fe92b5eaa5dabecb07b0d8', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 35, 'created': '2018-12-10 09:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72750c60b4d484a67d06bff1681eacb69047341b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 36, 'created': '2018-12-14 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d795c54d8363d6c7cd23da307dce77879e8e79b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 37, 'created': '2018-12-18 11:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/59565c8e772038a083b3950644485c31148a664a', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 38, 'created': '2018-12-18 14:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/afd845860ee08b09b09f23c45808a4c58920af82', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 39, 'created': '2018-12-18 15:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/835f63f1d876ea8a380f6b57913d3493e35e44db', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 40, 'created': '2018-12-19 15:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6ad75ba75a221d60dc762e28e99563bed85c0f7', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch makes it possible to boot server with a neutron\nport that has resource request. But it does not handle many server\nlifecycle operations like resize, migrate, live-migrate, unshelve.\nHowever the nova code only activated if the neutron port has a\nresource_request attribute. This attribute is introduced in a new\nneutron API extension[1]. So my suggestion is to consider that API\nextension as a feature flag for this whole feature. See a bit more\ndetailed description about this approach in the ML post [2].\n\n[1] https://review.openstack.org/#/c/590363\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 41, 'created': '2018-12-20 10:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6ef074a53d6fce5fb3bef904fe616577050f6db', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch makes it possible to boot server with a neutron\nport that has resource request. But it does not handle many server\nlifecycle operations like resize, migrate, live-migrate, unshelve.\nHowever the nova code only activated if the neutron port has a\nresource_request attribute. This attribute is introduced in a new\nneutron API extension[1]. So my suggestion is to consider that API\nextension as a feature flag for this whole feature. See a bit more\ndetailed description about this approach in the ML post [2].\n\n[1] https://review.openstack.org/#/c/590363\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 42, 'created': '2018-12-20 16:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5e471e1f968ce6142ee2d48185780483dd54d023', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch makes it possible to boot server with a neutron\nport that has resource request. But it does not handle many server\nlifecycle operations like resize, migrate, live-migrate, unshelve.\nTo avoid possible resource allocation inconsistencies due to the partial\nsupport for this type of requests a new config option is introduced as a\nfeature flag. The support is disabled by default by this flag but also\nthis flag allows functional and higher level tests to enable and\ntherefore test the already implemented cases. For more discussion about\nthis approach see the ML thread starting at [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 43, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85873bbd3bd94f5e5ca7e53b056ac57665b49f05', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 44, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03a6bfbbad42e0bb6b60ebf547c48f2920c90e66', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 45, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96e0bef7888e02baec8de2963fb7e65136ac6876', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 46, 'created': '2019-01-28 14:51:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2983a49f8be40b5f6f5572988fdb22f2d423c8b', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 47, 'created': '2019-02-06 15:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27202ff41ea8a89af077346c1bb1ed5465f1e391', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}, {'number': 48, 'created': '2019-02-08 01:07:13.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/integrated_helpers.py', 'nova/conductor/tasks/migrate.py', 'nova/conductor/manager.py', 'nova/conductor/tasks/live_migrate.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/03bc8b6a6b47d5372b30453283f85d2264e5b1f9', 'message': 'Transfer port.resource_request to the scheduler\n\nThis patch collects the resource requests from each neutron port\ninvolved in a server create request. Converts each request to\na RequestGroup object and includes them in the RequestSpec.\nThis way the requests are reaching the scheduler and there\nthey are included in the generation of the allocation_candidates\nquery.\n\nThis patch only handles the happy path of a server create request. But\nit adds couple of TODOs to places where the server move operations\nrelated code paths need to be implemented. That implementation will be\npart of subsequent patches.\n\nNote that this patch technically makes it possible to boot server with\none neutron port that has resource request. But it does not handle\nmultiple such ports or SRIOV ports where two PFs are supporting the\nsame physnet as well as many server lifecycle operations like resize,\nmigrate, live-migrate, unshelve. To avoid possible resource allocation\ninconsistencies due to the partial support nova rejects any requests\nthat involves such ports. See the previous patches in this patch\nseries for details.\n\nAlso note that the simple boot cases are verified with functional tests\nand in those tests we need to mock out the above described logic that\nreject such requests. See a more background about this approach on the\nML [1].\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html\n\nblueprint bandwidth-resource-provider\nChange-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f\n'}]",178,567268,03bc8b6a6b47d5372b30453283f85d2264e5b1f9,576,24,48,9708,,,0,"Transfer port.resource_request to the scheduler

This patch collects the resource requests from each neutron port
involved in a server create request. Converts each request to
a RequestGroup object and includes them in the RequestSpec.
This way the requests are reaching the scheduler and there
they are included in the generation of the allocation_candidates
query.

This patch only handles the happy path of a server create request. But
it adds couple of TODOs to places where the server move operations
related code paths need to be implemented. That implementation will be
part of subsequent patches.

Note that this patch technically makes it possible to boot server with
one neutron port that has resource request. But it does not handle
multiple such ports or SRIOV ports where two PFs are supporting the
same physnet as well as many server lifecycle operations like resize,
migrate, live-migrate, unshelve. To avoid possible resource allocation
inconsistencies due to the partial support nova rejects any requests
that involves such ports. See the previous patches in this patch
series for details.

Also note that the simple boot cases are verified with functional tests
and in those tests we need to mock out the above described logic that
reject such requests. See a more background about this approach on the
ML [1].

[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/001129.html

blueprint bandwidth-resource-provider
Change-Id: Ica6152ccb97dce805969d964d6ed032bfe22a33f
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/567268/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/placement/lib.py', 'nova/network/neutronv2/api.py', 'nova/objects/request_spec.py', 'nova/scheduler/utils.py', 'nova/tests/fixtures.py', 'nova/objects/network_request.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py']",8,66317dbf425636c4eaea8d98166d49d1c6088361,bp/bandwidth-resource-provider," # NOTE(gibi): It is a big hack that create_pci_requests_for_sriov_ports # fills the resource requests in the requested_networks # TODO(gibi): make create_pci_requests_for_sriov_ports more generic # to handle both the pci request and the resource request part LOG.error('!!!!!!!!!!! requested_networks' + str(requested_networks)) port_resource_requests = [] if requested_networks: port_resource_requests = requested_networks.get_resource_requests() 'system_metadata': system_metadata, 'port_resource_requests': port_resource_requests} security_groups=security_groups, port_resource_requests=base_options[ 'port_resource_requests'])", 'system_metadata': system_metadata} security_groups=security_groups),146,14
openstack%2Fheat-agents~master~Ideb9d57e7ab719e4f45cd5bc8cd92056ad478a64,openstack/heat-agents,master,Ideb9d57e7ab719e4f45cd5bc8cd92056ad478a64,Add Ubuntu version of heat-config-kubelet,MERGED,2018-12-07 11:09:32.000000000,2019-02-12 07:33:47.000000000,2019-02-12 07:33:47.000000000,"[{'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 25277}]","[{'number': 1, 'created': '2018-12-07 11:09:32.000000000', 'files': ['heat-config-kubelet/install.d/50-heat-config-kubelet'], 'web_link': 'https://opendev.org/openstack/heat-agents/commit/b1f36deedc0b97d4e7538c7c43072615f40178ff', 'message': 'Add Ubuntu version of heat-config-kubelet\n\nAdds Ubuntu-compatible version of heat-config-kubelet.\n\nChange-Id: Ideb9d57e7ab719e4f45cd5bc8cd92056ad478a64\n'}]",0,623448,b1f36deedc0b97d4e7538c7c43072615f40178ff,8,5,1,25277,,,0,"Add Ubuntu version of heat-config-kubelet

Adds Ubuntu-compatible version of heat-config-kubelet.

Change-Id: Ideb9d57e7ab719e4f45cd5bc8cd92056ad478a64
",git fetch https://review.opendev.org/openstack/heat-agents refs/changes/48/623448/1 && git format-patch -1 --stdout FETCH_HEAD,['heat-config-kubelet/install.d/50-heat-config-kubelet'],1,b1f36deedc0b97d4e7538c7c43072615f40178ff,heat-config-kubelet-ubuntu-version,"elif [[ ""ubuntu"" =~ ""$DISTRO_NAME"" ]]; then apt-get update apt-get install -y apt-transport-https gnupg curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add cat << EOF > /etc/apt/sources.list.d/kubernetes.list deb http://apt.kubernetes.io/ kubernetes-$(lsb_release -cs) main EOF apt-get update apt-get install -y kubelet kubeadm kubectl kubernetes-cni bridge-utils docker.io cat << EOF > /etc/network/interfaces.d/cbr0.cfg auto cbr0 iface cbr0 inet static bridge_ports none bridge_stp on bridge_waitport 2 bridge_fd 2 address 10.240.1.1 netmask 255.255.255.0 mtu 1450 post-up /bin/ip route add 10.240.0.0/16 dev cbr0 scope link src 10.240.1.1 EOF # defer docker starting until cbr0 is up cat > /etc/systemd/system/docker.service <<EOF .include /lib/systemd/system/docker.service [Unit] After=network-online.target docker.socket EOF cat > /etc/systemd/system/heat-config-kubelet-nat-rule.service <<EOF [Unit] Description=iptables rule to allow nat masquerading out of 10.240.1.0/24 [Service] ExecStart=/sbin/iptables -t nat -A POSTROUTING -o eth0 -s 10.240.1.0/24 -j MASQUERADE Type=oneshot [Install] WantedBy=multi-user.target EOF if [ -f ""/opt/heat-docker/images.tar"" ]; then cat > /etc/systemd/system/heat-config-kubelet-load-images.service <<EOF [Unit] Description=Call docker load on /opt/heat-config/images.tar After=docker.service Before=os-collect-config.service kubelet.service [Service] ExecStart=/usr/bin/docker load -i /opt/heat-docker/images.tar ExecStart=/bin/rm -f /opt/heat-docker/images.tar Type=oneshot [Install] WantedBy=multi-user.target EOF systemctl enable heat-config-kubelet-load-images.service fi cat << EOF > /etc/docker/daemon.json { ""bridge"": ""cbr0"", ""mtu"": 1450, ""iptables"": false, ""insecure-registries"": [""192.168.20.112:5001""] } EOF sed -e 's|KUBELET_EXTRA_ARGS=|KUBELET_EXTRA_ARGS=""--config=/var/lib/heat-config/heat-config-kubelet/kubelet-manifests""|g' -i /etc/default/kubelet systemctl disable docker.service systemctl enable docker.service systemctl enable kubelet.service systemctl enable heat-config-kubelet-nat-rule.service SCRIPTDIR=$(dirname $0) install -D -g root -o root -m 0755 ${SCRIPTDIR}/hook-kubelet.py /var/lib/heat-config/hooks/kubelet",SCRIPTDIR=$(dirname $0) install -D -g root -o root -m 0755 ${SCRIPTDIR}/hook-kubelet.py /var/lib/heat-config/hooks/kubelet,72,2
openstack%2Fheat-agents~master~I38c2a0086f55661d2426b42721c406ad58ea9c58,openstack/heat-agents,master,I38c2a0086f55661d2426b42721c406ad58ea9c58,dict_object.keys() is not required for *in* operator,MERGED,2018-12-19 11:48:56.000000000,2019-02-12 07:26:25.000000000,2019-02-12 07:26:25.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-12-19 11:48:56.000000000', 'files': ['heat-config-json-file/install.d/hook-json-file.py', 'heat-config-docker-compose/install.d/hook-docker-compose.py'], 'web_link': 'https://opendev.org/openstack/heat-agents/commit/baf746afb8e19fac4a44b381472c6e96691d07d6', 'message': 'dict_object.keys() is not required for *in* operator\n\ncleanup of .keys() from dict_object.keys() *in* operator\n\nChange-Id: I38c2a0086f55661d2426b42721c406ad58ea9c58\n'}]",0,626160,baf746afb8e19fac4a44b381472c6e96691d07d6,21,5,1,23717,,,0,"dict_object.keys() is not required for *in* operator

cleanup of .keys() from dict_object.keys() *in* operator

Change-Id: I38c2a0086f55661d2426b42721c406ad58ea9c58
",git fetch https://review.opendev.org/openstack/heat-agents refs/changes/60/626160/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat-config-json-file/install.d/hook-json-file.py', 'heat-config-docker-compose/install.d/hook-docker-compose.py']",2,baf746afb8e19fac4a44b381472c6e96691d07d6,, if file in input_env_files:, if file in input_env_files.keys():,2,2
openstack%2Ftripleo-common~master~I82ae0276b34d702abc9578539ac574a231c2afd1,openstack/tripleo-common,master,I82ae0276b34d702abc9578539ac574a231c2afd1,Set indent to 4 spaces as per bashate in opendaylight-api script,ABANDONED,2018-10-03 07:03:45.000000000,2019-02-12 07:18:20.000000000,,"[{'_account_id': 16448}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-10-03 07:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f03215df691097becde23654dcce312db1afbc36', 'message': 'Set indent to 4 spaces as per bashate in opendaylight-api script\n\nChange-Id: I82ae0276b34d702abc9578539ac574a231c2afd1\nSigned-off-by: Pablo Iranzo Gmez <Pablo.Iranzo@gmail.com>\n'}, {'number': 2, 'created': '2018-10-05 13:20:03.000000000', 'files': ['healthcheck/opendaylight-api'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0ae50cfa192c78f2465720b971af9d707ab4a248', 'message': 'Set indent to 4 spaces as per bashate in opendaylight-api script\n\nChange-Id: I82ae0276b34d702abc9578539ac574a231c2afd1\nSigned-off-by: Pablo Iranzo Gmez <Pablo.Iranzo@gmail.com>\n'}]",0,607478,0ae50cfa192c78f2465720b971af9d707ab4a248,38,5,2,16448,,,0,"Set indent to 4 spaces as per bashate in opendaylight-api script

Change-Id: I82ae0276b34d702abc9578539ac574a231c2afd1
Signed-off-by: Pablo Iranzo Gmez <Pablo.Iranzo@gmail.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/78/607478/1 && git format-patch -1 --stdout FETCH_HEAD,['healthcheck/opendaylight-api'],1,f03215df691097becde23654dcce312db1afbc36,indent," bind_host=""[${bind_host}]"""," bind_host=""[${bind_host}]""",1,1
openstack%2Ftripleo-common~master~I711bbd6200f94c3b53d86a5211481e6ddbd4fb89,openstack/tripleo-common,master,I711bbd6200f94c3b53d86a5211481e6ddbd4fb89,Replace simple $var usage to ${var},ABANDONED,2018-10-24 10:18:27.000000000,2019-02-12 07:18:07.000000000,,"[{'_account_id': 14985}, {'_account_id': 16448}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-24 10:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/706197a47482316ea408da8ec9b430cd17f04ecf', 'message': 'Replace simple var usage  to\n\nChange-Id: I711bbd6200f94c3b53d86a5211481e6ddbd4fb89\n'}, {'number': 2, 'created': '2018-10-24 10:19:38.000000000', 'files': ['healthcheck/ovn-dbs', 'healthcheck/neutron-api', 'healthcheck/octavia-housekeeping', 'healthcheck/neutron-l3', 'healthcheck/cinder-volume', 'healthcheck/nova-compute', 'healthcheck/swift-object-server', 'healthcheck/ceilometer-agent-ipmi', 'healthcheck/octavia-worker', 'healthcheck/nova-ironic', 'healthcheck/neutron-dhcp', 'healthcheck/mistral-event-engine', 'healthcheck/memcached', 'healthcheck/swift-account-server', 'healthcheck/mariadb', 'healthcheck/barbican-worker', 'healthcheck/neutron-ovs-agent', 'healthcheck/nova-conductor', 'healthcheck/neutron-sriov-agent', 'healthcheck/common.sh', 'healthcheck/nova-consoleauth', 'healthcheck/barbican-keystone-listener', 'healthcheck/swift-proxy', 'healthcheck/ceilometer-agent-central', 'healthcheck/ironic-inspector', 'healthcheck/ironic-conductor', 'healthcheck/opendaylight-api', 'healthcheck/mistral-engine', 'healthcheck/manila-scheduler', 'healthcheck/sahara-api', 'healthcheck/sahara-engine', 'healthcheck/aodh-listener', 'healthcheck/redis', 'healthcheck/gnocchi-statsd', 'healthcheck/cinder-scheduler', 'healthcheck/cinder-backup', 'healthcheck/aodh-notifier', 'healthcheck/mistral-executor', 'healthcheck/ovn-metadata', 'healthcheck/octavia-health-manager', 'healthcheck/ceilometer-agent-notification', 'healthcheck/sensu-client', 'healthcheck/swift-object-expirer', 'healthcheck/gnocchi-metricd', 'healthcheck/aodh-evaluator', 'healthcheck/heat-engine', 'healthcheck/octavia-api', 'healthcheck/glance-api', 'healthcheck/swift-rsync', 'healthcheck/ceilometer-agent-compute', 'healthcheck/neutron-metadata', 'healthcheck/tacker', 'healthcheck/swift-container-server', 'healthcheck/nova-scheduler', 'healthcheck/ovn-controller'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/95db6bfe6d6266c835832bbedec6f8b8efbcce01', 'message': 'Replace simple $var usage to ${var}\n\nChange-Id: I711bbd6200f94c3b53d86a5211481e6ddbd4fb89\n'}]",3,612977,95db6bfe6d6266c835832bbedec6f8b8efbcce01,19,4,2,16448,,,0,"Replace simple $var usage to ${var}

Change-Id: I711bbd6200f94c3b53d86a5211481e6ddbd4fb89
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/77/612977/1 && git format-patch -1 --stdout FETCH_HEAD,"['healthcheck/ovn-dbs', 'healthcheck/neutron-api', 'healthcheck/octavia-housekeeping', 'healthcheck/neutron-l3', 'healthcheck/cinder-volume', 'healthcheck/nova-compute', 'healthcheck/swift-object-server', 'healthcheck/ceilometer-agent-ipmi', 'healthcheck/octavia-worker', 'healthcheck/nova-ironic', 'healthcheck/neutron-dhcp', 'healthcheck/mistral-event-engine', 'healthcheck/memcached', 'healthcheck/swift-account-server', 'healthcheck/mariadb', 'healthcheck/barbican-worker', 'healthcheck/neutron-ovs-agent', 'healthcheck/nova-conductor', 'healthcheck/neutron-sriov-agent', 'healthcheck/common.sh', 'healthcheck/nova-consoleauth', 'healthcheck/barbican-keystone-listener', 'healthcheck/swift-proxy', 'healthcheck/ceilometer-agent-central', 'healthcheck/ironic-inspector', 'healthcheck/ironic-conductor', 'healthcheck/opendaylight-api', 'healthcheck/mistral-engine', 'healthcheck/manila-scheduler', 'healthcheck/sahara-api', 'healthcheck/sahara-engine', 'healthcheck/aodh-listener', 'healthcheck/redis', 'healthcheck/gnocchi-statsd', 'healthcheck/cinder-scheduler', 'healthcheck/cinder-backup', 'healthcheck/aodh-notifier', 'healthcheck/mistral-executor', 'healthcheck/ovn-metadata', 'healthcheck/octavia-health-manager', 'healthcheck/ceilometer-agent-notification', 'healthcheck/sensu-client', 'healthcheck/swift-object-expirer', 'healthcheck/gnocchi-metricd', 'healthcheck/aodh-evaluator', 'healthcheck/heat-engine', 'healthcheck/octavia-api', 'healthcheck/glance-api', 'healthcheck/swift-rsync', 'healthcheck/ceilometer-agent-compute', 'healthcheck/neutron-metadata', 'healthcheck/tacker', 'healthcheck/swift-container-server', 'healthcheck/nova-scheduler', 'healthcheck/ovn-controller']",55,706197a47482316ea408da8ec9b430cd17f04ecf,simplevars,if healthcheck_port ${process} ${args}; then,if healthcheck_port $process $args; then,105,105
openstack%2Ftacker-specs~master~I50c6db0462b936a76457b908fb7d9c3c454a662c,openstack/tacker-specs,master,I50c6db0462b936a76457b908fb7d9c3c454a662c,Update specs for tacker-service-function-forwarding-group,NEW,2019-01-28 07:54:15.000000000,2019-02-12 07:13:28.000000000,,"[{'_account_id': 2874}, {'_account_id': 12455}, {'_account_id': 18955}, {'_account_id': 22290}, {'_account_id': 22348}, {'_account_id': 26222}]","[{'number': 1, 'created': '2019-01-28 07:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/ecba56f74c002240c2fad527a02047b1cee81d88', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 2, 'created': '2019-01-28 12:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/dad359aaf80119e2e3aac0506b175e7a56f7695c', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 3, 'created': '2019-01-28 12:18:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/01da3acafd59dbc036fa59461df5d0c18c621a3d', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 4, 'created': '2019-01-28 12:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/c800038852d7af2e6cfa05d869ad23a97add1d85', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 5, 'created': '2019-01-28 13:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/e3abf7d115bf0617f9ccf3fd715c4e515d1e73a9', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 6, 'created': '2019-01-29 01:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/b6b39463944e57b395fd47cf9508741bba7c09c2', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}, {'number': 7, 'created': '2019-01-30 06:00:53.000000000', 'files': ['specs/stein/tacker-service-function-forwarding-group.rst'], 'web_link': 'https://opendev.org/openstack/tacker-specs/commit/874a4be62c565a3414422224a4666d1e8f4e3bae', 'message': 'Update specs for tacker-service-function-forwarding-group\n\nCorrect syntax for specs\n\nChange-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c\n'}]",8,633449,874a4be62c565a3414422224a4666d1e8f4e3bae,15,6,7,29809,,,0,"Update specs for tacker-service-function-forwarding-group

Correct syntax for specs

Change-Id: I50c6db0462b936a76457b908fb7d9c3c454a662c
",git fetch https://review.opendev.org/openstack/tacker-specs refs/changes/49/633449/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/tacker-service-function-forwarding-group.rst'],1,ecba56f74c002240c2fad527a02047b1cee81d88,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============= Tacker Service Function Forwarding Group ============= https://blueprints.launchpad.net/tacker/+spec This spec describes the plan to add multiple VNF forwarding in VNFFG VNFFG support load balancing, multicast and HA for Service Function Chaining in Tacker. :: +---+ +---+ +---+ +---+ +---+ |sf2| |sf3| |sf1| |sf2| |sf5| +---+ +---+ +---+ +---+ +---+ | | | | | +---+---+ +-----+-----+ | | + + +---+ +---+ +---+ +---+ +---+ source+-->|sfg|+-->|sfg|+--->|sfg|+--->|sfg|+-->|sfg|+-->destination +---+ +---+ +---+ +---+ +---+ + + + | | | +---+ +---+ +---+ |sf1| |sf4| |sf6| +---+ +---+ +---+ Problem description =================== Currently VNFFGD only allow forwarding traffic to one VNFD in service function path. It's very inflexible for user to apply some network tech like load balancing, multicast or HA mechanism that require packets routed to multi destination or re-route the traffic. Proposed changes ================ Adding SF Node group. Allow packets will forward to group of VNF instances in a service chain instead only one VNF. Support 3 type of packet forwarding: - Select: Same as load balancing. Packets will be forwarded to one of the members in the group at a time. - All: Using for multicast traffic. Packets will be routed to all members in the group. - Failover: Only one VNF is used at a time, and the forwarding path will only be changed if the VNF state transitions from up to down. Upon such an event, another VNF will be chosen whose VNF indicates the state is up. Failover SF group/cluster provides a system that ensures that chaining service function is not lost due to a failure. The Tacker server will monitor the ""liveness"" or up/down status of the indicated Service Function. If the liveness is deemed to be down, then the VNF will not be used. If the liveness is determined to be up, then the SF can be used. Only one SF can be used at a time, and the SF in use will not be changed unless the liveness of the currently used application service transitions from up to down. When such an event occurs, the FAST-FAILOVER group will quickly select the next SF in the VNF list with a application service that is up. :: TOSCA Definition for new forwarding path: tosca.nfv.datatypes.pathType: properties: forwarder: type: string required: true capability: type: string required: true tosca.nfv.datatypes.pathTypeVNFFGroup: properties: id: type: int required: false type: type: string default: select required: true forwarders: type: list required: true entry_schema: type: tosca.nfv.datatypes.pathType TOSCA sample for VNFFG: tosca_definitions_version: tosca_simple_profile_for_nfv_1_0_0 description: Sample VNFFG template topology_template: node_templates: Forwarding_path2: type: tosca.nodes.nfv.FP.TackerV2 description: creates path (CP1->CP2) properties: id: 52 symmetrical: false policy: type: ACL criteria: - name: block_tcp classifier: network_src_port_id: 640dfd77-c92b-45a3-b8fc-22712de480e1 destination_port_range: 22-28 ip_proto: 6 ip_dst_prefix: 192.168.1.2/24 path: - type: select forwarders: - forwarder: VNFD1 capability: CP1 - type: failover forwarders: - forwarder: VNFD4 capability: CP4 - forwarder: VNFD5 capability: CP5 - type: all forwarders: - forwarder: VNFD2 capability: CP2 - forwarder: VNFD3 capability: CP3 groups: VNFFG1: type: tosca.groups.nfv.VNFFG description: SSH to Corporate Net properties: vendor: tacker version: 1.0 number_of_endpoints: 2 dependent_virtual_link: [VL1,VL2] connection_point: [CP1,CP2] constituent_vnfs: [VNFD1,VNFD2] members: [Forwarding_path2] Alternatives ------------ * Tacker currently supports a single method of monitoring a VNF, pinging the management IP address. Failover SFC VNFs group may require additional monitoring methods in order to be able to use Tacker to check liveness of SF [#f2]. Data model impact ----------------- In the future work, we can save the group of forwarding VNF into the Tacker database using Tacker API. In that case, a new table need to be created to store the VNF forwarding group. The table model will be as following: :: +----------------------------------------------------------------+ | Table name: vnffgroup | +------------------+--------+------------------------------------+ | Column | Type | Index | +------------------+--------+------------------------------------+ | id | string | True | +------------------+--------+------------------------------------+ | group_type | string | False | +------------------+--------+------------------------------------+ +----------------------------------------------------------------+ | Table name: vnf_vnffgroup | +------------------+--------+------------------------------------+ | Column | Type | Index | +------------------+--------+------------------------------------+ | group_id | string | True | +------------------+--------+------------------------------------+ | vnf_id | string | True | +------------------+--------+------------------------------------+ | vnf_state | string | False | +------------------+--------+------------------------------------+ +----------------------------------------------------------------+ | Table name: vnffgnfps_vnffgroup | +------------------+--------+------------------------------------+ | Column | Type | Index | +------------------+--------+------------------------------------+ | vnffgnfps_id | string | True | +------------------+--------+------------------------------------+ | group_id | string | True | +------------------+--------+------------------------------------+ **Note:** group_type values are: * 0: select * 1: all * 2: failover REST API impact --------------- A set of new Tacker API functions needed to be made to manipulate the new SF Forwarding group table (CRUD). Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Binh Nguyen <nhbinh@dcn.ssu.ac.kr> Work Items ---------- 1. Adding API for networking-sfc to support ALL and FAILOVER group forwarding. 2. Implement Tacker SF route managerment (using networking-sfc API) to re-route traffic incase one SF state change from up to down. 3. Add the unit test cases of all of the above functions 4. Write the user guide for Tacker Service Function Forwarding Group Dependencies ============ None Testing ======= A new set of unit test cases will need to be developed to validate the basic function and the packets flow. Documentation Impact ==================== A new user guide for this will be added. References ========== .. [#f1] https://docs.openstack.org/tacker/latest/contributor/vnfd_template_description.html .. [#f2] https://specs.openstack.org/openstack/tacker-specs/specs/liberty/monitor-framework.html ",,280,0
openstack%2Fos-brick~master~Ibfa1e66bc40656a9ce09d20570565c2d9fa62169,openstack/os-brick,master,Ibfa1e66bc40656a9ce09d20570565c2d9fa62169,Implement extend_volume for RBD,ABANDONED,2018-08-08 14:36:25.000000000,2019-02-12 07:05:48.000000000,,"[{'_account_id': 4523}, {'_account_id': 5575}, {'_account_id': 5997}, {'_account_id': 8871}, {'_account_id': 9236}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24230}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 27710}]","[{'number': 1, 'created': '2018-08-08 14:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cb42863d565b8f3607164627be4216cede7c8ab0', 'message': 'Implement extend_volume for RBD\n\nOn a cinder managed ceph pool the extension of the volume is done already\nthrough cinder. As the disk is not available on the hypervisor, we only\nneed to retrieve the size using the connection information provided.\n\nChange-Id: Ibfa1e66bc40656a9ce09d20570565c2d9fa62169\nCloses-Bug: #1786050\n'}, {'number': 2, 'created': '2018-08-28 13:10:55.000000000', 'files': ['os_brick/tests/initiator/connectors/test_rbd.py', 'os_brick/initiator/connectors/rbd.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/cb346610294a327577b11f81818a78e695f0ac0d', 'message': 'Implement extend_volume for RBD\n\nOn a cinder managed ceph pool the extension of the volume is done already\nthrough cinder. As the disk is not available on the hypervisor, we only\nneed to retrieve the size using the connection information provided.\n\nChange-Id: Ibfa1e66bc40656a9ce09d20570565c2d9fa62169\nCloses-Bug: #1786050\n'}]",6,589925,cb346610294a327577b11f81818a78e695f0ac0d,53,24,2,5575,,,0,"Implement extend_volume for RBD

On a cinder managed ceph pool the extension of the volume is done already
through cinder. As the disk is not available on the hypervisor, we only
need to retrieve the size using the connection information provided.

Change-Id: Ibfa1e66bc40656a9ce09d20570565c2d9fa62169
Closes-Bug: #1786050
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/25/589925/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/connectors/test_rbd.py', 'os_brick/initiator/connectors/rbd.py']",2,cb42863d565b8f3607164627be4216cede7c8ab0,bug/1786050," # The extension of the volume is normally done through # cinder directly on the ceph pool, we only need to retrieve # the size of the extended volume. device_info = self.connect_volume(connection_properties) new_size = device_info.get('path').rbd_image.size() self.disconnect_volume(connection_properties, device_info) return new_size", # TODO(walter-boring): is this possible? raise NotImplementedError,19,6
openstack%2Fpython-mistralclient~master~I52b1d87ada2ead4f47a402b8aa683a0fa1629e70,openstack/python-mistralclient,master,I52b1d87ada2ead4f47a402b8aa683a0fa1629e70,Add 'execution-get-report' command,MERGED,2019-02-05 07:51:52.000000000,2019-02-12 06:55:09.000000000,2019-02-12 06:55:09.000000000,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9712}, {'_account_id': 15353}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 28101}, {'_account_id': 29124}]","[{'number': 1, 'created': '2019-02-05 07:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/0aaadf1517ad95baf4bcf34c2a8bf3e903845815', 'message': ""WIP: add 'execution-get-report' command\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 2, 'created': '2019-02-06 11:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/34c875c80cf8086097828bbf7eab1ae6e9bf6865', 'message': ""WIP: add 'execution-get-report' command\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 3, 'created': '2019-02-07 16:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/0ce88508bcb0e637ce68c87f0b17cd92d53d7b54', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: bp/workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 4, 'created': '2019-02-07 16:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/2b47a2cfee1fdd14d962e9552d50b3a9c132179c', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 5, 'created': '2019-02-07 16:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/54721aed8b525f68f0b8147a3f37cb91e316e12b', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 6, 'created': '2019-02-07 17:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/81d3dbc6c293b22995d3afb66a43576dd980dbd2', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 7, 'created': '2019-02-08 05:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/5828fbc5af1d7701f48ec874e46284a481aab4a1', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 8, 'created': '2019-02-08 05:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/dcbce72d43eb1ef41606f9bf590993417e78daeb', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}, {'number': 9, 'created': '2019-02-08 08:02:32.000000000', 'files': ['mistralclient/shell.py', 'mistralclient/commands/v2/executions.py', 'mistralclient/tests/unit/v2/test_executions.py', 'mistralclient/api/v2/executions.py'], 'web_link': 'https://opendev.org/openstack/python-mistralclient/commit/8cbf2fa1b9bf626b8b6c6cfda72c80d6b3cf63bc', 'message': ""Add 'execution-get-report' command\n\nImplements blueprint: workflow-error-analysis\n\nDepends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n\nChange-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70\n""}]",0,634870,8cbf2fa1b9bf626b8b6c6cfda72c80d6b3cf63bc,22,8,9,8731,,,0,"Add 'execution-get-report' command

Implements blueprint: workflow-error-analysis

Depends-On: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2

Change-Id: I52b1d87ada2ead4f47a402b8aa683a0fa1629e70
",git fetch https://review.opendev.org/openstack/python-mistralclient refs/changes/70/634870/2 && git format-patch -1 --stdout FETCH_HEAD,"['mistralclient/shell.py', 'mistralclient/commands/v2/executions.py', 'mistralclient/tests/unit/v2/test_executions.py', 'mistralclient/api/v2/executions.py']",4,0aaadf1517ad95baf4bcf34c2a8bf3e903845815,bp/workflow-error-analysis,"urlparse = six.moves.urllib.parse self._ensure_not_empty( workflow_identifier=workflow_identifier or source_execution_id ) data = {'description': description} query_params = {} if force: query_params['force'] = True query_string = self._build_query_params(filters=query_params) def get_report(self, id, errors_only=True, max_depth=-1): self._ensure_not_empty(id=id) query_params = { 'errors_only': errors_only, 'max_depth': max_depth } query_string = ""?%s"" % urlparse.urlencode(list(query_params.items())) resp = self.http_client.get('/executions/%s/report%s' % (id, query_string)) return resp.json() #return self._get('/executions/%s/report%s' % (id, query_string))"," ident = workflow_identifier or source_execution_id self._ensure_not_empty(workflow_identifier=ident) data = { 'description': description, } qparams = {} if force: qparams['force'] = True query_string = self._build_query_params(filters=qparams)",96,9
openstack%2Fneutron~stable%2Fqueens~I2e38457942518c8a3e07e606091bb6720317b77e,openstack/neutron,stable/queens,I2e38457942518c8a3e07e606091bb6720317b77e,Fix update of ports cache in router_info class,MERGED,2019-02-09 15:18:38.000000000,2019-02-12 06:48:06.000000000,2019-02-12 06:48:06.000000000,"[{'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-09 15:18:38.000000000', 'files': ['neutron/tests/unit/agent/l3/test_router_info.py', 'neutron/agent/l3/router_info.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/48749c2788396a1dadd57232d18abb7bd131b826', 'message': 'Fix update of ports cache in router_info class\n\nRouterInfo class has got internal_ports cache which is updated\nin _process_internal_ports() method.\nThere was an issue in this updates logic because it was\niterating through enumerate local variable ""internal_ports""\nwhich represents current router ports and if such current port\nwas found in updated_ports list it was storred in\nRouterInfo().internal_ports variable under same index as was\nfound in ""internal_ports"" local variable.\nThis sometimes leads to an issue because same port can be\nstored under different index in internal_ports and\nRouterInfo().internal_ports lists thus wrong port in\nRouterInfo().internal_ports was overwritten.\n\nSuch issue leads to problem with generating radvd config file\nbecause in ports cache list there was duplicate info about same port\nso radvd config file contained duplicate interface definitions too.\n\nThis should be properly fixed by changing RouterInfo.internal_ports\nto be a dict instead of list of ports but such patch would be much\nbigger and (possibly) harded to backport to stable branches.\n\nChange-Id: I2e38457942518c8a3e07e606091bb6720317b77e\nCloses-Bug: #1813279\n(cherry picked from commit 21cddc47b446fdfb5535b347c1d7825a04e02c62)\n'}]",0,636024,48749c2788396a1dadd57232d18abb7bd131b826,13,6,1,11975,,,0,"Fix update of ports cache in router_info class

RouterInfo class has got internal_ports cache which is updated
in _process_internal_ports() method.
There was an issue in this updates logic because it was
iterating through enumerate local variable ""internal_ports""
which represents current router ports and if such current port
was found in updated_ports list it was storred in
RouterInfo().internal_ports variable under same index as was
found in ""internal_ports"" local variable.
This sometimes leads to an issue because same port can be
stored under different index in internal_ports and
RouterInfo().internal_ports lists thus wrong port in
RouterInfo().internal_ports was overwritten.

Such issue leads to problem with generating radvd config file
because in ports cache list there was duplicate info about same port
so radvd config file contained duplicate interface definitions too.

This should be properly fixed by changing RouterInfo.internal_ports
to be a dict instead of list of ports but such patch would be much
bigger and (possibly) harded to backport to stable branches.

Change-Id: I2e38457942518c8a3e07e606091bb6720317b77e
Closes-Bug: #1813279
(cherry picked from commit 21cddc47b446fdfb5535b347c1d7825a04e02c62)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/24/636024/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/l3/test_router_info.py', 'neutron/agent/l3/router_info.py']",2,48749c2788396a1dadd57232d18abb7bd131b826,bug/1813279-patch5-stable/queens," def _update_internal_ports_cache(self, port): # NOTE(slaweq): self.internal_ports is a list of port objects but # when it is updated in _process_internal_ports() method, # but it can be based only on indexes of elements in # self.internal_ports as index of element to updated is unknown. # It has to be done based on port_id and this method is doing exactly # that. for index, p in enumerate(self.internal_ports): if p['id'] == port['id']: self.internal_ports[index] = port break else: self.internal_ports.append(port) updated_ports = [] updated_ports.append(current_port) self._update_internal_ports_cache(p) for p in updated_ports: self._update_internal_ports_cache(p) interface_name = self.get_internal_device_name(p['id']) ip_cidrs = common_utils.fixed_ip_cidrs(p['fixed_ips']) LOG.debug(""updating internal network for port %s"", p) updated_cidrs += ip_cidrs self.internal_network_updated( interface_name, ip_cidrs, p['mtu']) enable_ra = enable_ra or self._port_has_ipv6_subnet(p)"," updated_ports = dict() updated_ports[current_port['id']] = current_port self.internal_ports.append(p) if updated_ports: for index, p in enumerate(internal_ports): if not updated_ports.get(p['id']): continue self.internal_ports[index] = updated_ports[p['id']] interface_name = self.get_internal_device_name(p['id']) ip_cidrs = common_utils.fixed_ip_cidrs(p['fixed_ips']) LOG.debug(""updating internal network for port %s"", p) updated_cidrs += ip_cidrs self.internal_network_updated( interface_name, ip_cidrs, p['mtu']) enable_ra = enable_ra or self._port_has_ipv6_subnet(p)",48,15
openstack%2Fsyntribos~master~Ibd92861173b1fea55e277b44f963305f7db6fa83,openstack/syntribos,master,Ibd92861173b1fea55e277b44f963305f7db6fa83,Trivial: Update pypi url to new url,ABANDONED,2018-04-21 10:30:42.000000000,2019-02-12 06:37:47.000000000,,"[{'_account_id': 22348}, {'_account_id': 25254}, {'_account_id': 25903}]","[{'number': 1, 'created': '2018-04-21 10:30:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/syntribos/commit/f54255685ae58f3d0b3519113e0c1e130ce2b6d2', 'message': 'Trivial: Update pypi url to new url\n\nPypi url changed from [1] to [2]\n\n[1] https://pypi.python.org/pypi/<package>\n[2] https://pypi.org/project/<package>\n\nChange-Id: Ibd92861173b1fea55e277b44f963305f7db6fa83\n'}, {'number': 2, 'created': '2018-05-09 07:04:37.000000000', 'files': ['README.rst', 'scripts/readme.py', 'doc/source/installation.rst'], 'web_link': 'https://opendev.org/openstack/syntribos/commit/87b3f210a5955d4af49711aff28e1b9e77b5c42a', 'message': 'Trivial: Update pypi url to new url\n\nPypi url changed from [1] to [2]\n\n[1] https://pypi.python.org/pypi/<package>\n[2] https://pypi.org/project/<package>\n\nChange-Id: Ibd92861173b1fea55e277b44f963305f7db6fa83\n'}]",2,563410,87b3f210a5955d4af49711aff28e1b9e77b5c42a,8,3,2,17130,,,0,"Trivial: Update pypi url to new url

Pypi url changed from [1] to [2]

[1] https://pypi.python.org/pypi/<package>
[2] https://pypi.org/project/<package>

Change-Id: Ibd92861173b1fea55e277b44f963305f7db6fa83
",git fetch https://review.opendev.org/openstack/syntribos refs/changes/10/563410/2 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'scripts/readme.py', 'doc/source/installation.rst']",3,f54255685ae58f3d0b3519113e0c1e130ce2b6d2,pypi-url,Syntribos can be installed directly from `pypi with pip <https://pypi.org/project/pip>`__.\with `pip <https://pypi.org/project/pip>`__.,Syntribos can be installed directly from `pypi with pip <https://pypi.python.org/pypi/pip>`__.with `pip <https://pypi.python.org/pypi/pip>`__.,10,10
openstack%2Fbifrost~master~Ib0e0b8dd458b8aa1621dd6f51c161a2aec4a7378,openstack/bifrost,master,Ib0e0b8dd458b8aa1621dd6f51c161a2aec4a7378,Follow the new PTI for document build,ABANDONED,2018-03-23 11:08:14.000000000,2019-02-12 06:36:38.000000000,,"[{'_account_id': 11655}, {'_account_id': 13689}, {'_account_id': 22348}, {'_account_id': 22474}]","[{'number': 1, 'created': '2018-03-23 11:08:14.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/6de487ff47b3ae139ff4a5344b7affe8d7d1fafe', 'message': 'Follow the new PTI for document build\n\nFor compliance with the Project Testing Interface as described in:\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nFor more detials information, please refer to:\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html\n\nChange-Id: Ib0e0b8dd458b8aa1621dd6f51c161a2aec4a7378\n'}]",2,555740,6de487ff47b3ae139ff4a5344b7affe8d7d1fafe,9,4,1,17130,,,0,"Follow the new PTI for document build

For compliance with the Project Testing Interface as described in:
https://governance.openstack.org/tc/reference/project-testing-interface.html

For more detials information, please refer to:
http://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html

Change-Id: Ib0e0b8dd458b8aa1621dd6f51c161a2aec4a7378
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/40/555740/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",4,6de487ff47b3ae139ff4a5344b7affe8d7d1fafe,update-pti,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt -r{toxinidir}/doc/requirements.txt commands = sphinx-build -W -b html doc/source doc/build/htmldeps = -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -r{toxinidir}/requirements.txt -r{toxinidir}/doc/requirements.txt,commands = python setup.py build_sphinx,12,13
openstack%2Fopenstack-ansible-ops~master~I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5,openstack/openstack-ansible-ops,master,I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5,Add the ability to enable or disable rollups / indexes,MERGED,2019-02-11 05:58:26.000000000,2019-02-12 06:33:05.000000000,2019-02-12 06:33:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 05:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/fa356d7cb533daa16b109d3e28f4006af9684c2c', 'message': 'Add the ability to enable or disable rollups / indexes\n\nThis change creates a new option to enable or disbale rollup jobs. This\nis also providing the default basic index patterns for kibana index\npatterns and elastic indexes.\n\nChange-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 2, 'created': '2019-02-12 03:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/d720849e55becee79230dedecee34ab150fad639', 'message': 'Add the ability to enable or disable rollups / indexes\n\nThis change creates a new option to enable or disbale rollup jobs. This\nis also providing the default basic index patterns for kibana index\npatterns and elastic indexes.\n\nChange-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 3, 'created': '2019-02-12 04:07:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/539ca82919d08fc2417bc36d1871890a9f30b708', 'message': 'Add the ability to enable or disable rollups / indexes\n\nThis change creates a new option to enable or disbale rollup jobs. This\nis also providing the default basic index patterns for kibana index\npatterns and elastic indexes.\n\nChange-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 4, 'created': '2019-02-12 04:50:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/5e601065bd6332085e0eb713d55ba229fbc13106', 'message': 'Add the ability to enable or disable rollups / indexes\n\nThis change creates a new option to enable or disbale rollup jobs. This\nis also providing the default basic index patterns for kibana index\npatterns and elastic indexes.\n\nChange-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 5, 'created': '2019-02-12 05:15:18.000000000', 'files': ['elk_metrics_6x/roles/elastic_retention/defaults/main.yml', 'elk_metrics_6x/installKibana.yml', 'elk_metrics_6x/installHeartbeat.yml', 'elk_metrics_6x/vars/variables.yml', 'elk_metrics_6x/roles/elastic_journalbeat/tasks/systemd.general-overrides.conf.j2', 'elk_metrics_6x/installJournalbeat.yml', 'elk_metrics_6x/createElasticIndexes.yml', 'elk_metrics_6x/installAuditbeat.yml', 'elk_metrics_6x/installFilebeat.yml', 'elk_metrics_6x/installPacketbeat.yml', 'elk_metrics_6x/installMetricbeat.yml', 'elk_metrics_6x/installAPMserver.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/0a0a4a0880b2839eff8496d57c88ee3b955895fd', 'message': 'Add the ability to enable or disable rollups / indexes\n\nThis change creates a new option to enable or disbale rollup jobs. This\nis also providing the default basic index patterns for kibana index\npatterns and elastic indexes.\n\nChange-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}]",0,636090,0a0a4a0880b2839eff8496d57c88ee3b955895fd,13,2,5,7353,,,0,"Add the ability to enable or disable rollups / indexes

This change creates a new option to enable or disbale rollup jobs. This
is also providing the default basic index patterns for kibana index
patterns and elastic indexes.

Change-Id: I60e96a2cdbe27de760b54c4d9d43bcde4d09bbf5
Signed-off-by: cloudnull <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/90/636090/4 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics_6x/roles/elastic_retention/defaults/main.yml', 'elk_metrics_6x/installKibana.yml', 'elk_metrics_6x/installHeartbeat.yml', 'elk_metrics_6x/vars/variables.yml', 'elk_metrics_6x/roles/elastic_journalbeat/tasks/systemd.general-overrides.conf.j2', 'elk_metrics_6x/installJournalbeat.yml', 'elk_metrics_6x/createElasticIndexes.yml', 'elk_metrics_6x/installAuditbeat.yml', 'elk_metrics_6x/installFilebeat.yml', 'elk_metrics_6x/installPacketbeat.yml', 'elk_metrics_6x/installMetricbeat.yml', 'elk_metrics_6x/installAPMserver.yml']",12,fa356d7cb533daa16b109d3e28f4006af9684c2c,, when: - elastic_create_rollup | bool when: - elastic_create_rollup | bool,,151,63
openstack%2Fheat-agents~master~If982f3a9d769698b177071dba1364255676c6647,openstack/heat-agents,master,If982f3a9d769698b177071dba1364255676c6647,Skip Hook docker cmd test until story 2004926 fixed,MERGED,2019-02-12 06:03:28.000000000,2019-02-12 06:33:04.000000000,2019-02-12 06:33:04.000000000,"[{'_account_id': 8833}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-12 06:03:28.000000000', 'files': ['tests/test_hook_docker_cmd.py'], 'web_link': 'https://opendev.org/openstack/heat-agents/commit/0f0fc98bd9f76e7bf108fdeb5ceb6555a17ceb42', 'message': 'Skip Hook docker cmd test until story 2004926 fixed\n\nChange-Id: If982f3a9d769698b177071dba1364255676c6647\nTask: #29443\n'}]",0,636268,0f0fc98bd9f76e7bf108fdeb5ceb6555a17ceb42,6,2,1,12404,,,0,"Skip Hook docker cmd test until story 2004926 fixed

Change-Id: If982f3a9d769698b177071dba1364255676c6647
Task: #29443
",git fetch https://review.opendev.org/openstack/heat-agents refs/changes/68/636268/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/test_hook_docker_cmd.py'],1,0f0fc98bd9f76e7bf108fdeb5ceb6555a17ceb42,story/2004926,from testtools import testcase@testcase.skip('Skipped until story/2004926 fixed'),,2,0
openstack%2Fnova~master~Id54226dc926839686906d04ecf8d791c0881f82a,openstack/nova,master,Id54226dc926839686906d04ecf8d791c0881f82a,Fix deprecation warning for threadgroup.add_timer,MERGED,2019-02-07 14:11:21.000000000,2019-02-12 06:23:19.000000000,2019-02-08 05:41:23.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-07 14:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/23c21887a3c6200c31cf9fdd96e4eafe5bd4318d', 'message': ""Fix deprecation warning for threadgroup.add_timer\n\nThis resolves the following deprecation warning:\n\nb'/home/zuul/src/git.openstack.org/openstack/nova/.tox/functional-py35/\nlib/python3.5/site-packages/oslo_service/threadgroup.py:193:\nDeprecationWarning: Calling add_timer() with arguments to the callback\nfunction is deprecated. Use add_timer_args() instead.'\n\nChange-Id: Id54226dc926839686906d04ecf8d791c0881f82a\nPartial-Bug: #1813147\n""}, {'number': 2, 'created': '2019-02-07 14:38:09.000000000', 'files': ['requirements.txt', 'nova/tests/unit/servicegroup/test_mc_servicegroup.py', 'nova/servicegroup/drivers/db.py', 'nova/tests/unit/servicegroup/test_db_servicegroup.py', 'lower-constraints.txt', 'nova/servicegroup/drivers/mc.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c03cc26ee04734b610d13c694cc8b12ad554b4aa', 'message': ""Fix deprecation warning for threadgroup.add_timer\n\nThis resolves the following deprecation warning:\n\nb'/home/zuul/src/git.openstack.org/openstack/nova/.tox/functional-py35/\nlib/python3.5/site-packages/oslo_service/threadgroup.py:193:\nDeprecationWarning: Calling add_timer() with arguments to the callback\nfunction is deprecated. Use add_timer_args() instead.'\n\nThe add_timer_args method was added in 1.34.0:\n\n  Ib2791342263e2b88c045bcc92adc8160f57a0ed6\n\nSo the required version of oslo.service is also updated.\n\nChange-Id: Id54226dc926839686906d04ecf8d791c0881f82a\nPartial-Bug: #1813147\n""}]",2,635516,c03cc26ee04734b610d13c694cc8b12ad554b4aa,27,12,2,6873,,,0,"Fix deprecation warning for threadgroup.add_timer

This resolves the following deprecation warning:

b'/home/zuul/src/git.openstack.org/openstack/nova/.tox/functional-py35/
lib/python3.5/site-packages/oslo_service/threadgroup.py:193:
DeprecationWarning: Calling add_timer() with arguments to the callback
function is deprecated. Use add_timer_args() instead.'

The add_timer_args method was added in 1.34.0:

  Ib2791342263e2b88c045bcc92adc8160f57a0ed6

So the required version of oslo.service is also updated.

Change-Id: Id54226dc926839686906d04ecf8d791c0881f82a
Partial-Bug: #1813147
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/635516/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/servicegroup/test_mc_servicegroup.py', 'nova/servicegroup/drivers/db.py', 'nova/tests/unit/servicegroup/test_db_servicegroup.py', 'nova/servicegroup/drivers/mc.py']",4,23c21887a3c6200c31cf9fdd96e4eafe5bd4318d,bug/1813147," service.tg.add_timer_args( report_interval, self._report_state, args=[service], initial_delay=api.INITIAL_REPORTING_DELAY)"," service.tg.add_timer(report_interval, self._report_state, api.INITIAL_REPORTING_DELAY, service)",10,6
openstack%2Fi18n~master~Ib134437fd44a8c6ff61be4b32a24ee833f75e70d,openstack/i18n,master,Ib134437fd44a8c6ff61be4b32a24ee833f75e70d,Add atc-stats Stein,MERGED,2019-01-27 10:01:16.000000000,2019-02-12 05:58:45.000000000,2019-02-12 05:58:45.000000000,"[{'_account_id': 841}, {'_account_id': 6882}, {'_account_id': 17765}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-27 10:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/4e7b18ef37f7dbd6fdfb9b9daaee4be2096e344b', 'message': 'Add atc-stats Stein\n\nChange-Id: Ib134437fd44a8c6ff61be4b32a24ee833f75e70d\n'}, {'number': 2, 'created': '2019-01-27 15:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/afcd6d834b0c586a2ea7e79e4221c05d292daf0d', 'message': 'Add atc-stats Stein\n\nChange-Id: Ib134437fd44a8c6ff61be4b32a24ee833f75e70d\n'}, {'number': 3, 'created': '2019-01-27 15:54:46.000000000', 'files': ['doc/source/data/stein.csv', 'doc/source/atc-stats.rst'], 'web_link': 'https://opendev.org/openstack/i18n/commit/2a93e0be2202767bd9f0f52022e87e293015902d', 'message': 'Add atc-stats Stein\n\nChange-Id: Ib134437fd44a8c6ff61be4b32a24ee833f75e70d\n'}]",0,633401,2a93e0be2202767bd9f0f52022e87e293015902d,13,4,3,17765,,,0,"Add atc-stats Stein

Change-Id: Ib134437fd44a8c6ff61be4b32a24ee833f75e70d
",git fetch https://review.opendev.org/openstack/i18n refs/changes/01/633401/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/data/stein.csv', 'doc/source/atc-stats.rst']",2,4e7b18ef37f7dbd6fdfb9b9daaee4be2096e344b,,Train cycleStein cycle ----------- * Period: 2018-07-10 to 2019-01-25 * Patch on governance repository: https://review.openstack.org/633398 * Foundation membership was validated by calling a REST API in https://openstackid-resources.openstack.org .. csv-table:: :header-rows: 1 :widths: 2 1 1 1 1 1 1 1 1 1 1 2 :file: data/stein.csv ,Stein cycle,88,1
openstack%2Fpuppet-tripleo~stable%2Fqueens~I6de446c2f9d87719e428ea83d8d55f80e2907131,openstack/puppet-tripleo,stable/queens,I6de446c2f9d87719e428ea83d8d55f80e2907131,Prepare for 8.3.7 release,MERGED,2019-02-07 16:43:22.000000000,2019-02-12 05:53:34.000000000,2019-02-11 23:21:01.000000000,"[{'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 16:43:22.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f50f3a844b60e77e6b5f010661cd9174b1809141', 'message': 'Prepare for 8.3.7 release\n\nNeeded-By: https://review.openstack.org/#/c/635539\nChange-Id: I6de446c2f9d87719e428ea83d8d55f80e2907131\n'}]",0,635565,f50f3a844b60e77e6b5f010661cd9174b1809141,9,3,1,8655,,,0,"Prepare for 8.3.7 release

Needed-By: https://review.openstack.org/#/c/635539
Change-Id: I6de446c2f9d87719e428ea83d8d55f80e2907131
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/65/635565/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,f50f3a844b60e77e6b5f010661cd9174b1809141,release-8.3.7," ""version"": ""8.3.7"","," ""version"": ""8.3.6"",",1,1
openstack%2Ftripleo-common~master~If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e,openstack/tripleo-common,master,If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e,overcloud_containers.yaml.j2: remove unused *-base entry,MERGED,2017-10-10 20:59:51.000000000,2019-02-12 05:43:25.000000000,2019-02-11 23:21:00.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4571}, {'_account_id': 13039}, {'_account_id': 15895}, {'_account_id': 16282}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-10-10 20:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/49c159d5b1c1e04ab11877712221be88449781f1', 'message': 'overcloud_containers.yaml.j2: remove unused manila-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 2, 'created': '2017-10-10 21:13:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4c3d131062c7462676f24b2b68f5db8508c4353b', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nthere was only test_killa_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 3, 'created': '2018-02-23 12:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/71560ceb70e4dbaad06f549650b48df23027a24d', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nthere was only test_killa_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 4, 'created': '2018-06-21 17:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/37db976fb874f78258a16bedb54128c9d1da4a6d', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nthere was only test_kolla_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 5, 'created': '2018-06-21 17:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a9601f97d2e935237b64d71a240d7160d10251ed', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nthere was only test_kolla_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 6, 'created': '2018-06-21 19:26:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8a32aca0f398607b6bd0e33d54a77cea11c23348', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nthere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nthere was only test_kolla_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 7, 'created': '2019-01-03 09:55:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a16b9fb639e69c9c679cc350a8cf67ffbd0dee16', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nThere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nThere was only test_kolla_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nCo-Authored-By: Martin Andr <m.andre@redhat.com>\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}, {'number': 8, 'created': '2019-01-29 12:08:55.000000000', 'files': ['container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c6905ddf3a2be0a35c9ffec519dc14e8dd71137b', 'message': 'overcloud_containers.yaml.j2: remove unused *-base entry\n\nThere are no other references to manila-base in tripleo-common for\nusage of manila-base container image.\n\nThere was only test_kolla_builder reference to ovn-base\nthere were no other references to opendaylight-base\n\nThere are only a few -base container images listed in this template.\n\nCo-Authored-By: Martin Andr <m.andre@redhat.com>\nChange-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e\n'}]",1,511039,c6905ddf3a2be0a35c9ffec519dc14e8dd71137b,40,8,8,16282,,,0,"overcloud_containers.yaml.j2: remove unused *-base entry

There are no other references to manila-base in tripleo-common for
usage of manila-base container image.

There was only test_kolla_builder reference to ovn-base
there were no other references to opendaylight-base

There are only a few -base container images listed in this template.

Co-Authored-By: Martin Andr <m.andre@redhat.com>
Change-Id: If8ea1d4aa988a205ab6f3cf87d8c0a90ffbbd08e
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/39/511039/8 && git format-patch -1 --stdout FETCH_HEAD,['container-images/overcloud_containers.yaml.j2'],1,49c159d5b1c1e04ab11877712221be88449781f1,trim_extra_entries,,"- imagename: ""{{namespace}}/{{name_prefix}}manila-base{{name_suffix}}:{{tag}}"" ",0,2
openstack%2Fnova~master~Id8c02e745742980d3dd0a24e6e2b7a5859f3cb88,openstack/nova,master,Id8c02e745742980d3dd0a24e6e2b7a5859f3cb88,Ignore sqla-migrate inspect.getargspec deprecation warnings,MERGED,2019-02-01 16:46:38.000000000,2019-02-12 05:38:30.000000000,2019-02-07 14:17:27.000000000,"[{'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-01 16:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11ece34db6b65bd788d716ee2f3c162983ae8cae', 'message': 'Ignore sqla-migrate inspect.getargspec deprecation warnings\n\nThis adds a warnings filter to ignore the ""inspect.getargspec""\nwarnings from sqlalchemy-migrate until bug 1814288 is fixed\nin that library.\n\nChange-Id: Id8c02e745742980d3dd0a24e6e2b7a5859f3cb88\nRelated-Bug: #1813147\n'}, {'number': 2, 'created': '2019-02-07 12:31:09.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d916a045c19beb0d058fa04e387bc0c4097d5990', 'message': 'Ignore sqla-migrate inspect.getargspec deprecation warnings\n\nThis adds a warnings filter to ignore the ""inspect.getargspec""\nwarnings from sqlalchemy-migrate until bug 1814288 is fixed\nin that library.\n\nChange-Id: Id8c02e745742980d3dd0a24e6e2b7a5859f3cb88\nRelated-Bug: #1813147\n'}]",0,634451,d916a045c19beb0d058fa04e387bc0c4097d5990,20,8,2,6873,,,0,"Ignore sqla-migrate inspect.getargspec deprecation warnings

This adds a warnings filter to ignore the ""inspect.getargspec""
warnings from sqlalchemy-migrate until bug 1814288 is fixed
in that library.

Change-Id: Id8c02e745742980d3dd0a24e6e2b7a5859f3cb88
Related-Bug: #1813147
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/634451/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,11ece34db6b65bd788d716ee2f3c162983ae8cae,bug/1814288," # TODO(mriedem): Change (or remove) this DeprecationWarning once # https://bugs.launchpad.net/sqlalchemy-migrate/+bug/1814288 is fixed. warnings.filterwarnings( 'ignore', message='inspect\.getargspec\(\) is deprecated', category=DeprecationWarning, module='migrate.versioning.script.py') ",,7,0
openstack%2Foslo.service~master~Id2418093494f1e233a653f6c73bd6894e4a40184,openstack/oslo.service,master,Id2418093494f1e233a653f6c73bd6894e4a40184,Profile Oslo Service processes,MERGED,2018-12-26 17:01:12.000000000,2019-02-12 05:35:18.000000000,2019-02-11 21:31:19.000000000,"[{'_account_id': 1669}, {'_account_id': 4257}, {'_account_id': 6928}, {'_account_id': 8788}, {'_account_id': 9107}, {'_account_id': 10061}, {'_account_id': 10237}, {'_account_id': 10267}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15334}, {'_account_id': 16845}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 27954}, {'_account_id': 28522}]","[{'number': 1, 'created': '2018-12-26 17:01:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/f606e18832e696f1dbf16ec307c47ba8a4b93eb0', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace) worker processes\non the fly while service is running. User requests the oslo service process\nto start profiling by writing ""trace"" command to backdoor socket,\nonce the application finishes expected processing (example finishing API call),\nuser again writes ""trace"" command with file name as argument to dump the\nfunction calltrace stats.\n\nFor example, to profile neutron server process,\n1) echo ""trace"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""trace(\'/tmp/trace\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'/tmp/trace\')\nstats.print_stats()\nThe trace file will look like (for above neutron API calls) [1]\n\nWe use GreenletProfiler [2] as it is the only profiler\nwhich profiles greenlets [3].\n\n[1] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[1] https://pypi.org/project/GreenletProfiler/\n[2] https://emptysqua.re/blog/greenletprofiler/\n\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}, {'number': 2, 'created': '2018-12-28 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/0681a0b380ad8fde9f2e57e8ab80476d402fe0b9', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace) worker processes\non the fly while service is running. User requests the oslo service process\nto start profiling by writing ""trace"" command to backdoor socket,\nonce the application finishes expected processing (example finishing API call),\nuser again writes ""trace"" command with file name as argument to dump the\nfunction calltrace stats.\n\nFor example, to profile neutron server process,\n1) echo ""trace"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""trace(\'/tmp/trace\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'/tmp/trace\')\nstats.print_stats()\nThe trace file will look like (for above neutron API calls) [1]\n\nWe use Yappi with context set to greenlet [2] to profile greenlets.\nWe can\'t use GreenletProfiler [3], which does the same [4]\n1) as it is no more maintained\n2) Also compiling yappi source inside GreenletProfiler is failing for\n   python3.\n\n[1] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[2] https://bitbucket.org/sumerc/yappi/pull-requests/3\n[3] https://pypi.org/project/GreenletProfiler/\n[4] https://emptysqua.re/blog/greenletprofiler/\n\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}, {'number': 3, 'created': '2018-12-28 12:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/4e1895a3ca77bd926eba8049b180a4b753e57bf8', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace) worker processes\non the fly while service is running. User requests the oslo service process\nto start profiling by writing ""trace"" command to backdoor socket,\nonce the application finishes expected processing (example finishing API call),\nuser again writes ""trace"" command with file name as argument to dump the\nfunction calltrace stats.\n\nFor example, to profile neutron server process,\n1) echo ""trace"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""trace(\'/tmp/trace\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'/tmp/trace\')\nstats.print_stats()\nThe trace file will look like (for above neutron API calls) [1]\n\nWe use Yappi with context set to greenlet [2] to profile greenlets.\nWe can\'t use GreenletProfiler [3], which does the same [4]\n1) as it is no more maintained\n2) Also compiling yappi source inside GreenletProfiler is failing for\n   python3.\n\n[1] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[2] https://bitbucket.org/sumerc/yappi/pull-requests/3\n[3] https://pypi.org/project/GreenletProfiler/\n[4] https://emptysqua.re/blog/greenletprofiler/\n\nDepends-On: Ibea0cdb732923f1b53d5cb6aeeb4041fb5973494\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}, {'number': 4, 'created': '2019-01-04 09:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/d2eeac1400d86ab6215166493054750474a5c351', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace) worker processes\non the fly while service is running. User requests the oslo service process\nto start profiling by writing ""prof"" command to backdoor socket,\nonce the application finishes expected processing (example finishing API call),\nuser again writes ""prof"" command with file name as argument to dump the\nfunction calltrace stats. A temporary random file will be generated in /tmp\ndirectory with the user provided prefix by adding .prof as suffix and stats\nwill be dumped to this file.\n\nFor example, to profile neutron server process,\n1) echo ""prof"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""prof(\'neutron\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'neutron0imTJk.prof\')\nstats.print_stats()\nThe trace file will look like (for above neutron API calls) [1]\n\nWe use Yappi with context set to greenlet [2] to profile greenlets.\nWe can\'t use GreenletProfiler [3], which does the same [4]\n1) as it is no more maintained\n2) Also compiling yappi source inside GreenletProfiler is failing for\n   python3.\n\n[1] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[2] https://bitbucket.org/sumerc/yappi/pull-requests/3\n[3] https://pypi.org/project/GreenletProfiler/\n[4] https://emptysqua.re/blog/greenletprofiler/\n\nDepends-On: Ibea0cdb732923f1b53d5cb6aeeb4041fb5973494\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}, {'number': 5, 'created': '2019-01-16 09:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/5249d058bbd451d38d7328a2fb08e20c3708ba7e', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace like\ncProfile [1]) worker processes on the fly while service is running.\nUser requests the oslo service process to start profiling by writing\n""prof()"" command to backdoor socket, once the service (like\nneutron-server) finishes expected processing (example finishing API\ncall), user again writes ""prof()"" command with file name as argument\nto dump the function calltrace stats. Stats file (in pstat format\nwith user provided filename by adding .prof) will be generated in\ntemp directory.\n\nFor example, to profile neutron server process,\n1) echo ""prof()"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""prof(\'neutron\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'/tmp/neutron.prof\')\nstats.print_stats()\nThe trace file will look like in (for above neutron API calls) [2].\n\nWe use Yappi with context set to greenlet [3] to profile greenlets.\nWe can\'t use GreenletProfiler [4], which does the same [5]\n1) as it is no more maintained\n2) Also compiling yappi source inside GreenletProfiler is failing for\n   python3.\n\n[1] https://docs.python.org/2/library/profile.html\n[2] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[3] https://bitbucket.org/sumerc/yappi/pull-requests/3\n[4] https://pypi.org/project/GreenletProfiler/\n[5] https://emptysqua.re/blog/greenletprofiler/\n\nDepends-On: Ibea0cdb732923f1b53d5cb6aeeb4041fb5973494\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}, {'number': 6, 'created': '2019-01-16 12:38:22.000000000', 'files': ['requirements.txt', 'doc/source/user/usage.rst', 'lower-constraints.txt', 'releasenotes/notes/profile-worker-5d3fd0f0251d62b8.yaml', 'oslo_service/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/a04daefbb158e955dcfe7379e2b38c272ff31da2', 'message': 'Profile Oslo Service processes\n\nThis patch enables profiling (capturing function call trace like\ncProfile [1]) worker processes on the fly while service is running.\nUser requests the oslo service process to start profiling by writing\n""prof()"" command to backdoor socket, once the service (like\nneutron-server) finishes expected processing (example finishing API\ncall), user again writes ""prof()"" command with file name as argument\nto dump the function calltrace stats. Stats file (in pstat format\nwith user provided filename by adding .prof) will be generated in\ntemp directory.\n\nFor example, to profile neutron server process,\n1) echo ""prof()"" | nc localhost 8002\n2) Issue neutron command (or run rally scenarios tests)\n   neutron net-create n1\n   neutron port-create --name p1 n1\n   neutron port-delete p1\n   neutron net-delete n1\n3) echo ""prof(\'neutron\')"" | nc localhost 8002\nwhere 8002 is the port which we set like below in neutron.conf\nbackdoor_port=8002\n\nWe can later print the stats from the trace file like below\nstats = pstats.Stats(\'/tmp/neutron.prof\')\nstats.print_stats()\nThe trace file will look like in (for above neutron API calls) [2].\n\nWe use Yappi with context set to greenlet [3] to profile greenlets.\nWe can\'t use GreenletProfiler [4], which does the same [5]\n1) as it is no more maintained\n2) Also compiling yappi source inside GreenletProfiler is failing for\n   python3.\n\n[1] https://docs.python.org/2/library/profile.html\n[2] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983\n[3] https://bitbucket.org/sumerc/yappi/pull-requests/3\n[4] https://pypi.org/project/GreenletProfiler/\n[5] https://emptysqua.re/blog/greenletprofiler/\n\nDepends-On: Ibea0cdb732923f1b53d5cb6aeeb4041fb5973494\nChange-Id: Id2418093494f1e233a653f6c73bd6894e4a40184\n'}]",21,627414,a04daefbb158e955dcfe7379e2b38c272ff31da2,51,17,6,10267,,,0,"Profile Oslo Service processes

This patch enables profiling (capturing function call trace like
cProfile [1]) worker processes on the fly while service is running.
User requests the oslo service process to start profiling by writing
""prof()"" command to backdoor socket, once the service (like
neutron-server) finishes expected processing (example finishing API
call), user again writes ""prof()"" command with file name as argument
to dump the function calltrace stats. Stats file (in pstat format
with user provided filename by adding .prof) will be generated in
temp directory.

For example, to profile neutron server process,
1) echo ""prof()"" | nc localhost 8002
2) Issue neutron command (or run rally scenarios tests)
   neutron net-create n1
   neutron port-create --name p1 n1
   neutron port-delete p1
   neutron net-delete n1
3) echo ""prof('neutron')"" | nc localhost 8002
where 8002 is the port which we set like below in neutron.conf
backdoor_port=8002

We can later print the stats from the trace file like below
stats = pstats.Stats('/tmp/neutron.prof')
stats.print_stats()
The trace file will look like in (for above neutron API calls) [2].

We use Yappi with context set to greenlet [3] to profile greenlets.
We can't use GreenletProfiler [4], which does the same [5]
1) as it is no more maintained
2) Also compiling yappi source inside GreenletProfiler is failing for
   python3.

[1] https://docs.python.org/2/library/profile.html
[2] https://gist.github.com/venkataanil/64d5e672bf0206dc151e73fc1058a983
[3] https://bitbucket.org/sumerc/yappi/pull-requests/3
[4] https://pypi.org/project/GreenletProfiler/
[5] https://emptysqua.re/blog/greenletprofiler/

Depends-On: Ibea0cdb732923f1b53d5cb6aeeb4041fb5973494
Change-Id: Id2418093494f1e233a653f6c73bd6894e4a40184
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/14/627414/4 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'oslo_service/eventlet_backdoor.py']",2,f606e18832e696f1dbf16ec307c47ba8a4b93eb0,profiler,"import GreenletProfilerdef _trace(trace_file=None): if not trace_file: GreenletProfiler.set_clock_type('cpu') GreenletProfiler.start() else: GreenletProfiler.stop() stats = GreenletProfiler.get_func_stats() try: stats.save(trace_file, ""pstat"") except Exception as e: print(""Error while saving the trace stats "", str(e)) GreenletProfiler.clear_stats() 'trace': _trace,",,17,0
openstack%2Ftempest~master~I8a0d5935b695a1649b204bd3c3351f34a80e9059,openstack/tempest,master,I8a0d5935b695a1649b204bd3c3351f34a80e9059,Immutable user source: v3 test_groups,MERGED,2019-01-17 17:15:38.000000000,2019-02-12 05:34:55.000000000,2019-02-12 05:34:55.000000000,"[{'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 20378}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-01-17 17:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/36531f59d1917174b95380faa22fb5fa5af7da04', 'message': 'Immutable user source: v3 test_groups\n\nIf the keystone user source is immutable, such as an LDAP\nactive directory implementation, tempest tests that try\nto create or delete a user will fail. Instead of failing,\nwe would like them to skip. This change uses a testtools\ndecorator to avoid unnecessary modifications and allow those tests\nto skip.\n\nChange-Id: I8a0d5935b695a1649b204bd3c3351f34a80e9059\n'}, {'number': 2, 'created': '2019-01-17 20:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d69f0c1ade276f234acacece3e1d4fb49f9e1551', 'message': 'Immutable user source: v3 test_groups\n\nIf the keystone user source is immutable, such as an LDAP\nactive directory implementation, tempest tests that try\nto create or delete a user will fail. Instead of failing,\nwe would like them to skip. This change uses a testtools\ndecorator to avoid unnecessary modifications and allow those tests\nto skip.\n\nPartial-Bug: #1777047\n\nChange-Id: I8a0d5935b695a1649b204bd3c3351f34a80e9059\n'}, {'number': 3, 'created': '2019-02-08 20:00:50.000000000', 'files': ['tempest/api/identity/admin/v3/test_groups.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/566237c0a1c1fc8421415fd414ce845956b41d90', 'message': 'Immutable user source: v3 test_groups\n\nIf the keystone user source is immutable, such as an LDAP\nactive directory implementation, tempest tests that try\nto create or delete a user will fail. Instead of failing,\nwe would like them to skip. This change uses a testtools\ndecorator to avoid unnecessary modifications and allow those tests\nto skip.\n\nPartial-Bug: #1777047\n\nChange-Id: I8a0d5935b695a1649b204bd3c3351f34a80e9059\n'}]",0,631582,566237c0a1c1fc8421415fd414ce845956b41d90,38,14,3,20378,,,0,"Immutable user source: v3 test_groups

If the keystone user source is immutable, such as an LDAP
active directory implementation, tempest tests that try
to create or delete a user will fail. Instead of failing,
we would like them to skip. This change uses a testtools
decorator to avoid unnecessary modifications and allow those tests
to skip.

Partial-Bug: #1777047

Change-Id: I8a0d5935b695a1649b204bd3c3351f34a80e9059
",git fetch https://review.opendev.org/openstack/tempest refs/changes/82/631582/3 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_groups.py'],1,36531f59d1917174b95380faa22fb5fa5af7da04,bug/1777047,"import testtools @testtools.skipIf(CONF.identity_feature_enabled.immutable_user_source, 'Skipped because environment has an ' 'immutable user source and solely ' 'provides read-only access to users.') @testtools.skipIf(CONF.identity_feature_enabled.immutable_user_source, 'Skipped because environment has an ' 'immutable user source and solely ' 'provides read-only access to users.')",,9,0
openstack%2Fneutron~stable%2Fpike~I4a045e0dcfcbd3c7959a78f1460d5bf7da0252ff,openstack/neutron,stable/pike,I4a045e0dcfcbd3c7959a78f1460d5bf7da0252ff,Always fill UDP checksums in DHCPv6 replies,MERGED,2019-02-01 23:25:18.000000000,2019-02-12 05:31:27.000000000,2019-02-12 05:31:27.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 13995}, {'_account_id': 15554}, {'_account_id': 17685}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-01 23:25:18.000000000', 'files': ['neutron/common/constants.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/399f1c1b65b5aad5a810d9986da35d07216fa707', 'message': 'Always fill UDP checksums in DHCPv6 replies\n\nBug #1244589 re-appeared for IPv6.\n\nThis change adds an ip6tables rule to fix the checksum of DHCPv6\nresponse packets. Those checksums were left unfilled by virtio (as a\nhypervisor internal optimization), but some picky dhcp clients (AFAIU\nparticularly ISC dhclient) try verifying the checksums, so they fail\nto acquire an address if the checksums are left incorrect.\n\nChange-Id: I4a045e0dcfcbd3c7959a78f1460d5bf7da0252ff\nCloses-Bug: #1811639\nRelated-Bug: #1244589\n(cherry picked from commit 26eb2509fea632e67ffabcc15195cc13ee02bf68)\n'}]",0,634515,399f1c1b65b5aad5a810d9986da35d07216fa707,20,9,1,7016,,,0,"Always fill UDP checksums in DHCPv6 replies

Bug #1244589 re-appeared for IPv6.

This change adds an ip6tables rule to fix the checksum of DHCPv6
response packets. Those checksums were left unfilled by virtio (as a
hypervisor internal optimization), but some picky dhcp clients (AFAIU
particularly ISC dhclient) try verifying the checksums, so they fail
to acquire an address if the checksums are left incorrect.

Change-Id: I4a045e0dcfcbd3c7959a78f1460d5bf7da0252ff
Closes-Bug: #1811639
Related-Bug: #1244589
(cherry picked from commit 26eb2509fea632e67ffabcc15195cc13ee02bf68)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/634515/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/common/constants.py', 'neutron/tests/unit/agent/dhcp/test_agent.py', 'neutron/agent/linux/dhcp.py']",3,399f1c1b65b5aad5a810d9986da35d07216fa707,bug/1811639-stable/queens-stable/pike," iptables_mgr = iptables_manager.IptablesManager(use_ipv6=True, ipv6_rule = ('-p udp -m udp --dport %d -j CHECKSUM --checksum-fill' % n_const.DHCPV6_CLIENT_PORT) iptables_mgr.ipv6['mangle'].add_rule('POSTROUTING', ipv6_rule)"," iptables_mgr = iptables_manager.IptablesManager(use_ipv6=False,",20,5
openstack%2Ftempest~master~Ifad293dddb7c7fe76005761b43e1252e40ce7bdc,openstack/tempest,master,Ifad293dddb7c7fe76005761b43e1252e40ce7bdc,Update regions tests to work w/ pre-prov,MERGED,2019-01-07 17:09:53.000000000,2019-02-12 05:31:25.000000000,2019-02-12 05:31:24.000000000,"[{'_account_id': 8556}, {'_account_id': 8911}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 20378}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 23625}, {'_account_id': 27078}]","[{'number': 1, 'created': '2019-01-07 17:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/24c15196f548d07e1ee69f9f3e97e73819836bc3', 'message': ""Move 1 regions test to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for this test:\n\n* test_list_regions_filter_by_parent_region_id\n\nNote that this test is not an interop test [0] so can\nbe safely moved.\n\nBy setting force_tenant_isolation=False this test can now\nbe executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nThe following tests are interop tests [0] and because of\nthat are not moved:\n\n* test_create_region_with_specific_id\n* test_create_update_get_delete_region\n* test_list_regions\n\n[0] http://codesearch.openstack.org/?q=test_regions&i=nope&files=&repos=interop\n\nChange-Id: Ifad293dddb7c7fe76005761b43e1252e40ce7bdc\n""}, {'number': 2, 'created': '2019-01-14 15:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/24b2e2fc8f9695bf1d4b2f784039d38ab43bf5a5', 'message': ""Update regions tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for this test:\n\n* test_list_regions_filter_by_parent_region_id\n* test_create_region_with_specific_id\n* test_create_update_get_delete_region\n* test_list_regions\n\nBy setting force_tenant_isolation=False this test can now\nbe executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nChange-Id: Ifad293dddb7c7fe76005761b43e1252e40ce7bdc\n""}, {'number': 3, 'created': '2019-02-08 19:48:35.000000000', 'files': ['tempest/api/identity/admin/v3/test_regions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e4c8a6a4a7e05e6fa10e9829a2505d138c7b1e1d', 'message': ""Update regions tests to work w/ pre-prov\n\nI don't see any limitations by using pre-provisioned\ncredentials for this test:\n\n* test_list_regions_filter_by_parent_region_id\n* test_create_region_with_specific_id\n* test_create_update_get_delete_region\n* test_list_regions\n\nBy setting force_tenant_isolation=False this test can now\nbe executed with backends that don't allow user creation\n(immutable user source) like LDAP.\n\nChange-Id: Ifad293dddb7c7fe76005761b43e1252e40ce7bdc\n""}]",7,629017,e4c8a6a4a7e05e6fa10e9829a2505d138c7b1e1d,59,10,3,20378,,,0,"Update regions tests to work w/ pre-prov

I don't see any limitations by using pre-provisioned
credentials for this test:

* test_list_regions_filter_by_parent_region_id
* test_create_region_with_specific_id
* test_create_update_get_delete_region
* test_list_regions

By setting force_tenant_isolation=False this test can now
be executed with backends that don't allow user creation
(immutable user source) like LDAP.

Change-Id: Ifad293dddb7c7fe76005761b43e1252e40ce7bdc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/17/629017/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/identity/admin/v3/test_regions.py'],1,24c15196f548d07e1ee69f9f3e97e73819836bc3,bug/1714277,"class BaseRegionsTestJSON(base.BaseIdentityV3AdminTest): super(BaseRegionsTestJSON, cls).setup_clients() super(BaseRegionsTestJSON, cls).resource_setup() class RegionsTestJSON(BaseRegionsTestJSON): class RegionsStaticTestJSON(BaseRegionsTestJSON): # NOTE: force_tenant_isolation is true in the base class by default but # overridden to false here to allow test execution for clouds using the # pre-provisioned credentials provider. force_tenant_isolation = False ","class RegionsTestJSON(base.BaseIdentityV3AdminTest): super(RegionsTestJSON, cls).setup_clients() super(RegionsTestJSON, cls).resource_setup()",13,3
openstack%2Ffuel-octane~master~Ia785e69029a91a0fcd86122fc7198b255405f681,openstack/fuel-octane,master,Ia785e69029a91a0fcd86122fc7198b255405f681,Remove support for py34,ABANDONED,2018-12-19 16:21:11.000000000,2019-02-12 05:24:23.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:21:11.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/28edea98697f36d320b70b21452455271629a4bf', 'message': 'Remove support for py34\n\nChange-Id: Ia785e69029a91a0fcd86122fc7198b255405f681\n'}]",0,626271,28edea98697f36d320b70b21452455271629a4bf,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ia785e69029a91a0fcd86122fc7198b255405f681
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/71/626271/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,28edea98697f36d320b70b21452455271629a4bf,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ffuel-dev-tools~master~Iccc0c3982eed4f6523d394a4547046a0a502999e,openstack/fuel-dev-tools,master,Iccc0c3982eed4f6523d394a4547046a0a502999e,Remove support for py34,ABANDONED,2018-12-19 16:20:21.000000000,2019-02-12 05:24:18.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:20:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-dev-tools/commit/f4780145021b5cd377ed118a1af57df1f47345ce', 'message': 'Remove support for py34\n\nChange-Id: Iccc0c3982eed4f6523d394a4547046a0a502999e\n'}]",0,626260,f4780145021b5cd377ed118a1af57df1f47345ce,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Iccc0c3982eed4f6523d394a4547046a0a502999e
",git fetch https://review.opendev.org/openstack/fuel-dev-tools refs/changes/60/626260/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f4780145021b5cd377ed118a1af57df1f47345ce,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fsecurity-analysis~master~Ia1e0f22a3da31302c60ee9bc53c16eace32c89d2,openstack/security-analysis,master,Ia1e0f22a3da31302c60ee9bc53c16eace32c89d2,Remove support for py34,ABANDONED,2018-12-19 16:23:10.000000000,2019-02-12 05:24:01.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:23:10.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/security-analysis/commit/e18ea1c8435c13a75924280cd60d93277db483b1', 'message': 'Remove support for py34\n\nChange-Id: Ia1e0f22a3da31302c60ee9bc53c16eace32c89d2\n'}]",0,626328,e18ea1c8435c13a75924280cd60d93277db483b1,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ia1e0f22a3da31302c60ee9bc53c16eace32c89d2
",git fetch https://review.opendev.org/openstack/security-analysis refs/changes/28/626328/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,e18ea1c8435c13a75924280cd60d93277db483b1,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fopenstack-helm-images~master~I465c6c46eaa208f706fcca1f7a84d5152ef70d49,openstack/openstack-helm-images,master,I465c6c46eaa208f706fcca1f7a84d5152ef70d49,Update the Ubuntu to 18.04,ABANDONED,2018-12-19 15:21:52.000000000,2019-02-12 05:23:56.000000000,,"[{'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 29268}]","[{'number': 1, 'created': '2018-12-19 15:21:52.000000000', 'files': ['tempest/Dockerfile.ubuntu_xenial'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/bb1b045ca17e2f7c94974291bd925f2b74cc6459', 'message': 'Update the Ubuntu to 18.04\n\nrefer to docs of images, the ubuntu should be 18.04[1]\n\n[1]: https://docs.openstack.org/openstack-helm-images/latest/\n\nChange-Id: I465c6c46eaa208f706fcca1f7a84d5152ef70d49\n'}]",0,626209,bb1b045ca17e2f7c94974291bd925f2b74cc6459,5,3,1,28614,,,0,"Update the Ubuntu to 18.04

refer to docs of images, the ubuntu should be 18.04[1]

[1]: https://docs.openstack.org/openstack-helm-images/latest/

Change-Id: I465c6c46eaa208f706fcca1f7a84d5152ef70d49
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/09/626209/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/Dockerfile.ubuntu_xenial'],1,bb1b045ca17e2f7c94974291bd925f2b74cc6459,,FROM ubuntu:18.04,FROM ubuntu:16.04,1,1
openstack%2Fdeb-python-positional~master~I74ffe5e05c9c5c55c98fb959fdd967f75242a826,openstack/deb-python-positional,master,I74ffe5e05c9c5c55c98fb959fdd967f75242a826,Remove support for py34,ABANDONED,2018-12-19 16:19:37.000000000,2019-02-12 05:22:51.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:19:37.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-positional/commit/10b6b137561960b616524d0fbc220d37cac8f0e9', 'message': 'Remove support for py34\n\nChange-Id: I74ffe5e05c9c5c55c98fb959fdd967f75242a826\n'}]",0,626251,10b6b137561960b616524d0fbc220d37cac8f0e9,2,0,1,28614,,,0,"Remove support for py34

Change-Id: I74ffe5e05c9c5c55c98fb959fdd967f75242a826
",git fetch https://review.opendev.org/openstack/deb-python-positional refs/changes/51/626251/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,10b6b137561960b616524d0fbc220d37cac8f0e9,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-python-requests-unixsocket~master~I0dd7a937b4c5a7191028b943d39b2c99b1b05d16,openstack/deb-python-requests-unixsocket,master,I0dd7a937b4c5a7191028b943d39b2c99b1b05d16,Remove support for py34,ABANDONED,2018-12-19 16:19:55.000000000,2019-02-12 05:22:47.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:19:55.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-requests-unixsocket/commit/f6cb7aeaafb9dfda9db8e62372938623c098f667', 'message': 'Remove support for py34\n\nChange-Id: I0dd7a937b4c5a7191028b943d39b2c99b1b05d16\n'}]",0,626252,f6cb7aeaafb9dfda9db8e62372938623c098f667,2,0,1,28614,,,0,"Remove support for py34

Change-Id: I0dd7a937b4c5a7191028b943d39b2c99b1b05d16
",git fetch https://review.opendev.org/openstack/deb-python-requests-unixsocket refs/changes/52/626252/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f6cb7aeaafb9dfda9db8e62372938623c098f667,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-python-traceback2~master~I83b72b853ac7501b836f4c746d6cba829067fb8b,openstack/deb-python-traceback2,master,I83b72b853ac7501b836f4c746d6cba829067fb8b,Remove support for py34,ABANDONED,2018-12-19 16:20:04.000000000,2019-02-12 05:22:44.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:20:04.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-traceback2/commit/5d244e2b2d06f022027e7f873b1ff1d188c7e704', 'message': 'Remove support for py34\n\nChange-Id: I83b72b853ac7501b836f4c746d6cba829067fb8b\n'}]",0,626253,5d244e2b2d06f022027e7f873b1ff1d188c7e704,2,0,1,28614,,,0,"Remove support for py34

Change-Id: I83b72b853ac7501b836f4c746d6cba829067fb8b
",git fetch https://review.opendev.org/openstack/deb-python-traceback2 refs/changes/53/626253/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5d244e2b2d06f022027e7f873b1ff1d188c7e704,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-ryu~master~I8a702bc2af3ee30c202d94b4134b3b7a7e902256,openstack/deb-ryu,master,I8a702bc2af3ee30c202d94b4134b3b7a7e902256,Remove support for py34,ABANDONED,2018-12-19 16:20:08.000000000,2019-02-12 05:22:41.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:20:08.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-ryu/commit/3ead65f00a481439a7813644648926995461d41b', 'message': 'Remove support for py34\n\nChange-Id: I8a702bc2af3ee30c202d94b4134b3b7a7e902256\n'}]",0,626255,3ead65f00a481439a7813644648926995461d41b,2,0,1,28614,,,0,"Remove support for py34

Change-Id: I8a702bc2af3ee30c202d94b4134b3b7a7e902256
",git fetch https://review.opendev.org/openstack/deb-ryu refs/changes/55/626255/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,3ead65f00a481439a7813644648926995461d41b,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fcastellan-ui~master~Ia0f35d3e8bec300260abc05a0d3ae9b3e9c79f26,openstack/castellan-ui,master,Ia0f35d3e8bec300260abc05a0d3ae9b3e9c79f26,Remove support for py34,ABANDONED,2018-12-19 16:18:08.000000000,2019-02-12 05:22:29.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:18:08.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/castellan-ui/commit/c307d088c7fc4aae860950d691fd775160e8ef1c', 'message': 'Remove support for py34\n\nChange-Id: Ia0f35d3e8bec300260abc05a0d3ae9b3e9c79f26\n'}]",0,626237,c307d088c7fc4aae860950d691fd775160e8ef1c,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ia0f35d3e8bec300260abc05a0d3ae9b3e9c79f26
",git fetch https://review.opendev.org/openstack/castellan-ui refs/changes/37/626237/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,c307d088c7fc4aae860950d691fd775160e8ef1c,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ffuel-nailgun-extension-cluster-upgrade~master~Ie3812ae3fa0a6340331881eb372c9ee9358f438c,openstack/fuel-nailgun-extension-cluster-upgrade,master,Ie3812ae3fa0a6340331881eb372c9ee9358f438c,Remove support for py34,ABANDONED,2018-12-19 16:20:26.000000000,2019-02-12 05:22:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:20:26.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade/commit/bada1818374b66e126f120129426687c4599e53e', 'message': 'Remove support for py34\n\nChange-Id: Ie3812ae3fa0a6340331881eb372c9ee9358f438c\n'}]",0,626263,bada1818374b66e126f120129426687c4599e53e,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ie3812ae3fa0a6340331881eb372c9ee9358f438c
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-cluster-upgrade refs/changes/63/626263/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bada1818374b66e126f120129426687c4599e53e,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-python-linecache2~master~Ia52dbc4ef1dcad4821a2bd3f845bf9806989266c,openstack/deb-python-linecache2,master,Ia52dbc4ef1dcad4821a2bd3f845bf9806989266c,Remove support for py34,ABANDONED,2018-12-19 16:19:27.000000000,2019-02-12 05:22:19.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:19:27.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-linecache2/commit/44bf17250f7fe41332d69b740c44d99786982819', 'message': 'Remove support for py34\n\nChange-Id: Ia52dbc4ef1dcad4821a2bd3f845bf9806989266c\n'}]",0,626250,44bf17250f7fe41332d69b740c44d99786982819,2,0,1,28614,,,0,"Remove support for py34

Change-Id: Ia52dbc4ef1dcad4821a2bd3f845bf9806989266c
",git fetch https://review.opendev.org/openstack/deb-python-linecache2 refs/changes/50/626250/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,44bf17250f7fe41332d69b740c44d99786982819,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-python-gabbi~master~Ic08f163ee4dede012230d301b5f4b737db2d8535,openstack/deb-python-gabbi,master,Ic08f163ee4dede012230d301b5f4b737db2d8535,Remove support for py34,ABANDONED,2018-12-19 16:19:21.000000000,2019-02-12 05:22:15.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:19:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-gabbi/commit/6739b02ecd6cceaacc0922827f74ec060bbe3c40', 'message': 'Remove support for py34\n\nChange-Id: Ic08f163ee4dede012230d301b5f4b737db2d8535\n'}]",0,626249,6739b02ecd6cceaacc0922827f74ec060bbe3c40,2,0,1,28614,,,0,"Remove support for py34

Change-Id: Ic08f163ee4dede012230d301b5f4b737db2d8535
",git fetch https://review.opendev.org/openstack/deb-python-gabbi refs/changes/49/626249/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6739b02ecd6cceaacc0922827f74ec060bbe3c40,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fdeb-python-cotyledon~master~Ie287a2b502da000ad3ae03f5fd45361f70d10938,openstack/deb-python-cotyledon,master,Ie287a2b502da000ad3ae03f5fd45361f70d10938,Remove support for py34,ABANDONED,2018-12-19 16:18:58.000000000,2019-02-12 05:22:12.000000000,,[],"[{'number': 1, 'created': '2018-12-19 16:18:58.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/deb-python-cotyledon/commit/577dd5e31afdfca85a00acb84ed1df2c27d1e939', 'message': 'Remove support for py34\n\nChange-Id: Ie287a2b502da000ad3ae03f5fd45361f70d10938\n'}]",0,626248,577dd5e31afdfca85a00acb84ed1df2c27d1e939,2,0,1,28614,,,0,"Remove support for py34

Change-Id: Ie287a2b502da000ad3ae03f5fd45361f70d10938
",git fetch https://review.opendev.org/openstack/deb-python-cotyledon refs/changes/48/626248/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,577dd5e31afdfca85a00acb84ed1df2c27d1e939,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fmagnum~master~Ic33e0f47a4d6e88680d92179e240af3bd98deff7,openstack/magnum,master,Ic33e0f47a4d6e88680d92179e240af3bd98deff7,Pin get-pip.py to 3.2,ABANDONED,2018-07-05 15:40:05.000000000,2019-02-12 05:22:07.000000000,,"[{'_account_id': 11869}, {'_account_id': 17068}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27781}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-07-05 15:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fbea91e08782b9b8af3b04cd06bde1c7ba55aebc', 'message': ""Pin get-pip.py to 3.2\n\nAs get-pip.py evolves based on pip 10, while we're still using\npip 9, changes in the way it can be used are causing problems.\n\nFor example, the ability to use --download is no longer there.\n\nAs such, let's pin to a known good version and leave it at that\nuntil we no longer need to use this script. Version 3.2 maps to\npip 7.1.2 which fulfills our needs.\n\nChange-Id: Ic33e0f47a4d6e88680d92179e240af3bd98deff7\n""}, {'number': 2, 'created': '2018-08-15 04:02:06.000000000', 'files': ['doc/source/contributor/quickstart.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/e5763b49ed08749ff1f6e87c9733f053000897d8', 'message': ""Pin get-pip.py to 3.2\n\nAs get-pip.py evolves based on pip 10, while we're still using\npip 9, changes in the way it can be used are causing problems.\n\nFor example, the ability to use --download is no longer there.\n\nAs such, let's pin to a known good version and leave it at that\nuntil we no longer need to use this script. Version 3.2 maps to\npip 7.1.2 which fulfills our needs.\n\nChange-Id: Ic33e0f47a4d6e88680d92179e240af3bd98deff7\n""}]",0,580424,e5763b49ed08749ff1f6e87c9733f053000897d8,13,7,2,28614,,,0,"Pin get-pip.py to 3.2

As get-pip.py evolves based on pip 10, while we're still using
pip 9, changes in the way it can be used are causing problems.

For example, the ability to use --download is no longer there.

As such, let's pin to a known good version and leave it at that
until we no longer need to use this script. Version 3.2 maps to
pip 7.1.2 which fulfills our needs.

Change-Id: Ic33e0f47a4d6e88680d92179e240af3bd98deff7
",git fetch https://review.opendev.org/openstack/magnum refs/changes/24/580424/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/quickstart.rst'],1,fbea91e08782b9b8af3b04cd06bde1c7ba55aebc,, curl -s https://bootstrap.pypa.io/3.2/get-pip.py | sudo python, curl -s https://bootstrap.pypa.io/get-pip.py | sudo python,1,1
openstack%2Fkolla~master~I5936a1f3a2e104ff214da564cdecf422bbd031d4,openstack/kolla,master,I5936a1f3a2e104ff214da564cdecf422bbd031d4,Remove the duplicated pip installation,ABANDONED,2018-07-05 16:29:03.000000000,2019-02-12 05:22:03.000000000,,"[{'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 19853}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-07-05 16:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/10b9967ab4f2e7e8d3240ec41f5ba8deffa7be02', 'message': 'Remove the duplicated pip installation\n\nAll images is built from base, and the pip is installed in base[0],\nso it is duplicated for the other images install[1], this ps to\nremove the duplicated installation.\n\nCo-Authored-By: chenqiaomin <chen.qiaomin@99cloud.net>\n[0]: https://github.com/openstack/kolla/blob/master/docker/base/Dockerfile.j2#L428\n[1]: https://github.com/openstack/kolla/blob/master/docker/kolla-toolbox/Dockerfile.j2#L66\n\nChange-Id: I5936a1f3a2e104ff214da564cdecf422bbd031d4\n'}, {'number': 2, 'created': '2018-07-07 05:24:45.000000000', 'files': ['docker/openstack-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2a9355b4c19822ded800d685604ac7a506fd9b8c', 'message': 'Remove the duplicated pip installation\n\nAll images is built from base, and the pip is installed in base[0],\nso it is duplicated for the other images install[1], this ps to\nremove the duplicated installation.\n\nCo-Authored-By: chenqiaomin <chen.qiaomin@99cloud.net>\n[0]: https://github.com/openstack/kolla/blob/master/docker/base/Dockerfile.j2#L428\n[1]: https://github.com/openstack/kolla/blob/master/docker/kolla-toolbox/Dockerfile.j2#L66\n\nChange-Id: I5936a1f3a2e104ff214da564cdecf422bbd031d4\n'}]",2,580442,2a9355b4c19822ded800d685604ac7a506fd9b8c,10,5,2,28614,,,0,"Remove the duplicated pip installation

All images is built from base, and the pip is installed in base[0],
so it is duplicated for the other images install[1], this ps to
remove the duplicated installation.

Co-Authored-By: chenqiaomin <chen.qiaomin@99cloud.net>
[0]: https://github.com/openstack/kolla/blob/master/docker/base/Dockerfile.j2#L428
[1]: https://github.com/openstack/kolla/blob/master/docker/kolla-toolbox/Dockerfile.j2#L66

Change-Id: I5936a1f3a2e104ff214da564cdecf422bbd031d4
",git fetch https://review.opendev.org/openstack/kolla refs/changes/42/580442/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/helm-repository/Dockerfile.j2', 'docker/openstack-base/Dockerfile.j2', 'docker/kolla-toolbox/Dockerfile.j2']",3,10b9967ab4f2e7e8d3240ec41f5ba8deffa7be02,,,{% block kolla_toolbox_source_install_python_pip %} RUN curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py \ && python get-pip.py \ && rm get-pip.py {% endblock %} ,0,18
openstack%2Fopenstack-ansible-os_congress~stable%2Frocky~I78f42ff0be7b7e703bf5d76f88b9f2f0a09c79a0,openstack/openstack-ansible-os_congress,stable/rocky,I78f42ff0be7b7e703bf5d76f88b9f2f0a09c79a0,Fix the wrong home-page,ABANDONED,2018-11-13 13:51:31.000000000,2019-02-12 05:21:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-11-13 13:51:31.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_congress/commit/a4ae68ee0413cb846d95d7cd6c634c889256c00f', 'message': 'Fix the wrong home-page\n\nChange-Id: I78f42ff0be7b7e703bf5d76f88b9f2f0a09c79a0\nCloses-Bug: #1792861\n(cherry picked from commit 084519034c66c30e5b0580e766300e7231daa08d)\n'}]",0,617657,a4ae68ee0413cb846d95d7cd6c634c889256c00f,3,1,1,28614,,,0,"Fix the wrong home-page

Change-Id: I78f42ff0be7b7e703bf5d76f88b9f2f0a09c79a0
Closes-Bug: #1792861
(cherry picked from commit 084519034c66c30e5b0580e766300e7231daa08d)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_congress refs/changes/57/617657/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a4ae68ee0413cb846d95d7cd6c634c889256c00f,bug/1792861-stable/rocky,home-page = https://docs.openstack.org/openstack-ansible-os_congress/latest/universal = 1 ,home-page = https://docs.openstack.org/openstack-ansible-os_neutron/latest/universal = 1,2,2
openstack%2Fopenstack-ansible-os_tacker~stable%2Frocky~Idf922c4e7d921dc1cb2d89becdd083a0d1925a76,openstack/openstack-ansible-os_tacker,stable/rocky,Idf922c4e7d921dc1cb2d89becdd083a0d1925a76,Fix the wrong home-page,ABANDONED,2018-11-13 13:51:24.000000000,2019-02-12 05:21:55.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-11-13 13:51:24.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tacker/commit/803b757044f76259763117a788debf82029d2151', 'message': 'Fix the wrong home-page\n\nChange-Id: Idf922c4e7d921dc1cb2d89becdd083a0d1925a76\nCloses-Bug: #1792861\n(cherry picked from commit 1362769261134367a014bb78b0154f721a23c076)\n'}]",0,617656,803b757044f76259763117a788debf82029d2151,3,1,1,28614,,,0,"Fix the wrong home-page

Change-Id: Idf922c4e7d921dc1cb2d89becdd083a0d1925a76
Closes-Bug: #1792861
(cherry picked from commit 1362769261134367a014bb78b0154f721a23c076)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tacker refs/changes/56/617656/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,803b757044f76259763117a788debf82029d2151,bug/1792861-stable/rocky,home-page = https://docs.openstack.org/openstack-ansible-os_tacker/latest/,home-page = https://docs.openstack.org/openstack-ansible-os_neutron/latest/,1,1
openstack%2Fopenstack-ansible-rsyslog_client~stable%2Focata~I5fbd000bbc3f8584ef937dbe9cc6daa7e94fe568,openstack/openstack-ansible-rsyslog_client,stable/ocata,I5fbd000bbc3f8584ef937dbe9cc6daa7e94fe568,Replace Chinese punctuation with English punctuation,ABANDONED,2019-01-14 13:17:02.000000000,2019-02-12 05:19:45.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-14 13:17:02.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/a7954f19da868831a665313f66d73759b5b0d4c1', 'message': 'Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input\nmethod. When read from english context, it makes some confusion.\n\nChange-Id: I5fbd000bbc3f8584ef937dbe9cc6daa7e94fe568\nCloses-Bug: #1792131\n(cherry picked from commit 7d9e2ed01913d38676a822331f08dcd724223932)\n'}]",0,630666,a7954f19da868831a665313f66d73759b5b0d4c1,3,1,1,28614,,,0,"Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input
method. When read from english context, it makes some confusion.

Change-Id: I5fbd000bbc3f8584ef937dbe9cc6daa7e94fe568
Closes-Bug: #1792131
(cherry picked from commit 7d9e2ed01913d38676a822331f08dcd724223932)
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/66/630666/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,a7954f19da868831a665313f66d73759b5b0d4c1,, the 'backport potential' tag TO THE ISSUE (not the PR)., the backport potential tag TO THE ISSUE (not the PR).,1,1
openstack%2Fopenstack-ansible-os_heat~stable%2Focata~I240b0e01ee3cc5824d5f3c6a90be21c8e7a5e34d,openstack/openstack-ansible-os_heat,stable/ocata,I240b0e01ee3cc5824d5f3c6a90be21c8e7a5e34d,Replace Chinese punctuation with English punctuation,ABANDONED,2019-01-14 13:17:50.000000000,2019-02-12 05:19:42.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-14 13:17:50.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/78ce24307d8ffcb84d69e510f8ae3182059de325', 'message': 'Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input\nmethod. When read from english context, it makes some confusion.\n\nChange-Id: I240b0e01ee3cc5824d5f3c6a90be21c8e7a5e34d\nCloses-Bug: #1792131\n(cherry picked from commit 1c05785cea9de839cb3fb60a61f36d9a3115de5c)\n'}]",0,630668,78ce24307d8ffcb84d69e510f8ae3182059de325,3,1,1,28614,,,0,"Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input
method. When read from english context, it makes some confusion.

Change-Id: I240b0e01ee3cc5824d5f3c6a90be21c8e7a5e34d
Closes-Bug: #1792131
(cherry picked from commit 1c05785cea9de839cb3fb60a61f36d9a3115de5c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/68/630668/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,78ce24307d8ffcb84d69e510f8ae3182059de325,, add the 'backport potential' tag TO THE ISSUE (not the PR)., add the backport potential tag TO THE ISSUE (not the PR).,1,1
openstack%2Fopenstack-ansible-ceph_client~stable%2Focata~Ibddb45adf164c47ed848a3aab5f2ae40d4021eac,openstack/openstack-ansible-ceph_client,stable/ocata,Ibddb45adf164c47ed848a3aab5f2ae40d4021eac,Replace Chinese punctuation with English punctuation,ABANDONED,2019-01-14 13:17:17.000000000,2019-02-12 05:19:38.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-01-14 13:17:17.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/1ce0e8c66c90a48e5b16abfdc124886d74a75bec', 'message': 'Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input\nmethod. When read from english context, it makes some confusion.\n\nChange-Id: Ibddb45adf164c47ed848a3aab5f2ae40d4021eac\nCloses-Bug: #1792131\n(cherry picked from commit d285fe6602fe6b43e1dd939e96fb5677aa2ce88c)\n'}]",0,630667,1ce0e8c66c90a48e5b16abfdc124886d74a75bec,3,1,1,28614,,,0,"Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input
method. When read from english context, it makes some confusion.

Change-Id: Ibddb45adf164c47ed848a3aab5f2ae40d4021eac
Closes-Bug: #1792131
(cherry picked from commit d285fe6602fe6b43e1dd939e96fb5677aa2ce88c)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/67/630667/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,1ce0e8c66c90a48e5b16abfdc124886d74a75bec,, add the 'backport potential' tag TO THE ISSUE (not the PR)., add the backport potential tag TO THE ISSUE (not the PR).,1,1
openstack%2Fi18n~master~Iea2507e27820e0bc3d4e6c48e19238f118dfd550,openstack/i18n,master,Iea2507e27820e0bc3d4e6c48e19238f118dfd550,Remove support for py34,ABANDONED,2018-12-19 16:21:12.000000000,2019-02-12 05:19:24.000000000,,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-19 16:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/17030b92aba85ea42ed228fa22d2879c76552c58', 'message': 'Remove support for py34\n\nChange-Id: Iea2507e27820e0bc3d4e6c48e19238f118dfd550\n'}, {'number': 2, 'created': '2018-12-27 09:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/i18n/commit/3d8d039fee13c74b0f03370af52474b00f2ae4c7', 'message': 'Remove support for py34\n\nChange-Id: Iea2507e27820e0bc3d4e6c48e19238f118dfd550\n'}, {'number': 3, 'created': '2018-12-28 08:21:19.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/i18n/commit/c0cfa4ff98c52bd5947cacef94f879097082e0e7', 'message': 'Remove support for py34\n\nChange-Id: Iea2507e27820e0bc3d4e6c48e19238f118dfd550\n'}]",1,626272,c0cfa4ff98c52bd5947cacef94f879097082e0e7,12,2,3,28614,,,0,"Remove support for py34

Change-Id: Iea2507e27820e0bc3d4e6c48e19238f118dfd550
",git fetch https://review.opendev.org/openstack/i18n refs/changes/72/626272/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,17030b92aba85ea42ed228fa22d2879c76552c58,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fopenstackclient~master~Ibc43b73d345d355d8f4165633f428be20766788b,openstack/openstackclient,master,Ibc43b73d345d355d8f4165633f428be20766788b,Remove support for py34,ABANDONED,2018-12-19 16:22:06.000000000,2019-02-12 05:19:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:22:06.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstackclient/commit/9f1a48250555448f087aa21c268ecc1a0e7783f9', 'message': 'Remove support for py34\n\nChange-Id: Ibc43b73d345d355d8f4165633f428be20766788b\n'}]",0,626299,9f1a48250555448f087aa21c268ecc1a0e7783f9,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ibc43b73d345d355d8f4165633f428be20766788b
",git fetch https://review.opendev.org/openstack/openstackclient refs/changes/99/626299/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9f1a48250555448f087aa21c268ecc1a0e7783f9,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fproject-config~master~I289cd7eab16bf91770aeeee439858e66c09306ad,openstack/project-config,master,I289cd7eab16bf91770aeeee439858e66c09306ad,[rally] Remove readthedocs jobs,MERGED,2018-11-06 13:21:24.000000000,2019-02-12 05:19:13.000000000,2019-02-12 05:19:13.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-06 13:21:24.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4eeee8b4996f7bf9ed8c9371f04bdb4566995b56', 'message': '[rally] Remove readthedocs jobs\n\nIt is easier to fix rtd job locally\n(Attempt: https://review.openstack.org/#/c/615820/ )\n\nChange-Id: I289cd7eab16bf91770aeeee439858e66c09306ad\n'}]",0,615868,4eeee8b4996f7bf9ed8c9371f04bdb4566995b56,11,4,1,9545,,,0,"[rally] Remove readthedocs jobs

It is easier to fix rtd job locally
(Attempt: https://review.openstack.org/#/c/615820/ )

Change-Id: I289cd7eab16bf91770aeeee439858e66c09306ad
",git fetch https://review.opendev.org/openstack/project-config refs/changes/68/615868/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,4eeee8b4996f7bf9ed8c9371f04bdb4566995b56,rally_rtd,, # Revert to docs-on-readthedocs when fixed - docs-on-readthedocs-failing,0,2
openstack%2Fpython-fuelclient~master~I1dc4cc24c4ae0212f7b3f17b6d8d247b941702b2,openstack/python-fuelclient,master,I1dc4cc24c4ae0212f7b3f17b6d8d247b941702b2,Remove support for py34,ABANDONED,2018-12-19 16:22:33.000000000,2019-02-12 05:19:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:22:33.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/2579eea92a9607b6fae83e82e4f79fe3395d1c9a', 'message': 'Remove support for py34\n\nChange-Id: I1dc4cc24c4ae0212f7b3f17b6d8d247b941702b2\n'}]",0,626313,2579eea92a9607b6fae83e82e4f79fe3395d1c9a,3,1,1,28614,,,0,"Remove support for py34

Change-Id: I1dc4cc24c4ae0212f7b3f17b6d8d247b941702b2
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/13/626313/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,2579eea92a9607b6fae83e82e4f79fe3395d1c9a,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fheat-dashboard~master~I33cf013ab95be5b2053b193d38436bf8b3c0135b,openstack/heat-dashboard,master,I33cf013ab95be5b2053b193d38436bf8b3c0135b,Remove support for py34,ABANDONED,2018-12-19 16:20:42.000000000,2019-02-12 05:19:06.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:20:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/80716f396cf8bcfb807f61425809c225d586447f', 'message': 'Remove support for py34\n\nChange-Id: I33cf013ab95be5b2053b193d38436bf8b3c0135b\n'}]",0,626266,80716f396cf8bcfb807f61425809c225d586447f,3,1,1,28614,,,0,"Remove support for py34

Change-Id: I33cf013ab95be5b2053b193d38436bf8b3c0135b
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/66/626266/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,80716f396cf8bcfb807f61425809c225d586447f,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fopenstack-ux~master~I81d2766533b7611671526496295b13ac5f550098,openstack/openstack-ux,master,I81d2766533b7611671526496295b13ac5f550098,Remove support for py34,ABANDONED,2018-12-19 16:22:14.000000000,2019-02-12 05:18:58.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:22:14.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstack-ux/commit/a51679029c5ba63036cb9fe8388849f68b93d5cc', 'message': 'Remove support for py34\n\nChange-Id: I81d2766533b7611671526496295b13ac5f550098\n'}]",0,626303,a51679029c5ba63036cb9fe8388849f68b93d5cc,3,1,1,28614,,,0,"Remove support for py34

Change-Id: I81d2766533b7611671526496295b13ac5f550098
",git fetch https://review.opendev.org/openstack/openstack-ux refs/changes/03/626303/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a51679029c5ba63036cb9fe8388849f68b93d5cc,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fworkload-ref-archs~master~Ic79471c7f5ffeb8ac378eac8b08e2e892c425d7e,openstack/workload-ref-archs,master,Ic79471c7f5ffeb8ac378eac8b08e2e892c425d7e,Remove support for py34,ABANDONED,2018-12-19 16:24:12.000000000,2019-02-12 05:18:50.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:24:12.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/workload-ref-archs/commit/08291ec1b94c6bc3e9c2c63d753f13c84cabf81e', 'message': 'Remove support for py34\n\nChange-Id: Ic79471c7f5ffeb8ac378eac8b08e2e892c425d7e\n'}]",0,626350,08291ec1b94c6bc3e9c2c63d753f13c84cabf81e,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ic79471c7f5ffeb8ac378eac8b08e2e892c425d7e
",git fetch https://review.opendev.org/openstack/workload-ref-archs refs/changes/50/626350/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,08291ec1b94c6bc3e9c2c63d753f13c84cabf81e,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fqinling-dashboard~master~If3d78c26be65dc86afb77ab407b61607c42f7c56,openstack/qinling-dashboard,master,If3d78c26be65dc86afb77ab407b61607c42f7c56,Remove support for py34,ABANDONED,2018-12-19 16:22:57.000000000,2019-02-12 05:17:34.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:22:57.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/qinling-dashboard/commit/4015902d8ba3f3f4b5f79ffa4b564541adf907fd', 'message': 'Remove support for py34\n\nChange-Id: If3d78c26be65dc86afb77ab407b61607c42f7c56\n'}]",0,626324,4015902d8ba3f3f4b5f79ffa4b564541adf907fd,3,1,1,28614,,,0,"Remove support for py34

Change-Id: If3d78c26be65dc86afb77ab407b61607c42f7c56
",git fetch https://review.opendev.org/openstack/qinling-dashboard refs/changes/24/626324/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,4015902d8ba3f3f4b5f79ffa4b564541adf907fd,,, Programming Language :: Python :: 3.4,0,1
openstack%2Foslo.upgradecheck~master~I4369080250c74717e09ae855492f164bd5117cd4,openstack/oslo.upgradecheck,master,I4369080250c74717e09ae855492f164bd5117cd4,update the tox minversion to 2.0,ABANDONED,2018-12-19 16:23:01.000000000,2019-02-12 05:17:21.000000000,,"[{'_account_id': 6928}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-19 16:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/7c29b3edf20cf96bbdaae39472fbcee93ae451c3', 'message': 'test\n\nChange-Id: I4369080250c74717e09ae855492f164bd5117cd4\n'}, {'number': 2, 'created': '2018-12-19 16:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/662ac68cd1ab1fe50b5293b1f7ffa130044a3a1f', 'message': 'update the tox minversion to 2.0\n \nChange-Id: I4369080250c74717e09ae855492f164bd5117cd4\n'}, {'number': 3, 'created': '2018-12-19 16:34:37.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.upgradecheck/commit/6d58ca6b5acfed09956a4cea41af4940000fdd96', 'message': 'update the tox minversion to 2.0\n\nChange-Id: I4369080250c74717e09ae855492f164bd5117cd4\n'}]",1,626325,6d58ca6b5acfed09956a4cea41af4940000fdd96,6,2,3,28614,,,0,"update the tox minversion to 2.0

Change-Id: I4369080250c74717e09ae855492f164bd5117cd4
",git fetch https://review.opendev.org/openstack/oslo.upgradecheck refs/changes/25/626325/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,7c29b3edf20cf96bbdaae39472fbcee93ae451c3,,minversion = 2.0 ,minversion = 1.8,1,1
openstack%2Ftrove-dashboard~master~I49c439be8028841e397d0e3279207a7236f170db,openstack/trove-dashboard,master,I49c439be8028841e397d0e3279207a7236f170db,Remove support for py34,ABANDONED,2018-12-19 16:23:54.000000000,2019-02-12 05:17:17.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:23:54.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove-dashboard/commit/fc7496153f4252776d835aee28a085b30c4510d9', 'message': 'Remove support for py34\n\nChange-Id: I49c439be8028841e397d0e3279207a7236f170db\n'}]",0,626344,fc7496153f4252776d835aee28a085b30c4510d9,3,1,1,28614,,,0,"Remove support for py34

Change-Id: I49c439be8028841e397d0e3279207a7236f170db
",git fetch https://review.opendev.org/openstack/trove-dashboard refs/changes/44/626344/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fc7496153f4252776d835aee28a085b30c4510d9,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ffuel-nailgun-extension-converted-serializers~master~I15ea467ff61ca522775837d39c656cbffafcf820,openstack/fuel-nailgun-extension-converted-serializers,master,I15ea467ff61ca522775837d39c656cbffafcf820,Remove support for py34,ABANDONED,2018-12-19 16:20:23.000000000,2019-02-12 05:17:14.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:20:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-converted-serializers/commit/ebc602ebf820f0a570bd579eba8ae2fa2f673024', 'message': 'Remove support for py34\n\nChange-Id: I15ea467ff61ca522775837d39c656cbffafcf820\n'}, {'number': 2, 'created': '2018-12-19 16:41:29.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-extension-converted-serializers/commit/470ddadce40b4f2db0e13b29859e601c32ce9774', 'message': 'Remove support for py34\n\nChange-Id: I15ea467ff61ca522775837d39c656cbffafcf820\n'}]",0,626262,470ddadce40b4f2db0e13b29859e601c32ce9774,5,1,2,28614,,,0,"Remove support for py34

Change-Id: I15ea467ff61ca522775837d39c656cbffafcf820
",git fetch https://review.opendev.org/openstack/fuel-nailgun-extension-converted-serializers refs/changes/62/626262/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ebc602ebf820f0a570bd579eba8ae2fa2f673024,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ftuning-box~master~I699bbd0d4b3882095d549645f87e407abbfb0232,openstack/tuning-box,master,I699bbd0d4b3882095d549645f87e407abbfb0232,Remove support for py34,ABANDONED,2018-12-19 16:24:00.000000000,2019-02-12 05:13:41.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:24:00.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tuning-box/commit/e27821c3b8fea8bb3a19d1c006788868e63e85db', 'message': 'Remove support for py34\n\nChange-Id: I699bbd0d4b3882095d549645f87e407abbfb0232\n'}]",0,626345,e27821c3b8fea8bb3a19d1c006788868e63e85db,3,1,1,28614,,,0,"Remove support for py34

Change-Id: I699bbd0d4b3882095d549645f87e407abbfb0232
",git fetch https://review.opendev.org/openstack/tuning-box refs/changes/45/626345/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,e27821c3b8fea8bb3a19d1c006788868e63e85db,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fzun~stable%2Frocky~I9e4987aec424bfaa66838662eccd69799351ec37,openstack/zun,stable/rocky,I9e4987aec424bfaa66838662eccd69799351ec37,Add validation on network attach/detach,MERGED,2019-01-31 04:58:32.000000000,2019-02-12 05:13:39.000000000,2019-02-12 05:13:39.000000000,"[{'_account_id': 21428}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-31 04:58:32.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/tests/unit/api/controllers/v1/test_containers.py', 'zun/api/controllers/v1/containers.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/d2459b08ba34009c0a7f7679ed3d38536d3381be', 'message': 'Add validation on network attach/detach\n\nChange-Id: I9e4987aec424bfaa66838662eccd69799351ec37\nRelated-Bug: #1812602\n(cherry picked from commit ced5e9e3d82c68037cc90442f555adcc8c2a5d76)\n'}]",0,634097,d2459b08ba34009c0a7f7679ed3d38536d3381be,6,2,1,11536,,,0,"Add validation on network attach/detach

Change-Id: I9e4987aec424bfaa66838662eccd69799351ec37
Related-Bug: #1812602
(cherry picked from commit ced5e9e3d82c68037cc90442f555adcc8c2a5d76)
",git fetch https://review.opendev.org/openstack/zun refs/changes/97/634097/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/tests/unit/api/controllers/v1/test_containers.py', 'zun/api/controllers/v1/containers.py']",3,d2459b08ba34009c0a7f7679ed3d38536d3381be,bug/1812602-stable/rocky," if (net_id not in container.addresses or port['id'] not in [a['port'] for a in container.addresses[net_id]]): raise exception.Invalid(_( ""Port '%(port)s' is not attached to container "" ""'%(container)s'."") % {""port"": kwargs.get('port'), ""container"": container_ident}) if net_id not in container.addresses: raise exception.Invalid(_( ""Network '%(network)s' is not attached to container "" ""'%(container)s'."") % {""network"": kwargs.get('network'), ""container"": container_ident}) if requested_networks[0]['network'] in container.addresses: if kwargs.get('port'): raise exception.Invalid(_( ""Cannot attach port '%(port)s' to container "" ""'%(container)s' because another port on the "" ""same network is already attached to this container."") % {""port"": kwargs.get('port'), ""container"": container_ident}) else: raise exception.Invalid(_( ""Network '%(network)s' is already connected to "" ""container '%(container)s'."") % {""network"": kwargs.get('network'), ""container"": container_ident})",,40,6
openstack%2Fzaqar-tempest-plugin~master~Idbfdc8c07a67edc59f298a7379314f0c4b26b529,openstack/zaqar-tempest-plugin,master,Idbfdc8c07a67edc59f298a7379314f0c4b26b529,Remove support for py34,ABANDONED,2018-12-19 16:24:25.000000000,2019-02-12 05:13:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:24:25.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/zaqar-tempest-plugin/commit/5e6cb711455f242629ae137f06a8d8509a66811c', 'message': 'Remove support for py34\n\nChange-Id: Idbfdc8c07a67edc59f298a7379314f0c4b26b529\n'}]",0,626353,5e6cb711455f242629ae137f06a8d8509a66811c,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Idbfdc8c07a67edc59f298a7379314f0c4b26b529
",git fetch https://review.opendev.org/openstack/zaqar-tempest-plugin refs/changes/53/626353/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5e6cb711455f242629ae137f06a8d8509a66811c,,, Programming Language :: Python :: 3.4,0,1
openstack%2Fvirtualpdu~master~Ic6736274718dd981aaa06f5b3df35e7ad040eab0,openstack/virtualpdu,master,Ic6736274718dd981aaa06f5b3df35e7ad040eab0,Remove support for py34,ABANDONED,2018-12-19 16:24:02.000000000,2019-02-12 05:13:22.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:24:02.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/virtualpdu/commit/9592844cf48b41024988dcada326a5eb61771a6d', 'message': 'Remove support for py34\n\nChange-Id: Ic6736274718dd981aaa06f5b3df35e7ad040eab0\n'}]",0,626346,9592844cf48b41024988dcada326a5eb61771a6d,3,1,1,28614,,,0,"Remove support for py34

Change-Id: Ic6736274718dd981aaa06f5b3df35e7ad040eab0
",git fetch https://review.opendev.org/openstack/virtualpdu refs/changes/46/626346/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9592844cf48b41024988dcada326a5eb61771a6d,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ffreezer~master~Ibee27dfcb758c5557a09b5814af78a93b5e2ef5b,openstack/freezer,master,Ibee27dfcb758c5557a09b5814af78a93b5e2ef5b,Update hacking version,ABANDONED,2018-12-26 07:06:12.000000000,2019-02-12 05:12:44.000000000,,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-12-26 07:06:12.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/freezer/commit/d3d166e49ce4a336f66000ef8ddc59a98678b598', 'message': 'Update hacking version\n\nChange-Id: Ibee27dfcb758c5557a09b5814af78a93b5e2ef5b\n'}]",0,627354,d3d166e49ce4a336f66000ef8ddc59a98678b598,4,2,1,28614,,,0,"Update hacking version

Change-Id: Ibee27dfcb758c5557a09b5814af78a93b5e2ef5b
",git fetch https://review.opendev.org/openstack/freezer refs/changes/54/627354/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d3d166e49ce4a336f66000ef8ddc59a98678b598,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Ftrove-tempest-plugin~master~I1198647ece0cb1e2eb3a076f34883204d4354138,openstack/trove-tempest-plugin,master,I1198647ece0cb1e2eb3a076f34883204d4354138,Remove support for py34,ABANDONED,2018-12-19 16:24:04.000000000,2019-02-12 05:05:12.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-12-19 16:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/512d996a124aa897ac4790bcc06318843f64aeef', 'message': 'Remove support for py34\n\nChange-Id: I1198647ece0cb1e2eb3a076f34883204d4354138\n'}, {'number': 2, 'created': '2019-01-05 08:44:37.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/trove-tempest-plugin/commit/03b6d55784dfbf26adcff93353fdaec6999a1181', 'message': 'Remove support for py34\n\nChange-Id: I1198647ece0cb1e2eb3a076f34883204d4354138\n'}]",0,626347,03b6d55784dfbf26adcff93353fdaec6999a1181,5,1,2,28614,,,0,"Remove support for py34

Change-Id: I1198647ece0cb1e2eb3a076f34883204d4354138
",git fetch https://review.opendev.org/openstack/trove-tempest-plugin refs/changes/47/626347/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,512d996a124aa897ac4790bcc06318843f64aeef,,, Programming Language :: Python :: 3.4,0,1
openstack%2Ftacker~master~Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61,openstack/tacker,master,Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61,Add a new VDU property `reservation`,ABANDONED,2018-10-11 07:55:50.000000000,2019-02-12 04:25:27.000000000,,"[{'_account_id': 16237}, {'_account_id': 18955}, {'_account_id': 19316}, {'_account_id': 20182}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26463}, {'_account_id': 27153}, {'_account_id': 29383}]","[{'number': 1, 'created': '2018-10-11 07:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/f03ebef731ca49b8bebc2af01d2ddce32a66e93a', 'message': '[WIP] add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 2, 'created': '2018-10-11 09:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/f67ea7da2f8ad833f9f574239d9ec8a7a2882c63', 'message': '[WIP] add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 3, 'created': '2018-12-10 10:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/878a229c16a7c220d3a46798d01ffdf383656d28', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 4, 'created': '2018-12-27 11:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5b8046dc7534ad3fa9cf6b82d1a08abb79b900dd', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 5, 'created': '2019-01-07 08:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c359533e7dd605eb95347f85a72d9c44ff27a3ce', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 6, 'created': '2019-01-09 06:12:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/257fb788bfd04c373da49d8939e4dc4756068dbc', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 7, 'created': '2019-01-11 08:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/2ab33d1990874cc57200e7383cee2b5f978628d0', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 8, 'created': '2019-01-11 10:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/60f092e56750f5c338c740863af999f61e4f9aa1', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 9, 'created': '2019-01-15 10:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ca2654a9b86e8d388c10460431faf572d3ee7734', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 10, 'created': '2019-01-23 04:52:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/b9dffffaac3a0d3021c9a5b9750198c4f6f2c487', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 11, 'created': '2019-01-28 11:08:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7dc63c97273f6d134aed57043ef623cb06903e4b', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}, {'number': 12, 'created': '2019-02-05 04:45:25.000000000', 'files': ['tacker/tosca/lib/tacker_nfv_defs.yaml', 'tacker/tests/unit/vnfm/tosca/test_utils.py', 'tacker/tests/unit/vnfm/infra_drivers/openstack/data/test_tosca_post_process_template.yaml', 'doc/source/contributor/vnfd_template_description.rst', 'tacker/tosca/utils.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/0a06d7d4cdeacd173cfb0877122296321f8afbe5', 'message': 'Add a new VDU property `reservation`\n\nThis patch adds a new VDU property `reservation`. In this property, a\nreservation-id which created by OpenStack Blazar can be placed. Note\nthat only reservation-id of `Host reservation` is valid. `reservation`\nin VNFD is translated to `scheduler_hints: { reservation:\n<reservation-id> } in Heat Orchestration Template.\n\nChange-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61\nImplements: blueprint reservation-vnfm\n'}]",0,609610,0a06d7d4cdeacd173cfb0877122296321f8afbe5,36,9,12,26588,,,0,"Add a new VDU property `reservation`

This patch adds a new VDU property `reservation`. In this property, a
reservation-id which created by OpenStack Blazar can be placed. Note
that only reservation-id of `Host reservation` is valid. `reservation`
in VNFD is translated to `scheduler_hints: { reservation:
<reservation-id> } in Heat Orchestration Template.

Change-Id: Ie85b325bc7182d48dc94086c92d0d7bbcd89dd61
Implements: blueprint reservation-vnfm
",git fetch https://review.opendev.org/openstack/tacker refs/changes/10/609610/12 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tosca/lib/tacker_nfv_defs.yaml', 'tacker/tosca/utils.py']",2,f03ebef731ca49b8bebc2af01d2ddce32a66e93a,bp/reservation-vnfm," if nt.type_definition.is_derived_from(TACKERVDU): prop_rsvid = nt.get_properties().get('reservation') if prop_rsvid is not None: hints = nt.get_property_value('scheduler_hints') if hints is None: hints = OrderedDict() hints_prop = properties.Property( 'scheduler_hints', hints, {'type': 'map', 'required': False, 'entry_schema': {'type': 'string'}}) nt.get_properties_objects().append(hints_prop) hints['reservation'] = prop_rsvid.value nt.get_properties_objects().remove(prop_rsvid) ",,17,0
openstack%2Ftripleo-common-tempest-plugin~master~I30766e492095297c99443939d6c72ce1c804c21e,openstack/tripleo-common-tempest-plugin,master,I30766e492095297c99443939d6c72ce1c804c21e,Update hacking version,ABANDONED,2019-02-05 08:09:47.000000000,2019-02-12 04:14:34.000000000,,"[{'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-02-05 08:09:47.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-common-tempest-plugin/commit/c86c6fd93a8491bcaf43b3603560be46d8c1ef7e', 'message': 'Update hacking version\n\nUse latest release 1.1.0, though no compatible changes\nrequires w.r.t pep8. So updating only version is enough.\n\nChange-Id: I30766e492095297c99443939d6c72ce1c804c21e\n'}]",0,634879,c86c6fd93a8491bcaf43b3603560be46d8c1ef7e,5,2,1,23717,,,0,"Update hacking version

Use latest release 1.1.0, though no compatible changes
requires w.r.t pep8. So updating only version is enough.

Change-Id: I30766e492095297c99443939d6c72ce1c804c21e
",git fetch https://review.opendev.org/openstack/tripleo-common-tempest-plugin refs/changes/79/634879/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,c86c6fd93a8491bcaf43b3603560be46d8c1ef7e,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fzun~master~I92f73bf0d759d9e770905debc6f40a5697ef0856,openstack/zun,master,I92f73bf0d759d9e770905debc6f40a5697ef0856,Pull image from registry,MERGED,2019-01-10 04:06:12.000000000,2019-02-12 03:57:53.000000000,2019-02-12 03:57:53.000000000,"[{'_account_id': 21428}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2019-01-10 04:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/b7b34c3c06cedf87d86d423149bdf2fb4d4c37b5', 'message': '[WIP] Pull image from registry\n\nChange-Id: I92f73bf0d759d9e770905debc6f40a5697ef0856\n'}, {'number': 2, 'created': '2019-01-13 16:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/7a9ea4d1c7cc593362b0676e9d37d2d03e6a9f56', 'message': '[WIP] Pull image from registry\n\nCloses-Bug: #1702830\nChange-Id: I92f73bf0d759d9e770905debc6f40a5697ef0856\n'}, {'number': 3, 'created': '2019-01-13 17:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/d2f31ccc0a9e01ee382c8070bbf375588b0c40ae', 'message': '[WIP] Pull image from registry\n\nCloses-Bug: #1702830\nChange-Id: I92f73bf0d759d9e770905debc6f40a5697ef0856\n'}, {'number': 4, 'created': '2019-01-13 20:19:29.000000000', 'files': ['zun/common/utils.py', 'zun/compute/api.py', 'zun/tests/unit/compute/test_compute_manager.py', 'zun/image/driver.py', 'zun/tests/unit/common/test_utils.py', 'zun/tests/unit/compute/test_compute_api.py', 'zun/compute/rpcapi.py', 'zun/image/docker/driver.py', 'zun/image/glance/driver.py', 'zun/container/docker/driver.py', 'zun/tests/unit/image/glance/test_driver.py', 'zun/compute/manager.py', 'zun/tests/unit/image/docker/test_driver.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/bcf8455d8e021ba58930111cb1e2c97c6bbd05a9', 'message': 'Pull image from registry\n\nThis commit complete the support of private docker registry.\nUsers can create a container with images from a specified\ndocker registry. The steps are as following:\n\n1. Registry a docker registry in Zun (with options to specify\n   the username/password to authenticate against the registry).\n2. Run a container with a reference to the registry created in #1.\n\nCloses-Bug: #1702830\nChange-Id: I92f73bf0d759d9e770905debc6f40a5697ef0856\n'}]",0,629758,bcf8455d8e021ba58930111cb1e2c97c6bbd05a9,13,3,4,11536,,,0,"Pull image from registry

This commit complete the support of private docker registry.
Users can create a container with images from a specified
docker registry. The steps are as following:

1. Registry a docker registry in Zun (with options to specify
   the username/password to authenticate against the registry).
2. Run a container with a reference to the registry created in #1.

Closes-Bug: #1702830
Change-Id: I92f73bf0d759d9e770905debc6f40a5697ef0856
",git fetch https://review.opendev.org/openstack/zun refs/changes/58/629758/4 && git format-patch -1 --stdout FETCH_HEAD,"['zun/common/utils.py', 'zun/compute/api.py', 'zun/compute/rpcapi.py', 'zun/image/docker/driver.py', 'zun/image/glance/driver.py', 'zun/container/docker/driver.py', 'zun/compute/manager.py', 'zun/image/driver.py']",8,b7b34c3c06cedf87d86d423149bdf2fb4d4c37b5,bug/1702830," def pull_image(self, context, repo, tag, image_pull_policy, registry):"," def pull_image(self, context, repo, tag, image_pull_policy):",39,25
openstack%2Fzun~master~I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9,openstack/zun,master,I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9,Add registry_id to container,MERGED,2019-01-06 23:02:07.000000000,2019-02-12 03:54:29.000000000,2019-02-12 03:54:29.000000000,"[{'_account_id': 11536}, {'_account_id': 21428}, {'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2019-01-06 23:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/04509663010a96d4c5c23d9d64bf0c6851dc9c29', 'message': '[WIP] Pull image from registry\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 2, 'created': '2019-01-07 00:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/b2186535149e6d5c7c80503c584e6a3cbdfed301', 'message': '[WIP] Pull image from registry\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 3, 'created': '2019-01-08 03:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/d95ab01c71bc92cb9d036669646c3883422eec70', 'message': '[WIP] Pull image from registry\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 4, 'created': '2019-01-10 03:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/47cb486f5d5ee17f8c5210a465351b74ead9bdf9', 'message': '[WIP] Pull image from registry\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 5, 'created': '2019-01-10 04:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/efa913d0fce07f33ce0325968906eca073be007b', 'message': '[WIP] Add registry_id to container\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 6, 'created': '2019-01-10 04:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/02bc0daaca6e1b4d3dc61e97680c4508a97f3171', 'message': '[WIP] Add registry_id to container\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 7, 'created': '2019-01-12 18:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/0c43017e8c083098de2b5a6ba4d55270b6700f3e', 'message': 'Add registry_id to container\n\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 8, 'created': '2019-01-13 16:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/daed1c05b4a318a818b86ca63b73d256c5fe02a8', 'message': 'Add registry_id to container\n\nPartial-Bug: #1702830\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 9, 'created': '2019-01-13 17:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/09843e2d7bfff5be61257b2959715e63d58a7704', 'message': 'Add registry_id to container\n\nPartial-Bug: #1702830\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}, {'number': 10, 'created': '2019-01-13 20:19:29.000000000', 'files': ['zun/common/utils.py', 'zun/tests/unit/db/utils.py', 'zun/db/api.py', 'zun/db/sqlalchemy/api.py', 'zun/api/controllers/v1/schemas/parameter_types.py', 'zun/api/controllers/v1/views/capsules_view.py', 'zun/api/rest_api_version_history.rst', 'zun/tests/unit/objects/test_objects.py', 'zun/tests/unit/api/base.py', 'zun/objects/registry.py', 'zun/db/sqlalchemy/models.py', 'zun/api/controllers/v1/schemas/containers.py', 'zun/api/controllers/v1/views/containers_view.py', 'zun/tests/unit/api/controllers/test_root.py', 'zun/api/controllers/v1/registries.py', 'zun/objects/container.py', 'zun/api/controllers/v1/containers.py', 'zun/api/controllers/versions.py', 'zun/db/sqlalchemy/alembic/versions/1bc34e18180b_add_registry_id_to_container.py', 'zun/tests/unit/api/controllers/v1/test_registries.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/f608300050cadce8f5cb5c24a1c0fe4e44cc1d5a', 'message': 'Add registry_id to container\n\nPartial-Bug: #1702830\nChange-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9\n'}]",1,628787,f608300050cadce8f5cb5c24a1c0fe4e44cc1d5a,25,4,10,11536,,,0,"Add registry_id to container

Partial-Bug: #1702830
Change-Id: I9de5e9786a6cddce9e31b1de7b71ceaa553b1fd9
",git fetch https://review.opendev.org/openstack/zun refs/changes/87/628787/5 && git format-patch -1 --stdout FETCH_HEAD,"['zun/common/utils.py', 'zun/image/docker/driver.py', 'zun/db/sqlalchemy/models.py', 'zun/api/controllers/v1/views/containers_view.py', 'zun/image/glance/driver.py', 'zun/container/docker/driver.py', 'zun/compute/manager.py', 'zun/image/driver.py', 'zun/objects/container.py', 'zun/api/controllers/v1/containers.py', 'zun/db/sqlalchemy/alembic/versions/1bc34e18180b_add_registry_id_to_container.py']",11,04509663010a96d4c5c23d9d64bf0c6851dc9c29,bug/1702830,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""add registry_id to container Revision ID: 1bc34e18180b Revises: 5ffc1cabe6b4 Create Date: 2019-01-06 21:45:57.505152 """""" # revision identifiers, used by Alembic. revision = '1bc34e18180b' down_revision = '5ffc1cabe6b4' branch_labels = None depends_on = None from alembic import op import sqlalchemy as sa def upgrade(): op.add_column('container', sa.Column('registry_id', sa.Integer(), nullable=True)) ",,84,20
openstack%2Fnova~master~Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72,openstack/nova,master,Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72,Add minimum value in maximum_instance_delete_attempts,MERGED,2019-01-24 23:04:14.000000000,2019-02-12 03:50:49.000000000,2019-02-09 07:42:47.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-24 23:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/950dc2380a4ed0f1f3a1c7777c7bdcd7052108f2', 'message': 'Add minimum value in maximum_instance_delete_attempts\n\nAdd minimum value 1 in the maximum_instance_delete_attempts option.\n\nChange-Id: Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72\n'}, {'number': 2, 'created': '2019-01-25 04:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3ca91677bf9f2f28f7e1a6c1debabae4b63b86a', 'message': 'Add minimum value in maximum_instance_delete_attempts\n\nAdd minimum value 1 in the maximum_instance_delete_attempts option.\n\nChange-Id: Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72\n'}, {'number': 3, 'created': '2019-02-07 08:26:50.000000000', 'files': ['nova/conf/compute.py', 'releasenotes/notes/maximum_instance_delete_attempts-option-force-minimum-value-2ce74351650e7b21.yaml', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/25477e6771a226bb676b2d54e5ccffe5c5a64fb0', 'message': 'Add minimum value in maximum_instance_delete_attempts\n\nAdd minimum value 1 in the maximum_instance_delete_attempts option.\n\nChange-Id: Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72\n'}]",2,633085,25477e6771a226bb676b2d54e5ccffe5c5a64fb0,43,15,3,7634,,,0,"Add minimum value in maximum_instance_delete_attempts

Add minimum value 1 in the maximum_instance_delete_attempts option.

Change-Id: Ic2ce1973971a6827f1a7d00c8c054b6561ab7e72
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/633085/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/conf/compute.py', 'releasenotes/notes/maximum_instance_delete_attempts-option-force-minimum-value-2ce74351650e7b21.yaml', 'nova/compute/manager.py']",3,950dc2380a4ed0f1f3a1c7777c7bdcd7052108f2,add_min_in_option,," # TODO(raj_singh): Remove this if condition when min value is # introduced to ""maximum_instance_delete_attempts"" cfg option. if CONF.maximum_instance_delete_attempts < 1: LOG.warning('Future versions of Nova will restrict the ' '""maximum_instance_delete_attempts"" config option ' 'to values >=1. Update your configuration file to ' 'mitigate future upgrade issues.') ",6,11
openstack%2Fkolla-ansible~master~I7c428155e73faa02aaa7473a4d89566292a9a39b,openstack/kolla-ansible,master,I7c428155e73faa02aaa7473a4d89566292a9a39b,Update image's tag to master rather than 6.0.0,ABANDONED,2018-07-18 15:01:33.000000000,2019-02-12 03:10:15.000000000,,"[{'_account_id': 1390}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 26285}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-07-18 15:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4d197a9aa388151ff7162025a25f0b9afe99b25a', 'message': '[NDM]: test\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 2, 'created': '2018-07-25 15:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f169ffad901fdb29f4c748380cb679697a85986e', 'message': '[NDM]: test\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 3, 'created': '2018-07-25 15:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2dbc187e153d9864de808aae0600f3a6ae93426f', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nthe cinder_iscsi_helper will be use by iscsi role, it use be\ndefined in all.yml\n\nhttps://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 4, 'created': '2018-07-25 15:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/71107973453f19a4762c1a500a8681f571b9693c', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nis that ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 5, 'created': '2018-07-25 15:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d999ed7a3f5a611f374ec8527383a9bfbb177749', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nis that ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 6, 'created': '2018-08-03 08:29:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/57c9e76bd93efe86b641c3e1c4429115db9152fb', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nlooks like ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\nCloses-Bug: #1785192\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 7, 'created': '2018-08-03 08:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c60a833ceb8096927ca1878b7562e5e36e63a601', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nlooks like ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\nCloses-Bug: #1785192\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 8, 'created': '2018-08-03 12:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e5c190b4751ea074f3ea112df21081dc89f23694', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nlooks like ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\nCloses-Bug: #1785192\n'}, {'number': 9, 'created': '2018-08-04 00:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/643947aee28d5f85b13663f80652af0c0d629bac', 'message': 'Fix the tgtd start failed due to cinder_iscsi_helper undefined\n\nThe cinder_iscsi_helper will be use by iscsi role[0] too,\nit should be defined in all.yml, or tasks raise error\nlooks like ""the cinder_iscsi_helper is undefined"" when run\niscsi role.\n\n[0]: https://github.com/openstack/kolla-ansible/blob/master/ansible/roles/iscsi/tasks/start.yml#L49\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\nCloses-Bug: #1785192\n'}, {'number': 10, 'created': '2018-08-14 06:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e693ea5fa707debd40e31dd0d8d685e2a5779f17', 'message': 'test\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\n'}, {'number': 11, 'created': '2018-11-16 04:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6ffe7e15441509a635ee18be6f95148c36952cac', 'message': ""Update image's tag to master rather than 6.0.0\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\nCloses-Bug: #1803656\n""}, {'number': 12, 'created': '2018-11-16 04:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/00a7012d8130936d18af554ca277e7e7d4719687', 'message': ""Update image's tag to master rather than 6.0.0\n\nrefer to docker hub[1]\n\n[1]: https://hub.docker.com/r/kolla/ubuntu-source-cinder-volume/tags/\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\nCloses-Bug: #1803656\n""}, {'number': 13, 'created': '2018-11-20 15:00:01.000000000', 'files': ['doc/source/user/operating-kolla.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b1b03121956707fc93a3b5c5734e4c9d4c1ca86a', 'message': ""Update image's tag to master rather than 6.0.0\n\nrefer to docker hub[1]\n\n[1]: https://hub.docker.com/r/kolla/ubuntu-source-cinder-volume/tags/\n\nChange-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b\nCloses-Bug: #1803656\n""}]",0,583641,b1b03121956707fc93a3b5c5734e4c9d4c1ca86a,32,6,13,22165,,,0,"Update image's tag to master rather than 6.0.0

refer to docker hub[1]

[1]: https://hub.docker.com/r/kolla/ubuntu-source-cinder-volume/tags/

Change-Id: I7c428155e73faa02aaa7473a4d89566292a9a39b
Closes-Bug: #1803656
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/41/583641/10 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4d197a9aa388151ff7162025a25f0b9afe99b25a,bug/1803656,test,,1,0
openstack%2Fkolla-ansible~master~I9195d5f24d938f5060fe748aac3ae58c79ec5abf,openstack/kolla-ansible,master,I9195d5f24d938f5060fe748aac3ae58c79ec5abf,Link kolla_log volume dir to /var/log/kolla,MERGED,2019-01-23 06:14:06.000000000,2019-02-12 03:09:50.000000000,2019-01-28 10:40:59.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23717}, {'_account_id': 29654}]","[{'number': 1, 'created': '2019-01-23 06:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f9296312a39dd69c30e48dea26bc5992587b94d4', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 2, 'created': '2019-01-23 06:17:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9a0347aecb16622685a8029c570d98cfeebfab62', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 3, 'created': '2019-01-23 07:12:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/835c607d12f05cd0d345de1fedd5ae194f20b9e8', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 4, 'created': '2019-01-23 09:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/765902df33e07174b43bce80f1118848ee4e9708', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 5, 'created': '2019-01-23 09:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c84ded80e44c0dc353c8ef93f7080cf475361f84', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 6, 'created': '2019-01-23 09:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c13f9c0ad15b6fa180d27299136ff52c016c34a2', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}, {'number': 7, 'created': '2019-01-24 03:03:21.000000000', 'files': ['ansible/roles/common/tasks/bootstrap.yml', 'releasenotes/notes/link_kolla_logs-e57a1e583f2872eb.yaml', 'tools/cleanup-containers', 'doc/source/user/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/93e5e8e631eb89599913bffe0fe76d24a835d4ff', 'message': 'Link kolla_log volume dir to /var/log/kolla\n\nThe path /var/lib/docker/volumes/kolla_logs/_data/ is too long\nshorter log path will help to debug from log.\nThe volume path is compatible with docker-engine and docker-ce.\n\nChange-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf\n'}]",8,632619,93e5e8e631eb89599913bffe0fe76d24a835d4ff,22,5,7,24687,,,0,"Link kolla_log volume dir to /var/log/kolla

The path /var/lib/docker/volumes/kolla_logs/_data/ is too long
shorter log path will help to debug from log.
The volume path is compatible with docker-engine and docker-ce.

Change-Id: I9195d5f24d938f5060fe748aac3ae58c79ec5abf
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/19/632619/5 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/tasks/bootstrap.yml'],1,f9296312a39dd69c30e48dea26bc5992587b94d4,link_log_volume, - name: Link kolla_logs volume to /var/log/kolla file: src: /var/lib/docker/volumes/kolla_logs/_data path: /var/log/kolla state: link,,6,0
openstack%2Fpuppet-neutron~master~I9f359a1110d175e232adc14671e448dd7a334eb9,openstack/puppet-neutron,master,I9f359a1110d175e232adc14671e448dd7a334eb9,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:20:59.000000000,2019-02-12 03:08:58.000000000,2019-02-12 03:08:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:20:59.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-8c62a5ed35cd1b42.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ae209826e363785acea5208fd30d064b5b313206', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I9f359a1110d175e232adc14671e448dd7a334eb9\n'}]",0,635802,ae209826e363785acea5208fd30d064b5b313206,15,5,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I9f359a1110d175e232adc14671e448dd7a334eb9
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/02/635802/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-8c62a5ed35cd1b42.yaml', 'manifests/db/mysql.pp']",3,ae209826e363785acea5208fd30d064b5b313206,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fsenlin~master~Iac7edc723b0279230440d415ddff3ec9cabad4d3,openstack/senlin,master,Iac7edc723b0279230440d415ddff3ec9cabad4d3,Fix health policy file describe message,ABANDONED,2018-02-06 08:12:04.000000000,2019-02-12 03:08:18.000000000,,"[{'_account_id': 8246}, {'_account_id': 17656}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 23401}, {'_account_id': 23517}]","[{'number': 1, 'created': '2018-02-06 08:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/63af458be458eb153bd2c70685c77c5ae5e7706b', 'message': 'Fix health policy file describe message\n\nBecause the health policy file interval support,\nthe type support should be different.\n\nChange-Id: Iac7edc723b0279230440d415ddff3ec9cabad4d3\nSigned-off-by: Yuanbin.Chen <cybing4@gmail.com>\n'}, {'number': 2, 'created': '2018-02-07 03:17:37.000000000', 'files': ['examples/policies/health_policy_event.yaml', 'examples/policies/health_policy_poll.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c59a67935979555b23492e2169a17a9afc47615c', 'message': 'Fix health policy file describe message\n\nBecause the health policy file interval support,\nthe type support should be different.\n\nChange-Id: Iac7edc723b0279230440d415ddff3ec9cabad4d3\nSigned-off-by: Yuanbin.Chen <cybing4@gmail.com>\n'}]",0,541175,c59a67935979555b23492e2169a17a9afc47615c,14,6,2,23517,,,0,"Fix health policy file describe message

Because the health policy file interval support,
the type support should be different.

Change-Id: Iac7edc723b0279230440d415ddff3ec9cabad4d3
Signed-off-by: Yuanbin.Chen <cybing4@gmail.com>
",git fetch https://review.opendev.org/openstack/senlin refs/changes/75/541175/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/policies/health_policy_event.yaml', 'examples/policies/health_policy_poll.yaml']",2,63af458be458eb153bd2c70685c77c5ae5e7706b,fix_example_policy," # NODE_STATUS_POLLING, LB_STATUS_POLLING"," # NODE_STATUS_POLLING, LB_STATUS_POLLING, LIFECYCLE_EVENTS",2,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I5c61c0049bfd16114894cf4db3b79f94b6d9291b,openstack/tripleo-heat-templates,stable/rocky,I5c61c0049bfd16114894cf4db3b79f94b6d9291b,Sanitize the uuid string for ceph-ansible,MERGED,2019-02-11 13:47:39.000000000,2019-02-12 02:34:58.000000000,2019-02-11 23:20:59.000000000,"[{'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 13:47:39.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/90c456463862fdedbb709966ead479051ed459a7', 'message': 'Sanitize the uuid string for ceph-ansible\n\ndmidecode can return some additional data if SMBIOS is updated; this\nensures output matches the UUID format.\n\nChange-Id: I5c61c0049bfd16114894cf4db3b79f94b6d9291b\nRelated-Bug: 1762460\n(cherry picked from commit ad803ab716448e2dfaa446d732f64c6bd851cb05)\n'}]",0,636125,90c456463862fdedbb709966ead479051ed459a7,8,3,1,6796,,,0,"Sanitize the uuid string for ceph-ansible

dmidecode can return some additional data if SMBIOS is updated; this
ensures output matches the UUID format.

Change-Id: I5c61c0049bfd16114894cf4db3b79f94b6d9291b
Related-Bug: 1762460
(cherry picked from commit ad803ab716448e2dfaa446d732f64c6bd851cb05)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/25/636125/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,90c456463862fdedbb709966ead479051ed459a7,bug/1762460," # awk strips unwanted output, see LP bug #1762460 shell: dmidecode -s system-uuid | awk 'match($0, /[0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12}/) { print substr($0, RSTART, RLENGTH) }' | tr A-F a-f", command: dmidecode -s system-uuid | tr A-F a-f,2,1
openstack%2Fneutron~master~I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca,openstack/neutron,master,I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca,use payloads for PORT BEFORE_DELETE callbacks,MERGED,2018-08-23 20:27:33.000000000,2019-02-12 02:29:45.000000000,2019-02-02 04:01:22.000000000,"[{'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 8313}, {'_account_id': 8871}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-08-23 20:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68c5f21abcbb55697aa6dcce05f0bc134654617b', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 2, 'created': '2018-10-05 17:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f5deeea298dcc5665807d878d23150bf0142fc1a', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 3, 'created': '2018-10-15 20:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b1fbdafeb69b3fc0649469a8b2840323d44531ac', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 4, 'created': '2018-12-11 18:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3cc88235109ff2c86674d55feefc66fd8dba87f1', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 5, 'created': '2018-12-13 19:28:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f0118a63a121125fea35e7165af24570dbaaa978', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 6, 'created': '2019-01-18 19:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/875aa54cc7ddf15f9c22d1e5f0a902744a68e257', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 7, 'created': '2019-01-28 19:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3f5228eb58651620bb19a5fdb8c64d5b1eb8efb7', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}, {'number': 8, 'created': '2019-01-30 19:13:20.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/services/trunk/rules.py', 'neutron/db/l3_db.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/extensions/dns_integration.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/453f39f23dc7d1bb7445178c6761ddd7e48e57e0', 'message': 'use payloads for PORT BEFORE_DELETE callbacks\n\nThis patch switches BEFORE_DELETE callback events for PORT resources\nover to the payload style args use a DBEventPayload object.\n\nNeutronLibImpact\n\nChange-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca\n'}]",3,595883,453f39f23dc7d1bb7445178c6761ddd7e48e57e0,79,14,8,5367,,,0,"use payloads for PORT BEFORE_DELETE callbacks

This patch switches BEFORE_DELETE callback events for PORT resources
over to the payload style args use a DBEventPayload object.

NeutronLibImpact

Change-Id: I8d8ff8f9ed7e2a1a6a66e3c3e6fc8e38cd9e29ca
",git fetch https://review.opendev.org/openstack/neutron refs/changes/83/595883/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/services/trunk/rules.py', 'neutron/db/l3_db.py', 'neutron/plugins/ml2/plugin.py', 'neutron/plugins/ml2/extensions/dns_integration.py']",5,68c5f21abcbb55697aa6dcce05f0bc134654617b,use-callback-payloads,"def _delete_port_in_external_dns_service(resource, event, trigger, payload=None): context = payload.context port_id = payload.resource_id","def _delete_port_in_external_dns_service(resource, event, trigger, **kwargs): context = kwargs['context'] port_id = kwargs['port_id']",29,26
openstack%2Fsenlin~master~I22d24659bcbef9a8cb90c608bdd7eccfc53034bf,openstack/senlin,master,I22d24659bcbef9a8cb90c608bdd7eccfc53034bf,Fix duplicating network ports on node recovery,MERGED,2019-01-25 08:46:19.000000000,2019-02-12 02:29:16.000000000,2019-02-12 02:29:16.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 23517}, {'_account_id': 25674}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-01-25 08:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/036c9b7a44d9f1b1fbdbb4d1f5359d22af0e3a4d', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 2, 'created': '2019-01-25 19:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3d4113f6f915529b08ed4834dc0d818ca6af2c35', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 3, 'created': '2019-01-28 18:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2cd3acfd12186740f0054af9e7f9f95ce15365d8', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 4, 'created': '2019-01-28 23:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5acf54489cbffcc9e4520cb4ff670d26c72109a3', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 5, 'created': '2019-01-29 21:06:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6331fc0f9796cba69728f6676cf78aab526bf97a', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nThis patch also cleans up some logging.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 6, 'created': '2019-02-04 21:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1801c667d383dfbdedeb97bea91190426073422c', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nThis patch also cleans up some logging.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}, {'number': 7, 'created': '2019-02-05 19:07:24.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py', 'senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py', 'senlin/db/sqlalchemy/api.py', 'senlin/drivers/sdk.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/01fe1997ee9f8729bf8b6bc2bc2671f58efb686a', 'message': 'Fix duplicating network ports on node recovery\n\nThis patch fixes the node_recover operation to properly delete\nports when the nodes physical vm has been deleted.\n\nThis patch also cleans up some logging.\n\nChange-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf\n'}]",7,633161,01fe1997ee9f8729bf8b6bc2bc2671f58efb686a,35,5,7,25674,,,0,"Fix duplicating network ports on node recovery

This patch fixes the node_recover operation to properly delete
ports when the nodes physical vm has been deleted.

This patch also cleans up some logging.

Change-Id: I22d24659bcbef9a8cb90c608bdd7eccfc53034bf
",git fetch https://review.opendev.org/openstack/senlin refs/changes/61/633161/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py']",2,036c9b7a44d9f1b1fbdbb4d1f5359d22af0e3a4d,hm_misc_fixes," test_server.data = {} def test_do_delete_no_physical_id_with_internal_ports(self, mock_node_obj): profile = server.ServerProfile('t', self.spec) cc = mock.Mock() nc = mock.Mock() nc.port_delete.return_value = None nc.floatingip_delete.return_value = None profile._computeclient = cc profile._networkclient = nc test_server = mock.Mock(physical_id=None) test_server.data = {'internal_ports': [{ 'floating': { 'remove': True, 'id': 'FAKE_FLOATING_ID', }, 'id': 'FAKE_PORT_ID', 'remove': True }]} # do it res = profile.do_delete(test_server) # assertions self.assertTrue(res) mock_node_obj.assert_called_once_with( mock.ANY, test_server.id, {'data': {'internal_ports': []}}) self.assertFalse(cc.server_delete.called) self.assertFalse(cc.wait_for_server_delete.called) @mock.patch.object(node_ob.Node, 'update')",,40,3
openstack%2Fopenstack-ansible-ops~master~I3cb951456f82090fad1b02cda470055691c0ae35,openstack/openstack-ansible-ops,master,I3cb951456f82090fad1b02cda470055691c0ae35,Update overlay inventory to resovle circular dep,MERGED,2019-02-11 18:25:08.000000000,2019-02-12 02:13:05.000000000,2019-02-12 02:13:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-11 18:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/435509cbd676360ab04541667160f32ce8b7fd8e', 'message': 'Update overlay inventory to resovle circular dep\n\nThis change adds the metering sub group and points all of our systems at\nthat instead of assuming they can all be built on ""hosts"" and\n""log_hosts"".\n\nChange-Id: I3cb951456f82090fad1b02cda470055691c0ae35\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 2, 'created': '2019-02-12 01:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/4d11a28e8e1a3473a99e1de21ca1eabc656b36df', 'message': 'Update overlay inventory to resovle circular dep\n\nThis change adds the metering sub group and points all of our systems at\nthat instead of assuming they can all be built on ""hosts"" and\n""log_hosts"".\n\nChange-Id: I3cb951456f82090fad1b02cda470055691c0ae35\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}, {'number': 3, 'created': '2019-02-12 01:43:51.000000000', 'files': ['overlay-inventories/osa-integration-inventory.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/e4d724421972b6419a426334c0434b5dbe7e1c68', 'message': 'Update overlay inventory to resovle circular dep\n\nThis change adds the metering sub group and points all of our systems at\nthat instead of assuming they can all be built on ""hosts"" and\n""log_hosts"".\n\nChange-Id: I3cb951456f82090fad1b02cda470055691c0ae35\nSigned-off-by: cloudnull <kevin@cloudnull.com>\n'}]",6,636204,e4d724421972b6419a426334c0434b5dbe7e1c68,12,3,3,7353,,,0,"Update overlay inventory to resovle circular dep

This change adds the metering sub group and points all of our systems at
that instead of assuming they can all be built on ""hosts"" and
""log_hosts"".

Change-Id: I3cb951456f82090fad1b02cda470055691c0ae35
Signed-off-by: cloudnull <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/04/636204/3 && git format-patch -1 --stdout FETCH_HEAD,['overlay-inventories/osa-integration-inventory.yml'],1,435509cbd676360ab04541667160f32ce8b7fd8e,," physical_hosts: children: hosts: {} all_metering: children: metering: children: metering_ui_targets: children: log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. metering_infra_targets: children: log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. hosts: {} physical_hosts: {} metering_ui_targets: {} metering_infra_targets: {} metering_ui_targets: {} physical_hosts: {} physical_hosts: {} physical_hosts: {} physical_hosts: {} physical_hosts: {} physical_hosts: {} metering_ui_targets: {} metering_ui_targets: {} metering_ui_targets: {} physical_hosts: {} metering_ui_targets: {}"," hosts: {} hosts: {} all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. utility_all: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. elastic_setup_flags: - ""--template"" - ""--pipelines"" - ""--machine-learning"" log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. kibana_all: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. log_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. all_hosts: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited. utility_all: {} # This is an osa native group, as such nothing needs to be added. Values will be inherited.",31,21
openstack%2Fnova~stable%2Fpike~Id847949b4761d51a14e5c2f39552f60a47889aa9,openstack/nova,stable/pike,Id847949b4761d51a14e5c2f39552f60a47889aa9,Don't overwrite binding-profile,ABANDONED,2018-04-23 07:17:36.000000000,2019-02-12 02:09:28.000000000,,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 12171}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-04-23 07:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/730cd024b4fdf774a1ba88272e093f4c405d1f51', 'message': ""Don't overwrite binding-profile\n\nCurrently when providing existing direct port, nova-compute\nwill overwrite the binding-profile information with pci_vendor_info\nand pci_slot. The binding-profile will be used to request\nNIC capabilities for SR-IOV ports [1]. This also allows to distinguish\nwhich neutron mechanism driver will bind the port [2].\n\nThis patch updates the behaviour that on update port it will update,\nrather than overwrite, the binding-profile information with\npci_vendor_info and pci_slot. And on unbind port it will remove\nonly the pci_vendor_info and pci_slot from the port binding-profile\nrather than unsetting the entire field.\n\n[1] https://review.openstack.org/#/c/435954/\n[2] https://review.openstack.org/#/c/499203/\n\nCloses-Bug: #1719327\n\nConflicts:\n        nova/network/neutronv2/api.py\n        nova/tests/fixtures.py\n        nova/tests/unit/network/test_neutronv2.py\n\nChange-Id: Id847949b4761d51a14e5c2f39552f60a47889aa9\n(cherry picked from commit 7b2f7a1f96787a490d56289c55b8ad7cb5ac030e)\n""}, {'number': 2, 'created': '2018-05-30 14:11:14.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/228a250915361601bb97ee20bc9506e928aae8bb', 'message': ""Don't overwrite binding-profile\n\nCurrently when providing existing direct port, nova-compute\nwill overwrite the binding-profile information with pci_vendor_info\nand pci_slot. The binding-profile will be used to request\nNIC capabilities for SR-IOV ports [1]. This also allows to distinguish\nwhich neutron mechanism driver will bind the port [2].\n\nThis patch updates the behaviour that on update port it will update,\nrather than overwrite, the binding-profile information with\npci_vendor_info and pci_slot. And on unbind port it will remove\nonly the pci_vendor_info and pci_slot from the port binding-profile\nrather than unsetting the entire field.\n\n[1] https://review.openstack.org/#/c/435954/\n[2] https://review.openstack.org/#/c/499203/\n\nCloses-Bug: #1719327\n\nConflicts:\n        nova/network/neutronv2/api.py\n        nova/tests/fixtures.py\n        nova/tests/unit/network/test_neutronv2.py\n\nNOTE(moshele): Undo change in nova/tests/fixtures.py because\n5a70f23ec5f37cbe5ebb008b9968d16daefeaa3c\nRegarding neutronv2 change because of refactoring in\n2db3f5a850fcdd38c8d873386d693d3824e10b8b basicly because of\nrenaming port to requested_ports_dict\n\nChange-Id: Id847949b4761d51a14e5c2f39552f60a47889aa9\n(cherry picked from commit 7b2f7a1f96787a490d56289c55b8ad7cb5ac030e)\n""}]",3,563501,228a250915361601bb97ee20bc9506e928aae8bb,28,11,2,12171,,,0,"Don't overwrite binding-profile

Currently when providing existing direct port, nova-compute
will overwrite the binding-profile information with pci_vendor_info
and pci_slot. The binding-profile will be used to request
NIC capabilities for SR-IOV ports [1]. This also allows to distinguish
which neutron mechanism driver will bind the port [2].

This patch updates the behaviour that on update port it will update,
rather than overwrite, the binding-profile information with
pci_vendor_info and pci_slot. And on unbind port it will remove
only the pci_vendor_info and pci_slot from the port binding-profile
rather than unsetting the entire field.

[1] https://review.openstack.org/#/c/435954/
[2] https://review.openstack.org/#/c/499203/

Closes-Bug: #1719327

Conflicts:
        nova/network/neutronv2/api.py
        nova/tests/fixtures.py
        nova/tests/unit/network/test_neutronv2.py

NOTE(moshele): Undo change in nova/tests/fixtures.py because
5a70f23ec5f37cbe5ebb008b9968d16daefeaa3c
Regarding neutronv2 change because of refactoring in
2db3f5a850fcdd38c8d873386d693d3824e10b8b basicly because of
renaming port to requested_ports_dict

Change-Id: Id847949b4761d51a14e5c2f39552f60a47889aa9
(cherry picked from commit 7b2f7a1f96787a490d56289c55b8ad7cb5ac030e)
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/563501/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,730cd024b4fdf774a1ba88272e093f4c405d1f51,bug/1719327," @mock.patch('nova.network.neutronv2.api.API._show_port') def test_unbind_ports_get_client( self, mock_neutron, mock_has_ext, mock_show): self._test_unbind_ports_get_client( mock_neutron, mock_has_ext, mock_show) def _test_unbind_ports( self, mock_neutron, mock_has_ext, mock_show, has_ext=False): mock_show.side_effect = [{""id"": ""1""}, {""id"": ""2""}, {""id"": ""3""}] @mock.patch('nova.network.neutronv2.api.API._show_port') def test_unbind_ports_binding_ext( self, mock_neutron, mock_has_ext, mock_show): self._test_unbind_ports(mock_neutron, mock_has_ext, mock_show, True) @mock.patch('nova.network.neutronv2.api.API._show_port') def test_unbind_ports(self, mock_neutron, mock_has_ext, mock_show): self._test_unbind_ports(mock_neutron, mock_has_ext, mock_show, False) @mock.patch('nova.network.neutronv2.api.API._show_port') @mock.patch('nova.network.neutronv2.api.API._has_port_binding_extension', return_value=True) def test_unbind_ports_reset_binding_profile(self, mock_ext, mock_show): neutron = mock.Mock() port_client = mock.Mock() ports = [uuids.port_id] mock_show.return_value = { 'id': uuids.port, 'binding:profile': {'pci_vendor_info': '1377:0047', 'pci_slot': '0000:0a:00.1', 'physical_network': 'phynet1', 'capabilities': ['switchdev']} } self.api._unbind_ports(self.context, ports, neutron, port_client) port_req_body = {'port': {'binding:host_id': None, 'binding:profile': {'physical_network': 'phynet1', 'capabilities': ['switchdev']}, 'device_id': '', 'device_owner': ''} } port_client.update_port.assert_called_once_with( uuids.port_id, port_req_body) dhcp_opts=None, available_macs=None, requested_ports_dict=None) @mock.patch('nova.network.neutronv2.api.API._show_port', side_effect=exception.PortNotFound(port_id=uuids.port)) @mock.patch('nova.network.neutronv2.api.API._has_port_binding_extension', return_value=True) @mock.patch.object(neutronapi.LOG, 'exception') def test_unbind_ports_port_show_portnotfound( self, mock_log, mock_ext, mock_show): api = neutronapi.API() neutron_client = mock.Mock() api._unbind_ports(self.context, [uuids.port_id], neutron_client, neutron_client) mock_show.assert_called_once_with( mock.ANY, uuids.port_id, fields='binding:profile', neutron_client=mock.ANY) mock_log.assert_not_called() @mock.patch('nova.network.neutronv2.api.API._show_port', side_effect=Exception) @mock.patch('nova.network.neutronv2.api.API._has_port_binding_extension', return_value=True) @mock.patch.object(neutronapi.LOG, 'exception') def test_unbind_ports_port_show_unexpected_error( self, mock_log, mock_ext, mock_show): api = neutronapi.API() neutron_client = mock.Mock() mock_show.return_value = {'id': uuids.port} api._unbind_ports(self.context, [uuids.port_id], neutron_client, neutron_client) neutron_client.update_port.assert_called_once_with( uuids.port_id, {'port': { 'device_id': '', 'device_owner': '', 'binding:profile': {}, 'binding:host_id': None}}) self.assertTrue(mock_log.called) @mock.patch('nova.network.neutronv2.api.API._show_port') def test_unbind_ports_portnotfound(self, mock_log, mock_ext, mock_show): api._unbind_ports(self.context, [uuids.port_id], neutron_client, neutron_client) mock_show.assert_not_called() def test_populate_neutron_extension_values_binding_sriov_with_cap(self, mock_get_instance_pci_devs, mock_get_pci_device_devspec): api = neutronapi.API() host_id = 'my_host_id' instance = {'host': host_id} port_req_body = {'port': { neutronapi.BINDING_PROFILE: { 'capabilities': ['switchdev']}}} pci_req_id = 'my_req_id' pci_dev = {'vendor_id': '1377', 'product_id': '0047', 'address': '0000:0a:00.1', } PciDevice = collections.namedtuple('PciDevice', ['vendor_id', 'product_id', 'address']) mydev = PciDevice(**pci_dev) profile = {'pci_vendor_info': '1377:0047', 'pci_slot': '0000:0a:00.1', 'physical_network': 'phynet1', 'capabilities': ['switchdev'], } mock_get_instance_pci_devs.return_value = [mydev] devspec = mock.Mock() devspec.get_tags.return_value = {'physical_network': 'phynet1'} mock_get_pci_device_devspec.return_value = devspec api._populate_neutron_binding_profile(instance, pci_req_id, port_req_body) self.assertEqual(profile, port_req_body['port'][neutronapi.BINDING_PROFILE]) @mock.patch.object(pci_whitelist.Whitelist, 'get_devspec') @mock.patch.object(pci_manager, 'get_instance_pci_devs') requested_ports_dict = {uuids.port1: {}, uuids.port2: {}} bind_host_id, dhcp_opts, available_macs, requested_ports_dict)"," def test_unbind_ports_get_client(self, mock_neutron, mock_has_ext): self._test_unbind_ports_get_client(mock_neutron, mock_has_ext) def _test_unbind_ports(self, mock_neutron, mock_has_ext, has_ext=False): def test_unbind_ports_binding_ext(self, mock_neutron, mock_has_ext): self._test_unbind_ports(mock_neutron, mock_has_ext, True) def test_unbind_ports(self, mock_neutron, mock_has_ext): self._test_unbind_ports(mock_neutron, mock_has_ext, False) dhcp_opts=None, available_macs=None) def test_unbind_ports_portnotfound(self, mock_log, mock_ext): api._unbind_ports(self.context, [uuids.port_id], neutron_client) bind_host_id, dhcp_opts, available_macs)",161,18
openstack%2Fpuppet-placement~master~I08b03e7ba87e0b3edcecb26de74ec6c2db6c867d,openstack/puppet-placement,master,I08b03e7ba87e0b3edcecb26de74ec6c2db6c867d,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:25:45.000000000,2019-02-12 02:06:20.000000000,2019-02-12 02:06:20.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:25:45.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-43a7592377270fe9.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-placement/commit/6e87109c0cdc9cf7f7c10a967e4f1dfe746ca4e0', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I08b03e7ba87e0b3edcecb26de74ec6c2db6c867d\n'}]",0,635806,6e87109c0cdc9cf7f7c10a967e4f1dfe746ca4e0,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I08b03e7ba87e0b3edcecb26de74ec6c2db6c867d
",git fetch https://review.opendev.org/openstack/puppet-placement refs/changes/06/635806/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-43a7592377270fe9.yaml', 'manifests/db/mysql.pp']",3,6e87109c0cdc9cf7f7c10a967e4f1dfe746ca4e0,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-keystone~stable%2Focata~Ic4b17a2c750c3162cc609a9469d7422c2084b977,openstack/puppet-keystone,stable/ocata,Ic4b17a2c750c3162cc609a9469d7422c2084b977,Keystone_user should not use disabled projects,MERGED,2019-02-07 08:38:10.000000000,2019-02-12 02:04:42.000000000,2019-02-12 02:04:42.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 08:38:10.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/30aea4941b44b7c3816bba8d2ca4076b90901e23', 'message': 'Keystone_user should not use disabled projects\n\nWhen testing the password for a keystone_user\nresource we need to ensure the project id that\nis used for testing auth is not disabled causing\nit to fail and puppet things the password should\nbe changed.\n\nChange-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977\nCloses-Bug: 1814906\n(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)\n'}]",0,635456,30aea4941b44b7c3816bba8d2ca4076b90901e23,13,4,1,16137,,,0,"Keystone_user should not use disabled projects

When testing the password for a keystone_user
resource we need to ensure the project id that
is used for testing auth is not disabled causing
it to fail and puppet things the password should
be changed.

Change-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977
Closes-Bug: 1814906
(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/56/635456/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb']",3,30aea4941b44b7c3816bba8d2ca4076b90901e23,bug/1814906-stable/rocky-stable/queens-stable/pike-stable/ocata," # all of the projects for the user, and use the id for the first one # that is enabled then fallback to domain id only. first_project = nil if projects && projects.respond_to?(:each) first_project = projects.detect { |p| p && p[:id] && p[:enabled] == 'True' } end if not first_project.nil? credentials.project_id = first_project[:id]"," # all of the projects for the user, and use the id from the first one. if projects && projects[0] && projects[0][:id] credentials.project_id = projects[0][:id]",44,3
openstack%2Fwatcher-tempest-plugin~master~Ic84e549f290f24d7ca310d2a19d54e9a91be89bf,openstack/watcher-tempest-plugin,master,Ic84e549f290f24d7ca310d2a19d54e9a91be89bf,"Remove unused parameter ""aggregation_method"" for vm_workload_consolidation strategy",MERGED,2019-02-11 06:54:29.000000000,2019-02-12 01:52:10.000000000,2019-02-12 01:52:09.000000000,"[{'_account_id': 12394}, {'_account_id': 13111}, {'_account_id': 18971}, {'_account_id': 19055}, {'_account_id': 19457}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 22775}, {'_account_id': 24501}, {'_account_id': 24872}]","[{'number': 1, 'created': '2019-02-11 06:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher-tempest-plugin/commit/775e5bbf4390b1b36393d450ab50230b9ca92414', 'message': 'Remove unused parameter ""aggregation_method""\nfor vm_workload_consolidation strategy\n\nActually, this vm_workload_consolidation strategy just need\nthe period parameter according to the docs in https://docs.open\nstack.org/watcher/latest/strategies/vm_workload_consolidation.html\n\nChange-Id: Ic84e549f290f24d7ca310d2a19d54e9a91be89bf\n'}, {'number': 2, 'created': '2019-02-11 08:25:51.000000000', 'files': ['watcher_tempest_plugin/tests/scenario/test_execute_vm_workload_consolidation.py'], 'web_link': 'https://opendev.org/openstack/watcher-tempest-plugin/commit/6479f36d49ecb204fad979495538d784bbb901c3', 'message': 'Remove unused parameter ""aggregation_method""\nfor vm_workload_consolidation strategy\n\nActually, this vm_workload_consolidation strategy just need\nthe period parameter according to the docs in https://docs.open\nstack.org/watcher/latest/strategies/vm_workload_consolidation.html\n\nChange-Id: Ic84e549f290f24d7ca310d2a19d54e9a91be89bf\n'}]",0,636096,6479f36d49ecb204fad979495538d784bbb901c3,8,10,2,28748,,,0,"Remove unused parameter ""aggregation_method""
for vm_workload_consolidation strategy

Actually, this vm_workload_consolidation strategy just need
the period parameter according to the docs in https://docs.open
stack.org/watcher/latest/strategies/vm_workload_consolidation.html

Change-Id: Ic84e549f290f24d7ca310d2a19d54e9a91be89bf
",git fetch https://review.opendev.org/openstack/watcher-tempest-plugin refs/changes/96/636096/2 && git format-patch -1 --stdout FETCH_HEAD,['watcher_tempest_plugin/tests/scenario/test_execute_vm_workload_consolidation.py'],1,775e5bbf4390b1b36393d450ab50230b9ca92414,fix_tempest," """"""Execute an action plan based on the vm_workload_consolidation strategy - create an audit template with the vm_workload_consolidation strategy ""period"": 72000"," """"""Execute an action plan based on the BASIC strategy - create an audit template with the basic strategy ""granularity"": 1, ""period"": 72000, ""aggregation_method"": {""instance"": ""last"", ""node"": ""last""}",4,5
openstack%2Fdevstack~master~Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba,openstack/devstack,master,Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba,DNM: test change to stage-output,ABANDONED,2019-01-30 23:40:47.000000000,2019-02-12 01:50:47.000000000,,"[{'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-30 23:40:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/37fe8f5c7e813827f9e11a9129481e8514f689a0', 'message': 'DNM: test change to stage-output\n\nChange-Id: Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba\nDepends-On: https://review.openstack.org/634069\n'}, {'number': 2, 'created': '2019-01-31 18:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7f8f7f124fc7edf28376666b0bf5b121caa3a7f5', 'message': 'DNM: test change to stage-output\n\nChange-Id: Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba\nDepends-On: https://review.openstack.org/634293\n'}, {'number': 3, 'created': '2019-02-05 17:51:23.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c8f1133ff879cda9fd64a331e21f4d7818696711', 'message': 'DNM: test change to stage-output\n\nChange-Id: Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba\nDepends-On: https://review.openstack.org/634992\n'}]",0,634070,c8f1133ff879cda9fd64a331e21f4d7818696711,13,3,3,1,,,0,"DNM: test change to stage-output

Change-Id: Icbc56f476fb54ab88d7aa957cbc03ec859b2e6ba
Depends-On: https://review.openstack.org/634992
",git fetch https://review.opendev.org/openstack/devstack refs/changes/70/634070/3 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,37fe8f5c7e813827f9e11a9129481e8514f689a0,,# Test ,,2,0
openstack%2Fpuppet-mistral~master~I8f0f2483b7e86e6c029f51e7c5f63816b587dc1b,openstack/puppet-mistral,master,I8f0f2483b7e86e6c029f51e7c5f63816b587dc1b,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:17:58.000000000,2019-02-12 01:43:50.000000000,2019-02-12 01:43:50.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:17:58.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-9b2078d1c2e1d0db.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-mistral/commit/f550dfc05920f516f204aa516e509f48696cf36b', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I8f0f2483b7e86e6c029f51e7c5f63816b587dc1b\n'}]",0,635799,f550dfc05920f516f204aa516e509f48696cf36b,9,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I8f0f2483b7e86e6c029f51e7c5f63816b587dc1b
",git fetch https://review.opendev.org/openstack/puppet-mistral refs/changes/99/635799/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-9b2078d1c2e1d0db.yaml', 'manifests/db/mysql.pp']",3,f550dfc05920f516f204aa516e509f48696cf36b,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpython-cinderclient~master~Ie18427499c170ee315181040eaa0943f3fefed08,openstack/python-cinderclient,master,Ie18427499c170ee315181040eaa0943f3fefed08,Don't run DSVM tests for doc changes,MERGED,2019-02-06 21:16:47.000000000,2019-02-12 01:41:50.000000000,2019-02-12 01:41:50.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 21:16:47.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2abfb558efe62221bc0593cc752e7bd7a45ea531', 'message': ""Don't run DSVM tests for doc changes\n\nDon't waste resources running the dsvm-functional tests on doc-only\nchanges.\n\nChange-Id: Ie18427499c170ee315181040eaa0943f3fefed08\n""}]",0,635316,2abfb558efe62221bc0593cc752e7bd7a45ea531,8,2,1,5314,,,0,"Don't run DSVM tests for doc changes

Don't waste resources running the dsvm-functional tests on doc-only
changes.

Change-Id: Ie18427499c170ee315181040eaa0943f3fefed08
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/16/635316/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2abfb558efe62221bc0593cc752e7bd7a45ea531,no-dsvm-for-doc-changes, irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^releasenotes/.*$,,8,1
openstack%2Foctavia-dashboard~master~I19bb41e3a5efd332a72bd269f0b214c7fa1f558f,openstack/octavia-dashboard,master,I19bb41e3a5efd332a72bd269f0b214c7fa1f558f,Deprecated error method,ABANDONED,2018-01-29 11:35:55.000000000,2019-02-12 01:39:11.000000000,,"[{'_account_id': 2245}, {'_account_id': 14151}, {'_account_id': 22348}, {'_account_id': 25740}]","[{'number': 1, 'created': '2018-01-29 11:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/6b37558d51bca8f123214daa5b4ae8cb6ee3a4d5', 'message': ""Deprecated error method\n\n$http's deprecated custom callback method: .error() has been\nremoved in AngularJS 1.6. Use the standard .catch() promise\nmethod instead.\n\nChange-Id: I19bb41e3a5efd332a72bd269f0b214c7fa1f558f\n""}, {'number': 2, 'created': '2018-02-07 06:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/40b9151d8ef15d480cbb213db6bacaf680da1c43', 'message': ""Deprecated error method\n\n$http's deprecated custom callback method: .error() has been\nremoved in AngularJS 1.6. Use the standard .catch() promise\nmethod instead.\n\nChange-Id: I19bb41e3a5efd332a72bd269f0b214c7fa1f558f\n""}, {'number': 3, 'created': '2018-02-07 07:15:04.000000000', 'files': ['octavia_dashboard/static/app/core/openstack-service-api/lbaasv2.service.js', 'package.json', 'octavia_dashboard/static/app/core/openstack-service-api/barbican.service.js'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/10a7dad061530792b55c2cde656cee89f944ce43', 'message': ""Deprecated error method\n\n$http's deprecated custom callback method: .error() has been\nremoved in AngularJS 1.6. Use the standard .catch() promise\nmethod instead.\n\nChange-Id: I19bb41e3a5efd332a72bd269f0b214c7fa1f558f\n""}]",1,538885,10a7dad061530792b55c2cde656cee89f944ce43,27,4,3,25740,,,0,"Deprecated error method

$http's deprecated custom callback method: .error() has been
removed in AngularJS 1.6. Use the standard .catch() promise
method instead.

Change-Id: I19bb41e3a5efd332a72bd269f0b214c7fa1f558f
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/85/538885/2 && git format-patch -1 --stdout FETCH_HEAD,['octavia_dashboard/static/app/core/openstack-service-api/lbaasv2.service.js'],1,6b37558d51bca8f123214daa5b4ae8cb6ee3a4d5,ErrorMethod, .catch(function () { .catch(function () { return quiet ? promise : promise.catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { return quiet ? promise : promise.catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { return quiet ? promise : promise.catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { .catch(function () { return quiet ? promise : promise.catch(function () { .catch(function () {, .error(function () { .error(function () { return quiet ? promise : promise.error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { return quiet ? promise : promise.error(function () { .error(function () { .error(function () { .error(function () { .error(function () { return quiet ? promise : promise.error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { .error(function () { return quiet ? promise : promise.error(function () { .error(function () {,25,25
openstack%2Fpuppet-keystone~stable%2Frocky~I46ec675fb959c5d1b8f9cbf300e480026e803a66,openstack/puppet-keystone,stable/rocky,I46ec675fb959c5d1b8f9cbf300e480026e803a66,Add a LDAP param group_members_are_ids,MERGED,2019-02-05 10:13:59.000000000,2019-02-12 01:39:08.000000000,2019-02-12 01:39:08.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 16339}, {'_account_id': 22348}, {'_account_id': 28522}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-02-05 10:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b7ec54cdc10fe5048b2de34236e775c41c0c9165', 'message': 'Add a LDAP param group_members_are_ids\n\nEnable this option if the members of the group\nobject class are keystone user IDs rather than LDAP DNs.\nThis is thecase when using posixGroup as the group object\nclass in Open Directory.\n\nCloses-Bug: #1805801\n\nChange-Id: I46ec675fb959c5d1b8f9cbf300e480026e803a66\nSigned-off-by: Cyril Lopez <cylopez@redhat.com>\n'}, {'number': 2, 'created': '2019-02-06 14:38:34.000000000', 'files': ['manifests/ldap_backend.pp', 'spec/classes/keystone_ldap_spec.rb', 'spec/defines/keystone_ldap_backend_spec.rb', 'manifests/ldap.pp', 'releasenotes/notes/add-group_members_are_ids-7decbef235d0afd8.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/5ca014bee9e6632825389fb13fe53b245de5516d', 'message': 'Add a LDAP param group_members_are_ids\n\nEnable this option if the members of the group\nobject class are keystone user IDs rather than LDAP DNs.\nThis is thecase when using posixGroup as the group object\nclass in Open Directory.\n\nCloses-Bug: #1805801\n\nChange-Id: I46ec675fb959c5d1b8f9cbf300e480026e803a66\nSigned-off-by: Cyril Lopez <cylopez@redhat.com>\n(cherry picked from commit 4fae828a981a688f27b110ce9d8acca558495b89)\n'}]",0,634902,5ca014bee9e6632825389fb13fe53b245de5516d,21,7,2,29222,,,0,"Add a LDAP param group_members_are_ids

Enable this option if the members of the group
object class are keystone user IDs rather than LDAP DNs.
This is thecase when using posixGroup as the group object
class in Open Directory.

Closes-Bug: #1805801

Change-Id: I46ec675fb959c5d1b8f9cbf300e480026e803a66
Signed-off-by: Cyril Lopez <cylopez@redhat.com>
(cherry picked from commit 4fae828a981a688f27b110ce9d8acca558495b89)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/02/634902/2 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/ldap_backend.pp', 'spec/classes/keystone_ldap_spec.rb', 'spec/defines/keystone_ldap_backend_spec.rb', 'manifests/ldap.pp', 'releasenotes/notes/add-group_members_are_ids-7decbef235d0afd8.yaml']",5,b7ec54cdc10fe5048b2de34236e775c41c0c9165,bug/1805801,"--- features: - | In Keystone, we can set group_members_are_ids option. This parameter enables the members of the group object class to be keystone user IDs rather than LDAP DNs. This is the case when using posixGroup as the group object class in Open Directory. ",,23,0
openstack%2Foctavia-dashboard~master~I9bfe2270c02d8da06bfda7c1f5e4f4689909c7eb,openstack/octavia-dashboard,master,I9bfe2270c02d8da06bfda7c1f5e4f4689909c7eb,Add postinstall in tox.ini,ABANDONED,2018-02-07 03:11:34.000000000,2019-02-12 01:38:43.000000000,,"[{'_account_id': 2245}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 25740}]","[{'number': 1, 'created': '2018-02-07 03:11:34.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/e668e4e50737f28cfcd22b1de42fb3e50ed8a2ed', 'message': 'Add postinstall in tox.ini\n\nAdd ""npm run postinstall"" in tox.ini to prevent errors when\nrunning tox -e karma. The error messages can be found at:\nhttp://paste.openstack.org/show/662024/\n\nChange-Id: I9bfe2270c02d8da06bfda7c1f5e4f4689909c7eb\n'}]",0,541526,e668e4e50737f28cfcd22b1de42fb3e50ed8a2ed,6,6,1,25740,,,0,"Add postinstall in tox.ini

Add ""npm run postinstall"" in tox.ini to prevent errors when
running tox -e karma. The error messages can be found at:
http://paste.openstack.org/show/662024/

Change-Id: I9bfe2270c02d8da06bfda7c1f5e4f4689909c7eb
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/26/541526/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e668e4e50737f28cfcd22b1de42fb3e50ed8a2ed,ToxFix, npm run postinstall,,1,0
openstack%2Fosc-lib~master~Iaf455860cf8e016390b258fbce16f83ba11101fc,openstack/osc-lib,master,Iaf455860cf8e016390b258fbce16f83ba11101fc,Change openstack-dev to openstack-discuss,MERGED,2018-12-04 17:05:47.000000000,2019-02-12 01:32:50.000000000,2019-02-12 01:32:50.000000000,"[{'_account_id': 970}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26297}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-12-04 17:05:47.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/9f48a7faeeb408cd72b26d7b835dc3618ab7917b', 'message': 'Change openstack-dev to openstack-discuss\n\nMailinglists have been updated. Openstack-discuss replaces openstack-dev.\n\nChange-Id: Iaf455860cf8e016390b258fbce16f83ba11101fc\n'}]",0,622433,9f48a7faeeb408cd72b26d7b835dc3618ab7917b,14,5,1,17499,,,0,"Change openstack-dev to openstack-discuss

Mailinglists have been updated. Openstack-discuss replaces openstack-dev.

Change-Id: Iaf455860cf8e016390b258fbce16f83ba11101fc
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/33/622433/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,9f48a7faeeb408cd72b26d7b835dc3618ab7917b,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Fopenstack-ansible~stable%2Fqueens~Id4aad165504a1e25f6a4d2c2d41824fc4b31e25c,openstack/openstack-ansible,stable/queens,Id4aad165504a1e25f6a4d2c2d41824fc4b31e25c,Update Octavia SHA to the 2.0.4 release,ABANDONED,2019-02-07 00:21:15.000000000,2019-02-12 01:20:24.000000000,,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 00:21:15.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bf05f63eb7068ff206b0025c3078d1b631a6fb77', 'message': 'Update Octavia SHA to the 2.0.4 release\n\nThis patch updates the Octavia SHA to pull in the 2.0.4 release patches.\n\nChange-Id: Id4aad165504a1e25f6a4d2c2d41824fc4b31e25c\n'}]",0,635376,bf05f63eb7068ff206b0025c3078d1b631a6fb77,4,2,1,11628,,,0,"Update Octavia SHA to the 2.0.4 release

This patch updates the Octavia SHA to pull in the 2.0.4 release patches.

Change-Id: Id4aad165504a1e25f6a4d2c2d41824fc4b31e25c
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/76/635376/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,bf05f63eb7068ff206b0025c3078d1b631a6fb77,,octavia_git_install_branch: de64db8e7bcd32d6da550109798bba5cfe3dbe2f # HEAD as of 06.02.2019,octavia_git_install_branch: 36e138cd1122d1a14959677e820451310627217a # HEAD as of 26.01.2019,1,1
openstack%2Fpuppet-senlin~master~I54801e76aed59c648a3da829d8d7fc90a81f36d4,openstack/puppet-senlin,master,I54801e76aed59c648a3da829d8d7fc90a81f36d4,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:37:55.000000000,2019-02-12 01:16:06.000000000,2019-02-12 01:16:06.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:37:55.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-senlin/commit/a366a56ed0217fb11bae125d4d6dc05f2cf3d870', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I54801e76aed59c648a3da829d8d7fc90a81f36d4\n'}]",0,635771,a366a56ed0217fb11bae125d4d6dc05f2cf3d870,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I54801e76aed59c648a3da829d8d7fc90a81f36d4
",git fetch https://review.opendev.org/openstack/puppet-senlin refs/changes/71/635771/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,a366a56ed0217fb11bae125d4d6dc05f2cf3d870,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-senlin~master~I543b73086ba88c1cecf176a45f4596c837c03469,openstack/puppet-senlin,master,I543b73086ba88c1cecf176a45f4596c837c03469,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:28:10.000000000,2019-02-12 01:16:05.000000000,2019-02-12 01:16:05.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:28:10.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4cca3d1b4c9bbcb4.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-senlin/commit/5862682e2ec42086c069c41fddcf35525c3bd1b4', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I543b73086ba88c1cecf176a45f4596c837c03469\n'}]",0,635809,5862682e2ec42086c069c41fddcf35525c3bd1b4,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I543b73086ba88c1cecf176a45f4596c837c03469
",git fetch https://review.opendev.org/openstack/puppet-senlin refs/changes/09/635809/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4cca3d1b4c9bbcb4.yaml', 'manifests/db/mysql.pp']",3,5862682e2ec42086c069c41fddcf35525c3bd1b4,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Ftripleo-common~stable%2Fqueens~Ic7ad351a7d564819bc8967045e6a227f158a9ae1,openstack/tripleo-common,stable/queens,Ic7ad351a7d564819bc8967045e6a227f158a9ae1,Handle case change for dmidecode >= 3.1 in ceph-ansible workbook,MERGED,2019-02-06 15:41:34.000000000,2019-02-12 01:01:02.000000000,2019-02-11 19:24:10.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-02-06 15:41:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9932f4a8174d8197748534fd0b75d1524dab6506', 'message': 'Handle case change for dmidecode >= 3.1 in ceph-ansible workbook\n\nForced lowercase on the dmidecode output and added a task inside\nthe workflow to manipulate the node_data_lookup parameter\n(lowercase enforcing).\n\nChange-Id: Ic7ad351a7d564819bc8967045e6a227f158a9ae1\nCo-Authored-By: Giulio Fidente <gfidente@redhat.com>\nCloses-Bug: 1814070\n'}, {'number': 2, 'created': '2019-02-07 09:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/68aa90ff5b77b089e1238f778e8acc5b26cc5aba', 'message': 'Handle case change for dmidecode >= 3.1 in ceph-ansible workbook\n\nForced lowercase on the dmidecode output matching the UUID\nformat returned if SMBIOS is updated and added a task inside\nthe workflow to manipulate the node_data_lookup parameter\n(lowercase enforcing).\n\nChange-Id: Ic7ad351a7d564819bc8967045e6a227f158a9ae1\nCo-Authored-By: Giulio Fidente <gfidente@redhat.com>\nCloses-Bug: 1814070\n'}, {'number': 3, 'created': '2019-02-08 13:48:28.000000000', 'files': ['workbooks/ceph-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/aa92a7f71755c6652e45a343f046d01ea1cbbe8b', 'message': 'Handle case change for dmidecode >= 3.1 in ceph-ansible workbook\n\nForced lowercase on the dmidecode output matching the UUID\nformat returned if SMBIOS is updated and added a task inside\nthe workflow to manipulate the node_data_lookup parameter\n(lowercase enforcing).\n\nChange-Id: Ic7ad351a7d564819bc8967045e6a227f158a9ae1\nCo-Authored-By: Giulio Fidente <gfidente@redhat.com>\nCloses-Bug: 1814070\n'}]",5,635193,aa92a7f71755c6652e45a343f046d01ea1cbbe8b,25,7,3,25402,,,0,"Handle case change for dmidecode >= 3.1 in ceph-ansible workbook

Forced lowercase on the dmidecode output matching the UUID
format returned if SMBIOS is updated and added a task inside
the workflow to manipulate the node_data_lookup parameter
(lowercase enforcing).

Change-Id: Ic7ad351a7d564819bc8967045e6a227f158a9ae1
Co-Authored-By: Giulio Fidente <gfidente@redhat.com>
Closes-Bug: 1814070
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/93/635193/2 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/ceph-ansible.yaml'],1,9932f4a8174d8197748534fd0b75d1524dab6506,bug/1814070," command: dmidecode -s system-uuid | tr A-F a-f on-success: - uuid_force_lowercase uuid_force_lowercase: publish: node_data: <% dict($.json_node_data_lookup.keys().select($.toLower()).zip($.json_node_data_lookup.values())) %> ips_data: <% let(uuids => $.ip_uuids, root => $) -> $.ips_list.toDict($, $root.node_data.get($uuids.get($, ""NO-UUID-FOUND""), {})) %>"," command: dmidecode -s system-uuid ips_data: <% let(uuids => $.ip_uuids, root => $) -> $.ips_list.toDict($, $root.json_node_data_lookup.get($uuids.get($, ""NO-UUID-FOUND""), {})) %>",7,2
openstack%2Fproject-config~master~If07c74d590acaed82c577d547dcc97f715e9d8e6,openstack/project-config,master,If07c74d590acaed82c577d547dcc97f715e9d8e6,Add more whitespace to zuul tenant config,MERGED,2019-02-11 23:28:33.000000000,2019-02-12 00:04:50.000000000,2019-02-11 23:52:54.000000000,"[{'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 23:28:33.000000000', 'files': ['zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4006e6c7785a42d38b78a27e3424255e81c1a828', 'message': 'Add more whitespace to zuul tenant config\n\nThere was a critical whitespace shortage which causes an invalid\nconfiguration.\n\nChange-Id: If07c74d590acaed82c577d547dcc97f715e9d8e6\n'}]",0,636237,4006e6c7785a42d38b78a27e3424255e81c1a828,7,2,1,1,,,0,"Add more whitespace to zuul tenant config

There was a critical whitespace shortage which causes an invalid
configuration.

Change-Id: If07c74d590acaed82c577d547dcc97f715e9d8e6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/37/636237/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,4006e6c7785a42d38b78a27e3424255e81c1a828,, include: - job - secret, include: - job - secret,3,3
openstack%2Ftripleo-repos~master~I938cb43a518c709ebbf5fefc2a91fa8cb0de85d6,openstack/tripleo-repos,master,I938cb43a518c709ebbf5fefc2a91fa8cb0de85d6,Fix unit test execution on Fedora 28,MERGED,2019-02-11 15:12:13.000000000,2019-02-11 23:49:24.000000000,2019-02-11 23:49:24.000000000,"[{'_account_id': 6928}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 15:12:13.000000000', 'files': ['tripleo_repos/tests/test_main.py'], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/e6b0badef24707cc1878416327e2b108f7e16fce', 'message': 'Fix unit test execution on Fedora 28\n\n[1] enabled OS auto-detection, however when unit tests are run on\nFedora 28 (for example, for packaging),\ntripleo_repos.tests.test_main.TestTripleORepos.test_main fails\nbecause _install_priorities is not called, due to auto-detection.\n\n[1] - https://review.openstack.org/635475\n\nChange-Id: I938cb43a518c709ebbf5fefc2a91fa8cb0de85d6\n'}]",0,636149,e6b0badef24707cc1878416327e2b108f7e16fce,8,4,1,13294,,,0,"Fix unit test execution on Fedora 28

[1] enabled OS auto-detection, however when unit tests are run on
Fedora 28 (for example, for packaging),
tripleo_repos.tests.test_main.TestTripleORepos.test_main fails
because _install_priorities is not called, due to auto-detection.

[1] - https://review.openstack.org/635475

Change-Id: I938cb43a518c709ebbf5fefc2a91fa8cb0de85d6
",git fetch https://review.opendev.org/openstack/tripleo-repos refs/changes/49/636149/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_repos/tests/test_main.py'],1,e6b0badef24707cc1878416327e2b108f7e16fce,," @mock.patch('sys.argv', ['tripleo-repos', 'current', '-d', 'centos7'])"," @mock.patch('sys.argv', ['tripleo-repos', 'current'])",1,1
openstack%2Ftripleo-image-elements~master~I83a5c1de989dbbcea186d40cb423ae188ca56f8e,openstack/tripleo-image-elements,master,I83a5c1de989dbbcea186d40cb423ae188ca56f8e,Update min tox version to 2.0,MERGED,2018-11-02 14:51:28.000000000,2019-02-11 23:43:57.000000000,2019-02-11 23:43:57.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 29222}]","[{'number': 1, 'created': '2018-11-02 14:51:28.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/0cdcd5d572202d740847d7f7b677111c2856919c', 'message': 'Update min tox version to 2.0\n\nThe commands used by constraints need at least tox 2.0.\nUpdate to reflect reality, which should help with local running of\nconstraints targets.\n\nChange-Id: I83a5c1de989dbbcea186d40cb423ae188ca56f8e\n'}]",0,615203,0cdcd5d572202d740847d7f7b677111c2856919c,9,4,1,28956,,,0,"Update min tox version to 2.0

The commands used by constraints need at least tox 2.0.
Update to reflect reality, which should help with local running of
constraints targets.

Change-Id: I83a5c1de989dbbcea186d40cb423ae188ca56f8e
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/03/615203/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0cdcd5d572202d740847d7f7b677111c2856919c,min-tox-version,minversion = 2.0,minversion = 1.6,1,1
openstack%2Ftripleo-heat-templates~master~I54e7730e6adaf3319819e0ba8e8275d315ee4812,openstack/tripleo-heat-templates,master,I54e7730e6adaf3319819e0ba8e8275d315ee4812,Fix Chinese quotes,MERGED,2018-11-24 07:34:44.000000000,2019-02-11 23:36:59.000000000,2019-02-11 23:36:59.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25747}, {'_account_id': 27549}]","[{'number': 1, 'created': '2018-11-24 07:34:44.000000000', 'files': ['releasenotes/notes/6.0.0-b52a14a71fc62788.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f252778d6c877fc85dbdf23fafa1d22396061681', 'message': 'Fix Chinese quotes\n\nChange-Id: I54e7730e6adaf3319819e0ba8e8275d315ee4812\n'}]",0,619864,f252778d6c877fc85dbdf23fafa1d22396061681,10,5,1,25747,,,0,"Fix Chinese quotes

Change-Id: I54e7730e6adaf3319819e0ba8e8275d315ee4812
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/64/619864/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/6.0.0-b52a14a71fc62788.yaml'],1,f252778d6c877fc85dbdf23fafa1d22396061681,," displays an 'Admin Password' field on the ""Change Password"" form to verify", displays an Admin Password field on the Change Password form to verify,1,1
openstack%2Ftripleo-heat-templates~master~I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b,openstack/tripleo-heat-templates,master,I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b,Push some NodeDataLookup in scenario001,MERGED,2019-01-31 16:26:58.000000000,2019-02-11 23:18:19.000000000,2019-02-11 23:18:19.000000000,"[{'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 18002}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-31 16:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/83b51971bd4ac79f65d72abe0fad46bff8497ba2', 'message': 'DO-NOT-MERGE: maybe yes, but now please test yaml NodeDataLookup anyway\n\nChange-Id: I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b\n'}, {'number': 2, 'created': '2019-02-06 14:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7efe2aedbba8194b52e28f6e1268013f728bebce', 'message': 'DO-NOT-MERGE: maybe yes, but now please test yaml NodeDataLookup anyway\n\nChange-Id: I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b\n'}, {'number': 3, 'created': '2019-02-06 14:20:08.000000000', 'files': ['ci/environments/scenario001-standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/93f52976440e80d3998c022bf5e97487cfa5f447', 'message': ""Push some NodeDataLookup in scenario001\n\nWhile we don't have tests to verify if the NodeDataLookup is correctly\npopulated into the ansible host vars, we can still push some value\nto make sure the existing code which parses and consumes it doesn't\nbreak.\n\nChange-Id: I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b\n""}]",0,634262,93f52976440e80d3998c022bf5e97487cfa5f447,20,5,3,6796,,,0,"Push some NodeDataLookup in scenario001

While we don't have tests to verify if the NodeDataLookup is correctly
populated into the ansible host vars, we can still push some value
to make sure the existing code which parses and consumes it doesn't
break.

Change-Id: I2782f4b3cbb9cd6f5c5819f6bb27d62ace8ecd3b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/634262/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario001-standalone.yaml'],1,83b51971bd4ac79f65d72abe0fad46bff8497ba2,bug/1814070," NodeDataLookup: AB4114B1-9C9D-409A-BEFB-D88C151BF2C3: {""foo"": ""bar""} 8CF1A7EA-7B4B-4433-AC83-17675514B1B8: {""foo2"": ""bar2""}",,3,0
openstack%2Fcharm-ceph-radosgw~master~I749698474b0647778b4e4850db234179bb5cec42,openstack/charm-ceph-radosgw,master,I749698474b0647778b4e4850db234179bb5cec42,Update functional test definitions,MERGED,2019-02-06 20:47:42.000000000,2019-02-11 23:12:28.000000000,2019-02-11 23:12:28.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:47:42.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/abfda164b4ca8ccaf7ac7c6876b32c5184653917', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I749698474b0647778b4e4850db234179bb5cec42\n'}]",0,635285,abfda164b4ca8ccaf7ac7c6876b32c5184653917,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I749698474b0647778b4e4850db234179bb5cec42
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/85/635285/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,abfda164b4ca8ccaf7ac7c6876b32c5184653917,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic ceph-radosgw deployment on trusty-icehouse."""""" from basic_deployment import CephRadosGwBasicDeployment if __name__ == '__main__': deployment = CephRadosGwBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-rabbitmq-server~master~I79424c8f6ea2882d16767fec87998edbb04c9254,openstack/charm-rabbitmq-server,master,I79424c8f6ea2882d16767fec87998edbb04c9254,Update functional test definitions,MERGED,2019-02-06 20:50:13.000000000,2019-02-11 23:11:43.000000000,2019-02-11 23:11:43.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:50:13.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/e90d2f3e9fc10749c87bf3bef4f79d45da944d9d', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I79424c8f6ea2882d16767fec87998edbb04c9254\n'}]",0,635304,e90d2f3e9fc10749c87bf3bef4f79d45da944d9d,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I79424c8f6ea2882d16767fec87998edbb04c9254
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/04/635304/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,e90d2f3e9fc10749c87bf3bef4f79d45da944d9d,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic rabbitmq-server deployment on trusty-icehouse."""""" from basic_deployment import RmqBasicDeployment if __name__ == '__main__': deployment = RmqBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-ceph-mon~master~I1defa1fcaf792afa64b2f52ed486a8881c737a0f,openstack/charm-ceph-mon,master,I1defa1fcaf792afa64b2f52ed486a8881c737a0f,Update functional test definitions,MERGED,2019-02-06 20:47:24.000000000,2019-02-11 23:10:28.000000000,2019-02-11 23:10:28.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:47:24.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/23bad4d905682a6f25877e02e6602a953d24ffa0', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I1defa1fcaf792afa64b2f52ed486a8881c737a0f\n'}]",0,635283,23bad4d905682a6f25877e02e6602a953d24ffa0,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I1defa1fcaf792afa64b2f52ed486a8881c737a0f
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/83/635283/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,23bad4d905682a6f25877e02e6602a953d24ffa0,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic ceph deployment on trusty-icehouse."""""" from basic_deployment import CephBasicDeployment if __name__ == '__main__': deployment = CephBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-hacluster~master~I7c5001cd7506932ef9168126e9f62f3ca0b3fe66,openstack/charm-hacluster,master,I7c5001cd7506932ef9168126e9f62f3ca0b3fe66,Update functional test definitions,MERGED,2019-02-06 20:48:32.000000000,2019-02-11 23:10:27.000000000,2019-02-11 23:10:27.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:32.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/a737bbcc031c52706940fe1670f319207c565ce2', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I7c5001cd7506932ef9168126e9f62f3ca0b3fe66\n'}]",0,635292,a737bbcc031c52706940fe1670f319207c565ce2,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I7c5001cd7506932ef9168126e9f62f3ca0b3fe66
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/92/635292/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,a737bbcc031c52706940fe1670f319207c565ce2,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic hacluster deployment on trusty-icehouse."""""" from basic_deployment import HAClusterBasicDeployment if __name__ == '__main__': deployment = HAClusterBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-glance-simplestreams-sync~master~I0fcb86bdf46f203fc5e4ba062516b4babb63f795,openstack/charm-glance-simplestreams-sync,master,I0fcb86bdf46f203fc5e4ba062516b4babb63f795,Update functional test definitions,MERGED,2019-02-06 20:48:23.000000000,2019-02-11 23:10:27.000000000,2019-02-11 23:10:27.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-glance-simplestreams-sync/commit/85c009d75fd78284ab15ecd05563b09b7558687f', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I0fcb86bdf46f203fc5e4ba062516b4babb63f795\n'}, {'number': 2, 'created': '2019-02-11 22:14:27.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-glance-simplestreams-sync/commit/77e472061ee54d8fb059122555149c90d3b084ac', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I0fcb86bdf46f203fc5e4ba062516b4babb63f795\n'}]",0,635290,77e472061ee54d8fb059122555149c90d3b084ac,10,3,2,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I0fcb86bdf46f203fc5e4ba062516b4babb63f795
",git fetch https://review.opendev.org/openstack/charm-glance-simplestreams-sync refs/changes/90/635290/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-trusty-icehouse', 'tests/gate-basic-bionic-rocky']",2,85c009d75fd78284ab15ecd05563b09b7558687f,update-func-defs,,,0,23
openstack%2Fcharm-ceilometer~master~Id14d83ae5a2dcb31267270ac5dacb2015708c756,openstack/charm-ceilometer,master,Id14d83ae5a2dcb31267270ac5dacb2015708c756,Update functional test definitions,MERGED,2019-02-06 20:47:07.000000000,2019-02-11 23:10:26.000000000,2019-02-11 23:10:26.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:47:07.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/e761ad36b8b92a2a81026ceffea85d6716c71f68', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Id14d83ae5a2dcb31267270ac5dacb2015708c756\n'}]",0,635280,e761ad36b8b92a2a81026ceffea85d6716c71f68,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Id14d83ae5a2dcb31267270ac5dacb2015708c756
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/80/635280/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,e761ad36b8b92a2a81026ceffea85d6716c71f68,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic ceilometer deployment on trusty-icehouse."""""" from basic_deployment import CeilometerBasicDeployment if __name__ == '__main__': deployment = CeilometerBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-swift-proxy~master~I533658c658a69b6f19e35d94c9a4ca4e2d655c7f,openstack/charm-swift-proxy,master,I533658c658a69b6f19e35d94c9a4ca4e2d655c7f,Update functional test definitions,MERGED,2019-02-06 20:50:22.000000000,2019-02-11 23:10:25.000000000,2019-02-11 23:10:25.000000000,"[{'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/e54ee6bb100df10253b94efe9836ac0e1c035be8', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I533658c658a69b6f19e35d94c9a4ca4e2d655c7f\n'}, {'number': 2, 'created': '2019-02-11 22:11:43.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/9e5a3b22efae09c213e8b69f1c298b16b6765f57', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I533658c658a69b6f19e35d94c9a4ca4e2d655c7f\n'}]",0,635305,9e5a3b22efae09c213e8b69f1c298b16b6765f57,10,3,2,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I533658c658a69b6f19e35d94c9a4ca4e2d655c7f
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/05/635305/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/dev-basic-cosmic-rocky'],1,e54ee6bb100df10253b94efe9836ac0e1c035be8,update-func-defs,"""""""Amulet tests on a basic swift-proxy deployment on cosmic-rocky."""""" deployment = SwiftProxyBasicDeployment(series='cosmic')","""""""Amulet tests on a basic swift-proxy deployment on trusty-icehouse."""""" deployment = SwiftProxyBasicDeployment(series='trusty')",2,2
openstack%2Fcharm-cinder-ceph~master~I564d55b43fa466d3f1087302c2a2f67a477effc1,openstack/charm-cinder-ceph,master,I564d55b43fa466d3f1087302c2a2f67a477effc1,Update functional test definitions,MERGED,2019-02-06 20:48:05.000000000,2019-02-11 23:10:25.000000000,2019-02-11 23:10:24.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:05.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-cinder-ceph/commit/f29b3b91e5418e370263871e528520886d550c5c', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I564d55b43fa466d3f1087302c2a2f67a477effc1\n'}]",0,635288,f29b3b91e5418e370263871e528520886d550c5c,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I564d55b43fa466d3f1087302c2a2f67a477effc1
",git fetch https://review.opendev.org/openstack/charm-cinder-ceph refs/changes/88/635288/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,f29b3b91e5418e370263871e528520886d550c5c,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic cinder-ceph deployment on trusty-icehouse."""""" from basic_deployment import CinderCephBasicDeployment if __name__ == '__main__': deployment = CinderCephBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fpuppet-glance~master~Ic83677a569ece443620cf991b64d356352fd8de7,openstack/puppet-glance,master,Ic83677a569ece443620cf991b64d356352fd8de7,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:08:57.000000000,2019-02-11 23:10:24.000000000,2019-02-11 23:10:24.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:08:57.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-c9dc054baa43c0ed.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9b9d5ae57ef44f858734a834da8acd32cf32d5e8', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ic83677a569ece443620cf991b64d356352fd8de7\n'}]",0,635791,9b9d5ae57ef44f858734a834da8acd32cf32d5e8,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ic83677a569ece443620cf991b64d356352fd8de7
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/91/635791/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-c9dc054baa43c0ed.yaml', 'manifests/db/mysql.pp']",3,9b9d5ae57ef44f858734a834da8acd32cf32d5e8,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fcharm-keystone~master~If68e9c5a6ddbc12176f22e9d777e5c8c76faf7c5,openstack/charm-keystone,master,If68e9c5a6ddbc12176f22e9d777e5c8c76faf7c5,Update functional test definitions,MERGED,2019-02-06 20:49:31.000000000,2019-02-11 23:09:15.000000000,2019-02-11 23:09:15.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/fd5c22d0a33f1e97b7d48e1a880517a7fdaf44c4', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: If68e9c5a6ddbc12176f22e9d777e5c8c76faf7c5\n'}, {'number': 2, 'created': '2019-02-06 20:50:24.000000000', 'files': ['tests/tests.yaml', 'tests/bundles/trusty-icehouse.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/07d798afa8775a06009c47fe646f7c0a92f1bb59', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: If68e9c5a6ddbc12176f22e9d777e5c8c76faf7c5\n'}]",0,635299,07d798afa8775a06009c47fe646f7c0a92f1bb59,10,4,2,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: If68e9c5a6ddbc12176f22e9d777e5c8c76faf7c5
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/99/635299/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/tests.yaml'],1,fd5c22d0a33f1e97b7d48e1a880517a7fdaf44c4,update-func-defs,,- trusty-icehouse,0,1
openstack%2Fopenstack-zuul-jobs~master~I27971ad1bd3ef93ea04aaede76e51afe9d770b5b,openstack/openstack-zuul-jobs,master,I27971ad1bd3ef93ea04aaede76e51afe9d770b5b,Remove configure-unbound role,MERGED,2019-02-08 17:51:24.000000000,2019-02-11 23:09:08.000000000,2019-02-11 23:09:08.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 17:51:24.000000000', 'files': ['roles/configure-unbound/defaults/main.yaml', 'roles/configure-unbound/templates/ttl.conf.j2', 'roles/configure-unbound/vars/default.yaml', 'roles/configure-unbound/templates/forwarding.conf.j2', 'roles/configure-unbound/handlers/main.yaml', 'roles/configure-unbound/README.rst', 'tests/configure-unbound.yaml', 'roles/configure-unbound/tasks/main.yaml', 'tests/base.yaml', 'zuul.d/jobs.yaml', 'roles/configure-unbound/vars/Debian.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/10405004a5a2f35d74e9023749613048e6aa1d39', 'message': 'Remove configure-unbound role\n\nThis role now lives in opendev/base-jobs so to reduce confusion we clean\nit out of ozj.\n\nDepends-On: https://review.openstack.org/635900\nChange-Id: I27971ad1bd3ef93ea04aaede76e51afe9d770b5b\n'}]",0,635901,10405004a5a2f35d74e9023749613048e6aa1d39,11,4,1,4146,,,0,"Remove configure-unbound role

This role now lives in opendev/base-jobs so to reduce confusion we clean
it out of ozj.

Depends-On: https://review.openstack.org/635900
Change-Id: I27971ad1bd3ef93ea04aaede76e51afe9d770b5b
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/01/635901/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/configure-unbound/defaults/main.yaml', 'roles/configure-unbound/templates/ttl.conf.j2', 'roles/configure-unbound/vars/default.yaml', 'roles/configure-unbound/templates/forwarding.conf.j2', 'roles/configure-unbound/handlers/main.yaml', 'roles/configure-unbound/README.rst', 'tests/configure-unbound.yaml', 'roles/configure-unbound/tasks/main.yaml', 'tests/base.yaml', 'zuul.d/jobs.yaml', 'roles/configure-unbound/vars/Debian.yaml']",11,10405004a5a2f35d74e9023749613048e6aa1d39,cleanup-configure-unbound,,unbound_confd: /etc/unbound/unbound.conf.d ,0,225
openstack%2Fcharm-neutron-gateway~master~I13262810105e68cf93d3df31a76c6f0f215cbcc1,openstack/charm-neutron-gateway,master,I13262810105e68cf93d3df31a76c6f0f215cbcc1,Update functional test definitions,MERGED,2019-02-06 20:49:14.000000000,2019-02-11 23:09:06.000000000,2019-02-11 23:09:05.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:14.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/2debccbdea351ebb7a9b79c33fc734b03e294128', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I13262810105e68cf93d3df31a76c6f0f215cbcc1\n'}]",0,635297,2debccbdea351ebb7a9b79c33fc734b03e294128,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I13262810105e68cf93d3df31a76c6f0f215cbcc1
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/97/635297/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,2debccbdea351ebb7a9b79c33fc734b03e294128,update-func-defs,,"#!/usr/bin/env python """"""Amulet tests on a basic quantum-gateway deployment on trusty-icehouse."""""" from basic_deployment import NeutronGatewayBasicDeployment if __name__ == '__main__': deployment = NeutronGatewayBasicDeployment(series='trusty') deployment.run_tests() ",0,9
openstack%2Fcharm-ceph-proxy~master~I12fb4a889e5358aac76e8c7d8f1663976e2b7185,openstack/charm-ceph-proxy,master,I12fb4a889e5358aac76e8c7d8f1663976e2b7185,Update functional test definitions,MERGED,2019-02-06 20:47:35.000000000,2019-02-11 23:07:59.000000000,2019-02-11 23:07:59.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:47:35.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/c5acc82fd2bbb16f083d4d09ac758bc04f513ea3', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I12fb4a889e5358aac76e8c7d8f1663976e2b7185\n'}]",0,635284,c5acc82fd2bbb16f083d4d09ac758bc04f513ea3,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I12fb4a889e5358aac76e8c7d8f1663976e2b7185
",git fetch https://review.opendev.org/openstack/charm-ceph-proxy refs/changes/84/635284/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,c5acc82fd2bbb16f083d4d09ac758bc04f513ea3,update-func-defs,,"#!/usr/bin/env python """"""Amulet tests on a basic ceph deployment on trusty-icehouse."""""" from basic_deployment import CephBasicDeployment if __name__ == '__main__': deployment = CephBasicDeployment(series='trusty') deployment.run_tests() ",0,9
openstack%2Fcharm-heat~master~I11b4facfc96a5eda9acbdba933f558174cdef156,openstack/charm-heat,master,I11b4facfc96a5eda9acbdba933f558174cdef156,Update functional test definitions,MERGED,2019-02-06 20:48:41.000000000,2019-02-11 23:07:56.000000000,2019-02-11 23:07:56.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:41.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/569897744bf8c7bc42446276ce736670ec9bd2d4', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I11b4facfc96a5eda9acbdba933f558174cdef156\n'}]",0,635293,569897744bf8c7bc42446276ce736670ec9bd2d4,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I11b4facfc96a5eda9acbdba933f558174cdef156
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/93/635293/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,569897744bf8c7bc42446276ce736670ec9bd2d4,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic heat deployment on trusty-icehouse."""""" from basic_deployment import HeatBasicDeployment if __name__ == '__main__': deployment = HeatBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-cinder~master~Ia2d5bee9903796b9788fe2e8320b4037c697d608,openstack/charm-cinder,master,Ia2d5bee9903796b9788fe2e8320b4037c697d608,Update functional test definitions,MERGED,2019-02-06 20:47:51.000000000,2019-02-11 23:07:29.000000000,2019-02-11 23:07:29.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:47:51.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-cinder/commit/4d985804b11663d63593c7479fb22c42d31416ad', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Ia2d5bee9903796b9788fe2e8320b4037c697d608\n'}]",0,635286,4d985804b11663d63593c7479fb22c42d31416ad,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Ia2d5bee9903796b9788fe2e8320b4037c697d608
",git fetch https://review.opendev.org/openstack/charm-cinder refs/changes/86/635286/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,4d985804b11663d63593c7479fb22c42d31416ad,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic Cinder deployment on trusty-icehouse."""""" from basic_deployment import CinderBasicDeployment if __name__ == '__main__': deployment = CinderBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-nova-compute~master~Id2d75d8e0edc7492f48b7cc4dacf619629a7eb83,openstack/charm-nova-compute,master,Id2d75d8e0edc7492f48b7cc4dacf619629a7eb83,Update functional test definitions,MERGED,2019-02-06 20:49:43.000000000,2019-02-11 23:07:24.000000000,2019-02-11 23:07:24.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:43.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/a3cac4e08007f346568ec5eaf8459a2730c35e6d', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Id2d75d8e0edc7492f48b7cc4dacf619629a7eb83\n'}]",0,635301,a3cac4e08007f346568ec5eaf8459a2730c35e6d,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Id2d75d8e0edc7492f48b7cc4dacf619629a7eb83
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/01/635301/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,a3cac4e08007f346568ec5eaf8459a2730c35e6d,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic nova compute deployment on trusty-icehouse."""""" from basic_deployment import NovaBasicDeployment if __name__ == '__main__': deployment = NovaBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-percona-cluster~master~I1ffafd2c64de7e62fbd5f53e7a87393078e74967,openstack/charm-percona-cluster,master,I1ffafd2c64de7e62fbd5f53e7a87393078e74967,Update functional test definitions,MERGED,2019-02-06 20:50:03.000000000,2019-02-11 23:06:46.000000000,2019-02-11 23:06:45.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:50:03.000000000', 'files': ['tests/gate-basic-trusty'], 'web_link': 'https://opendev.org/openstack/charm-percona-cluster/commit/b8ae801dde24882d0b745ce0e84d5fdd0fadaddf', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I1ffafd2c64de7e62fbd5f53e7a87393078e74967\n'}]",0,635303,b8ae801dde24882d0b745ce0e84d5fdd0fadaddf,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I1ffafd2c64de7e62fbd5f53e7a87393078e74967
",git fetch https://review.opendev.org/openstack/charm-percona-cluster refs/changes/03/635303/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty'],1,b8ae801dde24882d0b745ce0e84d5fdd0fadaddf,update-func-defs,,"#!/usr/bin/env python import basic_deployment if __name__ == ""__main__"": t = basic_deployment.BasicDeployment(units=3, series='trusty') t.run() ",0,8
openstack%2Fcharm-neutron-api~master~I2a384b5a2781b3c08685ed546c7ae0ecc8f20c60,openstack/charm-neutron-api,master,I2a384b5a2781b3c08685ed546c7ae0ecc8f20c60,Update functional test definitions,MERGED,2019-02-06 20:48:59.000000000,2019-02-11 23:06:23.000000000,2019-02-11 23:06:23.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:59.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/47d59207e813344bbc55123f0b4bfb05b5697b94', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I2a384b5a2781b3c08685ed546c7ae0ecc8f20c60\n'}]",0,635295,47d59207e813344bbc55123f0b4bfb05b5697b94,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I2a384b5a2781b3c08685ed546c7ae0ecc8f20c60
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/95/635295/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,47d59207e813344bbc55123f0b4bfb05b5697b94,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic neutron-api deployment on trusty-icehouse."""""" from basic_deployment import NeutronAPIBasicDeployment if __name__ == '__main__': deployment = NeutronAPIBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-openstack-dashboard~master~Ifc4263a56a35e698421e02bad786a7d1bee13e90,openstack/charm-openstack-dashboard,master,Ifc4263a56a35e698421e02bad786a7d1bee13e90,Update functional test definitions,MERGED,2019-02-06 20:49:54.000000000,2019-02-11 23:05:47.000000000,2019-02-11 23:05:47.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:54.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/693d3c274d7b0152c882f8d33c3e4677bbe45c4f', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Ifc4263a56a35e698421e02bad786a7d1bee13e90\n'}]",0,635302,693d3c274d7b0152c882f8d33c3e4677bbe45c4f,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Ifc4263a56a35e698421e02bad786a7d1bee13e90
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/02/635302/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,693d3c274d7b0152c882f8d33c3e4677bbe45c4f,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic openstack-dashboard deployment on trusty-icehouse."""""" from basic_deployment import OpenstackDashboardBasicDeployment if __name__ == '__main__': deployment = OpenstackDashboardBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-glance~master~Ifbb43a8eb12b1fb499fd73b6c7d5d184c29feb0f,openstack/charm-glance,master,Ifbb43a8eb12b1fb499fd73b6c7d5d184c29feb0f,Update functional test definitions,MERGED,2019-02-06 20:48:16.000000000,2019-02-11 23:05:47.000000000,2019-02-11 23:05:47.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:16.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-glance/commit/a258eb812c5cd8191a50ab3b270c2b64405cd7e9', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Ifbb43a8eb12b1fb499fd73b6c7d5d184c29feb0f\n'}]",0,635289,a258eb812c5cd8191a50ab3b270c2b64405cd7e9,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Ifbb43a8eb12b1fb499fd73b6c7d5d184c29feb0f
",git fetch https://review.opendev.org/openstack/charm-glance refs/changes/89/635289/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,a258eb812c5cd8191a50ab3b270c2b64405cd7e9,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic Glance deployment on trusty-icehouse."""""" from basic_deployment import GlanceBasicDeployment if __name__ == '__main__': deployment = GlanceBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-ceph-osd~master~I478fdf4e9ab7a25ccd35c611f623cefc116f672c,openstack/charm-ceph-osd,master,I478fdf4e9ab7a25ccd35c611f623cefc116f672c,Update functional test definitions,MERGED,2019-02-06 20:48:54.000000000,2019-02-11 23:05:25.000000000,2019-02-11 23:05:25.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/a2d9a7356212b7e2fe1315a16f2cbd15dd3d36b0', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I478fdf4e9ab7a25ccd35c611f623cefc116f672c\n'}, {'number': 2, 'created': '2019-02-06 20:50:04.000000000', 'files': ['tests/tests.yaml', 'tests/bundles/trusty-icehouse.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/bce5aabcb7d3b33ef9a9b4d463ed006baae1a68e', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I478fdf4e9ab7a25ccd35c611f623cefc116f672c\n'}]",0,635294,bce5aabcb7d3b33ef9a9b4d463ed006baae1a68e,9,4,2,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I478fdf4e9ab7a25ccd35c611f623cefc116f672c
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/94/635294/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/tests.yaml'],1,a2d9a7356212b7e2fe1315a16f2cbd15dd3d36b0,update-func-defs,, - trusty-icehouse,0,1
openstack%2Fcharm-swift-storage~master~Ib35689b2bd24c8ecfe7a1bcd973387a898faaae9,openstack/charm-swift-storage,master,Ib35689b2bd24c8ecfe7a1bcd973387a898faaae9,Update functional test definitions,MERGED,2019-02-06 20:50:30.000000000,2019-02-11 23:04:52.000000000,2019-02-11 23:04:52.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:50:30.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/70051c6e48848b50fdac171e2683806c9501455a', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: Ib35689b2bd24c8ecfe7a1bcd973387a898faaae9\n'}]",0,635306,70051c6e48848b50fdac171e2683806c9501455a,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: Ib35689b2bd24c8ecfe7a1bcd973387a898faaae9
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/06/635306/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,70051c6e48848b50fdac171e2683806c9501455a,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic swift-storage deployment on trusty-icehouse."""""" from basic_deployment import SwiftStorageBasicDeployment if __name__ == '__main__': deployment = SwiftStorageBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-neutron-openvswitch~master~I828b2003679b58512667a18e64a95db5e1f63c9f,openstack/charm-neutron-openvswitch,master,I828b2003679b58512667a18e64a95db5e1f63c9f,Update functional test definitions,MERGED,2019-02-06 20:49:22.000000000,2019-02-11 23:04:04.000000000,2019-02-11 23:04:04.000000000,"[{'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:22.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-neutron-openvswitch/commit/17112893fbf106ca1c355bca30d4bfff601c556c', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I828b2003679b58512667a18e64a95db5e1f63c9f\n'}]",0,635298,17112893fbf106ca1c355bca30d4bfff601c556c,9,5,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I828b2003679b58512667a18e64a95db5e1f63c9f
",git fetch https://review.opendev.org/openstack/charm-neutron-openvswitch refs/changes/98/635298/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,17112893fbf106ca1c355bca30d4bfff601c556c,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic neutron-openvswitch deployment on trusty-icehouse."""""" from basic_deployment import NeutronOVSBasicDeployment if __name__ == '__main__': deployment = NeutronOVSBasicDeployment(series='trusty') deployment.run_tests() ",0,23
openstack%2Fcharm-nova-cloud-controller~master~I31c5b959bb977aa4928b77792a741ceba9fcf5cf,openstack/charm-nova-cloud-controller,master,I31c5b959bb977aa4928b77792a741ceba9fcf5cf,Update functional test definitions,MERGED,2019-02-06 20:49:33.000000000,2019-02-11 23:03:54.000000000,2019-02-11 23:03:54.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:49:33.000000000', 'files': ['tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/3585885f077b864afed50aa9c5de44f5a6084e38', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I31c5b959bb977aa4928b77792a741ceba9fcf5cf\n'}]",0,635300,3585885f077b864afed50aa9c5de44f5a6084e38,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I31c5b959bb977aa4928b77792a741ceba9fcf5cf
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/00/635300/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/gate-basic-trusty-icehouse'],1,3585885f077b864afed50aa9c5de44f5a6084e38,update-func-defs,,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic nova cloud controller deployment on trusty-icehouse."""""" from basic_deployment import NovaCCBasicDeployment if __name__ == '__main__': deployment = NovaCCBasicDeployment(series='trusty') deployment.run_tests() ",0,24
openstack%2Fosc-lib~master~I33424f75e8624b84cdee01fea004a9bf0c7e5edb,openstack/osc-lib,master,I33424f75e8624b84cdee01fea004a9bf0c7e5edb,Allow use of user-id as well as username for authentication,MERGED,2019-01-30 14:35:18.000000000,2019-02-11 23:01:38.000000000,2019-02-11 23:01:38.000000000,"[{'_account_id': 2}, {'_account_id': 841}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8482}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-01-30 14:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/82e8cdbd354e3119e29c260ec35470a6e8ce4f83', 'message': 'Allow use of user-id as well as username for authentication\n\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 2, 'created': '2019-01-30 14:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/c9c3d842f9f2acfaf2935d0a1e44248030ee1ccb', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 3, 'created': '2019-01-30 14:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/9fa0c8e4e7a3a478b92786b39653b285728c4a8d', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 4, 'created': '2019-01-30 16:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/a48698a44b2e987760cc95429c3dd93595672e6b', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 5, 'created': '2019-01-30 16:06:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/a2f38807362b619833f0d05f612281709a1b9a54', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 6, 'created': '2019-01-30 16:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/def99e5f4f0e0d15f866423d6af1e0066eda73b6', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 7, 'created': '2019-01-31 10:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/aedecc4ba3fbd104ab93885c6f28c79f84f1c99f', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\n'}, {'number': 8, 'created': '2019-02-04 18:54:14.000000000', 'files': ['osc_lib/api/auth.py', 'osc_lib/tests/fakes.py', 'osc_lib/tests/test_clientmanager.py', 'osc_lib/tests/cli/test_client_config.py'], 'web_link': 'https://opendev.org/openstack/osc-lib/commit/023779311bb3cd9ad3600b3f6edc2ea5c99b1855', 'message': 'Allow use of user-id as well as username for authentication\n\nStory: 2004898\nTask: 29210\nChange-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb\nDepends-On: https://review.openstack.org/#/c/634776/\n'}]",6,633964,023779311bb3cd9ad3600b3f6edc2ea5c99b1855,34,10,8,28022,,,0,"Allow use of user-id as well as username for authentication

Story: 2004898
Task: 29210
Change-Id: I33424f75e8624b84cdee01fea004a9bf0c7e5edb
Depends-On: https://review.openstack.org/#/c/634776/
",git fetch https://review.opendev.org/openstack/osc-lib refs/changes/64/633964/8 && git format-patch -1 --stdout FETCH_HEAD,['osc_lib/api/auth.py'],1,82e8cdbd354e3119e29c260ec35470a6e8ce4f83,story/2004898," if 'password' in plugin_opts and not (options.auth.get('username') or options.auth.get('user_id')): ' or set a user-id with --os-user-id, OS_USER_ID,' ' or auth.user_id'", if 'password' in plugin_opts and not options.auth.get('username'):,3,1
openstack%2Fcharm-tempest~master~I2a0b9e6e6ba5466e10fb46b08dd3bbc1afd732fa,openstack/charm-tempest,master,I2a0b9e6e6ba5466e10fb46b08dd3bbc1afd732fa,Update functional test definitions,MERGED,2019-02-06 20:50:36.000000000,2019-02-11 23:00:55.000000000,2019-02-11 23:00:55.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 20:50:36.000000000', 'files': ['src/tests/gate-basic-trusty-icehouse'], 'web_link': 'https://opendev.org/openstack/charm-tempest/commit/93f812057c8c3e8e3a3c57b59196a61d13301638', 'message': 'Update functional test definitions\n\nRemove trusty-icehouse test combo from gate, leaving trusty-mitaka\nif/where it exists.\n\nChange-Id: I2a0b9e6e6ba5466e10fb46b08dd3bbc1afd732fa\n'}]",0,635307,93f812057c8c3e8e3a3c57b59196a61d13301638,8,4,1,20635,,,0,"Update functional test definitions

Remove trusty-icehouse test combo from gate, leaving trusty-mitaka
if/where it exists.

Change-Id: I2a0b9e6e6ba5466e10fb46b08dd3bbc1afd732fa
",git fetch https://review.opendev.org/openstack/charm-tempest refs/changes/07/635307/1 && git format-patch -1 --stdout FETCH_HEAD,['src/tests/gate-basic-trusty-icehouse'],1,93f812057c8c3e8e3a3c57b59196a61d13301638,update-func-defs,,"#!/usr/bin/env python """"""Amulet tests on a basic tempest deployment on trusty-icehouse."""""" from basic_deployment import TempestBasicDeployment if __name__ == '__main__': deployment = TempestBasicDeployment(series='trusty') deployment.run_tests() ",0,10
openstack%2Ftripleo-docs~master~I0942dd73d13c24b8e53435ed6c75db8d2f0cabf2,openstack/tripleo-docs,master,I0942dd73d13c24b8e53435ed6c75db8d2f0cabf2,Add f28/py3 notes for standalone deployment,MERGED,2019-02-06 15:05:37.000000000,2019-02-11 23:00:33.000000000,2019-02-11 23:00:33.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-06 15:05:37.000000000', 'files': ['_custom/custom.css', 'doc/source/install/containers_deployment/standalone.rst', 'doc/source/install/repositories.txt'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/00536db091fec89628eceed870b075cf7586fa03', 'message': 'Add f28/py3 notes for standalone deployment\n\nAdds some notes to standalone deployment docs for fedora 28.\nPart of ci-squad task at [1]\n\n[1] https://tree.taiga.io/project/tripleo-ci-board/task/708\n\nChange-Id: I0942dd73d13c24b8e53435ed6c75db8d2f0cabf2\n'}]",1,635184,00536db091fec89628eceed870b075cf7586fa03,8,4,1,8449,,,0,"Add f28/py3 notes for standalone deployment

Adds some notes to standalone deployment docs for fedora 28.
Part of ci-squad task at [1]

[1] https://tree.taiga.io/project/tripleo-ci-board/task/708

Change-Id: I0942dd73d13c24b8e53435ed6c75db8d2f0cabf2
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/84/635184/1 && git format-patch -1 --stdout FETCH_HEAD,"['_custom/custom.css', 'doc/source/install/containers_deployment/standalone.rst', 'doc/source/install/repositories.txt']",3,00536db091fec89628eceed870b075cf7586fa03,,.. warning:: Support for Python3 is still experimental. The Fedora 28 specific notes and commands appearing below should not be taken as indication that this is fully supported by TripleO - we're still working on it! .. admonition:: Fedora 28 :class: fedora28 For Fedora 28 you will need to download the python3-tripleo-repos from https://trunk.rdoproject.org/fedora/current/:: sudo yum install -y https://trunk.rdoproject.org/fedora/current/python3-tripleo-repos-<version>.fc28.noarch.rpm .. admonition:: Fedora 28 :class: fedora28 Enable the current Fedora 28 repositories .. code-block:: bash sudo -E tripleo-repos -d fedora current .. admonition:: Ceph :class: ceph Include the Ceph repo in the tripleo-repos call .. code-block:: bash sudo -E tripleo-repos -d fedora current ceph,,50,0
openstack%2Fpuppet-glance~master~Ib190eb81190430f82dd1c6ca3a39752c05a95959,openstack/puppet-glance,master,Ib190eb81190430f82dd1c6ca3a39752c05a95959,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:26:59.000000000,2019-02-11 22:56:46.000000000,2019-02-11 22:56:46.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:26:59.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/2d8f2f4ebc09274d7f8d661704165a7299666882', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ib190eb81190430f82dd1c6ca3a39752c05a95959\n'}]",0,635747,2d8f2f4ebc09274d7f8d661704165a7299666882,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ib190eb81190430f82dd1c6ca3a39752c05a95959
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/47/635747/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,2d8f2f4ebc09274d7f8d661704165a7299666882,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-glance~master~I37baa79943063a66922a9f82a286583a091122c7,openstack/puppet-glance,master,I37baa79943063a66922a9f82a286583a091122c7,Install python rbd package on Ubuntu,MERGED,2019-02-07 09:51:25.000000000,2019-02-11 22:56:45.000000000,2019-02-11 22:56:45.000000000,"[{'_account_id': 3153}, {'_account_id': 10135}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 09:51:25.000000000', 'files': ['spec/classes/glance_backend_rbd_spec.rb', 'releasenotes/notes/glance-rbd-ubuntu-package-b072d00a7e21b9af.yaml', 'manifests/params.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/1daac1805f8b20d4f3f263985e0aad466b9677f6', 'message': 'Install python rbd package on Ubuntu\n\nThe glance::backend::rbd class when managing the\nceph package would install the python-ceph package\nwhich after changing to python3 became python3-ceph.\n\nThe python3-ceph package does not exist and the python-ceph\npackage is only a meta package that points to all the python\n2 libraries.\n\nThis changes so that it installs python3-rbd on Ubuntu but\nleaves the python3-ceph package on Debian based packaging.\n\nChange-Id: I37baa79943063a66922a9f82a286583a091122c7\n'}]",0,635469,1daac1805f8b20d4f3f263985e0aad466b9677f6,14,6,1,16137,,,0,"Install python rbd package on Ubuntu

The glance::backend::rbd class when managing the
ceph package would install the python-ceph package
which after changing to python3 became python3-ceph.

The python3-ceph package does not exist and the python-ceph
package is only a meta package that points to all the python
2 libraries.

This changes so that it installs python3-rbd on Ubuntu but
leaves the python3-ceph package on Debian based packaging.

Change-Id: I37baa79943063a66922a9f82a286583a091122c7
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/69/635469/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/glance_backend_rbd_spec.rb', 'releasenotes/notes/glance-rbd-ubuntu-package-b072d00a7e21b9af.yaml', 'manifests/params.pp']",3,1daac1805f8b20d4f3f263985e0aad466b9677f6,ubuntu-py3," if $::os_package_type == 'debian' { $pyceph_package_name = ""python${pyvers}-ceph"" } else { $pyceph_package_name = ""python${pyvers}-rbd"" }"," $pyceph_package_name = ""python${pyvers}-ceph""",16,7
openstack%2Fpuppet-ironic~master~I14be6631aa1a4d0c9e21e58e661ddd8a563c86dd,openstack/puppet-ironic,master,I14be6631aa1a4d0c9e21e58e661ddd8a563c86dd,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:13:47.000000000,2019-02-11 22:47:30.000000000,2019-02-11 22:47:30.000000000,"[{'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:13:47.000000000', 'files': ['metadata.json', 'manifests/inspector/db/mysql.pp', 'manifests/db/mysql.pp', 'releasenotes/notes/puppet4-mysql-func-fc58d195f9d8a2ba.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/13156df4c9f173cbfbeb5d3036de86002ac22067', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I14be6631aa1a4d0c9e21e58e661ddd8a563c86dd\n'}]",0,635795,13156df4c9f173cbfbeb5d3036de86002ac22067,9,5,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I14be6631aa1a4d0c9e21e58e661ddd8a563c86dd
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/95/635795/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/inspector/db/mysql.pp', 'manifests/db/mysql.pp', 'releasenotes/notes/puppet4-mysql-func-fc58d195f9d8a2ba.yaml']",4,13156df4c9f173cbfbeb5d3036de86002ac22067,mysql-func,--- upgrade: - | This module now requires a puppetlabs-mysql version >= 6.0.0 ,,10,2
openstack%2Fpuppet-zaqar~master~I4978e2706e983735f37f5441efbc6b1c8d8fd053,openstack/puppet-zaqar,master,I4978e2706e983735f37f5441efbc6b1c8d8fd053,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:32:03.000000000,2019-02-11 22:41:28.000000000,2019-02-11 22:41:28.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:32:03.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-b2df8cd05bbb3c22.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-zaqar/commit/b6ed758a7805336a8c556ec19a269d7ca1edbbc0', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I4978e2706e983735f37f5441efbc6b1c8d8fd053\n'}]",0,635814,b6ed758a7805336a8c556ec19a269d7ca1edbbc0,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I4978e2706e983735f37f5441efbc6b1c8d8fd053
",git fetch https://review.opendev.org/openstack/puppet-zaqar refs/changes/14/635814/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-b2df8cd05bbb3c22.yaml', 'manifests/db/mysql.pp']",3,b6ed758a7805336a8c556ec19a269d7ca1edbbc0,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-keystone~stable%2Fpike~Ic4b17a2c750c3162cc609a9469d7422c2084b977,openstack/puppet-keystone,stable/pike,Ic4b17a2c750c3162cc609a9469d7422c2084b977,Keystone_user should not use disabled projects,MERGED,2019-02-07 08:38:05.000000000,2019-02-11 22:27:17.000000000,2019-02-11 22:27:17.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 08:38:05.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/974ee3e51c2e836c9b8652dd7fa5dff10260f37a', 'message': 'Keystone_user should not use disabled projects\n\nWhen testing the password for a keystone_user\nresource we need to ensure the project id that\nis used for testing auth is not disabled causing\nit to fail and puppet things the password should\nbe changed.\n\nChange-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977\nCloses-Bug: 1814906\n(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)\n'}]",0,635455,974ee3e51c2e836c9b8652dd7fa5dff10260f37a,10,4,1,16137,,,0,"Keystone_user should not use disabled projects

When testing the password for a keystone_user
resource we need to ensure the project id that
is used for testing auth is not disabled causing
it to fail and puppet things the password should
be changed.

Change-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977
Closes-Bug: 1814906
(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/55/635455/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb']",3,974ee3e51c2e836c9b8652dd7fa5dff10260f37a,bug/1814906-stable/rocky-stable/queens-stable/pike," # all of the projects for the user, and use the id for the first one # that is enabled then fallback to domain id only. first_project = nil if projects && projects.respond_to?(:each) first_project = projects.detect { |p| p && p[:id] && p[:enabled] == 'True' } end if not first_project.nil? credentials.project_id = first_project[:id]"," # all of the projects for the user, and use the id from the first one. if projects && projects[0] && projects[0][:id] credentials.project_id = projects[0][:id]",44,3
openstack%2Fpuppet-keystone~stable%2Fqueens~Ic4b17a2c750c3162cc609a9469d7422c2084b977,openstack/puppet-keystone,stable/queens,Ic4b17a2c750c3162cc609a9469d7422c2084b977,Keystone_user should not use disabled projects,MERGED,2019-02-07 08:34:20.000000000,2019-02-11 22:27:16.000000000,2019-02-11 22:27:16.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 08:34:20.000000000', 'files': ['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/292fa922e36ef69e81b1d0bee956b2825b8f5f8d', 'message': 'Keystone_user should not use disabled projects\n\nWhen testing the password for a keystone_user\nresource we need to ensure the project id that\nis used for testing auth is not disabled causing\nit to fail and puppet things the password should\nbe changed.\n\nChange-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977\nCloses-Bug: 1814906\n(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)\n'}]",0,635453,292fa922e36ef69e81b1d0bee956b2825b8f5f8d,8,3,1,16137,,,0,"Keystone_user should not use disabled projects

When testing the password for a keystone_user
resource we need to ensure the project id that
is used for testing auth is not disabled causing
it to fail and puppet things the password should
be changed.

Change-Id: Ic4b17a2c750c3162cc609a9469d7422c2084b977
Closes-Bug: 1814906
(cherry picked from commit c2456fcaa849d16273f6d00cf8cf07d02b949272)
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/53/635453/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/keystone_user/openstack_spec.rb', 'releasenotes/notes/keystone_user-bug-1814906-06781a797cd2e051.yaml', 'lib/puppet/provider/keystone_user/openstack.rb']",3,292fa922e36ef69e81b1d0bee956b2825b8f5f8d,bug/1814906-stable/rocky-stable/queens," # all of the projects for the user, and use the id for the first one # that is enabled then fallback to domain id only. first_project = nil if projects && projects.respond_to?(:each) first_project = projects.detect { |p| p && p[:id] && p[:enabled] == 'True' } end if not first_project.nil? credentials.project_id = first_project[:id]"," # all of the projects for the user, and use the id from the first one. if projects && projects[0] && projects[0][:id] credentials.project_id = projects[0][:id]",44,3
openstack%2Fpuppet-keystone~master~I82ecf608820f940cffc53b679545d3e9aee71195,openstack/puppet-keystone,master,I82ecf608820f940cffc53b679545d3e9aee71195,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:14:57.000000000,2019-02-11 22:27:15.000000000,2019-02-11 22:27:15.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:14:57.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d8adf965e1f5ee8f.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/16f2265203680d4bdcda26fc7f789302689cafc9', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I82ecf608820f940cffc53b679545d3e9aee71195\n'}]",0,635796,16f2265203680d4bdcda26fc7f789302689cafc9,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I82ecf608820f940cffc53b679545d3e9aee71195
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/96/635796/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d8adf965e1f5ee8f.yaml', 'manifests/db/mysql.pp']",3,16f2265203680d4bdcda26fc7f789302689cafc9,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-heat~master~I7244add57cf29c851ecd3cf49b3be721a13549d9,openstack/puppet-heat,master,I7244add57cf29c851ecd3cf49b3be721a13549d9,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:11:40.000000000,2019-02-11 22:26:24.000000000,2019-02-11 22:26:23.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 11:11:40.000000000', 'files': ['releasenotes/notes/puppet4-mysql-func-9583edec939bbaa2.yaml', 'metadata.json', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/be384424e4befacc538168b35b4799da210ab86b', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I7244add57cf29c851ecd3cf49b3be721a13549d9\n'}]",0,635794,be384424e4befacc538168b35b4799da210ab86b,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I7244add57cf29c851ecd3cf49b3be721a13549d9
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/94/635794/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-9583edec939bbaa2.yaml', 'manifests/db/mysql.pp']",3,be384424e4befacc538168b35b4799da210ab86b,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-cinder~master~I21380651c3b8f4d2fed2123a5c17f95cf0a630da,openstack/puppet-cinder,master,I21380651c3b8f4d2fed2123a5c17f95cf0a630da,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 10:59:01.000000000,2019-02-11 22:24:32.000000000,2019-02-11 22:24:31.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 10:59:01.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-e66797f83b328609.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/bba4a8ce82ab42f0a57698e805ab98d94903bdbe', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I21380651c3b8f4d2fed2123a5c17f95cf0a630da\n'}]",0,635782,bba4a8ce82ab42f0a57698e805ab98d94903bdbe,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I21380651c3b8f4d2fed2123a5c17f95cf0a630da
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/82/635782/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-e66797f83b328609.yaml', 'manifests/db/mysql.pp']",3,bba4a8ce82ab42f0a57698e805ab98d94903bdbe,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fopenstack-ansible-os_neutron~master~I9b11def329dc39a1b8dd1bb7c1dd0eec3e62e2e9,openstack/openstack-ansible-os_neutron,master,I9b11def329dc39a1b8dd1bb7c1dd0eec3e62e2e9,Add br-vlan and br-vxlan bridges to gates,ABANDONED,2019-02-11 17:24:01.000000000,2019-02-11 22:01:21.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-02-11 17:24:01.000000000', 'files': ['tests/host_vars/server2.yml', 'tests/host_vars/localhost.yml', 'tests/os_neutron-overrides.yml', 'tests/host_vars/infra1.yml', 'tests/host_vars/agents2.yml', 'tests/group_vars/all_containers.yml', 'tests/host_vars/agents1.yml', 'tests/host_vars/server1.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/619609cf3bdefc496ccd755ddb0eb908680b0d05', 'message': 'Add br-vlan and br-vxlan bridges to gates\n\nAdd the br-vlan and br-vxlan bridges to gating jobs.\n\nChange-Id: I9b11def329dc39a1b8dd1bb7c1dd0eec3e62e2e9\n'}]",0,636179,619609cf3bdefc496ccd755ddb0eb908680b0d05,3,1,1,28665,,,0,"Add br-vlan and br-vxlan bridges to gates

Add the br-vlan and br-vxlan bridges to gating jobs.

Change-Id: I9b11def329dc39a1b8dd1bb7c1dd0eec3e62e2e9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/79/636179/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/host_vars/server2.yml', 'tests/host_vars/localhost.yml', 'tests/os_neutron-overrides.yml', 'tests/host_vars/infra1.yml', 'tests/host_vars/agents2.yml', 'tests/group_vars/all_containers.yml', 'tests/host_vars/agents1.yml', 'tests/host_vars/server1.yml']",8,619609cf3bdefc496ccd755ddb0eb908680b0d05,add_bridges,ansible_host: 10.1.1.104tunnel_address: 10.1.2.104 vlan_address: 10.1.3.104,ansible_host: 10.1.0.3,40,8
openstack%2Fcinder~driverfixes%2Fnewton~I3f72481442436ddf78c10ab53c161663b05a330a,openstack/cinder,driverfixes/newton,I3f72481442436ddf78c10ab53c161663b05a330a,VNX Driver: delete_hba() instead of remove_hba(),ABANDONED,2019-02-11 20:21:16.000000000,2019-02-11 21:59:41.000000000,,"[{'_account_id': 15296}, {'_account_id': 24921}]","[{'number': 1, 'created': '2019-02-11 20:21:16.000000000', 'files': ['cinder/volume/drivers/emc/vnx/client.py', 'cinder/tests/unit/volume/drivers/emc/vnx/mocked_vnx.yaml', 'cinder/tests/unit/volume/drivers/emc/vnx/test_adapter.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/9d478f0593a9db77dc519aa602e266ff6b1a0740', 'message': ""VNX Driver: delete_hba() instead of remove_hba()\n\nThe storops drivers doesn't have a remove_hba() function,\nit's called delete_hba(). The confusion comes from the fact\nthat storops uses -removeHBA argument when calling\nnaviseccli.\n\nChange-Id: I3f72481442436ddf78c10ab53c161663b05a330a\nCloses-bug: #1813525\n(cherry picked from commit 1c1bcf6b023b02f2a8e4a5bdfc32fb28ceed3a93)\n""}]",0,636216,9d478f0593a9db77dc519aa602e266ff6b1a0740,4,2,1,27419,,,0,"VNX Driver: delete_hba() instead of remove_hba()

The storops drivers doesn't have a remove_hba() function,
it's called delete_hba(). The confusion comes from the fact
that storops uses -removeHBA argument when calling
naviseccli.

Change-Id: I3f72481442436ddf78c10ab53c161663b05a330a
Closes-bug: #1813525
(cherry picked from commit 1c1bcf6b023b02f2a8e4a5bdfc32fb28ceed3a93)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/16/636216/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/vnx/client.py', 'cinder/tests/unit/volume/drivers/emc/vnx/mocked_vnx.yaml', 'cinder/tests/unit/volume/drivers/emc/vnx/test_adapter.py']",3,9d478f0593a9db77dc519aa602e266ff6b1a0740,bug/1813525, try: common_adapter.client.vnx.delete_hba.assert_any_call( 'fake_initiator1') common_adapter.client.vnx.delete_hba.assert_any_call( 'fake_initiator2') except KeyError: common_adapter.client.vnx.remove_hba.assert_any_call( 'fake_initiator1') common_adapter.client.vnx.remove_hba.assert_any_call( 'fake_initiator2'), common_adapter.client.vnx.remove_hba.assert_any_call( 'fake_initiator1') common_adapter.client.vnx.remove_hba.assert_any_call( 'fake_initiator2'),15,6
openstack%2Fpuppet-sahara~master~Iec81077ea52a79c8ee48c2bdd2597459e58bde19,openstack/puppet-sahara,master,Iec81077ea52a79c8ee48c2bdd2597459e58bde19,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:27:22.000000000,2019-02-11 21:59:09.000000000,2019-02-11 21:59:09.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:27:22.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d65ac0d184e963e5.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/052c9ec9230e744e32aa6ff9a9d44b03931e2cee', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Iec81077ea52a79c8ee48c2bdd2597459e58bde19\n'}]",0,635808,052c9ec9230e744e32aa6ff9a9d44b03931e2cee,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Iec81077ea52a79c8ee48c2bdd2597459e58bde19
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/08/635808/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d65ac0d184e963e5.yaml', 'manifests/db/mysql.pp']",3,052c9ec9230e744e32aa6ff9a9d44b03931e2cee,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-sahara~master~I9af2b1819f5f83ea9e1f6b966762d2e19609fb64,openstack/puppet-sahara,master,I9af2b1819f5f83ea9e1f6b966762d2e19609fb64,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:37:38.000000000,2019-02-11 21:59:08.000000000,2019-02-11 21:59:08.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:37:38.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/843daba51fdf301bfa5c1aaeb9d007960e4a0738', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I9af2b1819f5f83ea9e1f6b966762d2e19609fb64\n'}]",0,635770,843daba51fdf301bfa5c1aaeb9d007960e4a0738,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I9af2b1819f5f83ea9e1f6b966762d2e19609fb64
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/70/635770/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,843daba51fdf301bfa5c1aaeb9d007960e4a0738,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-sahara~master~I7a208813a396f9434ac512ec10e8355aa05d56f9,openstack/puppet-sahara,master,I7a208813a396f9434ac512ec10e8355aa05d56f9,Deprecate the sahara-all service,MERGED,2019-02-08 10:10:13.000000000,2019-02-11 21:59:08.000000000,2019-02-11 21:59:07.000000000,"[{'_account_id': 3153}, {'_account_id': 10459}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/bf56094cc0a0540c2dd33b93ed7b3542ca743adb', 'message': ""Deprecate the sahara-all service\n\nIt's deprecated and is not recommend for usage by upstream as\nit has minimal testing.\n\nThis adds notes on what should be removed/changed when sahara-all\nis to be removed, adds a warning to the sahara::service::all class\nand adds a detailed release note on why and how to move away from it.\n\nChange-Id: I7a208813a396f9434ac512ec10e8355aa05d56f9\n""}, {'number': 2, 'created': '2019-02-08 10:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/bda6b69235b21275bd14b0e87e43232bbb684a88', 'message': ""Deprecate the sahara-all service\n\nIt's deprecated and is not recommend for usage by upstream as\nit has minimal testing.\n\nThis adds notes on what should be removed/changed when sahara-all\nis to be removed, adds a warning to the sahara::service::all class\nand adds a detailed release note on why and how to move away from it.\n\nChange-Id: I7a208813a396f9434ac512ec10e8355aa05d56f9\n""}, {'number': 3, 'created': '2019-02-08 10:16:54.000000000', 'files': ['examples/basic.pp', 'manifests/service/all.pp', 'lib/puppet/type/sahara_node_group_template.rb', 'manifests/params.pp', 'lib/puppet/type/sahara_cluster_template.rb', 'releasenotes/notes/deprecate-sahara-all-7b730356a653c0ab.yaml', 'spec/classes/sahara_all_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-sahara/commit/690de27e49992e271edda02918e56afa6a95abf5', 'message': ""Deprecate the sahara-all service\n\nIt's deprecated and is not recommend for usage by upstream as\nit has minimal testing.\n\nThis adds notes on what should be removed/changed when sahara-all\nis to be removed, adds a warning to the sahara::service::all class\nand adds a detailed release note on why and how to move away from it.\n\nChange-Id: I7a208813a396f9434ac512ec10e8355aa05d56f9\n""}]",0,635735,690de27e49992e271edda02918e56afa6a95abf5,10,4,3,16137,,,0,"Deprecate the sahara-all service

It's deprecated and is not recommend for usage by upstream as
it has minimal testing.

This adds notes on what should be removed/changed when sahara-all
is to be removed, adds a warning to the sahara::service::all class
and adds a detailed release note on why and how to move away from it.

Change-Id: I7a208813a396f9434ac512ec10e8355aa05d56f9
",git fetch https://review.opendev.org/openstack/puppet-sahara refs/changes/35/635735/2 && git format-patch -1 --stdout FETCH_HEAD,"['examples/basic.pp', 'manifests/service/all.pp', 'lib/puppet/type/sahara_node_group_template.rb', 'manifests/params.pp', 'lib/puppet/type/sahara_cluster_template.rb', 'releasenotes/notes/deprecate-sahara-all-7b730356a653c0ab.yaml', 'spec/classes/sahara_all_spec.rb']",7,bf56094cc0a0540c2dd33b93ed7b3542ca743adb,deprecate-all-service,# TODO(tobias-urdin): Remove this when deprecated sahara-all is removed.,,58,2
openstack%2Fnova~stable%2Fqueens~I19b0d8baea5440f5d5bc49a6956d9a97bf031a05,openstack/nova,stable/queens,I19b0d8baea5440f5d5bc49a6956d9a97bf031a05,Add functional regression test for bug 1794996,MERGED,2018-12-06 23:59:15.000000000,2019-02-11 21:53:26.000000000,2019-02-11 21:53:26.000000000,"[{'_account_id': 7166}, {'_account_id': 9373}, {'_account_id': 9708}, {'_account_id': 11904}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 28885}]","[{'number': 1, 'created': '2018-12-06 23:59:15.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1794996.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c3fd5e5061b837a78a95705074239c3d2e41e644', 'message': ""Add functional regression test for bug 1794996\n\nThe _destroy_evacuated_instances method on compute\nstartup tries to cleanup guests from the hypervisor\nand allocations held against that compute node resource\nprovider by evacuated instances, but doesn't take into\naccount that those evacuated instances could have been\ndeleted in the meantime which leads to a lazy-load\nInstanceNotFound error that kills the startup of the\ncompute service.\n\nThis change adds a functional regression test to recreate\nthe bug. A subsequent change with the fix will update\nthe test to show the bug is fixed.\n\nNote that assertFlavorMatchesAllocation and\n_boot_and_check_allocations are redefined in the test\nclass because If6aa37d9b6b48791e070799ab026c816fda4441c\nrefactored those methods which will cause problems with\nbackports of this test. The redefined methods will be\nremoved in a follow up cleanup patch.\n\nNOTE(mriedem): The ProviderUsageBaseTestCase import\nhad to change since Iea283322124cb35fc0bc6d25f35548621e8c8c2f\nis not in Queens.\n\nChange-Id: I19b0d8baea5440f5d5bc49a6956d9a97bf031a05\nRelated-Bug: #1794996\n(cherry picked from commit d252f81573cdfe7a0966f134608bb85d17311e33)\n(cherry picked from commit 83d74dbbb6b45bfeada0c0b9ac13385b126709bb)\n""}]",0,623354,c3fd5e5061b837a78a95705074239c3d2e41e644,13,9,1,6873,,,0,"Add functional regression test for bug 1794996

The _destroy_evacuated_instances method on compute
startup tries to cleanup guests from the hypervisor
and allocations held against that compute node resource
provider by evacuated instances, but doesn't take into
account that those evacuated instances could have been
deleted in the meantime which leads to a lazy-load
InstanceNotFound error that kills the startup of the
compute service.

This change adds a functional regression test to recreate
the bug. A subsequent change with the fix will update
the test to show the bug is fixed.

Note that assertFlavorMatchesAllocation and
_boot_and_check_allocations are redefined in the test
class because If6aa37d9b6b48791e070799ab026c816fda4441c
refactored those methods which will cause problems with
backports of this test. The redefined methods will be
removed in a follow up cleanup patch.

NOTE(mriedem): The ProviderUsageBaseTestCase import
had to change since Iea283322124cb35fc0bc6d25f35548621e8c8c2f
is not in Queens.

Change-Id: I19b0d8baea5440f5d5bc49a6956d9a97bf031a05
Related-Bug: #1794996
(cherry picked from commit d252f81573cdfe7a0966f134608bb85d17311e33)
(cherry picked from commit 83d74dbbb6b45bfeada0c0b9ac13385b126709bb)
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/623354/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1794996.py'],1,c3fd5e5061b837a78a95705074239c3d2e41e644,bug/1550919,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_log import log as logging from nova import exception from nova.tests.functional import test_servers LOG = logging.getLogger(__name__) class TestEvacuateDeleteServerRestartOriginalCompute( test_servers.ProviderUsageBaseTestCase): compute_driver = 'fake.SmallFakeDriver' def setUp(self): super(TestEvacuateDeleteServerRestartOriginalCompute, self).setUp() self.compute1 = self._start_compute(host='host1') self.compute2 = self._start_compute(host='host2') flavors = self.api.get_flavors() self.flavor1 = flavors[0] # NOTE(mriedem): This is here for backports and should be removed later # on master (Stein). def assertFlavorMatchesAllocation(self, flavor, allocation): self.assertEqual(flavor['vcpus'], allocation['VCPU']) self.assertEqual(flavor['ram'], allocation['MEMORY_MB']) self.assertEqual(flavor['disk'], allocation['DISK_GB']) # NOTE(mriedem): This is here for backports and should be removed later # on master (Stein). def _boot_and_check_allocations(self, flavor, source_hostname): """"""Boot an instance and check that the resource allocation is correct After booting an instance on the given host with a given flavor it asserts that both the providers usages and resource allocations match with the resources requested in the flavor. It also asserts that running the periodic update_available_resource call does not change the resource state. :param flavor: the flavor the instance will be booted with :param source_hostname: the name of the host the instance will be booted on :return: the API representation of the booted instance """""" server_req = self._build_minimal_create_server_request( self.api, 'some-server', flavor_id=flavor['id'], image_uuid='155d900f-4e14-4e4c-a73d-069cbf4541e6', networks='none') server_req['availability_zone'] = 'nova:%s' % source_hostname LOG.info('booting on %s', source_hostname) created_server = self.api.post_server({'server': server_req}) server = self._wait_for_state_change( self.admin_api, created_server, 'ACTIVE') # Verify that our source host is what the server ended up on self.assertEqual(source_hostname, server['OS-EXT-SRV-ATTR:host']) source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) # Before we run periodics, make sure that we have allocations/usages # only on the source host source_usages = self._get_provider_usages(source_rp_uuid) self.assertFlavorMatchesAllocation(flavor, source_usages) # Check that the other providers has no usage for rp_uuid in [self._get_provider_uuid_by_host(hostname) for hostname in self.computes.keys() if hostname != source_hostname]: usages = self._get_provider_usages(rp_uuid) self.assertEqual({'VCPU': 0, 'MEMORY_MB': 0, 'DISK_GB': 0}, usages) # Check that the server only allocates resource from the host it is # booted on allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(1, len(allocations), 'No allocation for the server on the host it ' 'is booted on') allocation = allocations[source_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(flavor, allocation) self._run_periodics() # After running the periodics but before we start any other operation, # we should have exactly the same allocation/usage information as # before running the periodics # Check usages on the selected host after boot source_usages = self._get_provider_usages(source_rp_uuid) self.assertFlavorMatchesAllocation(flavor, source_usages) # Check that the server only allocates resource from the host it is # booted on allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(1, len(allocations), 'No allocation for the server on the host it ' 'is booted on') allocation = allocations[source_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(flavor, allocation) # Check that the other providers has no usage for rp_uuid in [self._get_provider_uuid_by_host(hostname) for hostname in self.computes.keys() if hostname != source_hostname]: usages = self._get_provider_usages(rp_uuid) self.assertEqual({'VCPU': 0, 'MEMORY_MB': 0, 'DISK_GB': 0}, usages) return server def test_evacuate_delete_server_restart_original_compute(self): """"""Regression test for bug 1794996 where a server is successfully evacuated from a down host and then deleted. Then the source compute host is brought back online and attempts to cleanup the guest from the hypervisor and allocations for the evacuated (and now deleted) instance. Before the bug is fixed, the original compute fails to start because lazy-loading the instance.flavor on the deleted instance, which is needed to cleanup allocations from the source host, raises InstanceNotFound. """""" source_hostname = self.compute1.host dest_hostname = self.compute2.host server = self._boot_and_check_allocations( self.flavor1, source_hostname) source_compute_id = self.admin_api.get_services( host=source_hostname, binary='nova-compute')[0]['id'] self.compute1.stop() # force it down to avoid waiting for the service group to time out self.admin_api.put_service( source_compute_id, {'forced_down': 'true'}) # evacuate the server post = {'evacuate': {}} self.api.post_server_action( server['id'], post) expected_params = {'OS-EXT-SRV-ATTR:host': dest_hostname, 'status': 'ACTIVE'} server = self._wait_for_server_parameter(self.api, server, expected_params) # Expect to have allocation and usages on both computes as the # source compute is still down source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) dest_rp_uuid = self._get_provider_uuid_by_host(dest_hostname) source_usages = self._get_provider_usages(source_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor1, source_usages) dest_usages = self._get_provider_usages(dest_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor1, dest_usages) allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(2, len(allocations)) source_allocation = allocations[source_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor1, source_allocation) dest_allocation = allocations[dest_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor1, dest_allocation) # Delete the evacuated server. The allocations should be gone from # both the original evacuated-from host and the evacuated-to host. self._delete_and_check_allocations(server) # restart the source compute # FIXME(mriedem): This is bug 1794996 where we try to lazy-load the # instance.flavor from the deleted instance which causes the compute # startup to fail. self.assertRaises(exception.InstanceNotFound, self.restart_compute_service, self.compute1) ",,183,0
openstack%2Fnova~stable%2Fqueens~I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a,openstack/nova,stable/queens,I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a,Handle IndexError in _populate_neutron_binding_profile,MERGED,2019-02-08 17:35:38.000000000,2019-02-11 21:53:20.000000000,2019-02-11 21:53:19.000000000,"[{'_account_id': 6873}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 17:35:38.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8369a78af07b224f109586de398c702db342b49d', 'message': ""Handle IndexError in _populate_neutron_binding_profile\n\nThis fixes the code that was blindly pop'ing an entry\nfrom an empty list of PCI devices claimed by the instance.\nIt's not exactly clear how we can get into this situation,\npresumably there was a failure in the actual PCI device\nclaim logic in the ResourceTracker - maybe related to the\nconfigured PCI passthrough whitelist. Regardless, we should\nhandle the empty PCI device list in this method and raise\nan appropriate exception to fail the build on this host.\n\nChange-Id: I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a\nCloses-Bug: #1795064\n(cherry picked from commit 035708c37d587e4c5ede7fe80270bdbff98016ac)\n(cherry picked from commit dfbcf5e40bb51813f56f983e4f75e29a6034a830)\n""}]",0,635897,8369a78af07b224f109586de398c702db342b49d,12,8,1,17685,,,0,"Handle IndexError in _populate_neutron_binding_profile

This fixes the code that was blindly pop'ing an entry
from an empty list of PCI devices claimed by the instance.
It's not exactly clear how we can get into this situation,
presumably there was a failure in the actual PCI device
claim logic in the ResourceTracker - maybe related to the
configured PCI passthrough whitelist. Regardless, we should
handle the empty PCI device list in this method and raise
an appropriate exception to fail the build on this host.

Change-Id: I401bb74cf6e17c2b72cc62bf8ec03ec58238c44a
Closes-Bug: #1795064
(cherry picked from commit 035708c37d587e4c5ede7fe80270bdbff98016ac)
(cherry picked from commit dfbcf5e40bb51813f56f983e4f75e29a6034a830)
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/635897/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,8369a78af07b224f109586de398c702db342b49d,bug/1795064," @mock.patch.object(pci_manager, 'get_instance_pci_devs', return_value=[]) def test_populate_neutron_binding_profile_pci_dev_not_found( self, mock_get_instance_pci_devs): api = neutronapi.API() instance = objects.Instance(pci_devices=objects.PciDeviceList()) port_req_body = {'port': {}} pci_req_id = 'my_req_id' self.assertRaises(exception.PciDeviceNotFound, api._populate_neutron_binding_profile, instance, pci_req_id, port_req_body) mock_get_instance_pci_devs.assert_called_once_with( instance, pci_req_id) ",,30,2
openstack%2Fironic~master~I5530f8e1c2fdff9008e008cfa0c63edaa04e81d9,openstack/ironic,master,I5530f8e1c2fdff9008e008cfa0c63edaa04e81d9,Allow case-insensitivity when setting conductor_group via API,MERGED,2019-02-05 21:18:50.000000000,2019-02-11 21:51:31.000000000,2019-02-09 01:01:16.000000000,"[{'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 28429}]","[{'number': 1, 'created': '2019-02-05 21:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3bb2aab42f46ba88920eeb7b96b870615064f358', 'message': 'Allow case-insensitivity when setting conductor_group via API\n\nSince we use the new conductor group to calculate which conductor an\nupdate_node message should go to, we need to lowercase the new\nconductor_group value at the API level, rather than just before saving\nthe node object.\n\nChange-Id: I5530f8e1c2fdff9008e008cfa0c63edaa04e81d9\nStory: 2004947\nTask: 29362\n'}, {'number': 2, 'created': '2019-02-08 14:36:24.000000000', 'files': ['releasenotes/notes/bug-2004947-e5f27e11b8f9c96d.yaml', 'ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c803488af21e638bd83f522949608f27a5f1b85a', 'message': 'Allow case-insensitivity when setting conductor_group via API\n\nSince we use the new conductor group to calculate which conductor an\nupdate_node message should go to, we need to lowercase the new\nconductor_group value at the API level, rather than just before saving\nthe node object.\n\nChange-Id: I5530f8e1c2fdff9008e008cfa0c63edaa04e81d9\nStory: 2004947\nTask: 29362\n'}]",1,635044,c803488af21e638bd83f522949608f27a5f1b85a,23,8,2,10343,,,0,"Allow case-insensitivity when setting conductor_group via API

Since we use the new conductor group to calculate which conductor an
update_node message should go to, we need to lowercase the new
conductor_group value at the API level, rather than just before saving
the node object.

Change-Id: I5530f8e1c2fdff9008e008cfa0c63edaa04e81d9
Story: 2004947
Task: 29362
",git fetch https://review.opendev.org/openstack/ironic refs/changes/44/635044/2 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/api/controllers/v1/test_node.py', 'ironic/api/controllers/v1/node.py']",2,3bb2aab42f46ba88920eeb7b96b870615064f358,bug/2004947," # conductor_group is case-insensitive, and we use it to calculate # the conductor to send an update too. lowercase it here instead # of just before saving so we calculate correctly. if field == 'conductor_group': patch_val = patch_val.lower()",,18,0
openstack%2Fpuppet-trove~master~I314811639b0d9130b4bef483d510a5ad18f201b5,openstack/puppet-trove,master,I314811639b0d9130b4bef483d510a5ad18f201b5,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:29:39.000000000,2019-02-11 21:48:56.000000000,2019-02-11 21:48:56.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:29:39.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-a6bf94ee5cb5980e.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/c2c5c5f5135dff0a1b03f29dca22969970c7d42c', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I314811639b0d9130b4bef483d510a5ad18f201b5\n'}]",0,635811,c2c5c5f5135dff0a1b03f29dca22969970c7d42c,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I314811639b0d9130b4bef483d510a5ad18f201b5
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/11/635811/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-a6bf94ee5cb5980e.yaml', 'manifests/db/mysql.pp']",3,c2c5c5f5135dff0a1b03f29dca22969970c7d42c,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-panko~master~I01e3c803ef1aae428be01d7984efe0012aabd0f9,openstack/puppet-panko,master,I01e3c803ef1aae428be01d7984efe0012aabd0f9,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:25:06.000000000,2019-02-11 21:46:14.000000000,2019-02-11 21:46:14.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:25:06.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-361ea787e56650ee.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-panko/commit/b096fa6a91458e2ae1096ab7f241c0353efafffd', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I01e3c803ef1aae428be01d7984efe0012aabd0f9\n'}]",0,635805,b096fa6a91458e2ae1096ab7f241c0353efafffd,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I01e3c803ef1aae428be01d7984efe0012aabd0f9
",git fetch https://review.opendev.org/openstack/puppet-panko refs/changes/05/635805/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-361ea787e56650ee.yaml', 'manifests/db/mysql.pp']",3,b096fa6a91458e2ae1096ab7f241c0353efafffd,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-vitrage~master~Ice93b4a2260d898b5dc9a6135c7e55e4f947dd91,openstack/puppet-vitrage,master,Ice93b4a2260d898b5dc9a6135c7e55e4f947dd91,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:30:36.000000000,2019-02-11 21:45:43.000000000,2019-02-11 21:45:43.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:30:36.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-48990f554c142bf8.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/2f08f78fabe2027f6dc27b0cc2d4c75c37f2e0d0', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ice93b4a2260d898b5dc9a6135c7e55e4f947dd91\n'}]",0,635812,2f08f78fabe2027f6dc27b0cc2d4c75c37f2e0d0,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ice93b4a2260d898b5dc9a6135c7e55e4f947dd91
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/12/635812/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-48990f554c142bf8.yaml', 'manifests/db/mysql.pp']",3,2f08f78fabe2027f6dc27b0cc2d4c75c37f2e0d0,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-openstack-integration~master~Ia95778fff50eb7d3fb8fa408ed64d03e6d85f0fc,openstack/puppet-openstack-integration,master,Ia95778fff50eb7d3fb8fa408ed64d03e6d85f0fc,Move Debian jobs to experimental,MERGED,2019-02-07 22:49:44.000000000,2019-02-11 21:39:03.000000000,2019-02-11 21:39:03.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 22:49:44.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/511c739ae36524adc9f26adf870495f0017721e3', 'message': 'Move Debian jobs to experimental\n\nThe Debian jobs are running puppet 4, OpenStack queens and\nare failing. This moves those jobs to the experimental queue\nso we can still test it on Ubunut/Debian related changes.\n\nChange-Id: Ia95778fff50eb7d3fb8fa408ed64d03e6d85f0fc\n'}]",0,635687,511c739ae36524adc9f26adf870495f0017721e3,8,4,1,16137,,,0,"Move Debian jobs to experimental

The Debian jobs are running puppet 4, OpenStack queens and
are failing. This moves those jobs to the experimental queue
so we can still test it on Ubunut/Debian related changes.

Change-Id: Ia95778fff50eb7d3fb8fa408ed64d03e6d85f0fc
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/87/635687/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,511c739ae36524adc9f26adf870495f0017721e3,debian-experimental, - puppet-openstack-integration-4-scenario001-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario002-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario003-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario004-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario001-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario002-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario003-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario004-tempest-debian-stable-luminous: voting: false, - puppet-openstack-integration-4-scenario001-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario002-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario003-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario004-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario001-tempest-debian-stable-luminous: voting: false - puppet-openstack-integration-4-scenario002-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario003-tempest-debian-stable: voting: false - puppet-openstack-integration-4-scenario004-tempest-debian-stable-luminous: voting: false,16,16
openstack%2Fpuppet-manila~master~I9851658b1f979a2848ab719e82b719ad4669cbab,openstack/puppet-manila,master,I9851658b1f979a2848ab719e82b719ad4669cbab,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:16:33.000000000,2019-02-11 21:33:18.000000000,2019-02-11 21:33:18.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:16:33.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-bb1aa0cdcee7bd3c.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/44501f0f1bffbddcf49656edbb1c2704945e3e85', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I9851658b1f979a2848ab719e82b719ad4669cbab\n'}]",0,635798,44501f0f1bffbddcf49656edbb1c2704945e3e85,8,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I9851658b1f979a2848ab719e82b719ad4669cbab
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/98/635798/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-bb1aa0cdcee7bd3c.yaml', 'manifests/db/mysql.pp']",3,44501f0f1bffbddcf49656edbb1c2704945e3e85,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-watcher~master~I620a7d3281f8d4869c661a0b7c44793de3cef644,openstack/puppet-watcher,master,I620a7d3281f8d4869c661a0b7c44793de3cef644,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:31:21.000000000,2019-02-11 21:33:06.000000000,2019-02-11 21:33:06.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:31:21.000000000', 'files': ['releasenotes/notes/puppet4-mysql-func-6d6424c84aff4a6c.yaml', 'metadata.json', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-watcher/commit/29d293d64a18519e13118bb5cec815498b252dad', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I620a7d3281f8d4869c661a0b7c44793de3cef644\n'}]",0,635813,29d293d64a18519e13118bb5cec815498b252dad,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I620a7d3281f8d4869c661a0b7c44793de3cef644
",git fetch https://review.opendev.org/openstack/puppet-watcher refs/changes/13/635813/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/puppet4-mysql-func-6d6424c84aff4a6c.yaml', 'metadata.json', 'manifests/db/mysql.pp']",3,29d293d64a18519e13118bb5cec815498b252dad,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-gnocchi~master~I65315a0e12fb7c00816a37f54a17e90a4c990aa1,openstack/puppet-gnocchi,master,I65315a0e12fb7c00816a37f54a17e90a4c990aa1,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:10:50.000000000,2019-02-11 21:27:43.000000000,2019-02-11 21:27:43.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:10:50.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4d364d08e159b230.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/754abf000b87403a60f57c227ccdf06e7eb988df', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I65315a0e12fb7c00816a37f54a17e90a4c990aa1\n'}]",0,635793,754abf000b87403a60f57c227ccdf06e7eb988df,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I65315a0e12fb7c00816a37f54a17e90a4c990aa1
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/93/635793/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4d364d08e159b230.yaml', 'manifests/db/mysql.pp']",3,754abf000b87403a60f57c227ccdf06e7eb988df,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-designate~master~Ib0af84954cd7fc34b83e72915972f107d731957a,openstack/puppet-designate,master,Ib0af84954cd7fc34b83e72915972f107d731957a,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:04:06.000000000,2019-02-11 21:25:31.000000000,2019-02-11 21:25:31.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:04:06.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2c9ccc1e98ad0af3.yaml', 'manifests/db/powerdns/mysql.pp', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/e63fec36d312fe85f846172ab4d30cbd5f465e5a', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ib0af84954cd7fc34b83e72915972f107d731957a\n'}]",0,635787,e63fec36d312fe85f846172ab4d30cbd5f465e5a,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ib0af84954cd7fc34b83e72915972f107d731957a
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/87/635787/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2c9ccc1e98ad0af3.yaml', 'manifests/db/powerdns/mysql.pp', 'manifests/db/mysql.pp']",4,e63fec36d312fe85f846172ab4d30cbd5f465e5a,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",10,2
openstack%2Fpuppet-ec2api~master~Ia4f60d62d88fcbb9f360517ccdac02488f8b0062,openstack/puppet-ec2api,master,Ia4f60d62d88fcbb9f360517ccdac02488f8b0062,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:06:30.000000000,2019-02-11 21:25:06.000000000,2019-02-11 21:25:06.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:06:30.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-59529551402b3006.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ec2api/commit/3ef60205f6ecec50918602b7f130062b64fee75a', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ia4f60d62d88fcbb9f360517ccdac02488f8b0062\n'}]",0,635789,3ef60205f6ecec50918602b7f130062b64fee75a,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ia4f60d62d88fcbb9f360517ccdac02488f8b0062
",git fetch https://review.opendev.org/openstack/puppet-ec2api refs/changes/89/635789/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-59529551402b3006.yaml', 'manifests/db/mysql.pp']",3,3ef60205f6ecec50918602b7f130062b64fee75a,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-barbican~master~If06b9838d867328651e8d24e3c652ae1338c789f,openstack/puppet-barbican,master,If06b9838d867328651e8d24e3c652ae1338c789f,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 10:53:01.000000000,2019-02-11 21:25:01.000000000,2019-02-11 21:25:01.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:53:01.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4c7a1aa31c88dcbf.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/6585069a8624a856eb6dd792c8468c836a12eef1', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: If06b9838d867328651e8d24e3c652ae1338c789f\n'}]",0,635780,6585069a8624a856eb6dd792c8468c836a12eef1,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: If06b9838d867328651e8d24e3c652ae1338c789f
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/80/635780/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-4c7a1aa31c88dcbf.yaml', 'manifests/db/mysql.pp']",3,6585069a8624a856eb6dd792c8468c836a12eef1,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-aodh~master~Id676f3b7685a48989b95d3f0529160b398a72d0e,openstack/puppet-aodh,master,Id676f3b7685a48989b95d3f0529160b398a72d0e,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 09:50:55.000000000,2019-02-11 21:24:49.000000000,2019-02-11 21:24:48.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 09:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/916e433903140ea4add31d67961f5a1745c33175', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Id676f3b7685a48989b95d3f0529160b398a72d0e\n'}, {'number': 2, 'created': '2019-02-08 10:21:44.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-ed248d671e0622c7.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/58d359cd76c94eb0f09b78fe69163572f0db8dbc', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Id676f3b7685a48989b95d3f0529160b398a72d0e\n'}]",0,635729,58d359cd76c94eb0f09b78fe69163572f0db8dbc,9,3,2,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Id676f3b7685a48989b95d3f0529160b398a72d0e
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/29/635729/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/puppet4-mysql-func-ed248d671e0622c7.yaml', 'manifests/db/mysql.pp']",2,916e433903140ea4add31d67961f5a1745c33175,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",5,1
openstack%2Fpuppet-ceph~master~I7f107ff63232f1553d34ea5534431496e7460f4f,openstack/puppet-ceph,master,I7f107ff63232f1553d34ea5534431496e7460f4f,Remove Firefly base repo hacking,MERGED,2019-02-07 19:00:04.000000000,2019-02-11 21:21:07.000000000,2019-02-11 21:21:07.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 19:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/1404d511ccce0739c60e0cbc15ff5ccdbdd11030', 'message': 'Remove Firefly base repo hacking\n\nWith firefly there was a need to exclude base packages\nthat conflicted, firefly is EOL and all release after\ndoes not have that issue so we can remove this.\n\nChange-Id: I7f107ff63232f1553d34ea5534431496e7460f4f\n'}, {'number': 2, 'created': '2019-02-07 19:00:47.000000000', 'files': ['manifests/repo.pp', 'releasenotes/notes/firefly-removed-ff181871f3ea5be3.yaml', 'spec/classes/ceph_repo_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/e39f7d232059f12a52685e6c260d7b88ee405b86', 'message': 'Remove Firefly base repo hacking\n\nWith firefly there was a need to exclude base packages\nthat conflicted, firefly is EOL and all release after\ndoes not have that issue so we can remove this.\n\nChange-Id: I7f107ff63232f1553d34ea5534431496e7460f4f\n'}]",0,635601,e39f7d232059f12a52685e6c260d7b88ee405b86,8,3,2,16137,,,0,"Remove Firefly base repo hacking

With firefly there was a need to exclude base packages
that conflicted, firefly is EOL and all release after
does not have that issue so we can remove this.

Change-Id: I7f107ff63232f1553d34ea5534431496e7460f4f
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/01/635601/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/repo.pp', 'spec/classes/ceph_repo_spec.rb']",2,1404d511ccce0739c60e0cbc15ff5ccdbdd11030,,," it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should contain_file_line('exclude base').with( :ensure => 'present', :path => '/etc/yum.repos.d/CentOS-Base.repo', :after => '^\[base\]$', :line => 'exclude=python-ceph-compat python-rbd python-rados python-cephfs', )} it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } it { should_not contain_file_line('exclude base') } ",0,38
openstack%2Fpuppet-ceilometer~master~Ibec58311585315e8ec4f748ec26b5fc2dba78a67,openstack/puppet-ceilometer,master,Ibec58311585315e8ec4f748ec26b5fc2dba78a67,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 10:56:58.000000000,2019-02-11 21:19:46.000000000,2019-02-11 21:19:46.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:56:58.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-19d33ccd49701b0d.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/2727fa248da612d0823de8e35381df07985d9170', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ibec58311585315e8ec4f748ec26b5fc2dba78a67\n'}]",0,635781,2727fa248da612d0823de8e35381df07985d9170,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ibec58311585315e8ec4f748ec26b5fc2dba78a67
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/81/635781/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-19d33ccd49701b0d.yaml', 'manifests/db/mysql.pp']",3,2727fa248da612d0823de8e35381df07985d9170,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fnetworking-baremetal~master~I216961e5f7e4d170ce41ca12b0fcc267029bd34c,openstack/networking-baremetal,master,I216961e5f7e4d170ce41ca12b0fcc267029bd34c,Clean up oslo.messaging listener properly,MERGED,2019-02-05 04:09:18.000000000,2019-02-11 21:13:59.000000000,2019-02-11 21:13:59.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-02-05 04:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/98e99366575911ff654056724d9d1272c323aed2', 'message': ""Clean up oslo.messaging notifier and listener properly\n\nOn stop and reset call the .stop() method for the listener\nand the .cleanup() method for the notifier. i.e clean up\nconnection's more cleanly.\n\nStory: 2004938\nTask: 29333\nChange-Id: I216961e5f7e4d170ce41ca12b0fcc267029bd34c\n""}, {'number': 2, 'created': '2019-02-05 05:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/d4956061130dd989ecbe641ba928b5ab73e6518b', 'message': 'Clean up oslo.messaging listener properly\n\nOn stop and reset call the .stop() method for the listener\nand the i.e stop more cleanly.\n\nStory: 2004938\nTask: 29333\nChange-Id: I216961e5f7e4d170ce41ca12b0fcc267029bd34c\n'}, {'number': 3, 'created': '2019-02-05 05:21:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/dabd761b70ab9cf6b8ba5ccccdebd06da4c0e5e6', 'message': 'Clean up oslo.messaging listener properly\n\nOn stop and reset call the .stop() method for the listener\nand the i.e stop more cleanly.\n\nStory: 2004938\nTask: 29333\nChange-Id: I216961e5f7e4d170ce41ca12b0fcc267029bd34c\n'}, {'number': 4, 'created': '2019-02-06 13:46:32.000000000', 'files': ['networking_baremetal/agent/ironic_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/networking-baremetal/commit/d1464c428a532abe2d149ee5e2064850ea8e4a0f', 'message': 'Clean up oslo.messaging listener properly\n\nOn stop and reset call the .stop() method for the listener\nand the i.e stop more cleanly.\n\nStory: 2004938\nTask: 29333\nChange-Id: I216961e5f7e4d170ce41ca12b0fcc267029bd34c\n'}]",0,634851,d1464c428a532abe2d149ee5e2064850ea8e4a0f,23,5,4,24245,,,0,"Clean up oslo.messaging listener properly

On stop and reset call the .stop() method for the listener
and the i.e stop more cleanly.

Story: 2004938
Task: 29333
Change-Id: I216961e5f7e4d170ce41ca12b0fcc267029bd34c
",git fetch https://review.opendev.org/openstack/networking-baremetal refs/changes/51/634851/4 && git format-patch -1 --stdout FETCH_HEAD,['networking_baremetal/agent/ironic_neutron_agent.py'],1,98e99366575911ff654056724d9d1272c323aed2,story/2004938, self.listener.stop() self.pool_listener.stop() self.notifier.cleanup() self.listener.wait() self.pool_listener.wait() self.listener.stop() self.pool_listener.stop() self.notifier.cleanup() self.listener.wait() self.pool_listener.wait(),,10,0
openstack%2Fpuppet-rally~master~I609396a7c15b6f53340cd8844bd0e62da2eba4d6,openstack/puppet-rally,master,I609396a7c15b6f53340cd8844bd0e62da2eba4d6,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:26:34.000000000,2019-02-11 21:13:47.000000000,2019-02-11 21:13:47.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:26:34.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2a96728591f0122e.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/524346b975410ca5cf4fa3f8b7b5c4a634e69e9b', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I609396a7c15b6f53340cd8844bd0e62da2eba4d6\n'}]",0,635807,524346b975410ca5cf4fa3f8b7b5c4a634e69e9b,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I609396a7c15b6f53340cd8844bd0e62da2eba4d6
",git fetch https://review.opendev.org/openstack/puppet-rally refs/changes/07/635807/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2a96728591f0122e.yaml', 'manifests/db/mysql.pp']",3,524346b975410ca5cf4fa3f8b7b5c4a634e69e9b,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fcontributor-guide~master~I2e00505621ba4fec99e98bc1bfb1e37d2468d96d,openstack/contributor-guide,master,I2e00505621ba4fec99e98bc1bfb1e37d2468d96d,Tutorial: changes in a series,MERGED,2019-01-31 22:28:18.000000000,2019-02-11 21:11:58.000000000,2019-02-11 21:11:58.000000000,"[{'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6928}, {'_account_id': 9562}, {'_account_id': 10608}, {'_account_id': 14070}, {'_account_id': 16708}, {'_account_id': 21672}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-31 22:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/390b8f417cd26bcfcb5b2c7a4d9e71c71065225b', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}, {'number': 2, 'created': '2019-02-01 15:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/65db25fef099efbdc068be636f56c208da56028e', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}, {'number': 3, 'created': '2019-02-01 16:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/19941379f5412a8d408027d6505da0eeeba6e76b', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}, {'number': 4, 'created': '2019-02-01 19:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/b51f95634437bcc999836bcbe2d15e61f7d99997', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}, {'number': 5, 'created': '2019-02-06 22:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/ba8f81253ae250739712f88a07eef48ff97bc6df', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}, {'number': 6, 'created': '2019-02-07 15:17:51.000000000', 'files': ['doc/source/code-and-documentation/patch-series-tutorial.rst', 'doc/source/code-and-documentation/index.rst', 'doc/source/code-and-documentation/patch-best-practices.rst'], 'web_link': 'https://opendev.org/openstack/contributor-guide/commit/7a2205a0c9b8ba626357de93d2f4a1f01e0ca998', 'message': 'Tutorial: changes in a series\n\nThere was a mailing list post [1] walking through developing multiple\nchanges in a series. It was suggested [2] that this content would be\nsuitable for the contributor guide. This patch introduces a new document\nfor that, and also attempts to incorporate some of the other suggestions\n[3] [4] made in that thread.\n\n[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html\n[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html\n[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html\n[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html\n\nChange-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d\n'}]",10,634333,7a2205a0c9b8ba626357de93d2f4a1f01e0ca998,26,11,6,14070,,,0,"Tutorial: changes in a series

There was a mailing list post [1] walking through developing multiple
changes in a series. It was suggested [2] that this content would be
suitable for the contributor guide. This patch introduces a new document
for that, and also attempts to incorporate some of the other suggestions
[3] [4] made in that thread.

[1] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000629.html
[2] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000638.html
[3] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000637.html
[4] http://lists.openstack.org/pipermail/openstack-discuss/2018-December/000645.html

Change-Id: I2e00505621ba4fec99e98bc1bfb1e37d2468d96d
",git fetch https://review.opendev.org/openstack/contributor-guide refs/changes/33/634333/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/code-and-documentation/patch-series-tutorial.rst', 'doc/source/code-and-documentation/index.rst', 'doc/source/code-and-documentation/patch-best-practices.rst']",3,390b8f417cd26bcfcb5b2c7a4d9e71c71065225b,change-series-tutorial,"top of the chain. Alternatively you may wish to use `git-restack <https://docs.openstack.org/infra/git-restack/>`_, which figures out the appropriate ``git rebase`` command for you. Gerrit also provides you options to edit the patch itself or only the commit message and a few more for more advanced changes, like modifying the author.For a more in-depth look at managing patch chains, see :doc:`/code-and-documentation/patch-series-tutorial`. ","top of the chain. Gerrit also provides you options to edit the patch itself or only the commit message and a few more for more advanced changes, like modifying the author.",230,3
openstack%2Fpuppet-magnum~master~I2fb1b86cf6886579b5960010b543076fc11de6c8,openstack/puppet-magnum,master,I2fb1b86cf6886579b5960010b543076fc11de6c8,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:15:39.000000000,2019-02-11 21:08:20.000000000,2019-02-11 21:08:20.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:15:39.000000000', 'files': ['metadata.json', 'manifests/db/mysql.pp', 'releasenotes/notes/puppet4-mysql-func-1cf094997e6ffcce.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/b4957a74c6c1297fb8a304ae8309a0e78e70e202', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I2fb1b86cf6886579b5960010b543076fc11de6c8\n'}]",0,635797,b4957a74c6c1297fb8a304ae8309a0e78e70e202,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I2fb1b86cf6886579b5960010b543076fc11de6c8
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/97/635797/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'manifests/db/mysql.pp', 'releasenotes/notes/puppet4-mysql-func-1cf094997e6ffcce.yaml']",3,b4957a74c6c1297fb8a304ae8309a0e78e70e202,mysql-func,--- upgrade: - | This module now requires a puppetlabs-mysql version >= 6.0.0 ,,9,1
openstack%2Fkeystone~stable%2Frocky~I83eae5c390d720da05e91264519ae01e8ca32159,openstack/keystone,stable/rocky,I83eae5c390d720da05e91264519ae01e8ca32159,correct the admin_or_target_domain rule,MERGED,2019-01-10 00:23:20.000000000,2019-02-11 21:07:52.000000000,2019-01-29 10:18:24.000000000,"[{'_account_id': 1916}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-01-10 00:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2bb4c58fe9cb12bf1b7cbbcdba0f31cb6ee2e2ed', 'message': 'correct the admin_or_target_domain rule\n\nWith the removal of KeystoneToken from the token model, we longer\nhave the ability to use the token data syntax in the policy rules.\nThis change broke backward compatibility for those is deploying\ncustomized Keystone policies. Unfortunately, we can go back\nto KeystoneToken model as the change was tightly coupled with\nother new functionalities.\n\nSince the scope information is now available in the credential\ndictionary, we can just make use of it instead. Those who have\ncustom policies must update their policy files accordingly.\n\nChange-Id: I83eae5c390d720da05e91264519ae01e8ca32159\ncloses-bug: 1810983\n'}, {'number': 2, 'created': '2019-01-10 21:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/609cf60a64f0f88f96fbebfed7d10f56839d6797', 'message': 'correct the admin_or_target_domain rule\n\nWith the removal of KeystoneToken from the token model, we longer\nhave the ability to use the token data syntax in the policy rules.\nThis change broke backward compatibility for those is deploying\ncustomized Keystone policies. Unfortunately, we can go back\nto KeystoneToken model as the change was tightly coupled with\nother new functionalities.\n\nSince the scope information is now available in the credential\ndictionary, we can just make use of it instead. Those who have\ncustom policies must update their policy files accordingly.\n\nChange-Id: I83eae5c390d720da05e91264519ae01e8ca32159\ncloses-bug: 1810983\n'}, {'number': 3, 'created': '2019-01-28 17:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/38d63d37f18210f98c31c62e2b66b058192e3878', 'message': 'correct the admin_or_target_domain rule\n\nWith the removal of KeystoneToken from the token model, we longer\nhave the ability to use the token data syntax in the policy rules.\nThis change broke backward compatibility for those is deploying\ncustomized Keystone policies. Unfortunately, we can go back\nto KeystoneToken model as the change was tightly coupled with\nother new functionalities.\n\nSince the scope information is now available in the credential\ndictionary, we can just make use of it instead. Those who have\ncustom policies must update their policy files accordingly.\n\nChange-Id: I83eae5c390d720da05e91264519ae01e8ca32159\ncloses-bug: 1810983\n'}, {'number': 4, 'created': '2019-01-28 17:08:09.000000000', 'files': ['releasenotes/notes/fix-policy-for-get-domain-api-c48f4a23adc044cd.yaml', 'keystone/tests/unit/test_v3_protection.py', 'etc/policy.v3cloudsample.json', 'keystone/common/policies/base.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a2e307ed4d526e21cddf7551f160b587b89360e4', 'message': ""correct the admin_or_target_domain rule\n\nWith the removal of KeystoneToken from the token model, we longer\nhave the ability to use the token data syntax in the policy rules.\nThis change broke backward compatibility for those is deploying\ncustomized Keystone policies. Unfortunately, we can't go back\nto KeystoneToken model as the change was tightly coupled with\nthe other refactored authorization functionalities.\n\nSince the scope information is now available in the credential\ndictionary, we can just make use of it instead. Those who have\ncustom policies must update their policy files accordingly.\n\nChange-Id: I83eae5c390d720da05e91264519ae01e8ca32159\ncloses-bug: 1810983\n""}]",7,629692,a2e307ed4d526e21cddf7551f160b587b89360e4,22,7,4,1916,,,0,"correct the admin_or_target_domain rule

With the removal of KeystoneToken from the token model, we longer
have the ability to use the token data syntax in the policy rules.
This change broke backward compatibility for those is deploying
customized Keystone policies. Unfortunately, we can't go back
to KeystoneToken model as the change was tightly coupled with
the other refactored authorization functionalities.

Since the scope information is now available in the credential
dictionary, we can just make use of it instead. Those who have
custom policies must update their policy files accordingly.

Change-Id: I83eae5c390d720da05e91264519ae01e8ca32159
closes-bug: 1810983
",git fetch https://review.opendev.org/openstack/keystone refs/changes/92/629692/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/fix-policy-for-get-domain-api-c48f4a23adc044cd.yaml', 'keystone/tests/unit/test_v3_protection.py', 'etc/policy.v3cloudsample.json', 'keystone/common/policies/base.py']",4,2bb4c58fe9cb12bf1b7cbbcdba0f31cb6ee2e2ed,bug/1810983, 'project_domain_id:%(target.domain.id)s'), 'token.project.domain.id:%(target.domain.id)s'),33,2
openstack%2Fopenstack-helm-infra~master~I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5,openstack/openstack-helm-infra,master,I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5,Basic support for BGP communities in calico,MERGED,2019-01-08 19:34:24.000000000,2019-02-11 21:06:53.000000000,2019-01-12 23:16:58.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26449}, {'_account_id': 28628}]","[{'number': 1, 'created': '2019-01-08 19:34:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/335280b5ca5cc6f68995927ebf1a47d5c095727a', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}, {'number': 2, 'created': '2019-01-08 19:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3b4e46c6c3add6e6d1abcf1e94a1a4b7b5cdac69', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}, {'number': 3, 'created': '2019-01-08 22:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/735049a792757fac56023e9bf3e17234dc007980', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}, {'number': 4, 'created': '2019-01-09 22:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a672a5e4d87f66bcca0701c295fd24a6588d2ef6', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}, {'number': 5, 'created': '2019-01-10 15:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/fd080c3d8b8357b491b8fd1346f8464b061e314a', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}, {'number': 6, 'created': '2019-01-10 20:02:28.000000000', 'files': ['calico/values.yaml', 'calico/templates/bird/_bird_ipam.cfg.template.tpl', 'calico/templates/bird/_bird6_ipam.cfg.template.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e34270c51e6cdcd9306f2d3f71e0d05d24eb8108', 'message': 'Basic support for BGP communities in calico\n\nThis creates a new section in calico/values.yaml that enables\nBGP communities to be applied to a cidr by using the bird_ipam\ntemplates.\n\nChange-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5\n'}]",8,629293,e34270c51e6cdcd9306f2d3f71e0d05d24eb8108,21,6,6,28628,,,0,"Basic support for BGP communities in calico

This creates a new section in calico/values.yaml that enables
BGP communities to be applied to a cidr by using the bird_ipam
templates.

Change-Id: I4dbbc8d8e761e0484eeb7c8bf0fefa28d29493e5
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/93/629293/2 && git format-patch -1 --stdout FETCH_HEAD,"['calico/values.yaml', 'calico/templates/bird/_bird_ipam.cfg.template.tpl', 'calico/templates/bird/_bird6_ipam.cfg.template.tpl']",3,335280b5ca5cc6f68995927ebf1a47d5c095727a,,"function apply_communities () { # Set community value based on dictionary of cidrs {{$asnum := .Values.networking.bgp.asnumber}} {{- range .Values.networking.bgp.ipv6.community_cidr_ref }} if ( net ~ {{ .cidr }} ) then { bgp_community.add(({{$asnum}}, {{.community}})); } {{- end }} } filter calico_pools { apply_communities();",filter calico_pools {,32,0
openstack%2Fpuppet-monasca~master~I81b72476fb2b1315e7d521cbc847ed9f4983da45,openstack/puppet-monasca,master,I81b72476fb2b1315e7d521cbc847ed9f4983da45,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:19:09.000000000,2019-02-11 21:04:55.000000000,2019-02-11 21:04:55.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:19:09.000000000', 'files': ['releasenotes/notes/puppet4-mysql-func-5a0aec333e429d3f.yaml', 'metadata.json', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/1840e2f77da91c9ef67ee297619c79a36aca68b9', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I81b72476fb2b1315e7d521cbc847ed9f4983da45\n'}]",0,635800,1840e2f77da91c9ef67ee297619c79a36aca68b9,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I81b72476fb2b1315e7d521cbc847ed9f4983da45
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/00/635800/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/puppet4-mysql-func-5a0aec333e429d3f.yaml', 'metadata.json', 'manifests/db/mysql.pp']",3,1840e2f77da91c9ef67ee297619c79a36aca68b9,mysql-func," password_hash => mysql::password($sql_password),"," password_hash => mysql_password($sql_password),",9,1
openstack%2Fxstatic-angular-lrdragndrop~master~Ic7c9ed18f336ee175f014aa39fdd94c9f76ac66c,openstack/xstatic-angular-lrdragndrop,master,Ic7c9ed18f336ee175f014aa39fdd94c9f76ac66c,Update package to 1.0.2.4,MERGED,2019-02-11 15:35:51.000000000,2019-02-11 21:04:47.000000000,2019-02-11 21:04:47.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 15:35:51.000000000', 'files': ['xstatic/pkg/angular_lrdragndrop/__init__.py'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-lrdragndrop/commit/2192eb008f92cec81af070cfa19fad8a9e69bbed', 'message': 'Update package to 1.0.2.4\n\nIn order to sync git tags and PyPI uploads, we need to do\na new package release. Update the build to 1.0.2.4.\n\nChange-Id: Ic7c9ed18f336ee175f014aa39fdd94c9f76ac66c\n'}]",0,636155,2192eb008f92cec81af070cfa19fad8a9e69bbed,6,2,1,308,,,0,"Update package to 1.0.2.4

In order to sync git tags and PyPI uploads, we need to do
a new package release. Update the build to 1.0.2.4.

Change-Id: Ic7c9ed18f336ee175f014aa39fdd94c9f76ac66c
",git fetch https://review.opendev.org/openstack/xstatic-angular-lrdragndrop refs/changes/55/636155/1 && git format-patch -1 --stdout FETCH_HEAD,['xstatic/pkg/angular_lrdragndrop/__init__.py'],1,2192eb008f92cec81af070cfa19fad8a9e69bbed,fix-README,"BUILD = '4' # our package build number, so we can release new builds","BUILD = '2' # our package build number, so we can release new builds",1,1
openstack%2Fxstatic-jasmine~master~I37a5d5f752ce01a66732c0540799585f8609fcd5,openstack/xstatic-jasmine,master,I37a5d5f752ce01a66732c0540799585f8609fcd5,Update package to 2.4.1.2,MERGED,2019-02-11 15:38:09.000000000,2019-02-11 21:04:29.000000000,2019-02-11 21:04:29.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 15:38:09.000000000', 'files': ['xstatic/pkg/jasmine/__init__.py'], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/f8db790b6440f914968e7a6aa6b053a5d141c56c', 'message': 'Update package to 2.4.1.2\n\nIn order to sync git tags and PyPI uploads, we need to do\na new package release. Update the build to 2.4.1.2.\n\nChange-Id: I37a5d5f752ce01a66732c0540799585f8609fcd5\n'}]",0,636156,f8db790b6440f914968e7a6aa6b053a5d141c56c,6,2,1,308,,,0,"Update package to 2.4.1.2

In order to sync git tags and PyPI uploads, we need to do
a new package release. Update the build to 2.4.1.2.

Change-Id: I37a5d5f752ce01a66732c0540799585f8609fcd5
",git fetch https://review.opendev.org/openstack/xstatic-jasmine refs/changes/56/636156/1 && git format-patch -1 --stdout FETCH_HEAD,['xstatic/pkg/jasmine/__init__.py'],1,f8db790b6440f914968e7a6aa6b053a5d141c56c,fix-README,"BUILD = '2' # our package build number, so we can release new builds","BUILD = '0' # our package build number, so we can release new builds",1,1
openstack%2Fpuppet-octavia~master~I03184a7a5006ba7b0750b3ce058d873c3c397d57,openstack/puppet-octavia,master,I03184a7a5006ba7b0750b3ce058d873c3c397d57,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:22:46.000000000,2019-02-11 21:04:02.000000000,2019-02-11 21:04:02.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:22:46.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2a3fa2c6b7e24554.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/3856be12d2ee1faf90e614a22abec39f11f359cd', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I03184a7a5006ba7b0750b3ce058d873c3c397d57\n'}]",0,635804,3856be12d2ee1faf90e614a22abec39f11f359cd,8,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I03184a7a5006ba7b0750b3ce058d873c3c397d57
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/04/635804/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-2a3fa2c6b7e24554.yaml', 'manifests/db/mysql.pp']",3,3856be12d2ee1faf90e614a22abec39f11f359cd,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-murano~master~Ifc28598dac2ba7c5db16af960c0fd6a3692ee96e,openstack/puppet-murano,master,Ifc28598dac2ba7c5db16af960c0fd6a3692ee96e,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:20:12.000000000,2019-02-11 21:03:00.000000000,2019-02-11 21:03:00.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:20:12.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d1dcb51f4869e469.yaml', 'manifests/db/mysql_cfapi.pp', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/b9eed707052f6d07b8eee7d6d5baafb5299eecbf', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: Ifc28598dac2ba7c5db16af960c0fd6a3692ee96e\n'}]",0,635801,b9eed707052f6d07b8eee7d6d5baafb5299eecbf,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: Ifc28598dac2ba7c5db16af960c0fd6a3692ee96e
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/01/635801/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-d1dcb51f4869e469.yaml', 'manifests/db/mysql_cfapi.pp', 'manifests/db/mysql.pp']",4,b9eed707052f6d07b8eee7d6d5baafb5299eecbf,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",10,2
openstack%2Fxstatic-magic-search~master~If2b9738b57d0a31247ae09ab87a3addb2a3e7ee1,openstack/xstatic-magic-search,master,If2b9738b57d0a31247ae09ab87a3addb2a3e7ee1,Update package to 0.2.5.2,MERGED,2019-02-11 15:02:33.000000000,2019-02-11 21:02:56.000000000,2019-02-11 21:02:56.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 15:02:33.000000000', 'files': ['xstatic/pkg/magic_search/__init__.py'], 'web_link': 'https://opendev.org/openstack/xstatic-magic-search/commit/119f1348afe17a69e0ef0640d69ae6c4d4557751', 'message': 'Update package to 0.2.5.2\n\nIn order to sync git tags and PyPI uploads, we need to do\na new package release. Update the build to 0.2.5.2.\n\nChange-Id: If2b9738b57d0a31247ae09ab87a3addb2a3e7ee1\n'}]",0,636145,119f1348afe17a69e0ef0640d69ae6c4d4557751,6,2,1,308,,,0,"Update package to 0.2.5.2

In order to sync git tags and PyPI uploads, we need to do
a new package release. Update the build to 0.2.5.2.

Change-Id: If2b9738b57d0a31247ae09ab87a3addb2a3e7ee1
",git fetch https://review.opendev.org/openstack/xstatic-magic-search refs/changes/45/636145/1 && git format-patch -1 --stdout FETCH_HEAD,['xstatic/pkg/magic_search/__init__.py'],1,119f1348afe17a69e0ef0640d69ae6c4d4557751,release-0.2.5.2,"BUILD = '2' # our package build number, so we can release new builds","BUILD = '1' # our package build number, so we can release new builds",1,1
openstack%2Fnova~master~I3075e16fb33b2c7fd3be6bead492faf9114d18dc,openstack/nova,master,I3075e16fb33b2c7fd3be6bead492faf9114d18dc,Test for multiple limit/group_policy qparams,ABANDONED,2018-05-15 22:35:32.000000000,2019-02-11 21:00:20.000000000,,"[{'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25625}, {'_account_id': 26490}, {'_account_id': 26515}, {'_account_id': 27076}]","[{'number': 1, 'created': '2018-05-15 22:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/31fe4d8e7ccfb29d765ebad99f8c398a27434881', 'message': ""Use GET.get instead of GET.getall in alloc-cands\n\nFollowing up on [1], replace GET.getall() with GET.get() for 'limit' and\n'group_policy' in the GET /allocation_candidates handler.\n\n[1] https://review.openstack.org/#/c/517757/37/nova/api/openstack/placement/handlers/allocation_candidate.py@232\n\nChange-Id: I3075e16fb33b2c7fd3be6bead492faf9114d18dc\n""}, {'number': 2, 'created': '2018-05-16 13:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e64ee6ecef080deb4f43a7cb6beaad889fe21a2f', 'message': ""Use GET.get instead of GET.getall in alloc-cands\n\nFollowing up on [1], replace GET.getall() with GET.get() for 'limit' and\n'group_policy' in the GET /allocation_candidates handler.\n\n[1] https://review.openstack.org/#/c/517757/37/nova/api/openstack/placement/handlers/allocation_candidate.py@232\n\nChange-Id: I3075e16fb33b2c7fd3be6bead492faf9114d18dc\n""}, {'number': 3, 'created': '2018-06-01 22:29:50.000000000', 'files': ['nova/tests/functional/api/openstack/placement/gabbits/granular.yaml', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/2a39b00a314a35fc21e52033d131857ace8df116', 'message': ""Test for multiple limit/group_policy qparams\n\nFollowing up on [1], I tried to replace GET.getall() with GET.get() for\n'limit' and 'group_policy' in the GET /allocation_candidates handler.\nHowever, it turns out that this actually changes behavior, because\n.get() picks up the *last* value, whereas we were previously picking up\nthe first.\n\nRather than spin a whole microversion to change this behavior (if we do\nthat, we should just change the schema to disallow multiples) this\nchange set just adds tests proving that we pick up the first value, so\nthat if future me decides to come along and make such a change again,\nwe'll catch it.\n\n[1] https://review.openstack.org/#/c/517757/37/nova/api/openstack/placement/handlers/allocation_candidate.py@232\n\nChange-Id: I3075e16fb33b2c7fd3be6bead492faf9114d18dc\n""}]",1,568713,2a39b00a314a35fc21e52033d131857ace8df116,59,20,3,14070,,,0,"Test for multiple limit/group_policy qparams

Following up on [1], I tried to replace GET.getall() with GET.get() for
'limit' and 'group_policy' in the GET /allocation_candidates handler.
However, it turns out that this actually changes behavior, because
.get() picks up the *last* value, whereas we were previously picking up
the first.

Rather than spin a whole microversion to change this behavior (if we do
that, we should just change the schema to disallow multiples) this
change set just adds tests proving that we pick up the first value, so
that if future me decides to come along and make such a change again,
we'll catch it.

[1] https://review.openstack.org/#/c/517757/37/nova/api/openstack/placement/handlers/allocation_candidate.py@232

Change-Id: I3075e16fb33b2c7fd3be6bead492faf9114d18dc
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/568713/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/placement/handlers/allocation_candidate.py'],1,31fe4d8e7ccfb29d765ebad99f8c398a27434881,multi-qparam-behavior, limit = req.GET.get('limit') group_policy = req.GET.get('group_policy') if not group_policy:, limit = req.GET.getall('limit') group_policy = req.GET.getall('group_policy') or None if group_policy: group_policy = group_policy[0] else:,3,5
openstack%2Fpuppet-zaqar~master~I8fe10cb1f675f29d541fb7f4b2fe4389c5af8150,openstack/puppet-zaqar,master,I8fe10cb1f675f29d541fb7f4b2fe4389c5af8150,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:39:59.000000000,2019-02-11 21:00:01.000000000,2019-02-11 21:00:01.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:39:59.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-zaqar/commit/c13effa02211d8dea1053376d328580ed93196d2', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I8fe10cb1f675f29d541fb7f4b2fe4389c5af8150\n'}]",0,635778,c13effa02211d8dea1053376d328580ed93196d2,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I8fe10cb1f675f29d541fb7f4b2fe4389c5af8150
",git fetch https://review.opendev.org/openstack/puppet-zaqar refs/changes/78/635778/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,c13effa02211d8dea1053376d328580ed93196d2,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-glare~master~I07066787f021c1985a4708a9dc8c11c2d9ad1ec5,openstack/puppet-glare,master,I07066787f021c1985a4708a9dc8c11c2d9ad1ec5,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:09:57.000000000,2019-02-11 20:57:32.000000000,2019-02-11 20:57:32.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:09:57.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-8ced1e1b5d17fa28.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-glare/commit/6f143c16addd23c26e6f704e8cdc94f160484068', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I07066787f021c1985a4708a9dc8c11c2d9ad1ec5\n'}]",0,635792,6f143c16addd23c26e6f704e8cdc94f160484068,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I07066787f021c1985a4708a9dc8c11c2d9ad1ec5
",git fetch https://review.opendev.org/openstack/puppet-glare refs/changes/92/635792/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-8ced1e1b5d17fa28.yaml', 'manifests/db/mysql.pp']",3,6f143c16addd23c26e6f704e8cdc94f160484068,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-trove~master~Ib21b15d0070289e767ae435bc7f2191185e16fbc,openstack/puppet-trove,master,Ib21b15d0070289e767ae435bc7f2191185e16fbc,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:39:10.000000000,2019-02-11 20:57:23.000000000,2019-02-11 20:57:23.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:39:10.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-trove/commit/d3e724a8403e72f7ddec70fe52714661b4053531', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ib21b15d0070289e767ae435bc7f2191185e16fbc\n'}]",0,635775,d3e724a8403e72f7ddec70fe52714661b4053531,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ib21b15d0070289e767ae435bc7f2191185e16fbc
",git fetch https://review.opendev.org/openstack/puppet-trove refs/changes/75/635775/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,d3e724a8403e72f7ddec70fe52714661b4053531,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-vitrage~master~Idd6bd1dba98766f9c006b1a80c54de4355069f51,openstack/puppet-vitrage,master,Idd6bd1dba98766f9c006b1a80c54de4355069f51,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:39:25.000000000,2019-02-11 20:55:08.000000000,2019-02-11 20:55:08.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:39:25.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-vitrage/commit/e5a32a8299048b1aa825fb93041f5ac9c94bf513', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Idd6bd1dba98766f9c006b1a80c54de4355069f51\n'}]",0,635776,e5a32a8299048b1aa825fb93041f5ac9c94bf513,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Idd6bd1dba98766f9c006b1a80c54de4355069f51
",git fetch https://review.opendev.org/openstack/puppet-vitrage refs/changes/76/635776/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,e5a32a8299048b1aa825fb93041f5ac9c94bf513,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-watcher~master~Ie88fc7fab73d74841f382f4f3a3a5c2e0baaa4dc,openstack/puppet-watcher,master,Ie88fc7fab73d74841f382f4f3a3a5c2e0baaa4dc,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:39:45.000000000,2019-02-11 20:53:03.000000000,2019-02-11 20:53:03.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:39:45.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-watcher/commit/c51060ad95309febfcc4661ae9f205e06d9c4bcb', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ie88fc7fab73d74841f382f4f3a3a5c2e0baaa4dc\n'}]",0,635777,c51060ad95309febfcc4661ae9f205e06d9c4bcb,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ie88fc7fab73d74841f382f4f3a3a5c2e0baaa4dc
",git fetch https://review.opendev.org/openstack/puppet-watcher refs/changes/77/635777/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,c51060ad95309febfcc4661ae9f205e06d9c4bcb,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-congress~master~I3942f839d89cc02e695163e68f97cba48b416791,openstack/puppet-congress,master,I3942f839d89cc02e695163e68f97cba48b416791,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:01:00.000000000,2019-02-11 20:53:00.000000000,2019-02-11 20:53:00.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:01:00.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-7659cf892ef01823.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/6e24aa7349477e06c9be06fdf096337def72f25a', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I3942f839d89cc02e695163e68f97cba48b416791\n'}]",0,635784,6e24aa7349477e06c9be06fdf096337def72f25a,7,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I3942f839d89cc02e695163e68f97cba48b416791
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/84/635784/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-7659cf892ef01823.yaml', 'manifests/db/mysql.pp']",3,6e24aa7349477e06c9be06fdf096337def72f25a,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-freezer~master~I34aca114343f1d079e50f6d04728e7c3745c26fa,openstack/puppet-freezer,master,I34aca114343f1d079e50f6d04728e7c3745c26fa,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:07:57.000000000,2019-02-11 20:52:57.000000000,2019-02-11 20:52:57.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:07:57.000000000', 'files': ['metadata.json', 'releasenotes/notes/puppet4-mysql-func-66fc9e20bfccf6f5.yaml', 'manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/e34af1ef04cb7edeed176b4af4e2290fcf4a004e', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I34aca114343f1d079e50f6d04728e7c3745c26fa\n'}]",0,635790,e34af1ef04cb7edeed176b4af4e2290fcf4a004e,9,4,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I34aca114343f1d079e50f6d04728e7c3745c26fa
",git fetch https://review.opendev.org/openstack/puppet-freezer refs/changes/90/635790/1 && git format-patch -1 --stdout FETCH_HEAD,"['metadata.json', 'releasenotes/notes/puppet4-mysql-func-66fc9e20bfccf6f5.yaml', 'manifests/db/mysql.pp']",3,e34af1ef04cb7edeed176b4af4e2290fcf4a004e,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",9,1
openstack%2Fpuppet-openstack-cookiecutter~master~I6a94235531bc9e72ce5ab02959feb9ca58531f7d,openstack/puppet-openstack-cookiecutter,master,I6a94235531bc9e72ce5ab02959feb9ca58531f7d,Use puppet 4 compatible mysql functions,MERGED,2019-02-08 11:02:15.000000000,2019-02-11 20:52:12.000000000,2019-02-11 20:52:12.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 11:02:15.000000000', 'files': ['puppet-{{cookiecutter.project_name}}/metadata.json', 'puppet-{{cookiecutter.project_name}}/manifests/db/mysql.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/adf11d4a9bef7a269ce44bc0e0026750c0e35ad2', 'message': 'Use puppet 4 compatible mysql functions\n\nThese was introduced in 6.0.0 and is required to\nsupport later version of puppetlabs-mysql.\n\nChange-Id: I6a94235531bc9e72ce5ab02959feb9ca58531f7d\n'}]",0,635786,adf11d4a9bef7a269ce44bc0e0026750c0e35ad2,8,3,1,16137,,,0,"Use puppet 4 compatible mysql functions

These was introduced in 6.0.0 and is required to
support later version of puppetlabs-mysql.

Change-Id: I6a94235531bc9e72ce5ab02959feb9ca58531f7d
",git fetch https://review.opendev.org/openstack/puppet-openstack-cookiecutter refs/changes/86/635786/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet-{{cookiecutter.project_name}}/metadata.json', 'puppet-{{cookiecutter.project_name}}/manifests/db/mysql.pp']",2,adf11d4a9bef7a269ce44bc0e0026750c0e35ad2,mysql-func," password_hash => mysql::password($password),"," password_hash => mysql_password($password),",5,1
openstack%2Fpuppet-rally~master~Ieb683becfb1b259b9d52119c7a69f75b045c95b3,openstack/puppet-rally,master,Ieb683becfb1b259b9d52119c7a69f75b045c95b3,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:37:16.000000000,2019-02-11 20:52:03.000000000,2019-02-11 20:52:03.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:37:16.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/1fb89095d70c3f2410fd8cfbe0ec90320c2ec860', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ieb683becfb1b259b9d52119c7a69f75b045c95b3\n'}]",0,635769,1fb89095d70c3f2410fd8cfbe0ec90320c2ec860,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ieb683becfb1b259b9d52119c7a69f75b045c95b3
",git fetch https://review.opendev.org/openstack/puppet-rally refs/changes/69/635769/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,1fb89095d70c3f2410fd8cfbe0ec90320c2ec860,remove-xenial,," ""16.04"",",0,1
openstack%2Fnova~master~I8c51654eb0744c400a1b55a9d6b8594a103dadcc,openstack/nova,master,I8c51654eb0744c400a1b55a9d6b8594a103dadcc,Fup for the bandwidth resource provider series,MERGED,2019-01-29 16:18:27.000000000,2019-02-11 20:51:54.000000000,2019-02-11 20:51:54.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-29 16:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9524eeff0cf84e2e9f068e6bf0c054a665977ac6', 'message': 'Fup for the bandwidth resource provider series\n\nThis patch fixes minor comments found in the following patches:\nI7e1edede827cf8469771c0496b1dce55c627cf5d\nI4473cb192447b5bfa9d1dfcc0dd5216c536caf73\nI97f06d0ec34cbd75c182caaa686b8de5c777a576\n\nChange-Id: I8c51654eb0744c400a1b55a9d6b8594a103dadcc\nblueprint: bandwidth-resource-provider\n'}, {'number': 2, 'created': '2019-01-30 10:29:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/49ec9c803ab5513fc25a8a9afc79914751433ebe', 'message': 'Fup for the bandwidth resource provider series\n\nThis patch fixes minor comments found in the following patches:\nI7e1edede827cf8469771c0496b1dce55c627cf5d\nI4473cb192447b5bfa9d1dfcc0dd5216c536caf73\nI97f06d0ec34cbd75c182caaa686b8de5c777a576\n\nChange-Id: I8c51654eb0744c400a1b55a9d6b8594a103dadcc\nblueprint: bandwidth-resource-provider\n'}, {'number': 3, 'created': '2019-02-04 13:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f28753aaa945648b0872fe28d25d07abe37fc554', 'message': 'Fup for the bandwidth resource provider series\n\nThis patch fixes minor comments found in the following patches:\nI7e1edede827cf8469771c0496b1dce55c627cf5d\nI4473cb192447b5bfa9d1dfcc0dd5216c536caf73\nI97f06d0ec34cbd75c182caaa686b8de5c777a576\n\nChange-Id: I8c51654eb0744c400a1b55a9d6b8594a103dadcc\nblueprint: bandwidth-resource-provider\n'}, {'number': 4, 'created': '2019-02-04 13:10:49.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cc16de04e8dc21a666ddc414cf80a94f30e4d424', 'message': 'Fup for the bandwidth resource provider series\n\nThis patch fixes minor comments found in the following patches:\nI7e1edede827cf8469771c0496b1dce55c627cf5d\nI4473cb192447b5bfa9d1dfcc0dd5216c536caf73\nI97f06d0ec34cbd75c182caaa686b8de5c777a576\n\nChange-Id: I8c51654eb0744c400a1b55a9d6b8594a103dadcc\nblueprint: bandwidth-resource-provider\n'}]",6,633776,cc16de04e8dc21a666ddc414cf80a94f30e4d424,46,14,4,9708,,,0,"Fup for the bandwidth resource provider series

This patch fixes minor comments found in the following patches:
I7e1edede827cf8469771c0496b1dce55c627cf5d
I4473cb192447b5bfa9d1dfcc0dd5216c536caf73
I97f06d0ec34cbd75c182caaa686b8de5c777a576

Change-Id: I8c51654eb0744c400a1b55a9d6b8594a103dadcc
blueprint: bandwidth-resource-provider
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/633776/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py', 'nova/exception.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/functional/test_servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",7,9524eeff0cf84e2e9f068e6bf0c054a665977ac6,bp/bandwidth-resource-provider, exception.CreateWithPortResourceRequestOldVersion) as error:, exception.ServerCreateWithQoSPortNotSupported) as error:,29,67
openstack%2Fnova~master~Id9b9af5711cce8a0b7f0388a15299bb471490185,openstack/nova,master,Id9b9af5711cce8a0b7f0388a15299bb471490185,Move refresh time from report client to prov tree,ABANDONED,2018-01-18 23:02:06.000000000,2019-02-11 20:51:17.000000000,,"[{'_account_id': 7}, {'_account_id': 136}, {'_account_id': 2033}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17920}, {'_account_id': 19853}, {'_account_id': 21279}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-01-18 23:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/730b3cec93d9bf58d8da1169e95c29f54a6d24e4', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 2, 'created': '2018-01-19 15:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bef600575f392c268a3bc1281832a774b04a834', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 3, 'created': '2018-01-19 23:28:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b055c333541d788b04504695db2e5ed113eb4980', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 4, 'created': '2018-01-22 23:38:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b6b75de6e40b3893689a37223adf38e2d63f30a2', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 5, 'created': '2018-01-24 20:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9f65af1e741fb95bbdd8162d29b7f2a149c4fa87', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 6, 'created': '2018-01-25 00:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/551ac00e9ed2d03c214333d321634a1ca6a7fe49', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 7, 'created': '2018-01-25 02:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7cb2fc91198ae4858b053087b361dafd27bef974', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 8, 'created': '2018-01-25 02:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/251478097b5b268d6895d51323fe2c6146d6ca22', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 9, 'created': '2018-01-26 00:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/eca3ca51d7a68537c16492f5d5caa707293e1174', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 10, 'created': '2018-01-27 19:50:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91136ab435115cfe347b3933ff354d5f08d84f84', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 11, 'created': '2018-01-28 17:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/913c905985f82f72e60055459b9ca7ff072c0c78', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 12, 'created': '2018-01-29 21:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/474fa34a5f78cd55a516de8fc2f9a4cc3c043ff6', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 13, 'created': '2018-01-29 23:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cfdc462c679439eee302a6f3379b9ab32d8adfeb', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 14, 'created': '2018-01-30 00:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d16fb450ea1afef762ea0570726718eede977ebe', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 15, 'created': '2018-01-30 19:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d36587ecc69bebc4ffa6741e1439b03307826c4a', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 16, 'created': '2018-01-31 14:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/784666a0cb4e45318ec247b92950fd6699fff69a', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: nested-resource-providers\n'}, {'number': 17, 'created': '2018-02-01 22:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a792f0349863999f6b5946fcd747a4a2c84ca6bd', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 18, 'created': '2018-02-02 15:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4f8e1b29a036d6e8333f16b695c26b413be49bc5', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 19, 'created': '2018-02-02 16:11:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c906998b93d273d32e4cfb837c2c3397df53d8b', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 20, 'created': '2018-02-05 23:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5c0668bc16c4d8871fde31d301a910fccd0e711', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 21, 'created': '2018-02-08 17:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee42c2e113f31bf17892415258104039e8bc18bd', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 22, 'created': '2018-02-09 20:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/55d701e65470fe7d8d53eae5076629670f8d5f2c', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 23, 'created': '2018-02-16 23:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/241878a9f330532debbada141e9bf52f06e3f971', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 24, 'created': '2018-03-12 17:23:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/befa2311e28d30faa9754bda8cb0dca8b730ba58', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 25, 'created': '2018-03-16 21:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ac5fb295ccd6968497ebf9133cfc8bfb98e4120', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}, {'number': 26, 'created': '2018-03-22 00:27:17.000000000', 'files': ['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/compute/provider_tree.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/08e7b1b51b4a959c6c889a4c90d4c42e88e5944d', 'message': 'Move refresh time from report client to prov tree\n\nPreviously in report client we kept a dict, keyed by resource provider\nUUID, of time stamps indicating the last time we refreshed certain data\n(inventories, aggregates, and traits) associated with a resource\nprovider.  This was used to detect ""staleness"" and help us determine\nwhether we should go back to placement to refresh the local cache.\nManagement of this dict was spread across the report client, and it was\neasy to forget to do this bit of bookkeeping with each new report client\npatch.\n\nWith this change set, we move the last-refreshed timestamp into the\n_Provider object itself.  We update the timestamp automatically from\nwithin the operations that update the relevant data (inventories,\ntraits, aggregates).  And we expose a\nProviderTree.is_stale(name_or_uuid) method to allow the consumer to\ncheck for staleness.\n\nThis moves the management of staleness completely out of the report\nclient and into the ProviderTree framework.\n\nChange-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185\nblueprint: update-provider-tree\n'}]",3,535517,08e7b1b51b4a959c6c889a4c90d4c42e88e5944d,245,22,26,14070,,,0,"Move refresh time from report client to prov tree

Previously in report client we kept a dict, keyed by resource provider
UUID, of time stamps indicating the last time we refreshed certain data
(inventories, aggregates, and traits) associated with a resource
provider.  This was used to detect ""staleness"" and help us determine
whether we should go back to placement to refresh the local cache.
Management of this dict was spread across the report client, and it was
easy to forget to do this bit of bookkeeping with each new report client
patch.

With this change set, we move the last-refreshed timestamp into the
_Provider object itself.  We update the timestamp automatically from
within the operations that update the relevant data (inventories,
traits, aggregates).  And we expose a
ProviderTree.is_stale(name_or_uuid) method to allow the consumer to
check for staleness.

This moves the management of staleness completely out of the report
client and into the ProviderTree framework.

Change-Id: Id9b9af5711cce8a0b7f0388a15299bb471490185
blueprint: update-provider-tree
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/535517/18 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/compute/provider_tree.py']",3,730b3cec93d9bf58d8da1169e95c29f54a6d24e4,nix-refresh-time,"import time# Number of seconds between attempts to update a provider's aggregates, traits, # and inventory. PROVIDER_REFRESH_INTERVAL = 300 # Last time this provider's associations were updated. Init this to # zero to indicate that associations for this provider have not yet # been loaded. self._last_refreshed = 0 def _refreshed(self): """"""Update the refresh time (used to detect staleness) to *now*."""""" self._last_refreshed = time.time() def is_stale(self): """"""Returns whether ""too much"" time has passed since this _Provider was last refreshed."""""" return (time.time() - self._last_refreshed) > PROVIDER_REFRESH_INTERVAL # Update last-refresh time even if no changes were effected. self._refreshed() # Update last-refresh time even if no changes were effected. self._refreshed() # Update last-refresh time even if no changes were effected. self._refreshed() def is_stale(self, name_or_uuid): """"""Has the specified provider been refreshed ""recently""? :param name_or_uuid: Either name or UUID of the resource provider to check for staleness. :return: True if the specified provider is ""stale"" (hasn't been updated in the past PROVIDER_REFRESH_INTERVAL seconds); False otherwise. Also returns True if the specified provider does not exist, as this also indicates it needs to be ""refreshed"" (created in the ProviderTree). """""" with self.lock: try: return self._find_with_lock(name_or_uuid).is_stale() except ValueError: return True ",,50,37
openstack%2Fpuppet-neutron~master~I5a8b082b157e9d09a46c8b842d4c4e6533450176,openstack/puppet-neutron,master,I5a8b082b157e9d09a46c8b842d4c4e6533450176,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:32:45.000000000,2019-02-11 20:49:58.000000000,2019-02-11 20:49:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:32:45.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b02512bf81d6a996342d940852cd8e007282e63c', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I5a8b082b157e9d09a46c8b842d4c4e6533450176\n'}]",0,635759,b02512bf81d6a996342d940852cd8e007282e63c,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I5a8b082b157e9d09a46c8b842d4c4e6533450176
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/59/635759/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,b02512bf81d6a996342d940852cd8e007282e63c,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-tacker~master~I5104be0ce5dc2e7e4dfb83194d3d823fd9f3d8ca,openstack/puppet-tacker,master,I5104be0ce5dc2e7e4dfb83194d3d823fd9f3d8ca,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:38:33.000000000,2019-02-11 20:49:09.000000000,2019-02-11 20:49:09.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:38:33.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tacker/commit/49737d72f034cf07833c1d7a668d6d8e35189f6c', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I5104be0ce5dc2e7e4dfb83194d3d823fd9f3d8ca\n'}]",0,635773,49737d72f034cf07833c1d7a668d6d8e35189f6c,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I5104be0ce5dc2e7e4dfb83194d3d823fd9f3d8ca
",git fetch https://review.opendev.org/openstack/puppet-tacker refs/changes/73/635773/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,49737d72f034cf07833c1d7a668d6d8e35189f6c,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-tempest~master~Ia8a7b9d90f334fcfa033e3218729c36c536f7adf,openstack/puppet-tempest,master,Ia8a7b9d90f334fcfa033e3218729c36c536f7adf,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:38:48.000000000,2019-02-11 20:48:34.000000000,2019-02-11 20:48:34.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:38:48.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/44ba2338d1bc27b815c09457087b2b0c8d4f49a6', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ia8a7b9d90f334fcfa033e3218729c36c536f7adf\n'}]",0,635774,44ba2338d1bc27b815c09457087b2b0c8d4f49a6,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ia8a7b9d90f334fcfa033e3218729c36c536f7adf
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/74/635774/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,44ba2338d1bc27b815c09457087b2b0c8d4f49a6,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-openstack_extras~master~Iba1a9693929fa98194fb0d82e46deb0d5c61ecdf,openstack/puppet-openstack_extras,master,Iba1a9693929fa98194fb0d82e46deb0d5c61ecdf,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:33:57.000000000,2019-02-11 20:47:19.000000000,2019-02-11 20:47:19.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:33:57.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/166d8f944fd79c0349343e960a1da449b3722d8d', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Iba1a9693929fa98194fb0d82e46deb0d5c61ecdf\n'}]",0,635762,166d8f944fd79c0349343e960a1da449b3722d8d,8,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Iba1a9693929fa98194fb0d82e46deb0d5c61ecdf
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/62/635762/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,166d8f944fd79c0349343e960a1da449b3722d8d,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-swift~master~I30eea657b9468fde37b6a5be7cc0790ba095edcd,openstack/puppet-swift,master,I30eea657b9468fde37b6a5be7cc0790ba095edcd,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:38:14.000000000,2019-02-11 20:46:49.000000000,2019-02-11 20:46:49.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:38:14.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-swift/commit/7ae11fb09e704711289d8c2145d2bca8b042be75', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I30eea657b9468fde37b6a5be7cc0790ba095edcd\n'}]",0,635772,7ae11fb09e704711289d8c2145d2bca8b042be75,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I30eea657b9468fde37b6a5be7cc0790ba095edcd
",git fetch https://review.opendev.org/openstack/puppet-swift refs/changes/72/635772/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,7ae11fb09e704711289d8c2145d2bca8b042be75,remove-xenial,," ""16.04"",",0,1
openstack%2Fpython-openstackclient~master~I04862069cab28bc76eeafd60ba32be646f478d86,openstack/python-openstackclient,master,I04862069cab28bc76eeafd60ba32be646f478d86,More state handling in volume transfer requests functional tests,MERGED,2019-02-04 18:50:56.000000000,2019-02-11 20:45:32.000000000,2019-02-11 20:45:32.000000000,"[{'_account_id': 2}, {'_account_id': 970}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 18:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/68ca6de63ef0895e6a2720dc146d045ae2036d99', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 2, 'created': '2019-02-04 22:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d1b3177d744c6bd01e31400c49143ae87427922d', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 3, 'created': '2019-02-05 14:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/64712459d7aa67b3fd1f9b0c03be287d3bfadc6a', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 4, 'created': '2019-02-05 21:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d6112364d24a33925ddcc81c7c0d5af5f8546c25', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 5, 'created': '2019-02-06 15:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7c340f5f09e22c5eef8514c218519693271ac0f5', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 6, 'created': '2019-02-06 19:09:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/68250706a0bee6f9ba2f4c52e130f44327f0aedf', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}, {'number': 7, 'created': '2019-02-06 21:41:04.000000000', 'files': ['openstackclient/tests/functional/volume/v2/test_transfer_request.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1a0bef2b46c76e1c6308def709199c30c68aae47', 'message': 'More state handling in volume transfer requests functional tests\n\nUsing addCleanup() for removing the pending volume transfer request\nhas no way to wait for the volume status to become available before\ncleaning up the volume and gets racy when the tests are run with\nslow performance in the volume backend.  So we pause at the end of\nthe test after either accepting the transfer request or explicitly\ndeleting it so the cleanup can delete the volume.\n\nChange-Id: I04862069cab28bc76eeafd60ba32be646f478d86\nSigned-off-by: Dean Troyer <dtroyer@gmail.com>\n'}]",0,634776,1a0bef2b46c76e1c6308def709199c30c68aae47,23,3,7,970,,,0,"More state handling in volume transfer requests functional tests

Using addCleanup() for removing the pending volume transfer request
has no way to wait for the volume status to become available before
cleaning up the volume and gets racy when the tests are run with
slow performance in the volume backend.  So we pause at the end of
the test after either accepting the transfer request or explicitly
deleting it so the cleanup can delete the volume.

Change-Id: I04862069cab28bc76eeafd60ba32be646f478d86
Signed-off-by: Dean Troyer <dtroyer@gmail.com>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/76/634776/6 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/volume/v2/test_transfer_request.py'],1,68ca6de63ef0895e6a2720dc146d045ae2036d99,volume-status-check," self.wait_for_status(""volume"", volume_name, ""available"") self.wait_for_status(""volume"", volume_name, ""awaiting-transfer"") # NOTE(dtroyer): We need to delete the transfer request to allow the # volume to be deleted. The addCleanup() route does # not have a mechanism to wait for the volume status # to become 'available' before attempting to delete # the volume. cmd_output = self.openstack( '--os-volume-api-version ' + self.API_VERSION + ' ' + 'volume transfer request delete ' + xfer_name ) self.wait_for_status(""volume"", volume_name, ""available"")"," self.addCleanup( self.openstack, '--os-volume-api-version ' + self.API_VERSION + ' ' + 'volume transfer request delete ' + xfer_name )",14,6
openstack%2Fpuppet-ironic~master~Ib0f5dea2495fb834d033c5b655ff32349104b9ce,openstack/puppet-ironic,master,Ib0f5dea2495fb834d033c5b655ff32349104b9ce,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:29:29.000000000,2019-02-11 20:45:17.000000000,2019-02-11 20:45:17.000000000,"[{'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:29:29.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/16c5a3457328284ea3887bde6ab2fd45f42dc617', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ib0f5dea2495fb834d033c5b655ff32349104b9ce\n'}]",1,635752,16c5a3457328284ea3887bde6ab2fd45f42dc617,8,4,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ib0f5dea2495fb834d033c5b655ff32349104b9ce
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/52/635752/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,16c5a3457328284ea3887bde6ab2fd45f42dc617,remove-xenial,," ""16.04"",",0,1
openstack%2Fnova~master~I509eb88a612c35541e37ffb2f46f9fa6e13a0965,openstack/nova,master,I509eb88a612c35541e37ffb2f46f9fa6e13a0965,DNM: Leaked nrp-in-alloc-cands behavior,ABANDONED,2018-06-14 16:59:34.000000000,2019-02-11 20:44:30.000000000,,"[{'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-06-14 16:59:34.000000000', 'files': ['nova/tests/functional/api/openstack/placement/fixtures/gabbits.py', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/90aaf6ce94d5ea4c6e627148d5c2c611bdee4ecc', 'message': 'DNM: Leaked nrp-in-alloc-cands behavior\n\nChange-Id: I509eb88a612c35541e37ffb2f46f9fa6e13a0965\n'}]",0,575497,90aaf6ce94d5ea4c6e627148d5c2c611bdee4ecc,8,6,1,14070,,,0,"DNM: Leaked nrp-in-alloc-cands behavior

Change-Id: I509eb88a612c35541e37ffb2f46f9fa6e13a0965
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/575497/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api/openstack/placement/fixtures/gabbits.py', 'nova/tests/functional/api/openstack/placement/gabbits/allocation-candidates.yaml']",2,90aaf6ce94d5ea4c6e627148d5c2c611bdee4ecc,dnm-nrp-leak," - name: get allocation candidates with nested provider GET: /allocation_candidates?resources=VCPU:1,SRIOV_NET_VF:4 status: 200 request_headers: openstack-api-version: placement 1.13 response_json_paths: $.allocation_requests.`len`: 4 # $.provider_summaries.`len`: 10 $.allocation_requests..allocations[""$ENVIRON['CN1_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['PF1_1_UUID']""].resources.SRIOV_NET_VF: 4 $.allocation_requests..allocations[""$ENVIRON['PF1_2_UUID']""].resources.SRIOV_NET_VF: 4 $.allocation_requests..allocations[""$ENVIRON['CN2_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['PF2_1_UUID']""].resources.SRIOV_NET_VF: 4 $.allocation_requests..allocations[""$ENVIRON['PF2_2_UUID']""].resources.SRIOV_NET_VF: 4",,73,77
openstack%2Fpuppet-mistral~master~I8fe305c316fc8c4ac865eeb67446ac8165cc8a69,openstack/puppet-mistral,master,I8fe305c316fc8c4ac865eeb67446ac8165cc8a69,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:31:21.000000000,2019-02-11 20:43:05.000000000,2019-02-11 20:43:05.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:31:21.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-mistral/commit/979490a981b7265481388f39a39040a5ad117f7b', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I8fe305c316fc8c4ac865eeb67446ac8165cc8a69\n'}]",0,635756,979490a981b7265481388f39a39040a5ad117f7b,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I8fe305c316fc8c4ac865eeb67446ac8165cc8a69
",git fetch https://review.opendev.org/openstack/puppet-mistral refs/changes/56/635756/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,979490a981b7265481388f39a39040a5ad117f7b,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-nova~master~I1f9347668c0bc76235dbe4748ab898a4eb86aeb8,openstack/puppet-nova,master,I1f9347668c0bc76235dbe4748ab898a4eb86aeb8,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:33:08.000000000,2019-02-11 20:42:56.000000000,2019-02-11 20:42:56.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:33:08.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/54a31503666a96531ad287305623b8771410f2a0', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I1f9347668c0bc76235dbe4748ab898a4eb86aeb8\n'}]",0,635760,54a31503666a96531ad287305623b8771410f2a0,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I1f9347668c0bc76235dbe4748ab898a4eb86aeb8
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/60/635760/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,54a31503666a96531ad287305623b8771410f2a0,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-panko~master~I7ee743b410e5782fb6190e0282926fe7c5bf414c,openstack/puppet-panko,master,I7ee743b410e5782fb6190e0282926fe7c5bf414c,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:36:21.000000000,2019-02-11 20:42:41.000000000,2019-02-11 20:42:41.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:36:21.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-panko/commit/52994661cafae953627e5e1f2152724030699af0', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I7ee743b410e5782fb6190e0282926fe7c5bf414c\n'}]",0,635767,52994661cafae953627e5e1f2152724030699af0,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I7ee743b410e5782fb6190e0282926fe7c5bf414c
",git fetch https://review.opendev.org/openstack/puppet-panko refs/changes/67/635767/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,52994661cafae953627e5e1f2152724030699af0,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-ovn~master~Iab967526aa63540aa2f11f85900ec8b5cdbc0c11,openstack/puppet-ovn,master,Iab967526aa63540aa2f11f85900ec8b5cdbc0c11,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:35:57.000000000,2019-02-11 20:42:41.000000000,2019-02-11 20:42:41.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:35:57.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/24846bcf5e121512a883e70c929a584c799dd763', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Iab967526aa63540aa2f11f85900ec8b5cdbc0c11\n'}]",0,635766,24846bcf5e121512a883e70c929a584c799dd763,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Iab967526aa63540aa2f11f85900ec8b5cdbc0c11
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/66/635766/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,24846bcf5e121512a883e70c929a584c799dd763,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-oslo~master~I166efa50b1b9f2805398eaf83c2026f54e58b38a,openstack/puppet-oslo,master,I166efa50b1b9f2805398eaf83c2026f54e58b38a,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:35:29.000000000,2019-02-11 20:42:40.000000000,2019-02-11 20:42:40.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:35:29.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-oslo/commit/bf4076a01f352d4d3b917161923129a4a9cdfafd', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I166efa50b1b9f2805398eaf83c2026f54e58b38a\n'}]",0,635765,bf4076a01f352d4d3b917161923129a4a9cdfafd,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I166efa50b1b9f2805398eaf83c2026f54e58b38a
",git fetch https://review.opendev.org/openstack/puppet-oslo refs/changes/65/635765/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,bf4076a01f352d4d3b917161923129a4a9cdfafd,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-qdr~master~I9125096184cd914a4e2e9841ae7974c0839a2c43,openstack/puppet-qdr,master,I9125096184cd914a4e2e9841ae7974c0839a2c43,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:36:56.000000000,2019-02-11 20:42:37.000000000,2019-02-11 20:42:37.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:36:56.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-qdr/commit/0cb13f97e0472c7722d43e8a454e553c74bbca03', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I9125096184cd914a4e2e9841ae7974c0839a2c43\n'}]",0,635768,0cb13f97e0472c7722d43e8a454e553c74bbca03,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I9125096184cd914a4e2e9841ae7974c0839a2c43
",git fetch https://review.opendev.org/openstack/puppet-qdr refs/changes/68/635768/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,0cb13f97e0472c7722d43e8a454e553c74bbca03,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-openstacklib~master~I4834fbaa88559b04da6df1b705ef926b4fb10602,openstack/puppet-openstacklib,master,I4834fbaa88559b04da6df1b705ef926b4fb10602,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:34:27.000000000,2019-02-11 20:42:37.000000000,2019-02-11 20:42:37.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:34:27.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/be647504e095bd1cea03bea97d48a61999507911', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I4834fbaa88559b04da6df1b705ef926b4fb10602\n'}]",0,635763,be647504e095bd1cea03bea97d48a61999507911,8,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I4834fbaa88559b04da6df1b705ef926b4fb10602
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/63/635763/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,be647504e095bd1cea03bea97d48a61999507911,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-murano~master~I258bd33545706958b5f034c2c36219a4c4646f61,openstack/puppet-murano,master,I258bd33545706958b5f034c2c36219a4c4646f61,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:31:58.000000000,2019-02-11 20:41:31.000000000,2019-02-11 20:41:31.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:31:58.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/b6e38f1aca16bc5c170ede96beb2e1c06eaef7af', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I258bd33545706958b5f034c2c36219a4c4646f61\n'}]",0,635758,b6e38f1aca16bc5c170ede96beb2e1c06eaef7af,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I258bd33545706958b5f034c2c36219a4c4646f61
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/58/635758/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,b6e38f1aca16bc5c170ede96beb2e1c06eaef7af,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-gnocchi~master~I8ae520ce5f9a1ff0347b039482565a7cc5ed4ffc,openstack/puppet-gnocchi,master,I8ae520ce5f9a1ff0347b039482565a7cc5ed4ffc,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:27:38.000000000,2019-02-11 20:39:55.000000000,2019-02-11 20:39:55.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:27:38.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/bf5ce7fc5d01c4aa2893f78875beb5ea0b42b641', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I8ae520ce5f9a1ff0347b039482565a7cc5ed4ffc\n'}]",0,635749,bf5ce7fc5d01c4aa2893f78875beb5ea0b42b641,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I8ae520ce5f9a1ff0347b039482565a7cc5ed4ffc
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/49/635749/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,bf5ce7fc5d01c4aa2893f78875beb5ea0b42b641,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-manila~master~I89d4fe589938375578f8841baa9dac7ee1870586,openstack/puppet-manila,master,I89d4fe589938375578f8841baa9dac7ee1870586,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:30:59.000000000,2019-02-11 20:39:54.000000000,2019-02-11 20:39:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:30:59.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-manila/commit/16efd302ce6a1fd1ac9c2919895203d9cb18bcff', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I89d4fe589938375578f8841baa9dac7ee1870586\n'}]",0,635755,16efd302ce6a1fd1ac9c2919895203d9cb18bcff,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I89d4fe589938375578f8841baa9dac7ee1870586
",git fetch https://review.opendev.org/openstack/puppet-manila refs/changes/55/635755/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,16efd302ce6a1fd1ac9c2919895203d9cb18bcff,remove-xenial,," ""16.04"",",0,1
openstack%2Fopenstack-ansible~master~I9611810722283a8a0e4c57e60576bd0c3506eacc,openstack/openstack-ansible,master,I9611810722283a8a0e4c57e60576bd0c3506eacc,[docs] Apply provider network config on per-group basis,MERGED,2019-02-05 19:30:24.000000000,2019-02-11 20:39:09.000000000,2019-02-11 20:39:09.000000000,"[{'_account_id': 7353}, {'_account_id': 15993}, {'_account_id': 16011}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-05 19:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/07e0b9f78b526899b366804ab0d17e15b35090b8', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 2, 'created': '2019-02-05 20:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/36e5abd7211513257712713ccff241c658ccf5dc', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 3, 'created': '2019-02-06 19:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5e7790de7205666e86a48e5cf35a9e8048e3f9fb', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 4, 'created': '2019-02-06 20:03:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9b265d57074c7208bb7ebdc47b60bac377b18349', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 5, 'created': '2019-02-06 21:25:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/71994606f1602542688ce42c33697f47925c3574', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 6, 'created': '2019-02-06 21:56:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/51f43030aecfdf18112b554569a3a3b6f70cc45a', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 7, 'created': '2019-02-07 15:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/da0eb9098290a74ff1e5cf320467248cd1f1d695', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 8, 'created': '2019-02-07 19:05:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b0aa30f203026a40a60f030a3a8290f9cdbb59dc', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 9, 'created': '2019-02-11 18:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/aaa0463d1dd33f52845caaa77669bfbb143c016b', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}, {'number': 10, 'created': '2019-02-11 19:53:46.000000000', 'files': ['doc/source/user/network-arch/example.rst', 'doc/source/user/index.rst', 'doc/source/reference/figures/networking-compute-nobridge.png', 'doc/source/user/figures/network-arch-multiple-interfaces.png', 'doc/source/user/figures/arch-layout-provnet-groups.png', 'doc/source/reference/figures/networking-neutronagents-nobridge.png', 'doc/source/user/figures/arch-layout-provnet-groups-custom.png', 'doc/source/user/figures/network-arch-single-interface.png', 'etc/openstack_deploy/openstack_user_config.yml.singlebond.example', 'doc/source/user/figures/network-arch-single-bond.png', 'doc/source/user/prod/provnet_groups.rst', 'etc/openstack_deploy/openstack_user_config.yml.multibond.example', 'doc/source/reference/architecture/container-networking.rst', 'etc/network/interfaces.d/openstack_interface.cfg.singlebond.example', 'etc/openstack_deploy/openstack_user_config.yml.provnet-group.example', 'doc/source/user/figures/network-arch-multiple-bonds.png', 'etc/network/interfaces.d/openstack_interface.cfg.multibond.example'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/df43c5119dec29fbb0dcec6d1d58dbbb85381c3b', 'message': ""[docs] Apply provider network config on per-group basis\n\nThis patch provides documentation for 'Provider Network Groups',\naka 'the ability to define provider networks that are applied only to\ncertain groups'. This allows deployers to configure provider networks\nacross a heterogeneous environment as opposed to a homogeneous environment.\nIt also updates the documentation by providing examples of single and\nmulti-interface deployments.\n\nThe docs call out the steps necessary to configure the\nopenstack_user_config.yml file to configure provider networks\non a per-group basis. Only groups listed under group_binds for a given\nprovider network will utilize the given vars.\n\nChange-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc\nCloses-Bug: 1814686\n""}]",6,635013,df43c5119dec29fbb0dcec6d1d58dbbb85381c3b,34,5,10,16011,,,0,"[docs] Apply provider network config on per-group basis

This patch provides documentation for 'Provider Network Groups',
aka 'the ability to define provider networks that are applied only to
certain groups'. This allows deployers to configure provider networks
across a heterogeneous environment as opposed to a homogeneous environment.
It also updates the documentation by providing examples of single and
multi-interface deployments.

The docs call out the steps necessary to configure the
openstack_user_config.yml file to configure provider networks
on a per-group basis. Only groups listed under group_binds for a given
provider network will utilize the given vars.

Change-Id: I9611810722283a8a0e4c57e60576bd0c3506eacc
Closes-Bug: 1814686
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/13/635013/9 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/index.rst', 'doc/source/user/prod/provnet_groups.rst', 'etc/openstack_deploy/openstack_user_config.yml.provnet-group.example', 'doc/source/user/figures/arch-layout-provnet-groups.png']",4,07e0b9f78b526899b366804ab0d17e15b35090b8,bug/1814686,,,406,0
openstack%2Fpuppet-octavia~master~Ib5c6c51d9eb79e4e4d07963b639a473e0f623f61,openstack/puppet-octavia,master,Ib5c6c51d9eb79e4e4d07963b639a473e0f623f61,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:33:30.000000000,2019-02-11 20:39:07.000000000,2019-02-11 20:39:07.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:33:30.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/c588f6f116b8dfb55280b9e2b41aa8fbaca79a9f', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ib5c6c51d9eb79e4e4d07963b639a473e0f623f61\n'}]",0,635761,c588f6f116b8dfb55280b9e2b41aa8fbaca79a9f,8,4,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ib5c6c51d9eb79e4e4d07963b639a473e0f623f61
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/61/635761/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,c588f6f116b8dfb55280b9e2b41aa8fbaca79a9f,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-keystone~master~Iea05a8ad944b884288ca1ed0c7efc3b69d6a0265,openstack/puppet-keystone,master,Iea05a8ad944b884288ca1ed0c7efc3b69d6a0265,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:29:56.000000000,2019-02-11 20:39:02.000000000,2019-02-11 20:39:02.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:29:56.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/cb03afec8b48cfc31a5c586d237d6ca02333309f', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Iea05a8ad944b884288ca1ed0c7efc3b69d6a0265\n'}]",0,635753,cb03afec8b48cfc31a5c586d237d6ca02333309f,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Iea05a8ad944b884288ca1ed0c7efc3b69d6a0265
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/53/635753/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,cb03afec8b48cfc31a5c586d237d6ca02333309f,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-neutron~stable%2Fqueens~I192a190e714f42ac0e7deafc045244d8386bf9c8,openstack/puppet-neutron,stable/queens,I192a190e714f42ac0e7deafc045244d8386bf9c8,Prepare for 12.4.1 release,MERGED,2019-02-07 16:44:42.000000000,2019-02-11 20:38:30.000000000,2019-02-11 20:38:29.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 16:44:42.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/d924fa0ab73b1038026282679831a314f62f8576', 'message': 'Prepare for 12.4.1 release\n\nNeeded-By: https://review.openstack.org/#/c/635541\nChange-Id: I192a190e714f42ac0e7deafc045244d8386bf9c8\n'}]",0,635566,d924fa0ab73b1038026282679831a314f62f8576,8,4,1,8655,,,0,"Prepare for 12.4.1 release

Needed-By: https://review.openstack.org/#/c/635541
Change-Id: I192a190e714f42ac0e7deafc045244d8386bf9c8
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/66/635566/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,d924fa0ab73b1038026282679831a314f62f8576,release-12.4.1," ""version"": ""12.4.1"" } "," ""version"": ""12.4.0"" }",2,2
openstack%2Fpuppet-monasca~master~If7d7ab1736ddc0e436d2f12b951f0c54627faa79,openstack/puppet-monasca,master,If7d7ab1736ddc0e436d2f12b951f0c54627faa79,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:31:43.000000000,2019-02-11 20:38:00.000000000,2019-02-11 20:38:00.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:31:43.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/87bf97fedda73562ef593551d4e74d8a5e69085a', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: If7d7ab1736ddc0e436d2f12b951f0c54627faa79\n'}]",0,635757,87bf97fedda73562ef593551d4e74d8a5e69085a,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: If7d7ab1736ddc0e436d2f12b951f0c54627faa79
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/57/635757/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,87bf97fedda73562ef593551d4e74d8a5e69085a,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-glare~master~I181297c97acb79d059a65667cec95e9b392d3442,openstack/puppet-glare,master,I181297c97acb79d059a65667cec95e9b392d3442,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:27:20.000000000,2019-02-11 20:37:48.000000000,2019-02-11 20:37:48.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:27:20.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-glare/commit/f583de04e218cc4ec42db555e09c0ab06c1b170b', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I181297c97acb79d059a65667cec95e9b392d3442\n'}]",0,635748,f583de04e218cc4ec42db555e09c0ab06c1b170b,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I181297c97acb79d059a65667cec95e9b392d3442
",git fetch https://review.opendev.org/openstack/puppet-glare refs/changes/48/635748/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,f583de04e218cc4ec42db555e09c0ab06c1b170b,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-heat~master~I339e0525e5c335c7ac98c8ce2d79e7a15ecdb164,openstack/puppet-heat,master,I339e0525e5c335c7ac98c8ce2d79e7a15ecdb164,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:28:01.000000000,2019-02-11 20:36:20.000000000,2019-02-11 20:36:20.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:28:01.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-heat/commit/a76f651f359c378f6f376bdc4c8331cab756b4eb', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I339e0525e5c335c7ac98c8ce2d79e7a15ecdb164\n'}]",0,635750,a76f651f359c378f6f376bdc4c8331cab756b4eb,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I339e0525e5c335c7ac98c8ce2d79e7a15ecdb164
",git fetch https://review.opendev.org/openstack/puppet-heat refs/changes/50/635750/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,a76f651f359c378f6f376bdc4c8331cab756b4eb,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-designate~master~I5f5f1dbbacae96c9cce99badc4ff26a49275db63,openstack/puppet-designate,master,I5f5f1dbbacae96c9cce99badc4ff26a49275db63,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:25:48.000000000,2019-02-11 20:35:29.000000000,2019-02-11 20:35:29.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:25:48.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/b22f1c61258f2c89f0aa739c508529b2f95b0614', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I5f5f1dbbacae96c9cce99badc4ff26a49275db63\n'}]",0,635744,b22f1c61258f2c89f0aa739c508529b2f95b0614,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I5f5f1dbbacae96c9cce99badc4ff26a49275db63
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/44/635744/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,b22f1c61258f2c89f0aa739c508529b2f95b0614,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-horizon~master~I7e494b82c938da8a234653f6c3ca855deea50249,openstack/puppet-horizon,master,I7e494b82c938da8a234653f6c3ca855deea50249,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:28:16.000000000,2019-02-11 20:35:16.000000000,2019-02-11 20:35:16.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:28:16.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/d756d6aa76e25f195d5b09b3d15514075970e9ec', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I7e494b82c938da8a234653f6c3ca855deea50249\n'}]",0,635751,d756d6aa76e25f195d5b09b3d15514075970e9ec,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I7e494b82c938da8a234653f6c3ca855deea50249
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/51/635751/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,d756d6aa76e25f195d5b09b3d15514075970e9ec,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-magnum~master~I42dde35222bfba6ce71bd17a3d09357f6182856c,openstack/puppet-magnum,master,I42dde35222bfba6ce71bd17a3d09357f6182856c,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:30:16.000000000,2019-02-11 20:34:44.000000000,2019-02-11 20:34:44.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:30:16.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-magnum/commit/7c1cec77c902c2becfb530e50437cdaf29c65c3b', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I42dde35222bfba6ce71bd17a3d09357f6182856c\n'}]",0,635754,7c1cec77c902c2becfb530e50437cdaf29c65c3b,8,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I42dde35222bfba6ce71bd17a3d09357f6182856c
",git fetch https://review.opendev.org/openstack/puppet-magnum refs/changes/54/635754/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,7c1cec77c902c2becfb530e50437cdaf29c65c3b,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-freezer~master~I8a531103646ea732169bd6bf70b3747651acc14a,openstack/puppet-freezer,master,I8a531103646ea732169bd6bf70b3747651acc14a,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:26:37.000000000,2019-02-11 20:31:43.000000000,2019-02-11 20:31:43.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:26:37.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-freezer/commit/896753f7cd5b455164e9e9ec764717f5f0d1798b', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I8a531103646ea732169bd6bf70b3747651acc14a\n'}]",0,635746,896753f7cd5b455164e9e9ec764717f5f0d1798b,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I8a531103646ea732169bd6bf70b3747651acc14a
",git fetch https://review.opendev.org/openstack/puppet-freezer refs/changes/46/635746/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,896753f7cd5b455164e9e9ec764717f5f0d1798b,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-cinder~master~I1821d844b77e2bc73a790b6fff922c9d28f7f1a0,openstack/puppet-cinder,master,I1821d844b77e2bc73a790b6fff922c9d28f7f1a0,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:24:00.000000000,2019-02-11 20:30:45.000000000,2019-02-11 20:30:45.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:24:00.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-cinder/commit/1530dac810dbbca2b9d8fe5e1443916526f398c0', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I1821d844b77e2bc73a790b6fff922c9d28f7f1a0\n'}]",0,635741,1530dac810dbbca2b9d8fe5e1443916526f398c0,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I1821d844b77e2bc73a790b6fff922c9d28f7f1a0
",git fetch https://review.opendev.org/openstack/puppet-cinder refs/changes/41/635741/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,1530dac810dbbca2b9d8fe5e1443916526f398c0,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-ec2api~master~Ie9f22c5bb673a8b7164c3a2eb43e3161619e1a5c,openstack/puppet-ec2api,master,Ie9f22c5bb673a8b7164c3a2eb43e3161619e1a5c,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:26:11.000000000,2019-02-11 20:30:13.000000000,2019-02-11 20:30:13.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:26:11.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ec2api/commit/17071c8b7638a024870d17ede2785a42b35cd8ff', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ie9f22c5bb673a8b7164c3a2eb43e3161619e1a5c\n'}]",0,635745,17071c8b7638a024870d17ede2785a42b35cd8ff,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ie9f22c5bb673a8b7164c3a2eb43e3161619e1a5c
",git fetch https://review.opendev.org/openstack/puppet-ec2api refs/changes/45/635745/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,17071c8b7638a024870d17ede2785a42b35cd8ff,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-cloudkitty~master~I132635af907334e88e07faf675bfe2dc176293a2,openstack/puppet-cloudkitty,master,I132635af907334e88e07faf675bfe2dc176293a2,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:24:28.000000000,2019-02-11 20:29:36.000000000,2019-02-11 20:29:36.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:24:28.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/eb104774d06b4f6582c88cee97abb0d82f5d7f32', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I132635af907334e88e07faf675bfe2dc176293a2\n'}]",0,635742,eb104774d06b4f6582c88cee97abb0d82f5d7f32,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I132635af907334e88e07faf675bfe2dc176293a2
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/42/635742/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,eb104774d06b4f6582c88cee97abb0d82f5d7f32,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-congress~master~I60bfb987e656996f604b8d2f91048cada6e34754,openstack/puppet-congress,master,I60bfb987e656996f604b8d2f91048cada6e34754,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:24:57.000000000,2019-02-11 20:29:25.000000000,2019-02-11 20:29:25.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:24:57.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-congress/commit/affd25900e4f8ceacd8f31c15cb906e37a58fd67', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I60bfb987e656996f604b8d2f91048cada6e34754\n'}]",0,635743,affd25900e4f8ceacd8f31c15cb906e37a58fd67,8,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I60bfb987e656996f604b8d2f91048cada6e34754
",git fetch https://review.opendev.org/openstack/puppet-congress refs/changes/43/635743/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,affd25900e4f8ceacd8f31c15cb906e37a58fd67,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-ceilometer~master~Ia6ee6f40edfe83a791109823cf32c9003d2488ca,openstack/puppet-ceilometer,master,Ia6ee6f40edfe83a791109823cf32c9003d2488ca,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:23:39.000000000,2019-02-11 20:27:29.000000000,2019-02-11 20:27:29.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:23:39.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-ceilometer/commit/766a7faae79d7347704d514147dfa3d5a186ad8d', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ia6ee6f40edfe83a791109823cf32c9003d2488ca\n'}]",0,635740,766a7faae79d7347704d514147dfa3d5a186ad8d,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ia6ee6f40edfe83a791109823cf32c9003d2488ca
",git fetch https://review.opendev.org/openstack/puppet-ceilometer refs/changes/40/635740/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,766a7faae79d7347704d514147dfa3d5a186ad8d,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-barbican~master~Ic93ca9d37b844cf531e9588252607ed9bb3f85a4,openstack/puppet-barbican,master,Ic93ca9d37b844cf531e9588252607ed9bb3f85a4,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:23:15.000000000,2019-02-11 20:26:52.000000000,2019-02-11 20:26:52.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:23:15.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/c6ae5965c08da9d3c755c35615368cff8bd8d966', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: Ic93ca9d37b844cf531e9588252607ed9bb3f85a4\n'}]",0,635739,c6ae5965c08da9d3c755c35615368cff8bd8d966,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: Ic93ca9d37b844cf531e9588252607ed9bb3f85a4
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/39/635739/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,c6ae5965c08da9d3c755c35615368cff8bd8d966,remove-xenial,," ""16.04"",",0,1
openstack%2Fpuppet-aodh~master~I0570d28529082f601ad824733aa199327e26aa5a,openstack/puppet-aodh,master,I0570d28529082f601ad824733aa199327e26aa5a,Remove Ubuntu Xenial from metadata.json,MERGED,2019-02-08 10:22:38.000000000,2019-02-11 20:22:54.000000000,2019-02-11 20:22:54.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 10:22:38.000000000', 'files': ['metadata.json'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/3049eb7a239c1758a4e2f2aad98309f2b5ffe5d4', 'message': 'Remove Ubuntu Xenial from metadata.json\n\nThis is not supported anymore since packaging\nfor Stein will not only be for Bionic.\n\nChange-Id: I0570d28529082f601ad824733aa199327e26aa5a\n'}]",0,635738,3049eb7a239c1758a4e2f2aad98309f2b5ffe5d4,7,3,1,16137,,,0,"Remove Ubuntu Xenial from metadata.json

This is not supported anymore since packaging
for Stein will not only be for Bionic.

Change-Id: I0570d28529082f601ad824733aa199327e26aa5a
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/38/635738/1 && git format-patch -1 --stdout FETCH_HEAD,['metadata.json'],1,3049eb7a239c1758a4e2f2aad98309f2b5ffe5d4,remove-xenial,," ""16.04"",",0,1
openstack%2Fnova~master~I61f329ae61cb8f9d76985353564ee014d7c98af9,openstack/nova,master,I61f329ae61cb8f9d76985353564ee014d7c98af9,Don't log an error if attachment_create fails,ABANDONED,2018-10-10 21:14:14.000000000,2019-02-11 20:02:13.000000000,,"[{'_account_id': 7634}, {'_account_id': 8864}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-10-10 21:14:14.000000000', 'files': ['nova/volume/cinder.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/60fed368e7b76a71584c55823489621bc1efeaec', 'message': ""Don't log an error if attachment_create fails\n\nThere are very obvious reasons that creating a\nvolume attachment in cinder returns a failure, like\nif you try to create an attachment on an in-use\nvolume to another server when the volume does not\nsupport multi-attach.\n\nThe nova-api logs are currently logging an ERROR\nin this case which is excessive. It results in a\n400 response to the user, so it's not an error and\ndoesn't require any kind of operator intervention.\n\nThe translate_volume_exception and translate_cinder_exception\ndecorators are what handle and translate the\ncinderclient exception to a nova exception and are\nsufficient.\n\nChange-Id: I61f329ae61cb8f9d76985353564ee014d7c98af9\nCloses-Bug: #1797237\n""}]",0,609547,60fed368e7b76a71584c55823489621bc1efeaec,18,16,1,6873,,,0,"Don't log an error if attachment_create fails

There are very obvious reasons that creating a
volume attachment in cinder returns a failure, like
if you try to create an attachment on an in-use
volume to another server when the volume does not
support multi-attach.

The nova-api logs are currently logging an ERROR
in this case which is excessive. It results in a
400 response to the user, so it's not an error and
doesn't require any kind of operator intervention.

The translate_volume_exception and translate_cinder_exception
decorators are what handle and translate the
cinderclient exception to a nova exception and are
sufficient.

Change-Id: I61f329ae61cb8f9d76985353564ee014d7c98af9
Closes-Bug: #1797237
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/609547/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/volume/cinder.py'],1,60fed368e7b76a71584c55823489621bc1efeaec,bug/1797237," attachment_ref = cinderclient(context, '3.44').attachments.create( volume_id, _connector, instance_id) return _translate_attachment_ref(attachment_ref)"," try: attachment_ref = cinderclient(context, '3.44').attachments.create( volume_id, _connector, instance_id) return _translate_attachment_ref(attachment_ref) except cinder_exception.ClientException as ex: with excutils.save_and_reraise_exception(): LOG.error(('Create attachment failed for volume ' '%(volume_id)s. Error: %(msg)s Code: %(code)s'), {'volume_id': volume_id, 'msg': six.text_type(ex), 'code': getattr(ex, 'code', None)}, instance_uuid=instance_id)",3,13
openstack%2Fpython-magnumclient~master~I4ae2049d8a2469d0a37077bdc722481e68d7cc49,openstack/python-magnumclient,master,I4ae2049d8a2469d0a37077bdc722481e68d7cc49,Fix py37 compatibility,MERGED,2019-02-06 13:11:44.000000000,2019-02-11 19:59:16.000000000,2019-02-11 19:59:16.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27339}]","[{'number': 1, 'created': '2019-02-06 13:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/20230972bc8543bdf51eeb55b3a17797f43192f3', 'message': 'Fix py37 compatibility\n\nUnit tests are failing under python3.7.\nGenerators which explicitly raise StopIteration can generally be\nchanged to simply return instead. This will be compatible with\nall existing Python versions.\n\nPEP Documentation for this change:\nhttps://www.python.org/dev/peps/pep-0479/\n\nChange-Id: I4ae2049d8a2469d0a37077bdc722481e68d7cc49\nCloses-Bug: #1814890\n'}, {'number': 2, 'created': '2019-02-06 14:33:47.000000000', 'files': ['magnumclient/common/httpclient.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/5deb538930d98bf83e11bfb1dacb509982226540', 'message': 'Fix py37 compatibility\n\nUnit tests are failing under python3.7.\nGenerators which explicitly raise StopIteration can generally be\nchanged to simply return instead. This will be compatible with\nall existing Python versions.\n\nPEP Documentation for this change:\nhttps://www.python.org/dev/peps/pep-0479/\n\nChange-Id: I4ae2049d8a2469d0a37077bdc722481e68d7cc49\nCloses-Bug: #1814890\n'}]",0,635151,5deb538930d98bf83e11bfb1dacb509982226540,13,5,2,27339,,,0,"Fix py37 compatibility

Unit tests are failing under python3.7.
Generators which explicitly raise StopIteration can generally be
changed to simply return instead. This will be compatible with
all existing Python versions.

PEP Documentation for this change:
https://www.python.org/dev/peps/pep-0479/

Change-Id: I4ae2049d8a2469d0a37077bdc722481e68d7cc49
Closes-Bug: #1814890
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/51/635151/1 && git format-patch -1 --stdout FETCH_HEAD,['magnumclient/common/httpclient.py'],1,20230972bc8543bdf51eeb55b3a17797f43192f3,bug/1814890, return, raise StopIteration(),1,1
openstack%2Fproject-config~master~I242832fb075ada52f897bbcfea842f16bc424ea2,openstack/project-config,master,I242832fb075ada52f897bbcfea842f16bc424ea2,Remove opendev/base-jobs jobs,MERGED,2019-02-09 10:48:24.000000000,2019-02-11 19:53:10.000000000,2019-02-11 19:53:10.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 10:48:24.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2906ebe927aa7c513d6d7e37a8be16423d89bf94', 'message': 'Remove opendev/base-jobs jobs\n\nRemove noop-jobs from opendev/base-jobs since we now have in-tree jobs.\n\nChange-Id: I242832fb075ada52f897bbcfea842f16bc424ea2\nDepends-On: https://review.openstack.org/636006\n'}]",0,636009,2906ebe927aa7c513d6d7e37a8be16423d89bf94,7,3,1,6547,,,0,"Remove opendev/base-jobs jobs

Remove noop-jobs from opendev/base-jobs since we now have in-tree jobs.

Change-Id: I242832fb075ada52f897bbcfea842f16bc424ea2
Depends-On: https://review.openstack.org/636006
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/636009/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,2906ebe927aa7c513d6d7e37a8be16423d89bf94,opendev-noop,,# Minimal setup to allow us to merge changes to opendev/base-jobs - project: name: opendev/base-jobs templates: - noop-jobs ,0,6
openstack%2Ftripleo-heat-templates~master~Id3e52e272bae67ee4036c81b3d7640255e0349ae,openstack/tripleo-heat-templates,master,Id3e52e272bae67ee4036c81b3d7640255e0349ae,Add GlobalConfigExtraMapData,MERGED,2019-02-08 15:30:37.000000000,2019-02-11 19:24:15.000000000,2019-02-11 19:24:15.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 15:30:37.000000000', 'files': ['releasenotes/notes/add-GlobalConfigExtraMapData-793757a2b767abe3.yaml', 'overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2634ffaa5d9157ca16375456e3115cf2a9fcedf3', 'message': 'Add GlobalConfigExtraMapData\n\nAdds a new GlobalConfigExtraMapData parameter that can be used to inject\nglobal_config_settings hieradata into the deployment. Any values generated\nin the stack will override those passed in by the parameter value.\n\nThis will be used for the distributed compute node when deploying with separate\nstacks and data from the control plane stack needs to be injected into the\ncompute stack.\n\nChange-Id: Id3e52e272bae67ee4036c81b3d7640255e0349ae\n'}]",0,635861,2634ffaa5d9157ca16375456e3115cf2a9fcedf3,8,4,1,7144,,,0,"Add GlobalConfigExtraMapData

Adds a new GlobalConfigExtraMapData parameter that can be used to inject
global_config_settings hieradata into the deployment. Any values generated
in the stack will override those passed in by the parameter value.

This will be used for the distributed compute node when deploying with separate
stacks and data from the control plane stack needs to be injected into the
compute stack.

Change-Id: Id3e52e272bae67ee4036c81b3d7640255e0349ae
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/61/635861/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-GlobalConfigExtraMapData-793757a2b767abe3.yaml', 'overcloud.j2.yaml']",2,2634ffaa5d9157ca16375456e3115cf2a9fcedf3,, GlobalConfigExtraMapData: type: json default: {} description: Map of extra global_config_settings data to set on each node. - get_param: GlobalConfigExtraMapData,,11,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I0256ceae17bc7be2c9dfa7a8e12bb70c89eba14c,openstack/tripleo-heat-templates,stable/queens,I0256ceae17bc7be2c9dfa7a8e12bb70c89eba14c,[Queens-Only] Remove Glance's nfs hardcoded version,MERGED,2019-02-07 08:07:15.000000000,2019-02-11 19:24:13.000000000,2019-02-11 19:24:13.000000000,"[{'_account_id': 3153}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 08:07:15.000000000', 'files': ['docker/services/glance-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f32321d80f8d6e8b41d29de8dbd9eb1811dc496d', 'message': ""[Queens-Only] Remove Glance's nfs hardcoded version\n\nGlance nfs version is hardcoded in tripleo which makes the fstab\nentry with nfs version 4 even though user sets another version\nvia 'GlanceNfsOptions' parameter.\n\nSince this issues has been fixed in rocky during one nfs cleanup\npatch[1], we just need to fix this in Queens.\n\nNote: Partial-cherrypick of [1] is not possible here because glance\nnfs part of code is moved to another file.\n\n[1]: https://review.openstack.org/#/c/576043/\n\nChange-Id: I0256ceae17bc7be2c9dfa7a8e12bb70c89eba14c\nCloses-Bug: #1815011\n""}]",0,635449,f32321d80f8d6e8b41d29de8dbd9eb1811dc496d,8,4,1,19138,,,0,"[Queens-Only] Remove Glance's nfs hardcoded version

Glance nfs version is hardcoded in tripleo which makes the fstab
entry with nfs version 4 even though user sets another version
via 'GlanceNfsOptions' parameter.

Since this issues has been fixed in rocky during one nfs cleanup
patch[1], we just need to fix this in Queens.

Note: Partial-cherrypick of [1] is not possible here because glance
nfs part of code is moved to another file.

[1]: https://review.openstack.org/#/c/576043/

Change-Id: I0256ceae17bc7be2c9dfa7a8e12bb70c89eba14c
Closes-Bug: #1815011
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/49/635449/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/glance-api.yaml'],1,f32321d80f8d6e8b41d29de8dbd9eb1811dc496d,bug/1815011," mount: name=/var/lib/glance/images src=""{{item.NFS_SHARE}}"" fstype=nfs opts=""{{item.NFS_OPTIONS}}"" state=mounted"," mount: name=/var/lib/glance/images src=""{{item.NFS_SHARE}}"" fstype=nfs4 opts=""{{item.NFS_OPTIONS}}"" state=mounted",1,1
openstack%2Ftripleo-heat-templates~master~I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78,openstack/tripleo-heat-templates,master,I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78,Add support for persistence of MariaDB data during reprovisioning,MERGED,2019-01-16 10:49:01.000000000,2019-02-11 19:24:11.000000000,2019-02-11 19:24:10.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11166}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-16 10:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34501954440e3aae1ca3b296893f96c9bad69bd6', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}, {'number': 2, 'created': '2019-01-17 12:21:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2cb4f88ec8182eb19cb4c7fea842e64682e393e7', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}, {'number': 3, 'created': '2019-01-17 17:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/276ae914647f42c245309d8d34b591b8ce81f588', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}, {'number': 4, 'created': '2019-01-18 15:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2e3b0011623698c8ae24187db34bc4d27bf207ff', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nWe should support arbitrary tags in upgrade tasks, update the\nvalidation accordingly.\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}, {'number': 5, 'created': '2019-01-22 13:05:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a00336d9de016ffd7f0ee15966af0ebecca9ca5', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nWe should support arbitrary tags in upgrade tasks, update the\nvalidation accordingly.\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}, {'number': 6, 'created': '2019-02-06 13:16:17.000000000', 'files': ['docker/services/pacemaker/database/mysql.yaml', 'common/deploy-steps.j2', 'tools/yaml-validate.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a64fa251e587d78766bd5ccb495d8add9aa89b21', 'message': 'Add support for persistence of MariaDB data during reprovisioning\n\nWe should support arbitrary tags in upgrade tasks, update the\nvalidation accordingly.\n\nChange-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78\nImplements: blueprint upgrades-with-os\n'}]",2,631185,a64fa251e587d78766bd5ccb495d8add9aa89b21,28,6,6,8042,,,0,"Add support for persistence of MariaDB data during reprovisioning

We should support arbitrary tags in upgrade tasks, update the
validation accordingly.

Change-Id: I3ebeb06b18306a8d1de11b3519e62b90a9cd6a78
Implements: blueprint upgrades-with-os
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/85/631185/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/database/mysql.yaml', 'common/deploy-steps.j2']",2,34501954440e3aae1ca3b296893f96c9bad69bd6,bp/upgrades-with-os, tags: always,,25,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ib6efd03584c95ed4ab997f614aa3178b01877b8c,openstack/tripleo-heat-templates,stable/rocky,Ib6efd03584c95ed4ab997f614aa3178b01877b8c,run docker_puppet_tasks on any role,MERGED,2019-01-23 13:00:20.000000000,2019-02-11 19:24:08.000000000,2019-02-11 19:24:08.000000000,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-23 13:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/aaeac363b88800d2cb99fdf05b735dd05a7bb738', 'message': ""WIP run docker_puppet_tasks on any role\n\nCurrently this assumes all tasks will run on the primary controller\nbut because of composable roles, that may not be the case.\n\nAn example is if you deploy keystone on any role other than the\nrole tagged primary e.g Controller by default, we don't create\nany of the users/endpoints because the tasks aren't written to\nthe role unless keystone actually runs there.\n\nConflicts:\n\tcommon/deploy-steps-tasks.yaml\n\nRelated-Bug: #1792613\nDepends-On: Idcee177b21e85cff9e0bf10f4c43c71eff9364ec\nChange-Id: Ib6efd03584c95ed4ab997f614aa3178b01877b8c\n(cherry picked from commit edf2174b3ecb180bea7d770a95962c8efbb08be7)\n""}, {'number': 2, 'created': '2019-02-11 09:58:50.000000000', 'files': ['common/services.yaml', 'common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/87b16ddbfc19263e81bf49a5c643855c98ffb240', 'message': ""run docker_puppet_tasks on any role\n\nCurrently this assumes all tasks will run on the primary controller\nbut because of composable roles, that may not be the case.\n\nAn example is if you deploy keystone on any role other than the\nrole tagged primary e.g Controller by default, we don't create\nany of the users/endpoints because the tasks aren't written to\nthe role unless keystone actually runs there.\n\nConflicts:\n\tcommon/deploy-steps-tasks.yaml\n\nCloses-Bug: #1792613\nChange-Id: Ib6efd03584c95ed4ab997f614aa3178b01877b8c\n(cherry picked from commit a0a09d29aac1ad44fa48dae5d1db72e3905aeb69)\n""}]",0,632714,87b16ddbfc19263e81bf49a5c643855c98ffb240,11,5,2,4328,,,0,"run docker_puppet_tasks on any role

Currently this assumes all tasks will run on the primary controller
but because of composable roles, that may not be the case.

An example is if you deploy keystone on any role other than the
role tagged primary e.g Controller by default, we don't create
any of the users/endpoints because the tasks aren't written to
the role unless keystone actually runs there.

Conflicts:
	common/deploy-steps-tasks.yaml

Closes-Bug: #1792613
Change-Id: Ib6efd03584c95ed4ab997f614aa3178b01877b8c
(cherry picked from commit a0a09d29aac1ad44fa48dae5d1db72e3905aeb69)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/632714/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/services.yaml', 'common/deploy-steps-tasks.yaml']",2,aaeac363b88800d2cb99fdf05b735dd05a7bb738,bug/1792613," # Bootstrap tasks - run any tasks that have been defined - name: ""Clean docker_puppet_tasks for {{ansible_hostname}} step {{step}}"" file: path: /var/lib/docker-puppet/docker-puppet-tasks{{step}}.json state: absent - name: SHDEBUG Calculate docker_puppet_tasks for {{ansible_hostname}} step {{step}} debug: msg: ""SHDEBUG service name = {{item.service_name}} {{item.service_name}}_short_bootstrap_node_name = {{vars[item.service_name + '_short_bootstrap_node_name']}} ansible_hostname={{ansible_hostname}}"" loop: ""{{docker_puppet_tasks.get('step_' + step, [])}}"" vars: docker_puppet_tasks: ""{{ lookup('file', tripleo_role_name + '/docker_puppet_tasks.yaml', errors='ignore') | default({}, True) | from_yaml }}"" tags: - container_config_tasks - name: Calculate docker_puppet_tasks for {{ansible_hostname}} step {{step}} set_fact: host_docker_puppet_tasks: ""{{host_docker_puppet_tasks|default([]) + [item]}}"" loop: ""{{docker_puppet_tasks.get('step_' + step, [])}}"" when: vars[item.service_name + '_short_bootstrap_node_name'] == ansible_hostname vars: docker_puppet_tasks: ""{{ lookup('file', tripleo_role_name + '/docker_puppet_tasks.yaml', errors='ignore') | default({}, True) | from_yaml }}"" tags: - container_config_tasks - name: Write docker-puppet-tasks json file for {{ansible_hostname}} step {{step}} copy: content: ""{{host_docker_puppet_tasks|to_nice_json}}"" dest: ""/var/lib/docker-puppet/docker-puppet-tasks{{step}}.json"" force: yes mode: '0600' tags: - container_config_tasks when: host_docker_puppet_tasks is defined when: host_docker_puppet_tasks is defined"," ######################################################## # Bootstrap tasks, only performed on bootstrap_server_id ######################################################## - name: Clean /var/lib/docker-puppet/docker-puppet-tasks*.json files file: path: ""{{ item }}"" state: absent with_fileglob: - /var/lib/docker-puppet/docker-puppet-tasks*.json when: deploy_server_id == bootstrap_server_id tags: - container_config_tasks - name: Write docker-puppet-tasks json files copy: content: ""{{item[1]|to_nice_json}}"" dest: /var/lib/docker-puppet/docker-puppet-tasks{{item[0].replace(""step_"", """")}}.json force: yes mode: '0600' loop: ""{{ lookup('file', tripleo_role_name + '/docker_puppet_tasks.yaml', errors='ignore') | default({}, True) | from_yaml | dictsort }}"" loop_control: label: ""{{ item[0] }}"" when: deploy_server_id == bootstrap_server_id tags: - container_config_tasks # Bootstrap tasks, only performed on bootstrap_server_id - name: Check if /var/lib/docker-puppet/docker-puppet-tasks{{ step }}.json exists stat: path: /var/lib/docker-puppet/{{ ansible_check_mode | ternary('check-mode/', '') }}docker-puppet-tasks{{ step }}.json register: docker_puppet_tasks_json when: - deploy_server_id == bootstrap_server_id - docker_puppet_tasks_json.stat.exists",39,37
openstack%2Fsenlin~master~Iea4d667e62b2b6bdebe0ff74d7536987708aba10,openstack/senlin,master,Iea4d667e62b2b6bdebe0ff74d7536987708aba10,Use region_name when getting endpoint URL,MERGED,2019-02-08 21:49:06.000000000,2019-02-11 19:17:27.000000000,2019-02-11 19:17:27.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}]","[{'number': 1, 'created': '2019-02-08 21:49:06.000000000', 'files': ['senlin/tests/unit/drivers/test_keystone_v3.py', 'senlin/drivers/os/keystone_v3.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9d6c0a8d25218d6d956c7730ab1882e6bccae1d1', 'message': 'Use region_name when getting endpoint URL\n\nThe keystone driver was passing in the wrong parameter name for region\nwhen trying to get an endpoint.  It has to be region_name as described\nin the function signature in [1].\n\nThis fixes a problem where the webhook URL returned when creating a\nreceiver points to a different region.\n\n[1] https://github.com/openstack/keystoneauth/blob/master/keystoneauth1/identity/base.py#L162\n\nChange-Id: Iea4d667e62b2b6bdebe0ff74d7536987708aba10\n'}]",0,635953,9d6c0a8d25218d6d956c7730ab1882e6bccae1d1,8,3,1,27224,,,0,"Use region_name when getting endpoint URL

The keystone driver was passing in the wrong parameter name for region
when trying to get an endpoint.  It has to be region_name as described
in the function signature in [1].

This fixes a problem where the webhook URL returned when creating a
receiver points to a different region.

[1] https://github.com/openstack/keystoneauth/blob/master/keystoneauth1/identity/base.py#L162

Change-Id: Iea4d667e62b2b6bdebe0ff74d7536987708aba10
",git fetch https://review.opendev.org/openstack/senlin refs/changes/53/635953/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/drivers/test_keystone_v3.py', 'senlin/drivers/os/keystone_v3.py']",2,9d6c0a8d25218d6d956c7730ab1882e6bccae1d1,fix_senlin_ep_region, region_name=region)," # TODO(Yanyan Hu): Currently, region filtering is unsupported in # session.get_endpoint(). Need to propose fix to openstacksdk. region=region)",3,4
openstack%2Fnova~master~Id73a2665e7fa914e00dc60a085a7cd9f47655a73,openstack/nova,master,Id73a2665e7fa914e00dc60a085a7cd9f47655a73,doc: mention description field in user flavors docs,MERGED,2019-02-06 20:29:11.000000000,2019-02-11 19:13:37.000000000,2019-02-09 07:54:49.000000000,"[{'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-06 20:29:11.000000000', 'files': ['doc/source/user/flavors.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/cfa1cabd0fb467440e241194139c49ccd5343786', 'message': ""doc: mention description field in user flavors docs\n\nThe first section in the doc mentions the properties of\na flavor but didn't mention description which was added\nin 2.55 so this adds it.\n\nChange-Id: Id73a2665e7fa914e00dc60a085a7cd9f47655a73\n""}]",2,635263,cfa1cabd0fb467440e241194139c49ccd5343786,11,6,1,6873,,,0,"doc: mention description field in user flavors docs

The first section in the doc mentions the properties of
a flavor but didn't mention description which was added
in 2.55 so this adds it.

Change-Id: Id73a2665e7fa914e00dc60a085a7cd9f47655a73
",git fetch https://review.opendev.org/openstack/nova refs/changes/63/635263/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/flavors.rst'],1,cfa1cabd0fb467440e241194139c49ccd5343786,doc-flavor-description,Description A free form description of the flavor. Limited to 65535 characters in length. Only printable characters are allowed. Available starting in microversion 2.55. ,,5,0
openstack%2Ftripleo-heat-templates~master~I730b107d4b5a002f82f658a83d11162606e44a16,openstack/tripleo-heat-templates,master,I730b107d4b5a002f82f658a83d11162606e44a16,Remove incorrect mapped_data key from cisco ml2 hieradata,MERGED,2018-09-06 09:45:51.000000000,2019-02-11 19:13:00.000000000,2019-02-11 19:13:00.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-06 09:45:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b645c8333144e6268d79d41585ad424f9217d6a4', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 2, 'created': '2018-09-18 13:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47ba34f3c55be1d89b5c3102fb475a83e2e4ec5b', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 3, 'created': '2018-10-01 11:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/df11b28690bb5a4f19b476f47c7a5b0f034e325b', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 4, 'created': '2018-10-26 12:36:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d91dd288ad9bdf01fd5bda23cbac94553eca891c', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 5, 'created': '2018-10-30 10:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/499b9c2e1e62d79cd5aa086dc228d332a488654b', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 6, 'created': '2019-02-05 01:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fd7040cf0bc7122b44394ecf6f973d4169fa8adb', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 7, 'created': '2019-02-05 01:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1587768c83e10581ead508949b28b0ea9e63316c', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}, {'number': 8, 'created': '2019-02-05 01:06:24.000000000', 'files': ['puppet/extraconfig/all_nodes/neutron-ml2-cisco-nexus-ucsm.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/95245f6ad4a85584081cfe1004e44329995a85b1', 'message': 'Remove incorrect mapped_data key from cisco ml2 hieradata\n\nSince os-apply-config changed to the hiera hook here:\nhttps://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b\nthe mapped_data key is no longer required and results in an additional\nincorrect key being written to the hiera data. This patch removes it to\nensure the hiera data for cisco ml2 works as expected.\n\nChange-Id: I730b107d4b5a002f82f658a83d11162606e44a16\nCloses-Bug: #1791044\n'}]",0,600396,95245f6ad4a85584081cfe1004e44329995a85b1,25,5,8,6637,,,0,"Remove incorrect mapped_data key from cisco ml2 hieradata

Since os-apply-config changed to the hiera hook here:
https://github.com/openstack/tripleo-heat-templates/commit/c5d10cd9fc94e6557417673190b73867a83cbb7b
the mapped_data key is no longer required and results in an additional
incorrect key being written to the hiera data. This patch removes it to
ensure the hiera data for cisco ml2 works as expected.

Change-Id: I730b107d4b5a002f82f658a83d11162606e44a16
Closes-Bug: #1791044
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/600396/8 && git format-patch -1 --stdout FETCH_HEAD,['puppet/extraconfig/all_nodes/neutron-ml2-cisco-nexus-ucsm.j2.yaml'],1,b645c8333144e6268d79d41585ad424f9217d6a4,cisco-ucsm, neutron::plugins::ml2::cisco::ucsm::ucsm_ip: {get_input: UCSM_ip} neutron::plugins::ml2::cisco::ucsm::ucsm_username: {get_input: UCSM_username} neutron::plugins::ml2::cisco::ucsm::ucsm_password: {get_input: UCSM_password} neutron::plugins::ml2::cisco::ucsm::ucsm_host_list: {get_input: UCSM_host_list} neutron::plugins::ml2::cisco::ucsm::supported_pci_devs: {get_input: UCSMSupportedPciDevs} neutron::plugins::ml2::cisco::ucsm::ucsm_https_verify: {get_input: UCSMHttpsVerify} neutron::plugins::ml2::cisco::ucsm::sp_template_list: {get_input: UCSMSpTemplateList} neutron::plugins::ml2::cisco::ucsm::vnic_template_list: {get_input: UCSMVnicTemplateList} neutron::plugins::ml2::cisco::nexus::nexus_config: {get_input: NexusConfig} neutron::plugins::ml2::cisco::nexus::managed_physical_network: {get_input: NexusManagedPhysicalNetwork} neutron::plugins::ml2::cisco::nexus::vlan_name_prefix: {get_input: NexusVlanNamePrefix} neutron::plugins::ml2::cisco::nexus::svi_round_robin: {get_input: NexusSviRoundRobin} neutron::plugins::ml2::cisco::nexus::provider_vlan_name_prefix: {get_input: NexusProviderVlanNamePrefix} neutron::plugins::ml2::cisco::nexus::persistent_switch_config: {get_input: NexusPersistentSwitchConfig} neutron::plugins::ml2::cisco::nexus::never_cache_ssh_connection: {get_input: NexusNeverCacheSshConnection} neutron::plugins::ml2::cisco::nexus::switch_heartbeat_time: {get_input: NexusSwitchHeartbeatTime} neutron::plugins::ml2::cisco::nexus::switch_replay_count: {get_input: NexusSwitchReplayCount} neutron::plugins::ml2::cisco::nexus::nexus_driver: {get_input: NexusCfgDriver} neutron::plugins::ml2::cisco::nexus::provider_vlan_auto_create: {get_input: NexusProviderVlanAutoCreate} neutron::plugins::ml2::cisco::nexus::provider_vlan_auto_trunk: {get_input: NexusProviderVlanAutoTrunk} neutron::plugins::ml2::cisco::nexus::vxlan_global_config: {get_input: NexusVxlanGlobalConfig} neutron::plugins::ml2::cisco::nexus::host_key_checks: {get_input: NexusHostKeyChecks} neutron::plugins::ml2::cisco::type_nexus_vxlan::vni_ranges: {get_input: NexusVxlanVniRanges} neutron::plugins::ml2::cisco::type_nexus_vxlan::mcast_ranges: {get_input: NexusVxlanMcastRanges}, mapped_data: neutron::plugins::ml2::cisco::ucsm::ucsm_ip: {get_input: UCSM_ip} neutron::plugins::ml2::cisco::ucsm::ucsm_username: {get_input: UCSM_username} neutron::plugins::ml2::cisco::ucsm::ucsm_password: {get_input: UCSM_password} neutron::plugins::ml2::cisco::ucsm::ucsm_host_list: {get_input: UCSM_host_list} neutron::plugins::ml2::cisco::ucsm::supported_pci_devs: {get_input: UCSMSupportedPciDevs} neutron::plugins::ml2::cisco::ucsm::ucsm_https_verify: {get_input: UCSMHttpsVerify} neutron::plugins::ml2::cisco::ucsm::sp_template_list: {get_input: UCSMSpTemplateList} neutron::plugins::ml2::cisco::ucsm::vnic_template_list: {get_input: UCSMVnicTemplateList} neutron::plugins::ml2::cisco::nexus::nexus_config: {get_input: NexusConfig} neutron::plugins::ml2::cisco::nexus::managed_physical_network: {get_input: NexusManagedPhysicalNetwork} neutron::plugins::ml2::cisco::nexus::vlan_name_prefix: {get_input: NexusVlanNamePrefix} neutron::plugins::ml2::cisco::nexus::svi_round_robin: {get_input: NexusSviRoundRobin} neutron::plugins::ml2::cisco::nexus::provider_vlan_name_prefix: {get_input: NexusProviderVlanNamePrefix} neutron::plugins::ml2::cisco::nexus::persistent_switch_config: {get_input: NexusPersistentSwitchConfig} neutron::plugins::ml2::cisco::nexus::never_cache_ssh_connection: {get_input: NexusNeverCacheSshConnection} neutron::plugins::ml2::cisco::nexus::switch_heartbeat_time: {get_input: NexusSwitchHeartbeatTime} neutron::plugins::ml2::cisco::nexus::switch_replay_count: {get_input: NexusSwitchReplayCount} neutron::plugins::ml2::cisco::nexus::nexus_driver: {get_input: NexusCfgDriver} neutron::plugins::ml2::cisco::nexus::provider_vlan_auto_create: {get_input: NexusProviderVlanAutoCreate} neutron::plugins::ml2::cisco::nexus::provider_vlan_auto_trunk: {get_input: NexusProviderVlanAutoTrunk} neutron::plugins::ml2::cisco::nexus::vxlan_global_config: {get_input: NexusVxlanGlobalConfig} neutron::plugins::ml2::cisco::nexus::host_key_checks: {get_input: NexusHostKeyChecks} neutron::plugins::ml2::cisco::type_nexus_vxlan::vni_ranges: {get_input: NexusVxlanVniRanges} neutron::plugins::ml2::cisco::type_nexus_vxlan::mcast_ranges: {get_input: NexusVxlanMcastRanges},24,25
openstack%2Ftripleo-heat-templates~stable%2Fpike~I2e61030c863041cd73cb204e31e423da3c6f6944,openstack/tripleo-heat-templates,stable/pike,I2e61030c863041cd73cb204e31e423da3c6f6944,Catch directories we can not change ownership,MERGED,2019-02-05 08:06:45.000000000,2019-02-11 19:12:58.000000000,2019-02-11 19:12:58.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-05 08:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8e6e79dd563f09fc0fcde3d05785002c40a3f9ae', 'message': 'Catch directories we can not change ownership\n\nWhen there is a directory where the owner can not be changed, we\nfail and do not proceed to check the remaining directories. This\nhas been seen where netapp creates a special .snapshot directory\nwhich is protected and visible when useing NFSv3, not visible\nwhen using NFSv4.\n\nThis change catches the error and proceeds.\n\nChange-Id: I2e61030c863041cd73cb204e31e423da3c6f6944\nResolves-Bug: 1814260\n(cherry picked from commit 898154857501b09a0101d4b7d8cbbd2c4c8b64d6)\n(cherry picked from commit aaf20f4a1f36ad548528a2b8926816f19ae2cd28)\n(cherry picked from commit c6b1a1f0f090f2af0c633e6d75ad20ae6382750d)\n'}, {'number': 2, 'created': '2019-02-05 11:31:56.000000000', 'files': ['docker_config_scripts/nova_statedir_ownership.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fc4b59a9806d6d0f42aba6c4e79d7e2de644209c', 'message': 'Catch directories we can not change ownership\n\nWhen there is a directory where the owner can not be changed, we\nfail and do not proceed to check the remaining directories. This\nhas been seen where netapp creates a special .snapshot directory\nwhich is protected and visible when useing NFSv3, not visible\nwhen using NFSv4.\n\nThis change catches the error and proceeds.\n\nChange-Id: I2e61030c863041cd73cb204e31e423da3c6f6944\nResolves-Bug: 1814260\n(cherry picked from commit 898154857501b09a0101d4b7d8cbbd2c4c8b64d6)\n(cherry picked from commit aaf20f4a1f36ad548528a2b8926816f19ae2cd28)\n(cherry picked from commit c6b1a1f0f090f2af0c633e6d75ad20ae6382750d)\n'}]",0,634878,fc4b59a9806d6d0f42aba6c4e79d7e2de644209c,15,8,2,17216,,,0,"Catch directories we can not change ownership

When there is a directory where the owner can not be changed, we
fail and do not proceed to check the remaining directories. This
has been seen where netapp creates a special .snapshot directory
which is protected and visible when useing NFSv3, not visible
when using NFSv4.

This change catches the error and proceeds.

Change-Id: I2e61030c863041cd73cb204e31e423da3c6f6944
Resolves-Bug: 1814260
(cherry picked from commit 898154857501b09a0101d4b7d8cbbd2c4c8b64d6)
(cherry picked from commit aaf20f4a1f36ad548528a2b8926816f19ae2cd28)
(cherry picked from commit c6b1a1f0f090f2af0c633e6d75ad20ae6382750d)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/78/634878/1 && git format-patch -1 --stdout FETCH_HEAD,['docker_config_scripts/nova_statedir_ownership.py'],1,8e6e79dd563f09fc0fcde3d05785002c40a3f9ae,bug/1814260," try: os.chown(self.path, target_uid, target_gid) self._update() except Exception as e: LOG.exception('Could not change ownership of %s: ', self.path)"," os.chown(self.path, target_uid, target_gid) self._update()",6,2
openstack%2Ftripleo-heat-templates~stable%2Fpike~I5eaaad9371183dff070d0eb72457fb76a6a60ebe,openstack/tripleo-heat-templates,stable/pike,I5eaaad9371183dff070d0eb72457fb76a6a60ebe,Run nova_statedir_owner on every run,MERGED,2019-02-05 08:06:45.000000000,2019-02-11 19:12:57.000000000,2019-02-11 19:12:57.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-02-05 08:06:45.000000000', 'files': ['docker/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2ccd9ed267cbb9b078d8255ec6effb273ee1b50e', 'message': 'Run nova_statedir_owner on every run\n\nSo far nova_statedir_owner step is only run on initial deploy or\nwhen the image changes. This runs it on every deploy/scale/...\nrun.\n\nRelated-Bug: 1814260\n\nChange-Id: I5eaaad9371183dff070d0eb72457fb76a6a60ebe\n(cherry picked from commit efaf0c3bea07e64361390a2ac573552fe69715b4)\n(cherry picked from commit ea6fc8f95da041636fa4e1ab7e3524ad5c9992ed)\n(cherry picked from commit 4b52a678e431419f0a70ab6eaaade564b9eb8401)\n'}]",0,634877,2ccd9ed267cbb9b078d8255ec6effb273ee1b50e,12,8,1,17216,,,0,"Run nova_statedir_owner on every run

So far nova_statedir_owner step is only run on initial deploy or
when the image changes. This runs it on every deploy/scale/...
run.

Related-Bug: 1814260

Change-Id: I5eaaad9371183dff070d0eb72457fb76a6a60ebe
(cherry picked from commit efaf0c3bea07e64361390a2ac573552fe69715b4)
(cherry picked from commit ea6fc8f95da041636fa4e1ab7e3524ad5c9992ed)
(cherry picked from commit 4b52a678e431419f0a70ab6eaaade564b9eb8401)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/77/634877/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/nova-compute.yaml'],1,2ccd9ed267cbb9b078d8255ec6effb273ee1b50e,bug/1814260," DeployIdentifier: default: '' type: string description: > Setting this to a unique value will re-run any deployment tasks which perform configuration on a Heat stack-update. environment: # NOTE: this should force this container to re-run on each # update (scale-out, etc.) - list_join: - '' - - 'TRIPLEO_DEPLOY_IDENTIFIER=' - {get_param: DeployIdentifier}",,13,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ia615ac07d0c559deb65e307bb6254127e989794d,openstack/tripleo-heat-templates,stable/rocky,Ia615ac07d0c559deb65e307bb6254127e989794d,Ensure we get dedicated logging file for HAProxy,MERGED,2019-02-06 17:01:42.000000000,2019-02-11 19:12:54.000000000,2019-02-11 19:12:54.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-02-06 17:01:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b4c6871b731815c536f8855064dfc983339d413', 'message': ""Ensure we get dedicated logging file for HAProxy\n\nWith the current configuration, HAProxy logs are in the host journal.\nThis isn't really friendly when you want to debug issues with this service.\n\nThis patches ensures HAProxy logs are in a dedicated file, using the syslog\nfacility set in its configuration.\n\nDepends-On: I8fee040287940188f6bc6bc35bdbdaf6c234cbfd\nChange-Id: Ia615ac07d0c559deb65e307bb6254127e989794d\n(cherry picked from commit 0576e26234206ab36b161cd43e6b2b69daf49948)\n""}, {'number': 2, 'created': '2019-02-06 17:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/868e770cdd37bb6f754e5952e0736dd8256639f1', 'message': ""Ensure we get dedicated logging file for HAProxy\n\nWith the current configuration, HAProxy logs are in the host journal.\nThis isn't really friendly when you want to debug issues with this service.\n\nThis patches ensures HAProxy logs are in a dedicated file, using the syslog\nfacility set in its configuration.\n\nCloses-Bug: #1814880\nDepends-On: I8fee040287940188f6bc6bc35bdbdaf6c234cbfd\nChange-Id: Ia615ac07d0c559deb65e307bb6254127e989794d\n(cherry picked from commit 0576e26234206ab36b161cd43e6b2b69daf49948)\n""}, {'number': 3, 'created': '2019-02-08 13:44:12.000000000', 'files': ['docker/services/haproxy.yaml', 'docker/services/pacemaker/haproxy.yaml', 'puppet/services/haproxy.yaml', 'puppet/services/pacemaker/haproxy.yaml', 'common/deploy-steps-tasks.yaml', 'releasenotes/notes/haproxy-log-2805e3697cbadf49.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/80f48f131049b4f04a68bd07b56773510cadbafd', 'message': ""Ensure we get dedicated logging file for HAProxy\n\nWith the current configuration, HAProxy logs are in the host journal.\nThis isn't really friendly when you want to debug issues with this service.\n\nThis patches ensures HAProxy logs are in a dedicated file, using the syslog\nfacility set in its configuration.\n\nCloses-Bug: #1814880\nDepends-On: I8fee040287940188f6bc6bc35bdbdaf6c234cbfd\nChange-Id: Ia615ac07d0c559deb65e307bb6254127e989794d\n(cherry picked from commit 0576e26234206ab36b161cd43e6b2b69daf49948)\n""}]",1,635224,80f48f131049b4f04a68bd07b56773510cadbafd,24,7,3,20778,,,0,"Ensure we get dedicated logging file for HAProxy

With the current configuration, HAProxy logs are in the host journal.
This isn't really friendly when you want to debug issues with this service.

This patches ensures HAProxy logs are in a dedicated file, using the syslog
facility set in its configuration.

Closes-Bug: #1814880
Depends-On: I8fee040287940188f6bc6bc35bdbdaf6c234cbfd
Change-Id: Ia615ac07d0c559deb65e307bb6254127e989794d
(cherry picked from commit 0576e26234206ab36b161cd43e6b2b69daf49948)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/24/635224/2 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/haproxy.yaml', 'docker/services/pacemaker/haproxy.yaml', 'puppet/services/haproxy.yaml', 'puppet/services/pacemaker/haproxy.yaml', 'common/deploy-steps-tasks.yaml', 'releasenotes/notes/haproxy-log-2805e3697cbadf49.yaml']",6,3b4c6871b731815c536f8855064dfc983339d413,bug/1814880,--- features: - Allow to output HAProxy in a dedicated file - Adds new HAProxySyslogFacility param ,,93,2
openstack%2Ftripleo-heat-templates~master~I5c61c0049bfd16114894cf4db3b79f94b6d9291b,openstack/tripleo-heat-templates,master,I5c61c0049bfd16114894cf4db3b79f94b6d9291b,Sanitize the uuid string for ceph-ansible,MERGED,2019-02-07 08:03:22.000000000,2019-02-11 19:12:52.000000000,2019-02-11 19:12:52.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-02-07 08:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4d92451904a74c4d7144ecc011c064baf53b1618', 'message': 'Sanitize the uuid string for ceph-ansible\n\ndmidecode can return some additional data if SMBIOS is updated; this\nensures output matches the UUID format.\n\nChange-Id: I5c61c0049bfd16114894cf4db3b79f94b6d9291b\nRelated-Bug: 1762460\n'}, {'number': 2, 'created': '2019-02-08 13:18:49.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ad803ab716448e2dfaa446d732f64c6bd851cb05', 'message': 'Sanitize the uuid string for ceph-ansible\n\ndmidecode can return some additional data if SMBIOS is updated; this\nensures output matches the UUID format.\n\nChange-Id: I5c61c0049bfd16114894cf4db3b79f94b6d9291b\nRelated-Bug: 1762460\n'}]",0,635448,ad803ab716448e2dfaa446d732f64c6bd851cb05,16,6,2,6796,,,0,"Sanitize the uuid string for ceph-ansible

dmidecode can return some additional data if SMBIOS is updated; this
ensures output matches the UUID format.

Change-Id: I5c61c0049bfd16114894cf4db3b79f94b6d9291b
Related-Bug: 1762460
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/48/635448/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,4d92451904a74c4d7144ecc011c064baf53b1618,bug/1762460," # awk strips unwanted output, see LP bug #1762460 command: dmidecode -s system-uuid | awk 'match($0, /[0-9A-Fa-f]{8}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{4}-[0-9A-Fa-f]{12}/) { print substr($0, RSTART, RLENGTH) }' | tr A-F a-f", command: dmidecode -s system-uuid | tr A-F a-f,2,1
openstack%2Ftripleo-heat-templates~master~I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,openstack/tripleo-heat-templates,master,I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7,minor update: move VIP before stopping pacemaker on a node,MERGED,2019-02-07 12:13:38.000000000,2019-02-11 19:12:50.000000000,2019-02-11 19:12:50.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 11166}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 12:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/40659731c3a81e1eed2109ccafebbe9d30089d20', 'message': ""minor update: move VIP before stopping pacemaker on a node\n\nWhen pacemaker stops, it first stops all pacemaker resources\nmanaged on the node, and stops the pacemaker daemon.\n\nIf the node being stopped is hosting VIP resource, those ones\nmust be restarted as soon as possible to avoid long service\ndisruption, but there is currently no constraint defined to\nforce that behaviour.\n\nSo what can happen is the VIP resources are stopped, then other\nresources on the hosts are stopped (e.g. rabbit, galera), and only\nwhen there's no more resources pacemaker restarts VIPs elsewhere,\nwhich can lead to a long OpenStack service disruption.\n\nTo avoid unexpected long outage period due to VIP unavailability,\nforce-move the VIPs away from the node before stopping pacemaker.\n\nChange-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7\n""}, {'number': 2, 'created': '2019-02-07 20:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/499fe37ac4c864b81c2c8238d7883b5934eeb55b', 'message': ""minor update: move VIP before stopping pacemaker on a node\n\nWhen pacemaker stops, it first stops all pacemaker resources\nmanaged on the node, and stops the pacemaker daemon.\n\nIf the node being stopped is hosting VIP resource, those ones\nmust be restarted as soon as possible to avoid long service\ndisruption, but there is currently no constraint defined to\nforce that behaviour.\n\nSo what can happen is the VIP resources are stopped, then other\nresources on the hosts are stopped (e.g. rabbit, galera), and only\nwhen there's no more resources pacemaker restarts VIPs elsewhere,\nwhich can lead to a long OpenStack service disruption.\n\nTo avoid unexpected long outage period due to VIP unavailability,\nforce-move the VIPs away from the node before stopping pacemaker.\n\nChange-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7\n""}, {'number': 3, 'created': '2019-02-08 14:23:58.000000000', 'files': ['puppet/services/pacemaker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/38fb412ac0c76f0ba2b0737699845d9d882fdc2f', 'message': ""minor update: move VIP before stopping pacemaker on a node\n\nWhen pacemaker stops, it first stops all pacemaker resources\nmanaged on the node, and stops the pacemaker daemon.\n\nIf the node being stopped is hosting VIP resources, those ones\nmust be restarted elsewhere as soon as possible to avoid long\nservice disruption, but there is currently no constraint defined\nto force that behaviour.\n\nSo what can happen is the VIP resources are stopped, then other\nresources on the hosts are stopped (e.g. rabbit, galera), and only\nwhen there's no more resources pacemaker restarts VIPs elsewhere,\nwhich can lead to a long OpenStack service disruption.\n\nTo avoid unexpected long outage period due to VIP unavailability,\nforce-move the VIPs away from the node before stopping pacemaker.\n\nCloses-Bug: #1815204\nChange-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7\n""}]",3,635492,38fb412ac0c76f0ba2b0737699845d9d882fdc2f,24,7,3,20778,,,0,"minor update: move VIP before stopping pacemaker on a node

When pacemaker stops, it first stops all pacemaker resources
managed on the node, and stops the pacemaker daemon.

If the node being stopped is hosting VIP resources, those ones
must be restarted elsewhere as soon as possible to avoid long
service disruption, but there is currently no constraint defined
to force that behaviour.

So what can happen is the VIP resources are stopped, then other
resources on the hosts are stopped (e.g. rabbit, galera), and only
when there's no more resources pacemaker restarts VIPs elsewhere,
which can lead to a long OpenStack service disruption.

To avoid unexpected long outage period due to VIP unavailability,
force-move the VIPs away from the node before stopping pacemaker.

Closes-Bug: #1815204
Change-Id: I9cbbf9e66b804f00fd19b2b3641f10bb472a94c7
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/92/635492/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/pacemaker.yaml'],1,40659731c3a81e1eed2109ccafebbe9d30089d20,bug/1815204," - name: Move virtual IPs to another node before stopping pacemaker when: step|int == 1 shell: | CLUSTER_NODE=$(crm_node -n) # Retrieve all the VIPs which are currently hosted on the cluster node we're running on VIPS_TO_MOVE=$(crm_mon --as-xml | xmllint --xpath '//resource[@resource_agent = ""ocf::heartbeat:IPaddr2"" and @role = ""Started"" and @managed = ""true"" and ./node[@name = ""'${CLUSTER_NODE}'""]]/@id' - | sed -e 's/id=//g' -e 's/""//g') for v in ${VIPS_TO_MOVE}; do echo ""Moving VIP $v on another node"" pcs resource move $v --wait=300 done # Clear the internal location bans that were created by pcs to move the VIPs for v in ${VIPS_TO_MOVE}; do echo ""Clearing up temporary location ban for VIP $v"" ban_id=$(cibadmin --query | xmllint --xpath 'string(//rsc_location[@rsc=""'${v}'"" and @node=""'${CLUSTER_NODE}'"" and @score=""-INFINITY""]/@id)' -) if [ -n ""$ban_id"" ]; then pcs constraint remove ${ban_id} else echo ""Could not retrieve and clear location constraint for VIP $v"" 2>&1 fi done",,20,0
openstack%2Fnova~master~I0f206d9db70465d8ce6b1404f546f3e00eeb6e23,openstack/nova,master,I0f206d9db70465d8ce6b1404f546f3e00eeb6e23,update flavor admin docs,MERGED,2019-02-06 15:59:58.000000000,2019-02-11 18:56:49.000000000,2019-02-06 21:09:01.000000000,"[{'_account_id': 6873}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-06 15:59:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d172e450fb195fa677800f9668d06ceac1edcff', 'message': ""update flavor admin docs\n\n- This change updates the admin flavor docs\n  to reflect the use of osc to update flavor\n  descriptions\n\n- This change documents that modifcations to\n  flavor extra_specs are not reflected in an\n  instance's embeded flavor.\n\nChange-Id: I0f206d9db70465d8ce6b1404f546f3e00eeb6e23\n""}, {'number': 2, 'created': '2019-02-06 19:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1db1491d6dd9d93b2130d3edfa2b101c8a49c778', 'message': ""update flavor admin docs\n\n- This change updates the admin flavor docs\n  to reflect the use of osc to update flavor\n  descriptions\n\n- This change documents that modifcations to\n  flavor extra_specs are not reflected in an\n  instance's embedded flavor.\n\nChange-Id: I0f206d9db70465d8ce6b1404f546f3e00eeb6e23\n""}, {'number': 3, 'created': '2019-02-06 19:39:21.000000000', 'files': ['doc/source/admin/flavors.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/80ad7d9df6a84c54099fff4cdf979d52a8179413', 'message': ""update flavor admin docs\n\n- This change updates the admin flavor docs\n  to reflect the use of osc to update flavor\n  descriptions\n\n- This change documents that modifcations to\n  flavor extra_specs are not reflected in an\n  instance's embedded flavor.\n\nChange-Id: I0f206d9db70465d8ce6b1404f546f3e00eeb6e23\n""}]",15,635198,80ad7d9df6a84c54099fff4cdf979d52a8179413,20,6,3,11604,,,0,"update flavor admin docs

- This change updates the admin flavor docs
  to reflect the use of osc to update flavor
  descriptions

- This change documents that modifcations to
  flavor extra_specs are not reflected in an
  instance's embedded flavor.

Change-Id: I0f206d9db70465d8ce6b1404f546f3e00eeb6e23
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/635198/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/flavors.rst'],1,9d172e450fb195fa677800f9668d06ceac1edcff,admin-flavor-docs, $ openstack flavor set --description <DESCRIPTION> <FLAVOR> The only field that can be updated is the description field. Nova has historically intentionally not included an API to update a flavor because that would be confusing for instances already created with that flavor. Needing to change any other aspect of a flavor requires deleting and/or creating a new flavor. We store a serialized version of the flavor associated with an instance record in the instance_extras table. While nova supports updating flavor extra_specs it does not update the embeded flavor in existing instances. Nova does not update the embeded flavor as the extra_spec change my invalidate the current placement of the instance or alter the compute context that has been created for the instance by the virt driver. For this reason admins should avoid updating extra_specs for flavors that have existing instances. A resize can be used to update existing instances if required but as a resize performs a cold migration it is not transparent to a tenant., $ nova flavor-update FLAVOR DESCRIPTION There are no commands to update a description of a flavor in the :command:`openstack` command currently (version 3.15.0).,19,3
openstack%2Fnova~master~I536a260da639d32afbc998be220305f9489db375,openstack/nova,master,I536a260da639d32afbc998be220305f9489db375,cleanup *.pyc files in docs tox envs,MERGED,2019-02-06 16:33:50.000000000,2019-02-11 18:54:46.000000000,2019-02-06 23:42:40.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 11604}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-06 16:33:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6bd17dc7c5f082b683176e85154f536e6c8472c9', 'message': 'cleanup *.pyc files in docs tox envs\n\nThis change add {[testenv]commands} to the docs envs\nto cleanup stale .pyc files before running sphinx-build\n\nChange-Id: I536a260da639d32afbc998be220305f9489db375\n'}, {'number': 2, 'created': '2019-02-06 19:46:13.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/nova/commit/a32ccce6de8f076a9484f68d7fbe1b3d5edf1c77', 'message': ""cleanup *.pyc files in docs tox envs\n\n.pyc files are ignored by nova's .gitignore, as a result\nif you change branches after the .pyc files are generated\nfor example from stable/ocata to master it does not remove\nthe .pyc files.\n\nThis can lead to the _validate_bytecode_header function that\nis invoked as part of sphinx-build to fail as the .pyc\nfiles no longer match the contents of the checked out files.\n\nThis change adds {[testenv]commands} to the docs envs\nto clean up stale .pyc files before running sphinx-build\n\nChange-Id: I536a260da639d32afbc998be220305f9489db375\n""}]",3,635210,a32ccce6de8f076a9484f68d7fbe1b3d5edf1c77,18,8,2,11604,,,0,"cleanup *.pyc files in docs tox envs

.pyc files are ignored by nova's .gitignore, as a result
if you change branches after the .pyc files are generated
for example from stable/ocata to master it does not remove
the .pyc files.

This can lead to the _validate_bytecode_header function that
is invoked as part of sphinx-build to fail as the .pyc
files no longer match the contents of the checked out files.

This change adds {[testenv]commands} to the docs envs
to clean up stale .pyc files before running sphinx-build

Change-Id: I536a260da639d32afbc998be220305f9489db375
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/635210/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6bd17dc7c5f082b683176e85154f536e6c8472c9,cleanup-pyc-files, {[testenv]commands} {[testenv]commands} {[testenv]commands} {[testenv]commands},,4,0
openstack%2Fsahara~master~I82286be653066bacf65e820484a7495b8703b483,openstack/sahara,master,I82286be653066bacf65e820484a7495b8703b483,Adding oozie to fake plugin,ABANDONED,2019-01-08 19:46:19.000000000,2019-02-11 18:50:58.000000000,,"[{'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-08 19:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7ee5169ae4426715d4a4151329c3ec13c4175fd1', 'message': 'Adding oozie to fake plugin\n\nChange-Id: I82286be653066bacf65e820484a7495b8703b483\n'}, {'number': 2, 'created': '2019-01-09 13:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2d7b43b8f2af36fa35028017abc5f3bf9327f02e', 'message': 'Adding oozie to fake plugin\n\nDepends-On: https://review.openstack.org/629477\nChange-Id: I82286be653066bacf65e820484a7495b8703b483\n'}, {'number': 3, 'created': '2019-01-09 16:19:28.000000000', 'files': ['sahara/plugins/fake/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0cdc8aab66e83632bd27c8c7f1e0c27b3f09c7ed', 'message': 'Adding oozie to fake plugin\n\nChange-Id: I82286be653066bacf65e820484a7495b8703b483\n'}]",0,629296,0cdc8aab66e83632bd27c8c7f1e0c27b3f09c7ed,9,2,3,8932,,,0,"Adding oozie to fake plugin

Change-Id: I82286be653066bacf65e820484a7495b8703b483
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/629296/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/fake/plugin.py'],1,7ee5169ae4426715d4a4151329c3ec13c4175fd1,split-plugins-review," ""Oozie"": [""oozie""],",,1,0
openstack%2Fnova-powervm~master~I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0,openstack/nova-powervm,master,I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0,DNM: See what in the CI doesn't need our code,ABANDONED,2018-08-31 20:30:41.000000000,2019-02-11 18:49:08.000000000,,"[{'_account_id': 10608}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-31 20:30:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/57e129f5e5fbf73464376d3b522770268cf96971', 'message': ""DNM: See what in the CI doesn't need our code\n\nChange-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0\n""}, {'number': 2, 'created': '2018-08-31 21:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/5e4a8bb430b933eb3851c21206feee21df8f122a', 'message': ""DNM: See what in the CI doesn't need our code\n\nChange-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0\n""}, {'number': 3, 'created': '2018-08-31 21:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/dafa777c1f235b48e007c030e726160f697c0ba7', 'message': ""DNM: See what in the CI doesn't need our code\n\nChange-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0\n""}, {'number': 4, 'created': '2018-08-31 21:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0253f9ee9185d097d7d619224303f5c2498fc5a2', 'message': ""DNM: See what in the CI doesn't need our code\n\nChange-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0\n""}, {'number': 5, 'created': '2018-08-31 22:01:31.000000000', 'files': ['nova_powervm/virt/powervm/driver.py', 'nova/virt/powervm_ext/driver.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/4de83011b90fec54662fc31693537f33352a4891', 'message': ""DNM: See what in the CI doesn't need our code\n\nChange-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0\n""}]",0,599066,4de83011b90fec54662fc31693537f33352a4891,11,3,5,14070,,,0,"DNM: See what in the CI doesn't need our code

Change-Id: I856c1c1baaf1f7800d8e807ae87a7d7cc66847a0
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/66/599066/5 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/virt/powervm/driver.py'],1,57e129f5e5fbf73464376d3b522770268cf96971,dnm-scrub-ci,,"LOG = logging.getLogger(__name__) CONF = cfg.CONF DISK_ADPT_NS = 'nova_powervm.virt.powervm.disk' DISK_ADPT_MAPPINGS = { 'localdisk': 'localdisk.LocalStorage', 'ssp': 'ssp.SSPDiskAdapter' } # NVRAM store APIs for the NVRAM manager to use NVRAM_NS = 'nova_powervm.virt.powervm.nvram.' NVRAM_APIS = { 'swift': 'swift.SwiftNvramStore', } KEEP_NVRAM_STATES = {vm_states.SHELVED, } FETCH_NVRAM_STATES = {vm_states.SHELVED, vm_states.SHELVED_OFFLOADED} self.capabilities = { # NOTE(edmondsw): 'has_imagecache' will be set dynamically ""supports_recreate"": True, ""supports_migrate_to_same_host"": False, ""supports_attach_interface"": True, ""supports_device_tagging"": False, ""supports_tagged_attach_interface"": False, ""supports_tagged_attach_volume"": False, ""supports_extend_volume"": True, ""supports_multiattach"": False, } """"""Initialize anything that is necessary for the driver to function. Includes catching up with currently running VM's on the given host. """""" # Live migrations self.live_migrations = {} # Set the nvram mgr to None so events are not handled until it's setup self.nvram_mgr = None self.store_api = None # Get an adapter self._get_adapter() # First need to resolve the managed host UUID self._get_host_uuid() # Make sure the Virtual I/O Server(s) are available. pvm_par.validate_vios_ready(self.adapter) # Do a scrub of the I/O plane to make sure the system is in good shape LOG.info(""Clearing stale I/O connections on driver init."") pvm_stor.ComprehensiveScrub(self.adapter).execute() # Initialize the disk adapter. Sets self.disk_dvr self._setup_disk_adapter() self.image_api = image.API() self._setup_rebuild_store() # Init Host CPU Statistics self.host_cpu_cache = pvm_hcpu.HostCPUMetricCache(self.adapter, self.host_uuid) # Cache for instance overhead. # Key: max_mem (int MB) # Value: overhead (int MB) self._inst_overhead_cache = {} # Clean-up any orphan adapters self._cleanup_orphan_adapters(CONF.powervm.pvm_vswitch_for_novalink_io) LOG.info(""The compute driver has been initialized."") def cleanup_host(self, host): """"""Clean up anything that is necessary for the driver gracefully stop. Includes ending remote sessions. This is optional. """""" # Stop listening for events try: self.session.get_event_listener().shutdown() except Exception: pass LOG.info(""The compute driver has been shutdown."") def _get_adapter(self): # Build the adapter. May need to attempt the connection multiple times # in case the REST server is starting. self.session = pvm_apt.Session(conn_tries=300) self.adapter = pvm_apt.Adapter( self.session, helpers=[log_hlp.log_helper, vio_hlp.vios_busy_retry_helper]) # Register the event handler eh = event.PowerVMNovaEventHandler(self) self.session.get_event_listener().subscribe(eh) def _setup_disk_adapter(self): """"""Set up the nova ephemeral disk adapter."""""" self.disk_dvr = importutils.import_object_ns( DISK_ADPT_NS, DISK_ADPT_MAPPINGS[CONF.powervm.disk_driver.lower()], self.adapter, self.host_uuid) has_imagecache = self.disk_dvr.capabilities['has_imagecache'] self.capabilities['has_imagecache'] = has_imagecache def manage_image_cache(self, context, all_instances): self.disk_dvr.manage_image_cache(context, all_instances) def _setup_rebuild_store(self): """"""Set up the store for remote restart objects."""""" store = CONF.powervm.nvram_store.lower() if store != 'none': self.store_api = importutils.import_object( NVRAM_NS + NVRAM_APIS[store]) # Events will be handled once the nvram_mgr is set. self.nvram_mgr = nvram_manager.NvramManager( self.store_api, self.adapter, self.host_uuid) # Do host startup for NVRAM for existing VMs on the host n_utils.spawn(self._nvram_host_startup) def _nvram_host_startup(self): """"""NVRAM Startup. When the compute node starts up, it's not known if any NVRAM events were missed when the compute process was not running. During startup put each LPAR on the queue to be updated, just incase. """""" for lpar_w in vm.get_lpars(self.adapter): # Find the instance for the LPAR. inst = vm.get_instance(ctx.get_admin_context(), lpar_w.uuid) if inst is not None and inst.host == CONF.host: self.nvram_mgr.store(inst) time.sleep(0) def _get_host_uuid(self): """"""Get the System wrapper and its UUID for the (single) host."""""" syswraps = pvm_ms.System.get(self.adapter) if len(syswraps) != 1: raise Exception( _(""Expected exactly one host; found %d""), len(syswraps)) self.host_wrapper = syswraps[0] self.host_uuid = self.host_wrapper.uuid LOG.info(""Host UUID is:%s"", self.host_uuid) @staticmethod def _log_operation(op, instance): """"""Log entry point of driver operations."""""" LOG.info('Operation: %(op)s. Virtual machine display name: ' '%(display_name)s, name: %(name)s', {'op': op, 'display_name': instance.display_name, 'name': instance.name}, instance=instance) def get_info(self, instance): """"""Get the current status of an instance. :param instance: nova.objects.instance.Instance object :returns: An InstanceInfo object """""" return vm.get_vm_info(self.adapter, instance) def instance_exists(self, instance): """"""Checks existence of an instance on the host. :param instance: The instance to lookup Returns True if an instance with the supplied ID exists on the host, False otherwise. """""" return vm.instance_exists(self.adapter, instance) def estimate_instance_overhead(self, instance_info): """"""Estimate the virtualization overhead required to build an instance. Defaults to zero, Per-instance overhead calculations are desired. :param instance_info: Instance/flavor to calculate overhead for. It can be Instance or Flavor object or a simple dict. The dict is expected to contain: { 'memory_mb': <int>, 'extra_specs': {'powervm:max_mem': <int> }} Values not found will default to zero. :return: Dict of estimated overhead values {'memory_mb': overhead} """""" # Check if input passed is an object instance then extract Flavor if isinstance(instance_info, objects.Instance): instance_info = instance_info.get_flavor() # If the instance info passed is dict then create Flavor object. elif isinstance(instance_info, dict): instance_info = objects.Flavor(**instance_info) max_mem = 0 overhead = 0 try: cur_mem = instance_info.memory_mb if hasattr(instance_info, 'extra_specs'): if 'powervm:max_mem' in instance_info.extra_specs.keys(): mem = instance_info.extra_specs.get('powervm:max_mem', max_mem) max_mem = int(mem) max_mem = max(cur_mem, max_mem) if max_mem in self._inst_overhead_cache: overhead = self._inst_overhead_cache[max_mem] else: overhead, avail = pvm_mem.calculate_memory_overhead_on_host( self.adapter, self.host_uuid, {'max_mem': max_mem}) self._inst_overhead_cache[max_mem] = overhead except Exception: LOG.exception(""PowerVM error estimating instance overhead."") finally: return {'memory_mb': overhead} def list_instances(self): """"""Return the names of all the instances known to the virt host. :return: VM Names as a list. """""" lpar_list = vm.get_lpar_names(self.adapter) return lpar_list def get_host_cpu_stats(self): """"""Return the current CPU state of the host."""""" self.host_cpu_cache.refresh() return { 'kernel': self.host_cpu_cache.total_fw_cycles, 'user': self.host_cpu_cache.total_user_cycles, 'idle': (self.host_cpu_cache.total_cycles - self.host_cpu_cache.total_user_cycles - self.host_cpu_cache.total_fw_cycles), # Not reported by PowerVM 'iowait': 0, 'frequency': self.host_cpu_cache.cpu_freq} def instance_on_disk(self, instance): """"""Checks access of instance files on the host. :param instance: nova.objects.instance.Instance to lookup Returns True if files of an instance with the supplied ID accessible on the host, False otherwise. .. note:: Used in rebuild for HA implementation and required for validation of access to instance shared disk files """""" # If the instance is booted from volume then we shouldn't # really care if instance ""disks"" are on shared storage. context = ctx.get_admin_context() block_device_info = self._get_block_device_info(context, instance) if self._is_booted_from_volume(block_device_info): LOG.debug('Instance booted from volume.', instance=instance) return True # If configured for shared storage, see if we can find the disks if self.disk_dvr.capabilities['shared_storage']: LOG.debug('Looking for instance disks on shared storage.', instance=instance) # Try to get a reference to the disk try: if self.disk_dvr.get_disk_ref(instance, disk_dvr.DiskType.BOOT): LOG.debug('Disks found on shared storage.', instance=instance) return True except Exception: LOG.exception(""PowerVM error checking instance on disk."", instance=instance) LOG.debug('Instance disks not found on this host.', instance=instance) return False def spawn(self, context, instance, image_meta, injected_files, admin_password, allocations, network_info=None, block_device_info=None): """"""Create a new instance/VM/domain on the virtualization platform. Once this successfully completes, the instance should be running (power_state.RUNNING). If this fails, any partial instance should be completely cleaned up, and the virtualization platform should be in the state that it was before this call began. :param context: security context :param instance: nova.objects.instance.Instance This function should use the data there to guide the creation of the new instance. :param nova.objects.ImageMeta image_meta: The metadata of the image of the instance. :param injected_files: User files to inject into instance. :param admin_password: Administrator password to set in instance. :param allocations: Information about resources allocated to the instance via placement, of the form returned by SchedulerReportClient.get_allocations_for_consumer. :param network_info: instance network information :param block_device_info: Information about block devices to be attached to the instance. """""" self._log_operation('spawn', instance) # Extract the block devices. bdms = self._extract_bdm(block_device_info) # Define the flow flow_spawn = tf_lf.Flow(""spawn"") # Determine if this is a VM recreate recreate = (instance.task_state == task_states.REBUILD_SPAWNING and 'id' not in image_meta) # Create the transaction manager (FeedTask) for Storage I/O. xag = self._get_inst_xag(instance, bdms, recreate=recreate) stg_ftsk = pvm_par.build_active_vio_feed_task(self.adapter, xag=xag) # Build the PowerVM Slot lookup map. Only the recreate action needs # the volume driver iterator (to look up volumes and their client # mappings). vol_drv_iter = (self._vol_drv_iter(instance, bdms, stg_ftsk=stg_ftsk) if recreate else None) slot_mgr = slot.build_slot_mgr( instance, self.store_api, adapter=self.adapter, vol_drv_iter=vol_drv_iter) # Create the LPAR, check if NVRAM restore is needed. nvram_mgr = (self.nvram_mgr if self.nvram_mgr and (recreate or instance.vm_state in FETCH_NVRAM_STATES) else None) # If we're recreating pass None in for the FeedTask. This will make the # Create task produce a FeedTask that will be used to scrub stale # adapters immediately after the LPAR is created. flow_spawn.add(tf_vm.Create( self.adapter, self.host_wrapper, instance, stg_ftsk=(None if recreate else stg_ftsk), nvram_mgr=nvram_mgr, slot_mgr=slot_mgr)) # Create a flow for the IO flow_spawn.add(tf_net.PlugVifs( self.virtapi, self.adapter, instance, network_info, self.host_uuid, slot_mgr)) flow_spawn.add(tf_net.PlugMgmtVif( self.adapter, instance, self.host_uuid, slot_mgr)) # Only add the image disk if this is from Glance. if not self._is_booted_from_volume(block_device_info): # If a recreate, just hookup the existing disk on shared storage. if recreate: flow_spawn.add(tf_stg.FindDisk( self.disk_dvr, context, instance, disk_dvr.DiskType.BOOT)) else: # Creates the boot image. flow_spawn.add(tf_stg.CreateDiskForImg( self.disk_dvr, context, instance, image_meta)) # Connects up the disk to the LPAR flow_spawn.add(tf_stg.ConnectDisk( self.disk_dvr, instance, stg_ftsk=stg_ftsk)) # Determine if there are volumes to connect. If so, add a connection # for each type. self._add_volume_connection_tasks( context, instance, bdms, flow_spawn, stg_ftsk, slot_mgr) # If the config drive is needed, add those steps. Should be done # after all the other I/O. if configdrive.required_by(instance) and not recreate: flow_spawn.add(tf_stg.CreateAndConnectCfgDrive( self.adapter, instance, injected_files, network_info, admin_password, stg_ftsk=stg_ftsk)) # Add the transaction manager flow to the end of the 'I/O # connection' tasks. This will run all the connections in parallel. flow_spawn.add(stg_ftsk) # Update load source of IBMi VM distro = instance.system_metadata.get('image_os_distro', '') if distro.lower() == img.OSDistro.OS400: boot_type = self._get_boot_connectivity_type( bdms, block_device_info) flow_spawn.add(tf_vm.UpdateIBMiSettings( self.adapter, instance, boot_type)) # Save the slot map information flow_spawn.add(tf_slot.SaveSlotStore(instance, slot_mgr)) pwr_opts = pvm_popts.PowerOnOpts() if CONF.powervm.remove_vopt_media_on_boot: # Get the cfgdrive media name for the vopt removal task in PowerOn. media_name = pvm_util.sanitize_file_name_for_api( instance.name, prefix=media.CFG_DRV_PREFIX, suffix=media.CFG_DRV_SUFFIX, max_len=pvm_const.MaxLen.VOPT_NAME) pwr_opts.remove_optical( media_name, time=CONF.powervm.remove_vopt_media_time) # Last step is to power on the system. flow_spawn.add(tf_vm.PowerOn(self.adapter, instance, pwr_opts=pwr_opts)) # Run the flow. tf_base.run(flow_spawn, instance=instance) def _add_volume_connection_tasks(self, context, instance, bdms, flow, stg_ftsk, slot_mgr): """"""Determine if there are volumes to connect to this instance. If there are volumes to connect to this instance add a task to the flow for each volume. :param context: security context. :param instance: Instance object as returned by DB layer. :param bdms: block device mappings. :param flow: the flow to add the tasks to. :param stg_ftsk: the storage task flow. :param slot_mgr: A NovaSlotManager. Used to store/retrieve the client slots used when a volume is attached to a VM. """""" for bdm, vol_drv in self._vol_drv_iter(instance, bdms, stg_ftsk=stg_ftsk): # First connect the volume. This will update the # connection_info. flow.add(tf_stg.ConnectVolume(vol_drv, slot_mgr)) # Save the BDM so that the updated connection info is # persisted. flow.add(tf_stg.SaveBDM(bdm, instance)) def _add_volume_disconnection_tasks(self, context, instance, bdms, flow, stg_ftsk, slot_mgr): """"""Determine if there are volumes to disconnect from this instance. If there are volumes to disconnect from this instance add a task to the flow for each volume. :param context: security context. :param instance: Instance object as returned by DB layer. :param bdms: block device mappings. :param flow: the flow to add the tasks to. :param stg_ftsk: the storage task flow. :param slot_mgr: A NovaSlotManager. Used to store/retrieve the client slots used when a volume is detached from a VM. """""" # TODO(thorst) Do we need to do something on the disconnect for slots? for bdm, vol_drv in self._vol_drv_iter(instance, bdms, stg_ftsk=stg_ftsk): flow.add(tf_stg.DisconnectVolume(vol_drv, slot_mgr)) def _get_block_device_info(self, context, instance): """"""Retrieves the instance's block_device_info."""""" bdms = objects.BlockDeviceMappingList.get_by_instance_uuid( context, instance.uuid) return driver.get_block_device_info(instance, bdms) def _is_booted_from_volume(self, block_device_info): """"""Determine whether the root device is listed in block_device_info. If it is, this can be considered a 'boot from Cinder Volume'. :param block_device_info: The block device info from the compute manager. :return: True if the root device is in block_device_info and False if it is not. """""" if block_device_info is None: return False root_bdm = block_device.get_root_bdm( driver.block_device_info_get_mapping(block_device_info)) return root_bdm is not None @property def need_legacy_block_device_info(self): return False def _destroy(self, context, instance, block_device_info=None, network_info=None, destroy_disks=True, shutdown=True): """"""Internal destroy method used by multiple operations. :param context: security context :param instance: Instance object as returned by DB layer. :param block_device_info: Information about block devices that should be detached from the instance. This can be None when destroying the original VM during confirm resize/migration. In that case, the storage mappings have already been removed from the original VM, so no work to do. :param network_info: The network information associated with the instance :param destroy_disks: Indicates if disks should be destroyed :param shutdown: Indicate whether to shutdown the VM first """""" def _setup_flow_and_run(): # Extract the block devices. bdms = self._extract_bdm(block_device_info) # Define the flow flow = tf_lf.Flow(""destroy"") if shutdown: # Power Off the LPAR. If its disks are about to be deleted, # VSP hard shutdown it. flow.add(tf_vm.PowerOff(self.adapter, instance, force_immediate=destroy_disks)) # Create the transaction manager (FeedTask) for Storage I/O. xag = self._get_inst_xag(instance, bdms) stg_ftsk = pvm_par.build_active_vio_feed_task(self.adapter, xag=xag) # Build the PowerVM Slot lookup map. slot_mgr = slot.build_slot_mgr(instance, self.store_api) # Call the unplug VIFs task. While CNAs get removed from the LPAR # directly on the destroy, this clears up the I/O Host side. flow.add(tf_vm.Get(self.adapter, self.host_uuid, instance)) flow.add(tf_net.UnplugVifs(self.adapter, instance, network_info, self.host_uuid, slot_mgr)) # Add the disconnect/deletion of the vOpt to the transaction # manager. if configdrive.required_by(instance): flow.add(tf_stg.DeleteVOpt( self.adapter, instance, stg_ftsk=stg_ftsk)) # Determine if there are volumes to disconnect. If so, remove each # volume (within the transaction manager) self._add_volume_disconnection_tasks( context, instance, bdms, flow, stg_ftsk, slot_mgr) # Only detach the disk adapters if this is not a boot from volume # since volumes are handled above. This is only for disks. destroy_disk_task = None if not self._is_booted_from_volume(block_device_info): # Detach the disk storage adapters (when the stg_ftsk runs) flow.add(tf_stg.DetachDisk( self.disk_dvr, instance, stg_ftsk=stg_ftsk)) # Delete the storage disks if destroy_disks: destroy_disk_task = tf_stg.DeleteDisk( self.disk_dvr, instance) # It's possible that volume disconnection may have failed for disks # which had been removed from the VIOS by the storage back end # (e.g. if we're destroying an evacuated instance). In that case, # the storage is already gone, but we had no way to identify its # mappings because no disk name/UDID. We now remove such mappings # based on their association with the LPAR ID. def _rm_vscsi_maps(vwrap): removals = pvm_smap.remove_maps(vwrap, pvm_inst_uuid) if removals: LOG.warning(""Removing %(num_maps)d storage-less VSCSI "" ""mappings associated with LPAR ID "" ""%(lpar_uuid)s from VIOS %(vios_name)s."", {'num_maps': len(removals), 'lpar_uuid': pvm_inst_uuid, 'vios_name': vwrap.name}, instance=instance) return removals stg_ftsk.add_functor_subtask(_rm_vscsi_maps) # Add the transaction manager flow to the end of the 'storage # connection' tasks. This will run all the disconnection ops # in parallel flow.add(stg_ftsk) # The disks shouldn't be destroyed until the unmappings are done. if destroy_disk_task: flow.add(destroy_disk_task) # Last step is to delete the LPAR from the system and delete # the NVRAM from the store. # Note: If moving to a Graph Flow, will need to change to depend on # the prior step. flow.add(tf_vm.Delete(self.adapter, instance)) if (destroy_disks and instance.vm_state not in KEEP_NVRAM_STATES and instance.host in [None, CONF.host]): # If the disks are being destroyed and not one of the # operations that we should keep the NVRAM around for, then # it's probably safe to delete the NVRAM from the store. flow.add(tf_vm.DeleteNvram(self.nvram_mgr, instance)) flow.add(tf_slot.DeleteSlotStore(instance, slot_mgr)) # Run the flow tf_base.run(flow, instance=instance) try: pvm_inst_uuid = vm.get_pvm_uuid(instance) _setup_flow_and_run() except exception.InstanceNotFound: LOG.warning('VM was not found during destroy operation.', instance=instance) return except Exception as e: LOG.exception(""PowerVM error destroying instance."", instance=instance) # Convert to a Nova exception raise exception.InstanceTerminationFailure( reason=six.text_type(e)) def destroy(self, context, instance, network_info, block_device_info=None, destroy_disks=True, migrate_data=None): """"""Destroy (shutdown and delete) the specified instance. If the instance is not found (for example if networking failed), this function should still succeed. It's probably a good idea to log a warning in that case. :param context: security context :param instance: Instance object as returned by DB layer. :param network_info: :py:meth:`~nova.network.manager.NetworkManager.get_instance_nw_info` :param block_device_info: Information about block devices that should be detached from the instance. :param destroy_disks: Indicates if disks should be destroyed :param migrate_data: a LiveMigrateData object """""" if instance.task_state == task_states.RESIZE_REVERTING: LOG.info('Destroy called for migrated/resized instance.', instance=instance) # This destroy is part of resize or migrate. It's called to # revert the resize/migration on the destination host. # Get the VM and see if we've renamed it to the resize name, # if not delete as usual because then we know it's not the # original VM. pvm_inst_uuid = vm.get_pvm_uuid(instance) vm_name = vm.get_vm_qp(self.adapter, pvm_inst_uuid, qprop='PartitionName', log_errors=False) if vm_name == self._gen_resize_name(instance, same_host=True): # Since it matches it must have been a resize, don't delete it! LOG.info('Ignoring destroy call during resize revert.', instance=instance) return # Run the destroy self._log_operation('destroy', instance) self._destroy( context, instance, block_device_info=block_device_info, network_info=network_info, destroy_disks=destroy_disks, shutdown=True) def attach_volume(self, context, connection_info, instance, mountpoint, disk_bus=None, device_type=None, encryption=None): """"""Attach the volume to the instance at mountpoint using info."""""" self._log_operation('attach_volume', instance) # Define the flow flow = tf_lf.Flow(""attach_volume"") # Get the LPAR Wrapper flow.add(tf_vm.Get(self.adapter, self.host_uuid, instance)) # Determine if there are volumes to connect. If so, add a connection # for each type. slot_mgr = slot.build_slot_mgr(instance, self.store_api) vol_drv = vol_attach.build_volume_driver( self.adapter, self.host_uuid, instance, connection_info) flow.add(tf_stg.ConnectVolume(vol_drv, slot_mgr)) # Save the new slot info flow.add(tf_slot.SaveSlotStore(instance, slot_mgr)) # Run the flow tf_base.run(flow, instance=instance) # The volume connector may have updated the system metadata. Save # the instance to persist the data. Spawn/destroy auto saves instance, # but the attach does not. Detach does not need this save - as the # detach flows do not (currently) modify system metadata. May need # to revise in the future as volume connectors evolve. instance.save() def extend_volume(self, connection_info, instance): """"""Extend the disk attached to the instance. :param dict connection_info: The connection for the extended volume. :param nova.objects.instance.Instance instance: The instance whose volume gets extended. :return: None """""" vol_drv = vol_attach.build_volume_driver( self.adapter, self.host_uuid, instance, connection_info) vol_drv.extend_volume() def detach_volume(self, context, connection_info, instance, mountpoint, encryption=None): """"""Detach the volume attached to the instance."""""" self._log_operation('detach_volume', instance) # Define the flow flow = tf_lf.Flow(""detach_volume"") # Get a volume adapter for this volume vol_drv = vol_attach.build_volume_driver( self.adapter, self.host_uuid, instance, connection_info) # Before attempting to detach a volume, ensure the instance exists # If a live migration fails, the compute manager will call detach # for each volume attached to the instance, against the destination # host. If the migration failed, then the VM is probably not on # the destination host. if not vm.instance_exists(self.adapter, instance): LOG.info('During volume detach, the instance was not found on ' 'this host.', instance=instance) # Check if there is live migration cleanup to do on this volume. mig = self.live_migrations.get(instance.uuid, None) if mig is not None and isinstance(mig, lpm.LiveMigrationDest): mig.cleanup_volume(vol_drv) return # Add a task to detach the volume slot_mgr = slot.build_slot_mgr(instance, self.store_api) flow.add(tf_stg.DisconnectVolume(vol_drv, slot_mgr)) # Save the new slot info flow.add(tf_slot.SaveSlotStore(instance, slot_mgr)) # Run the flow tf_base.run(flow, instance=instance) def snapshot(self, context, instance, image_id, update_task_state): """"""Snapshots the specified instance. :param context: security context :param instance: nova.objects.instance.Instance :param image_id: Reference to a pre-created image that will hold the snapshot. :param update_task_state: Callback function to update the task_state on the instance while the snapshot operation progresses. The function takes a task_state argument and an optional expected_task_state kwarg which defaults to nova.compute.task_states.IMAGE_SNAPSHOT. See nova.objects.instance.Instance.save for expected_task_state usage. """""" if not self.disk_dvr.capabilities.get('snapshot'): raise exception.NotSupportedWithOption( message=_(""The snapshot operation is not supported in "" ""conjunction with a [powervm]/disk_driver setting "" ""of %s."") % CONF.powervm.disk_driver) self._log_operation('snapshot', instance) # Define the flow flow = tf_lf.Flow(""snapshot"") # Notify that we're starting the process flow.add(tf_img.UpdateTaskState(update_task_state, task_states.IMAGE_PENDING_UPLOAD)) # Connect the instance's boot disk to the management partition, and # scan the scsi bus and bring the device into the management partition. flow.add(tf_stg.InstanceDiskToMgmt(self.disk_dvr, instance)) # Notify that the upload is in progress flow.add(tf_img.UpdateTaskState( update_task_state, task_states.IMAGE_UPLOADING, expected_state=task_states.IMAGE_PENDING_UPLOAD)) # Stream the disk to glance flow.add(tf_img.StreamToGlance(context, self.image_api, image_id, instance)) # Disconnect the boot disk from the management partition and delete the # device flow.add(tf_stg.RemoveInstanceDiskFromMgmt(self.disk_dvr, instance)) # Run the flow tf_base.run(flow, instance=instance) def rescue(self, context, instance, network_info, image_meta, rescue_password): """"""Rescue the specified instance. :param nova.context.RequestContext context: The context for the rescue. :param nova.objects.instance.Instance instance: The instance being rescued. :param nova.network.model.NetworkInfo network_info: Necessary network information for the resume. :param nova.objects.ImageMeta image_meta: The metadata of the image of the instance. :param rescue_password: new root password to set for rescue. """""" self._log_operation('rescue', instance) # Define the flow flow = tf_lf.Flow(""rescue"") # Power Off the LPAR flow.add(tf_vm.PowerOff(self.adapter, instance)) # Create and populate the rescue disk. flow.add(tf_stg.CreateDiskForImg( self.disk_dvr, context, instance, image_meta, image_type=disk_dvr.DiskType.RESCUE)) # Connect up the disk to the LPAR flow.add(tf_stg.ConnectDisk(self.disk_dvr, instance)) # Last step is to power on the system. flow.add(tf_vm.PowerOn( self.adapter, instance, pwr_opts=pvm_popts.PowerOnOpts().bootmode(pvm_popts.BootMode.SMS))) # Run the flow tf_base.run(flow, instance=instance) def unrescue(self, instance, network_info): """"""Unrescue the specified instance. :param instance: nova.objects.instance.Instance """""" self._log_operation('unrescue', instance) # Define the flow flow = tf_lf.Flow(""unrescue"") # Power Off the LPAR flow.add(tf_vm.PowerOff(self.adapter, instance)) # Detach the disk adapter for the rescue image flow.add(tf_stg.DetachDisk( self.disk_dvr, instance, disk_type=[disk_dvr.DiskType.RESCUE])) # Delete the storage disk for the rescue image flow.add(tf_stg.DeleteDisk(self.disk_dvr, instance)) # Last step is to power on the system. flow.add(tf_vm.PowerOn(self.adapter, instance)) # Run the flow tf_base.run(flow, instance=instance) def power_off(self, instance, timeout=0, retry_interval=0): """"""Power off the specified instance. :param instance: nova.objects.instance.Instance :param timeout: time to wait for GuestOS to shutdown :param retry_interval: How often to signal guest while waiting for it to shutdown """""" self._log_operation('power_off', instance) force_immediate = (timeout == 0) timeout = timeout or None vm.power_off(self.adapter, instance, force_immediate=force_immediate, timeout=timeout) def power_on(self, context, instance, network_info, block_device_info=None): """"""Power on the specified instance. :param instance: nova.objects.instance.Instance """""" self._log_operation('power_on', instance) vm.power_on(self.adapter, instance) def reboot(self, context, instance, network_info, reboot_type, block_device_info=None, bad_volumes_callback=None): """"""Reboot the specified instance. After this is called successfully, the instance's state goes back to power_state.RUNNING. The virtualization platform should ensure that the reboot action has completed successfully even in cases in which the underlying domain/vm is paused or halted/stopped. :param instance: nova.objects.instance.Instance :param network_info: :py:meth:`~nova.network.manager.NetworkManager.get_instance_nw_info` :param reboot_type: Either a HARD or SOFT reboot :param block_device_info: Info pertaining to attached volumes :param bad_volumes_callback: Function to handle any bad volumes encountered """""" self._log_operation(reboot_type + ' reboot', instance) vm.reboot(self.adapter, instance, reboot_type == 'HARD') # pypowervm exceptions are sufficient to indicate real failure. # Otherwise, pypowervm thinks the instance is up. return True def get_available_resource(self, nodename): """"""Retrieve resource information. This method is called when nova-compute launches, and as part of a periodic task :param nodename: node which the caller want to get resources from a driver that manages only one node can safely ignore this :return: Dictionary describing resources """""" # Do this here so it refreshes each time this method is called. self.host_wrapper = pvm_ms.System.get(self.adapter)[0] return self._get_available_resource() def _get_available_resource(self): # Get host information data = pvm_host.build_host_resource_from_ms(self.host_wrapper) # Add the disk information data[""local_gb""] = self.disk_dvr.capacity data[""local_gb_used""] = self.disk_dvr.capacity_used return data def update_provider_tree(self, provider_tree, nodename): """"""Update a ProviderTree with current provider and inventory data. :param nova.compute.provider_tree.ProviderTree provider_tree: A nova.compute.provider_tree.ProviderTree object representing all the providers in the tree associated with the compute node, and any sharing providers (those with the ``MISC_SHARES_VIA_AGGREGATE`` trait) associated via aggregate with any of those providers (but not *their* tree- or aggregate-associated providers), as currently known by placement. :param nodename: String name of the compute node (i.e. ComputeNode.hypervisor_hostname) for which the caller is requesting updated provider information. """""" # Get (legacy) resource information. Same as get_available_resource, # but we don't need to refresh self.host_wrapper as it was *just* # refreshed by get_available_resource in the resource tracker's # update_available_resource flow. data = self._get_available_resource() # TODO(efried): Fix these to reflect something like reality # For now, duplicate the logic the resource tracker uses via # update_compute_node when get_inventory/update_provider_tree is not # implemented. cpu_alloc_ratio = CONF.cpu_allocation_ratio or 16.0 cpu_reserved = CONF.reserved_host_cpus mem_alloc_ratio = CONF.ram_allocation_ratio or 1.5 mem_reserved = CONF.reserved_host_memory_mb disk_alloc_ratio = CONF.disk_allocation_ratio or 1.0 disk_reserved = compute_utils.convert_mb_to_ceil_gb( CONF.reserved_host_disk_mb) inventory = { rc_fields.ResourceClass.VCPU: { 'total': data['vcpus'], 'max_unit': data['vcpus'], 'allocation_ratio': cpu_alloc_ratio, 'reserved': cpu_reserved, }, rc_fields.ResourceClass.MEMORY_MB: { 'total': data['memory_mb'], 'max_unit': data['memory_mb'], 'allocation_ratio': mem_alloc_ratio, 'reserved': mem_reserved, }, rc_fields.ResourceClass.DISK_GB: { # TODO(efried): Proper DISK_GB sharing when SSP driver in play 'total': int(data['local_gb']), 'max_unit': int(data['local_gb']), 'allocation_ratio': disk_alloc_ratio, 'reserved': disk_reserved, }, } provider_tree.update_inventory(nodename, inventory) def get_host_uptime(self): """"""Returns the result of calling ""uptime"" on the target host."""""" # trivial implementation from libvirt/driver.py for consistency out, err = n_utils.execute('env', 'LANG=C', 'uptime') return out def attach_interface(self, context, instance, image_meta, vif): """"""Attach an interface to the instance."""""" self.plug_vifs(instance, [vif]) def detach_interface(self, context, instance, vif): """"""Detach an interface from the instance."""""" self.unplug_vifs(instance, [vif]) def plug_vifs(self, instance, network_info): """"""Plug VIFs into networks."""""" self._log_operation('plug_vifs', instance) # Define the flow flow = tf_lf.Flow(""plug_vifs"") # Get the LPAR Wrapper flow.add(tf_vm.Get(self.adapter, self.host_uuid, instance)) # Run the attach slot_mgr = slot.build_slot_mgr(instance, self.store_api) flow.add(tf_net.PlugVifs(self.virtapi, self.adapter, instance, network_info, self.host_uuid, slot_mgr)) # Save the new slot info flow.add(tf_slot.SaveSlotStore(instance, slot_mgr)) # Run the flow try: tf_base.run(flow, instance=instance) except exception.InstanceNotFound: raise exception.VirtualInterfacePlugException( _(""Plug vif failed because instance %s was not found."") % instance.name) except Exception: LOG.exception(""PowerVM error plugging vifs."", instance=instance) raise exception.VirtualInterfacePlugException( _(""Plug vif failed because of an unexpected error."")) def unplug_vifs(self, instance, network_info): """"""Unplug VIFs from networks."""""" self._log_operation('unplug_vifs', instance) # Define the flow flow = tf_lf.Flow(""unplug_vifs"") # Get the LPAR Wrapper flow.add(tf_vm.Get(self.adapter, self.host_uuid, instance)) # Run the detach slot_mgr = slot.build_slot_mgr(instance, self.store_api) flow.add(tf_net.UnplugVifs(self.adapter, instance, network_info, self.host_uuid, slot_mgr)) # Save the new slot info flow.add(tf_slot.SaveSlotStore(instance, slot_mgr)) # Run the flow try: tf_base.run(flow, instance=instance) except exception.InstanceNotFound: LOG.warning('VM was not found during unplug operation as it is ' 'already possibly deleted.', instance=instance) except Exception: LOG.exception(""PowerVM error trying to unplug vifs."", instance=instance) raise exception.InterfaceDetachFailed(instance_uuid=instance.uuid) def get_available_nodes(self, refresh=False): """"""Returns nodenames of all nodes managed by the compute service. This method is for multi compute-nodes support. If a driver supports multi compute-nodes, this method returns a list of nodenames managed by the service. Otherwise, this method should return [hypervisor_hostname]. """""" return [CONF.host] def legacy_nwinfo(self): """"""Indicate if the driver requires the legacy network_info format."""""" return False def get_host_ip_addr(self): """"""Retrieves the IP address of the Host."""""" # This code was pulled from the libvirt driver. ips = compute_utils.get_machine_ips() if CONF.my_ip not in ips: LOG.warning('my_ip address (%(my_ip)s) was not found on ' 'any of the interfaces: %(ifaces)s', {'my_ip': CONF.my_ip, 'ifaces': "", "".join(ips)}) return CONF.my_ip def get_volume_connector(self, instance): """"""Get connector information for the instance for attaching to volumes. Connector information is a dictionary representing the ip of the machine that will be making the connection, the name of the iscsi initiator and the hostname of the machine as follows:: { 'ip': ip, 'initiator': initiator, 'host': hostname } """""" # Put the values in the connector connector = {} wwpn_list = vol_attach.get_wwpns_for_volume_connector( self.adapter, self.host_uuid, instance) if wwpn_list is not None: connector[""wwpns""] = wwpn_list connector[""multipath""] = CONF.powervm.volume_use_multipath connector['host'] = vol_attach.get_hostname_for_volume(instance) initiator_dict = iscsi.get_iscsi_initiators(self.adapter) if initiator_dict: connector['initiator'] = list(initiator_dict.values())[0] return connector def migrate_disk_and_power_off(self, context, instance, dest, flavor, network_info, block_device_info=None, timeout=0, retry_interval=0): disk_info = {} if flavor and flavor.root_gb < instance.root_gb: raise exception.InstanceFaultRollback( exception.ResizeError(reason=_('Cannot reduce disk size.'))) same_host = dest == self.get_host_ip_addr() if same_host: self._log_operation('resize', instance) else: self._log_operation('migration', instance) # Can't migrate the disks if they are not on shared storage if not self._is_booted_from_volume(block_device_info): if not self.disk_dvr.capabilities['shared_storage']: raise exception.InstanceFaultRollback( exception.ResizeError( reason=_('Cannot migrate local disks.'))) # Get disk info from disk driver. disk_info = dict(disk_info, **self.disk_dvr.get_info()) # Define the migrate flow flow = tf_lf.Flow(""migrate_vm"") # Power off the VM flow.add(tf_vm.PowerOff(self.adapter, instance)) if not same_host: # If VM is moving to a new host make sure the NVRAM is at the very # latest. flow.add(tf_vm.StoreNvram(self.nvram_mgr, instance, immediate=True)) if flavor.root_gb > instance.root_gb: # Resize the root disk flow.add(tf_stg.ExtendDisk( self.disk_dvr, instance, dict(type='boot'), flavor.root_gb)) # Disconnect any volumes that are attached. They are reattached # on the new VM (or existing VM if this is just a resize.) # Extract the block devices. bdms = self._extract_bdm(block_device_info) if bdms: # Create the transaction manager (FeedTask) for Storage I/O. xag = self._get_inst_xag(instance, bdms) stg_ftsk = pvm_par.build_active_vio_feed_task(self.adapter, xag=xag) # Get the slot map. This is so we build the client # adapters in the same slots. slot_mgr = slot.build_slot_mgr( instance, self.store_api, adapter=self.adapter, vol_drv_iter=self._vol_drv_iter(instance, bdms, stg_ftsk=stg_ftsk)) # Determine if there are volumes to disconnect. If so, remove each # volume (within the transaction manager) self._add_volume_disconnection_tasks(context, instance, bdms, flow, stg_ftsk, slot_mgr) # Add the transaction manager flow to the end of the 'storage # disconnection' tasks. This will run all the disconnections in # parallel flow.add(stg_ftsk) # We rename the VM to help identify if this is a resize and so it's # easy to see the VM is being migrated from pvmctl. We use the resize # name so we don't destroy it on a revert when it's on the same host. new_name = self._gen_resize_name(instance, same_host=same_host) flow.add(tf_vm.Rename(self.adapter, instance, new_name)) try: tf_base.run(flow, instance=instance) except Exception as e: raise exception.InstanceFaultRollback(e) return disk_info @staticmethod def _gen_resize_name(instance, same_host=False): """"""Generate a temporary name for the source VM being resized/migrated. :param instance: nova.objects.instance.Instance being migrated/resized. :param same_host: Boolean indicating whether this resize is being performed for the sake of a resize (True) or a migration (False). :return: A new name which can be assigned to the source VM. """""" prefix = 'resize_' if same_host else 'migrate_' return pvm_util.sanitize_partition_name_for_api(prefix + instance.name) def finish_migration(self, context, migration, instance, disk_info, network_info, image_meta, resize_instance, block_device_info=None, power_on=True): """"""Completes a resize or cold migration. :param context: the context for the migration/resize :param migration: the migrate/resize information :param instance: nova.objects.instance.Instance being migrated/resized :param disk_info: the newly transferred disk information :param network_info: :py:meth:`~nova.network.manager.NetworkManager.get_instance_nw_info` :param nova.objects.ImageMeta image_meta: The metadata of the image of the instance. :param resize_instance: True if the instance disks are being resized, False otherwise :param block_device_info: instance volume block device info :param power_on: True if the instance should be powered on, False otherwise """""" # See if this was to the same host same_host = migration.source_compute == migration.dest_compute if same_host: self._log_operation('finish resize', instance) else: self._log_operation('finish migration', instance) # Ensure the disk drivers are compatible. if (not same_host and not self._is_booted_from_volume(block_device_info)): # Can't migrate the disks if they are not on shared storage if not self.disk_dvr.capabilities['shared_storage']: raise exception.InstanceFaultRollback( exception.ResizeError( reason=_('Cannot migrate local disks.'))) # Call the disk driver to evaluate the disk info reason = self.disk_dvr.validate(disk_info) if reason: raise exception.InstanceFaultRollback( exception.ResizeError(reason=reason)) # Extract the block devices. bdms = self._extract_bdm(block_device_info) # Define the flow flow = tf_lf.Flow(""finish_migration"") # If attaching disks or volumes if bdms or not same_host: # Create the transaction manager (FeedTask) for Storage I/O. xag = self._get_inst_xag(instance, bdms) stg_ftsk = pvm_par.build_active_vio_feed_task(self.adapter, xag=xag) # We need the slot manager # a) If migrating to a different host: to restore the proper slots; # b) If adding/removing block devices, to register the slots. slot_mgr = slot.build_slot_mgr( instance, self.store_api, adapter=self.adapter, vol_drv_iter=self._vol_drv_iter(instance, bdms, stg_ftsk=stg_ftsk)) else: stg_ftsk = None if same_host: # This is just a resize. new_name = self._gen_resize_name(instance, same_host=True) flow.add(tf_vm.Resize(self.adapter, self.host_wrapper, instance, name=new_name)) else: # This is a migration over to another host. We have a lot of work. # Create the LPAR flow.add(tf_vm.Create(self.adapter, self.host_wrapper, instance, stg_ftsk=stg_ftsk, nvram_mgr=self.nvram_mgr, slot_mgr=slot_mgr)) # Create a flow for the network IO flow.add(tf_net.PlugVifs(self.virtapi, self.adapter, instance, network_info, self.host_uuid, slot_mgr)) flow.add(tf_net.PlugMgmtVif( self.adapter, instance, self.host_uuid, slot_mgr)) # Need to attach the boot disk, if present. if not self._is_booted_from_volume(block_device_info): flow.add(tf_stg.FindDisk(self.disk_dvr, context, instance, disk_dvr.DiskType.BOOT)) # Connects up the disk to the LPAR # TODO(manas) Connect the disk flow into the slot lookup map flow.add(tf_stg.ConnectDisk( self.disk_dvr, instance, stg_ftsk=stg_ftsk)) if bdms: # Determine if there are volumes to connect. If so, add a # connection for each type. self._add_volume_connection_tasks( context, instance, bdms, flow, stg_ftsk, slot_mgr) if stg_ftsk: # Add the transaction manager flow to the end of the 'storage # connection' tasks to run all the connections in parallel flow.add(stg_ftsk) if power_on: flow.add(tf_vm.PowerOn(self.adapter, instance)) # Run the flow try: tf_base.run(flow, instance=instance) except Exception as e: raise exception.InstanceFaultRollback(e) def confirm_migration(self, context, migration, instance, network_info): """"""Confirms a resize, destroying the source VM. :param migration: the migrate/resize information :param instance: nova.objects.instance.Instance :param network_info: :py:meth:`~nova.network.manager.NetworkManager.get_instance_nw_info` """""" # See if this was to the same host same_host = migration.source_compute == migration.dest_compute if same_host: # This was a local resize, don't delete our only VM! self._log_operation('confirm resize', instance) vm.rename(self.adapter, instance, instance.name) return # Confirming the migrate means we need to delete source VM. self._log_operation('confirm migration', instance) # Destroy the old VM. destroy_disks = not self.disk_dvr.capabilities['shared_storage'] self._destroy(context, instance, block_device_info=None, destroy_disks=destroy_disks, shutdown=False) def finish_revert_migration(self, context, instance, network_info, block_device_info=None, power_on=True): """"""Finish reverting a resize on the source host. :param context: the context for the finish_revert_migration :param instance: nova.objects.instance.Instance being migrated/resized :param network_info: :py:meth:`~nova.network.manager.NetworkManager.get_instance_nw_info` :param block_device_info: instance volume block device info :param power_on: True if the instance should be powered on, False otherwise """""" self._log_operation('revert resize/migration', instance) # This method is always run on the source host, so we just need to # revert the VM back to it's old sizings, if it was even changed # at all. If it was a migration, then it wasn't changed but it # shouldn't hurt to ""update"" it with the prescribed flavor. This # makes it easy to handle both resize and migrate. # # The flavor should be the 'old' flavor now. vm.power_off(self.adapter, instance) vm.update(self.adapter, self.host_wrapper, instance) if power_on: vm.power_on(self.adapter, instance) def ensure_filtering_rules_for_instance(self, instance, network_info): """"""Setting up filtering rules and waiting for its completion. To migrate an instance, filtering rules to hypervisors and firewalls are inevitable on destination host. ( Waiting only for filtering rules to hypervisor, since filtering rules to firewall rules can be set faster). Concretely, the below method must be called. - setup_basic_filtering (for nova-basic, etc.) - prepare_instance_filter(for nova-instance-instance-xxx, etc.) to_xml may have to be called since it defines PROJNET, PROJMASK. but libvirt migrates those value through migrateToURI(), so , no need to be called. Don't use thread for this method since migration should not be started when setting-up filtering rules operations are not completed. :param instance: nova.objects.instance.Instance object """""" # No op for PowerVM def check_can_live_migrate_destination(self, context, instance, src_compute_info, dst_compute_info, block_migration=False, disk_over_commit=False): """"""Check if it is possible to execute live migration. This runs checks on the destination host, and then calls back to the source host to check the results. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance :param src_compute_info: Info about the sending machine :param dst_compute_info: Info about the receiving machine :param block_migration: if true, prepare for block migration :param disk_over_commit: if true, allow disk over commit :returns: a dict containing migration info (hypervisor-dependent) """""" LOG.info(""Checking live migration capability on destination host."", instance=instance) mig = lpm.LiveMigrationDest(self, instance) self.live_migrations[instance.uuid] = mig return mig.check_destination(context, src_compute_info, dst_compute_info) def cleanup_live_migration_destination_check(self, context, dest_check_data): """"""Do required cleanup on dest host after check_can_live_migrate calls :param context: security context :param dest_check_data: result of check_can_live_migrate_destination """""" LOG.info(""Cleaning up from checking live migration capability "" ""on destination."") def check_can_live_migrate_source(self, context, instance, dest_check_data, block_device_info=None): """"""Check if it is possible to execute live migration. This checks if the live migration can succeed, based on the results from check_can_live_migrate_destination. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance :param dest_check_data: result of check_can_live_migrate_destination :param block_device_info: result of _get_instance_block_device_info :returns: a dict containing migration info (hypervisor-dependent) """""" LOG.info(""Checking live migration capability on source host."", instance=instance) mig = lpm.LiveMigrationSrc(self, instance, dest_check_data) self.live_migrations[instance.uuid] = mig # Get a volume driver for each volume vol_drvs = self._build_vol_drivers(context, instance, block_device_info) return mig.check_source(context, block_device_info, vol_drvs) def pre_live_migration(self, context, instance, block_device_info, network_info, disk_info, migrate_data=None): """"""Prepare an instance for live migration :param context: security context :param instance: nova.objects.instance.Instance object :param block_device_info: instance block device information :param network_info: instance network information :param disk_info: instance disk information :param migrate_data: a LiveMigrateData object """""" LOG.info(""Pre live migration processing."", instance=instance) mig = self.live_migrations[instance.uuid] # Get a volume driver for each volume vol_drvs = self._build_vol_drivers(context, instance, block_device_info) # Run pre-live migration return mig.pre_live_migration(context, block_device_info, network_info, disk_info, migrate_data, vol_drvs) def live_migration(self, context, instance, dest, post_method, recover_method, block_migration=False, migrate_data=None): """"""Live migration of an instance to another host. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance object instance object that is migrated. :param dest: destination host :param post_method: post operation method. expected nova.compute.manager._post_live_migration. :param recover_method: recovery method when any exception occurs. expected nova.compute.manager._rollback_live_migration. :param block_migration: if true, migrate VM disk. :param migrate_data: a LiveMigrateData object """""" self._log_operation('live_migration', instance) try: mig = self.live_migrations[instance.uuid] try: mig.live_migration(context, migrate_data) except pvm_exc.JobRequestTimedOut as timeout_ex: # If the migration operation exceeds configured timeout LOG.error(""Live migration timed out. Aborting migration"", instance=instance) mig.migration_abort() self._migration_exception_util(context, instance, dest, recover_method, migrate_data, mig, ex=timeout_ex) except Exception as e: LOG.exception(""PowerVM error during live migration."", instance=instance) self._migration_exception_util(context, instance, dest, recover_method, migrate_data, mig, ex=e) LOG.debug(""Calling post live migration method."", instance=instance) # Post method to update host in OpenStack and finish live-migration post_method(context, instance, dest, block_migration, migrate_data) finally: # Remove the migration record on the source side. del self.live_migrations[instance.uuid] def _migration_exception_util(self, context, instance, dest, recover_method, migrate_data, mig, ex): """"""Migration exception utility. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance object instance object that is migrated. :param dest: destination host :param recover_method: recovery method when any exception occurs. expected nova.compute.manager._rollback_live_migration. :param migrate_data: a LiveMigrateData object :param mig: live_migration object :param ex: exception reason """""" LOG.warning(""Rolling back live migration."", instance=instance) try: mig.rollback_live_migration(context) recover_method(context, instance, dest, migrate_data=migrate_data) except Exception: LOG.exception(""PowerVM error rolling back live migration."", instance=instance) raise lpm.LiveMigrationFailed(name=instance.name, reason=six.text_type(ex)) def rollback_live_migration_at_destination(self, context, instance, network_info, block_device_info, destroy_disks=True, migrate_data=None): """"""Clean up destination node after a failed live migration. :param context: security context :param instance: instance object that was being migrated :param network_info: instance network information :param block_device_info: instance block device information :param destroy_disks: if true, destroy disks at destination during cleanup :param migrate_data: a LiveMigrateData object """""" # Run the rollback mig = self.live_migrations[instance.uuid] mig.rollback_live_migration_at_destination( context, instance, network_info, block_device_info, destroy_disks=destroy_disks, migrate_data=migrate_data) # Remove the active migration del self.live_migrations[instance.uuid] def check_instance_shared_storage_local(self, context, instance): """"""Check if instance files located on shared storage. This runs check on the destination host, and then calls back to the source host to check the results. :param context: security context :param instance: nova.objects.instance.Instance object """""" # Defer to the disk driver method. return self.disk_dvr.check_instance_shared_storage_local( context, instance) def check_instance_shared_storage_remote(self, context, data): """"""Check if instance files located on shared storage. :param context: security context :param data: result of check_instance_shared_storage_local """""" # Defer to the disk driver method. return self.disk_dvr.check_instance_shared_storage_remote( context, data) def check_instance_shared_storage_cleanup(self, context, data): """"""Do cleanup on host after check_instance_shared_storage calls :param context: security context :param data: result of check_instance_shared_storage_local """""" # Defer to the disk driver method. return self.disk_dvr.check_instance_shared_storage_cleanup( context, data) def post_live_migration(self, context, instance, block_device_info, migrate_data=None): """"""Post operation of live migration at source host. :param context: security context :instance: instance object that was migrated :block_device_info: instance block device information :param migrate_data: a LiveMigrateData object """""" # Build the volume drivers vol_drvs = self._build_vol_drivers(context, instance, block_device_info) mig = self.live_migrations[instance.uuid] mig.post_live_migration(vol_drvs, migrate_data) def post_live_migration_at_source(self, context, instance, network_info): """"""Unplug VIFs from networks at source. :param context: security context :param instance: instance object reference :param network_info: instance network information """""" LOG.info(""Post live migration processing on source host."", instance=instance) mig = self.live_migrations[instance.uuid] mig.post_live_migration_at_source(network_info) def post_live_migration_at_destination(self, context, instance, network_info, block_migration=False, block_device_info=None): """"""Post operation of live migration at destination host. :param context: security context :param instance: instance object that is migrated :param network_info: instance network information :param block_migration: if true, post operation of block_migration. :param block_device_info: instance block device information. """""" LOG.info(""Post live migration processing on destination host."", instance=instance) mig = self.live_migrations[instance.uuid] mig.instance = instance bdms = self._extract_bdm(block_device_info) # Get a volume driver iterator for volume and BDM mapping vol_drv_iter = self._vol_drv_iter(instance, bdms) # Run post live migration mig.post_live_migration_at_destination(network_info, vol_drv_iter) del self.live_migrations[instance.uuid] def _vol_drv_iter(self, instance, bdms, stg_ftsk=None): """"""Yields a bdm and volume driver."""""" # Get a volume driver for each volume for bdm in bdms or []: vol_drv = vol_attach.build_volume_driver( self.adapter, self.host_uuid, instance, bdm.get('connection_info'), stg_ftsk=stg_ftsk) yield bdm, vol_drv def _build_vol_drivers(self, context, instance, block_device_info): """"""Builds the volume connector drivers for a block device info."""""" # Get a volume driver for each volume bdms = self._extract_bdm(block_device_info) return [vol_drv for bdm, vol_drv in self._vol_drv_iter(instance, bdms)] def unfilter_instance(self, instance, network_info): """"""Stop filtering instance."""""" # No op for PowerVM pass @staticmethod def _extract_bdm(block_device_info): """"""Returns the block device mapping out of the block device info. The block device mapping is a list of instances of block device classes from nova.virt.block_device. Each block device represents one volume connection. An example string representation of a DriverVolumeBlockDevice from the early Liberty time frame is: {'guest_format': None, 'boot_index': 0, 'mount_device': u'/dev/sda', 'connection_info': {u'driver_volume_type': u'fibre_channel', u'serial': u'e11765ea-dd14-4aa9-a953-4fd6b4999635', u'data': {u'initiator_target_map': {u'21000024ff747e59': [u'500507680220E522', u'500507680210E522'], u'21000024ff747e58': [u'500507680220E522', u'500507680210E522']}, u'vendor': u'IBM', u'target_discovered':False, u'target_UID': u'600507680282...', u'qos_specs': None, u'volume_id': u'e11765ea-...', u'target_lun': u'2', u'access_mode': u'rw', u'target_wwn': u'500507680220E522'} }, 'disk_bus': None, 'device_type': u'disk', 'delete_on_termination': True} """""" if block_device_info is None: return [] return block_device_info.get('block_device_mapping', []) def get_vnc_console(self, context, instance): """"""Get connection info for a vnc console. :param context: security context :param instance: nova.objects.instance.Instance :return: An instance of console.type.ConsoleVNC """""" self._log_operation('get_vnc_console', instance) lpar_uuid = vm.get_pvm_uuid(instance) # Build the connection to the VNC. host = CONF.vnc.server_proxyclient_address use_x509_auth = CONF.powervm.vnc_use_x509_auth ca_certs = CONF.powervm.vnc_ca_certs server_key = CONF.powervm.vnc_server_key server_cert = CONF.powervm.vnc_server_cert try: # Open up a remote vterm with the host and certificates configured # This will only use TLS if the use_x509_auth is set to True port = pvm_vterm.open_remotable_vnc_vterm( self.adapter, lpar_uuid, host, vnc_path=lpar_uuid, use_x509_auth=use_x509_auth, ca_certs=ca_certs, server_cert=server_cert, server_key=server_key) except pvm_exc.HttpNotFound: raise exception.InstanceNotFound(instance_id=instance.uuid) except pvm_exc.Error as exc: # Otherwise wrapper the error in an exception that can be handled LOG.exception(""Unable to open console."", instance=instance) msg = (_(""VNC based terminal for instance %(instance_name)s "" ""failed to open: %(exc_msg)s"") % {'instance_name': instance.name, 'exc_msg': exc.args[0]}) # Need to raise ConsoleTypeUnavailable with overwritten message # because otherwise the exception will not be caught. It is # disallowed to send a non-nova exception over the wire. raise exception.ConsoleTypeUnavailable(msg) # Note that the VNC viewer will wrap the internal_access_path with # the HTTP content. return console_type.ConsoleVNC(host=host, port=port, internal_access_path=lpar_uuid) def _get_inst_xag(self, instance, bdms, recreate=False): """"""Returns the extended attributes required for a given instance. This is used in coordination with the FeedTask. It identifies ahead of time what each request requires for its general operations. :param instance: Nova instance for which the volume adapter is needed. :param bdms: The BDMs for the operation. :param recreate: (Optional, Default: False) If set to true, will return all of the storage XAGs so that a full scrub can be done (since specific slots are needed). :return: List of extended attributes required for the operation. """""" if recreate: return {pvm_const.XAG.VIO_FMAP, pvm_const.XAG.VIO_SMAP, pvm_const.XAG.VIO_STOR} # All operations for deploy/destroy require scsi by default. This is # either vopt, local/SSP disks, etc... xags = {pvm_const.XAG.VIO_SMAP} # BDMs could be none, if there are no cinder volumes. bdms = bdms if bdms else [] # If we have any volumes, add the volumes required mapping XAGs. for bdm in bdms: driver_type = bdm.get('connection_info').get('driver_volume_type') vol_cls = vol_attach.get_volume_class(driver_type) xags.update(set(vol_cls.min_xags())) LOG.debug('Instance XAGs: %(xags)s.', {'xags': ','.join(xags)}, instance=instance) return list(xags) def _get_boot_connectivity_type(self, bdms, block_device_info): """"""Get connectivity information for the instance. :param bdms: The BDMs for the operation. If boot volume of the instance is ssp lu or local disk, the bdms is None. :param block_device_info: Instance volume block device info. :return: The boot connectivity type. If boot volume is an npiv volume, returns 'fibre_channel'. Otherwise, returns 'vscsi'. """""" if self._is_booted_from_volume(block_device_info) and bdms is not None: for bdm in bdms: if bdm.get('boot_index') == 0: return self._get_connectivity_type(bdm) # Default connectivity type is 'vscsi' return 'vscsi' @staticmethod def _get_connectivity_type(bdm): conn_info = bdm.get('connection_info') if 'connection-type' in conn_info['data']: connectivity_type = conn_info['data']['connection-type'] return ('vscsi' if connectivity_type == 'pv_vscsi' else connectivity_type) # Seemingly bogus path (driver_volume_type shouldn't be in 'data'), # preserved for potential compatibility. if 'driver_volume_type' in conn_info['data']: return conn_info['data']['driver_volume_type'] # Actual location for driver_volume_type. Default to vscsi. return conn_info.get('driver_volume_type', 'vscsi') def deallocate_networks_on_reschedule(self, instance): """"""Does the driver want networks deallocated on reschedule? :param instance: the instance object. :returns: Boolean value. If True deallocate networks on reschedule. """""" return True def _cleanup_orphan_adapters(self, vswitch_name): """"""Finds and removes trunk VEAs that have no corresponding CNA."""""" orphans = pvm_cna.find_orphaned_trunks(self.adapter, vswitch_name) for orphan in orphans: LOG.info(""Deleting orphan CNA: %s"", orphan.dev_name) orphan.delete()",0,1824
openstack%2Fnova~master~I41c479278940444ed5733ca35839d86073db31de,openstack/nova,master,I41c479278940444ed5733ca35839d86073db31de,WIP: libvirt: Turn off max_unit,ABANDONED,2018-09-20 14:49:49.000000000,2019-02-11 18:48:33.000000000,,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-20 14:49:49.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ed4ef50544a8b2646f77abc5a1cc3713345eb426', 'message': ""WIP: libvirt: Turn off max_unit\n\nDon't enforce max_unit for any resources from libvirt.\n\nChange-Id: I41c479278940444ed5733ca35839d86073db31de\n""}]",0,604110,ed4ef50544a8b2646f77abc5a1cc3713345eb426,12,10,1,14070,,,0,"WIP: libvirt: Turn off max_unit

Don't enforce max_unit for any resources from libvirt.

Change-Id: I41c479278940444ed5733ca35839d86073db31de
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/604110/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,ed4ef50544a8b2646f77abc5a1cc3713345eb426,libvirt-no-max-unit,," 'max_unit': vcpus, 'max_unit': memory_mb, 'max_unit': disk_gb, 'max_unit': vgpus,",0,4
openstack%2Fpuppet-tripleo~stable%2Frocky~Icca33ec759a9ef5abca6da4cd2e59f0a5d9b7061,openstack/puppet-tripleo,stable/rocky,Icca33ec759a9ef5abca6da4cd2e59f0a5d9b7061,mysql: use clustercheck credentials to poll galera state,MERGED,2019-02-08 14:48:25.000000000,2019-02-11 18:48:23.000000000,2019-02-11 18:48:23.000000000,"[{'_account_id': 3153}, {'_account_id': 11090}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 14:48:25.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/b35b807670f68c757ed561c19b3467d778096129', 'message': 'mysql: use clustercheck credentials to poll galera state\n\nIn the galera container, clustercheck is currently configured to\nuse root credentials to poll the state of the local galera node.\n\nconfigure clustercheck to use the clustercheck credentials instead.\n\nChange-Id: Icca33ec759a9ef5abca6da4cd2e59f0a5d9b7061\nRelated-Bug: #1792416\n(cherry picked from commit 8fe26972a0777f8e7bc7aa0e5e16774d1df5d15d)\n'}]",0,635853,b35b807670f68c757ed561c19b3467d778096129,9,5,1,20778,,,0,"mysql: use clustercheck credentials to poll galera state

In the galera container, clustercheck is currently configured to
use root credentials to poll the state of the local galera node.

configure clustercheck to use the clustercheck credentials instead.

Change-Id: Icca33ec759a9ef5abca6da4cd2e59f0a5d9b7061
Related-Bug: #1792416
(cherry picked from commit 8fe26972a0777f8e7bc7aa0e5e16774d1df5d15d)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/53/635853/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,b35b807670f68c757ed561c19b3467d778096129,bug/1792416,"# [*clustercheck_user*] # (Optional) The name of the clustercheck user. # Defaults to 'clustercheck' # # [*clustercheck_password*] # (Optional) The password for the clustercheck user. # Defaults to hiera('mysql_clustercheck_password') # $clustercheck_user = 'clustercheck', $clustercheck_password = hiera('mysql_clustercheck_password'), content => ""MYSQL_USERNAME=${clustercheck_user}\n MYSQL_PASSWORD='${clustercheck_password}'\n File['/etc/sysconfig/clustercheck'] -> Exec['galera-ready']"," content => ""MYSQL_USERNAME=root\n MYSQL_PASSWORD='${mysql_root_password}'\n File['/etc/sysconfig/clustercheck'] -> Mysql_database<||> File['/etc/sysconfig/clustercheck'] -> Mysql_user<||> File['/etc/sysconfig/clustercheck'] -> Mysql_grant<||>",13,5
openstack%2Fpython-senlinclient~master~Ife9d3be5acd740f6de7721ba54aa87d44f924728,openstack/python-senlinclient,master,Ife9d3be5acd740f6de7721ba54aa87d44f924728,Fix getting action id in Location header,MERGED,2019-01-31 22:09:46.000000000,2019-02-11 18:43:34.000000000,2019-02-11 18:43:34.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 25674}]","[{'number': 1, 'created': '2019-01-31 22:09:46.000000000', 'files': ['senlinclient/v1/cluster.py', 'senlinclient/v1/node.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/380ebb797a88771005b3a722438db2465e0194b6', 'message': 'Fix getting action id in Location header\n\nopenstacksdk was changed to return action object with id inside for API\ncalls that have location in response header.\n\nThis change retrieves the action id from the action object returned when\ncalling cluster delete and node delete.\n\nDepends-On: https://review.openstack.org/#/c/631362/\nChange-Id: Ife9d3be5acd740f6de7721ba54aa87d44f924728\nCloses-Bug: #1814171\n'}]",0,634326,380ebb797a88771005b3a722438db2465e0194b6,7,3,1,27224,,,0,"Fix getting action id in Location header

openstacksdk was changed to return action object with id inside for API
calls that have location in response header.

This change retrieves the action id from the action object returned when
calling cluster delete and node delete.

Depends-On: https://review.openstack.org/#/c/631362/
Change-Id: Ife9d3be5acd740f6de7721ba54aa87d44f924728
Closes-Bug: #1814171
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/26/634326/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/v1/cluster.py', 'senlinclient/v1/node.py']",2,380ebb797a88771005b3a722438db2465e0194b6,bug/1814171," node_delete_action = senlin_client.delete_node( result[nid] = ('OK', node_delete_action['id'])"," node = senlin_client.delete_node( result[nid] = ('OK', node.location.split('/')[-1])",4,4
openstack%2Fopenstack-ansible~stable%2Frocky~I6546b612593f700c89184f8b2cd87eecae3dde4e,openstack/openstack-ansible,stable/rocky,I6546b612593f700c89184f8b2cd87eecae3dde4e,Bump SHAs for stable/rocky,MERGED,2019-02-09 08:44:11.000000000,2019-02-11 18:43:01.000000000,2019-02-11 18:43:01.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 08:44:11.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/fix-l3-agent-ha-keepalive-helper-5f1f82c437c8a430.yaml', 'releasenotes/notes/os_cinder-private-volume-type-9b2cc92c6c74c277.yaml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5fbdf242aae297e00d50df7c7da962117190cbc8', 'message': 'Bump SHAs for stable/rocky\n\nChange-Id: I6546b612593f700c89184f8b2cd87eecae3dde4e\n'}]",0,636003,5fbdf242aae297e00d50df7c7da962117190cbc8,7,3,1,17068,,,0,"Bump SHAs for stable/rocky

Change-Id: I6546b612593f700c89184f8b2cd87eecae3dde4e
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/03/636003/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'releasenotes/notes/fix-l3-agent-ha-keepalive-helper-5f1f82c437c8a430.yaml', 'releasenotes/notes/os_cinder-private-volume-type-9b2cc92c6c74c277.yaml', 'ansible-role-requirements.yml']",5,5fbdf242aae297e00d50df7c7da962117190cbc8,bump_osa, version: 37f4b6d08b50445a23dfbbb6056e15a4af40c7bb version: 3138838ff8f169ae0cf413c459785d5f20306f33 version: e0439b40c2911ebe44b492969f791f09b0d63c0c version: 6aca261a7c3ed5e6a7561cb66d8956df89657b78 version: 1966ebc4ae777680ddcbb0bd8831901cd131582f version: 8acb54f92295bbd25faa472fc3143751b5080190 version: 7c6c019ff1135b1fee532abf10c0071b3053a4a7, version: ba36e620361db1daf9180ecd687c17064259b844 version: ed7072da96ee21f0263f0b81aaf7c6ec7c9905c0 version: 9b8d7483d69e60f4ae71ceb6a3336ff81f355c38 version: 3fbd72ffe9e7197949410b7a95f1d59c581b5d8e version: 7c90daa9097f816aac797a0d93cabff23bdd7edd version: d324fa78b035cfc86531141b8a87d0728e314cd5 version: 08341f4a19b2ed2231b790496c9f7cf2b4eda2e6,53,45
openstack%2Fopenstack-ansible~stable%2Fqueens~I57cede7c7f41d38951e56624aa8c136ca4432258,openstack/openstack-ansible,stable/queens,I57cede7c7f41d38951e56624aa8c136ca4432258,Bump SHAs for stable/queens,MERGED,2019-02-09 08:44:27.000000000,2019-02-11 18:32:06.000000000,2019-02-11 18:32:06.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 08:44:27.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c08cf470c577381dde3081b7f2e9c62774108640', 'message': 'Bump SHAs for stable/queens\n\nChange-Id: I57cede7c7f41d38951e56624aa8c136ca4432258\n'}]",0,636004,c08cf470c577381dde3081b7f2e9c62774108640,7,3,1,17068,,,0,"Bump SHAs for stable/queens

Change-Id: I57cede7c7f41d38951e56624aa8c136ca4432258
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/04/636004/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml']",2,c08cf470c577381dde3081b7f2e9c62774108640,bump_osa,gnocchi_git_install_branch: 17f1d51493781daaafdfca67b4b912d3bae02055 # HEAD as of 09.02.2019,gnocchi_git_install_branch: 17f1d51493781daaafdfca67b4b912d3bae02055 # HEAD as of 26.01.2019,40,40
openstack%2Fopenstack-ansible~stable%2Fpike~I431053adcbb957084b7bc0856d2ea6f3c5f019d2,openstack/openstack-ansible,stable/pike,I431053adcbb957084b7bc0856d2ea6f3c5f019d2,Bump SHAs for stable/pike,MERGED,2019-02-09 08:45:32.000000000,2019-02-11 18:32:05.000000000,2019-02-11 18:32:05.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 08:45:32.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3bf08d154c8618c37a34d1ed824d9edf2508fbc5', 'message': 'Bump SHAs for stable/pike\n\nChange-Id: I431053adcbb957084b7bc0856d2ea6f3c5f019d2\n'}]",0,636005,3bf08d154c8618c37a34d1ed824d9edf2508fbc5,7,3,1,17068,,,0,"Bump SHAs for stable/pike

Change-Id: I431053adcbb957084b7bc0856d2ea6f3c5f019d2
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/05/636005/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml']",3,3bf08d154c8618c37a34d1ed824d9edf2508fbc5,bump_osa, version: 5aa69064b50501d5b6604aeddcbb9f151b5503cd, version: 2c0651f30ed7f62827b32c471da4fd74866d5bcc,34,34
openstack%2Fopenstack-ansible~master~I93b4ae07feb11749d8af7018dc83fa2d887b8376,openstack/openstack-ansible,master,I93b4ae07feb11749d8af7018dc83fa2d887b8376,Fix typo btrfs -> zfs,MERGED,2019-02-10 01:08:28.000000000,2019-02-11 18:32:04.000000000,2019-02-11 18:32:04.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 9061}, {'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-02-10 01:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3c88988d7e7eae7820f8afdd80e89b319cebe2aa', 'message': 'Fix typo btrfs -> zfs\n\nThis was likely a copy paste from a few lines prior.\n\nChange-Id: I93b4ae07feb11749d8af7018dc83fa2d887b8376\n'}, {'number': 2, 'created': '2019-02-10 02:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ced7fff71b3a5bea36a83ff192e8d101a5ce3ddf', 'message': 'Fix typo btrfs -> zfs\n\nThis was likely a copy paste from a few lines prior.\n\nChange-Id: I93b4ae07feb11749d8af7018dc83fa2d887b8376\n'}, {'number': 3, 'created': '2019-02-11 11:40:36.000000000', 'files': ['tests/roles/bootstrap-host/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6f0a218efa8a49e36bfb4c81dc3c87d451fbef68', 'message': 'Fix typo btrfs -> zfs\n\nThis was likely a copy paste from a few lines prior.\n\nDepends-On: https://review.openstack.org/636115\nChange-Id: I93b4ae07feb11749d8af7018dc83fa2d887b8376\n'}]",0,636035,6f0a218efa8a49e36bfb4c81dc3c87d451fbef68,16,6,3,9061,,,0,"Fix typo btrfs -> zfs

This was likely a copy paste from a few lines prior.

Depends-On: https://review.openstack.org/636115
Change-Id: I93b4ae07feb11749d8af7018dc83fa2d887b8376
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/35/636035/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/defaults/main.yml'],1,3c88988d7e7eae7820f8afdd80e89b319cebe2aa,,# Boolean option to deploy the loopback disk for zfs,# Boolean option to deploy the loopback disk for btrfs,1,1
openstack%2Fproject-config~master~I1d73f543006d94a52fa1cfe38870391da959ae74,openstack/project-config,master,I1d73f543006d94a52fa1cfe38870391da959ae74,Cleanup ozj confingure-unbound usage,MERGED,2019-02-08 17:45:48.000000000,2019-02-11 18:26:14.000000000,2019-02-11 18:26:14.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 17:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a8af1c2287d30c1070cd44003c862290dc4c566a', 'message': 'Cleanup ozj confingure-unbound usage\n\nThis role now lives in opendev/base-jobs but we still have some usage\nfrom ozj. We can clean that up by removing what appears to be the only\njob doing that since it was tempoarary anyway.\n\nAdditioanlly point the nodepool element comments at the right role in\nopendev/base-jobs\n\nChange-Id: I1d73f543006d94a52fa1cfe38870391da959ae74\n'}, {'number': 2, 'created': '2019-02-08 18:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9988a7178f8a9e5846a0e5048e5dc5a85301983c', 'message': 'Cleanup ozj confingure-unbound usage\n\nThis role now lives in opendev/base-jobs but we still have some usage\nfrom ozj. We can clean that up by removing what appears to be the only\njob doing that since it was tempoarary anyway.\n\nAdditioanlly point the nodepool element comments at the right role in\nopendev/base-jobs\n\nChange-Id: I1d73f543006d94a52fa1cfe38870391da959ae74\n'}, {'number': 3, 'created': '2019-02-08 20:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0dd9c45c11423153ab05aefa9cc2597b55cb0f88', 'message': 'Cleanup ozj confingure-unbound usage\n\nThis role now lives in opendev/base-jobs but we still have some usage\nfrom ozj. We can clean that up by removing what appears to be the only\njob doing that since it was tempoarary anyway.\n\nAdditioanlly point the nodepool element comments at the right role in\nopendev/base-jobs\n\nChange-Id: I1d73f543006d94a52fa1cfe38870391da959ae74\n'}, {'number': 4, 'created': '2019-02-08 20:27:40.000000000', 'files': ['zuul.d/secrets.yaml', 'playbooks/base-test/post.yaml', 'nodepool/elements/nodepool-base/finalise.d/89-unbound', 'playbooks/base-test/pre.yaml', 'playbooks/base-test/post-logs-swift.yaml', 'zuul.d/jobs.yaml', 'playbooks/base-test/post-logs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/947c2fd409632caae8056ca750a28ffbbe734e62', 'message': 'Cleanup ozj confingure-unbound usage\n\nThis role now lives in opendev/base-jobs but we still have some usage\nfrom ozj. We can clean that up by removing what appears to be the only\njob doing that since it was tempoarary anyway.\n\nAdditioanlly point the nodepool element comments at the right role in\nopendev/base-jobs\n\nChange-Id: I1d73f543006d94a52fa1cfe38870391da959ae74\n'}]",0,635900,947c2fd409632caae8056ca750a28ffbbe734e62,14,4,4,4146,,,0,"Cleanup ozj confingure-unbound usage

This role now lives in opendev/base-jobs but we still have some usage
from ozj. We can clean that up by removing what appears to be the only
job doing that since it was tempoarary anyway.

Additioanlly point the nodepool element comments at the right role in
opendev/base-jobs

Change-Id: I1d73f543006d94a52fa1cfe38870391da959ae74
",git fetch https://review.opendev.org/openstack/project-config refs/changes/00/635900/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/base-test/post.yaml', 'nodepool/elements/nodepool-base/finalise.d/89-unbound', 'playbooks/base-test/pre.yaml', 'playbooks/base-test/post-logs-swift.yaml', 'zuul.d/jobs.yaml', 'playbooks/base-test/post-logs.yaml']",6,a8af1c2287d30c1070cd44003c862290dc4c566a,cleanup-base,,"- hosts: localhost roles: - role: add-fileserver fileserver: ""{{ site_logs }}"" - role: ara-report - hosts: ""{{ site_logs.fqdn }}"" gather_facts: False roles: - role: test-upload-logs zuul_log_url: ""http://logs.openstack.org"" - hosts: localhost # NOTE(pabelanger): We ignore_errors for the following tasks as not to fail # successful jobs. ignore_errors: yes roles: - submit-logstash-jobs - submit-subunit-jobs ",1,133
openstack%2Fproject-config~master~I3977c5734e0e67b5ce72917a1fb15c1ac3bd5c1c,openstack/project-config,master,I3977c5734e0e67b5ce72917a1fb15c1ac3bd5c1c,Update tenant config for opendev,MERGED,2019-02-09 15:33:07.000000000,2019-02-11 18:12:09.000000000,2019-02-11 18:09:21.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 15:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1ca089711d52cfd74e7f0ab513b7b0112b80d238', 'message': ""Update tenant config for opendev\n\nChange 636006 will move a project stanza into opendev/base-job, take\ncare that it is only used in the openstack tenant and not in others.\nLet's be explicit and only load jobs and secrets.\n\nChange-Id: I3977c5734e0e67b5ce72917a1fb15c1ac3bd5c1c\nNeeded-By: https://review.openstack.org/636006\n""}, {'number': 2, 'created': '2019-02-09 15:36:20.000000000', 'files': ['zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b79cd70324334eace832e772bce1bc54cbab67a9', 'message': ""Update tenant config for opendev\n\nChange 636006 will move a project stanza into opendev/base-job, take\ncare that it is only used in the openstack tenant and not in others.\nLet's be explicit and only load jobs and secrets.\n\nChange-Id: I3977c5734e0e67b5ce72917a1fb15c1ac3bd5c1c\nNeeded-By: https://review.openstack.org/636006\n""}]",1,636027,b79cd70324334eace832e772bce1bc54cbab67a9,11,3,2,6547,,,0,"Update tenant config for opendev

Change 636006 will move a project stanza into opendev/base-job, take
care that it is only used in the openstack tenant and not in others.
Let's be explicit and only load jobs and secrets.

Change-Id: I3977c5734e0e67b5ce72917a1fb15c1ac3bd5c1c
Needed-By: https://review.openstack.org/636006
",git fetch https://review.opendev.org/openstack/project-config refs/changes/27/636027/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,1ca089711d52cfd74e7f0ab513b7b0112b80d238,opendev," # Only use jobs and secrets from this repo, we do not want # the project definition. - opendev/base-jobs: include: - job - secrets", - opendev/base-jobs,6,1
openstack%2Fproject-config~master~I768c4db811bbc54d3bcc7e40fa37b6e83684eab1,openstack/project-config,master,I768c4db811bbc54d3bcc7e40fa37b6e83684eab1,Add opendev/base-jobs to gerritbot,MERGED,2019-02-09 10:45:42.000000000,2019-02-11 18:09:19.000000000,2019-02-11 18:09:19.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 10:45:42.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a75ab96692f71c1cf002c4f53e4fde84082de68', 'message': 'Add opendev/base-jobs to gerritbot\n\nAnnounce changes for the new repo in our IRC channels.\n\nChange-Id: I768c4db811bbc54d3bcc7e40fa37b6e83684eab1\n'}]",0,636008,4a75ab96692f71c1cf002c4f53e4fde84082de68,7,3,1,6547,,,0,"Add opendev/base-jobs to gerritbot

Announce changes for the new repo in our IRC channels.

Change-Id: I768c4db811bbc54d3bcc7e40fa37b6e83684eab1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/08/636008/1 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,4a75ab96692f71c1cf002c4f53e4fde84082de68,base-jobs, - opendev/base-jobs - opendev/base-jobs,,2,0
openstack%2Fsahara~stable%2Fqueens~If8db759ab40ca858594498bc5e6f94f416da2545,openstack/sahara,stable/queens,If8db759ab40ca858594498bc5e6f94f416da2545,Changing hdfs fs to hdfs dfs,MERGED,2019-02-11 13:09:33.000000000,2019-02-11 18:07:48.000000000,2019-02-11 18:07:48.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 13:09:33.000000000', 'files': ['releasenotes/notes/hdfs-dfs-94a9c4f64cf8994f.yaml', 'sahara/tests/unit/service/edp/test_hdfs_helper.py', 'sahara/service/edp/hdfs_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/8277d38419b3a3442ceb52b2aedec4a450fceddc', 'message': 'Changing hdfs fs to hdfs dfs\n\nThe command hdfs fs has been deprecated in favor of hdfs dfs.\n\nStory: #2004952\nTask: #29368\nChange-Id: If8db759ab40ca858594498bc5e6f94f416da2545\n(cherry picked from commit 21791d1f8929af24196150b70db5864836ac8c83)\n'}]",0,636121,8277d38419b3a3442ceb52b2aedec4a450fceddc,7,3,1,10459,,,0,"Changing hdfs fs to hdfs dfs

The command hdfs fs has been deprecated in favor of hdfs dfs.

Story: #2004952
Task: #29368
Change-Id: If8db759ab40ca858594498bc5e6f94f416da2545
(cherry picked from commit 21791d1f8929af24196150b70db5864836ac8c83)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/21/636121/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/hdfs-dfs-94a9c4f64cf8994f.yaml', 'sahara/tests/unit/service/edp/test_hdfs_helper.py', 'sahara/service/edp/hdfs_helper.py']",3,8277d38419b3a3442ceb52b2aedec4a450fceddc,," r.execute_command('sudo su - -c ""hdfs dfs -put -p %s %s"" hdfs'"," r.execute_command('sudo su - -c ""hdfs fs -put -p %s %s"" hdfs'",7,2
openstack%2Fsahara~stable%2Fqueens~I3573523a67d7b77cd2fce8746c334fc5b04f898f,openstack/sahara,stable/queens,I3573523a67d7b77cd2fce8746c334fc5b04f898f,archive-primary.cloudera.com -> archive.cloudera.com,MERGED,2019-02-07 16:06:41.000000000,2019-02-11 18:07:46.000000000,2019-02-11 18:07:46.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-07 16:06:41.000000000', 'files': ['sahara/plugins/cdh/v5_7_0/resources/images/ubuntu/wget_repo', 'sahara/plugins/cdh/v5_9_0/resources/images/ubuntu/wget_repo', 'sahara/plugins/cdh/v5_11_0/resources/images/ubuntu/wget_repo'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0445faa0b66a7084e282b21d9dd93946506d5edc', 'message': 'archive-primary.cloudera.com -> archive.cloudera.com\n\nThe former is no more active.\n\nStory: 2004936\nTask: 29328\nChange-Id: I3573523a67d7b77cd2fce8746c334fc5b04f898f\n(cherry picked from commit 98480c8e740acc830dcde78318ee2169bfc1ec3c)\n'}]",0,635556,0445faa0b66a7084e282b21d9dd93946506d5edc,6,2,1,10459,,,0,"archive-primary.cloudera.com -> archive.cloudera.com

The former is no more active.

Story: 2004936
Task: 29328
Change-Id: I3573523a67d7b77cd2fce8746c334fc5b04f898f
(cherry picked from commit 98480c8e740acc830dcde78318ee2169bfc1ec3c)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/56/635556/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/v5_7_0/resources/images/ubuntu/wget_repo', 'sahara/plugins/cdh/v5_9_0/resources/images/ubuntu/wget_repo', 'sahara/plugins/cdh/v5_11_0/resources/images/ubuntu/wget_repo']",3,0445faa0b66a7084e282b21d9dd93946506d5edc,fix-archive-cloudera, wget -qO - http://archive.cloudera.com/cdh5/ubuntu/xenial/amd64/cdh/archive.key | apt-key add - wget -qO - http://archive.cloudera.com/cm5/ubuntu/xenial/amd64/cm/archive.key | apt-key add -, wget -qO - http://archive-primary.cloudera.com/cdh5/ubuntu/xenial/amd64/cdh/archive.key | apt-key add - wget -qO - http://archive-primary.cloudera.com/cm5/ubuntu/xenial/amd64/cm/archive.key | apt-key add -,6,6
openstack%2Fnova~master~Ia24cda353bdcadf3fe8405aac588e8abf1100608,openstack/nova,master,Ia24cda353bdcadf3fe8405aac588e8abf1100608,api-ref: fix link to flavor extra specs docs,MERGED,2019-02-06 19:48:00.000000000,2019-02-11 17:54:21.000000000,2019-02-07 16:08:58.000000000,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-06 19:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/247caa6d883b9cdd8c380c7b7c9c8172a536707a', 'message': ""api-ref: fix link to flavor extra specs docs\n\nThis fixes the link, re-words it a bit, moves it to the main\ndescription (since it applies to PUT also) and drops the note\nsince we don't need note formatting for linking in reference\nmaterial.\n\nChange-Id: Ia24cda353bdcadf3fe8405aac588e8abf1100608\n""}, {'number': 2, 'created': '2019-02-06 19:49:43.000000000', 'files': ['api-ref/source/os-flavor-extra-specs.inc'], 'web_link': 'https://opendev.org/openstack/nova/commit/46a9d73ad868d09377c739d6f1ed4758f74bb941', 'message': ""api-ref: fix link to flavor extra specs docs\n\nThis fixes the link, re-words it a bit, moves it to the main\ndescription (since it applies to PUT also) and drops the note\nsince we don't need note formatting for linking in reference\nmaterial.\n\nCloses-Bug: #1814953\n\nChange-Id: Ia24cda353bdcadf3fe8405aac588e8abf1100608\n""}]",2,635252,46a9d73ad868d09377c739d6f1ed4758f74bb941,14,7,2,6873,,,0,"api-ref: fix link to flavor extra specs docs

This fixes the link, re-words it a bit, moves it to the main
description (since it applies to PUT also) and drops the note
since we don't need note formatting for linking in reference
material.

Closes-Bug: #1814953

Change-Id: Ia24cda353bdcadf3fe8405aac588e8abf1100608
",git fetch https://review.opendev.org/openstack/nova refs/changes/52/635252/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/os-flavor-extra-specs.inc'],1,247caa6d883b9cdd8c380c7b7c9c8172a536707a,bug/1814953,Refer to `Compute Flavors <https://docs.openstack.org/nova/latest/user/flavors.html#extra-specs>`__ for available built-in extra specs. ,.. note:: Please reference: `Compute Flavors <http://docs.openstack.org/admin-guide/compute-flavors.html#extra-specs>`__ for available built-in extra specs under ``Extra Specs`` section. ,4,5
openstack%2Fnova~master~I99c5cc24c7e9bf5e2e72ffc868990b87b0e8e3f8,openstack/nova,master,I99c5cc24c7e9bf5e2e72ffc868990b87b0e8e3f8,Fix InstanceMapping to always default queued_for_delete=False,MERGED,2019-02-06 15:12:24.000000000,2019-02-11 17:44:30.000000000,2019-02-07 14:17:20.000000000,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 26936}]","[{'number': 1, 'created': '2019-02-06 15:12:24.000000000', 'files': ['nova/objects/instance_mapping.py', 'nova/tests/unit/objects/test_instance_mapping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ccec9ba82de7c9525981a34bb126e9ca98042d04', 'message': 'Fix InstanceMapping to always default queued_for_delete=False\n\nThis object has a default=False setting for queued_for_delete, but never\nactually sets that value. All newly created records should have a non-NULL\nvalue for this field, and we have a migration to fix them, so this\nchange explicitly forces that =False, unless the object is being created\nwith a value set.\n\nCloses-Bug: #1814913\nChange-Id: I99c5cc24c7e9bf5e2e72ffc868990b87b0e8e3f8\n'}]",4,635185,ccec9ba82de7c9525981a34bb126e9ca98042d04,34,12,1,4393,,,0,"Fix InstanceMapping to always default queued_for_delete=False

This object has a default=False setting for queued_for_delete, but never
actually sets that value. All newly created records should have a non-NULL
value for this field, and we have a migration to fix them, so this
change explicitly forces that =False, unless the object is being created
with a value set.

Closes-Bug: #1814913
Change-Id: I99c5cc24c7e9bf5e2e72ffc868990b87b0e8e3f8
",git fetch https://review.opendev.org/openstack/nova refs/changes/85/635185/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/instance_mapping.py', 'nova/tests/unit/objects/test_instance_mapping.py']",2,ccec9ba82de7c9525981a34bb126e9ca98042d04,bug/1814913," 'queued_for_delete': False, 'queued_for_delete': False, @mock.patch.object(instance_mapping.InstanceMapping, '_create_in_db') def test_create_cell_mapping_with_qfd_true(self, create_in_db): db_mapping = get_db_mapping(cell_mapping=None, cell_id=None) create_in_db.return_value = db_mapping mapping_obj = objects.InstanceMapping(self.context) mapping_obj.instance_uuid = db_mapping['instance_uuid'] mapping_obj.cell_mapping = None mapping_obj.project_id = db_mapping['project_id'] mapping_obj.queued_for_delete = True mapping_obj.create() create_in_db.assert_called_once_with(self.context, {'instance_uuid': db_mapping['instance_uuid'], 'queued_for_delete': True, 'project_id': db_mapping['project_id']}) ",,23,0
openstack%2Fswift~master~Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec,openstack/swift,master,Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec,Rebuild frags for unmounted disks,MERGED,2019-01-07 22:07:49.000000000,2019-02-11 17:25:17.000000000,2019-02-09 04:13:48.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-07 22:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/a5a60663aea6e5f52c7a7b7284176b23235ea4f8', 'message': 'wip: rebuild frags for unmounted disks\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n'}, {'number': 2, 'created': '2019-01-09 23:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/379ca19049ad0a3a0d34b0c7ae32c45b964deb4e', 'message': 'wip: rebuild frags for unmounted disks\n\nTODO:\n * how many nodes should primaries check (config?)\n * will we ever want to disable rebuilds to handoffs (config?)\n * can we move to a 12 disk saio config\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n'}, {'number': 3, 'created': '2019-01-14 23:10:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/10dac65c971d740f6b55b7a3ce27ad564e2fd28e', 'message': 'NEED HELP: Rebuild frags for unmounted disks\n\nTODO:\n * how many nodes should primaries check (config?)\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n'}, {'number': 4, 'created': '2019-01-29 18:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ea259ce097c74873a5a291fea3c6e4790bbef7ff', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote node a node_index so that it knows it is the\nprimary responsibility holder for that fragment index.  We use different\nhandoffs for each fragment index to prevent multiple unmounted primary\ndisks from forcing a single handoff node to hold more than one rebuilt\nfragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}, {'number': 5, 'created': '2019-02-04 21:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e414a8428604f9e3917b906a089d84bc80d8e17c', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote handoff node the correct backend_index for the\nfragments it will recieve.  In the common case we will use\ndetermistically different handoffs for each fragment index to prevent\nmultiple unmounted primary disks from forcing a single handoff node to\nhold more than one rebuilt fragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}, {'number': 6, 'created': '2019-02-04 23:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d07b48dc66597462ac716526f57e2c4636feacb6', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote handoff node the correct backend_index for the\nfragments it will recieve.  In the common case we will use\ndetermistically different handoffs for each fragment index to prevent\nmultiple unmounted primary disks from forcing a single handoff node to\nhold more than one rebuilt fragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}, {'number': 7, 'created': '2019-02-07 15:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7d569444f79a416b163d92e7874725e03f643816', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote handoff node the correct backend_index for the\nfragments it will recieve.  In the common case we will use\ndetermistically different handoffs for each fragment index to prevent\nmultiple unmounted primary disks from forcing a single handoff node to\nhold more than one rebuilt fragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}, {'number': 8, 'created': '2019-02-07 21:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/7ce86f05a957723afd6ac310068bf25316692b92', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote handoff node the correct backend_index for the\nfragments it will recieve.  In the common case we will use\ndetermistically different handoffs for each fragment index to prevent\nmultiple unmounted primary disks from forcing a single handoff node to\nhold more than one rebuilt fragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}, {'number': 9, 'created': '2019-02-08 18:05:20.000000000', 'files': ['test/probe/test_reconstructor_rebuild.py', 'swift/obj/reconstructor.py', 'test/unit/__init__.py', 'test/unit/common/ring/test_ring.py', 'swift/common/ring/ring.py', 'etc/object-server.conf-sample', 'test/unit/obj/test_reconstructor.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/ea8e545a27f06868323ff91c1584d18ab9ac6cda', 'message': ""Rebuild frags for unmounted disks\n\nChange the behavior of the EC reconstructor to perform a fragment\nrebuild to a handoff node when a primary peer responds with 507 to the\nREPLICATE request.\n\nEach primary node in a EC ring will sync with exactly three primary\npeers, in addition to the left & right nodes we now select a third node\nfrom the far side of the ring.  If any of these partners respond\nunmounted the reconstructor will rebuild it's fragments to a handoff\nnode with the appropriate index.\n\nTo prevent ssync (which is uninterruptible) receiving a 409 (Conflict)\nwe must give the remote handoff node the correct backend_index for the\nfragments it will recieve.  In the common case we will use\ndetermistically different handoffs for each fragment index to prevent\nmultiple unmounted primary disks from forcing a single handoff node to\nhold more than one rebuilt fragment.\n\nHandoff nodes will continue to attempt to revert rebuilt handoff\nfragments to the appropriate primary until it is remounted or\nrebalanced.  After a rebalance of EC rings (potentially removing\nunmounted/failed devices), it's most IO efficient to run in\nhandoffs_only mode to avoid unnecessary rebuilds.\n\nCloses-Bug: #1510342\n\nChange-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec\n""}]",44,629056,ea8e545a27f06868323ff91c1584d18ab9ac6cda,34,3,9,1179,,,0,"Rebuild frags for unmounted disks

Change the behavior of the EC reconstructor to perform a fragment
rebuild to a handoff node when a primary peer responds with 507 to the
REPLICATE request.

Each primary node in a EC ring will sync with exactly three primary
peers, in addition to the left & right nodes we now select a third node
from the far side of the ring.  If any of these partners respond
unmounted the reconstructor will rebuild it's fragments to a handoff
node with the appropriate index.

To prevent ssync (which is uninterruptible) receiving a 409 (Conflict)
we must give the remote handoff node the correct backend_index for the
fragments it will recieve.  In the common case we will use
determistically different handoffs for each fragment index to prevent
multiple unmounted primary disks from forcing a single handoff node to
hold more than one rebuilt fragment.

Handoff nodes will continue to attempt to revert rebuilt handoff
fragments to the appropriate primary until it is remounted or
rebalanced.  After a rebalance of EC rings (potentially removing
unmounted/failed devices), it's most IO efficient to run in
handoffs_only mode to avoid unnecessary rebuilds.

Closes-Bug: #1510342

Change-Id: Ief44ed39d97f65e4270bf73051da9a2dd0ddbaec
",git fetch https://review.opendev.org/openstack/swift refs/changes/56/629056/5 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/reconstructor.py', 'swift/obj/ssync_sender.py', 'test/unit/obj/test_reconstructor.py']",3,a5a60663aea6e5f52c7a7b7284176b23235ea4f8,bug/1510342," with mocked_http_conn(*[507] * 9): possible_errors = [404, Timeout(), Exception('kaboom!')] def test_process_job_sync_partner_unmounted(self): partition = 0 part_nodes = self.policy.object_ring.get_part_nodes(partition) frag_index = [n['id'] for n in part_nodes].index(self.local_dev['id']) stub_hashes = { '123': {frag_index: 'hash', None: 'hash'}, 'abc': {frag_index: 'hash', None: 'hash'}, } sync_to = object_reconstructor._get_partners(frag_index, part_nodes) self.assertEqual(2, len(sync_to)) part_path = os.path.join(self.devices, self.local_dev['device'], diskfile.get_data_dir(self.policy), str(partition)) job = { 'job_type': object_reconstructor.SYNC, 'frag_index': frag_index, 'suffixes': stub_hashes.keys(), 'sync_to': sync_to, 'partition': partition, 'path': part_path, 'hashes': stub_hashes, 'policy': self.policy, 'device': self.local_dev['device'], 'local_dev': self.local_dev, } codes = [ 200, # hashes left partner 200, # hashes post-sync 507, # unmounted right partner 200, # hashes handoff 200, # hashes post-sync ] ssync_calls = [] replicate_resp = pickle.dumps(stub_hashes) with mock_ssync_sender(ssync_calls), \ mock.patch('swift.obj.diskfile.ECDiskFileManager._get_hashes', return_value=(None, stub_hashes)), \ mocked_http_conn(*codes, body=replicate_resp) as request_log: self.reconstructor.process_job(job) # increment frag_index since we're rebuilding to our right frag_index = (frag_index + 1) % self.policy.ec_n_unique_fragments handoffs = self.policy.object_ring.get_more_nodes(partition) for i, handoff in enumerate(handoffs): if i == frag_index: break else: self.fail('Unable to find handoff?!') self.assertEqual([ (200, sync_to[0]['ip']), (200, sync_to[0]['ip']), (507, sync_to[1]['ip']), (200, handoff['ip']), (200, handoff['ip']), ], [(c, r['ip']) for c, r in zip(codes, request_log.requests)]) self.assertEqual([ sync_to[0]['ip'], handoff['ip'], ], [c['node']['ip'] for c in ssync_calls]) node['remote_index'] = node['index']"," with mocked_http_conn(*[507] * 8): possible_errors = [404, 507, Timeout(), Exception('kaboom!')]",127,42
openstack%2Fnova~stable%2Frocky~I6e871311a0fa10beaf601ca6912b4a33ba4094e0,openstack/nova,stable/rocky,I6e871311a0fa10beaf601ca6912b4a33ba4094e0,PCI: do not force remove allocated devices,MERGED,2019-02-05 23:29:36.000000000,2019-02-11 17:17:21.000000000,2019-02-11 17:17:20.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-05 23:29:36.000000000', 'files': ['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/9f9f372f33310ba6d57067fb0200aaa3e8d02978', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved from the [DEFAULT] section of the nova.conf\nto the [pci] section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmistypes the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regardless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n(cherry picked from commit 26c41eccade6412f61f9a8721d853b545061adcc)\n'}]",0,635071,9f9f372f33310ba6d57067fb0200aaa3e8d02978,24,8,1,11604,,,0,"PCI: do not force remove allocated devices

In the ocata release the pci_passthrough_whitelist
was moved from the [DEFAULT] section of the nova.conf
to the [pci] section and renamed to passthrough_whitelist.

On upgrading if the operator chooses to migrate the config
value to the new section it is not uncommon
to forget to rename the config value.
Similarly if an operator is updateing the whitelist and
mistypes the value it can also lead to the whitelist
being ignored.

As a result of either error the nova compute agent
would delete all database entries for a host regardless of
if the pci device was in use by an instance. If this occurs
the only recorse for an operator is to delete and recreate
the guest on that host after correcting the error or manually
restore the database to backup or otherwise consistent state.

This change alters the _set_hvdevs function to not force
remove allocated or claimed devices if they are no longer
present in the pci whitelist.

Closes-Bug: #1633120
Change-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0
(cherry picked from commit 26c41eccade6412f61f9a8721d853b545061adcc)
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/635071/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py']",2,9f9f372f33310ba6d57067fb0200aaa3e8d02978,bug/1633120," def test_set_hvdev_remove_tree_maintained_with_allocations(self): # Make sure the device tree is properly maintained when there are # devices removed from the system that are allocated to vms. all_devs = fake_db_devs_tree[:] self._create_tracker(all_devs) # we start with 3 devices self.assertEqual( 3, len([dev for dev in self.tracker.pci_devs if dev.status != fields.PciDeviceStatus.REMOVED])) # we then allocate one device pci_requests_obj = self._create_pci_requests_object( [{'count': 1, 'spec': [{'vendor_id': 'v2'}]}]) # NOTE(sean-k-mooney): context, pci request, numa topology claimed_dev = self.tracker.claim_instance( mock.sentinel.context, pci_requests_obj, None)[0] self.tracker._set_hvdevs(all_devs) # and assert that no devices were removed self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) # we then try to remove the allocated device from the set reported # by the driver. fake_pci_devs = [dev for dev in all_devs if dev['address'] != claimed_dev.address] with mock.patch(""nova.pci.manager.LOG.warning"") as log: self.tracker._set_hvdevs(fake_pci_devs) log.assert_called_once() args = log.call_args_list[0][0] # args of first call self.assertIn('Unable to remove device with', args[0]) # and assert no devices are removed from the tracker self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) # free the device that was allocated and update tracker again self.tracker._free_device(claimed_dev) self.tracker._set_hvdevs(fake_pci_devs) # and assert that one device is removed from the tracker self.assertEqual( 1, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) ",,77,5
openstack%2Fnova~master~I9d8175c78f068cf9bdad4aeba0941f6ff49a9acc,openstack/nova,master,I9d8175c78f068cf9bdad4aeba0941f6ff49a9acc,Ignore some PendingDeprecationWarnings for os-vif,MERGED,2019-02-05 13:01:57.000000000,2019-02-11 17:14:56.000000000,2019-02-06 16:05:32.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 25733}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-05 13:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/594cc40c2ae88da36e6cc69f79e7781a32b60d4a', 'message': 'Ignore some PendingDeprecationWarnings for os-vif\n\nos-vif got bumped to 1.14.0 in https://review.openstack.org/572082 and\nNova is touching the VIFPortProfileOVSRepresentor class in a supported\nfashion until at least Train.\n\nHowever, that commit contributes to triggering bug 1813147 in check and\ngate. The warning is safe to silence and should be converted to an error\nin Train (once the older path is removed).\n\nChange-Id: I9d8175c78f068cf9bdad4aeba0941f6ff49a9acc\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nRelated-Bug: #1813147\nblueprint: generic-os-vif-offloads\n'}, {'number': 2, 'created': '2019-02-06 07:55:32.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/cd1823195fac3d18aa58a45c819e6e97151b0f23', 'message': 'Ignore some PendingDeprecationWarnings for os-vif\n\nos-vif got bumped to 1.14.0 in https://review.openstack.org/572082 and\nNova is touching the VIFPortProfileOVSRepresentor class in a supported\nfashion until at least Train.\n\nHowever, that commit contributes to triggering bug 1813147 in check and\ngate. The warning is safe to silence and should be converted to an error\nin Train (once the older path is removed).\n\nChange-Id: I9d8175c78f068cf9bdad4aeba0941f6ff49a9acc\nSigned-off-by: Jan Gutter <jan.gutter@netronome.com>\nRelated-Bug: #1813147\nblueprint: generic-os-vif-offloads\n'}]",2,634928,cd1823195fac3d18aa58a45c819e6e97151b0f23,19,8,2,25733,,,0,"Ignore some PendingDeprecationWarnings for os-vif

os-vif got bumped to 1.14.0 in https://review.openstack.org/572082 and
Nova is touching the VIFPortProfileOVSRepresentor class in a supported
fashion until at least Train.

However, that commit contributes to triggering bug 1813147 in check and
gate. The warning is safe to silence and should be converted to an error
in Train (once the older path is removed).

Change-Id: I9d8175c78f068cf9bdad4aeba0941f6ff49a9acc
Signed-off-by: Jan Gutter <jan.gutter@netronome.com>
Related-Bug: #1813147
blueprint: generic-os-vif-offloads
",git fetch https://review.opendev.org/openstack/nova refs/changes/28/634928/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,594cc40c2ae88da36e6cc69f79e7781a32b60d4a,bug/1813147," # TODO(jangutter): Change (or remove) this to an error during the Train # cycle when the os-vif port profile is no longer used. warnings.filterwarnings( 'ignore', message="".* \'VIFPortProfileOVSRepresentor\' .* "" ""is deprecated"", category=PendingDeprecationWarning) ",,6,0
openstack%2Fopenstack-ansible~master~I0b2796024c334afb97537fe455f14d1f98f5cfaf,openstack/openstack-ansible,master,I0b2796024c334afb97537fe455f14d1f98f5cfaf,Correct python venv build target,ABANDONED,2019-02-10 02:40:56.000000000,2019-02-11 17:09:24.000000000,,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 02:40:56.000000000', 'files': ['inventory/group_vars/all/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8e89714d608b42ea84cbc6bfbe7719c2745c681c', 'message': 'Correct python venv build target\n\nCurrently python venv build targets run within the first repo server\nwhen > 0 repo servers are found or localhost however this is sub-optimal\nespecially in environments with mixed architectures and operating systems.\nThis change sets the python venv build to a repo server target node of the\nsame os family when one is available otherwise the build process is performed\non the target host, instead of falling back to localhost, which in many cases\nis a bastion server.\n\nTwo options were added to group_vars/all.yml, an internal variable for repo\nserver classitifaction and the built-in `venv_build_host` option which\nsets the build target accordingly.\n\nChange-Id: I0b2796024c334afb97537fe455f14d1f98f5cfaf\nSigned-off-by: Kevin Carter <kevin@cloudnull.com>\n'}]",2,636036,8e89714d608b42ea84cbc6bfbe7719c2745c681c,7,3,1,7353,,,0,"Correct python venv build target

Currently python venv build targets run within the first repo server
when > 0 repo servers are found or localhost however this is sub-optimal
especially in environments with mixed architectures and operating systems.
This change sets the python venv build to a repo server target node of the
same os family when one is available otherwise the build process is performed
on the target host, instead of falling back to localhost, which in many cases
is a bastion server.

Two options were added to group_vars/all.yml, an internal variable for repo
server classitifaction and the built-in `venv_build_host` option which
sets the build target accordingly.

Change-Id: I0b2796024c334afb97537fe455f14d1f98f5cfaf
Signed-off-by: Kevin Carter <kevin@cloudnull.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/36/636036/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/all.yml'],1,8e89714d608b42ea84cbc6bfbe7719c2745c681c,,"_venv_build_targets: |- {% set targets = {(ansible_os_family | string): inventory_hostname} %} {% if (groups['repo_all'] | default([]) | length) > 0 %} {% for item in groups['repo_all'] %} {% set _ = targets.__setitem__(hostvars[item]['ansible_os_family'], item) %} {% endfor %} {% endif %} {{ targets }} venv_build_host: ""{{ _venv_build_targets[ansible_os_family] }}""",,9,0
openstack%2Fopenstack-ansible-os_cinder~master~I9de3a3566df913487b0cbf971c4006e9e52feaac,openstack/openstack-ansible-os_cinder,master,I9de3a3566df913487b0cbf971c4006e9e52feaac,Ensure cinder-volumes tool packages install correct ceph dependancies,MERGED,2019-02-11 11:24:48.000000000,2019-02-11 16:27:25.000000000,2019-02-11 16:27:25.000000000,"[{'_account_id': 6816}, {'_account_id': 13095}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 11:24:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/09d8cd894d747d788b37987fb73864a079ac7ecf', 'message': 'Ensure cinder-volumes tool packages install correct ceph dependancies\n\nThe cinder-volumes service requires a set of tools installed from\ndistro packages, which have dependacies on librados and librbd. This\npatch moves the installation of these tools to after the point that\nthe ceph_client role has run. This ensures that the ceph repo config\nis correct and in the case of ubuntu any necessary apt pins have\nbeen installed. This prevents issues where packages in the distro\nrepo may have sematically higher version numbers that the ceph\nrepo and then require a package downgrade - this leads to an install\nfailure.\n\nChange-Id: I9de3a3566df913487b0cbf971c4006e9e52feaac\n'}, {'number': 2, 'created': '2019-02-11 12:06:42.000000000', 'files': ['tasks/main.yml', 'vars/redhat-7.yml', 'vars/ubuntu.yml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/2e08d866e41bb20c2beb1bda65f26921d23138a4', 'message': 'Ensure cinder-volumes tool packages install correct ceph dependancies\n\nThe cinder-volumes service requires a set of tools installed from\ndistro packages, which have dependancies on librados and librbd. This\npatch moves the installation of these tools to after the point that\nthe ceph_client role has run. This ensures that the ceph repo config\nis correct and in the case of ubuntu any necessary apt pins have\nbeen installed. This prevents issues where packages in the distro\nrepo may have sematically higher version numbers that the ceph\nrepo and then require a package downgrade - this leads to an install\nfailure.\n\nChange-Id: I9de3a3566df913487b0cbf971c4006e9e52feaac\n'}]",0,636115,2e08d866e41bb20c2beb1bda65f26921d23138a4,8,3,2,25023,,,0,"Ensure cinder-volumes tool packages install correct ceph dependancies

The cinder-volumes service requires a set of tools installed from
distro packages, which have dependancies on librados and librbd. This
patch moves the installation of these tools to after the point that
the ceph_client role has run. This ensures that the ceph repo config
is correct and in the case of ubuntu any necessary apt pins have
been installed. This prevents issues where packages in the distro
repo may have sematically higher version numbers that the ceph
repo and then require a package downgrade - this leads to an install
failure.

Change-Id: I9de3a3566df913487b0cbf971c4006e9e52feaac
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/15/636115/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'vars/redhat-7.yml', 'vars/ubuntu.yml', 'vars/suse.yml']",4,09d8cd894d747d788b37987fb73864a079ac7ecf,,cinder_volume_distro_packages: [] cinder_volume_distro_packages_tools:,cinder_volume_distro_packages:,25,3
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ia77f1a82c4164f53fa90a6f05ba728787622285d,openstack/tripleo-heat-templates,stable/rocky,Ia77f1a82c4164f53fa90a6f05ba728787622285d,Fix generation of configs that contain password files,MERGED,2019-02-08 22:46:52.000000000,2019-02-11 16:22:27.000000000,2019-02-11 16:22:27.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 22:46:52.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8b4fd25faa4241aaca658f5243509795e8a8353', 'message': ""Fix generation of configs that contain password files\n\nIn I8fe9a640ba36288a1f9cb18563b363159d4731c0 we added the ability\nto prevent overwriting password files during docker-puppet runs, to\ngive the service the ability to update his own user credentials.\n\nThis doesn't work in case a stack update is running and config files\ndon't exist on the host in the first place (e.g. because of a\nprevious deploy failure, or due to a controller node replacement).\nThis also causes complications if a password file is already present\nduring a stack creation (e.g re-creating a stack on a split-stack\nenvironment).\n\nChange the way password files are handled:\n\n  . if a previous password file exists on the host, do not overwrite\n    it with the new password. Only use the new password for\n    computing the hash.\n\n  . otherwise, always copy the newly generated password file on the\n    host.\n\nAlso, fix the config hash generation that currently considers the\npassword file twice, which makes the hash vary and cause\nunexpected service restart at each stack update.\n\nChange-Id: Ia77f1a82c4164f53fa90a6f05ba728787622285d\nCloses-bug: #1809145\n(cherry picked from commit ec5fbe8de78ad37ec8ed4f6642be0e545da7fcf9)\n""}]",0,635975,c8b4fd25faa4241aaca658f5243509795e8a8353,7,4,1,20778,,,0,"Fix generation of configs that contain password files

In I8fe9a640ba36288a1f9cb18563b363159d4731c0 we added the ability
to prevent overwriting password files during docker-puppet runs, to
give the service the ability to update his own user credentials.

This doesn't work in case a stack update is running and config files
don't exist on the host in the first place (e.g. because of a
previous deploy failure, or due to a controller node replacement).
This also causes complications if a password file is already present
during a stack creation (e.g re-creating a stack on a split-stack
environment).

Change the way password files are handled:

  . if a previous password file exists on the host, do not overwrite
    it with the new password. Only use the new password for
    computing the hash.

  . otherwise, always copy the newly generated password file on the
    host.

Also, fix the config hash generation that currently considers the
password file twice, which makes the hash vary and cause
unexpected service restart at each stack update.

Change-Id: Ia77f1a82c4164f53fa90a6f05ba728787622285d
Closes-bug: #1809145
(cherry picked from commit ec5fbe8de78ad37ec8ed4f6642be0e545da7fcf9)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/75/635975/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,c8b4fd25faa4241aaca658f5243509795e8a8353,bug/1809145," # password file in docker-puppet if the file already existed # before and let the service regenerate it instead. password_files=""/root/.my.cnf"" if [ -f ""$p"" -a -f ""/var/lib/config-data/${NAME}$p"" ]; then exclude_files+="" --exclude=$p"" fi excluded_original_passwords="""" excluded_original_passwords+="" --exclude=/var/lib/config-data/*${p}"" EXCLUDE=--exclude='*/etc/swift/backups/*'\ --exclude='*/etc/swift/*.ring.gz'\ --exclude='*/etc/swift/*.builder'\ --exclude='*/etc/libvirt/passwd.db'\ ${excluded_original_passwords}"," # password file in docker-puppet and let the service # regenerate it instead. action=$(hiera -c /etc/puppet/hiera.yaml stack_action) if [ ""x$action"" = ""xUPDATE"" ];then password_files=""/root/.my.cnf"" else password_files="""" fi exclude_files+="" --exclude=$p"" EXCLUDE=--exclude='*/etc/swift/backups/*'\ --exclude='*/etc/swift/*.ring.gz'\ --exclude='*/etc/swift/*.builder'\ --exclude='*/etc/libvirt/passwd.db'",10,10
openstack%2Fpuppet-tripleo~stable%2Frocky~I8fe9a640ba36288a1f9cb18563b363159d4731c0,openstack/puppet-tripleo,stable/rocky,I8fe9a640ba36288a1f9cb18563b363159d4731c0,mysql: fix root password update for containerized mysql,MERGED,2019-02-08 16:57:47.000000000,2019-02-11 16:22:26.000000000,2019-02-11 16:22:26.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 16:57:47.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ed2c3d22968901cb8d4a577613243e0450a15ff9', 'message': 'mysql: fix root password update for containerized mysql\n\nSince the mysql service has been containerized, we lost the ability\nto update the root password during a stack update.\n\nWhen the mysql root password in hiera differs from the one currently\nset in the mysql DB, connect to the DB with password from .my.cnf and\nupdate credentials of the root user before the puppet mysql module\ntries to access the database. Also update other root DB users.\n\nChange-Id: I8fe9a640ba36288a1f9cb18563b363159d4731c0\nDepends-On: I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea\nCloses-Bug: #1792416\n(cherry picked from commit 467c6879d62b27225e3cb57a237491cd3505d92b)\n'}]",0,635886,ed2c3d22968901cb8d4a577613243e0450a15ff9,9,5,1,20778,,,0,"mysql: fix root password update for containerized mysql

Since the mysql service has been containerized, we lost the ability
to update the root password during a stack update.

When the mysql root password in hiera differs from the one currently
set in the mysql DB, connect to the DB with password from .my.cnf and
update credentials of the root user before the puppet mysql module
tries to access the database. Also update other root DB users.

Change-Id: I8fe9a640ba36288a1f9cb18563b363159d4731c0
Depends-On: I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea
Closes-Bug: #1792416
(cherry picked from commit 467c6879d62b27225e3cb57a237491cd3505d92b)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/86/635886/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,ed2c3d22968901cb8d4a577613243e0450a15ff9,bug/1792416," # If the root password is to be updated: # . hiera contains the new password # . .my.cnf still contains the current root credentials # so changing the root password can only happen before # .my.cnf is re-generated by puppet mysql_user { 'root@localhost': ensure => present, password_hash => mysql_password($mysql_root_password), } Mysql_user['root@localhost'] -> File['/root/.my.cnf'] # make sure to update all root users in the mysql DB mysql_user { 'root@%': ensure => present, password_hash => mysql_password($mysql_root_password), } File['/root/.my.cnf'] -> Mysql_user<|title!='root@localhost'|>", File['/root/.my.cnf'] -> Mysql_user<||>,18,1
openstack%2Fsahara-plugin-ambari~master~I67ae47d35db35ac9e4987df1393782987fef33fa,openstack/sahara-plugin-ambari,master,I67ae47d35db35ac9e4987df1393782987fef33fa,Fix image generation for ambari plugin on Ubuntu,MERGED,2019-02-07 16:14:55.000000000,2019-02-11 16:22:09.000000000,2019-02-11 16:22:09.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 23078}, {'_account_id': 29051}]","[{'number': 1, 'created': '2019-02-07 16:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-plugin-ambari/commit/bf45d199c039e4df813dd0061445e73a3db0b16a', 'message': 'Fix image generation for ambari plugin on Ubuntu\n\nSeveral things (missing packages, ...) to fix mainly on the image\nmanifest. Details on the story page.\n\nStory: #2004551\nTask: #28307\nChange-Id: I67ae47d35db35ac9e4987df1393782987fef33fa\n'}, {'number': 2, 'created': '2019-02-11 11:19:47.000000000', 'files': ['sahara_plugin_ambari/plugins/ambari/resources/images/ubuntu/setup_java_home', 'releasenotes/notes/fix-ambari-ubuntu-7915be74bdeaf730.yaml', 'sahara_plugin_ambari/plugins/ambari/resources/images/image.yaml', 'sahara_plugin_ambari/plugins/ambari/resources/images/ubuntu/wget_repo'], 'web_link': 'https://opendev.org/openstack/sahara-plugin-ambari/commit/76c0588e26fdc0d2f4347a83bd03b293d5c2e158', 'message': 'Fix image generation for ambari plugin on Ubuntu\n\nSeveral things (missing packages, ...) to fix mainly on the image\nmanifest. Details on the story page.\n\nStory: #2004551\nTask: #28307\nChange-Id: I67ae47d35db35ac9e4987df1393782987fef33fa\n'}]",0,635558,76c0588e26fdc0d2f4347a83bd03b293d5c2e158,11,5,2,10459,,,0,"Fix image generation for ambari plugin on Ubuntu

Several things (missing packages, ...) to fix mainly on the image
manifest. Details on the story page.

Story: #2004551
Task: #28307
Change-Id: I67ae47d35db35ac9e4987df1393782987fef33fa
",git fetch https://review.opendev.org/openstack/sahara-plugin-ambari refs/changes/58/635558/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_plugin_ambari/plugins/ambari/resources/images/ubuntu/setup_java_home', 'sahara_plugin_ambari/plugins/ambari/resources/images/image.yaml', 'sahara_plugin_ambari/plugins/ambari/resources/images/ubuntu/wget_repo']",3,bf45d199c039e4df813dd0061445e73a3db0b16a,image_ambari_ubuntu, wget http://public-repo-1.hortonworks.com/ambari/ubuntu14/2.x/updates/$ambari_version/ambari.list -O /etc/apt/sources.list.d/ambari.list && \ apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD && \ apt-get update, wget http://public-repo-1.hortonworks.com/ambari/ubuntu12/2.x/updates/$ambari_version/ambari.list -O /etc/apt/sources.list.d/ambari.list apt-key adv --recv-keys --keyserver keyserver.ubuntu.com B9733A7A07513CAD,70,7
openstack%2Fcinder~master~I1d97e9756996b33e8d00760fc32d8777d9486e0e,openstack/cinder,master,I1d97e9756996b33e8d00760fc32d8777d9486e0e,Fix some miscapitalizations of VMware,MERGED,2019-02-07 19:28:23.000000000,2019-02-11 16:20:45.000000000,2019-02-11 12:50:54.000000000,"[{'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 20722}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}, {'_account_id': 29637}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-02-07 19:28:23.000000000', 'files': ['doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/vmware/volumeops.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2a00fffc6d16038842f54652d6d3154b7cfc7260', 'message': 'Fix some miscapitalizations of VMware\n\nChange-Id: I1d97e9756996b33e8d00760fc32d8777d9486e0e\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,635609,2a00fffc6d16038842f54652d6d3154b7cfc7260,71,36,1,11904,,,0,"Fix some miscapitalizations of VMware

Change-Id: I1d97e9756996b33e8d00760fc32d8777d9486e0e
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/cinder refs/changes/09/635609/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/support-matrix.ini', 'cinder/volume/drivers/vmware/volumeops.py']",2,2a00fffc6d16038842f54652d6d3154b7cfc7260,vmWARE," # VMware API needs the capacity unit to be in KB, so convert the"," # VMWare API needs the capacity unit to be in KB, so convert the",2,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea,openstack/tripleo-heat-templates,stable/rocky,I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea,mysql: do not overwrite password file during docker-puppet,MERGED,2019-02-08 16:27:25.000000000,2019-02-11 16:20:33.000000000,2019-02-11 16:20:33.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 16:27:25.000000000', 'files': ['docker/services/database/mysql.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9a59f1b0a23441d3e71671455b3fbef4d70f4ec4', 'message': ""mysql: do not overwrite password file during docker-puppet\n\nDuring a stack update, when docker-puppet regenerates configs files for the\nmysql service, the root mysql passwords may change. Mysql has to update its\ninternal state (e.g. password in mysql DB) to reflect the change, but this\nonly happens when paunch restarts mysql; and the old password it required\nto until the change is applied.\n\nFor such services, update the config hash to notify paunch that a restart is\nneeded, but do not update the password file in docker-puppet and let the\nservice's containers regenerate it instead.\n\nChange-Id: I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea\nPartial-Bug: #1792416\n(cherry picked from commit 8e67ec833173920ac60b5548a711885a4d28e16f)\n""}]",0,635883,9a59f1b0a23441d3e71671455b3fbef4d70f4ec4,8,4,1,20778,,,0,"mysql: do not overwrite password file during docker-puppet

During a stack update, when docker-puppet regenerates configs files for the
mysql service, the root mysql passwords may change. Mysql has to update its
internal state (e.g. password in mysql DB) to reflect the change, but this
only happens when paunch restarts mysql; and the old password it required
to until the change is applied.

For such services, update the config hash to notify paunch that a restart is
needed, but do not update the password file in docker-puppet and let the
service's containers regenerate it instead.

Change-Id: I5bdbc89897a6dcd5bd57f2132e2acf99702b28ea
Partial-Bug: #1792416
(cherry picked from commit 8e67ec833173920ac60b5548a711885a4d28e16f)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/83/635883/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/database/mysql.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/docker-puppet.py']",3,9a59f1b0a23441d3e71671455b3fbef4d70f4ec4,bug/1792416," # On stack update, if a password was changed in a config file, # some services (e.g. mysql) must change their internal state # (e.g. password in mysql DB) when paunch restarts them; and # they need the old password to achieve that. # For those services, we update the config hash to notify # paunch that a restart is needed, but we do not update the # password file in docker-puppet and let the service # regenerate it instead. action=$(hiera -c /etc/puppet/hiera.yaml stack_action) if [ ""x$action"" = ""xUPDATE"" ];then password_files=""/root/.my.cnf"" else password_files="""" fi exclude_files="""" for p in $password_files; do exclude_files+="" --exclude=$p"" done rsync -a -R --delay-updates --delete-after $exclude_files $rsync_srcs /var/lib/config-data/${NAME} rsync -a -R -0 --delay-updates --delete-after $exclude_files \ # note: while being excluded from the output, password files # are still included in checksum computation additional_checksum_files="""" for p in $password_files; do if [ -f ""$p"" ]; then additional_checksum_files+="" $p"" fi done tar -c --mtime='1970-01-01' $EXCLUDE -f - /var/lib/config-data/${NAME} $additional_checksum_files | tar xO | \ tar -c --mtime='1970-01-01' $EXCLUDE -f - /var/lib/config-data/puppet-generated/${NAME} $additional_checksum_files --mtime='1970-01-01' | tar xO \", rsync -a -R --delay-updates --delete-after $rsync_srcs /var/lib/config-data/${NAME} rsync -a -R -0 --delay-updates --delete-after \ tar -c --mtime='1970-01-01' $EXCLUDE -f - /var/lib/config-data/${NAME} | tar xO | \ tar -c --mtime='1970-01-01' $EXCLUDE -f - /var/lib/config-data/puppet-generated/${NAME} --mtime='1970-01-01' | tar xO \,33,5
openstack%2Fpuppet-pacemaker~master~I39d2895bc6c8221c4d30dc7da553be372cbf0e76,openstack/puppet-pacemaker,master,I39d2895bc6c8221c4d30dc7da553be372cbf0e76,Add fence-redfish support,MERGED,2019-01-08 09:41:56.000000000,2019-02-11 16:03:00.000000000,2019-02-11 16:03:00.000000000,"[{'_account_id': 3153}, {'_account_id': 8297}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-08 09:41:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/a0d7afd5ed783a400694fbfd147dfd7cb6d7b9ad', 'message': 'WIP Add fence-redfish support\n\nInitial redfish support\nNB: Note that the manifest has been generated with skipping the\ndeprecated args\n\nChange-Id: I39d2895bc6c8221c4d30dc7da553be372cbf0e76\n'}, {'number': 2, 'created': '2019-02-08 11:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/92f1a56dcfcd504dbe84eae1eb6dc880ccebfb37', 'message': 'Add fence-redfish support\n\nWith the release of fence-agents-4.2.1-11.el7_6.7 (BZ1666848) we\nnow have a fence_redfish agent. We can now add support for it\nso it can be used when configuring fencing.\n\nAdded by adding the following to agent_generator/variables.sh:\n   ""fence_redfish:fence-agents-redfish""\n\nAnd by running:\nfence_redfish -o metadata > agent_generator/src_xml/fence_redfish.xml\nrake generate_stonith\n\nChange-Id: I39d2895bc6c8221c4d30dc7da553be372cbf0e76\n'}, {'number': 3, 'created': '2019-02-11 10:13:35.000000000', 'files': ['manifests/stonith/fence_redfish.pp', 'agent_generator/src_xml/fence_redfish.xml', 'agent_generator/variables.sh'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/bc7b4728961c6b1f083b6e0bd05980129a6e0d98', 'message': 'Add fence-redfish support\n\nWith the release of fence-agents-4.2.1-11.el7_6.7 (BZ1666848) we\nnow have a fence_redfish agent. We can now add support for it\nso it can be used when configuring fencing.\n\nAdded by adding the following to agent_generator/variables.sh:\n   ""fence_redfish:fence-agents-redfish""\n\nAnd by running:\nfence_redfish -o metadata > agent_generator/src_xml/fence_redfish.xml\nand then filtering out the deprecated parameters in order to avoid lint\nerrors on parameters containing a \'-\' in the name. Then:\nrake generate_stonith\n\nChange-Id: I39d2895bc6c8221c4d30dc7da553be372cbf0e76\n'}]",0,629117,bc7b4728961c6b1f083b6e0bd05980129a6e0d98,14,5,3,20172,,,0,"Add fence-redfish support

With the release of fence-agents-4.2.1-11.el7_6.7 (BZ1666848) we
now have a fence_redfish agent. We can now add support for it
so it can be used when configuring fencing.

Added by adding the following to agent_generator/variables.sh:
   ""fence_redfish:fence-agents-redfish""

And by running:
fence_redfish -o metadata > agent_generator/src_xml/fence_redfish.xml
and then filtering out the deprecated parameters in order to avoid lint
errors on parameters containing a '-' in the name. Then:
rake generate_stonith

Change-Id: I39d2895bc6c8221c4d30dc7da553be372cbf0e76
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/17/629117/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/stonith/fence_redfish.pp', 'agent_generator/src_xml/fence_redfish.xml', 'agent_generator/variables.sh']",3,a0d7afd5ed783a400694fbfd147dfd7cb6d7b9ad,redfish," ""fence_redfish:fence-agents-redfish""",,486,0
openstack%2Fironic-tempest-plugin~master~I2905db2aad56eb615bfe9d529e0f448b1967611c,openstack/ironic-tempest-plugin,master,I2905db2aad56eb615bfe9d529e0f448b1967611c,Rename zuulv3 jobs,MERGED,2019-01-09 14:07:41.000000000,2019-02-11 15:56:37.000000000,2019-02-11 15:56:37.000000000,"[{'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-01-09 14:07:41.000000000', 'files': ['zuul.d/stable-jobs.yaml', 'zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/ee7491f5370a3ef77c6884463592d6d08fd64ebf', 'message': 'Rename zuulv3 jobs\n\nAccording to [1] the dsvm should be removed from zuulv3 jobs\n[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3\n\nDepends-On: https://review.openstack.org/#/c/629173/\nChange-Id: I2905db2aad56eb615bfe9d529e0f448b1967611c\n'}]",0,629494,ee7491f5370a3ef77c6884463592d6d08fd64ebf,12,7,1,15519,,,0,"Rename zuulv3 jobs

According to [1] the dsvm should be removed from zuulv3 jobs
[1] https://docs.openstack.org/infra/manual/drivers.html#naming-with-zuul-v3

Depends-On: https://review.openstack.org/#/c/629173/
Change-Id: I2905db2aad56eb615bfe9d529e0f448b1967611c
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/94/629494/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/stable-jobs.yaml', 'zuul.d/project.yaml']",2,ee7491f5370a3ef77c6884463592d6d08fd64ebf,zuulv3, - ironic-standalone - ironic-tempest-functional-python3 - ironic-inspector-tempest - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode - ironic-standalone - ironic-tempest-functional-python3 - ironic-inspector-tempest - ironic-tempest-ipa-wholedisk-direct-tinyipa-multinode, - ironic-dsvm-standalone - ironic-tempest-dsvm-functional-python3 - ironic-tempest-dsvm-ironic-inspector - ironic-tempest-dsvm-ipa-wholedisk-direct-tinyipa-multinode - ironic-dsvm-standalone - ironic-tempest-dsvm-functional-python3 - ironic-tempest-dsvm-ironic-inspector - ironic-tempest-dsvm-ipa-wholedisk-agent_ipmitool-tinyipa-multinode,18,18
openstack%2Fironic~master~I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18,openstack/ironic,master,I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18,Online Data Migration for boot_interface,NEW,2019-01-16 10:03:33.000000000,2019-02-11 15:50:42.000000000,,"[{'_account_id': 10118}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 14826}, {'_account_id': 15519}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 25547}, {'_account_id': 26340}, {'_account_id': 28429}, {'_account_id': 29209}]","[{'number': 1, 'created': '2019-01-16 10:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5d5cd3678037a85113713754b788ae560be7d274', 'message': 'Online Data Migration for boot_interface\n\nSince Ironic is separating the pxe and ipxe implementations\ninto separate boot interfaces, simplify the migration using\nonline data migration to change the boot_interface to ipxe\nif ipxe_enabled is true.\n\nChange-Id: I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18\nStory: #2004787\nTask: #28933\n'}, {'number': 2, 'created': '2019-01-16 10:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8216eae7cfb902530c84502e1729bbb48cc65b13', 'message': 'Online Data Migration for boot_interface\n\nSince Ironic is separating the pxe and ipxe implementations\ninto separate boot interfaces, simplify the migration using\nonline data migration to change the boot_interface to ipxe\nif ipxe_enabled is true.\n\nChange-Id: I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18\nStory: #2004787\nTask: #28933\n'}, {'number': 3, 'created': '2019-01-16 13:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5a08e49d693db7452de2e10ec7dd62a53d3b55b4', 'message': 'Online Data Migration for boot_interface\n\nSince Ironic is separating the pxe and ipxe implementations\ninto separate boot interfaces, simplify the migration using\nonline data migration to change the boot_interface to ipxe\nif ``[pxe]ipxe_enabled`` is True.\n\nChange-Id: I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18\nStory: #2004787\nTask: #28933\n'}, {'number': 4, 'created': '2019-01-16 15:49:43.000000000', 'files': ['ironic/db/sqlalchemy/api.py', 'releasenotes/notes/update_boot_interface_to_ipxe-7f3f9490c2c14e05.yaml', 'ironic/cmd/dbsync.py', 'ironic/tests/unit/db/test_api.py', 'ironic/db/api.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f3ab494c0ab297b2476203241d9f524b024d0819', 'message': 'Online Data Migration for boot_interface\n\nSince Ironic is separating the pxe and ipxe implementations\ninto separate boot interfaces, simplify the migration using\nonline data migration to change the boot_interface to ipxe\nif ``[pxe]ipxe_enabled`` is True.\n\nChange-Id: I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18\nStory: #2004787\nTask: #28933\n'}]",25,631178,f3ab494c0ab297b2476203241d9f524b024d0819,40,13,4,15519,,,0,"Online Data Migration for boot_interface

Since Ironic is separating the pxe and ipxe implementations
into separate boot interfaces, simplify the migration using
online data migration to change the boot_interface to ipxe
if ``[pxe]ipxe_enabled`` is True.

Change-Id: I2b2c8ef3a71b79830a201577d8f7bfd5eb29bd18
Story: #2004787
Task: #28933
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/631178/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/db/sqlalchemy/api.py', 'releasenotes/notes/update_boot_interface_to_ipxe-6c5031d77e359a21.yaml', 'ironic/cmd/dbsync.py', 'ironic/tests/unit/db/test_api.py', 'ironic/db/api.py']",5,5d5cd3678037a85113713754b788ae560be7d274,odm_boot_interface," def update_boot_interface_to_ipxe(self, context, max_count): """"""Updates the `boot_interface` to `ipxe` if `pxe/ipxe_enabled` is True. This scans the `nodes` table and will change `boot_interface` from `pxe` to `ipxe` when the `pxe/ipxe_enabled` is True in the configuration. :param context: the admin context :param max_count: The maximum number of objects to migrate. Must be >= 0. If zero, all the objects will be migrated. :returns: A 2-tuple, 1. the total number of objects that need to be migrated (at the beginning of this call) and 2. the number of migrated objects. """""" # TODO(iurygregory): remove in Train cycle. @abc.abstractmethod",,130,0
openstack%2Fansible-role-systemd_networkd~master~Iaea33b1bdde1964f38612ab8c278fed4985d390b,openstack/ansible-role-systemd_networkd,master,Iaea33b1bdde1964f38612ab8c278fed4985d390b,Add ipforward option to configure IPForward,MERGED,2019-02-08 20:50:27.000000000,2019-02-11 15:49:43.000000000,2019-02-11 15:49:43.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 16011}, {'_account_id': 22348}, {'_account_id': 27379}, {'_account_id': 28665}]","[{'number': 1, 'created': '2019-02-08 20:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/cce2b0db8ffad5275a8d2e9ca2ceb6c7db701b60', 'message': 'Add ipforward option to configure IPForward\n\nAdd ipforward bool optional setting to systemd_networks to enable\nor disable forwarding for a given interface.  IPForward is disabled\nby default.\n\nChange-Id: Iaea33b1bdde1964f38612ab8c278fed4985d390b\n'}, {'number': 2, 'created': '2019-02-11 15:13:05.000000000', 'files': ['tasks/main.yml', 'templates/systemd-network.j2', 'tests/test.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/242b3c3fb4a3f8ebeba5c24cf8c7a510cba14143', 'message': 'Add ipforward option to configure IPForward\n\nAdd ipforward bool optional setting to systemd_networks to enable\nor disable forwarding for a given interface.  IPForward is disabled\nby default.\n\nChange-Id: Iaea33b1bdde1964f38612ab8c278fed4985d390b\n'}]",2,635929,242b3c3fb4a3f8ebeba5c24cf8c7a510cba14143,12,6,2,28665,,,0,"Add ipforward option to configure IPForward

Add ipforward bool optional setting to systemd_networks to enable
or disable forwarding for a given interface.  IPForward is disabled
by default.

Change-Id: Iaea33b1bdde1964f38612ab8c278fed4985d390b
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_networkd refs/changes/29/635929/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/systemd-network.j2', 'tests/test.yml']",2,cce2b0db8ffad5275a8d2e9ca2ceb6c7db701b60,forwarding," - NetDev: Name: br-test2 Kind: bridge - interface: ""br-test2"" address: 10.2.0.1 netmask: ""255.255.255.0"" ipforward: true - name: Check forwarding is enabled shell: 'grep -wo ^1$ /proc/sys/net/ipv4/conf/br-test2/forwarding' changed_when: false",,13,0
openstack%2Fblazar~master~I2a1b12b737e434f2816bfc1bbc9ee30e4686286c,openstack/blazar,master,I2a1b12b737e434f2816bfc1bbc9ee30e4686286c,Improve traceback for lease status change errors,ABANDONED,2019-02-05 18:18:22.000000000,2019-02-11 15:49:06.000000000,,"[{'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-05 18:18:22.000000000', 'files': ['blazar/status.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/c75a4cb1b7242ac3dde31f22c3e33f1cbb7149c8', 'message': 'Improve traceback for lease status change errors\n\nIn case of errors when changing the status of a lease, the traceback logged\nusing `raise e` starts from the exception handler in the wrapper function,\nwhich is not very helpful. Instead, using just `raise` keeps the initial\ntraceback from where the exception originated.\n\nChange-Id: I2a1b12b737e434f2816bfc1bbc9ee30e4686286c\n'}]",0,635004,c75a4cb1b7242ac3dde31f22c3e33f1cbb7149c8,5,2,1,15197,,,0,"Improve traceback for lease status change errors

In case of errors when changing the status of a lease, the traceback logged
using `raise e` starts from the exception handler in the wrapper function,
which is not very helpful. Instead, using just `raise` keeps the initial
traceback from where the exception originated.

Change-Id: I2a1b12b737e434f2816bfc1bbc9ee30e4686286c
",git fetch https://review.opendev.org/openstack/blazar refs/changes/04/635004/1 && git format-patch -1 --stdout FETCH_HEAD,['blazar/status.py'],1,c75a4cb1b7242ac3dde31f22c3e33f1cbb7149c8,keep-traceback, raise, raise e,1,1
openstack%2Ftripleo-heat-templates~stable%2Frocky~If503e733b103a34ae5639eb56dfae05f9783d59a,openstack/tripleo-heat-templates,stable/rocky,If503e733b103a34ae5639eb56dfae05f9783d59a,Include the DB password in a Mistral environment for creating backups and restores,MERGED,2019-02-05 16:33:06.000000000,2019-02-11 15:47:55.000000000,2019-02-11 15:47:55.000000000,"[{'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 8042}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-05 16:33:06.000000000', 'files': ['extraconfig/post_deploy/undercloud_post.yaml', 'extraconfig/post_deploy/undercloud_post.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/30892a6fc773416686f6b8b0c08bd8166fa3561e', 'message': ""Include the DB password in a Mistral environment for creating backups and restores\n\nWe need to include also the Undercloud DB in a Mistral\nenvironment to be able to create the DB backup from the CLI.\n\nNow, we do this using python and THT but we didn't include it.\n\nChange-Id: If503e733b103a34ae5639eb56dfae05f9783d59a\n(cherry picked from commit 166803d05fe05899c8613c96f627cda4f2a2aa26)\nCloses-Bug: 1812839\n""}]",0,634973,30892a6fc773416686f6b8b0c08bd8166fa3561e,9,7,1,20775,,,0,"Include the DB password in a Mistral environment for creating backups and restores

We need to include also the Undercloud DB in a Mistral
environment to be able to create the DB backup from the CLI.

Now, we do this using python and THT but we didn't include it.

Change-Id: If503e733b103a34ae5639eb56dfae05f9783d59a
(cherry picked from commit 166803d05fe05899c8613c96f627cda4f2a2aa26)
Closes-Bug: 1812839
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/73/634973/1 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/post_deploy/undercloud_post.yaml', 'extraconfig/post_deploy/undercloud_post.sh']",2,30892a6fc773416686f6b8b0c08bd8166fa3561e,bug/1812839," # Store the SNMP and MySQL password in a mistral environment echo ""{\""name\"": \""tripleo.undercloud-config\"", \""variables\"": {\""undercloud_ceilometer_snmpd_password\"": \""$snmp_readonly_user_password\"", \""undercloud_db_password\"": \""$undercloud_db_password\""}}"" > $TMP_MISTRAL_ENV"," # Store the SNMP password in a mistral environment echo ""{\""name\"": \""tripleo.undercloud-config\"", \""variables\"": {\""undercloud_ceilometer_snmpd_password\"": \""$snmp_readonly_user_password\""}}"" > $TMP_MISTRAL_ENV",8,2
openstack%2Fironic-tempest-plugin~master~Ib202880e7039113a58dc1596de54be4167c5307d,openstack/ironic-tempest-plugin,master,Ib202880e7039113a58dc1596de54be4167c5307d,Enable tempest run -l without credential setting,MERGED,2019-02-04 08:17:45.000000000,2019-02-11 15:42:49.000000000,2019-02-11 15:42:49.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 08:17:45.000000000', 'files': ['ironic_tempest_plugin/services/introspection_client.py'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/51266a5ed2b06754a4f92ba585fcff9cf16b0bdc', 'message': ""Enable tempest run -l without credential setting\n\nThis commit moves the admin credential code to the initialization phase\nof Manager class. This change enables to run `tempest run -l` without\ncredential settings. We shouldn't require like that settings to just\nlist tests.\n\nChange-Id: Ib202880e7039113a58dc1596de54be4167c5307d\n""}]",0,634641,51266a5ed2b06754a4f92ba585fcff9cf16b0bdc,8,3,1,5689,,,0,"Enable tempest run -l without credential setting

This commit moves the admin credential code to the initialization phase
of Manager class. This change enables to run `tempest run -l` without
credential settings. We shouldn't require like that settings to just
list tests.

Change-Id: Ib202880e7039113a58dc1596de54be4167c5307d
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/41/634641/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/services/introspection_client.py'],1,51266a5ed2b06754a4f92ba585fcff9cf16b0bdc,tempest-sanity-gate," credentials=None, api_microversions=None): if not credentials: credentials = common_creds.get_configured_admin_credentials()","ADMIN_CREDS = common_creds.get_configured_admin_credentials() credentials=ADMIN_CREDS, api_microversions=None):",3,2
openstack%2Ftripleo-docs~master~I116fd249b4330ac9992428a1c77409a7376a1d73,openstack/tripleo-docs,master,I116fd249b4330ac9992428a1c77409a7376a1d73,Update NodeDataLookup examples to use JSON instead of strings,MERGED,2019-02-06 16:22:45.000000000,2019-02-11 15:41:07.000000000,2019-02-11 15:41:07.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 25402}]","[{'number': 1, 'created': '2019-02-06 16:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/46750525db581c543b427f47c54e0489b181d1ff', 'message': 'Update NodeDataLookup examples to use JSON instead of strings\n\nThe changes introduced to resolve bug 1814070 assume NodeDataLookup\nto be a real JSON object instead of a string. This updates our\nexamples in the docs.\n\nChange-Id: I116fd249b4330ac9992428a1c77409a7376a1d73\n'}, {'number': 2, 'created': '2019-02-06 17:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/923b339ad13117bd809eb94ce15a9dd4df342f26', 'message': 'Update NodeDataLookup examples to use JSON instead of strings\n\nThe changes introduced to resolve bug 1814070 assume NodeDataLookup\nto be a real JSON object instead of a string. This updates our\nexamples in the docs.\n\nChange-Id: I116fd249b4330ac9992428a1c77409a7376a1d73\n'}, {'number': 3, 'created': '2019-02-06 17:09:39.000000000', 'files': ['doc/source/install/advanced_deployment/node_specific_hieradata.rst', 'doc/source/install/advanced_deployment/ceph_config.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e070db531fdc65118e1ce3af6d7043e1a3f94c69', 'message': 'Update NodeDataLookup examples to use JSON instead of strings\n\nThe changes introduced to resolve bug 1814070 assume NodeDataLookup\nto be a real JSON object instead of a string. This updates our\nexamples in the docs.\n\nChange-Id: I116fd249b4330ac9992428a1c77409a7376a1d73\n'}]",2,635206,e070db531fdc65118e1ce3af6d7043e1a3f94c69,12,6,3,6796,,,0,"Update NodeDataLookup examples to use JSON instead of strings

The changes introduced to resolve bug 1814070 assume NodeDataLookup
to be a real JSON object instead of a string. This updates our
examples in the docs.

Change-Id: I116fd249b4330ac9992428a1c77409a7376a1d73
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/06/635206/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/advanced_deployment/node_specific_hieradata.rst', 'doc/source/install/advanced_deployment/ceph_config.rst']",2,46750525db581c543b427f47c54e0489b181d1ff,bug/1814070, NodeDataLookup:, NodeDataLookup: |,3,3
openstack%2Fsushy-tools~master~I3a0c2645f689c84ba474f8777bb23f07fc81746c,openstack/sushy-tools,master,I3a0c2645f689c84ba474f8777bb23f07fc81746c,Update tests for libvirt driver,ABANDONED,2018-08-06 06:42:52.000000000,2019-02-11 15:40:05.000000000,,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 26340}]","[{'number': 1, 'created': '2018-08-06 06:42:52.000000000', 'files': ['sushy_tools/tests/unit/emulator/test_libvirt.py'], 'web_link': 'https://opendev.org/openstack/sushy-tools/commit/9fdb9e49bf3d62c7461e3eb17be2555131098c2f', 'message': 'Update tests for libvirt driver\n\n* Flask API calls was removed from libvirt driver tests. Module\n  contains only tests for specific calls which relates to libvirt\n  driver.\n\n* Add missing tests for boot mode functions.\n\nChange-Id: I3a0c2645f689c84ba474f8777bb23f07fc81746c\nStory: 1751134\nTask: 12046\n'}]",0,589025,9fdb9e49bf3d62c7461e3eb17be2555131098c2f,3,3,1,10155,,,0,"Update tests for libvirt driver

* Flask API calls was removed from libvirt driver tests. Module
  contains only tests for specific calls which relates to libvirt
  driver.

* Add missing tests for boot mode functions.

Change-Id: I3a0c2645f689c84ba474f8777bb23f07fc81746c
Story: 1751134
Task: 12046
",git fetch https://review.opendev.org/openstack/sushy-tools refs/changes/25/589025/1 && git format-patch -1 --stdout FETCH_HEAD,['sushy_tools/tests/unit/emulator/test_libvirt.py'],1,9fdb9e49bf3d62c7461e3eb17be2555131098c2f,,"import xml.etree.ElementTree as ET@mock.patch('libvirt.openReadOnly') @mock.patch('libvirt.open') class LibvirtDriverTestCase(base.BaseTestCase): super(LibvirtDriverTestCase, self).setUp() def test_systems(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value conn_mock.listDefinedDomains.return_value = [] self.assertEqual(conn_mock.listDefinedDomains.return_value, self.test_driver.systems) def test_uuid(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.UUIDString.return_value = 'xxx-yyy-zzz' self.assertEqual('xxx-yyy-zzz', self.test_driver.uuid('zzz-yyy-xxx')) def test_get_power_state_on(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value self.assertEqual('On', self.test_driver.get_power_state('xxx-yyy-zzz')) def test_get_power_state_off(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.return_value = False self.assertEqual('Off', self.test_driver.get_power_state('xxx-yyy-zzz')) def test_set_power_state_forceon(self, libvirt_mock, libvirt_mock_readonly): domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.return_value = False self.test_driver.set_power_state('xxx-yyy-zzz', 'ForceOn') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') domain_mock.create.assert_called_once_with() def test_set_power_state_forceoff(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock.return_value domain_mock = conn_mock.lookupByName.return_value self.test_driver.set_power_state('xxx-yyy-zzz', 'ForceOff') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') def test_set_power_state_gracefulshutdown(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock.return_value domain_mock = conn_mock.lookupByName.return_value self.test_driver.set_power_state('xxx-yyy-zzz', 'GracefulShutdown') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') def test_set_power_state_gracefulrestart(self, libvirt_mock, libvirt_mock_readonly): domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.return_value = True self.test_driver.set_power_state('xxx-yyy-zzz', 'GracefulRestart') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') def test_set_power_state_forcerestart(self, libvirt_mock, libvirt_mock_readonly): domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.return_value = True self.test_driver.set_power_state('xxx-yyy-zzz', 'ForceRestart') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') def test_set_power_state_nmi(self, libvirt_mock, libvirt_mock_readonly): domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.return_value = True self.test_driver.set_power_state('xxx-yyy-zzz', 'Nmi') conn_mock.lookupByName.assert_called_once_with('xxx-yyy-zzz') def test_set_power_state_exception(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.isActive.side_effect = libvirt.libvirtError( 'because I can') self.assertRaises(FishyError, self.test_driver.set_power_state, 'xxx-yyy-zzz', 'Nmi') def test_get_boot_device(self, libvirt_mock, libvirt_mock_readonly): with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: data = f.read() conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.XMLDesc.return_value = data domain_mock.isActive.return_value = True boot_device = self.test_driver.get_boot_device('xxx-yyy-zzz') self.assertEqual('Cd', boot_device) def test_set_boot_device(self, libvirt_mock, libvirt_mock_readonly): with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: data = f.read() tree = ET.fromstring(data) upd_data = ET.tostring(tree).decode('utf-8') data_string = ''.join(upd_data.split()) conn_mock = libvirt_mock.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.XMLDesc.return_value = data domain_mock.isActive.return_value = True self.test_driver.set_boot_device('xxx-yyy-zzz', 'Cd') mock_args = conn_mock.defineXML.call_args mock_string = ''.join(mock_args[0][0].split()) self.assertEqual(len(data_string), len(mock_string)) def test_set_boot_device_exception(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock.return_value conn_mock.defineXML.side_effect = libvirt.libvirtError( 'because I can') domain_mock = conn_mock.lookupByName.return_value with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: domain_mock.XMLDesc.return_value = f.read() self.assertRaises(FishyError, self.test_driver.set_boot_device, 'xxx-yyy-zzz', 'Nmi') def test_get_total_memory(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.maxMemory.return_value = 1024 * 1024 result = self.test_driver.get_total_memory('xxx-yyy-zzz') self.assertEqual(1, result) def test_get_total_cpus(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: domain_mock.XMLDesc.return_value = f.read() domain_mock.isActive.return_value = True domain_mock.maxVcpus.return_value = 2 result = self.test_driver.get_total_cpus('xxx-yyy-zzz') self.assertEqual(2, result) def test_get_total_cpus_xml(self, libvirt_mock, libvirt_mock_readonly): conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: domain_mock.XMLDesc.return_value = f.read() domain_mock.isActive.return_value = True domain_mock.maxVcpus.return_value = 0 result = self.test_driver.get_total_cpus('xxx-yyy-zzz') self.assertEqual(2, result) def test_get_total_cpus_xml_mis(self, libvirt_mock, libvirt_mock_readonly): with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: s = f.read() conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.XMLDesc.return_value = s.replace(""<vcpu>2</vcpu>\n"", """") domain_mock.isActive.return_value = True domain_mock.maxVcpus.return_value = 0 result = self.test_driver.get_total_cpus('xxx-yyy-zzz') self.assertEqual(None, result) def test_get_bios(self, libvirt_mock, libvirt_mock_readonly): def test_get_bios_existing(self, libvirt_mock, libvirt_mock_readonly): def test_set_bios(self, libvirt_mock, libvirt_mock_readonly): def test_reset_bios(self, libvirt_mock, libvirt_mock_readonly): def test__process_bios_attributes_get_default(self, libvirt_mock, libvirt_mock_readonly): def test__process_bios_attributes_get_default_metadata_exists( self, libvirt_mock, libvirt_mock_readonly): def test__process_bios_attributes_get_existing(self, libvirt_mock, libvirt_mock_readonly): def test__process_bios_attributes_update(self, libvirt_mock, libvirt_mock_readonly): def test__process_bios_error(self, libvirt_mock, libvirt_mock_readonly): def test_get_boot_mode(self, libvirt_mock, libvirt_mock_readonly): with open('sushy_tools/tests/unit/emulator/domain.xml') as f: domain_xml = f.read() conn_mock = libvirt_mock_readonly.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.XMLDesc.return_value = domain_xml boot_mode = self.test_driver.get_boot_mode('xxx-yyy-zzz') self.assertEqual(""Legacy"", boot_mode) def test_set_boot_mode(self, libvirt_mock, libvirt_mock_readonly): with open('sushy_tools/tests/unit/emulator/domain.xml') as f: data = f.read() tree = ET.fromstring(data) for os_element in tree.findall('os'): for loader_element in os_element.findall('loader'): os_element.remove(loader_element) loader_element = ET.SubElement(os_element, 'loader') loader_element.set('type', 'Uefi') upd_data = ET.tostring(tree).decode('utf-8') data_string = ''.join(upd_data.split()) conn_mock = libvirt_mock.return_value domain_mock = conn_mock.lookupByName.return_value domain_mock.XMLDesc.return_value = data domain_mock.isActive.return_value = True self.test_driver.set_boot_mode('xxx-yyy-zzz', 'Uefi') mock_args = conn_mock.defineXML.call_args mock_string = ''.join(mock_args[0][0].split()) self.assertEqual(len(data_string), len(mock_string) - 2)","from sushy_tools.emulator import main@mock.patch.object(main, 'driver', None) # This enables libvirt driver class EmulatorTestCase(base.BaseTestCase): self.app = main.app.test_client() # This enables libvirt driver main.driver = None super(EmulatorTestCase, self).setUp() def test_root_resource(self): response = self.app.get('/redfish/v1/') self.assertEqual(200, response.status_code) self.assertTrue(response.json) @mock.patch('libvirt.openReadOnly', autospec=True) def test_collection_resource(self, libvirt_mock): conn_mock = libvirt_mock.return_value conn_mock.listDefinedDomains.return_value = ['host0', 'host1'] response = self.app.get('/redfish/v1/Systems') self.assertEqual(200, response.status_code) self.assertEqual({'@odata.id': '/redfish/v1/Systems/host0'}, response.json['Members'][0]) self.assertEqual({'@odata.id': '/redfish/v1/Systems/host1'}, response.json['Members'][1]) @mock.patch('libvirt.openReadOnly', autospec=True) def test_system_resource_get(self, libvirt_mock): with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: data = f.read() domain_mock = mock.Mock() domain_mock.XMLDesc.return_value = data domain_mock.isActive.return_value = True domain_mock.maxMemory.return_value = 1024 * 1024 domain_mock.UUIDString.return_value = 'zzzz-yyyy-xxxx' domain_mock.maxVcpus.return_value = 2 conn_mock = libvirt_mock.return_value conn_mock.lookupByName.return_value = domain_mock response = self.app.get('/redfish/v1/Systems/xxxx-yyyy-zzzz') self.assertEqual(200, response.status_code) self.assertEqual('xxxx-yyyy-zzzz', response.json['Id']) self.assertEqual('zzzz-yyyy-xxxx', response.json['UUID']) self.assertEqual('On', response.json['PowerState']) self.assertEqual( 1, response.json['MemorySummary']['TotalSystemMemoryGiB']) self.assertEqual(2, response.json['ProcessorSummary']['Count']) self.assertEqual( 'Cd', response.json['Boot']['BootSourceOverrideTarget']) self.assertEqual( 'Legacy', response.json['Boot']['BootSourceOverrideMode']) @mock.patch('libvirt.open', autospec=True) def test_system_resource_patch(self, libvirt_mock): with open('sushy_tools/tests/unit/emulator/domain.xml', 'r') as f: data = f.read() domain_mock = mock.Mock() domain_mock.XMLDesc.return_value = data conn_mock = libvirt_mock.return_value conn_mock.lookupByName.return_value = domain_mock conn_mock.defineXML = mock.Mock() data = {'Boot': {'BootSourceOverrideTarget': 'Cd'}} response = self.app.patch('/redfish/v1/Systems/xxxx-yyyy-zzzz', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_on(self, libvirt_mock): domain_mock = mock.Mock() conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'On'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) domain_mock.create.assert_not_called() @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_forceon(self, libvirt_mock): domain_mock = mock.Mock() conn_mock = libvirt_mock.return_value conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'ForceOn'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) domain_mock.create.assert_not_called() @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_forceoff(self, libvirt_mock): domain_mock = mock.Mock() domain_mock.isActive.return_value = True conn_mock = libvirt_mock.return_value conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'ForceOff'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_shutdown(self, libvirt_mock): domain_mock = mock.Mock() conn_mock = libvirt_mock.return_value conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'GracefulShutdown'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_restart(self, libvirt_mock): domain_mock = mock.Mock() domain_mock.isActive.return_value = True conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'GracefulRestart'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_forcerestart(self, libvirt_mock): domain_mock = mock.Mock() domain_mock.isActive.return_value = True conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'ForceRestart'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_system_reset_action_nmi(self, libvirt_mock): domain_mock = mock.Mock() domain_mock.isActive.return_value = True conn_mock.lookupByName.return_value = domain_mock data = {'ResetType': 'Nmi'} response = self.app.post( '/redfish/v1/Systems/xxxx-yyyy-zzzz/Actions/ComputerSystem.Reset', json=data) self.assertEqual(204, response.status_code) @mock.patch('libvirt.open', autospec=True) def test_get_bios(self, libvirt_mock): @mock.patch('libvirt.open', autospec=True) def test_get_bios_existing(self, libvirt_mock): @mock.patch('libvirt.open', autospec=True) def test_set_bios(self, libvirt_mock): @mock.patch('libvirt.open', autospec=True) def test_reset_bios(self, libvirt_mock): def test__process_bios_attributes_get_default(self): def test__process_bios_attributes_get_default_metadata_exists(self): def test__process_bios_attributes_get_existing(self): def test__process_bios_attributes_update(self): @mock.patch('libvirt.open', autospec=True) def test__process_bios_error(self, libvirt_mock):",220,152
openstack%2Fneutron~stable%2Fqueens~I419a451633badbc3d32edcee1945fca3e3d9f6be,openstack/neutron,stable/queens,I419a451633badbc3d32edcee1945fca3e3d9f6be,Ensure dnsmasq is down before enabling it in restart method,MERGED,2019-02-07 09:45:00.000000000,2019-02-11 15:36:10.000000000,2019-02-11 15:36:10.000000000,"[{'_account_id': 1131}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 25618}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-02-07 09:45:00.000000000', 'files': ['neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/757129b49ce01a0c928e5cd6843f70aee19142d7', 'message': 'Ensure dnsmasq is down before enabling it in restart method\n\nDnsmasq driver used by dhcp agent has restart() method which is\ncalling disable() and then enable() dnsmasq process again.\nWhat can be observed in functional tests from time to time it may\nhappen that start dnsmasq process will be called before old process\nis really down. That leads to error that IP address to which\ndnsmasq wants to bind is already in use and it fails to start.\n\nThis patch adds possibility to call disable() method with block flag\nset to True. In such case driver will ensure in disable() method that\nprocess is really not active.\nThis blocking disable() is used in restart() method now.\n\nChange-Id: I419a451633badbc3d32edcee1945fca3e3d9f6be\nCloses-Bug: #1811126\n(cherry picked from commit d471a85931d6f6495efdb8ff43bf903e3e1d639d)\n'}]",0,635466,757129b49ce01a0c928e5cd6843f70aee19142d7,9,5,1,11975,,,0,"Ensure dnsmasq is down before enabling it in restart method

Dnsmasq driver used by dhcp agent has restart() method which is
calling disable() and then enable() dnsmasq process again.
What can be observed in functional tests from time to time it may
happen that start dnsmasq process will be called before old process
is really down. That leads to error that IP address to which
dnsmasq wants to bind is already in use and it fails to start.

This patch adds possibility to call disable() method with block flag
set to True. In such case driver will ensure in disable() method that
process is really not active.
This blocking disable() is used in restart() method now.

Change-Id: I419a451633badbc3d32edcee1945fca3e3d9f6be
Closes-Bug: #1811126
(cherry picked from commit d471a85931d6f6495efdb8ff43bf903e3e1d639d)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/635466/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py']",2,757129b49ce01a0c928e5cd6843f70aee19142d7,bug/1811126-stable/queens," def disable(self, retain_port=False, block=False): self.disable(retain_port=True, block=True) def disable(self, retain_port=False, block=False): pm = self._get_process_manager() pm.disable() if block: common_utils.wait_until_true(lambda: not pm.active)"," def disable(self, retain_port=False): self.disable(retain_port=True) def disable(self, retain_port=False): self._get_process_manager().disable()",10,7
openstack%2Ftripleo-quickstart-extras~master~I99ba2fd6a85b4895b577719a7541b7cbf1fdb85c,openstack/tripleo-quickstart-extras,master,I99ba2fd6a85b4895b577719a7541b7cbf1fdb85c,Skip test not supported by OVN,MERGED,2019-01-31 09:18:24.000000000,2019-02-11 15:26:53.000000000,2019-02-11 15:26:53.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 8367}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 11082}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}, {'_account_id': 26343}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-01-31 09:18:24.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c45688c695373ce9e0530e0c44aeba6e581dc847', 'message': 'Skip test not supported by OVN\n\nWe need skip this test because ovn is not supporting\nthis test case. This skip can be removed after bug\nhttps://bugs.launchpad.net/tempest/+bug/1728886\nwill be fix.\n\nChange-Id: I99ba2fd6a85b4895b577719a7541b7cbf1fdb85c\n'}]",0,634144,c45688c695373ce9e0530e0c44aeba6e581dc847,26,14,1,11082,,,0,"Skip test not supported by OVN

We need skip this test because ovn is not supporting
this test case. This skip can be removed after bug
https://bugs.launchpad.net/tempest/+bug/1728886
will be fix.

Change-Id: I99ba2fd6a85b4895b577719a7541b7cbf1fdb85c
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/44/634144/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_master.yml'],1,c45688c695373ce9e0530e0c44aeba6e581dc847,feature/ovn-testing, - test: 'tempest.scenario.test_network_basic_ops.TestNetworkBasicOps.test_port_security_macspoofing_port' reason: 'It can be removed when bug for OVN is repaired' lp: 'https://bugs.launchpad.net/tempest/+bug/1728886',,3,0
openstack%2Fheat-translator~master~Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a,openstack/heat-translator,master,Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a,Update hacking version,MERGED,2019-01-04 16:53:27.000000000,2019-02-11 15:14:16.000000000,2019-02-11 15:14:16.000000000,"[{'_account_id': 16511}, {'_account_id': 18955}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-04 16:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/ae42ec20d95b6eda1f6087600af78082d6f0ca3b', 'message': 'Update hacking version to latest\n\nChange-Id: Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a\n'}, {'number': 2, 'created': '2019-02-05 03:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/f30f7d7cc9ddce266296c0017eacd1a5270ff0e0', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a\n'}, {'number': 3, 'created': '2019-02-05 03:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/120cea46b59ad6f87e7d7afc436b6350c94713e8', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a\n'}, {'number': 4, 'created': '2019-02-07 01:53:50.000000000', 'files': ['test-requirements.txt', 'translator/hot/translate_node_templates.py', 'translator/common/utils.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/de9d98cfc6f2e575dae718d3cdf8f98738e1dedb', 'message': 'Update hacking version\n\nUse latest release 1.1.0 and compatible changes w.r.t pep8\n\nChange-Id: Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a\n'}]",1,628613,de9d98cfc6f2e575dae718d3cdf8f98738e1dedb,20,5,4,27781,,,0,"Update hacking version

Use latest release 1.1.0 and compatible changes w.r.t pep8

Change-Id: Ib3a7568750ca5bf14b445e3de3aa3b020c6dbb2a
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/13/628613/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ae42ec20d95b6eda1f6087600af78082d6f0ca3b,,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fheat-translator~master~I2b989a49ac3447995a82ddb7193bf478bb847b73,openstack/heat-translator,master,I2b989a49ac3447995a82ddb7193bf478bb847b73,Support reservation policy in heat-translator,MERGED,2018-11-21 07:05:04.000000000,2019-02-11 15:10:39.000000000,2019-02-11 15:10:39.000000000,"[{'_account_id': 1011}, {'_account_id': 6456}, {'_account_id': 16511}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 26222}, {'_account_id': 26463}]","[{'number': 1, 'created': '2018-11-21 07:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/d69fc028c5bc6421a6ff1ca29dbc38a1d1e5b869', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 2, 'created': '2018-12-03 08:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/dc045fd7ca9bc7a6ae995928042be9c68c12ce6b', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 3, 'created': '2018-12-12 07:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/019af2bdc1a3973c4524b8a79646151a2feffcab', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 4, 'created': '2018-12-19 07:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/4ad133c1cf6793292cce23669c6b95db2e4fa7ce', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 5, 'created': '2019-01-09 05:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/19b35b7238a45d612f9ea23fbf4ce57ca2f6951e', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 6, 'created': '2019-01-09 06:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/2f83b41bf3e1acd13479b97f0b96b48ceaf5aa49', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}, {'number': 7, 'created': '2019-01-09 06:29:07.000000000', 'files': ['requirements.txt', 'translator/tests/data/reservation/tosca-vnfd-reservation-id.yaml', 'translator/hot/tosca/tosca_policies_reservation.py', 'translator/tests/data/hot_output/reservation/SP_RSV_res.yaml', 'translator/tests/data/nfv/tacker_defs.yaml', 'translator/tests/data/hot_output/reservation/hot_reservation_scaling.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/hot/translate_node_templates.py', 'lower-constraints.txt', 'translator/hot/tosca/tosca_policies_scaling.py', 'translator/hot/syntax/hot_resource.py'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/30f4d2ff8371bb7a33d2790ca5df77de951965ee', 'message': 'Support reservation policy in heat-translator\n\nImplementation of reservation policy in heat-translator\n\nTacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm\nTacker Spec: https://review.openstack.org/#/c/561840/\nDepends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568\nChange-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73\n'}]",4,619154,30f4d2ff8371bb7a33d2790ca5df77de951965ee,32,7,7,26463,,,0,"Support reservation policy in heat-translator

Implementation of reservation policy in heat-translator

Tacker Blueprint: https://blueprints.launchpad.net/tacker/+spec/reservation-vnfm
Tacker Spec: https://review.openstack.org/#/c/561840/
Depends-On: Ic5d790df938b40d75bc50252e1e688e9c09eb568
Change-Id: I2b989a49ac3447995a82ddb7193bf478bb847b73
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/54/619154/6 && git format-patch -1 --stdout FETCH_HEAD,"['translator/tests/data/reservation/tosca-vnfd-reservation-id.yaml', 'translator/hot/tosca/tosca_policies_reservation.py', 'translator/tests/data/hot_output/reservation/SP_RSV_res.yaml', 'translator/tests/data/nfv/tacker_defs.yaml', 'translator/hot/translate_node_templates.py', 'translator/tests/data/hot_output/reservation/hot_reservation_scaling.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/hot/tosca/tosca_policies_scaling.py', 'translator/hot/syntax/hot_resource.py']",9,d69fc028c5bc6421a6ff1ca29dbc38a1d1e5b869,bp/https," 'tosca.policies.Monitoring', 'tosca.policies.Reservation']", 'tosca.policies.Monitoring'],230,2
openstack%2Ftripleo-repos~master~I4a0807133dcf7c3081f228d1b6b2119e3cd29300,openstack/tripleo-repos,master,I4a0807133dcf7c3081f228d1b6b2119e3cd29300,Allow distro to be auto detected,MERGED,2019-02-07 11:08:06.000000000,2019-02-11 14:59:16.000000000,2019-02-11 14:32:49.000000000,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2019-02-07 11:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/cee5190f57bade7b7c58712118e49c0fefcb720c', 'message': 'Avoid failure to find yum\n\nAvoid possible failure to call yum in some case, likely due to PATH\nnot being set:\n\nOSErrr: [Errno 2] No such file or directory\n\nChange-Id: I4a0807133dcf7c3081f228d1b6b2119e3cd29300\nRelated: https://tree.taiga.io/project/tripleo-ci-board/us/651\n'}, {'number': 2, 'created': '2019-02-07 12:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/4a643f5c420bec86e5517847229134164b3eb979', 'message': 'Allow distro to be auto detected\n\nAvoids the need to add --distro parameter to specify the distro by\nmaking the default be auto detected.\n\nKeeps --distro parameter working as before.\n\nThis allows us to avoid having to mention the parameter when we\ncall the tool.\n\nChange-Id: I4a0807133dcf7c3081f228d1b6b2119e3cd29300\nRelated: https://tree.taiga.io/project/tripleo-ci-board/us/651\n'}, {'number': 3, 'created': '2019-02-07 12:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/102f47d84f924cf329bf9ed96b4b924bb507c78e', 'message': 'Allow distro to be auto detected\n\nAvoids the need to add --distro parameter to specify the distro by\nmaking the default be auto detected.\n\nKeeps --distro parameter working as before.\n\nThis allows us to avoid having to mention the parameter when we\ncall the tool.\n\nAllows `current-tripleo` on fedora.\n\nDisplays extra information if yum call to install priorities fails.\n\nChange-Id: I4a0807133dcf7c3081f228d1b6b2119e3cd29300\nRelated: https://tree.taiga.io/project/tripleo-ci-board/us/651\n'}, {'number': 4, 'created': '2019-02-08 17:21:56.000000000', 'files': ['tripleo_repos/main.py'], 'web_link': 'https://opendev.org/openstack/tripleo-repos/commit/0fdb8ebdb4a8e2364f9dbb74916c995d76f64fac', 'message': 'Allow distro to be auto detected\n\nAvoids the need to add --distro parameter to specify the distro by\nmaking the default be auto detected.\n\nKeeps --distro parameter working as before.\n\nThis allows us to avoid having to mention the parameter when we\ncall the tool.\n\nAllows `current-tripleo` on fedora.\n\nDisplays extra information if yum call to install priorities fails.\n\nChange-Id: I4a0807133dcf7c3081f228d1b6b2119e3cd29300\nRelated: https://tree.taiga.io/project/tripleo-ci-board/us/651\n'}]",9,635475,0fdb8ebdb4a8e2364f9dbb74916c995d76f64fac,27,13,4,24162,,,0,"Allow distro to be auto detected

Avoids the need to add --distro parameter to specify the distro by
making the default be auto detected.

Keeps --distro parameter working as before.

This allows us to avoid having to mention the parameter when we
call the tool.

Allows `current-tripleo` on fedora.

Displays extra information if yum call to install priorities fails.

Change-Id: I4a0807133dcf7c3081f228d1b6b2119e3cd29300
Related: https://tree.taiga.io/project/tripleo-ci-board/us/651
",git fetch https://review.opendev.org/openstack/tripleo-repos refs/changes/75/635475/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_repos/main.py'],1,cee5190f57bade7b7c58712118e49c0fefcb720c,oooq/f28," subprocess.check_call(['/usr/bin/yum', 'install', '-y',"," subprocess.check_call(['yum', 'install', '-y',",1,1
openstack%2Frpm-packaging~stable%2Frocky~I5e71bdc2fc826a352da88410c0704315bf561b3c,openstack/rpm-packaging,stable/rocky,I5e71bdc2fc826a352da88410c0704315bf561b3c,Add telemetry-tempest-plugin,MERGED,2019-02-11 14:28:35.000000000,2019-02-11 14:52:14.000000000,2019-02-11 14:52:14.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-11 14:28:35.000000000', 'files': ['openstack/telemetry-tempest-plugin/telemetry-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/73b188172658a5d677b22444fd906463e808d645', 'message': 'Add telemetry-tempest-plugin\n\n(cherry picked from commit b1e66b287e277833731eacaa934639aa96e875ca)\n\nChange-Id: I5e71bdc2fc826a352da88410c0704315bf561b3c\n'}]",0,636135,73b188172658a5d677b22444fd906463e808d645,10,6,1,7102,,,0,"Add telemetry-tempest-plugin

(cherry picked from commit b1e66b287e277833731eacaa934639aa96e875ca)

Change-Id: I5e71bdc2fc826a352da88410c0704315bf561b3c
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/35/636135/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/telemetry-tempest-plugin/telemetry-tempest-plugin.spec.j2'],1,73b188172658a5d677b22444fd906463e808d645,stable-rocky,"{% set pypi_name = 'telemetry_tempest_plugin' %} {% set source = fetch_source('https://tarballs.openstack.org/telemetry-tempest-plugin/telemetry_tempest_plugin-0.1.0.tar.gz') %} {% set upstream_version = upstream_version() %} {% set rpm_release = '1' %} Name: {{ py2pkg('telemetry-tempest-plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for Telemetry Projects (Aodh, Ceilometer, Gnocchi and Panko) License: {{ license('Apache-2.0') }} Group: Development/Languages/Python URL: https://git.openstack.org/cgit/openstack/telemetry-tempest-plugin Source0: {{ source|basename }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('gabbi') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('oslo.utils') }} Requires: {{ py2pkg('six') }} BuildArch: noarch %python_subpackages %description Tempest plugin for Telemetry Project. It contains tempest tests for Aodh, Ceilometer, Gnocchi and Panko Projects. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{python_build} %install %{python_install} %files %{python_files} %license LICENSE %{python_sitelib}/telemetry_tempest_plugin* %changelog ",,42,0
openstack%2Fopenstack-ansible-nspawn_container_create~master~I5b0ba4e516af2facb145f9f228aa168de75402dd,openstack/openstack-ansible-nspawn_container_create,master,I5b0ba4e516af2facb145f9f228aa168de75402dd,"Fix the misspelling of ""container""",MERGED,2019-01-23 08:29:03.000000000,2019-02-11 14:33:48.000000000,2019-02-11 14:33:48.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-23 08:29:03.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_container_create/commit/ed8a54347d4cb55d5f33186a5243005955960453', 'message': 'Fix the misspelling of ""container""\n\nChange-Id: I5b0ba4e516af2facb145f9f228aa168de75402dd\n'}]",0,632644,ed8a54347d4cb55d5f33186a5243005955960453,11,2,1,29721,,,0,"Fix the misspelling of ""container""

Change-Id: I5b0ba4e516af2facb145f9f228aa168de75402dd
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_container_create refs/changes/44/632644/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,ed8a54347d4cb55d5f33186a5243005955960453,,# container prior to writting the config.,# contianer prior to writting the config.,1,1
openstack%2Frpm-packaging~master~I4748bec4c75d166fe2ce3417ce04cdc0190bfb86,openstack/rpm-packaging,master,I4748bec4c75d166fe2ce3417ce04cdc0190bfb86,Add telemetry-tempest-plugin,MERGED,2019-02-07 12:47:25.000000000,2019-02-11 14:23:18.000000000,2019-02-11 14:23:17.000000000,"[{'_account_id': 7102}, {'_account_id': 8482}, {'_account_id': 13294}, {'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 12:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/eb1700a78d050d1e7a2a968b2946984bc2eca6a0', 'message': 'Add telemetry_tempest_plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}, {'number': 2, 'created': '2019-02-07 13:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/8cad191d511648c4f6b70f5324223815a0f60adb', 'message': 'Add telemetry_tempest_plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}, {'number': 3, 'created': '2019-02-11 13:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/433d894bcb0ef96bd122a4d0798aaf106a970fd5', 'message': 'Add telemetry_tempest_plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}, {'number': 4, 'created': '2019-02-11 13:42:00.000000000', 'files': ['openstack/telemetry-tempest-plugin/telemetry-tempest-plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b1e66b287e277833731eacaa934639aa96e875ca', 'message': 'Add telemetry-tempest-plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}]",2,635499,b1e66b287e277833731eacaa934639aa96e875ca,26,6,4,7102,,,0,"Add telemetry-tempest-plugin

Change-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/99/635499/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack/telemetry_tempest_plugin/telemetry_tempest_plugin.spec.j2'],1,eb1700a78d050d1e7a2a968b2946984bc2eca6a0,635499,"{% set pypi_name = 'telemetry_tempest_plugin' %} {% set upstream_version = upstream_version('0.1.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2pkg('telemetry_tempest_plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for Telemetry Projects (Aodh, Ceilometer, Gnocchi and Panko) License: {{ license('Apache-2.0') }} URL: https://git.openstack.org/cgit/openstack/{{ pypi_name }} Group: Development/Languages/Python Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('gabbi') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('oslo.utils') }} Requires: {{ py2pkg('six') }} BuildArch: noarch %python_subpackages %description Tempest plugin for Telemetry Project. It contains tempest tests for Aodh, Ceilometer, Gnocchi and Panko Projects. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{python_build} %install %{python_install} %files %{python_files} %license LICENSE %{python_sitelib}/telemetry_tempest_plugin* %changelog ",,42,0
openstack%2Fsahara-dashboard~stable%2Fqueens~I007f6cb5528e658fa8a0211a833500385a4aa07a,openstack/sahara-dashboard,stable/queens,I007f6cb5528e658fa8a0211a833500385a4aa07a,Increasing max number fields,MERGED,2019-02-11 11:33:53.000000000,2019-02-11 14:12:38.000000000,2019-02-11 14:12:38.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 11:33:53.000000000', 'files': ['sahara_dashboard/local_settings.d/_12_toggle_data_upload_max_number_fields.py', 'releasenotes/notes/increase-max-fields-91b921991f1e8978.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/57f1b411dacd2e7855d4b0acf59ac1478120a8aa', 'message': 'Increasing max number fields\n\nIncreasing the max number fields to allow CDH node group templates creation\n\nStory: 2004866\nTask: 29110\n\nChange-Id: I007f6cb5528e658fa8a0211a833500385a4aa07a\n(cherry picked from commit f8649ba63aa337a7451c212874570edfa596441a)\n'}]",0,636116,57f1b411dacd2e7855d4b0acf59ac1478120a8aa,6,2,1,10459,,,0,"Increasing max number fields

Increasing the max number fields to allow CDH node group templates creation

Story: 2004866
Task: 29110

Change-Id: I007f6cb5528e658fa8a0211a833500385a4aa07a
(cherry picked from commit f8649ba63aa337a7451c212874570edfa596441a)
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/16/636116/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/local_settings.d/_12_toggle_data_upload_max_number_fields.py', 'releasenotes/notes/increase-max-fields-91b921991f1e8978.yaml']",2,57f1b411dacd2e7855d4b0acf59ac1478120a8aa,,--- fixes: - | Increasing DATA_UPLOAD_MAX_NUMBER_FIELDS django configuration to allow creation of CDH node group templates. ,,6,1
openstack%2Fxstatic-angular-lrdragndrop~master~I2ad9731eba3a04982b108e85d3d98e82e854e05f,openstack/xstatic-angular-lrdragndrop,master,I2ad9731eba3a04982b108e85d3d98e82e854e05f,Fixing README so that PyPI does not reject them,MERGED,2019-02-11 14:03:16.000000000,2019-02-11 14:06:44.000000000,2019-02-11 14:06:43.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 14:03:16.000000000', 'files': ['README.txt'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-lrdragndrop/commit/15b71267555e6234dc2bc45879069f8dfc6f0258', 'message': ""Fixing README so that PyPI does not reject them\n\nA format error in README.txt prevents PyPI from accepting\nnew uploads of xstatic-angular-lrdragndrop. Let's fix that.\n\nChange-Id: I2ad9731eba3a04982b108e85d3d98e82e854e05f\nNeeded-By: https://review.openstack.org/636128\n""}]",0,636131,15b71267555e6234dc2bc45879069f8dfc6f0258,6,2,1,308,,,0,"Fixing README so that PyPI does not reject them

A format error in README.txt prevents PyPI from accepting
new uploads of xstatic-angular-lrdragndrop. Let's fix that.

Change-Id: I2ad9731eba3a04982b108e85d3d98e82e854e05f
Needed-By: https://review.openstack.org/636128
",git fetch https://review.opendev.org/openstack/xstatic-angular-lrdragndrop refs/changes/31/636131/1 && git format-patch -1 --stdout FETCH_HEAD,['README.txt'],1,15b71267555e6234dc2bc45879069f8dfc6f0258,fix-README,---------------------------,-------------------,1,2
openstack%2Fxstatic-jasmine~master~I49f9cf7632b8ece55dfe4e579aee40e658584995,openstack/xstatic-jasmine,master,I49f9cf7632b8ece55dfe4e579aee40e658584995,Fixing README so that PyPI does not reject them,MERGED,2019-02-11 14:01:28.000000000,2019-02-11 14:06:21.000000000,2019-02-11 14:06:21.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 14:01:28.000000000', 'files': ['README.txt'], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/5bd478e4e7463d4ed9a243b8677bcce27ba0f0f0', 'message': ""Fixing README so that PyPI does not reject them\n\nA format error in README.txt prevents PyPI from accepting\nnew uploads of xstatic-jasmine. Let's fix that.\n\nChange-Id: I49f9cf7632b8ece55dfe4e579aee40e658584995\nNeeded-By: https://review.openstack.org/636129\n""}]",0,636130,5bd478e4e7463d4ed9a243b8677bcce27ba0f0f0,6,2,1,308,,,0,"Fixing README so that PyPI does not reject them

A format error in README.txt prevents PyPI from accepting
new uploads of xstatic-jasmine. Let's fix that.

Change-Id: I49f9cf7632b8ece55dfe4e579aee40e658584995
Needed-By: https://review.openstack.org/636129
",git fetch https://review.opendev.org/openstack/xstatic-jasmine refs/changes/30/636130/1 && git format-patch -1 --stdout FETCH_HEAD,['README.txt'],1,5bd478e4e7463d4ed9a243b8677bcce27ba0f0f0,fix-README,---------------,--------------,1,1
openstack%2Fopenstack-ansible-nspawn_container_create~master~I5f2b69e84ecbca1bede3019cb601b5bce69193a6,openstack/openstack-ansible-nspawn_container_create,master,I5f2b69e84ecbca1bede3019cb601b5bce69193a6,Trivial: Fix the pep8 warning,MERGED,2018-11-08 12:02:20.000000000,2019-02-11 13:55:32.000000000,2019-02-11 13:55:32.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-11-08 12:02:20.000000000', 'files': ['tests/ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_container_create/commit/2fa5d8af22707916a791a88c209486179ebdfe3d', 'message': 'Trivial: Fix the pep8 warning\n\nThe yaml should start with ""---""\n\nChange-Id: I5f2b69e84ecbca1bede3019cb601b5bce69193a6\n'}]",0,616527,2fa5d8af22707916a791a88c209486179ebdfe3d,11,3,1,17130,,,0,"Trivial: Fix the pep8 warning

The yaml should start with ""---""

Change-Id: I5f2b69e84ecbca1bede3019cb601b5bce69193a6
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_container_create refs/changes/27/616527/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/ansible-role-requirements.yml'],1,2fa5d8af22707916a791a88c209486179ebdfe3d,pep8,---,,1,0
openstack%2Fproject-config~master~I754d6343172d46432564e9037716df4eccf9d14d,openstack/project-config,master,I754d6343172d46432564e9037716df4eccf9d14d,Remove unused pbrx container publish job,MERGED,2019-02-09 14:08:20.000000000,2019-02-11 13:51:47.000000000,2019-02-11 13:51:47.000000000,"[{'_account_id': 3099}, {'_account_id': 6547}, {'_account_id': 16068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-09 14:08:20.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fd393b3caa066457184b1ff431e1af5c5e36dcb2', 'message': ""Remove unused pbrx container publish job\n\nWe've switched zuul and nodepool to dockerfile based builds. This\nis no longer needed.\n\nChange-Id: I754d6343172d46432564e9037716df4eccf9d14d\n""}]",0,636018,fd393b3caa066457184b1ff431e1af5c5e36dcb2,8,4,1,2,,,0,"Remove unused pbrx container publish job

We've switched zuul and nodepool to dockerfile based builds. This
is no longer needed.

Change-Id: I754d6343172d46432564e9037716df4eccf9d14d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/18/636018/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,fd393b3caa066457184b1ff431e1af5c5e36dcb2,,, - job: name: openstackzuul-pbrx-push-container-images parent: pbrx-build-container-images description: | Publish images built by pbrx to openstackzuul Docker Hub account. A value must be supplied for the pbrx_prefix variable. allowed-projects: - openstack-infra/nodepool - openstack-infra/zuul post-run: playbooks/pbrx-push/post.yaml secrets: - zuulzuul_docker_login,0,13
openstack%2Fnova~master~If752b51faa2677e0f9cf9e8e5fad8742fc4eb33c,openstack/nova,master,If752b51faa2677e0f9cf9e8e5fad8742fc4eb33c,Move resize.(start|end) notification sending to helper method,MERGED,2019-02-04 23:33:10.000000000,2019-02-11 13:49:11.000000000,2019-02-07 21:16:55.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 23:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1214dd99814ef0782bddcbeca2eb3e6234d3b36f', 'message': 'Move resize.(start|end) notification sending to helper method\n\nThis refactors the code that sends the resize.start and resize.end\nnotifications to a helper method.\n\nChange-Id: If752b51faa2677e0f9cf9e8e5fad8742fc4eb33c\n'}, {'number': 2, 'created': '2019-02-05 17:34:02.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d883a1b3d174b9f8af373d254fe880c322df2ad2', 'message': 'Move resize.(start|end) notification sending to helper method\n\nThis refactors the code that sends the resize.start and resize.end\nnotifications to a helper method.\n\nChange-Id: If752b51faa2677e0f9cf9e8e5fad8742fc4eb33c\n'}]",6,634831,d883a1b3d174b9f8af373d254fe880c322df2ad2,29,11,2,6873,,,0,"Move resize.(start|end) notification sending to helper method

This refactors the code that sends the resize.start and resize.end
notifications to a helper method.

Change-Id: If752b51faa2677e0f9cf9e8e5fad8742fc4eb33c
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/634831/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,1214dd99814ef0782bddcbeca2eb3e6234d3b36f,bp/cross-cell-resize," self._send_resize_instance_notifications( context, instance, bdms, network_info, fields.NotificationPhase.START) self._send_resize_instance_notifications( context, instance, bdms, network_info, fields.NotificationPhase.END) def _send_resize_instance_notifications( self, context, instance, bdms, network_info, phase): """"""Send ""resize.(start|end)"" notifications. :param context: nova auth request context :param instance: The instance being resized :param bdms: BlockDeviceMappingList for the BDMs associated with the instance :param network_info: NetworkInfo for the instance info cache of ports :param phase: The phase of the action (NotificationPhase enum, either ``start`` or ``end``) """""" action = fields.NotificationAction.RESIZE # Send the legacy unversioned notification. self._notify_about_instance_usage( context, instance, ""%s.%s"" % (action, phase), network_info=network_info) # Send the versioned notification. compute_utils.notify_about_instance_action( context, instance, self.host, action=action, phase=phase, bdms=bdms) "," self._notify_about_instance_usage( context, instance, ""resize.start"", network_info=network_info) compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.RESIZE, phase=fields.NotificationPhase.START, bdms=bdms) self._notify_about_instance_usage(context, instance, ""resize.end"", network_info=network_info) compute_utils.notify_about_instance_action(context, instance, self.host, action=fields.NotificationAction.RESIZE, phase=fields.NotificationPhase.END, bdms=bdms)",28,13
openstack%2Fnova~master~I08630bbbd1df9b758ff5088f9b48183a503ecc09,openstack/nova,master,I08630bbbd1df9b758ff5088f9b48183a503ecc09,Extract compute API _create_image to compute.utils,MERGED,2018-11-30 22:51:32.000000000,2019-02-11 13:42:01.000000000,2019-02-07 21:17:09.000000000,"[{'_account_id': 4690}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-30 22:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fda8f0042f19dcb37937ecdca0a8bed5e7f6928', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 2, 'created': '2018-12-18 03:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4706c6833d7e1ffcf075923699e5356db7af85f1', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 3, 'created': '2018-12-31 15:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4bc297709d2278c6d96097875eacf058ff60254b', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 4, 'created': '2019-01-16 03:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f52d51db343adb370fc0ff249e8186000f6ce87d', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 5, 'created': '2019-01-17 17:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11fec3ef8ebce415009b46f04c1782239e07af96', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 6, 'created': '2019-01-25 19:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf0cdb95e7c668ca474e5a2c6cc8c09f4319c9d5', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 7, 'created': '2019-01-30 00:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ad183e85b61de8f8e40dcc8bf36b2def3977f4b6', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}, {'number': 8, 'created': '2019-02-05 17:34:02.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/api.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7e229ba40df60b963e0e9450af276c62d4b6bf60', 'message': 'Extract compute API _create_image to compute.utils\n\nThis refactors the _create_image and related\n_initialize_instance_snapshot_metadata methods to\nnova.compute.utils and makes them public utilities\nso that code outside the API can re-use it.\n\nChange-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09\n'}]",0,621311,7e229ba40df60b963e0e9450af276c62d4b6bf60,112,18,8,6873,,,0,"Extract compute API _create_image to compute.utils

This refactors the _create_image and related
_initialize_instance_snapshot_metadata methods to
nova.compute.utils and makes them public utilities
so that code outside the API can re-use it.

Change-Id: I08630bbbd1df9b758ff5088f9b48183a503ecc09
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/621311/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/compute/test_shelve.py', 'nova/compute/api.py', 'nova/compute/utils.py']",4,4fda8f0042f19dcb37937ecdca0a8bed5e7f6928,bp/cross-cell-resize,"def create_image(context, instance, name, image_type, image_api, extra_properties=None): """"""Create new image entry in the image service. This new image will be reserved for the compute manager to upload a snapshot or backup. :param context: security context :param instance: nova.objects.instance.Instance object :param name: string for name of the snapshot :param image_type: snapshot | backup :param image_api: instance of nova.image.API :param extra_properties: dict of extra image properties to include """""" properties = { 'instance_uuid': instance.uuid, 'user_id': str(context.user_id), 'image_type': image_type, } properties.update(extra_properties or {}) image_meta = initialize_instance_snapshot_metadata( instance, name, properties) # if we're making a snapshot, omit the disk and container formats, # since the image may have been converted to another format, and the # original values won't be accurate. The driver will populate these # with the correct values later, on image upload. if image_type == 'snapshot': image_meta.pop('disk_format', None) image_meta.pop('container_format', None) return image_api.create(context, image_meta) def initialize_instance_snapshot_metadata(instance, name, extra_properties=None): """"""Initialize new metadata for a snapshot of the given instance. :param instance: nova.objects.instance.Instance object :param name: string for name of the snapshot :param extra_properties: dict of extra metadata properties to include :returns: the new instance snapshot metadata """""" image_meta = utils.get_image_from_system_metadata( instance.system_metadata) image_meta.update({'name': name, 'is_public': False}) # Delete properties that are non-inheritable properties = image_meta['properties'] for key in CONF.non_inheritable_image_properties: properties.pop(key, None) # The properties in extra_properties have precedence properties.update(extra_properties or {}) return image_meta ",,72,69
openstack%2Fnova~master~Iea1a4c76384d0fda45610f3f1dab99df039236ec,openstack/nova,master,Iea1a4c76384d0fda45610f3f1dab99df039236ec,Isolate cell-targeting code in MigrationTask,MERGED,2018-11-30 22:51:32.000000000,2019-02-11 13:40:26.000000000,2019-02-07 20:30:26.000000000,"[{'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-30 22:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88cede49bb7c6793c019767883caabbbf1becfba', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 2, 'created': '2018-12-18 03:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de4c2580645d9037de642d9f93c9eb5e8d6453c0', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 3, 'created': '2018-12-31 15:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0d9729d8bfb52152cdb6781ecf69fabc8b2217a0', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 4, 'created': '2019-01-16 03:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/76d3d6bf816cec12280aa1b5641065848524d5d6', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 5, 'created': '2019-01-17 17:10:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc740cebd7e48f6c23894426e39a7030bf25ae0c', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 6, 'created': '2019-01-25 19:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fe14e9b31a7fb4b30cccde7fb69a84726b169593', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 7, 'created': '2019-01-30 00:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f3a3a275ae653c9651c84a59d1c344c12df63865', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}, {'number': 8, 'created': '2019-02-05 17:34:02.000000000', 'files': ['nova/conductor/tasks/migrate.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/512397423092b2260b1a914bfcd4a54ba14f343c', 'message': 'Isolate cell-targeting code in MigrationTask\n\nThis is a simple refactor to isolate the code that\nrestricts the RequestSpec during a cold migration\nto only select hosts from within the cell in which\nthe instance is already running.\n\nChange-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec\n'}]",1,621310,512397423092b2260b1a914bfcd4a54ba14f343c,112,17,8,6873,,,0,"Isolate cell-targeting code in MigrationTask

This is a simple refactor to isolate the code that
restricts the RequestSpec during a cold migration
to only select hosts from within the cell in which
the instance is already running.

Change-Id: Iea1a4c76384d0fda45610f3f1dab99df039236ec
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/621310/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/conductor/tasks/migrate.py'],1,88cede49bb7c6793c019767883caabbbf1becfba,bp/cross-cell-resize," def _restrict_request_spec_to_cell(self, legacy_props): def _execute(self): # TODO(sbauza): Remove that once prep_resize() accepts a RequestSpec # object in the signature and all the scheduler.utils methods too legacy_spec = self.request_spec.to_legacy_request_spec_dict() legacy_props = self.request_spec.to_legacy_filter_properties_dict() scheduler_utils.setup_instance_group(self.context, self.request_spec) # If a target host is set in a requested destination, # 'populate_retry' need not be executed. if not ('requested_destination' in self.request_spec and self.request_spec.requested_destination and 'host' in self.request_spec.requested_destination): scheduler_utils.populate_retry(legacy_props, self.instance.uuid) # NOTE(sbauza): Force_hosts/nodes needs to be reset # if we want to make sure that the next destination # is not forced to be the original host self.request_spec.reset_forced_destinations() self._restrict_request_spec_to_cell(legacy_props) "," def _execute(self): # TODO(sbauza): Remove that once prep_resize() accepts a RequestSpec # object in the signature and all the scheduler.utils methods too legacy_spec = self.request_spec.to_legacy_request_spec_dict() legacy_props = self.request_spec.to_legacy_filter_properties_dict() scheduler_utils.setup_instance_group(self.context, self.request_spec) # If a target host is set in a requested destination, # 'populate_retry' need not be executed. if not ('requested_destination' in self.request_spec and self.request_spec.requested_destination and 'host' in self.request_spec.requested_destination): scheduler_utils.populate_retry(legacy_props, self.instance.uuid) # NOTE(sbauza): Force_hosts/nodes needs to be reset # if we want to make sure that the next destination # is not forced to be the original host self.request_spec.reset_forced_destinations() ",22,19
openstack%2Fnova~master~I259a95ddcd688f7ed16352e4a1e3320343eb27ba,openstack/nova,master,I259a95ddcd688f7ed16352e4a1e3320343eb27ba,Move resize.prep.start/end notifications to helper method,MERGED,2019-01-26 00:17:40.000000000,2019-02-11 13:39:22.000000000,2019-02-07 20:38:44.000000000,"[{'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-26 00:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec686f0a8ddb25c6dbf966ab06f74da046d5cdfc', 'message': 'Move resize.prep.start/end notifications to helper method\n\nThis refactors the code that sends the resize.prep.start\nand resize.prep.end notifications to a helper method.\n\nChange-Id: I259a95ddcd688f7ed16352e4a1e3320343eb27ba\n'}, {'number': 2, 'created': '2019-01-30 00:51:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dca1ee529590ac118e2aca3fc4f8bfe424970e61', 'message': 'Move resize.prep.start/end notifications to helper method\n\nThis refactors the code that sends the resize.prep.start\nand resize.prep.end notifications to a helper method.\n\nChange-Id: I259a95ddcd688f7ed16352e4a1e3320343eb27ba\n'}, {'number': 3, 'created': '2019-02-05 17:34:02.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/883da6cb8129b96138339c24890b8871eb122111', 'message': 'Move resize.prep.start/end notifications to helper method\n\nThis refactors the code that sends the resize.prep.start\nand resize.prep.end notifications to a helper method.\n\nChange-Id: I259a95ddcd688f7ed16352e4a1e3320343eb27ba\n'}]",2,633298,883da6cb8129b96138339c24890b8871eb122111,51,15,3,6873,,,0,"Move resize.prep.start/end notifications to helper method

This refactors the code that sends the resize.prep.start
and resize.prep.end notifications to a helper method.

Change-Id: I259a95ddcd688f7ed16352e4a1e3320343eb27ba
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/633298/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,ec686f0a8ddb25c6dbf966ab06f74da046d5cdfc,bp/cross-cell-resize," def _send_prep_resize_notifications( self, context, instance, phase, flavor): """"""Send ""resize.prep.*"" notifications. :param context: nova auth request context :param instance: The instance being resized :param phase: The phase of the action (NotificationPhase enum) :param flavor: The (new) flavor for the resize (same as existing instance.flavor for a cold migration) """""" # Only send notify_usage_exists if it's the ""start"" phase. if phase == fields.NotificationPhase.START: compute_utils.notify_usage_exists( self.notifier, context, instance, self.host, current_period=True) # Send extra usage info about the flavor if it's the ""end"" phase for # the legacy unversioned notification. extra_usage_info = None if phase == fields.NotificationPhase.END: extra_usage_info = dict( new_instance_type=flavor.name, new_instance_type_id=flavor.id) self._notify_about_instance_usage( context, instance, ""resize.prep.%s"" % phase, extra_usage_info=extra_usage_info) # Send the versioned notification. compute_utils.notify_about_resize_prep_instance( context, instance, self.host, phase, flavor) self._send_prep_resize_notifications( context, instance, fields.NotificationPhase.START, instance_type) self._send_prep_resize_notifications( context, instance, fields.NotificationPhase.END, instance_type)"," compute_utils.notify_usage_exists(self.notifier, context, instance, self.host, current_period=True) self._notify_about_instance_usage( context, instance, ""resize.prep.start"") compute_utils.notify_about_resize_prep_instance( context, instance, self.host, fields.NotificationPhase.START, instance_type) extra_usage_info = dict( new_instance_type=instance_type.name, new_instance_type_id=instance_type.id) self._notify_about_instance_usage( context, instance, ""resize.prep.end"", extra_usage_info=extra_usage_info) compute_utils.notify_about_resize_prep_instance( context, instance, self.host, fields.NotificationPhase.END, instance_type)",37,17
openstack%2Fmonasca-thresh~master~I29a294ee6bda6c6889dcc16320050f5ae485ec42,openstack/monasca-thresh,master,I29a294ee6bda6c6889dcc16320050f5ae485ec42,Add tempest tests job,MERGED,2019-01-31 20:54:57.000000000,2019-02-11 13:32:52.000000000,2019-02-11 13:32:52.000000000,"[{'_account_id': 14123}, {'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 26141}]","[{'number': 1, 'created': '2019-01-31 20:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/e2b81e3c716f6811e95d5be7c307f87054f4ac84', 'message': 'Add tempest tests job\n\nChange-Id: I29a294ee6bda6c6889dcc16320050f5ae485ec42\n'}, {'number': 2, 'created': '2019-02-07 11:19:29.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/443cce3951f392695ee6e2e4b26601ab82c284d3', 'message': 'Add tempest tests job\n\nChange-Id: I29a294ee6bda6c6889dcc16320050f5ae485ec42\n'}]",0,634310,443cce3951f392695ee6e2e4b26601ab82c284d3,13,5,2,16222,,,0,"Add tempest tests job

Change-Id: I29a294ee6bda6c6889dcc16320050f5ae485ec42
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/10/634310/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e2b81e3c716f6811e95d5be7c307f87054f4ac84,tempest, - monasca-tempest-python3-influxdb:, - monasca-tempest-python-influxdb: voting: false - monasca-tempest-python-cassandra: voting: false - monasca-tempest-java-influxdb: voting: false - monasca-tempest-java-cassandra:,1,7
openstack%2Frpm-packaging~stable%2Frocky~I4748bec4c75d166fe2ce3417ce04cdc0190bfb86,openstack/rpm-packaging,stable/rocky,I4748bec4c75d166fe2ce3417ce04cdc0190bfb86,Add telemetry_tempest_plugin,ABANDONED,2019-02-07 12:47:44.000000000,2019-02-11 13:21:56.000000000,,"[{'_account_id': 19648}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-07 12:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/86364003babe47fb3745b9d3ff35e2ecf8fbbe1e', 'message': 'Add telemetry_tempest_plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}, {'number': 2, 'created': '2019-02-07 13:13:13.000000000', 'files': ['openstack/telemetry_tempest_plugin/telemetry_tempest_plugin.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0a36567b7c467214b698a9c42e1c87a9cee1213c', 'message': 'Add telemetry_tempest_plugin\n\nChange-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86\n'}]",0,635500,0a36567b7c467214b698a9c42e1c87a9cee1213c,8,3,2,7102,,,0,"Add telemetry_tempest_plugin

Change-Id: I4748bec4c75d166fe2ce3417ce04cdc0190bfb86
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/00/635500/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/telemetry_tempest_plugin/telemetry_tempest_plugin.spec.j2'],1,86364003babe47fb3745b9d3ff35e2ecf8fbbe1e,635500,"{% set pypi_name = 'telemetry_tempest_plugin' %} {% set upstream_version = upstream_version('0.1.0') %} {% set rpm_release = '1' %} {% set source = url_pypi() %} Name: {{ py2pkg('telemetry_tempest_plugin') }} Version: {{ py2rpmversion() }} Release: {{ py2rpmrelease() }} Summary: Tempest plugin for Telemetry Projects (Aodh, Ceilometer, Gnocchi and Panko) License: {{ license('Apache-2.0') }} URL: https://git.openstack.org/cgit/openstack/{{ pypi_name }} Group: Development/Languages/Python Source0: {{ source }} BuildRequires: openstack-macros BuildRequires: {{ py2pkg('devel', py_versions=['py2', 'py3']) }} BuildRequires: {{ py2pkg('pbr', py_versions=['py2', 'py3']) }} Requires: {{ py2pkg('gabbi') }} Requires: {{ py2pkg('oslo.config') }} Requires: {{ py2pkg('oslo.utils') }} Requires: {{ py2pkg('six') }} BuildArch: noarch %python_subpackages %description Tempest plugin for Telemetry Project. It contains tempest tests for Aodh, Ceilometer, Gnocchi and Panko Projects. %prep %autosetup -p1 -n {{ pypi_name }}-{{ upstream_version }} %py_req_cleanup %build %{python_build} %install %{python_install} %files %{python_files} %license LICENSE %{python_sitelib}/telemetry_tempest_plugin* %changelog ",,42,0
openstack%2Ftripleo-quickstart-extras~master~I0ff13af51c4057a101c43c1fa3e18343475d2dfb,openstack/tripleo-quickstart-extras,master,I0ff13af51c4057a101c43c1fa3e18343475d2dfb,DNM: Document nodepool-setup functionality is in pre playbooks,ABANDONED,2018-10-25 20:28:02.000000000,2019-02-11 13:21:04.000000000,,"[{'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-25 20:28:02.000000000', 'files': ['roles/nodepool-setup/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f1709a025db4258de271493a9055d20b0e225f9a', 'message': 'DNM: Document nodepool-setup functionality is in pre playbooks\n\nThis is in support of card:\nhttps://tree.taiga.io/project/tripleo-ci-board/task/284\n\nDo not duplicate functionality already in pre playbooks.\n\nChange-Id: I0ff13af51c4057a101c43c1fa3e18343475d2dfb\n'}]",0,613414,f1709a025db4258de271493a9055d20b0e225f9a,6,6,1,9976,,,0,"DNM: Document nodepool-setup functionality is in pre playbooks

This is in support of card:
https://tree.taiga.io/project/tripleo-ci-board/task/284

Do not duplicate functionality already in pre playbooks.

Change-Id: I0ff13af51c4057a101c43c1fa3e18343475d2dfb
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/14/613414/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/nodepool-setup/tasks/main.yml'],1,f1709a025db4258de271493a9055d20b0e225f9a,compare-nodepool-setup,## exact match with ## github.com/openstack-infra/tripleo-ci/blob/master/playbooks/openstack-zuul-jobs/legacy/pre.yaml## https://github.com/openstack-infra/tripleo-ci/blob/master/playbooks/tripleo-ci/run-v3.yaml#L9 ## https://github.com/openstack-infra/openstack-zuul-jobs/tree/master/roles/configure-swap## From here down - follow https://github.com/openstack-infra/project-config/blob/master/playbooks/base/pre.yaml ## https://github.com/openstack-infra/openstack-zuul-jobs/blob/master/roles/mirror-info/tasks/main.yaml#L1## https://github.com/openstack-infra/openstack-zuul-jobs/blob/master/roles/mirror-info/tasks/main.yaml#L10## CAN'T MATCH THIS AND BLOCK BELOW## ocata - should probably update that ## I don't see this anywhere but assume the nodepool nodes have these packages ## Either way - this can stay## This creates /opt/stack and clones repos into /opt/stack ## And applies changes ... ## We should clone repos into home/zuul/src/ ## https://github.com/openstack-infra/openstack-zuul-jobs/blob/master/tests/use-cached-repos.yaml ## https://github.com/openstack-infra/zuul-jobs/blob/master/roles/mirror-workspace-git-repos/tasks/main.yaml## https://github.com/openstack-infra/zuul-jobs/tree/master/roles/add-build-sshkey## https://github.com/openstack-infra/openstack-zuul-jobs/tree/master/roles/configure-unbound## https://github.com/openstack-infra/openstack-zuul-jobs/blob/master/tests/multi-node-firewall.yaml??? ## persistent-firewall## I don't think these are still needed,,22,0
openstack%2Ftripleo-quickstart~master~Ib6e9ce1e5d1c658bb41614cadba5ab79e8fc78f3,openstack/tripleo-quickstart,master,Ib6e9ce1e5d1c658bb41614cadba5ab79e8fc78f3,DNM: Put back idempotent check for master,ABANDONED,2019-01-11 13:57:13.000000000,2019-02-11 13:20:38.000000000,,"[{'_account_id': 6926}, {'_account_id': 9976}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-01-11 13:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/c7988a000b342c904fd4213a3702cf897c001b6f', 'message': 'DNM: Put back idempotent check for master\n\nChange-Id: Ib6e9ce1e5d1c658bb41614cadba5ab79e8fc78f3\n'}, {'number': 2, 'created': '2019-01-11 14:10:38.000000000', 'files': ['config/general_config/featureset020.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/04672b78e43101bf0b1e2a03fd9d2346d6ce0b20', 'message': 'DNM: Put back idempotent check for master\n\nChange-Id: Ib6e9ce1e5d1c658bb41614cadba5ab79e8fc78f3\n'}]",0,630229,04672b78e43101bf0b1e2a03fd9d2346d6ce0b20,9,5,2,9976,,,0,"DNM: Put back idempotent check for master

Change-Id: Ib6e9ce1e5d1c658bb41614cadba5ab79e8fc78f3
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/29/630229/2 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset020.yml'],1,c7988a000b342c904fd4213a3702cf897c001b6f,test-idempotent-fs020,undercloud_check_idempotency: true,"undercloud_check_idempotency: >- {% if release not in ['ocata','pike','queens', 'rocky'] -%} false {%- else -%} true {%- endif -%}",1,6
openstack%2Fmonasca-notification~master~I8d7ad198599943fc23a8a55d25eab672c096725d,openstack/monasca-notification,master,I8d7ad198599943fc23a8a55d25eab672c096725d,Update hacking version to latest,MERGED,2019-01-06 09:49:40.000000000,2019-02-11 13:20:31.000000000,2019-02-11 13:20:31.000000000,"[{'_account_id': 22348}, {'_account_id': 26141}, {'_account_id': 29909}]","[{'number': 1, 'created': '2019-01-06 09:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/eb9d9efc3a3fb222f1e8f61d156fb2b7814ee9f8', 'message': 'Update hacking version to latest\n\nChange-Id: I8d7ad198599943fc23a8a55d25eab672c096725d\n'}, {'number': 2, 'created': '2019-02-08 14:49:25.000000000', 'files': ['tests/test_email_notification.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/226a070b4ab307f2e1db766f80858f3d915ad4cc', 'message': 'Update hacking version to latest\n\nStory: 2004930\nTask: 29317\n\nChange-Id: I8d7ad198599943fc23a8a55d25eab672c096725d\n'}]",0,628768,226a070b4ab307f2e1db766f80858f3d915ad4cc,9,3,2,17130,,,0,"Update hacking version to latest

Story: 2004930
Task: 29317

Change-Id: I8d7ad198599943fc23a8a55d25eab672c096725d
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/68/628768/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,eb9d9efc3a3fb222f1e8f61d156fb2b7814ee9f8,hacking,"hacking>=1.1.0,<1.2.0 # Apache-2.0","hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0",1,1
openstack%2Fnova~master~I744afa1df9a6ed8e0eba4310b20c33755ce1ba88,openstack/nova,master,I744afa1df9a6ed8e0eba4310b20c33755ce1ba88,Drop nova-multiattach job,MERGED,2018-10-01 15:39:05.000000000,2019-02-11 13:05:06.000000000,2019-02-09 22:46:34.000000000,"[{'_account_id': 4690}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-10-01 15:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/edba473bbfa4634be3b933a0bcaf9c2036a99cb2', 'message': 'Drop nova-multiattach job\n\nThe dependent tempest change enables the volume multiattach\ntests in the tempest-full and tempest-slow jobs, on which\nnova already gates, which allows us to drop the special\nnova-multiattach job which is mostly redundant test coverage\nof the other tempest.api.compute.* tests, and allows us to\nrun one fewer job on nova/cinder/tempest changes in Stein.\n\nDepends-On: https://review.openstack.org/606978\nChange-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88\n'}, {'number': 2, 'created': '2018-10-01 15:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/011242ceadc50d21aca6e098327dea35bad9cb73', 'message': 'Drop nova-multiattach job\n\nThe dependent tempest change enables the volume multiattach\ntests in the tempest-full and tempest-slow jobs, on which\nnova already gates, which allows us to drop the special\nnova-multiattach job which is mostly redundant test coverage\nof the other tempest.api.compute.* tests, and allows us to\nrun one fewer job on nova/cinder/tempest changes in Stein.\n\nAlso depends on cinder dropping its usage of the nova-multiattach\njob before we can drop the job definition from nova.\n\nDepends-On: https://review.openstack.org/606978\nDepends-On: https://review.openstack.org/606985\nChange-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88\n'}, {'number': 3, 'created': '2018-10-01 15:52:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e61328e01d6146c0053d6a920b3948241a6468de', 'message': 'Drop nova-multiattach job\n\nThe dependent tempest change enables the volume multiattach\ntests in the tempest-full and tempest-slow jobs, on which\nnova already gates, which allows us to drop the special\nnova-multiattach job which is mostly redundant test coverage\nof the other tempest.api.compute.* tests, and allows us to\nrun one fewer job on nova/cinder/tempest changes in Stein.\n\nThe docs are updated to reflect the source of the testing\nnow.\n\nAlso depends on cinder dropping its usage of the nova-multiattach\njob before we can drop the job definition from nova.\n\nDepends-On: https://review.openstack.org/606978\nDepends-On: https://review.openstack.org/606985\nChange-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88\n'}, {'number': 4, 'created': '2018-12-07 19:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb0fcf7aff99a4ff7212b3fc1000dabcd9911ddb', 'message': 'Drop nova-multiattach job\n\nThe dependent tempest change enables the volume multiattach\ntests in the tempest-full and tempest-slow jobs, on which\nnova already gates, which allows us to drop the special\nnova-multiattach job which is mostly redundant test coverage\nof the other tempest.api.compute.* tests, and allows us to\nrun one fewer job on nova/cinder/tempest changes in Stein.\n\nThe docs are updated to reflect the source of the testing\nnow.\n\nAlso depends on cinder dropping its usage of the nova-multiattach\njob before we can drop the job definition from nova.\n\nDepends-On: https://review.openstack.org/606978\nDepends-On: https://review.openstack.org/606985\nChange-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88\n'}, {'number': 5, 'created': '2019-02-05 14:14:40.000000000', 'files': ['.zuul.yaml', 'doc/source/admin/manage-volumes.rst', 'playbooks/legacy/nova-multiattach/post.yaml', 'playbooks/legacy/nova-multiattach/run.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/e9dd8c0f48643211b6cc58ac7dd630fe43cf73a7', 'message': 'Drop nova-multiattach job\n\nThe dependent tempest change enables the volume multiattach\ntests in the tempest-full and tempest-slow jobs, on which\nnova already gates, which allows us to drop the special\nnova-multiattach job which is mostly redundant test coverage\nof the other tempest.api.compute.* tests, and allows us to\nrun one fewer job on nova/cinder/tempest changes in Stein.\n\nThe docs are updated to reflect the source of the testing\nnow.\n\nAlso depends on cinder dropping its usage of the nova-multiattach\njob before we can drop the job definition from nova.\n\nDepends-On: https://review.openstack.org/606978\nDepends-On: https://review.openstack.org/606985\nChange-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88\n'}]",0,606981,e9dd8c0f48643211b6cc58ac7dd630fe43cf73a7,85,18,5,6873,,,0,"Drop nova-multiattach job

The dependent tempest change enables the volume multiattach
tests in the tempest-full and tempest-slow jobs, on which
nova already gates, which allows us to drop the special
nova-multiattach job which is mostly redundant test coverage
of the other tempest.api.compute.* tests, and allows us to
run one fewer job on nova/cinder/tempest changes in Stein.

The docs are updated to reflect the source of the testing
now.

Also depends on cinder dropping its usage of the nova-multiattach
job before we can drop the job definition from nova.

Depends-On: https://review.openstack.org/606978
Depends-On: https://review.openstack.org/606985
Change-Id: I744afa1df9a6ed8e0eba4310b20c33755ce1ba88
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/606981/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'playbooks/legacy/nova-multiattach/post.yaml', 'playbooks/legacy/nova-multiattach/run.yaml']",3,edba473bbfa4634be3b933a0bcaf9c2036a99cb2,drop-multiattach-job,,"- hosts: all name: nova-multiattach tasks: - name: Ensure workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x cat << 'EOF' >>""/tmp/dg-local.conf"" [[local|localrc]] ENABLE_VOLUME_MULTIATTACH=True EOF executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true # Yes we want to run Tempest. export DEVSTACK_GATE_TEMPEST=1 # Only run compute API tests; note that this will need to # be updated if multiattach scenario tests are ever added. export DEVSTACK_GATE_TEMPEST_REGEX=""api.compute"" cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,81
openstack%2Fnova~master~Ica88d94f9b4c3e9552c36d46c671b3d27b237c27,openstack/nova,master,Ica88d94f9b4c3e9552c36d46c671b3d27b237c27,Don't force evacuate/live migrate in notification sample tests,MERGED,2019-02-05 11:59:11.000000000,2019-02-11 12:52:31.000000000,2019-02-07 20:30:13.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-05 11:59:11.000000000', 'files': ['nova/tests/functional/notification_sample_tests/test_instance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c1fb445b8d94e69d7878fad60c4653650052313a', 'message': ""Don't force evacuate/live migrate in notification sample tests\n\nThis appears to have been used simply to avoid additional scheduler\nnotifications. Given that we're deprecating the ability to force\nevacuations and live migrations, just deal with the additional\nnotifications.\n\nChange-Id: Ica88d94f9b4c3e9552c36d46c671b3d27b237c27\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nImplements: blueprint remove-force-flag-from-live-migrate-and-evacuate\n""}]",0,634920,c1fb445b8d94e69d7878fad60c4653650052313a,13,8,1,15334,,,0,"Don't force evacuate/live migrate in notification sample tests

This appears to have been used simply to avoid additional scheduler
notifications. Given that we're deprecating the ability to force
evacuations and live migrations, just deal with the additional
notifications.

Change-Id: Ica88d94f9b4c3e9552c36d46c671b3d27b237c27
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Implements: blueprint remove-force-flag-from-live-migrate-and-evacuate
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/634920/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/notification_sample_tests/test_instance.py'],1,c1fb445b8d94e69d7878fad60c4653650052313a,bp/remove-force-flag-from-live-migrate-and-evacuate," # 0. scheduler.select_destinations.start # 1. scheduler.select_destinations.end # 2. instance.live_migration_rollback.start # 3. instance.live_migration_rollback.end # 4. instance.live_migration_rollback_dest.start # 5. instance.live_migration_rollback_dest.end self.assertEqual(6, len(fake_notifier.VERSIONED_NOTIFICATIONS), [x['event_type'] for x in fake_notifier.VERSIONED_NOTIFICATIONS]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[4]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[5]) # 0. scheduler.select_destinations.start # 1. scheduler.select_destinations.end # 2. instance.live_migration_pre.start # 3. instance.live_migration_pre.end self.assertEqual(4, len(fake_notifier.VERSIONED_NOTIFICATIONS), [x['event_type'] for x in fake_notifier.VERSIONED_NOTIFICATIONS]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) # 0. scheduler.select_destinations.start # 1. scheduler.select_destinations.end # 2. instance.live_migration_pre.start # 3. instance.live_migration_pre.end # 4. instance.live_migration_post.start # 5. instance.live_migration_post_dest.start # 6. instance.live_migration_post_dest.end # 7. instance.live_migration_post.end self.assertEqual(8, len(fake_notifier.VERSIONED_NOTIFICATIONS), [x['event_type'] for x in fake_notifier.VERSIONED_NOTIFICATIONS]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[4]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[5]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[6]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[7]) # 0. scheduler.select_destinations.start # 1. scheduler.select_destinations.end # 2. instance.live_migration_pre.start # 3. instance.live_migration_pre.end # 4. instance.live_migration_abort.start # 5. instance.live_migration_abort.end # 6. instance.live_migration_rollback.start # 7. instance.live_migration_rollback.end self.assertEqual(8, len(fake_notifier.VERSIONED_NOTIFICATIONS), [x['event_type'] for x in fake_notifier.VERSIONED_NOTIFICATIONS]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[4]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[5]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[6]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[7])"," 'force': True, # 0. instance.live_migration_rollback.start # 1. instance.live_migration_rollback.end # 2. instance.live_migration_rollback_dest.start # 3. instance.live_migration_rollback_dest.end self.assertEqual(4, len(fake_notifier.VERSIONED_NOTIFICATIONS)) actual=fake_notifier.VERSIONED_NOTIFICATIONS[0]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[1]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) 'force': True, self.assertEqual(2, len(fake_notifier.VERSIONED_NOTIFICATIONS)) actual=fake_notifier.VERSIONED_NOTIFICATIONS[0]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[1]) self.assertEqual(6, len(fake_notifier.VERSIONED_NOTIFICATIONS)) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[4]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[5]) ""force"": True self.assertEqual(6, len(fake_notifier.VERSIONED_NOTIFICATIONS)) actual=fake_notifier.VERSIONED_NOTIFICATIONS[0]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[1]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[2]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[3]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[4]) actual=fake_notifier.VERSIONED_NOTIFICATIONS[5]) 'force': True 'force': False,",55,29
openstack%2Fdragonflow~master~I38f14e8faa45e4ef3740bdbee78bd493f6d602ab,openstack/dragonflow,master,I38f14e8faa45e4ef3740bdbee78bd493f6d602ab,Add exitpoint for legacy classifier app,MERGED,2019-02-10 10:12:55.000000000,2019-02-11 12:46:58.000000000,2019-02-11 12:46:58.000000000,"[{'_account_id': 6598}, {'_account_id': 17880}, {'_account_id': 20229}, {'_account_id': 22348}, {'_account_id': 23235}, {'_account_id': 23766}]","[{'number': 1, 'created': '2019-02-10 10:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/93ceeecefeec09d17496a111b33b730b1f1a39ca', 'message': 'Add exitpoint for legacy classifier app\n\nClassifier app currently send the packet directly to portsec\napp. This is Bad.\n\nThis change adds a classifier exitpoint table, and classifier\napp sends the packets there. The datapath wiring then sends\nthe packet to the portsec app (if so configured).\n\nThis is important, since sometimes registered are moved,\nand skipping this behaviour causes errors.\n\nChange-Id: I38f14e8faa45e4ef3740bdbee78bd493f6d602ab\n'}, {'number': 2, 'created': '2019-02-11 07:38:34.000000000', 'files': ['dragonflow/controller/apps/classifier.py', 'dragonflow/controller/common/constants.py', 'etc/dragonflow_datapath_layout.yaml'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8976a2cf9e5687ed21f4e1542bfc28d9d57fec58', 'message': 'Add exitpoint for legacy classifier app\n\nClassifier app currently sends the packet directly to portsec\napp. This is Bad. As described in the bug, metadata stored in\nregisters can be lost.\n\nThis change adds a classifier exitpoint table, and classifier\napp sends the packets there. The datapath wiring then sends\nthe packet to the portsec app (if so configured).\n\nThis is important, since sometimes the datapath code allocates different\nregisters to the same metadata accross different applications, and registers\nare moved. Skipping this behaviour causes errors.\n\nCloses-Bug: #1815416\nChange-Id: I38f14e8faa45e4ef3740bdbee78bd493f6d602ab\n'}]",8,636042,8976a2cf9e5687ed21f4e1542bfc28d9d57fec58,13,6,2,20229,,,0,"Add exitpoint for legacy classifier app

Classifier app currently sends the packet directly to portsec
app. This is Bad. As described in the bug, metadata stored in
registers can be lost.

This change adds a classifier exitpoint table, and classifier
app sends the packets there. The datapath wiring then sends
the packet to the portsec app (if so configured).

This is important, since sometimes the datapath code allocates different
registers to the same metadata accross different applications, and registers
are moved. Skipping this behaviour causes errors.

Closes-Bug: #1815416
Change-Id: I38f14e8faa45e4ef3740bdbee78bd493f6d602ab
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/42/636042/1 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/controller/apps/classifier.py', 'dragonflow/controller/common/constants.py', 'etc/dragonflow_datapath_layout.yaml']",3,93ceeecefeec09d17496a111b33b730b1f1a39ca,bug/1815416, dragonflow-legacy.out.1: portsec.in.default, dragonflow-legacy.out.5: portsec.in.default,3,2
openstack%2Fsahara~stable%2Frocky~If8db759ab40ca858594498bc5e6f94f416da2545,openstack/sahara,stable/rocky,If8db759ab40ca858594498bc5e6f94f416da2545,Changing hdfs fs to hdfs dfs,MERGED,2019-02-08 22:23:13.000000000,2019-02-11 12:45:22.000000000,2019-02-11 12:45:22.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 22:23:13.000000000', 'files': ['releasenotes/notes/hdfs-dfs-94a9c4f64cf8994f.yaml', 'sahara/tests/unit/service/edp/test_hdfs_helper.py', 'sahara/service/edp/hdfs_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/debab6d14a5989c502ef100306f0d3f387d79785', 'message': 'Changing hdfs fs to hdfs dfs\n\nThe command hdfs fs has been deprecated in favor of hdfs dfs.\n\nStory: #2004952\nTask: #29368\nChange-Id: If8db759ab40ca858594498bc5e6f94f416da2545\n(cherry picked from commit 21791d1f8929af24196150b70db5864836ac8c83)\n'}]",0,635972,debab6d14a5989c502ef100306f0d3f387d79785,6,2,1,10459,,,0,"Changing hdfs fs to hdfs dfs

The command hdfs fs has been deprecated in favor of hdfs dfs.

Story: #2004952
Task: #29368
Change-Id: If8db759ab40ca858594498bc5e6f94f416da2545
(cherry picked from commit 21791d1f8929af24196150b70db5864836ac8c83)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/72/635972/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/hdfs-dfs-94a9c4f64cf8994f.yaml', 'sahara/tests/unit/service/edp/test_hdfs_helper.py', 'sahara/service/edp/hdfs_helper.py']",3,debab6d14a5989c502ef100306f0d3f387d79785,," r.execute_command('sudo su - -c ""hdfs dfs -put -p %s %s"" hdfs'"," r.execute_command('sudo su - -c ""hdfs fs -put -p %s %s"" hdfs'",7,2
openstack%2Fnova~master~I23c16075e0f88c7b1a50091650891e3efeb4d16e,openstack/nova,master,I23c16075e0f88c7b1a50091650891e3efeb4d16e,Move interface disabling to privsep.,MERGED,2018-12-04 09:37:59.000000000,2019-02-11 12:37:04.000000000,2019-02-05 13:23:13.000000000,"[{'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28885}]","[{'number': 1, 'created': '2018-12-04 09:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e52b2f8035ed6083abc845bcdfac825a456d1835', 'message': 'Move interface disabling to privsep.\n\nChange-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e\n'}, {'number': 2, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7bb7cc4c572e298358d0c3e7229842115526dfa', 'message': 'Move interface disabling to privsep.\n\nChange-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e\n'}, {'number': 3, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d69107ac58a8c4acaf04aa08f68bed619d3a94e6', 'message': 'Move interface disabling to privsep.\n\nChange-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e\n'}, {'number': 4, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/100ef6e2471a23c99e2f323d3a838dcca1fa9d43', 'message': 'Move interface disabling to privsep.\n\nChange-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e\n'}, {'number': 5, 'created': '2019-02-05 04:16:14.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/network/linux_net.py', 'nova/privsep/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d0797c21d52fc509c2e5fdd782bcac5bc83f69e0', 'message': 'Move interface disabling to privsep.\n\nChange-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e\n'}]",1,622150,d0797c21d52fc509c2e5fdd782bcac5bc83f69e0,84,18,5,2271,,,0,"Move interface disabling to privsep.

Change-Id: I23c16075e0f88c7b1a50091650891e3efeb4d16e
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/622150/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_linux_net.py', 'nova/network/linux_net.py', 'nova/privsep/linux_net.py']",3,e52b2f8035ed6083abc845bcdfac825a456d1835,my-own-personal-alternative-universe,"def set_device_disabled(dev): processutils.execute('ip', 'link', 'set', dev, 'down') @nova.privsep.sys_admin_pctxt.entrypoint",,11,8
openstack%2Fdevstack~stable%2Frocky~Ic8684871e1aef00a2ceb3e445000705b906d910e,openstack/devstack,stable/rocky,Ic8684871e1aef00a2ceb3e445000705b906d910e,Remove fedora-latest nodeset from Rocky,MERGED,2019-02-04 05:47:47.000000000,2019-02-11 12:32:11.000000000,2019-02-11 12:32:11.000000000,"[{'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-04 05:47:47.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f22c497c237c5f71437e5c9c0ed0811d005f0f4d', 'message': ""Remove fedora-latest nodeset from Rocky\n\nThis isn't required on the Rocky branch, as we're not keeping stable\nreleases running against Fedora, it's a master-only thing.\n\nRemove it so it doesn't conflict with the master definition of this\nnodeset, which we want to update to later Fedora versions.\n\nChange-Id: Ic8684871e1aef00a2ceb3e445000705b906d910e\n""}]",0,634627,f22c497c237c5f71437e5c9c0ed0811d005f0f4d,8,4,1,7118,,,0,"Remove fedora-latest nodeset from Rocky

This isn't required on the Rocky branch, as we're not keeping stable
releases running against Fedora, it's a master-only thing.

Remove it so it doesn't conflict with the master definition of this
nodeset, which we want to update to later Fedora versions.

Change-Id: Ic8684871e1aef00a2ceb3e445000705b906d910e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/27/634627/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f22c497c237c5f71437e5c9c0ed0811d005f0f4d,rocky-remove-fedora,, name: devstack-single-node-fedora-latest nodes: - name: controller label: fedora-28 groups: - name: tempest nodes: - controller - nodeset:,0,10
openstack%2Fcinder~master~Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435,openstack/cinder,master,Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435,Fix _per_gb_min usage with _per_gb,MERGED,2018-12-13 12:28:31.000000000,2019-02-11 12:16:41.000000000,2018-12-18 19:32:14.000000000,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}]","[{'number': 1, 'created': '2018-12-13 12:28:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b9f8026cacd4a3fba29f04455ab4c0ab5800ae5', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n'}, {'number': 2, 'created': '2018-12-14 18:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1ef74fd3428d12dbc12280593248ed474250315a', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\nChanged unit test to cover the case\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n'}, {'number': 3, 'created': '2018-12-14 18:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e48a504a476f29615244725255cc040d18ab1701', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n'}, {'number': 4, 'created': '2018-12-14 18:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1922efdc4eab2dad48190c90eefb082eca0ec3d9', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n'}, {'number': 5, 'created': '2018-12-14 18:19:48.000000000', 'files': ['cinder/tests/unit/volume/test_connection.py', 'cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b9b260a0a8dcf24995aa586dd5f2714326095257', 'message': 'Fix _per_gb_min usage with _per_gb\n\nAs _per_gb_min was a text, it was in many cases larger, than\n_per_gb value. So, situations, when big drives were attached\nwith min iops are now excluded.\n\nChange-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435\n'}]",0,624970,b9b260a0a8dcf24995aa586dd5f2714326095257,83,37,5,28619,,,0,"Fix _per_gb_min usage with _per_gb

As _per_gb_min was a text, it was in many cases larger, than
_per_gb value. So, situations, when big drives were attached
with min iops are now excluded.

Change-Id: Ie24e5a85b54e4734c9b96987cc8ec497aa0ac435
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/624970/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,3b9f8026cacd4a3fba29f04455ab4c0ab5800ae5,fix/qos_per_gb_min," minimum_value = int(specs.pop(option_per_gb_min, 0))"," minimum_value = specs.pop(option_per_gb_min, 0)",1,1
openstack%2Fmistral~master~Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2,openstack/mistral,master,Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2,Add a workflow execution report endpoint,MERGED,2019-01-16 08:41:29.000000000,2019-02-11 11:44:49.000000000,2019-02-11 11:44:48.000000000,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 9712}, {'_account_id': 15353}, {'_account_id': 15895}, {'_account_id': 18955}, {'_account_id': 21970}, {'_account_id': 22348}, {'_account_id': 28101}, {'_account_id': 29124}]","[{'number': 1, 'created': '2019-01-16 08:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/40b5a73bce4f31c0f997d6c2487014895b8f06e4', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Add filters to select only needed report entries\n * Implement method sample() for all report entry resources\n * Write required unit tests\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 2, 'created': '2019-01-17 10:58:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ddbf2841b621aee4b6f78c5d6b909208a5c32b66', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Add filters to select only needed report entries\n * Implement method sample() for all report entry resources\n * Write required unit tests\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 3, 'created': '2019-01-17 11:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/dcbf275fb03e0183912b5e9f908fcc7403b3ed3e', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Add filters to select only needed report entries\n * Implement method sample() for all report entry resources\n * Write required unit tests\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 4, 'created': '2019-01-31 12:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/11ca7b310a091e0b3d063741b2352ef9a74c3dac', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Add filters to select only needed report entries\n * Implement method sample() for all report entry resources\n * Write required unit tests\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 5, 'created': '2019-02-01 08:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/37ffbada5206ed2d6ea9772911d5afc70c48a1ed', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Implement method sample() for all report entry resources\n * Write required unit tests\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 6, 'created': '2019-02-04 02:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f94fab865ca2932b031ceb4c17575fdb0fb44458', 'message': 'WIP: add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Implement method sample() for all report entry resources\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 7, 'created': '2019-02-04 04:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/ad8228882e514f36d37b7624bd50ce373551eca2', 'message': 'WIP: Add a workflow execution report endpoint\n\nTODO:\n * Add all needed attributes into report entry resources\n * Implement method sample() for all report entry resources\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 8, 'created': '2019-02-04 07:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/e1adbe2a9f6f9975fc342a5aa0681bd1dda19e71', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associate with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of all execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0 the only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (which is by default) then\n        no limit is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 9, 'created': '2019-02-06 06:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8c69c6a35b69e31fc1fcec05c07a7d71bcccc419', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associate with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of all execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0 the only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (which is by default) then\n        no limit is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 10, 'created': '2019-02-06 08:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/f1251be6e8df3a0735b6d310159ac894ef389baa', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associated with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0, only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (by default) then no limit\n        is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 11, 'created': '2019-02-07 16:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/1cd86fe79dec801dac31543ed71089c5e6b2e1b3', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associated with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0, only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (by default) then no limit\n        is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 12, 'created': '2019-02-11 03:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/3fa363d046a32d969b8fa57e13823f0c27521043', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associated with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0, only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (by default) then no limit\n        is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}, {'number': 13, 'created': '2019-02-11 08:03:49.000000000', 'files': ['mistral/tests/unit/api/v2/test_execution_report.py', 'mistral/api/controllers/v2/resources.py', 'mistral/api/controllers/v2/execution.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v2/execution_report.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/ae2c5fdbbbd118c371dfd6af238f1c32bb50a6db', 'message': 'Add a workflow execution report endpoint\n\n* This patch adds the first version of the REST endpoint that\n  can generate a report for a workflow execution. Without any\n  query parameters, GET method of the endpoint returns a tree-like\n  structure that includes information about all execution objects\n  associated with the specified workflow execution. The root object\n  is the workflow execution itself, its children are task executions,\n  each task execution has either action executions or workflow\n  executions and so on. So the structure describes the entire set\n  of execution objects regardless of how deep there are from the\n  root object. This kind of data itself can be used to better\n  understand and visualise the process related with a parent workflow,\n  see what paths were taken while the workflow was running.\n  If additional parameters are provided in a query string, the\n  endpoint can give only a subset of the entire tree. Currently,\n  the filters are:\n    1. ""errors_only"" (boolean) to retain only all execution objects\n        with the error state, meaning that only all error paths are\n        present in the report. It is useful when we need to do a root\n        cause analysis of the workflow failure. False by default.\n    2. ""max_depth"" (integer) to limit how deep the algorithm can go\n        into nested workflows. If set to 0, only the root workflow\n        execution will be in the report. If set to 1, then the report\n        will have only the root workflow execution and its direct\n\tchildren. And so on. If negative (by default) then no limit\n        is set.\n  Additionally, the report contains statistics about task executions\n  examined while the report was being generated, like the number of\n  tasks in the error state, number of tasks that successfully\n  finished and so on.\n* Added all main tests for the endpoint. Note that despite the fact\n  that this test verifies a REST API endpoint, unlike the other API\n  tests it runs a Mistral engine to run workflows. This is done to\n  simplify the test implementation so that we don\'t have to mock\n  everything with huge data structures like we do in other API tests.\n\nPossible changes that may be made based on the feedback:\n* Statistics can contain not only number of tasks in certain states.\n  We can also add things like number of actions, depth of the tree,\n  number of nested workflows, average task/action/workflow execution\n  time etc.\n* Additional query parameters to configure a generated report. For\n  example, ""statistics_only"" just to get a general information about\n  the workflow execution tree, not the tree itself. Another example\n  is ""running_only"" to retain only not finished workflow paths.\n\nImplements blueprint: mistral-error-analysis\n\nChange-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2\n'}]",18,631163,ae2c5fdbbbd118c371dfd6af238f1c32bb50a6db,54,10,13,8731,,,0,"Add a workflow execution report endpoint

* This patch adds the first version of the REST endpoint that
  can generate a report for a workflow execution. Without any
  query parameters, GET method of the endpoint returns a tree-like
  structure that includes information about all execution objects
  associated with the specified workflow execution. The root object
  is the workflow execution itself, its children are task executions,
  each task execution has either action executions or workflow
  executions and so on. So the structure describes the entire set
  of execution objects regardless of how deep there are from the
  root object. This kind of data itself can be used to better
  understand and visualise the process related with a parent workflow,
  see what paths were taken while the workflow was running.
  If additional parameters are provided in a query string, the
  endpoint can give only a subset of the entire tree. Currently,
  the filters are:
    1. ""errors_only"" (boolean) to retain only all execution objects
        with the error state, meaning that only all error paths are
        present in the report. It is useful when we need to do a root
        cause analysis of the workflow failure. False by default.
    2. ""max_depth"" (integer) to limit how deep the algorithm can go
        into nested workflows. If set to 0, only the root workflow
        execution will be in the report. If set to 1, then the report
        will have only the root workflow execution and its direct
	children. And so on. If negative (by default) then no limit
        is set.
  Additionally, the report contains statistics about task executions
  examined while the report was being generated, like the number of
  tasks in the error state, number of tasks that successfully
  finished and so on.
* Added all main tests for the endpoint. Note that despite the fact
  that this test verifies a REST API endpoint, unlike the other API
  tests it runs a Mistral engine to run workflows. This is done to
  simplify the test implementation so that we don't have to mock
  everything with huge data structures like we do in other API tests.

Possible changes that may be made based on the feedback:
* Statistics can contain not only number of tasks in certain states.
  We can also add things like number of actions, depth of the tree,
  number of nested workflows, average task/action/workflow execution
  time etc.
* Additional query parameters to configure a generated report. For
  example, ""statistics_only"" just to get a general information about
  the workflow execution tree, not the tree itself. Another example
  is ""running_only"" to retain only not finished workflow paths.

Implements blueprint: mistral-error-analysis

Change-Id: Id3e17821e04b7a1b84dfea5126d223d90ad8e3c2
",git fetch https://review.opendev.org/openstack/mistral refs/changes/63/631163/10 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/tests/unit/api/v2/test_execution_report.py', 'mistral/api/controllers/v2/resources.py', 'mistral/api/controllers/v2/execution.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v2/execution_report.py']",5,40b5a73bce4f31c0f997d6c2487014895b8f06e4,bp/mistral-error-analysis,"# Copyright 2013 - Mirantis, Inc. # Copyright 2015 - StackStorm, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. from oslo_log import log as logging from pecan import rest from wsme import types as wtypes import wsmeext.pecan as wsme_pecan from mistral.api.controllers.v2 import resources from mistral.api.controllers.v2 import types from mistral.db.v2 import api as db_api from mistral.db.v2.sqlalchemy import models as db_models from mistral.utils import rest_utils from mistral.workflow import states LOG = logging.getLogger(__name__) STATE_TYPES = wtypes.Enum(str, states.IDLE, states.RUNNING, states.SUCCESS, states.ERROR, states.RUNNING_DELAYED) def create_workflow_execution_entry(wf_ex): entry = resources.WorkflowExecutionReportEntry.from_db_model(wf_ex) entry.type = 'workflow' return entry def create_task_execution_entry(task_ex): entry = resources.TaskExecutionReportEntry.from_db_model(task_ex) entry.type = 'task' return entry def create_action_execution_entry(action_ex): entry = resources.ActionExecutionReportEntry.from_db_model(action_ex) entry.type = 'action' return entry def analyse_task_execution(task_ex_id, stat): with db_api.transaction(): task_ex = db_api.get_task_execution(task_ex_id) entry = create_task_execution_entry(task_ex) child_executions = task_ex.executions entry.action_executions = [] entry.workflow_executions = [] for c_ex in child_executions: if isinstance(c_ex, db_models.ActionExecution): entry.action_executions.append( create_action_execution_entry(c_ex) ) else: entry.workflow_executions.append( analyse_workflow_execution(c_ex, stat) ) return entry def analyse_workflow_execution(wf_ex_id, stat): with db_api.transaction(): wf_ex = db_api.get_workflow_execution(wf_ex_id) entry = create_workflow_execution_entry(wf_ex) # TODO(rakhmerov): Maybe it's better to return the full graph in this case? if wf_ex.state != states.ERROR: return entry task_execs = wf_ex.task_executions task_exec_entries = [] for t_ex in task_execs: task_exec_entries.append(analyse_task_execution(t_ex.id, stat)) setattr(entry, 'task_executions', task_exec_entries) print(""Task execution entries:"", type(entry.task_executions)) return entry def build_report(wf_ex_id): report = resources.ExecutionReport() stat = resources.ExecutionReportStatistics() report.statistics = stat report.root_entry = analyse_workflow_execution(wf_ex_id, stat) # TODO(rakhmerov): Build a report. # 1. Fetch an execution from DB # 1.1. If it's SUCCESS or RUNNING then just return the execution itself (???) # 2.2. If it's ERROR then recursively find errors: # Workflow execution -> task executions -> nested workflow execution |action execution -> ... # and fill a tree of ReportEntries return report class ExecutionReportController(rest.RestController): @rest_utils.wrap_wsme_controller_exception @wsme_pecan.wsexpose(resources.ExecutionReport, types.uuid) def get(self, workflow_execution_id): """"""Return workflow execution report. TODO :param workflow_execution_id: Optional. Keep only resources with a specific workflow execution ID. """""" #acl.enforce('execution_report:get', context.ctx()) LOG.debug( ""Fetch execution report [workflow_execution_id=%s]"", workflow_execution_id ) return build_report(workflow_execution_id)",,323,2
openstack%2Fnova~master~Ie8a31dd4d80e74b5700b3449ac42db7960843936,openstack/nova,master,Ie8a31dd4d80e74b5700b3449ac42db7960843936,Move setting mac addresses for network devices to privsep.,MERGED,2018-12-03 09:40:21.000000000,2019-02-11 11:43:26.000000000,2019-02-05 13:23:08.000000000,"[{'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-03 09:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c2d05a06b16d896f60f27e762b86c608e4cbd24e', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}, {'number': 2, 'created': '2018-12-04 09:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1886f8e688eb1a9c94fdfd016f8d04b5bc6aec9', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}, {'number': 3, 'created': '2018-12-10 22:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7af9e42285f0381944d1321540a1e663d4a54fd', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}, {'number': 4, 'created': '2018-12-12 07:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/791f352c02927e1e7b5623f720e3fa6f4d6e8925', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}, {'number': 5, 'created': '2018-12-18 04:49:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/562ba3958648cf3d7c0a1e23cd570baef69e9831', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}, {'number': 6, 'created': '2019-02-05 04:16:14.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/network/linux_net.py', 'nova/tests/unit/network/test_utils.py', 'nova/tests/unit/virt/libvirt/test_vif.py', 'nova/network/linux_utils.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/13e283cc82e7cab564850501f9781385fb7b3f68', 'message': 'Move setting mac addresses for network devices to privsep.\n\nChange-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936\n'}]",0,621529,13e283cc82e7cab564850501f9781385fb7b3f68,105,18,6,2271,,,0,"Move setting mac addresses for network devices to privsep.

Change-Id: Ie8a31dd4d80e74b5700b3449ac42db7960843936
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/621529/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/network/test_linux_net.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/unit/virt/xenapi/test_xenapi.py', 'nova/network/linux_net.py', 'nova/tests/unit/network/test_utils.py', 'nova/tests/unit/virt/libvirt/test_vif.py', 'nova/network/linux_utils.py', 'nova/privsep/linux_net.py', 'nova/tests/unit/network/test_manager.py']",9,c2d05a06b16d896f60f27e762b86c608e4cbd24e,my-own-personal-alternative-universe," @mock.patch('nova.privsep.linux_net.set_device_macaddr') def test_allocate_for_instance(self, mock_set_macaddr, mock_set_enabled, mock_set_mtu, mock_add_bridge): @mock.patch('nova.privsep.linux_net.set_device_macaddr') def test_allocate_for_instance_with_mac(self, mock_set_addr, mock_enabled, mock_set_mtu,"," def test_allocate_for_instance(self, mock_set_enabeld, mock_set_mtu, mock_add_bridge): def test_allocate_for_instance_with_mac(self, mock_enabled, mock_set_mtu,",56,45
openstack%2Fkayobe~stable%2Fqueens~Idfa2f33dd6641031ea8a287d74b6dbbfa578c9ab,openstack/kayobe,stable/queens,Idfa2f33dd6641031ea8a287d74b6dbbfa578c9ab,Retry adding custom repos until success,MERGED,2018-12-21 15:56:45.000000000,2019-02-11 11:39:17.000000000,2019-02-11 11:39:16.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-21 15:56:45.000000000', 'files': ['ansible/roles/yum/tasks/custom_repo.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/32d1a8bace0dfad1a15e4687e91dff79f8538a78', 'message': 'Retry adding custom repos until success\n\nPreviously we checked for false in the result. The behavior\nof Ansible has probably changed, as failed is always in the\nresult dictionary - just with the value ""false"". Tested\nwith Ansible 2.5.11.\n\nChange-Id: Idfa2f33dd6641031ea8a287d74b6dbbfa578c9ab\n(cherry picked from commit a2dd79f8b100384ea83c7835688a5795eea90ba6)\n'}]",0,626943,32d1a8bace0dfad1a15e4687e91dff79f8538a78,8,4,1,14826,,,0,"Retry adding custom repos until success

Previously we checked for false in the result. The behavior
of Ansible has probably changed, as failed is always in the
result dictionary - just with the value ""false"". Tested
with Ansible 2.5.11.

Change-Id: Idfa2f33dd6641031ea8a287d74b6dbbfa578c9ab
(cherry picked from commit a2dd79f8b100384ea83c7835688a5795eea90ba6)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/43/626943/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/yum/tasks/custom_repo.yml'],1,32d1a8bace0dfad1a15e4687e91dff79f8538a78,queens-backports, until: register_yum_command is success," until: ""'failed' not in register_yum_command""",1,1
openstack%2Fkayobe~stable%2Fqueens~I1a580a7b88a3e088aa7d5129290427320401f46b,openstack/kayobe,stable/queens,I1a580a7b88a3e088aa7d5129290427320401f46b,Move group_vars for switches group to all group,MERGED,2018-12-21 15:56:45.000000000,2019-02-11 11:39:15.000000000,2019-02-11 11:39:15.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-21 15:56:45.000000000', 'files': ['ansible/group_vars/all/switches/config', 'ansible/group_vars/all/switches/dell', 'ansible/group_vars/all/switches/dell-powerconnect', 'ansible/group_vars/all/switches/junos', 'ansible/group_vars/all/switches/mellanox'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/70bde2115a048a20e003c9b44ac2036ac59897d7', 'message': ""Move group_vars for switches group to all group\n\nThere are various playbook group variables used to configure switches,\ndefined in files in ansible/group_vars/switches/. In Ansible 2.3\nit was possible to override these via inventory group variables.\nIn Ansible 2.4+ this is no longer possible, and inventory group\nvariables have a lower precedence than playbook group variables.\n\nTo resolve this, this change moves the switch configuration defaults to\nthe all group, as is done for other global defaults. The slight downside\nis that these variables enter the namespace of every host, but there\naren't too many of them so it shouldn't be a problem.\n\nChange-Id: I1a580a7b88a3e088aa7d5129290427320401f46b\nStory: 2004278\nTask: 27827\n(cherry picked from commit a0bd6320a4ec1acd06e2f28839db96b65e2b444a)\n""}]",0,626942,70bde2115a048a20e003c9b44ac2036ac59897d7,8,4,1,14826,,,0,"Move group_vars for switches group to all group

There are various playbook group variables used to configure switches,
defined in files in ansible/group_vars/switches/. In Ansible 2.3
it was possible to override these via inventory group variables.
In Ansible 2.4+ this is no longer possible, and inventory group
variables have a lower precedence than playbook group variables.

To resolve this, this change moves the switch configuration defaults to
the all group, as is done for other global defaults. The slight downside
is that these variables enter the namespace of every host, but there
aren't too many of them so it shouldn't be a problem.

Change-Id: I1a580a7b88a3e088aa7d5129290427320401f46b
Story: 2004278
Task: 27827
(cherry picked from commit a0bd6320a4ec1acd06e2f28839db96b65e2b444a)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/42/626942/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all/switches/config', 'ansible/group_vars/all/switches/dell', 'ansible/group_vars/all/switches/dell-powerconnect', 'ansible/group_vars/all/switches/junos', 'ansible/group_vars/all/switches/mellanox']",5,70bde2115a048a20e003c9b44ac2036ac59897d7,queens-backports,,,0,0
openstack%2Fnova~master~I3805361834f7d954ae6759a22f61f02db139bcc5,openstack/nova,master,I3805361834f7d954ae6759a22f61f02db139bcc5,doc: Add solution to live migration ssh issues,MERGED,2018-12-21 15:21:19.000000000,2019-02-11 11:33:44.000000000,2019-02-04 22:22:45.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 6962}, {'_account_id': 7166}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-21 15:21:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38fbab888f84834e0c4ac366f191cba7559dbc2e', 'message': 'doc: Add solution to live migration ssh issues\n\nThis took me a good hour to suss and while there were a couple of Google\nhits for it, the top suggestion was to use TCP (rather than SSH) and\ndisable all security, which is rarely good advice.\n\nPaste an sample error and link to the doc where you can find advice of\nresolving the issue.\n\nChange-Id: I3805361834f7d954ae6759a22f61f02db139bcc5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 2, 'created': '2019-02-04 17:36:13.000000000', 'files': ['doc/source/admin/support-compute.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/76aea693dcccfe4a4c21520ce0e07fcc74892c3b', 'message': 'doc: Add solution to live migration ssh issues\n\nThis took me a good hour to suss and while there were a couple of Google\nhits for it, the top suggestion was to use TCP (rather than SSH) and\ndisable all security, which is rarely good advice.\n\nPaste an sample error and link to the doc where you can find advice of\nresolving the issue.\n\nChange-Id: I3805361834f7d954ae6759a22f61f02db139bcc5\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n'}]",4,626931,76aea693dcccfe4a4c21520ce0e07fcc74892c3b,26,15,2,15334,,,0,"doc: Add solution to live migration ssh issues

This took me a good hour to suss and while there were a couple of Google
hits for it, the top suggestion was to use TCP (rather than SSH) and
disable all security, which is rarely good advice.

Paste an sample error and link to the doc where you can find advice of
resolving the issue.

Change-Id: I3805361834f7d954ae6759a22f61f02db139bcc5
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/626931/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/support-compute.rst'],1,38fbab888f84834e0c4ac366f191cba7559dbc2e,live-migration-ssh-docs,"Live migration permission issues -------------------------------- Problem ~~~~~~~ When live migrating an instance, you may see errors like the below:: libvirtError: operation failed: Failed to connect to remote libvirt URI qemu+ssh://stack@cld6b16/system: Cannot recv data: Host key verification failed.: Connection reset by peer Solution ~~~~~~~~ Ensure you have completed all the steps outlined in :doc:`/admin/ssh-configuration`. In particular, it's important to that note that the ``libvirt`` process runs as ``root`` even though it may be connecting to a different user (``stack`` in the above example). You can ensure everything is correctly configured by attempting to connect to the remote host via the ``root`` user. Using the above example once again: .. code-block:: shell $ su - -c 'ssh stack@cld6b16' ",,27,0
openstack%2Fsahara-dashboard~stable%2Frocky~I007f6cb5528e658fa8a0211a833500385a4aa07a,openstack/sahara-dashboard,stable/rocky,I007f6cb5528e658fa8a0211a833500385a4aa07a,Increasing max number fields,MERGED,2019-02-08 19:42:29.000000000,2019-02-11 11:33:36.000000000,2019-02-11 11:33:36.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-08 19:42:29.000000000', 'files': ['sahara_dashboard/local_settings.d/_12_toggle_data_upload_max_number_fields.py', 'releasenotes/notes/increase-max-fields-91b921991f1e8978.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/b0a16b2c7d798713f9c9213446ffd9c46b8720c2', 'message': 'Increasing max number fields\n\nIncreasing the max number fields to allow CDH node group templates creation\n\nStory: 2004866\nTask: 29110\n\nChange-Id: I007f6cb5528e658fa8a0211a833500385a4aa07a\n(cherry picked from commit f8649ba63aa337a7451c212874570edfa596441a)\n'}]",0,635923,b0a16b2c7d798713f9c9213446ffd9c46b8720c2,6,2,1,10459,,,0,"Increasing max number fields

Increasing the max number fields to allow CDH node group templates creation

Story: 2004866
Task: 29110

Change-Id: I007f6cb5528e658fa8a0211a833500385a4aa07a
(cherry picked from commit f8649ba63aa337a7451c212874570edfa596441a)
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/23/635923/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara_dashboard/local_settings.d/_12_toggle_data_upload_max_number_fields.py', 'releasenotes/notes/increase-max-fields-91b921991f1e8978.yaml']",2,b0a16b2c7d798713f9c9213446ffd9c46b8720c2,,--- fixes: - | Increasing DATA_UPLOAD_MAX_NUMBER_FIELDS django configuration to allow creation of CDH node group templates. ,,6,1
openstack%2Fkayobe~stable%2Fqueens~I30a83a9851345ece061413d3c1751112247425ae,openstack/kayobe,stable/queens,I30a83a9851345ece061413d3c1751112247425ae,Seed hypervisor user bootstrapping skipped,MERGED,2018-12-21 15:56:45.000000000,2019-02-11 11:30:01.000000000,2019-02-11 11:30:01.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-21 15:56:45.000000000', 'files': ['releasenotes/notes/seed-hypervisor-bootstrap-58bafc1ea0d125bc.yaml', 'ansible/kayobe-ansible-user.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/15e4a60464f33e7dcd6cd2630c2f5e7d49efa92e', 'message': ""Seed hypervisor user bootstrapping skipped\n\nAlthough the 'kayobe seed hypervisor host configure' command executes\nthe kayobe-ansible-user.yml playbook correctly, the playbook does not\nhave the seed-hypervisor group in its host list, so it is a noop. This\nchange fixes that.\n\nChange-Id: I30a83a9851345ece061413d3c1751112247425ae\nStory: 2004401\nTask: 28034\n(cherry picked from commit 5f791a4b46ddf15c35770af4df58139f15a8c9cf)\n""}]",0,626941,15e4a60464f33e7dcd6cd2630c2f5e7d49efa92e,8,4,1,14826,,,0,"Seed hypervisor user bootstrapping skipped

Although the 'kayobe seed hypervisor host configure' command executes
the kayobe-ansible-user.yml playbook correctly, the playbook does not
have the seed-hypervisor group in its host list, so it is a noop. This
change fixes that.

Change-Id: I30a83a9851345ece061413d3c1751112247425ae
Story: 2004401
Task: 28034
(cherry picked from commit 5f791a4b46ddf15c35770af4df58139f15a8c9cf)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/41/626941/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/seed-hypervisor-bootstrap-58bafc1ea0d125bc.yaml', 'ansible/kayobe-ansible-user.yml']",2,15e4a60464f33e7dcd6cd2630c2f5e7d49efa92e,queens-backports, hosts: seed-hypervisor:seed:overcloud hosts: seed-hypervisor:seed:overcloud, hosts: seed:overcloud hosts: seed:overcloud,9,2
openstack%2Fnova~master~I1fbfa46b52b32039ff3d6703a27306b56314c1d5,openstack/nova,master,I1fbfa46b52b32039ff3d6703a27306b56314c1d5,Follow up for per-instance serial number change,MERGED,2019-02-04 16:57:53.000000000,2019-02-11 11:28:50.000000000,2019-02-05 13:01:38.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9373}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 16:57:53.000000000', 'files': ['releasenotes/notes/per-instance-serial-f2e597cb05d1b09e.yaml', 'nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/b29158149d802cfc81541f13255394da559d0c48', 'message': 'Follow up for per-instance serial number change\n\nThis is a follow up change to address review nits\nfrom I001beb2840496f7950988acc69018244847aa888.\n\nChange-Id: I1fbfa46b52b32039ff3d6703a27306b56314c1d5\n'}]",0,634743,b29158149d802cfc81541f13255394da559d0c48,24,13,1,6873,,,0,"Follow up for per-instance serial number change

This is a follow up change to address review nits
from I001beb2840496f7950988acc69018244847aa888.

Change-Id: I1fbfa46b52b32039ff3d6703a27306b56314c1d5
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/634743/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/per-instance-serial-f2e597cb05d1b09e.yaml', 'nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",4,b29158149d802cfc81541f13255394da559d0c48,bp/per-instance-libvirt-sysinfo-serial, expected_serial = instance_ref.uuid, expected_serial = instance_ref['uuid'],20,15
openstack%2Fkayobe~stable%2Fqueens~I88b1b7b9e9be15b52e730d353ce1b1a6feacceb8,openstack/kayobe,stable/queens,I88b1b7b9e9be15b52e730d353ce1b1a6feacceb8,Fix use of --ask-vault-pass argument,MERGED,2018-12-21 15:56:45.000000000,2019-02-11 11:27:48.000000000,2019-02-11 11:27:48.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-12-21 15:56:45.000000000', 'files': ['kayobe/tests/unit/test_kolla_ansible.py', 'kayobe/kolla_ansible.py', 'kayobe/ansible.py', 'kayobe/tests/unit/test_ansible.py', 'kayobe/vault.py', 'releasenotes/notes/ask-vault-pass-b6ced0220384dde1.yaml', 'kayobe/tests/unit/test_vault.py'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/39bdddc1ec2df69fd4135eb3807ec2c245863e8f', 'message': 'Fix use of --ask-vault-pass argument\n\nCurrently, this argument does not work correctly, since the vault\npassword is not passed to kayobe via $KAYOBE_VAULT_PASSWORD, meaning\nthat it cannot update the kolla-ansible passwords.yml file.\n\nIt also works non-optimally, since every invocation of ansible-playbook\nwill prompt for a password.\n\nThis change fixes the issue by prompting for a password once in the\nkayobe CLI, and storing the password in the $KAYOBE_VAULT_PASSWORD\nenvironment variable. The kayobe-vault-password-helper command is then\nused as the --vault-password-file to ansible-playbook, and the helper\npulls the password out of the environment.\n\nChange-Id: I88b1b7b9e9be15b52e730d353ce1b1a6feacceb8\nStory: 2001664\nTask: 27009\n(cherry picked from commit 358b5c68828e6e7de8bfc7654c7418c02380052b)\n'}]",0,626940,39bdddc1ec2df69fd4135eb3807ec2c245863e8f,8,4,1,14826,,,0,"Fix use of --ask-vault-pass argument

Currently, this argument does not work correctly, since the vault
password is not passed to kayobe via $KAYOBE_VAULT_PASSWORD, meaning
that it cannot update the kolla-ansible passwords.yml file.

It also works non-optimally, since every invocation of ansible-playbook
will prompt for a password.

This change fixes the issue by prompting for a password once in the
kayobe CLI, and storing the password in the $KAYOBE_VAULT_PASSWORD
environment variable. The kayobe-vault-password-helper command is then
used as the --vault-password-file to ansible-playbook, and the helper
pulls the password out of the environment.

Change-Id: I88b1b7b9e9be15b52e730d353ce1b1a6feacceb8
Story: 2001664
Task: 27009
(cherry picked from commit 358b5c68828e6e7de8bfc7654c7418c02380052b)
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/40/626940/1 && git format-patch -1 --stdout FETCH_HEAD,"['kayobe/tests/unit/test_kolla_ansible.py', 'kayobe/kolla_ansible.py', 'kayobe/ansible.py', 'kayobe/tests/unit/test_ansible.py', 'kayobe/vault.py', 'releasenotes/notes/ask-vault-pass-b6ced0220384dde1.yaml', 'kayobe/tests/unit/test_vault.py']",7,39bdddc1ec2df69fd4135eb3807ec2c245863e8f,queens-backports,"# Copyright (c) 2018 StackHPC Ltd. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import argparse import os import unittest import mock from kayobe import utils from kayobe import vault class TestCase(unittest.TestCase): def test_validate_args_ok(self): parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([]) vault.validate_args(parsed_args) @mock.patch.dict(os.environ, {""KAYOBE_VAULT_PASSWORD"": ""test-pass""}) def test_validate_args_env(self): parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([]) vault.validate_args(parsed_args) @mock.patch.dict(os.environ, {""KAYOBE_VAULT_PASSWORD"": ""test-pass""}) def test_validate_args_ask_vault_pass(self): parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([""--ask-vault-pass""]) self.assertRaises(SystemExit, vault.validate_args, parsed_args) @mock.patch.dict(os.environ, {""KAYOBE_VAULT_PASSWORD"": ""test-pass""}) def test_validate_args_vault_password_file(self): parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([""--vault-password-file"", ""/path/to/file""]) self.assertRaises(SystemExit, vault.validate_args, parsed_args) @mock.patch.object(vault.getpass, 'getpass') def test__ask_vault_pass(self, mock_getpass): mock_getpass.return_value = 'test-pass' # Call twice to verify that the user is only prompted once. result = vault._ask_vault_pass() self.assertEqual('test-pass', result) mock_getpass.assert_called_once_with(""Vault password: "") result = vault._ask_vault_pass() self.assertEqual('test-pass', result) mock_getpass.assert_called_once_with(""Vault password: "") @mock.patch.object(utils, 'read_file') def test__read_vault_password_file(self, mock_read): mock_read.return_value = ""test-pass\n"" result = vault._read_vault_password_file(""/path/to/file"") self.assertEqual(""test-pass"", result) mock_read.assert_called_once_with(""/path/to/file"") def test_update_environment_no_vault(self): parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([]) env = {} vault.update_environment(parsed_args, env) self.assertEqual({}, env) @mock.patch.object(vault, '_ask_vault_pass') def test_update_environment_prompt(self, mock_ask): mock_ask.return_value = ""test-pass"" parser = argparse.ArgumentParser() vault.add_args(parser) parsed_args = parser.parse_args([""--ask-vault-pass""]) env = {} vault.update_environment(parsed_args, env) self.assertEqual({""KAYOBE_VAULT_PASSWORD"": ""test-pass""}, env) mock_ask.assert_called_once_with() @mock.patch.object(vault, '_read_vault_password_file') def test_update_environment_file(self, mock_read): mock_read.return_value = ""test-pass"" parser = argparse.ArgumentParser() vault.add_args(parser) args = [""--vault-password-file"", ""/path/to/file""] parsed_args = parser.parse_args(args) env = {} vault.update_environment(parsed_args, env) self.assertEqual({""KAYOBE_VAULT_PASSWORD"": ""test-pass""}, env) mock_read.assert_called_once_with(""/path/to/file"") ",,262,62
openstack%2Fceilometer~master~I6b262dd440a72f25662b64d938ab9e5328709a97,openstack/ceilometer,master,I6b262dd440a72f25662b64d938ab9e5328709a97,Remove deprecated storage drivers,MERGED,2017-10-17 16:29:05.000000000,2019-02-11 11:10:12.000000000,2017-10-27 10:04:24.000000000,"[{'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 15843}, {'_account_id': 22348}, {'_account_id': 22752}, {'_account_id': 26159}]","[{'number': 1, 'created': '2017-10-17 16:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1ac3269523b172ffb1bab332a27c343ffb357ade', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 2, 'created': '2017-10-18 07:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d1f3407922f5e028af03a8f31931f5f2f3ce59ba', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 3, 'created': '2017-10-18 07:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6494ec3cc2c38f62fcb801ed7b81bc9321f40943', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 4, 'created': '2017-10-18 07:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/51b865b4e89e77fd7e3beb4bc2167209a68e8a36', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 5, 'created': '2017-10-18 16:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/475ea8775f563f83fb832a17d72be194dba1ef28', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 6, 'created': '2017-10-18 16:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c35576bbcc07b0f1b6a6b9b472e1b8990f8693a', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 7, 'created': '2017-10-19 08:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cff4404509230f9d1cb42752f61144e4c0048aab', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 8, 'created': '2017-10-19 11:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5de2c166063c2c636a41b6a029efc0aa2c4e3c46', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 9, 'created': '2017-10-23 14:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f3590c9d0cd47f1a69eb65a59ed9507ec30876a3', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 10, 'created': '2017-10-23 16:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/565d557d6d51a49bdccf9813dbbc4c7756052680', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 11, 'created': '2017-10-24 16:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/07c18c56ce0cc5ad00fa99721643b1b59e0f8e19', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 12, 'created': '2017-10-24 18:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/28fe2ec8f4cfa4416b4ccf5d89503eeb56915b99', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 13, 'created': '2017-10-25 07:06:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/823cb072b4832c6c281ea22334835e45de29c6fa', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 14, 'created': '2017-10-25 09:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c5e8e69400ea8c05704a6e39acaefe4c43cc19df', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 15, 'created': '2017-10-25 12:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2c18c1d7aba7870567bba8baf85ee4dc25c68e4a', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 16, 'created': '2017-10-25 16:16:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dadefef3b8e9c81865c9b30763b9e9ebecbab498', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}, {'number': 17, 'created': '2017-10-26 07:35:30.000000000', 'files': ['doc/source/contributor/testing.rst', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/021_add_event_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/029_sample_recorded_at.py', 'test-requirements.txt', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/010_add_index_to_meter.py', 'ceilometer/tests/unit/storage/test_base.py', 'ceilometer/tests/functional/storage/test_impl_log.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/service.py', 'ceilometer/storage/sqlalchemy/migrate_repo/manage.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/014_add_event_message_id.py', 'ceilometer/tests/unit/storage/sqlalchemy/test_models.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/004_add_counter_unit.py', 'ceilometer/storage/hbase/migration.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/030_rename_meter_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/012_add_missing_foreign_keys.py', 'etc/ceilometer/ceilometer-config-generator.conf', 'ceilometer/tests/unit/dispatcher/test_db.py', 'ceilometer/storage/models.py', 'ceilometer/storage/hbase/base.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/028_alembic_migrations.py', 'ceilometer/storage/hbase/__init__.py', 'devstack/upgrade/upgrade.sh', 'ceilometer/tests/functional/__init__.py', 'ceilometer/tests/unit/test_bin.py', 'ceilometer/tests/functional/publisher/test_direct.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/009_event_strings.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/016_simpler_alarm.py', 'ceilometer/storage/sqlalchemy/utils.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/036_drop_sourceassoc_resource_tables.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/034_drop_dump_tables.py', 'ceilometer/tests/functional/storage/test_storage_scenarios.py', 'ceilometer/dispatcher/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/026_float_size.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/019_alarm_history_detail_is_text.py', 'doc/source/install/install-base-config-common.inc', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/007_add_alarm_table.py', 'ceilometer/tests/unit/event/test_endpoint.py', 'ceilometer/storage/hbase/inmemory.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/005_remove_resource_timestamp.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/023_sqlite_upgrade.sql', 'ceilometer/tests/functional/storage/test_impl_hbase.py', 'requirements.txt', 'bindep.txt', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/023_add_trait_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/042_add_raw_column.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/044_restore_long_uuid_data_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/021_sqlite_upgrade.sql', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/038_normalise_tables.py', 'ceilometer/storage/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/022_metadata_int_is_bigint.py', 'ceilometer/storage/sqlalchemy/models.py', 'tools/migrate_data_to_gnocchi.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/024_event_use_floatingprecision.py', '.zuul.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/006_counter_volume_is_float.py', 'ceilometer/tests/unit/storage/sqlalchemy/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/013_rename_counter_to_meter_alarm.py', 'playbooks/legacy/ceilometer-dsvm-functional-mongodb/run.yaml', 'doc/source/admin/telemetry-data-pipelines.rst', 'ceilometer/tests/unit/storage/test_get_connection.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/045_add_resource_metadatahash_index.py', 'ceilometer/tests/functional/storage/__init__.py', 'playbooks/legacy/ceilometer-dsvm-functional-mongodb/post.yaml', 'ceilometer/event/models.py', 'tools/make_test_data.py', 'ceilometer/tests/functional/storage/test_impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/033_alarm_id_rename.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/035_drop_user_project_tables.py', 'doc/source/contributor/install/manual.rst', 'ceilometer/opts.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/020_add_metadata_tables.py', 'ceilometer/tests/unit/storage/__init__.py', 'ceilometer/storage/pymongo_base.py', 'playbooks/legacy/ceilometer-tox-py27-mysql/run.yaml', 'playbooks/legacy/ceilometer-dsvm-functional-mysql/post.yaml', 'ceilometer/dispatcher/database.py', 'ceilometer/storage/impl_log.py', 'playbooks/legacy/ceilometer-tox-py27-postgresql/post.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/011_indexes_cleanup.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/017_convert_timestamp_as_datetime_to_decimal.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/040_add_alarm_severity.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/tests/mocks.py', 'run-tests.sh', 'ceilometer/storage/sqlalchemy/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/041_expand_event_traits.py', 'playbooks/legacy/ceilometer-tox-py27-mysql/post.yaml', 'ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/sqlalchemy/migration.py', 'setup.cfg', 'tox.ini', 'ceilometer/tests/db.py', 'ceilometer/tests/functional/publisher/__init__.py', 'ceilometer/tests/functional/hooks/post_test_hook.sh', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/032_add_alarm_time_constraints.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/001_add_meter_table.py', 'ceilometer/tests/unit/test_notification.py', 'playbooks/legacy/ceilometer-tox-py27-mongodb/run.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/__init__.py', 'doc/source/contributor/new_resource_types.rst', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/025_alarm_use_floatingprecision.py', 'ceilometer/storage/sqlalchemy/migrate_repo/README', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/003_set_utf8_charset.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/031_add_new_meter_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/043_reduce_uuid_data_types.py', 'doc/source/contributor/install/custom.rst', 'ceilometer/publisher/direct.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/008_add_events.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/037_sample_index_cleanup.py', 'ceilometer/tests/unit/dispatcher/test_dispatcher.py', 'ceilometer/tests/functional/storage/test_pymongo_base.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/015_add_alarm_history_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/018_resource_resource_metadata_is_text.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/039_event_floatingprecision_pgsql.py', 'playbooks/legacy/ceilometer-dsvm-functional-mysql/run.yaml', 'playbooks/legacy/ceilometer-tox-py27-postgresql/run.yaml', 'ceilometer/storage/base.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/tests/unit/dispatcher/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/migrate.cfg', 'devstack/plugin.sh', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/mongo/__init__.py', 'tools/make_test_data.sh', 'playbooks/legacy/ceilometer-tox-py27-mongodb/post.yaml', 'ceilometer/cmd/storage.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/027_remove_alarm_fk_constraints.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/002_remove_duration.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9323f07f977f320882f8b536c3b54835274826fc', 'message': 'Remove deprecated storage drivers\n\nChange-Id: I6b262dd440a72f25662b64d938ab9e5328709a97\n'}]",4,512700,9323f07f977f320882f8b536c3b54835274826fc,61,7,17,1669,,,0,"Remove deprecated storage drivers

Change-Id: I6b262dd440a72f25662b64d938ab9e5328709a97
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/00/512700/16 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/testing.rst', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/021_add_event_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/029_sample_recorded_at.py', 'test-requirements.txt', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/010_add_index_to_meter.py', 'ceilometer/tests/functional/test_notification.py', 'ceilometer/tests/unit/storage/test_base.py', 'ceilometer/tests/functional/storage/test_impl_log.py', 'ceilometer/storage/impl_sqlalchemy.py', 'ceilometer/service.py', 'ceilometer/storage/sqlalchemy/migrate_repo/manage.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/014_add_event_message_id.py', 'ceilometer/tests/unit/storage/sqlalchemy/test_models.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/004_add_counter_unit.py', 'ceilometer/storage/hbase/migration.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/030_rename_meter_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/012_add_missing_foreign_keys.py', 'etc/ceilometer/ceilometer-config-generator.conf', 'ceilometer/tests/unit/dispatcher/test_db.py', 'ceilometer/storage/models.py', 'ceilometer/storage/hbase/base.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/028_alembic_migrations.py', 'ceilometer/storage/hbase/__init__.py', 'devstack/upgrade/upgrade.sh', 'ceilometer/tests/functional/publisher/test_direct.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/009_event_strings.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/016_simpler_alarm.py', 'ceilometer/storage/sqlalchemy/utils.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/036_drop_sourceassoc_resource_tables.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/034_drop_dump_tables.py', 'ceilometer/tests/functional/storage/test_storage_scenarios.py', 'ceilometer/dispatcher/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/026_float_size.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/019_alarm_history_detail_is_text.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/007_add_alarm_table.py', 'ceilometer/storage/hbase/inmemory.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/005_remove_resource_timestamp.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/023_sqlite_upgrade.sql', 'ceilometer/tests/functional/storage/test_impl_hbase.py', 'requirements.txt', 'bindep.txt', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/023_add_trait_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/042_add_raw_column.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/044_restore_long_uuid_data_types.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/021_sqlite_upgrade.sql', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/038_normalise_tables.py', 'ceilometer/storage/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/022_metadata_int_is_bigint.py', 'ceilometer/storage/sqlalchemy/models.py', 'tools/migrate_data_to_gnocchi.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/024_event_use_floatingprecision.py', '.zuul.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/006_counter_volume_is_float.py', 'ceilometer/tests/unit/storage/sqlalchemy/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/013_rename_counter_to_meter_alarm.py', 'playbooks/legacy/ceilometer-dsvm-functional-mongodb/run.yaml', 'doc/source/admin/telemetry-data-pipelines.rst', 'ceilometer/tests/unit/storage/test_get_connection.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/045_add_resource_metadatahash_index.py', 'ceilometer/tests/functional/storage/__init__.py', 'playbooks/legacy/ceilometer-dsvm-functional-mongodb/post.yaml', 'tools/make_test_data.py', 'ceilometer/tests/functional/storage/test_impl_mongodb.py', 'ceilometer/storage/impl_hbase.py', 'ceilometer/event/storage/models.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/033_alarm_id_rename.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/035_drop_user_project_tables.py', 'doc/source/contributor/install/manual.rst', 'ceilometer/opts.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/020_add_metadata_tables.py', 'ceilometer/tests/unit/storage/__init__.py', 'ceilometer/storage/pymongo_base.py', 'playbooks/legacy/ceilometer-tox-py27-mysql/run.yaml', 'playbooks/legacy/ceilometer-dsvm-functional-mysql/post.yaml', 'ceilometer/dispatcher/database.py', 'ceilometer/storage/impl_log.py', 'playbooks/legacy/ceilometer-tox-py27-postgresql/post.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/011_indexes_cleanup.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/017_convert_timestamp_as_datetime_to_decimal.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/040_add_alarm_severity.py', 'ceilometer/storage/mongo/utils.py', 'ceilometer/tests/mocks.py', 'run-tests.sh', 'ceilometer/tests/functional/test_bin.py', 'ceilometer/storage/sqlalchemy/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/041_expand_event_traits.py', 'playbooks/legacy/ceilometer-tox-py27-mysql/post.yaml', 'ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/sqlalchemy/migration.py', 'setup.cfg', 'tox.ini', 'ceilometer/tests/db.py', 'ceilometer/tests/functional/publisher/__init__.py', 'ceilometer/tests/functional/hooks/post_test_hook.sh', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/032_add_alarm_time_constraints.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/001_add_meter_table.py', 'playbooks/legacy/ceilometer-tox-py27-mongodb/run.yaml', 'ceilometer/storage/sqlalchemy/migrate_repo/__init__.py', 'ceilometer/models.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/025_alarm_use_floatingprecision.py', 'ceilometer/storage/sqlalchemy/migrate_repo/README', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/003_set_utf8_charset.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/031_add_new_meter_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/043_reduce_uuid_data_types.py', 'ceilometer/publisher/direct.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/008_add_events.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/037_sample_index_cleanup.py', 'ceilometer/tests/unit/dispatcher/test_dispatcher.py', 'ceilometer/tests/functional/storage/test_pymongo_base.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/015_add_alarm_history_table.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/018_resource_resource_metadata_is_text.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/039_event_floatingprecision_pgsql.py', 'playbooks/legacy/ceilometer-dsvm-functional-mysql/run.yaml', 'playbooks/legacy/ceilometer-tox-py27-postgresql/run.yaml', 'ceilometer/storage/hbase/utils.py', 'ceilometer/tests/unit/dispatcher/__init__.py', 'ceilometer/storage/sqlalchemy/migrate_repo/migrate.cfg', 'devstack/plugin.sh', 'ceilometer/storage/impl_mongodb.py', 'ceilometer/storage/mongo/__init__.py', 'tools/make_test_data.sh', 'playbooks/legacy/ceilometer-tox-py27-mongodb/post.yaml', 'ceilometer/cmd/storage.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/027_remove_alarm_fk_constraints.py', 'ceilometer/storage/sqlalchemy/migrate_repo/versions/002_remove_duration.py']",126,1ac3269523b172ffb1bab332a27c343ffb357ade,remove-ceilometer-api,,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from sqlalchemy import Column from sqlalchemy import Integer from sqlalchemy import MetaData from sqlalchemy import Table def upgrade(migrate_engine): meta = MetaData(bind=migrate_engine) meter = Table('meter', meta, autoload=True) duration = Column('counter_duration', Integer) meter.drop_column(duration) ",49,12785
openstack%2Fsecurity-doc~master~I58964cd14bfc22d278b701975e35dde368c91dd8,openstack/security-doc,master,I58964cd14bfc22d278b701975e35dde368c91dd8,Imported Translations from Zanata,MERGED,2019-02-11 09:02:22.000000000,2019-02-11 10:53:34.000000000,2019-02-11 10:53:34.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 09:02:22.000000000', 'files': ['security-guide/source/locale/de/LC_MESSAGES/security-guide.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/824524451d5dad2767c61286ea4ee1b142dd8cb3', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I58964cd14bfc22d278b701975e35dde368c91dd8\n'}]",0,636104,824524451d5dad2767c61286ea4ee1b142dd8cb3,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I58964cd14bfc22d278b701975e35dde368c91dd8
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/04/636104/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/locale/de/LC_MESSAGES/security-guide.po'],1,824524451d5dad2767c61286ea4ee1b142dd8cb3,zanata/translations,"# Andreas Jaeger <jaegerandi@gmail.com>, 2019. #zanata""POT-Creation-Date: 2019-01-19 08:53+0000\n""""PO-Revision-Date: 2019-02-11 07:55+0000\n"" ""Last-Translator: Andreas Jaeger <jaegerandi@gmail.com>\n""""Once a user is authenticated, a token is generated for authorization and "" ""access to an OpenStack environment. A token can have a variable life span; "" ""however the default value for expiry is one hour. The recommended expiry "" ""value should be set to a lower value that allows enough time for internal "" ""services to complete tasks. In the event that the token expires before tasks "" ""complete, the cloud may become unresponsive or stop providing services. An "" ""example of expended time during use would be the time needed by the Compute "" ""service to transfer a disk image onto the hypervisor for local caching. "" ""Fetching expired tokens when using a valid service token is allowed."" msgstr """" ""Sobald ein Benutzer authentifiziert ist, wird ein Token fr die "" ""Autorisierung und den Zugriff auf eine OpenStack-Umgebung generiert. Ein "" ""Token kann eine variable Lebensdauer haben. Der Vorgabewert fr das "" ""Auslaufen betrgt jedoch eine Stunde. Der empfohlene Verfallwert sollte auf "" ""einen niedrigeren Wert gesetzt werden, der gengend Zeit fr interne Dienste "" ""zur Ausfhrung von Aufgaben bietet. In dem Fall, dass das Token abluft, "" ""bevor Aufgaben abgeschlossen sind, kann die Cloud nicht mehr reagieren oder "" ""die Bereitstellung von Diensten beenden. Ein Beispiel fr die verbrauchte "" ""Zeit whrend des Gebrauchs wre die Zeit, die der Compute-Dienst bentigt, "" ""um ein Disk-Image auf den Hypervisor fr die lokale Zwischenspeicherung zu "" ""bertragen. Es ist erlaubt ein abgelaufenes Token abzurufen whrend ein "" ""valides Service Token benutzt wird."" msgid """"""The following example shows a PKI token. Note that token ID values are "" ""typically 3500 bytes. In this example, the value has been truncated."" msgstr """" ""Das folgende Beispiel zeigt ein PKI-Token. Beachten Sie, dass Token-ID-Werte "" ""typischerweise 3500 Bytes sind. In diesem Beispiel wurde der Wert "" ""abgeschnitten."" msgid """"","""POT-Creation-Date: 2019-01-18 09:42+0000\n""""PO-Revision-Date: 2019-01-11 03:31+0000\n"" ""Last-Translator: Robert Simai <robert.simai@suse.com>\n""",36,3
openstack%2Fnova~master~If9b72290d3e7faa486dc0d3a7b2e4a6928705011,openstack/nova,master,If9b72290d3e7faa486dc0d3a7b2e4a6928705011,doc: link Kashyap's cpu model talk to the libvirt driver config docs,MERGED,2019-02-04 16:09:58.000000000,2019-02-11 10:46:30.000000000,2019-02-04 23:27:04.000000000,"[{'_account_id': 6962}, {'_account_id': 7166}, {'_account_id': 14070}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-04 16:09:58.000000000', 'files': ['doc/source/admin/configuration/hypervisor-kvm.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3251c3f9fee8fc2f808889ba2fc0d80ffeb7a66', 'message': ""doc: link Kashyap's cpu model talk to the libvirt driver config docs\n\nChange-Id: If9b72290d3e7faa486dc0d3a7b2e4a6928705011\n""}]",2,634731,d3251c3f9fee8fc2f808889ba2fc0d80ffeb7a66,13,7,1,6873,,,0,"doc: link Kashyap's cpu model talk to the libvirt driver config docs

Change-Id: If9b72290d3e7faa486dc0d3a7b2e4a6928705011
",git fetch https://review.opendev.org/openstack/nova refs/changes/31/634731/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/configuration/hypervisor-kvm.rst'],1,d3251c3f9fee8fc2f808889ba2fc0d80ffeb7a66,kvm-cpu-model-video,.. todo:: Some of this is installation guide material and should probably beSee `Effective Virtual CPU configuration in Nova`_ for a recorded presentation about this topic. .. _Effective Virtual CPU configuration in Nova: https://www.openstack.org/videos/summits/berlin-2018/effective-virtual-cpu-configuration-in-nova ,.. todo:: This is really installation guide material and should probably be,6,1
openstack%2Fnova~master~I001beb2840496f7950988acc69018244847aa888,openstack/nova,master,I001beb2840496f7950988acc69018244847aa888,Per-instance serial number,MERGED,2018-11-26 03:50:43.000000000,2019-02-11 10:10:08.000000000,2019-02-04 22:22:31.000000000,"[{'_account_id': 4393}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9373}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 25113}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-26 03:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8aa859096268f1c7781e59fb64488a1982525635', 'message': 'WIP per instance serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 2, 'created': '2018-11-26 07:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57b924a6ddabe8b8d187d710515452bec84c4f81', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nIf not set, the serial number in the guest will be based on the\n``[libvirt]/sysinfo_serial`` configuration like it is currently.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 3, 'created': '2018-11-28 07:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/52597f07bde8c86796fc106b410febf1a20c0bed', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nIf not set, the serial number in the guest will be based on the\n``[libvirt]/sysinfo_serial`` configuration like it is currently.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 4, 'created': '2019-01-15 10:45:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/397f7ea9f686eaf8d0ca8f267f26e29ded710bb3', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 5, 'created': '2019-01-17 07:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5d9762dbf9748e5facd6e1779cad046d6b41774e', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 6, 'created': '2019-01-22 09:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/38e5e33aaf9f8d241b04763b5d186cbbff2a540a', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 7, 'created': '2019-01-23 08:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5158327bc8a2fbc4c3cabcf3fd964e5f61285fa1', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 8, 'created': '2019-02-01 09:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5158b509703a111c3f1cd5dde05dfa5e50a81f20', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 9, 'created': '2019-02-02 02:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fda1655fdcb0504120c8061b97b46eb52fdaabdc', 'message': 'Per-instance serial number\n\nA new flavor extra spec ``hw:unique_serial`` and corresponding\nimage property ``hw_unique_serial`` will be introduced which\nwhen either is set to ``True`` will result in the guest serial\nnumber being set to the instance UUID.\n\nAlso added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}, {'number': 10, 'created': '2019-02-03 03:02:13.000000000', 'files': ['releasenotes/notes/per-instance-serial-f2e597cb05d1b09e.yaml', 'nova/virt/libvirt/driver.py', 'nova/conf/libvirt.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dec5dd9286e0d218d3f7658879369b5d4a529a65', 'message': 'Per-instance serial number\n\nAdded a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``\nconfiguration which if set will result in the guest serial number\nbeing set to ``instance.uuid`` on this host. It is also made to be\nthe default value of ``[libvirt]/sysinfo_serial`` config option.\n\nImplements: blueprint per-instance-libvirt-sysinfo-serial\n\nChange-Id: I001beb2840496f7950988acc69018244847aa888\n'}]",62,619953,dec5dd9286e0d218d3f7658879369b5d4a529a65,192,22,10,15888,,,0,"Per-instance serial number

Added a new ``unique`` choice to the ``[libvirt]/sysinfo_serial``
configuration which if set will result in the guest serial number
being set to ``instance.uuid`` on this host. It is also made to be
the default value of ``[libvirt]/sysinfo_serial`` config option.

Implements: blueprint per-instance-libvirt-sysinfo-serial

Change-Id: I001beb2840496f7950988acc69018244847aa888
",git fetch https://review.opendev.org/openstack/nova refs/changes/53/619953/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/objects/image_meta.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",3,8aa859096268f1c7781e59fb64488a1982525635,bp/per-instance-libvirt-sysinfo-serial," def test_get_guest_config_with_unique_serial(self): drvr = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) instance_ref = objects.Instance(**self.test_instance) # Test with image properties image_meta = objects.ImageMeta.from_dict({ ""disk_format"": ""raw"", ""properties"": {""hw_unique_serial"": True}}) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref, image_meta) cfg = drvr._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(cfg.sysinfo.system_serial, instance_ref.uuid) # Test with flavor extra specs image_meta.properties = {} instance_ref.flavor.extra_specs = {'hw:unique_serial': True} disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref, image_meta) cfg = drvr._get_guest_config(instance_ref, [], image_meta, disk_info) self.assertEqual(cfg.sysinfo.system_serial, instance_ref.uuid) ",,44,4
openstack%2Fhorizon~master~I0f8a00ad57e6e6d5fca93f9c937ffe464d574557,openstack/horizon,master,I0f8a00ad57e6e6d5fca93f9c937ffe464d574557,Imported Translations from Zanata,MERGED,2019-02-11 08:33:32.000000000,2019-02-11 10:08:50.000000000,2019-02-11 10:08:50.000000000,"[{'_account_id': 841}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 08:33:32.000000000', 'files': ['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d5b7feb5d4bf622905d717cd20fc83fd136c8a8c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I0f8a00ad57e6e6d5fca93f9c937ffe464d574557\n'}]",0,636102,d5b7feb5d4bf622905d717cd20fc83fd136c8a8c,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I0f8a00ad57e6e6d5fca93f9c937ffe464d574557
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/636102/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po']",2,d5b7feb5d4bf622905d717cd20fc83fd136c8a8c,zanata/translations,,"# OpenStack Infra <zanata@openstack.org>, 2015. #zanata # Joris S'heeren <joris.sheeren@gmail.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: horizon VERSION\n"" ""Report-Msgid-Bugs-To: https://bugs.launchpad.net/openstack-i18n/\n"" ""POT-Creation-Date: 2019-01-05 15:24+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-03-04 12:36+0000\n"" ""Last-Translator: Joris S'heeren <joris.sheeren@gmail.com>\n"" ""Language-Team: Dutch (Netherlands)\n"" ""Language: nl_NL\n"" ""X-Generator: Zanata 4.3.3\n"" ""Plural-Forms: nplurals=2; plural=(n != 1)\n"" msgid "" - End"" msgstr ""- Einde"" msgid "" : Next hop"" msgstr "": Volgende punt"" #, python-format msgid ""%(field_name)s: Invalid IP address (value=%(ip)s)"" msgstr ""%(field_name)s: Invalide IP adres (waarde=%(ip)s)"" #, python-format msgid ""%(field_name)s: Invalid IP address (value=%(network)s)"" msgstr ""%(field_name)s: Invalide IP adres (waarde=%(network)s)"" #, python-format msgid ""%(name)s - %(size)s GB (%(label)s)"" msgstr ""%(name)s - %(size)s GB (%(label)s)"" #, python-format msgid ""%(type)s (%(backend)s backend)"" msgstr ""%(type)s (%(backend)s achterkant)"" #, python-format msgid ""%s (current)"" msgstr ""%s (huidig)"" #, python-format msgid ""%s GB"" msgstr ""%s GB"" #, python-format msgid ""%s instances"" msgstr ""%s exemplaren"" #, python-format msgid ""%sGB"" msgstr ""%sGB"" #, python-format msgid ""%sMB"" msgstr ""%sMB"" msgid ""(Quota exceeded)"" msgstr ""(quota overschreden)"" msgid "", add project groups"" msgstr "", projectgroepen toevoegen"" msgid "", update project groups"" msgstr "", projectgroepen bijwerken"" msgid ""-"" msgstr ""-"" msgid ""A local image to upload."" msgstr ""Een lokale afbeelding om te uploaden."" msgid """" ""A script or set of commands to be executed after the instance has been built "" ""(max 16kb)."" msgstr """" ""Een script of set commando's dat uitgevoerd wordt nadat het exemplaar is "" ""gebouwd (maximaal 16kb)."" msgid ""AKI - Amazon Kernel Image"" msgstr ""AKI - Amazon Kernel Afbeelding"" #, python-format msgid ""ALLOW %(ethertype)s %(proto_port)s %(direction)s %(remote)s"" msgstr ""TOESTAAN %(ethertype)s %(proto_port)s %(direction)s %(remote)s"" msgid ""AMI - Amazon Machine Image"" msgstr ""AMI - Amazon Machine Afbeelding"" msgid ""API Access"" msgstr ""API toegang"" msgid ""API Endpoints"" msgstr ""API eindpunten"" msgid ""ARI - Amazon Ramdisk Image"" msgstr ""ARI - Amazon Geheugenschijf Afbeelding"" msgid ""Access & Security"" msgstr ""Toegang & Beveiliging"" msgid ""Action"" msgstr ""Actie"" msgctxt ""Current status of a Floating IP"" msgid ""Active"" msgstr ""Actief"" msgctxt ""Current status of a Network"" msgid ""Active"" msgstr ""Actief"" msgctxt ""Current status of an Image"" msgid ""Active"" msgstr ""Actief"" msgctxt ""Current status of an Instance"" msgid ""Active"" msgstr ""Actief"" msgctxt ""current status of port"" msgid ""Active"" msgstr ""Actief"" msgctxt ""current status of router"" msgid ""Active"" msgstr ""Actief"" msgctxt ""status of a network port"" msgid ""Active"" msgstr ""Actief"" msgid ""Add"" msgstr ""Toevoegen"" msgid ""Add DHCP Agent"" msgstr ""Voeg DHCP Agent Toe"" msgid ""Add Group Assignment"" msgstr ""Groepstoewijzing toevoegen"" msgid ""Add Interface"" msgstr ""Aansluiting toevoegen"" msgid ""Add Rule"" msgstr ""Regel toevoegen"" msgid ""Add User to Group"" msgstr ""Gebruiker toevoegen aan groep"" msgid ""Add/Remove Hosts to Aggregate"" msgstr ""Toevoegen/verwijderen van gastheren aan het aggregaat"" msgid ""Admin"" msgstr ""Beheerder"" msgid ""Admin State"" msgstr ""Beheertoestand"" msgid ""Advanced Options"" msgstr ""Geavanceerde opties"" msgid """" ""After launching an instance, you login using the private key (the username "" ""might be different depending on the image you launched):"" msgstr """" ""Na het starten van een exemplaar logt u in met de prive sleutel (de "" ""gebruikersnaam kan verschillen, afhankelijk van de gestartte afbeelding):"" msgid ""All Available Hosts"" msgstr ""Alle beschikbare gastheren"" msgid ""All Groups"" msgstr ""Alle groepen"" msgid ""All Hypervisors"" msgstr ""Alle Hypervisors"" msgid ""All ICMP"" msgstr ""Alle ICMP"" msgid ""All Projects"" msgstr ""Alle projecten"" msgid ""All Security Groups"" msgstr ""Alle beveiligingsgroepen"" msgid ""All TCP"" msgstr ""Alle TCP"" msgid ""All UDP"" msgstr ""Alle UDP"" msgid ""All Users"" msgstr ""Alle gebruikers"" msgid ""All available hosts"" msgstr ""Alle beschikbare gastheren"" msgid ""Allocate Floating IP"" msgstr ""Vlottend IP toewijzen"" msgid ""Allocate IP"" msgstr "" IP Toewijzen"" msgid ""Allocate IP To Project"" msgstr ""IP toewijzen aan project"" msgid ""Allocate a floating IP from a given floating IP pool."" msgstr ""Wijst u een vlottend IP toe van een gegeven vlottende IP poule."" #, python-format msgid ""Allocated Floating IP %(ip)s."" msgstr ""Vlottend IP %(ip)s toegewezen."" msgid ""Allocation Pools"" msgstr ""Allocatiepoules"" msgid """" ""An instance can be launched with varying types of attached storage. You may "" ""select from those options here."" msgstr """" ""Een exemplaar kan gestart worden met verschillende typen aangekoppelde "" ""opslag. Selecteert u uit de hier gegeven opties."" msgid """" ""An unexpected error has occurred. Try refreshing the page. If that doesn't "" ""help, contact your local administrator."" msgstr """" ""Er is een onverwachte fout opgetreden. Probeert u de pagina te verversen. "" ""Neem contact op met uw lokale beheerder als dat niet helpt."" msgid ""Any"" msgstr ""Elke"" msgid ""Any Availability Zone"" msgstr ""Elke beschikbaarheidszone"" msgid ""Architecture"" msgstr ""Architectuur"" msgid ""Associate"" msgstr ""Aankoppelen"" msgid ""Associate Floating IP"" msgstr ""Vlottend IP adres aankoppelen"" msgid ""At least one network must be specified."" msgstr ""Minimaal n netwerk dient te worden gespecificeerd."" msgid ""Attach To Instance"" msgstr ""Koppel aan exemplaar"" msgid ""Attach Volume"" msgstr ""Volume aankoppelen"" msgid ""Attach to Instance"" msgstr ""Aankoppelen aan exemplaar"" msgid ""Attached"" msgstr ""Aangekoppeld"" msgid ""Attached Device"" msgstr ""Aangekoppeld apparaat"" msgid ""Attached To"" msgstr ""Aangekoppeld aan"" #, python-format msgid ""Attaching volume %(vol)s to instance %(inst)s on %(dev)s."" msgstr ""Volume %(vol)s aan het koppelen aan exemplaar %(inst)s op %(dev)s."" msgid ""Attachments"" msgstr ""Aankoppelingen"" msgid ""Authorization Key"" msgstr ""Autorisatiesleutel"" msgid ""Automatic"" msgstr ""Automatisch"" msgid ""Availability Zone"" msgstr ""Beschikbaarheidszone"" msgid ""Availability Zone Name"" msgstr ""Naam beschikbaarheidszone"" msgid ""Availability Zones"" msgstr ""Beschikbaarheidszones"" msgid ""Available"" msgstr ""Beschikbaar"" msgctxt ""Current status of a Volume"" msgid ""Available"" msgstr ""Beschikbaar"" msgctxt ""Current status of a Volume Backup"" msgid ""Available"" msgstr ""Beschikbaar"" msgid ""Available Types"" msgstr ""Beschikbare Types"" msgid ""Available networks"" msgstr ""Beschikbare netwerken"" msgid ""Backups"" msgstr ""Archieven"" msgid ""Block Migration"" msgstr ""Blokmigratie"" msgid ""Block Storage Services"" msgstr ""Blokkeer Opslagservices"" msgid ""Boot from image"" msgstr ""Opstarten vanaf afbeelding"" msgid ""Boot from image (creates a new volume)"" msgstr ""Opstarten vanaf afbeelding (maakt een nieuw volume aan)"" msgid ""Boot from snapshot"" msgstr ""Opstarten vanaf momentopname"" msgid ""Boot from volume"" msgstr ""Opstarten vanaf volume"" msgid ""Boot from volume snapshot (creates a new volume)"" msgstr ""Opstarten vanaf volume momentopname (creert een nieuw volume)"" msgid ""CIDR"" msgstr ""CIDR"" msgid ""CIDR must be specified."" msgstr ""CIDR moet worden gespecificeerd."" msgid ""Cancel"" msgstr ""Annuleren"" msgid ""Change"" msgstr ""Wijzigen"" msgid ""Change Password"" msgstr ""Wachtwoord wijzigen"" msgid ""Change your password. We highly recommend you create a strong one. "" msgstr """" ""Verander uw wachtwoord. We raden ten zeerste aan dat u een sterk wachtwoord "" ""creert."" msgid ""Changing password is not supported."" msgstr ""Wijzigen van het wachtwoord wordt niet ondersteund."" msgid ""Checksum"" msgstr ""Controlesom"" msgid ""Choose Your Boot Source Type."" msgstr ""Kies uw opstartbrontype."" msgid ""Choose a Host to migrate to."" msgstr ""Kies een Host om naar te verplaatsen."" msgid """" ""Choose a key pair name you will recognise and paste your SSH public key into "" ""the space provided."" msgstr """" ""Kies een sleutelpaarnaam die herkenbaar is en plak de publieke SSH sleutel "" ""in de beschikbare ruimte."" msgid ""Choose a snapshot"" msgstr ""Kies een momentopname"" msgid ""Choose a volume"" msgstr ""Selecteer een volume"" msgid ""Choose an image"" msgstr ""Kies een afbeelding"" msgid ""Choose the flavor to launch."" msgstr ""Kies de te starten smaak."" msgid ""Clear Domain Context"" msgstr ""Domeincontext wissen"" msgid ""Click here to show only console"" msgstr ""Klik hier om alleen het beheervenster weer te geven"" msgid ""Close"" msgstr ""Sluiten"" msgid ""Code"" msgstr ""Code"" msgid ""Compute"" msgstr ""Rekenen"" msgid ""Compute Services"" msgstr ""Rekendiensten"" msgid ""Configuration Drive"" msgstr ""Configuratieschijf"" msgid ""Confirm Password"" msgstr ""Bevestig wachtwoord"" msgid ""Confirm Rebuild Password"" msgstr ""Bevestig herbouw wachtwoord"" msgid ""Confirm Resize/Migrate"" msgstr ""Bevestig herdimensionering/migratie"" msgid ""Confirm new password"" msgstr ""bevestig nieuwe wachtwoord"" msgctxt ""Current status of an Instance"" msgid ""Confirm or Revert Resize/Migrate"" msgstr ""Bevestig of herstel herdimensionering of verplaatsing"" msgctxt ""Task status of an Instance"" msgid ""Confirming Resize or Migrate"" msgstr ""Herdimensionering of verplaatsing aan het bevestigen"" msgid ""Console"" msgstr ""Beheervenster"" msgid ""Container Format"" msgstr ""Houderformaat"" msgid ""Container Name"" msgstr ""Houdernaam"" msgid ""Containers"" msgstr ""Houders"" msgid ""Contents"" msgstr ""Inhouden"" msgid """" ""Control access to your instance via key pairs, security groups, and other "" ""mechanisms."" msgstr """" ""Beheers toegang tot uw exemplaar middels sleutelparen, beveiligingsgroepen "" ""en andere mechanismen."" #, python-format msgid ""Could not find default role \""%s\"" in Keystone"" msgstr ""Kon de standaardrol \""%s\"" niet vinden in Keystone"" msgctxt ""Power state of an Instance"" msgid ""Crashed"" msgstr ""Gecrasht"" msgid ""Create"" msgstr ""Creren"" msgctxt ""Action log of an instance"" msgid ""Create"" msgstr ""Creren"" msgid ""Create An Image"" msgstr ""Creer een afbeelding"" msgid ""Create Backup"" msgstr ""Creer archief"" msgid ""Create Domain"" msgstr ""Creer domein"" msgid ""Create Flavor"" msgstr ""Creer smaak"" msgid ""Create Group"" msgstr ""Creer groep"" msgid ""Create Host Aggregate"" msgstr ""Aanmaken gastheersaggregaat"" msgid ""Create Image"" msgstr ""Creer afbeelding"" msgid ""Create Key Pair"" msgstr ""Sleutelpaar aanmaken"" msgid ""Create Network"" msgstr ""Creer netwerk"" msgid ""Create Port"" msgstr ""Creer poort"" msgid ""Create Project"" msgstr ""Creer project"" msgid ""Create Role"" msgstr ""Creer rol"" msgid ""Create Router"" msgstr ""Creer router"" msgid ""Create Security Group"" msgstr ""Creer beveiligingsgroep"" msgid ""Create Snapshot"" msgstr ""Creer momentopname"" msgid ""Create Subnet"" msgstr ""Creer subnet"" msgid ""Create User"" msgstr ""Creer gebruiker"" msgid ""Create Volume"" msgstr ""Creer volume"" msgid ""Create Volume Snapshot"" msgstr ""Creer volume momentopname"" msgid ""Create Volume Snapshot (Force)"" msgstr ""Creer volume momentopname (Forceer)"" msgid ""Create Volume Type"" msgstr ""Creer volumetype"" msgid ""Create a New Volume"" msgstr ""Creer een nieuw volume"" msgid ""Create a Router"" msgstr ""Creer een router"" msgid ""Created"" msgstr ""Gecreerd"" #, python-format msgid ""Created extra spec \""%s\""."" msgstr ""Creer extra specificatie \""%s\""."" #, python-format msgid ""Created network \""%s\""."" msgstr ""Netwerk \""%s\"" gecreerd."" #, python-format msgid ""Created new domain \""%s\""."" msgstr ""Nieuw domein \""%s\"" gecreerd."" #, python-format msgid ""Created new flavor \""%s\""."" msgstr ""Nieuwe smaak \""%s\"" gecreerd."" #, python-format msgid ""Created new host aggregate \""%s\""."" msgstr ""Nieuw gastheersaggregaat \""%s\"" aangemaakt."" #, python-format msgid ""Created new project \""%s\""."" msgstr ""Nieuw project \""%s\"" gecreerd."" #, python-format msgid ""Created subnet \""%s\""."" msgstr ""Subnet \""%s\"" gecreeerd."" msgctxt ""Current status of a Volume"" msgid ""Creating"" msgstr ""Aanmaken"" msgctxt ""Current status of a Volume Backup"" msgid ""Creating"" msgstr ""Aanmaken"" #, python-format msgid ""Creating volume \""%s\"""" msgstr ""Volume \""%s\"" aan het creren"" #, python-format msgid ""Creating volume snapshot \""%s\""."" msgstr ""Bezig met aanmaken van volume momentopname \""%s\""."" msgid ""Current Host"" msgstr ""Huidige Host"" msgid ""Current password"" msgstr ""Huidig wachtwoord"" msgid ""Custom ICMP Rule"" msgstr ""Maatwerk ICMP regel"" msgid ""Custom Properties"" msgstr ""Aangepaste eigenschappen"" msgid ""Custom TCP Rule"" msgstr ""Maatwerk TCP regel"" msgid ""Custom UDP Rule"" msgstr ""Maatwerk UDP regel"" msgid ""DHCP Agents"" msgstr ""DHCP Agenten"" msgid ""DNS Name Servers"" msgstr ""DNS naamservers"" msgctxt ""Admin state of a Network"" msgid ""DOWN"" msgstr ""OMLAAG"" msgctxt ""Admin state of a Port"" msgid ""DOWN"" msgstr ""OMLAAG"" msgctxt ""Admin state of a Router"" msgid ""DOWN"" msgstr ""OMLAAG"" msgid ""Decrypt Password"" msgstr ""Wachtwoord ontcijferen"" msgctxt ""Default style theme"" msgid ""Default"" msgstr ""Standaard"" msgid ""Defaults"" msgstr ""Standaarden"" msgid ""Delete DHCP Agent"" msgid_plural ""Delete DHCP Agents"" msgstr[0] ""DHCP Agent Verwijderen"" msgstr[1] ""DHCP Agenten Verwijderen"" msgid ""Delete Network"" msgid_plural ""Delete Networks"" msgstr[0] ""Netwerk Verwijderen"" msgstr[1] ""Netwerken Verwijderen"" msgid ""Delete Port"" msgid_plural ""Delete Ports"" msgstr[0] ""Poort Verwijderen"" msgstr[1] ""Poorten Verwijderen"" #, python-format msgid ""Delete the created network \""%s\"" due to subnet creation failure."" msgstr """" ""Verwijder het gecreerde netwerk \""%s\"" vanwege misluking bij subnet creatie."" msgid ""Deleted"" msgstr ""Verwijderd"" msgctxt ""Current status of an Image"" msgid ""Deleted"" msgstr ""Verwijderd"" msgctxt ""Current status of an Instance"" msgid ""Deleted"" msgstr ""Verwijderd"" msgid ""Deleted DHCP Agent"" msgid_plural ""Deleted DHCP Agents"" msgstr[0] ""DHCP Agent Verwijderd"" msgstr[1] ""DHCP Agenten Verwijderd"" msgid ""Deleted Network"" msgid_plural ""Deleted Networks"" msgstr[0] ""Netwerk Verwijderd"" msgstr[1] ""Netwerken Verwijderd"" msgid ""Deleted Port"" msgid_plural ""Deleted Ports"" msgstr[0] ""Poorten Verwijderd"" msgstr[1] ""Poorten Verwijderd"" msgctxt ""Current status of a Volume"" msgid ""Deleting"" msgstr ""Verwijderen"" msgctxt ""Current status of a Volume Backup"" msgid ""Deleting"" msgstr ""Verwijderen"" msgctxt ""Task status of an Instance"" msgid ""Deleting"" msgstr ""Verwijderen"" msgid ""Description"" msgstr ""Omschrijving"" msgid ""Description:"" msgstr ""Omschrijving:"" msgid ""Destination"" msgstr ""Doel"" msgid ""Destination CIDR"" msgstr ""Doel CIDR"" msgid ""Detached"" msgstr ""Ontkoppeld"" msgctxt ""Current status of a Volume"" msgid ""Detaching"" msgstr ""Aan het afkoppelen"" msgid ""Details"" msgstr ""Details"" msgid ""Device"" msgstr ""Apparaat"" msgid ""Device ID"" msgstr ""Apparaat ID"" msgid ""Device ID attached to the port"" msgstr ""Apparaat ID gekoppeld aan de poort"" msgid ""Device Name"" msgstr ""Apparaatnaam"" msgid ""Device Owner"" msgstr ""Apparaateigenaar"" msgid ""Device size (GB)"" msgstr ""Apparaatgrootte (GB)"" msgid ""Direct Input"" msgstr ""Directe Invoer"" msgid ""Direction"" msgstr ""Richting"" msgid ""Disable Gateway"" msgstr ""Gateway deactiveren"" msgid ""Disable Service"" msgstr ""Service Deactiveren"" msgid ""Disabled"" msgstr ""Gedeactiveerd"" msgctxt ""Current status of a Hypervisor"" msgid ""Disabled"" msgstr ""Gedeactiveerd"" msgid ""Disassociate"" msgstr ""Afkoppelen"" msgid ""Disassociate Floating IP"" msgstr ""Vlottend IP adres afkoppelen"" msgid ""Disk"" msgstr ""Schijf"" msgid ""Disk (GB)"" msgstr ""Schijf (GB)"" msgid ""Disk Format"" msgstr ""Schijfformaat"" msgid ""Disk GB Hours"" msgstr ""Schijf GB uren"" msgid ""Disk Over Commit"" msgstr ""Schijf overbenutting"" msgid ""Disk Partition"" msgstr ""Schijfpartitie"" msgid ""Display Name"" msgstr ""Naam Weergeven"" #, python-format msgid ""Domain \""%s\"" must be disabled before it can be deleted."" msgstr """" ""Domein \""%s\"" moet eerst buiten gebruik gesteld worden voordat het "" ""verwijderd kan worden."" msgid ""Domain Context cleared."" msgstr ""Domeincontext gewist."" #, python-format msgid ""Domain Context updated to Domain %s."" msgstr ""Domeincontext bijgewerkt naar Domein %s."" msgid ""Domain Groups"" msgstr ""Domeingroepen"" msgid ""Domain ID"" msgstr ""Domein ID"" msgid ""Domain Name"" msgstr ""Domeinnaam"" msgid ""Domains"" msgstr ""Domeinen"" msgid ""Domains:"" msgstr ""Domeinen:"" msgid ""Down"" msgstr ""Omlaag"" msgctxt ""Current state of a Hypervisor"" msgid ""Down"" msgstr ""Omlaag"" msgctxt ""Current status of a Floating IP"" msgid ""Down"" msgstr ""Omlaag"" msgctxt ""Current status of a Network"" msgid ""Down"" msgstr ""Omlaag"" msgctxt ""current status of port"" msgid ""Down"" msgstr ""Omlaag"" msgctxt ""status of a network port"" msgid ""Down"" msgstr ""Omlaag"" msgid ""Download CSV Summary"" msgstr ""CSV samenvatting ophalen"" msgid ""Edit"" msgstr ""Bewerken"" msgid ""Edit Domain"" msgstr ""Domein bewerken"" msgid ""Edit Flavor"" msgstr ""Smaak bewerken"" msgid ""Edit Group"" msgstr ""Groep bewerken"" msgid ""Edit Host Aggregate"" msgstr ""Wijzigen gastheeraggregaat"" msgid ""Edit Instance"" msgstr ""Exemplaar bewerken"" msgid ""Edit Network"" msgstr ""Netwerk bewerken"" msgid ""Edit Policy"" msgstr ""Beleid bewerken"" msgid ""Edit Port"" msgstr ""Poort bewerken"" msgid ""Edit Project"" msgstr ""Project bewerken"" msgid ""Edit Router"" msgstr ""Router Aanpassen"" msgid ""Edit Security Group"" msgstr ""Beveiligingsgroep bewerken"" msgid ""Edit Security Groups"" msgstr ""Beveiligingsgroepen bewerken"" msgid ""Edit Snapshot"" msgstr ""Momentopname wijzigen"" msgid ""Edit Subnet"" msgstr ""Subnet bewerken"" msgid ""Edit Volume"" msgstr ""Volume bewerken"" msgid ""Edit the image details."" msgstr ""Pas de details van de afbeelding aan."" msgid ""Egress"" msgstr ""Uitgaand"" msgid ""Email"" msgstr ""E-mail"" msgid ""Enable DHCP"" msgstr ""DHCP activeren"" msgid ""Enable Service"" msgid_plural ""Enable Services"" msgstr[0] ""Service Activeren"" msgstr[1] ""Services Activeren"" msgid ""Enabled"" msgstr ""Geactiveerd"" msgctxt ""Current status of a Hypervisor"" msgid ""Enabled"" msgstr ""Geactiveerd"" msgid ""Enabled Service"" msgid_plural ""Enabled Services"" msgstr[0] ""Service Geactiveerd"" msgstr[1] ""Services Geactiveerd"" msgid ""Encrypted Password"" msgstr ""Versleuteld wachtwoord"" msgid ""Enter a value for ICMP code in the range (-1: 255)"" msgstr ""Voer een waarde in voor ICMP code in het bereik (-1: 255)"" msgid ""Enter a value for ICMP type in the range (-1: 255)"" msgstr ""Voer een waarde in voor ICMP type in het bereik (-1: 255)"" msgid ""Enter an integer value between 1 and 65535."" msgstr ""Voor een geheel getal in tussen 1 en 65535."" msgid ""Ephemeral Disk"" msgstr ""Eigen schijf"" msgctxt ""Current status of a Floating IP"" msgid ""Error"" msgstr ""Fout"" msgctxt ""Current status of a Network"" msgid ""Error"" msgstr ""Fout"" msgctxt ""Current status of a Volume"" msgid ""Error"" msgstr ""Fout"" msgctxt ""Current status of a Volume Backup"" msgid ""Error"" msgstr ""Fout"" msgctxt ""Current status of an Instance"" msgid ""Error"" msgstr ""Fout"" msgctxt ""current status of port"" msgid ""Error"" msgstr ""Fout"" msgctxt ""current status of router"" msgid ""Error"" msgstr ""Fout"" #, python-format msgid ""Error Downloading RC File: %s"" msgstr ""Fout bij het ophalen van RC bestand: %s"" msgid ""Error adding Hosts to the aggregate."" msgstr ""Fout tijdens het toevoegen van gastheren aan het aggregaat."" msgid ""Error when adding or removing hosts."" msgstr ""Fout bij het toevoegen of verwijderen van gastheren."" #, python-format msgid ""Error writing zipfile: %(exc)s"" msgstr ""Fout bij wegschrijven van zipbestand: %(exc)s"" msgid ""Ether Type"" msgstr ""Ethertype"" msgid ""Extend Volume"" msgstr ""Volume uitbreiden"" msgid ""Extend the size of a volume."" msgstr ""Grootte van een volume uitbreiden."" msgid ""External Gateway"" msgstr ""Externe Gateway"" msgid ""External Network"" msgstr ""Extern netwerk"" msgid ""Extra Specs"" msgstr ""Extra Specificaties"" msgctxt ""Power state of an Instance"" msgid ""Failed"" msgstr ""Mislukt"" #, python-format msgid """" ""Failed to add %(users_to_add)s project members%(group_msg)s and set project "" ""quotas."" msgstr """" ""Het toevoegen van %(users_to_add)s projectleden %(group_msg)s en instellen "" ""van projectquota's is mislukt."" #, python-format msgid ""Failed to add %s project groups and update project quotas."" msgstr """" ""Het toevoegen van %s projectgroepen en bijwerken van projectquota's is "" ""mislukt."" #, python-format msgid ""Failed to add agent %(agent_name)s for network %(network)s."" msgstr """" ""Mislukt om agent %(agent_name)s toe te voegen voor netwerk %(network)s."" #, python-format msgid ""Failed to create network \""%(network)s\"": %(reason)s"" msgstr ""Creren van netwerk \""%(network)s\"" mislukt: %(reason)s"" #, python-format msgid ""Failed to create network %s"" msgstr ""Creren van netwerk %s mislukt"" #, python-format msgid ""Failed to create router \""%s\""."" msgstr ""Creren van router \""%s\"" mislukt."" #, python-format msgid ""Failed to delete network \""%s\"""" msgstr ""Verwijderen van netwerk \""%s\"" mislukt"" #, python-format msgid ""Failed to delete port %s"" msgstr ""Verwijderen van poort %s mislukt"" #, python-format msgid ""Failed to live migrate instance to host \""%s\""."" msgstr ""Live verplaatsing van exemplaar naar gastheer \""%s\"" mislukt."" #, python-format msgid """" ""Failed to modify %(users_to_modify)s project members%(group_msg)s and update "" ""project quotas."" msgstr """" ""Het aanpassen van %(users_to_modify)s projectleden %(group_msg)s en "" ""bijwerken van projectquota's is mislukt."" #, python-format msgid ""Failed to modify %s domain groups."" msgstr ""Aanpassen van %s domeingroepen mislukt."" #, python-format msgid """" ""Failed to modify %s project members, update project groups and update "" ""project quotas."" msgstr """" ""Het aanpassen van %s projectleden, bijwerken van projectgroepen en bijwerken "" ""van projectquota's is mislukt."" #, python-format msgid ""Failed to update network %s"" msgstr ""Bijwerken van netwerk %s is mislukt"" #, python-format msgid ""Failed to update subnet \""%(sub)s\"": %(reason)s"" msgstr ""Bijwerken van subnet \""%(sub)s\"" mislukt: %(reason)s"" msgid ""False"" msgstr ""Onwaar"" msgid ""Fault"" msgstr ""Fout"" msgid ""File"" msgstr ""Bestand"" msgid ""Filter"" msgstr ""Filter"" msgid ""Fingerprint"" msgstr ""Vingerafdruk"" msgctxt ""Task status of an Instance"" msgid ""Finishing Resize or Migrate"" msgstr ""Herdimensionering of verplaatsing aan het afronden"" msgid ""Fixed IPs"" msgstr ""Vaste IPs"" msgid ""Flat"" msgstr ""Plat"" msgid ""Flavor"" msgstr ""Smaak"" msgid ""Flavor Access"" msgstr ""Smaaktoegang"" msgid ""Flavor Choice"" msgstr ""Smaakkeuze"" msgid ""Flavor Details"" msgstr ""Smaakdetails"" msgid """" ""Flavor ID should be UUID4 or integer. Leave this field blank or use 'auto' "" ""to set a random UUID4."" msgstr """" ""Smaak ID dient UUID4 of geheel getal te zijn. Laat dit veld blanco of "" ""gebruik 'auto' om een willekeurig UUID4 in te stellen."" msgid ""Flavor Name"" msgstr ""Smaaknaam"" msgid ""Flavors"" msgstr ""Smaken"" msgid ""Floating IP"" msgstr ""Volttend IP"" msgid ""Floating IPs"" msgstr ""Vlottende IPs"" msgid """" ""For TCP and UDP rules you may choose to open either a single port or a range "" ""of ports. Selecting the \""Port Range\"" option will provide you with space to "" ""provide both the starting and ending ports for the range. For ICMP rules you "" ""instead specify an ICMP type and code in the spaces provided."" msgstr """" ""Voor TCP en UDP regels mag u er voor kiezen op een enkele poort of een "" ""poortbereik te openen. Het selecteren van de \""poortbereik\"" optie verschaft "" ""u de ruimte om een begin en eindpoort voor het bereik in te geven. Voor ICMP "" ""regels dient u in de weergegeven velden een ICMP type en code in te vullen."" msgid ""Forbidden"" msgstr ""Verboden"" #, python-format msgid ""Forcing to create snapshot \""%s\"" from attached volume."" msgstr """" ""Aanmaken van momentopname \""%s\"" van het gekoppelde volume aan het afdwingen."" msgid ""Format"" msgstr ""Formaat"" msgid ""Format ="" msgstr ""Formaat ="" msgid ""From Port"" msgstr ""Van poort"" msgid ""GB"" msgstr ""GB"" msgid ""GMT"" msgstr ""GMT"" msgid ""GRE"" msgstr ""GRE"" msgid ""Gateway IP"" msgstr ""Gateway IP"" msgid ""Gateway IP and IP version are inconsistent."" msgstr ""Gateway IP en IP versie zijn inconsistent."" msgid ""Gateway interface is added"" msgstr ""Gatewayaansluiting is toegevoegd"" msgid ""Go"" msgstr ""Ga"" #, python-format msgid ""Group \""%s\"" was successfully created."" msgstr ""Groep \""%s\"" was succesvol gecreerd."" msgid ""Group ID"" msgstr ""Groep ID"" msgid ""Group Management"" msgstr ""Groepsbeheer"" msgid ""Group Members"" msgstr ""Groepsleden"" msgid ""Group has been updated successfully."" msgstr ""Groep was succesvol bijgewerkt."" msgid ""Groups"" msgstr ""Groepen"" msgctxt ""Current status of an Instance"" msgid ""Hard Reboot"" msgstr ""Harde herstart"" msgid ""Help"" msgstr ""Help"" msgid ""Home"" msgstr ""Thuis"" msgid ""Host"" msgstr ""Gastheer"" msgid ""Host ="" msgstr ""Host ="" msgid ""Host Aggregates"" msgstr ""Gastheersaggregaties"" msgid ""Host Routes"" msgstr ""Gastheerroutes"" #, python-format msgid """" ""Host Routes format error: Destination CIDR and nexthop must be specified "" ""(value=%s)"" msgstr """" ""Gastheerroutes formaat fout: Doel CIDR en nexthop moeten gespecificeerd zijn "" ""(waarde=%s)"" msgid ""Hostname"" msgstr ""Gastheer naam"" msgid ""Hosts"" msgstr ""Gastheren"" msgid ""Hypervisor"" msgstr ""Hypervisor"" msgid ""Hypervisor Instances"" msgstr ""Hypervisor Exemplaren"" msgid ""Hypervisor Servers"" msgstr ""Hypervisor servers"" msgid ""Hypervisor Summary"" msgstr ""Hypervisor samenvatting"" msgid ""Hypervisors"" msgstr ""Hypervisors"" msgid ""ID"" msgstr ""ID"" msgid ""IP Address"" msgstr ""IP Adres"" msgid ""IP Address (optional)"" msgstr ""IP adres (optioneel)"" msgid ""IP Addresses"" msgstr ""IP adres"" msgid ""IP Protocol"" msgstr ""IP Protocol"" msgid ""IP Version"" msgstr ""IP versie"" #, python-format msgid ""IP address %s associated."" msgstr ""IP adres %s aangekoppeld."" msgid """" ""IP address list of DNS name servers for this subnet. One entry per line."" msgstr """" ""IP adreslijst van DNS naamservers voor dit subnet. Een adres per regel."" msgid ""IPv4"" msgstr ""IPv4"" msgid ""IPv4 Address ="" msgstr ""IPv4 Adres ="" msgid ""IPv6"" msgstr ""IPv6"" msgid ""IPv6 Address ="" msgstr ""IPv6 Adres ="" msgid ""ISO - Optical Disk Image"" msgstr ""ISO - Optische Schijf Afbeelding"" msgid ""Identity service does not allow editing user data."" msgstr ""Identiteitsdienst staat het bewerken van gebruikersgegevens niet toe."" msgid """" ""If console is not responding to keyboard input: click the grey status bar "" ""below."" msgstr """" ""Als het beheervenster niet reageert op toetsaanslagen: klik op de grijze "" ""statusbalk hieronder."" msgid ""Image"" msgstr ""Afbeelding"" msgctxt ""Type of an image"" msgid ""Image"" msgstr ""Afbeelding"" msgid ""Image File"" msgstr ""Afbeeldingsbestand"" msgid ""Image ID ="" msgstr ""Afbeelding ID ="" msgid ""Image Location"" msgstr ""Afbeeldingslocatie"" msgid ""Image Name"" msgstr ""Afbeeldingsnaam"" msgid ""Image Name ="" msgstr ""Afbeeldingsnaam ="" msgid ""Image Source"" msgstr ""Afbeeldingsbron"" msgid ""Image was successfully updated."" msgstr ""Afbeelding is succesvol bijgewerkt."" msgid ""Images"" msgstr ""Afbeeldingen"" msgid ""Import Key Pair"" msgstr ""Sleutelpaar importeren"" msgid ""Info"" msgstr ""Informatie"" msgid ""Information"" msgstr ""Informatie"" msgid ""Ingress"" msgstr ""Inkomend"" msgid ""Injected File Content Bytes"" msgstr ""Genjecteerde bestandsinhoud in Bytes"" msgid ""Injected File Path Bytes"" msgstr ""Geinjecteerde bestandspad Bytes"" msgid ""Injected Files"" msgstr ""Genjecteerde bestanden"" msgid ""Instance"" msgstr ""Exemplaar"" msgid ""Instance Admin Password"" msgstr ""Beheerderswachtwoord van het exemplaar"" msgid ""Instance Boot Source"" msgstr ""Exemplaar opstartbron"" msgid ""Instance Console"" msgstr ""Exemplaar beheervenster"" msgid ""Instance Console Log"" msgstr ""Exemplaar beheervenster log"" msgid ""Instance ID"" msgstr ""Exemplaar ID"" msgid ""Instance Name"" msgstr ""Exemplaarnaam"" msgid ""Instance Overview"" msgstr ""Exemplaaroverzicht"" msgid ""Instance Password is not set or is not yet available"" msgstr ""Het exemplaar wachtwoord is niet ingesteld of nog niet beschikbaar"" msgid ""Instance Security Groups"" msgstr ""Exemplaar beveiligingsgroepen"" msgid ""Instance Snapshot"" msgstr ""Exemplaar momentopname"" msgid ""Instances"" msgstr ""Exemplaren"" msgid ""Interface added"" msgstr ""Aansluiting toegevoegd"" msgid ""Interfaces"" msgstr ""Aansluitingen"" msgid ""Internal Interface"" msgstr ""Interne aansluiting"" msgid ""Invalid date format: Using today as default."" msgstr ""Ongeldig datumformaat: Vandaag als standaard gebruikt."" msgid """" ""Invalid time period. The end date should be more recent than the start date."" msgstr ""Ongeldige tijdsperiode. De einddatum dient na de startdatum te vallen."" msgid """" ""Invalid time period. You are requesting data from the future which may not "" ""exist."" msgstr """" ""Ongeldige tijdsperiode. U vraagt gegevens uit de toekomst die mogelijk nog "" ""niet bestaan."" msgid ""Items Per Page"" msgstr ""Artikelen per pagina"" msgid ""Kernel ID"" msgstr ""Kernel ID"" msgid ""Key"" msgstr ""Sleutel"" msgid ""Key Name"" msgstr ""Sleutelnaam"" msgid ""Key Pair"" msgstr ""Sleutelpaar"" msgid ""Key Pair Name"" msgstr ""Sleutelpaarnaam"" msgid ""Key Pairs"" msgstr ""Sleutelparen"" msgid ""Key Pairs are how you login to your instance after it is launched."" msgstr ""Met sleutelparen logt u in op een exemplaar nadat deze is gestart."" msgid ""Key Size (bits)"" msgstr ""Sleutelgrootte (bits)"" msgid ""Language"" msgstr ""Taal"" msgctxt ""Time since the last update"" msgid ""Last Updated"" msgstr ""Laatst bijgewerkt"" msgid ""Launch"" msgstr ""Starten"" msgid ""Launch Instance"" msgstr ""Start exemplaar"" msgid ""Launch instance in these security groups."" msgstr ""Start exemplaar in deze beveiligingsgroep."" msgid ""Launch instance with these networks"" msgstr ""Start exemplaar met deze netwerken"" msgid """" ""Launching multiple instances is only supported for images and instance "" ""snapshots."" msgstr """" ""Het starten van meerdere exemplaren wordt alleen ondersteund voor "" ""afbeeldingen en momentopnamen."" msgid ""Limit"" msgstr ""Limiet"" msgid ""Live Migrate"" msgstr ""Live Verplaatsen"" msgid ""Live Migrate Instance"" msgstr ""Live exemplaar verplaatsen"" msgid ""Local"" msgstr ""Locaal"" msgid ""Local Disk Usage"" msgstr ""Locaal Schijfverbruik"" msgid ""Local Storage (total)"" msgstr ""Locale Opslag (totaal)"" msgid ""Local Storage (used)"" msgstr ""Locale Opslag (gebruikt)"" msgid ""Log"" msgstr ""Log"" msgid ""Log Length"" msgstr ""Log lengte"" msgid ""MB"" msgstr ""MB"" msgid ""MTU"" msgstr ""MTU"" msgid ""Manage Floating IP Associations"" msgstr ""Beheer vlottende IP associaties"" msgid ""Manage Hosts"" msgstr ""Beheer gastheren"" msgid ""Manage Hosts Aggregate"" msgstr ""Beheer gastheersaggregaat"" msgid ""Manage Rules"" msgstr ""Beheer regels"" msgid ""Manage Volume Attachments"" msgstr ""Volumeaankoppelingen beheren"" msgid ""Manual"" msgstr ""Handmatig"" msgid ""Memory Usage"" msgstr ""Geheugenverbruik"" msgid ""Message"" msgstr ""Bericht"" msgid ""Metadata"" msgstr ""Metadata"" msgid ""Metadata Definitions"" msgstr ""Metadata Definities"" msgid ""Metadata Items"" msgstr ""Metadata artikelen"" msgid ""Migrate"" msgstr ""Migreren"" msgctxt ""Current status of an Instance"" msgid ""Migrating"" msgstr ""Migreren"" msgctxt ""Task status of an Instance"" msgid ""Migrating"" msgstr ""Migreren"" msgid ""Min Disk"" msgstr ""Min Schijf"" msgid ""Min RAM"" msgstr ""Min werkgeheugen"" msgid ""Minimum Disk (GB)"" msgstr ""Minimum Schijf (GB)"" msgid ""Minimum RAM (MB)"" msgstr ""Minimum werkgeheugen (MB)"" #, python-format msgid ""Modified domain \""%s\""."" msgstr ""Bewerk domein \""%s\""."" #, python-format msgid ""Modified instance \""%s\""."" msgstr ""Exemplaar \""%s\"" aangepast."" #, python-format msgid ""Modified project \""%s\""."" msgstr ""Project \""%s\"" is aangepast."" msgid ""Modify Access"" msgstr ""Toegang aanpassen"" msgid ""Modify Consumer"" msgstr ""Pas Verbruiker Aan"" msgid ""Modify Groups"" msgstr ""Groepen aanpassen"" msgid ""Modify Quotas"" msgstr ""Quota's aanpassen"" msgid ""Monitoring:"" msgstr ""Monitoren:"" msgid ""N/A"" msgstr ""n.v.t."" msgid ""Name"" msgstr ""Naam"" msgid ""Namespace"" msgstr ""Naamplaats"" msgid ""Namespaces"" msgstr ""Naamplaatsen"" msgid ""Network"" msgstr ""Netwerk"" #, python-format msgid ""Network %s was successfully updated."" msgstr ""Netwerk %s was succesvol bijgewerkt."" msgid ""Network Address"" msgstr ""Netwerkadres"" msgid ""Network Address and IP version are inconsistent."" msgstr ""Netwerkadres en IP versie zijn inconsistent."" msgid ""Network Agents"" msgstr ""Netwerkagenten"" msgid ""Network Details"" msgstr ""Netwerk Details"" msgid ""Network ID"" msgstr ""Netwerk ID"" msgid ""Network Name"" msgstr ""Netwerknaam"" msgid ""Network Topology"" msgstr ""Netwerktopologie"" msgid ""Network address in CIDR format (e.g. 192.168.0.0/24)"" msgstr ""Netwerkadres in CIDR formaat (bv. 192.168.0.0/24)"" msgid ""Network list can not be retrieved."" msgstr ""Netwerklijst kan niet worden opgehaald."" msgid ""Networking"" msgstr ""Netwerken"" msgctxt ""Task status of an Instance"" msgid ""Networking"" msgstr ""Netwerken"" msgid ""Networks"" msgstr ""Netwerken"" msgid ""Never"" msgstr ""Nooit"" msgid ""Never updated"" msgstr ""Nooit bijgewerkt"" msgid ""New DHCP Agent"" msgstr ""Nieuw DHCP Agent"" msgid ""New Flavor"" msgstr ""Nieuwe smaak"" msgid ""New Host"" msgstr ""Nieuwe Host"" msgid ""New password"" msgstr ""Nieuw wachtwoord"" msgid ""No"" msgstr ""Nee"" msgid ""No Host selected."" msgstr ""Geen gastheer geselecteerd"" msgid ""No Hosts found."" msgstr ""Geen gastheren gevonden"" msgid ""No attached device"" msgstr ""Geen gekoppeld apparaat"" msgid ""No availability zones found"" msgstr ""Geen beschikbaarheidszones gevonden"" msgid ""No available projects"" msgstr ""Geen projecten beschikbaar"" msgid ""No flavors available"" msgstr ""Geen smaken beschikbaar"" msgid ""No floating IP pools available"" msgstr ""Geen vlottende IP poules beschikbaar."" msgid ""No groups found."" msgstr ""Geen groepen gevonden."" msgid ""No groups."" msgstr ""Geen groepen"" msgid ""No host selected."" msgstr ""Geen gastheren geselecteerd"" msgid ""No hosts found."" msgstr ""Geen gastheren gevonden"" msgid ""No images available"" msgstr ""Geen afbeeldingen beschikbaar"" msgid ""No instances available"" msgstr ""Geen exemplaren beschikbaar"" msgid ""No key pairs available"" msgstr ""Geen sleutelparen beschikbaar"" msgid ""No networks available"" msgstr ""Geen netwerken beschikbaar"" msgid ""No options specified"" msgstr ""Geen opties gespecificeerd"" msgid ""No other agents available."" msgstr ""Geen andere agenten beschikbaar."" msgid ""No other hosts available."" msgstr ""Geen andere host beschikbaar."" msgid ""No ports available"" msgstr ""Geen poorten beschikbaar"" msgid ""No projects found."" msgstr ""Geen projecten gevonden."" msgid ""No projects selected. All projects can use the flavor."" msgstr """" ""Geen projecten geselecteerd. Alle projecten kunnen gebruik maken van deze "" ""smaak."" msgid ""No rules defined."" msgstr ""Geen regels gedefinieerd."" msgid ""No security groups available"" msgstr ""Geen beveiligingsgroepen beschikbaar"" msgid ""No security groups enabled."" msgstr ""Geen beveiligingsgroepen geactiveerd."" msgid ""No security groups found."" msgstr ""Geen beveiligingsgroepen gevonden."" msgid ""No snapshots available"" msgstr ""Geen momentopnamen beschikbaar."" msgid ""No source, empty volume"" msgstr ""Geen bron, leeg volume"" msgid ""No subnets available"" msgstr ""Geen subnetten beschikbaar"" msgid ""No users found."" msgstr ""Geen gebruikers gevonden."" msgid ""No users."" msgstr ""Geen gebruikers."" msgid ""No volume snapshots available"" msgstr ""Geen volume momentopnamen beschikbaar"" msgid ""No volumes attached."" msgstr ""Geen aangekoppelde volumes."" msgid ""No volumes available"" msgstr ""Geen volumen beschikbaar"" msgid ""Non-Members"" msgstr ""Niet-leden"" msgid ""None"" msgstr ""Geen"" msgctxt ""Task status of an Instance"" msgid ""None"" msgstr ""Geen"" msgid ""Normal"" msgstr ""Normaal"" msgid ""Not attached"" msgstr ""Niet aangekoppeld"" msgid ""Not available"" msgstr ""Niet beschikbaar"" msgid ""Note: "" msgstr ""Let op:"" msgid ""Number of Instances"" msgstr ""Aantal exemplaren"" msgid ""Number of Snapshots"" msgstr ""Aantal momentopnames"" msgid ""Number of VCPUs"" msgstr ""Aantal VCPUs"" msgid ""Number of Volumes"" msgstr ""Aantal volumes"" msgid ""OR Copy/Paste your Private Key"" msgstr ""OF kopieer/plak uw privsleutel"" msgid ""Object Store"" msgstr ""Objectobslag"" msgid ""Old Flavor"" msgstr ""Oude smaak"" msgid ""Open Port"" msgstr ""Open poort"" msgid ""Other Protocol"" msgstr ""Ander protocol"" msgid ""Overview"" msgstr ""Overzicht"" msgid ""Owner"" msgstr ""Eigenaar"" msgid ""Page Not Found"" msgstr ""Pagina niet gevonden"" msgid ""Password"" msgstr ""Wachtwoord"" msgctxt ""Current status of an Instance"" msgid ""Password"" msgstr ""Wachtwoord"" msgid ""Password changed. Please log in again to continue."" msgstr ""Wachtwoord gewijzigd. Meldt u zich opnieuw aan om door te gaan."" msgid ""Passwords do not match."" msgstr ""Wachtwoorden komen niet overeen."" msgctxt ""Action log of an instance"" msgid ""Pause"" msgstr ""Pauze"" msgctxt ""Current status of an Instance"" msgid ""Paused"" msgstr ""Gepauzeerd"" msgctxt ""Power state of an Instance"" msgid ""Paused"" msgstr ""Gepauzeerd"" msgctxt ""Task status of an Instance"" msgid ""Pausing"" msgstr ""Pauze"" msgid ""Physical Network"" msgstr ""Fysiek netwerk"" msgid ""Please note: "" msgstr ""Let op:"" #, python-format msgid ""Please try again later [Error: %s]."" msgstr ""Probeert u alstublieft later nogmaals [Fout: %s]"" msgid ""Pool"" msgstr ""Poule"" msgid ""Port"" msgstr ""Poort"" #, python-format msgid ""Port %s was successfully created."" msgstr ""Poort %s was succesvol gecreerd."" #, python-format msgid ""Port %s was successfully updated."" msgstr ""Poort %s was succesvol bijgewerkt."" msgid ""Port Range"" msgstr ""Poortbereik"" msgid ""Port list can not be retrieved."" msgstr ""Poortlijst kan niet worden opgehaald."" msgid ""Port to be associated"" msgstr ""Aan te koppelen poort"" msgid ""Ports"" msgstr ""Poorten"" msgid ""Post-Creation"" msgstr ""Post-creatie"" msgid ""Power State"" msgstr ""Energietoestand"" msgctxt ""Task status of an Instance"" msgid ""Powering Off"" msgstr ""Afsluiten"" msgctxt ""Task status of an Instance"" msgid ""Powering On"" msgstr ""Opstarten"" msgid ""Prefix: "" msgstr ""Voorvoegsel:"" msgctxt ""Task status of an Instance"" msgid ""Preparing Resize or Migrate"" msgstr ""Herdimensionering of verplaatsing aan het voorbereiden"" msgid ""Primary Project"" msgstr ""Primair project"" msgid ""Private Key File"" msgstr ""Bestand met de privsleutel"" msgid ""Profile"" msgstr ""Profiel"" msgid ""Project"" msgstr ""Project"" msgid ""Project & User"" msgstr ""Project & Gebruiker"" msgid ""Project Groups"" msgstr ""Projectgroepen"" msgid ""Project ID"" msgstr ""Project ID"" msgid ""Project Limits"" msgstr ""Projectlimieten"" msgid ""Project Members"" msgstr ""Projectleden"" msgid ""Project Name"" msgstr ""Projectnaam"" msgid ""Project Quotas"" msgstr ""Projectquota's"" msgid ""Project Usage"" msgstr ""Projectverbruik"" msgid ""Project Usage Overview"" msgstr ""Projectverbruik overzicht"" msgid ""Projects"" msgstr ""Projecten"" msgid ""Projects:"" msgstr ""Projecten:"" msgid ""Protected"" msgstr ""Beschermd"" msgid ""Provider"" msgstr ""Leverancier"" msgid ""Provider Network"" msgstr ""Leveranciersnetwerk"" msgid ""Public"" msgstr ""Publiek"" msgid ""Public Key"" msgstr ""Publieke sleutel"" msgid ""QCOW2 - QEMU Emulator"" msgstr ""QCOW2 - QEMU Emulator"" msgid ""Quota Name"" msgstr ""Quotum naam"" msgid ""RAM"" msgstr ""Werkgeheugen"" msgid ""RAM (MB)"" msgstr ""Werkgeheugen (MB)"" msgid ""RAM (total)"" msgstr ""Werkgeheugen (totaal)"" msgid ""RAM (used)"" msgstr ""Werkgeheugen (gebruikt)"" msgid ""Ramdisk ID"" msgstr ""Geheugenschijf ID"" msgid ""Raw"" msgstr ""Ruw"" msgctxt ""Image format for display in table"" msgid ""Raw"" msgstr ""Ruw"" msgid ""Reason"" msgstr ""Reden"" #, python-format msgid ""Reason: %(disabled_reason)s"" msgstr ""Reden: %(disabled_reason)s"" msgctxt ""Action log of an instance"" msgid ""Reboot"" msgstr ""Herstarten"" msgctxt ""Current status of an Instance"" msgid ""Reboot"" msgstr ""Herstarten"" msgctxt ""Task status of an Instance"" msgid ""Rebooting"" msgstr ""Herstarten"" msgid ""Rebuild Instance"" msgstr ""Herbouw exemplaar"" msgid ""Rebuild Password"" msgstr ""Herbouw wachtwoord"" #, python-format msgid ""Rebuilding instance %s."" msgstr ""Herbouw exemplaar %s."" msgid ""Regions:"" msgstr ""Regio's:"" msgid ""Remote"" msgstr ""Van op afstand"" msgid ""Resize"" msgstr ""Herdimensioneren"" msgctxt ""Action log of an instance"" msgid ""Resize"" msgstr ""Herdimensioneren"" msgid ""Resize Instance"" msgstr ""Herdimensioneer exemplaar"" msgctxt ""Current status of an Instance"" msgid ""Resize/Migrate"" msgstr ""Vergroten/Verkleinen/Verplaatsen"" msgctxt ""Task status of an Instance"" msgid ""Resized or Migrated"" msgstr ""Herdimensioneerd of verplaatst"" msgctxt ""Task status of an Instance"" msgid ""Resizing or Migrating"" msgstr ""Aan het herdimensioneren of verplaatsen"" msgid ""Resources"" msgstr ""Middelen"" msgid ""Restore Backup"" msgstr ""Herstel archief"" msgctxt ""Action log of an instance"" msgid ""Resume"" msgstr ""Hervatten"" msgctxt ""Task status of an Instance"" msgid ""Resuming"" msgstr ""Aan het hervatten"" msgid ""Retrieve Instance Password"" msgstr ""Wachtwoord van het exemplaar opvragen"" msgid ""Retrieve Password"" msgstr ""Wachtwoord opvragen"" msgid ""Revert Resize/Migrate"" msgstr ""Terugdraaien herdimensionering/migratie"" msgctxt ""Current status of an Instance"" msgid ""Revert Resize/Migrate"" msgstr ""Terugdraaien herdimensionering/migratie"" msgctxt ""Task status of an Instance"" msgid ""Reverting Resize or Migrate"" msgstr ""Herdimensionering of verplaatsing aan het terugdraaien"" msgid ""Role"" msgstr ""Rol"" msgid ""Role ID"" msgstr ""Rol ID"" msgid ""Role Name"" msgstr ""Rolnaam"" msgid ""Role created successfully."" msgstr ""Rol is succesvol gecreeerd."" msgid ""Role updated successfully."" msgstr ""Rol is succesvol bijgewerkt."" msgid ""Roles"" msgstr ""Rollen"" msgid ""Root Disk"" msgstr ""Systeemschijf"" msgid ""Router"" msgstr ""Router"" #, python-format msgid ""Router %s was successfully created."" msgstr ""Router %s was succesvol gecreeerd."" #, python-format msgid ""Router %s was successfully updated."" msgstr ""Router %s is succesvol bijgewerkt."" msgid ""Router Name"" msgstr ""Routernaam"" msgid ""Router Type"" msgstr ""Routertype"" msgid ""Routers"" msgstr ""Routers"" msgid ""Rule"" msgstr ""Regel"" msgid ""Rules"" msgstr ""Regels"" msgid """" ""Rules define which traffic is allowed to instances assigned to the security "" ""group. A security group rule consists of three main parts:"" msgstr """" ""Regels definiren het toegestane verkeer naar exemplaren die onderdeel "" ""uitmaken van de beveiligingsgroep. Een beveiligingsgroep bestaat uit drie "" ""hoofdonderdelen:"" msgid ""SSH key pairs can be generated with the ssh-keygen command:"" msgstr """" ""SSH sleutelparen kunnen worden gegenereerd met het commando ssh-keygen:"" msgid ""Save"" msgstr ""Opslaan"" msgid ""Save Changes"" msgstr ""Wijzigingen opslaan"" #, python-format msgid ""Saved extra spec \""%s\""."" msgstr ""Extra specificatie \""%s\"" opgeslagen."" msgid ""Security Group"" msgstr ""Beveiligingsgroep"" msgid ""Security Group Rules"" msgstr ""Beveiligingsgroepsregels"" msgid ""Security Groups"" msgstr ""Beveiligingsgroepen"" msgid ""Segmentation ID"" msgstr ""Segment ID"" msgid ""Select Image"" msgstr ""Selecteer afbeelding"" msgid ""Select Instance Snapshot"" msgstr ""Selecteer een exemplaar momentopname"" msgid ""Select Subnet"" msgstr ""Selecteer subnet"" msgid ""Select Volume"" msgstr ""Selecteer volume"" msgid ""Select Volume Snapshot"" msgstr ""Selecteer volume momentopname"" msgid ""Select a New Flavor"" msgstr ""Selecteer een nieuwe smaak"" msgid ""Select a key pair"" msgstr ""Selecteer een sleutelpaar"" msgid ""Select a new agent"" msgstr ""Selecteer een nieuw agent"" msgid ""Select a new host"" msgstr ""Selecteer een nieuwe host"" msgid ""Select a port"" msgstr ""Selecteer een poort"" msgid ""Select a project"" msgstr ""Selecteer een project"" msgid ""Select a target host"" msgstr ""Selecteer een doelhost"" msgid ""Select an IP address"" msgstr ""Selecteer een IP adres"" msgid ""Select an instance"" msgstr ""Selecteer een exemplaar"" msgid ""Select an instance to attach to."" msgstr ""Selecteer een exemplaar om aan te koppelen."" msgid ""Select format"" msgstr ""Selecteer formaat"" msgid ""Select network"" msgstr ""Selecteer netwerk"" msgid ""Select networks for your instance."" msgstr ""Selecteer netwerken voor uw exemplaar."" msgid ""Select the image to rebuild your instance."" msgstr ""Selecteer de afbeelding om uw exemplaar te herbouwen."" msgid ""Selected Hosts"" msgstr ""Geselecteerde gastheren"" msgid ""Selected hosts"" msgstr ""Geselecteerde gastheren"" msgid ""Selected networks"" msgstr ""Geselecteerde netwerken"" msgid ""Server error"" msgstr ""Serverfout"" msgid ""Service"" msgstr ""Dienst"" msgid ""Service Endpoint"" msgstr ""Dienst eindpunt"" msgid ""Services"" msgstr ""Diensten"" msgid ""Services Down"" msgstr ""Inactieve diensten"" msgid ""Services Up"" msgstr ""Actieve diensten"" msgid ""Set Domain Context"" msgstr ""Stel domeincontext in"" msgid ""Set Gateway"" msgstr ""Instellen Gateway"" msgid ""Settings"" msgstr ""Instellingen"" msgid ""Settings saved."" msgstr ""Instellingen opgeslagen."" msgid ""Shared"" msgstr ""Gedeeld"" msgid ""Shared Storage"" msgstr ""Gedeelde Opslag"" msgctxt ""Power state of an Instance"" msgid ""Shut Off"" msgstr ""Uitzetten"" msgid ""Sign Out"" msgstr ""Afmelden"" msgid ""Size"" msgstr ""Omvang"" msgid ""Size of image to launch."" msgstr ""Grootte van te starten afbeelding."" msgid ""Slash is not an allowed character."" msgstr ""Schuine streep is geen toegelaten karakter."" msgid ""Snapshot"" msgstr ""Momentopname"" msgctxt ""Type of an image"" msgid ""Snapshot"" msgstr ""Momentopname"" #, python-format msgid ""Snapshot \""%(name)s\"" created for instance \""%(inst)s\"""" msgstr ""Momentopname \""%(name)s\"" gemaakt voor exemplaar \""%(inst)s\"""" msgid ""Snapshot Name"" msgstr ""Momentopname naam"" msgctxt ""Task status of an Instance"" msgid ""Snapshotting"" msgstr ""Momentopnamen"" msgid ""Something went wrong!"" msgstr ""Er is iets misgegaan!"" msgid ""Specify an image to upload to the Image Service."" msgstr ""Specificeer een afbeelding om te uploaden naar de afbeeldingsdienst."" msgid ""Specify the details for launching an instance."" msgstr ""Specificeer de details voor het starten van een exemplaar."" msgid ""Specs"" msgstr ""Specificatie"" msgid ""Start"" msgstr ""Start"" msgctxt ""Action log of an instance"" msgid ""Start"" msgstr ""Start"" #, python-format msgid ""Start address is larger than end address (value=%s)"" msgstr ""Startadres is groter dan eindadres (waarde=%s)"" #, python-format msgid ""Start and end addresses must be specified (value=%s)"" msgstr ""Start en en eind-adres moeten worden gespecificeerd (waarde=%s)"" msgid ""State"" msgstr ""Toestand"" msgid ""Status"" msgstr ""Status"" msgid ""Status ="" msgstr ""Statuus ="" msgid ""Subnet"" msgstr ""Subnet"" msgid ""Subnet ID"" msgstr ""Subnet ID"" msgid ""Subnet Name"" msgstr ""Subnetnaam"" msgid ""Subnet list can not be retrieved."" msgstr ""Subnetlijst kan niet worden opgehaald."" msgid ""Subnets"" msgstr ""Subnetten"" msgid ""Subnets Associated"" msgstr ""Gekoppelde subnetten"" #, python-format msgid ""Successfully added rule: %s"" msgstr ""Succesvol toegevoegde regel: %s"" #, python-format msgid ""Successfully created security group: %s"" msgstr ""Succesvol gecreerd beveiligingsgroep: %s"" #, python-format msgid ""Successfully created volume type: %s"" msgstr ""Succesvol gecreerd volumetype: %s"" #, python-format msgid ""Successfully disassociated Floating IP: %s"" msgstr ""Volttend IP adres %s succesvol afgekoppeld"" #, python-format msgid ""Successfully imported public key: %s"" msgstr ""Succesvol geimporteerde publieke sleutel: %s"" #, python-format msgid ""Successfully updated aggregate: \""%s.\"""" msgstr ""Het aggregaat \""%s\"" is met succes aangepast."" #, python-format msgid ""Successfully updated security group: %s"" msgstr ""Succesvol bijgewerkte beveiligingsgroep: %s"" msgctxt ""Action log of an instance"" msgid ""Suspend"" msgstr ""Opschorten"" msgctxt ""Current status of an Instance"" msgid ""Suspended"" msgstr ""Opgeschort"" msgctxt ""Power state of an Instance"" msgid ""Suspended"" msgstr ""Opgeschort"" msgid ""Swap Disk"" msgstr ""Wisselgeheugenschijf"" msgid ""System"" msgstr ""Systeem"" msgid ""System Information"" msgstr ""Systeeminformatie"" msgid ""Target Host"" msgstr ""Doelhost"" msgid ""Task"" msgstr ""Taak"" msgid ""The \""from\"" port number is invalid."" msgstr ""Het \""van\"" poortnummer is ongeldig."" msgid ""The \""to\"" port number is invalid."" msgstr ""Het \""tot\"" poortnummer is ongeldig."" msgid """" ""The \""to\"" port number must be greater than or equal to the \""from\"" port "" ""number."" msgstr """" ""Het \""tot\"" poortnummer moet groter dan of gelijk aan het \""van\"" "" ""poortnummer zijn."" msgid ""The Aggregate was updated."" msgstr ""Het aggregaat is aangepast."" msgid ""The ICMP code not in range (-1, 255)"" msgstr ""De ICMP code valt niet binnen het geldige bereik (-1, 255)"" msgid ""The ICMP type not in range (-1, 255)"" msgstr ""Het ICMP tpye valt niet binnen het geldige bereik (-1, 255)"" #, python-format msgid ""The ID \""%s\"" is already used by another flavor."" msgstr ""De ID \""%s\"" is al in gebruik door een andere smaak."" msgid """" ""The Image Location field MUST be a valid and direct URL to the image binary. "" ""URLs that redirect or serve error pages will result in unusable images."" msgstr """" ""Het afbeeldingslocatieveld MOET een valide en directe URL zijn naar de "" ""programma-afbeelding. URL's die doorverwijzen of eindigen in "" ""foutmeldingspagina's zullen resulteren in onbruikbare afbeeldingen."" msgid ""The Key Pair name that was associated with the instance"" msgstr ""De naam van het sleutelpaar dat is gekoppeld met het exemplaar"" #, python-format msgid """" ""The Volume size is too small for the '%(image_name)s' image and has to be "" ""greater than or equal to '%(smallest_size)d' GB."" msgstr """" ""De volumegrootte is te klein voor de '%(image_name)s' afbeelding en moet "" ""minimaal '%(smallest_size)d' GB groot zijn."" msgid """" ""The chart below shows the resources used by this project in relation to the "" ""project's quotas."" msgstr """" ""De kaart hieronder toont de middelen benut door dit project in relatie tot "" ""de projectquota's."" #, python-format msgid """" ""The flavor '%(flavor)s' is too small for requested image.\n"" ""Minimum requirements: %(min_ram)s MB of RAM and %(min_disk)s GB of Root Disk."" msgstr """" ""De smaak '%(flavor)s' is te klein voor de aangevraagde afbeelding.\n"" ""Minimale vereisten: %(min_ram)s MB aan werkgeheugen en %(min_disk)s GB voor "" ""de hoofdschijf."" msgid ""The instance password encrypted with your public key."" msgstr ""Het exemplaar wachtwoord versleuteld met uw publieke sleutel."" msgid """" ""The minimum disk size required to boot the image. If unspecified, this value "" ""defaults to 0 (no minimum)."" msgstr """" ""De minimum schijfgrootte benodigd om de afbeelding te starten. Indien "" ""ongespecificeerd staat deze waarde standaard op 0 (geen minimum)."" msgid """" ""The minimum memory size required to boot the image. If unspecified, this "" ""value defaults to 0 (no minimum)."" msgstr """" ""De minimum geheugengrootte benodigd om de afbeelding te starten. Indien "" ""ongespecificeerd staat deze waarde standaard op 0 (geen minimum)."" #, python-format msgid ""The name \""%s\"" is already used by another flavor."" msgstr ""De naam \""%s\"" is al in gebruik door een andere smaak."" #, python-format msgid ""The name \""%s\"" is already used by another host aggregate."" msgstr ""De naam \""%s\"" al al en gebruik door een ander gastheeraggregaat."" msgid """" ""The private key will be only used in your browser and will not be sent to "" ""the server"" msgstr """" ""De privsleutel zal alleen in de webbrowser gebruikt worden en niet naar de "" ""server verzonden worden."" msgid ""The specified port is invalid."" msgstr ""De gespecificeerde poort is ongeldig."" #, python-format msgid ""The subnet in the Network Address is too small (/%s)."" msgstr ""Het subnet in het netwerkadres is te klein (/%s)."" #, python-format msgid ""The volume size cannot be less than the image size (%s)"" msgstr ""Het volume kan niet kleiner zijn dan de afbeelding (%s)"" msgid ""There are no networks, routers, or connected instances to display."" msgstr """" ""Er zijn geen netwerken, routers of verbonden exemplaren om weer te geven."" msgid """" ""There is not enough capacity for this flavor in the selected availability "" ""zone. Try again later or select a different availability zone."" msgstr """" ""Er is onvoldoende capaciteit voor deze smaak in de gekozen "" ""beschikbaarheidszone. Probeert u later opnieuw of selecteer een andere "" ""beschikbaarheidszone."" #, python-format msgid ""There was a problem parsing the %(prefix)s: %(error)s"" msgstr """" ""Er heeft een fout opgetreden bij het verwerken van %(prefix)s: %(error)s"" msgid """" ""This generates a pair of keys: a key you keep private (cloud.key) and a "" ""public key (cloud.key.pub). Paste the contents of the public key file here."" msgstr """" ""Dit genereert een sleutelpaar: de prive sleutel (cloud.key) wordt veilig "" ""bewaard en de publieke sleutel (cloud.key.pub). Kopieer de inhoud van de "" ""publieke sleutel hier."" msgid """" ""This volume is currently attached to an instance. In some cases, creating a "" ""snapshot from an attached volume can result in a corrupted snapshot."" msgstr """" ""Dit volume is momenteel gekoppeld aan een exemplaar. In bepaalde gevallen "" ""kan het maken van een momentopname van een gekoppeld volume resulteren in "" ""een beschadigde momentopname."" msgid ""Timezone"" msgstr ""Tijdzone"" msgid ""To Port"" msgstr ""Tot poort"" msgid """" ""To decrypt your password you will need the private key of your key pair for "" ""this instance. Select the private key file, or copy and paste the content of "" ""your private key file into the text area below, then click Decrypt Password."" msgstr """" ""Om uw wachtwoord te ontcijferen heeft u de privsleutel van het sleutelpaar "" ""nodig dat behoord bij dit exemplaar. Selecteer het privsleutel bestand, of "" ""kopieer en plak de inhoud van het privsleutel bestand in het tekstvak "" ""hieronder, en klik vervolgens op \""Wachtwoord ontcijferen\"". "" msgid ""To exit the fullscreen mode, click the browser's back button."" msgstr """" ""Klik op de Terug knop in de webbrowser om uit de volledig scherm modus te "" ""gaan."" msgid ""Topology"" msgstr ""Topologie"" msgid ""Total Disk"" msgstr ""Schijftotaal"" msgid ""Total RAM"" msgstr ""Totaal werkgeheugen"" msgid ""Total Size of Volumes and Snapshots (GB)"" msgstr ""Totale grootte van de volumen en momentopnamen (GB)"" msgid ""Type"" msgstr ""Type"" msgctxt ""Admin state of a Network"" msgid ""UP"" msgstr ""OMHOOG"" msgctxt ""Admin state of a Port"" msgid ""UP"" msgstr ""OMHOOG"" msgctxt ""Admin state of a Router"" msgid ""UP"" msgstr ""OMHOOG"" msgid ""UTC"" msgstr ""UTC"" msgid ""Unable to add rule to security group."" msgstr ""Niet in staat om de regel toe te voegen aan de beveiligingsgroep."" msgid ""Unable to add user to primary project."" msgstr ""Niet in staat om de gebruiker toe te voegen aan het primaire project."" msgid ""Unable to allocate Floating IP."" msgstr ""Niet in staat om het vlottend IP toe te wijzen."" #, python-format msgid ""Unable to associate IP address %s."" msgstr ""Niet in staat om het IP adres %s aan te koppelen."" msgid ""Unable to attach volume."" msgstr ""Niet in staat om het volume aan te koppelen."" msgid ""Unable to change password."" msgstr ""Niet in staat om het wachtwoord te wijzigen."" msgid ""Unable to connect to Neutron."" msgstr ""Niet in staat om te verbinden met Neutron."" #, python-format msgid ""Unable to create domain \""%s\""."" msgstr ""Niet in staat om domein \""%s\"" te creren."" #, python-format msgid ""Unable to create flavor \""%s\""."" msgstr ""Niet in staat om de smaak \""%s\"" te creren."" msgid ""Unable to create flavor."" msgstr ""Niet in staat om de smaak te creren."" msgid ""Unable to create group."" msgstr ""Niet in staat om de groep te creren."" #, python-format msgid ""Unable to create host aggregate \""%s\""."" msgstr ""Het aanmaken van het nieuwe gastheersaggregaat \""%s\"" is mislukt."" msgid ""Unable to create host aggregate."" msgstr ""Het gastheersaggregaat kon niet worden aangemaakt."" #, python-format msgid ""Unable to create network \""%s\""."" msgstr ""Niet in staat om het netwerk \""%s\"" te creren."" #, python-format msgid ""Unable to create project \""%s\""."" msgstr ""Niet in staat om het project \""%s\"" te creren."" msgid ""Unable to create role."" msgstr ""Niet in staat om de rol te creren."" msgid ""Unable to create snapshot."" msgstr ""Niet in staat om de momentopname te creren."" #, python-format msgid ""Unable to create subnet \""%s\""."" msgstr ""Niet in staat om het subnet \""%s\"" te creren."" msgid ""Unable to create user."" msgstr ""Niet in staat om de gebruiker te creren."" msgid ""Unable to create volume snapshot."" msgstr ""Niet in staat om de momentopname van het volume te creren."" msgid ""Unable to create volume type."" msgstr ""Niet in staat om het volumetype te creren."" msgid ""Unable to create volume."" msgstr ""Niet in staat om het volume te creren."" msgid ""Unable to determine if availability zones extension is supported."" msgstr """" ""Niet in staat om vast te stellen of de beschikbaarheidszone uitbreiding "" ""ondersteund is."" msgid ""Unable to disassociate floating IP."" msgstr ""Niet in staat om het vlottend IP adres af te koppelen."" msgid ""Unable to extend volume."" msgstr ""Kon het volume niet uitbreiden."" msgid ""Unable to fetch EC2 credentials."" msgstr ""Niet in staat om de EC2 identiteitsgegevens op te halen."" #, python-format msgid ""Unable to get RDP console for instance \""%s\""."" msgstr ""Kon het RDP beheervenster voor exemplaar \""%s\"" niet openen."" #, python-format msgid ""Unable to get SPICE console for instance \""%s\""."" msgstr """" ""Niet in staat om het SPICE beheervenster te verkrijgen voor exemplaar \""%s\""."" #, python-format msgid ""Unable to get VNC console for instance \""%s\""."" msgstr """" ""Niet in staat om het VNC beheervenster te verkrijgen voor exemplaar \""%s\""."" msgid ""Unable to get flavor list"" msgstr ""Niet in staat om de smakenlijst op te halen"" msgid ""Unable to get host aggregate list"" msgstr ""De gastheeraggregatielijst kan niet worden opgehaald"" #, python-format msgid ""Unable to get log for instance \""%s\""."" msgstr ""Niet in staat om het log te verkrijgen voor exemplaar \""%s\""."" msgid ""Unable to get network agents list."" msgstr ""Niet in staat om de netwerkagentenlijst op te halen."" msgid ""Unable to get nova services list."" msgstr ""Niet in staat om de Nova dienstenlijst te verkrijgen."" #, python-format msgid ""Unable to get subnet \""%s\"""" msgstr ""Niet in staat om het subnet \""%s\"" te verkrijgen"" msgid ""Unable to get the available hosts"" msgstr ""Kon de beschikbare gastheren niet ophalen."" msgid ""Unable to import key pair."" msgstr ""Niet in staat om het sleutelpaar te importeren."" #, python-format msgid ""Unable to launch %(count)s named \""%(name)s\""."" msgstr ""Niet in staat om %(count)s te starten genaamd \""%(name)s\""."" #, python-format msgid ""Unable to load the specified image. %s"" msgstr ""Niet in staat om de gespecificeerde afbeelding te laden. %s"" msgid ""Unable to load the specified snapshot."" msgstr ""Niet in staat om de gespecificeerde momentopname te laden."" #, python-format msgid ""Unable to load the specified volume. %s"" msgstr ""Kon het gekozen volume niet laden. %s"" #, python-format msgid ""Unable to modify domain \""%s\""."" msgstr ""Niet in staat om domein \""%s\"" te bewerken."" #, python-format msgid ""Unable to modify instance \""%s\""."" msgstr ""Niet in staat om het exemplaar \""%s\"" aan te passen."" #, python-format msgid ""Unable to modify project \""%s\""."" msgstr ""Niet in staat om het project \""%s\"" aan te passen."" #, python-format msgid ""Unable to parse IP address %s."" msgstr ""Niet in staat om het IP adres %s te verwerken."" msgid ""Unable to rebuild instance."" msgstr ""Niet in staat om het exemplaar te herbouwen."" #, python-format msgid ""Unable to resize instance \""%s\""."" msgstr ""Niet in staat om de grootte van het exemplaar \""%s\"" aan te passen."" msgid ""Unable to retrieve IP addresses from Neutron."" msgstr ""Niet in staat om de IP adressen van Neutron op te halen."" #, python-format msgid ""Unable to retrieve a list of external networks \""%s\""."" msgstr ""Niet in staat om een lijst met externe netwerken \""%s\"" op te halen."" #, python-format msgid ""Unable to retrieve an external network \""%s\""."" msgstr ""Niet in staat om een extern netwerk \""%s\"" op te halen."" msgid ""Unable to retrieve attachment information."" msgstr ""Niet in staat om de aankoppelingsinformatie op te halen."" msgid ""Unable to retrieve availability zone list."" msgstr ""Niet in staat de beschikbaarheidszonelijst op te halen."" msgid ""Unable to retrieve availability zones."" msgstr ""Niet in staat om de beschikbaarheidszones op te halen."" msgid ""Unable to retrieve compute limit information."" msgstr ""Niet in staat om de rekendienst limietinformatie op te halen."" #, python-format msgid ""Unable to retrieve details for instance \""%s\""."" msgstr ""Niet in staat om de details voor exemplaar \""%s\"" op te halen."" #, python-format msgid ""Unable to retrieve details for network \""%s\""."" msgstr ""Niet in staat om de details voor netwerk \""%s\"" op te halen."" #, python-format msgid ""Unable to retrieve details for router \""%s\""."" msgstr ""Niet in staat om de details voor router \""%s\"" op te halen."" msgid ""Unable to retrieve domain details."" msgstr ""Niet in staat om de domeindetails op te halen."" msgid ""Unable to retrieve domain list."" msgstr ""Niet in staat om de domeinlijst op te halen."" msgid ""Unable to retrieve extensions information."" msgstr ""Niet in staat om de uitbreidingsinformatie op te halen."" msgid ""Unable to retrieve extra spec list."" msgstr ""Niet in staat om de extra specificatie op te halen."" msgid ""Unable to retrieve flavor access list. Please try again later."" msgstr """" ""Niet in staat om de smaaktoegangslijst op te halen. Probeert u het later nog "" ""eens."" msgid ""Unable to retrieve flavor details."" msgstr ""Niet in staat om de smaakdetails op te halen."" msgid ""Unable to retrieve flavor list."" msgstr ""Niet in staat om de smakenlijst op te halen."" msgid ""Unable to retrieve flavors."" msgstr ""Niet in staat om de smaken op te halen."" msgid ""Unable to retrieve floating IP addresses."" msgstr ""Niet in staat om de vlottende IP adressen op te halen."" msgid ""Unable to retrieve floating IP pools."" msgstr ""Niet in staat om de vlottende IP poules op te halen."" msgid ""Unable to retrieve group list."" msgstr ""Niet in staat om de groepslijst op te halen."" msgid ""Unable to retrieve group list. Please try again later."" msgstr """" ""Niet in staat om de groepslijst op te halen. Probeert u het later nog eens."" msgid ""Unable to retrieve group users."" msgstr ""Niet in staat om de gebruikers van de groep op te halen."" msgid ""Unable to retrieve host aggregates list."" msgstr ""Niet in staat om de gastheeraggregatielijst op te halen."" msgid ""Unable to retrieve hypervisor information."" msgstr ""Niet in staat om de hypervisorinformatie op te halen."" msgid ""Unable to retrieve hypervisor instances list."" msgstr ""De lijst met hypervisor exemplaren kon niet worden opgehaald."" msgid ""Unable to retrieve hypervisor statistics."" msgstr ""Niet in staat om de hypervisorstatistieken op te halen."" msgid ""Unable to retrieve image details."" msgstr ""Niet in staat om de afbeeldingsdetails op te halen."" msgid ""Unable to retrieve image list."" msgstr ""Niet in staat om de afbeeldingslijst op te halen."" msgid ""Unable to retrieve image."" msgstr ""Niet in staat om de afbeelding op te halen."" msgid ""Unable to retrieve images for the current project."" msgstr ""Niet in staat om de afbeeldingen voor het huidige project op te halen."" msgid ""Unable to retrieve images."" msgstr ""Niet in staat om de afbeeldingen op te halen."" msgid ""Unable to retrieve instance details."" msgstr ""Niet in staat om de details van het exemplaar op te halen."" msgid ""Unable to retrieve instance flavors."" msgstr ""Niet in staat om de exemplaarsmaken op te halen."" msgid ""Unable to retrieve instance list."" msgstr ""Niet in staat om de exemplarenlijst op te halen."" msgid ""Unable to retrieve instance password."" msgstr ""Kon het wachtwoord van het exemplaar niet ophalen."" msgid ""Unable to retrieve instance project information."" msgstr ""Niet in staat om de projectinformatie voor het exemplaar op te halen."" msgid ""Unable to retrieve instance size information."" msgstr """" ""Niet in staat om de afmetingsinformatie voor het exemplaar op te halen."" msgid ""Unable to retrieve instances."" msgstr ""Niet in staat om de exemplaren op te halen."" msgid ""Unable to retrieve key pair list."" msgstr ""Niet in staat om de sleutelparenlijst op te halen."" msgid ""Unable to retrieve key pairs."" msgstr ""Kon de sleutelparen niet ophalen."" msgid ""Unable to retrieve list of security groups"" msgstr ""Niet in staat om de beveiligingsgroepenlijst op te halen."" msgid ""Unable to retrieve list of volume snapshots."" msgstr ""Niet in staat om de lijst met volume momentopnamen op te halen."" msgid ""Unable to retrieve list of volumes."" msgstr ""Niet in staat om de volumelijst op te halen."" msgid ""Unable to retrieve network details."" msgstr ""Niet in staat om de netwerkdetails op te halen."" msgid ""Unable to retrieve network."" msgstr ""Niet in staat om het netwerk op te halen."" msgid ""Unable to retrieve port details"" msgstr ""Niet in staat om de poortdetails op te halen"" msgid ""Unable to retrieve port details."" msgstr ""Niet in staat om de poortdetails op te halen."" msgid ""Unable to retrieve project details."" msgstr ""Niet in staat om de projectdetails op te halen."" msgid ""Unable to retrieve project domain."" msgstr ""Niet in staat om het projectdomein op te halen."" msgid ""Unable to retrieve project information."" msgstr ""Niet in staat om de projectinformatie op te halen."" msgid ""Unable to retrieve project list."" msgstr ""Niet in staat om de projectlijst op te halen."" msgid ""Unable to retrieve public images."" msgstr ""Niet in staat om de publieke afbeeldingen op te halen."" msgid ""Unable to retrieve quota information."" msgstr ""Niet in staat om de quotainformatie op te halen."" msgid ""Unable to retrieve role list."" msgstr ""Niet in staat om de rollenlijst op te halen."" msgid ""Unable to retrieve roles list."" msgstr ""Niet in staat om de rollenlijst op te halen."" msgid ""Unable to retrieve router details."" msgstr ""Niet in staat om de routerdetails op te halen."" msgid ""Unable to retrieve router list."" msgstr ""Niet in staat om de routerlijst op te halen."" msgid ""Unable to retrieve router."" msgstr ""Niet in staat om de router op te halen."" msgid ""Unable to retrieve security group list. Please try again later."" msgstr """" ""Niet in staat om de beveiligingsgroepslijst op te vragen. Probeert u het "" ""later nog eens."" msgid ""Unable to retrieve security group."" msgstr ""Niet in staat om de beveiligingsgroep op te halen."" msgid ""Unable to retrieve security groups."" msgstr ""Niet in staat om de beveiligingsgroepen op te halen."" msgid ""Unable to retrieve snapshot details."" msgstr ""Niet in staat om de details van de momentopname op te halen."" msgid ""Unable to retrieve subnet details"" msgstr ""Niet in staat om de subnetdetails op te halen"" msgid ""Unable to retrieve subnet details."" msgstr ""Niet in staat om de subnetdetails op te halen."" msgid ""Unable to retrieve the aggregate to be updated"" msgstr ""Niet in staat het te wijzigen aggregaat op te halen."" msgid ""Unable to retrieve usage information."" msgstr ""Niet in staat om de verbruiksinformatie op te halen."" msgid ""Unable to retrieve user list."" msgstr ""Niet in staat om de gebruikerslijst op te halen."" msgid ""Unable to retrieve user list. Please try again later."" msgstr """" ""Niet in staat om de gebruikerslijst op te halen. Probeert u het later nog "" ""eens."" msgid ""Unable to retrieve user roles."" msgstr ""Niet in staat om de gebruikersrollen op te halen."" msgid ""Unable to retrieve users."" msgstr ""Niet in staat om de gebruikers op te halen."" msgid ""Unable to retrieve volume details."" msgstr ""Niet in staat om de volumedetails op te halen."" msgid ""Unable to retrieve volume information."" msgstr ""Niet in staat om de volumeinformatie op te halen."" msgid ""Unable to retrieve volume limit information."" msgstr ""Niet in staat om de volume limietinformatie op te halen."" msgid ""Unable to retrieve volume list."" msgstr ""Niet in staat om de volumelijst op te halen."" msgid ""Unable to retrieve volume project information."" msgstr ""Niet in staat om de projectinformatie voor het volume op te halen."" msgid ""Unable to retrieve volume snapshots."" msgstr ""Niet in staat om de momentopnamen van het volume op te halen."" msgid ""Unable to retrieve volume types"" msgstr ""Niet in staat om de volumetypen op te halen."" msgid ""Unable to retrieve volume."" msgstr ""Niet in staat om het volume op te halen."" msgid ""Unable to retrieve volume/instance attachment information"" msgstr ""Niet in staat om de volume/exemplaar koppelingsinformatie op te halen."" msgid ""Unable to set Domain Context."" msgstr ""Niet in staat om de domeincontext in te stellen."" #, python-format msgid ""Unable to set flavor access for project %s."" msgstr ""Niet in staat om de smaaktoegang voor project %s in te stellen."" msgid ""Unable to set gateway."" msgstr ""Niet in staat om de gateway in te stellen."" msgid ""Unable to sort instance flavors."" msgstr ""Kon de exemplaarsmaken niet sorteren."" msgid ""Unable to update default quotas."" msgstr ""Niet in staat om de standaardquota bij te werken."" msgid ""Unable to update group."" msgstr ""Niet in staat om de groep bij te werken."" #, python-format msgid ""Unable to update image \""%s\""."" msgstr ""Niet in staat om de afbeelding \""%s\"" bij te werken."" msgid ""Unable to update role."" msgstr ""Niet in staat om de rol bij te werken."" #, python-format msgid ""Unable to update subnet \""%s\""."" msgstr ""Niet in staat om het subnet \""%s\"" bij te werken."" msgid ""Unable to update the aggregate."" msgstr ""Niet in staat het aggregaat aan te passen."" msgid ""Unable to update the group."" msgstr ""Niet in staat om de groep bij te werken."" msgid ""Unable to update the user."" msgstr ""Niet in staat om de gebruiker bij te werken."" msgid ""Unable to update volume."" msgstr ""Niet in staat om volume bij te werken."" msgid ""Unknown"" msgstr ""Onbekend"" msgid ""Unknown instance"" msgstr ""Onbekend Exemplaar"" msgid ""Unknown instance (None)"" msgstr ""Onbekend exemplaar (geen)"" msgid ""Up"" msgstr ""Omhoog"" msgctxt ""Current state of a Hypervisor"" msgid ""Up"" msgstr ""Omhoog"" msgid ""Update"" msgstr ""Bijwerken"" msgid ""Update Default Quotas"" msgstr ""Standaardquota's bijwerken"" msgid ""Update Defaults"" msgstr ""Standaarden bijwerken"" msgid ""Update Group"" msgstr ""Groep bijwerken"" msgid ""Update Network"" msgstr ""Netwerk bijwerken"" msgid ""Update Role"" msgstr ""Rol bijwerken"" msgid ""Update Router"" msgstr ""Router Vernieuwen"" msgid ""Update User"" msgstr ""Gebruiker bijwerken"" msgid ""Updated"" msgstr ""Bijgewerkt"" msgid ""Updated At"" msgstr ""Bijgewerkt op"" #, python-format msgid ""Updated subnet \""%s\""."" msgstr ""Subnet \""%s\"" bijgewerkt."" #, python-format msgid ""Updating volume \""%s\"""" msgstr ""Bijwerken volume \""%s\"""" msgid ""Upload"" msgstr ""Uploaden"" msgid ""Usage"" msgstr ""Verbruik"" msgid ""Usage (Hours)"" msgstr ""Verbruik (uren)"" msgid ""Usage Overview"" msgstr ""Verbruiks-overzicht"" msgid ""Use a volume as source"" msgstr ""Gebruik een volume als bron"" msgid ""Use image as a source"" msgstr ""Gebruik een afbeelding as bron"" msgid ""Use snapshot as a source"" msgstr ""Gebruik een momentopname als bron"" #, python-format msgid ""Used <span> %(used)s </span> of <span> %(available)s </span>"" msgstr ""Gebruikt <span> %(used)s </span> van <span> %(available)s </span>"" msgid ""User"" msgstr ""Gebruiker"" #, python-format msgid ""User \""%s\"" was successfully created."" msgstr ""Gebruiker \""%s\"" was succesvol gecreeerd."" #, python-format msgid ""User %s has no role defined for that project."" msgstr ""Gebruiker %s kent geen gedefinieerde rol voor dat project."" msgid ""User ID"" msgstr ""Gebruiker ID"" msgid ""User Name"" msgstr ""Gebruikersnaam"" msgid ""User Settings"" msgstr ""Gebruikersinstellingen"" msgid ""User has been updated successfully."" msgstr ""Gebruiker is succesvol bijgewerkt."" msgid ""Users"" msgstr ""Gebruikers"" msgid ""VCPU"" msgstr ""VCPUs"" msgid ""VCPU Hours"" msgstr ""VCPU uren"" msgid ""VCPU Usage"" msgstr ""VCPU verbruik"" msgid ""VCPUs"" msgstr ""VCPUs"" msgid ""VCPUs (total)"" msgstr ""VCPUs (totaal)"" msgid ""VCPUs (used)"" msgstr ""VCPUs (gebruikt)"" msgid ""VLAN"" msgstr ""VLAN"" msgid ""VXLAN"" msgstr ""VXLAN"" msgid ""Value"" msgstr ""Waarde"" msgid ""View Extra Specs"" msgstr ""Bekijk extra specificaties"" msgid ""View Full Log"" msgstr ""Bekijk volledig log"" msgid ""View Log"" msgstr ""Bekijk log"" msgid ""View Usage"" msgstr ""Bekijk verbruik"" msgid ""Virtual Size"" msgstr ""Virtuele grootte"" msgid ""Volume"" msgstr ""Volume"" msgid ""Volume Limits"" msgstr ""Volumelimieten"" msgid ""Volume Name"" msgstr ""Volumenaam"" msgid ""Volume Snapshot"" msgstr ""Volume momentopname"" msgid ""Volume Snapshots"" msgstr ""Volume momentopnames"" msgid ""Volume Source"" msgstr ""Volumebron"" msgid ""Volume Type"" msgstr ""Volumetype"" msgid ""Volume Types"" msgstr ""Volumetypen"" msgid ""Volume size in gigabytes (integer value)."" msgstr ""Volumegrootte in Gigabytes (geheel getal)"" #, python-format msgid ""Volume size must be equal to or greater than the image size (%s)"" msgstr """" ""Volumegrootte moet gelijk of groter zijn dan de grootte van de afbeelding "" ""(%sGB)"" msgid ""Volumes"" msgstr ""Volumen"" msgid ""Volumes Attached"" msgstr ""Aangekoppelde volumes."" msgid ""Yes"" msgstr ""Ja"" msgid ""You are already using all of your available floating IPs."" msgstr ""U gebruikt reeds al uw beschikbare vlottende IPs."" msgid ""You are already using all of your available volumes."" msgstr ""U gebruikt reeds al uw beschikbare volumes."" msgid """" ""You can connect a specified external network to the router. The external "" ""network is regarded as a default route of the router and the router acts as "" ""a gateway for external connectivity."" msgstr """" ""U kunt een gespecificeerd extern netwerk verbinden aan de router. Het "" ""externe netwerk is beschouwd als een standaardroute van de router en de "" ""router acteert als gateway voor externe connectiviteit."" msgid ""You can connect a specified subnet to the router."" msgstr ""U kunt een gespecificeerd subnet verbinden met de router."" msgid """" ""You can create a port for the network. If you specify device ID to be "" ""attached, the device specified will be attached to the port created."" msgstr """" ""U kunt een poort voor het netwerk creren. Indien u een te koppelen apparaat "" ""ID specificeert zal deze gekoppeld worden met de aan te maken poort."" msgid """" ""You can specify the desired rule template or use custom rules, the options "" ""are Custom TCP Rule, Custom UDP Rule, or Custom ICMP Rule."" msgstr """" ""U kunt het gewenste regelsjabloon specificeren of maatwerk regels gebruiken. "" ""De opties zijn Maatwerk TCP regel, Maatwerk UDP regel of Maatwerk ICMP regel."" msgid """" ""You cannot revoke your administrative privileges from the project you are "" ""currently logged into. Please switch to another project with administrative "" ""privileges or remove the administrative role manually via the CLI."" msgstr """" ""U kunt uw beheerrechten niet intrekken van een project waarin u op dit "" ""moment bent aangemeld. Wisselt u alstublieft naar een ander project met "" ""beheerrechten of verwijder de beheerrol via de CLI."" msgid ""You may have mistyped the address or the page may have moved."" msgstr """" ""Wellicht heeft u het adres verkeerd ingegeven of is de pagina verhuisd."" msgid ""You may optionally set a password on the rebuilt instance."" msgstr """" ""U kunt optioneel een wachtwoord instellen voor het herbouwde exemplaar."" msgid ""You may update the editable properties of your network here."" msgstr ""U kunt hier de bewerkbare eigenschappen van uw netwerk bijwerken."" msgid ""You must select a snapshot."" msgstr ""U moet een momentopname selecteren."" msgid ""You must select a volume."" msgstr ""U moet een volume selecteren."" msgid ""You must select an image."" msgstr ""U moet een afbeelding selecteren."" msgid ""You must set volume size"" msgstr ""U moet een volumegrootte instellen"" msgid """" ""You must specify the source of the traffic to be allowed via this rule. You "" ""may do so either in the form of an IP address block (CIDR) or via a source "" ""group (Security Group). Selecting a security group as the source will allow "" ""any other instance in that security group access to any other instance via "" ""this rule."" msgstr """" ""U moet de bron opgeven van het verkeer dat via deze regel toegestaan gaat "" ""worden. Dit mag een IP adres blok (CIDR) of een brongroep "" ""(beveiligingsgroep) zijn. Bij het gebruik van een veiligheidsgroep als bron "" ""krijgen alle exemplaren in die beveiligingsgroep via deze regel toegang tot "" ""de andere exemplaren."" #, python-format msgid ""Your image %s has been queued for creation."" msgstr ""Uw afbeelding %s is in de wachtrij geplaatst voor creatie."" msgid ""Zone"" msgstr ""Zone"" msgctxt ""Both of front-end and back-end"" msgid ""both"" msgstr ""beiden"" msgid ""dm-crypt"" msgstr ""dm-crypt"" msgid ""instance"" msgstr ""Exemplaar"" ",338,3313
openstack%2Ftripleo-common~master~I86bfbc4729840bb38b2a30065fcffbdf19ee0add,openstack/tripleo-common,master,I86bfbc4729840bb38b2a30065fcffbdf19ee0add,placement: Reintroduce healthcheck,ABANDONED,2019-02-08 15:00:05.000000000,2019-02-11 10:05:16.000000000,,"[{'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-08 15:00:05.000000000', 'files': ['container-images/tripleo_kolla_template_overrides.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/098b0f9332da582c5ae786c8743dd3f20f9b588b', 'message': 'placement: Reintroduce healthcheck\n\nChange-Id: I86bfbc4729840bb38b2a30065fcffbdf19ee0add\n'}]",0,635854,098b0f9332da582c5ae786c8743dd3f20f9b588b,5,3,1,10135,,,0,"placement: Reintroduce healthcheck

Change-Id: I86bfbc4729840bb38b2a30065fcffbdf19ee0add
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/54/635854/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_kolla_template_overrides.j2'],1,098b0f9332da582c5ae786c8743dd3f20f9b588b,tripleo-placement-extraction,{% block placement_api_footer %} RUN mkdir -p /openstack && \ ln -s /usr/share/openstack-tripleo-common/healthcheck/placement-api /openstack/healthcheck && \ chmod a+rx /openstack/healthcheck {% endblock %},#TODO(aschultz): uncomment once we have promotion see LP#1813998 #{% block placement_api_footer %} #RUN mkdir -p /openstack && \ # ln -s /usr/share/openstack-tripleo-common/healthcheck/placement-api /openstack/healthcheck && \ # chmod a+rx /openstack/healthcheck #{% endblock %},5,6
openstack%2Ftripleo-heat-templates~master~Ib5e2dab1e94810ac02e5d64859d2e84f749f3994,openstack/tripleo-heat-templates,master,Ib5e2dab1e94810ac02e5d64859d2e84f749f3994,Disable stack check and cancel update for undercloud,MERGED,2019-02-05 05:19:25.000000000,2019-02-11 10:01:48.000000000,2019-02-08 16:11:23.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 17216}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-02-05 05:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/faa9f4c7597484d96b0080416678c64a32c83931', 'message': ""Disable stack check and cancel update for overcloud\n\n'overcloud update abort' command had been dropped since few\nreleases. However, users can still use heat commands to cancel\nan update which is not recommended.\n\nUndercloud now uses heat convergence architecture and stack check\nhas not been migrated to convergence yet.\n\nlet's add heat policy to disable both on undercloud.\n\nChange-Id: Ib5e2dab1e94810ac02e5d64859d2e84f749f3994\n""}, {'number': 2, 'created': '2019-02-05 05:20:57.000000000', 'files': ['releasenotes/notes/disable-heat-non-lifecycle-actions-d551fe4551d71770.yaml', 'environments/undercloud.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/18f4e11773bba8f2e4e5d4e2e175e713669f549f', 'message': ""Disable stack check and cancel update for undercloud\n\n'overcloud update abort' command had been dropped since few\nreleases. However, users can still use heat commands to cancel\nan update which is not recommended.\n\nUndercloud now uses heat convergence architecture and stack check\nhas not been migrated to convergence yet.\n\nlet's add heat policy to disable both on undercloud.\n\nChange-Id: Ib5e2dab1e94810ac02e5d64859d2e84f749f3994\n""}]",0,634853,18f4e11773bba8f2e4e5d4e2e175e713669f549f,12,6,2,8833,,,0,"Disable stack check and cancel update for undercloud

'overcloud update abort' command had been dropped since few
releases. However, users can still use heat commands to cancel
an update which is not recommended.

Undercloud now uses heat convergence architecture and stack check
has not been migrated to convergence yet.

let's add heat policy to disable both on undercloud.

Change-Id: Ib5e2dab1e94810ac02e5d64859d2e84f749f3994
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/634853/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/disable-heat-non-lifecycle-actions-d551fe4551d71770.yaml', 'environments/undercloud.yaml']",2,faa9f4c7597484d96b0080416678c64a32c83931,," # Disable non-lifecycle stack actions like # snapshot, resume, cancel update and stack check. HeatApiPolicies: heat-deny-action: key: 'actions:action' value: 'rule:deny_everybody'",,16,0
openstack%2Ftripleo-heat-templates~master~Ibb2d19c5db74817102fd49ab9b01fe2d90e49d39,openstack/tripleo-heat-templates,master,Ibb2d19c5db74817102fd49ab9b01fe2d90e49d39,Add RoleCtlplanePortMap output,ABANDONED,2018-07-02 13:28:20.000000000,2019-02-11 09:59:49.000000000,,"[{'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-07-02 13:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5e85d6975e8415ffed405ecf8fe3600033b7bc23', 'message': 'Add RoleCtlplanePortMap output\n\nThis outputs the ctlplane port ID in both the normal and deployed server\ncase, so we can discover the ID of the port that should be attached\nwhen creating servers via ironic instead of nova.\n\nPartially-Implements: blueprint nova-less-deploy\nChange-Id: Ibb2d19c5db74817102fd49ab9b01fe2d90e49d39\n'}, {'number': 2, 'created': '2018-07-25 12:38:11.000000000', 'files': ['overcloud.j2.yaml', 'puppet/role.role.j2.yaml', 'deployed-server/deployed-server.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9d7b4fc8b3e395b1e056d8dca9ae1194df90112e', 'message': 'Add RoleCtlplanePortMap output\n\nThis outputs the ctlplane port ID in both the normal and deployed server\ncase, so we can discover the ID of the port that should be attached\nwhen creating servers via ironic instead of nova.\n\nPartially-Implements: blueprint nova-less-deploy\nChange-Id: Ibb2d19c5db74817102fd49ab9b01fe2d90e49d39\n'}]",3,579556,9d7b4fc8b3e395b1e056d8dca9ae1194df90112e,11,6,2,4328,,,0,"Add RoleCtlplanePortMap output

This outputs the ctlplane port ID in both the normal and deployed server
case, so we can discover the ID of the port that should be attached
when creating servers via ironic instead of nova.

Partially-Implements: blueprint nova-less-deploy
Change-Id: Ibb2d19c5db74817102fd49ab9b01fe2d90e49d39
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/56/579556/1 && git format-patch -1 --stdout FETCH_HEAD,"['overcloud.j2.yaml', 'puppet/role.role.j2.yaml', 'deployed-server/deployed-server.yaml']",3,5e85d6975e8415ffed405ecf8fe3600033b7bc23,bp/nova-less-deploy, addresses: value: ctlplane: [{port: {get_resource: ControlPlanePort}}],,11,0
openstack%2Ftripleo-heat-templates~master~I991e30b1debadfa76f1fffb80bd9e5798b6cd527,openstack/tripleo-heat-templates,master,I991e30b1debadfa76f1fffb80bd9e5798b6cd527,"Enable decoupled deployment plans e.g for OpenShift, DPDK etc",ABANDONED,2018-06-12 14:56:50.000000000,2019-02-11 09:59:41.000000000,,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 7509}, {'_account_id': 8449}, {'_account_id': 8871}, {'_account_id': 11085}, {'_account_id': 13039}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 18575}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2018-06-12 14:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b5f05df8589a4de37358f8cae206b231b0afb6ed', 'message': 'WIP enable decoupled plan-samples e.g for OpenShift\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI\'s that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, but for now the focus is defining a reasonable split\nbetween the ""core"" tripleo deployment interfaces, and the OpenStack\nspecific services which are deployed by default.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n'}, {'number': 2, 'created': '2018-06-13 10:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/252e23db1a61986b2909d6fb83161c2f8ef050cb', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 3, 'created': '2018-06-13 15:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/67b60be7e79df5cdb35fae614789d8041249ee86', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 4, 'created': '2018-06-13 15:25:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a4f9f60b370b0ec05aea16006da83a22cb5736d8', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 5, 'created': '2018-06-14 08:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3cf487dcd9a96c91dff7c8a5a204bc4f4270d7d8', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 6, 'created': '2018-06-14 10:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e97dc41e5669d72a7a0d90743004e24f3644f426', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 7, 'created': '2018-06-18 11:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2d01ff4a0a47d60fcd7e97807e594ae86aadde05', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 8, 'created': '2018-06-18 11:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ef59e8f929e6f0f0f8c1b3efd8b7e8d190712a33', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 9, 'created': '2018-06-18 13:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/214b0b4fc2da5b74f927f5f3eaf47b8f4b94acf3', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 10, 'created': '2018-06-18 14:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b41295560f747e25fe5575d9e21cad3722772378', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 11, 'created': '2018-06-18 14:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0d477c9241a81b76ec7c363b77d13671aad2b4ef', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 12, 'created': '2018-06-19 10:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/51266c28d6ec6bd616fbaa269c275503b3640ac5', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 13, 'created': '2018-06-20 10:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/58a0631ee92de2e058d09d55d8933e8ea806d489', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 14, 'created': '2018-07-04 13:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/82ade8ea89f58154fcf921dddfdfc4096d7ddaa7', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nDepends-On: Ie26c2df437759a1b99c2498c9ba3039e2ac1c4ae\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 15, 'created': '2018-07-13 10:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a55c7966e05115e586bc982efa0442a8fe384e38', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nDepends-On: Ie26c2df437759a1b99c2498c9ba3039e2ac1c4ae\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 16, 'created': '2018-07-13 12:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6819ee3d037ccd9769ff1f6ebdc99ab05dacc43c', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nDepends-On: Ie26c2df437759a1b99c2498c9ba3039e2ac1c4ae\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 17, 'created': '2018-07-16 10:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/411747f1b7ef29faeba858c850d2e0e34436af85', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nDepends-On: Ie26c2df437759a1b99c2498c9ba3039e2ac1c4ae\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 18, 'created': '2018-07-16 10:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a05de2e4f8e38285f202427a13c3b9a9a0464cbe', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nThis also includes sample roles for OpenShift which use the new\nrole tags interface in the plan-environment.\n\nDepends-On: I5ce97e7970648e65041a69a691aade2193834fb9\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 19, 'created': '2018-07-17 14:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a4cfe70abb10d09fca8f1a31044498d42126965', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nDepends-On: I5ce97e7970648e65041a69a691aade2193834fb9\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 20, 'created': '2018-07-18 07:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6603e6cce96fb896e7fa896b44432b710f900d8', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 21, 'created': '2018-07-18 08:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1352497b97a076bf7f55af17e345f8d3d482f794', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}, {'number': 22, 'created': '2018-07-27 14:50:22.000000000', 'files': ['plan-environment.yaml', 'plan-samples/openshift/capabilities-map.yaml', 'plan-samples/openstack-derived-params/plan-environment.yaml', 'environments/openshift-services-environment.yaml', 'plan-samples/openshift/plan-environment.yaml', 'base-environment.j2.yaml', 'capabilities-map.yaml', 'environments/openstack-services-environment.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'plan-samples/README.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/028fd48893226c8dd5ebe53897cebeb832a5a1df', 'message': ""Enable decoupled deployment plans e.g for OpenShift, DPDK etc\n\nThis is exploring how we might pass a different -p option to the\nvarious CLI's that accept it, such that for example we can create\na plan which only deals with OpenShift without the default OpenStack\nservices and associated configuration options.\n\nThe same pattern could potentially be applied to other applications\ne.g ceph, and as in this patch specific OpenStack configurations\nsuch as DPDK.\n\nChange-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527\n""}]",28,574753,028fd48893226c8dd5ebe53897cebeb832a5a1df,113,16,22,4328,,,0,"Enable decoupled deployment plans e.g for OpenShift, DPDK etc

This is exploring how we might pass a different -p option to the
various CLI's that accept it, such that for example we can create
a plan which only deals with OpenShift without the default OpenStack
services and associated configuration options.

The same pattern could potentially be applied to other applications
e.g ceph, and as in this patch specific OpenStack configurations
such as DPDK.

Change-Id: I991e30b1debadfa76f1fffb80bd9e5798b6cd527
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/574753/14 && git format-patch -1 --stdout FETCH_HEAD,"['plan-environment.yaml', 'plan-samples/openshift/capabilities-map.yaml', 'plan-samples/openshift/openshift-services-envionment.yaml', 'plan-samples/openshift/plan-environment.yaml', 'base-environment.j2.yaml', 'capabilities-map.yaml', 'plan-samples/plan-environment-derived-params.yaml', 'openstack-services-environment.yaml']",8,b5f05df8589a4de37358f8cae206b231b0afb6ed,alternate_plans,," OS::TripleO::SoftwareDeployment: config-download-structured.yaml OS::Heat::SoftwareDeployment: config-download-software.yaml OS::Heat::StructuredDeployment: config-download-structured.yaml OS::TripleO::PostDeploySteps: common/post.yaml OS::TripleO::AllNodes::SoftwareConfig: puppet/all-nodes-config.yaml OS::TripleO::AllNodesDeployment: OS::Heat::StructuredDeployments OS::TripleO::Hosts::SoftwareConfig: hosts-config.yaml OS::TripleO::Ssh::HostPubKey: OS::Heat::None OS::TripleO::Ssh::KnownHostsConfig: extraconfig/tasks/ssh/known_hosts_config.yaml OS::TripleO::Ssh::KnownHostsDeployment: OS::Heat::None OS::TripleO::DefaultPasswords: default_passwords.yaml OS::TripleO::RandomString: OS::Heat::RandomString OS::TripleO::Reboot::SoftwareDeployment: OS::Heat::None {% for role in roles %} OS::TripleO::{{role.name}}::PreNetworkConfig: OS::Heat::None OS::TripleO::{{role.name}}PostDeploySteps: common/post.yaml OS::TripleO::{{role.name}}: puppet/{{role.name.lower()}}-role.yaml OS::TripleO::Tasks::{{role.name}}PreConfig: OS::Heat::None OS::TripleO::Tasks::{{role.name}}PostConfig: OS::Heat::None OS::TripleO::{{role.name}}ExtraConfigPre: puppet/extraconfig/pre_deploy/default.yaml # Port assignments for the {{role.name}} role {%- for network in networks %} OS::TripleO::{{role.name}}::Ports::{{network.name}}Port: network/ports/noop.yaml {%- endfor %} OS::TripleO::{{role.name}}::Net::SoftwareConfig: net-config-noop.yaml {% endfor %} # This resource registry entry will override the one generated by default # in the jinja loop OS::TripleO::Controller::Net::SoftwareConfig: net-config-bridge.yaml OS::TripleO::ServiceServerMetadataHook: OS::Heat::None OS::TripleO::Server: OS::Nova::Server {% for role in roles %} OS::TripleO::{{role.name}}Server: OS::TripleO::Server {% endfor %} # This creates the ""heat-admin"" user for all OS images by default # To disable, replace with firstboot/userdata_default.yaml OS::TripleO::NodeAdminUserData: firstboot/userdata_heat_admin.yaml # Hooks for operator extra config # NodeUserData == Cloud-init additional user-data, e.g cloud-config # role::NodeUserData == Role specific cloud-init additional user-data # ControllerExtraConfigPre == Controller configuration pre service deployment # NodeExtraConfig == All nodes configuration pre service deployment # NodeExtraConfigPost == All nodes configuration post service deployment OS::TripleO::NodeUserData: firstboot/userdata_default.yaml {% for role in roles %} OS::TripleO::{{role.name}}::NodeUserData: firstboot/userdata_default.yaml {% endfor %} OS::TripleO::NodeTLSCAData: OS::Heat::None OS::TripleO::NodeTLSData: OS::Heat::None OS::TripleO::NodeExtraConfig: puppet/extraconfig/pre_deploy/default.yaml OS::TripleO::NodeExtraConfigPost: extraconfig/post_deploy/default.yaml # ""AllNodes"" Extra cluster config, runs on all nodes prior to the post_deploy # phase, e.g when puppet is applied, but after the pre_deploy phase. Useful when # configuration with knowledge of all nodes in the cluster is required vs single # node configuration in the pre_deploy step. # See extraconfig/all_nodes/* for examples OS::TripleO::AllNodesExtraConfig: OS::Heat::None # TripleO overcloud networks OS::TripleO::Network: network/networks.yaml {%- for network in networks %} OS::TripleO::Network::{{network.name}}: OS::Heat::None {%- endfor %} OS::TripleO::Network::ExtraConfig: OS::Heat::None OS::TripleO::Network::Ports::NetVipMap: network/ports/net_ip_map.yaml OS::TripleO::Network::Ports::NetIpMap: network/ports/net_ip_map.yaml OS::TripleO::Network::Ports::NetIpListMap: network/ports/net_ip_list_map.yaml # Port assignments for the VIPs {%- for network in networks if network.vip|default(false) %} OS::TripleO::Network::Ports::{{network.name}}VipPort: network/ports/noop.yaml {%- endfor %} OS::TripleO::Network::Ports::RedisVipPort: network/ports/ctlplane_vip.yaml OS::TripleO::Network::Ports::ControlPlaneVipPort: OS::Neutron::Port # Service to network Mappings OS::TripleO::ServiceNetMap: network/service_net_map.yaml # Service Endpoint Mappings OS::TripleO::EndpointMap: network/endpoints/endpoint_map.yaml # validation resources OS::TripleO::AllNodes::Validation: all-nodes-validation.yaml OS::TripleO::DeployedServerEnvironment: OS::Heat::None OS::TripleO::DeploymentSteps: OS::Heat::None OS::TripleO::WorkflowSteps: OS::Mistral::ExternalResource # services OS::TripleO::Services: common/services.yaml OS::TripleO::Services::OpenShift::Master: OS::Heat::None OS::TripleO::Services::OpenShift::Worker: OS::Heat::None OS::TripleO::Services::OpenShift::GlusterFS: OS::Heat::None OS::TripleO::Services::BootParams: extraconfig/pre_network/boot-params-service.yaml # Deprecated, only defined to allow smooth transition of existing # stacks. Can be removed in S release. OS::TripleO::Tasks::UpdateWorkflow: OS::Heat::None OS::TripleO::Tasks::PackageUpdate: OS::Heat::None parameter_defaults: EnablePackageInstall: false SoftwareConfigTransport: POLL_TEMP_URL {% for role in roles %} # Parameters generated for {{role.name}} Role {{role.name}}Services: {{role.ServicesDefault|default([])}} {% endfor %}",259,183
openstack%2Fpython-heatclient~master~I9484072c14d2c3c3f1d2e7243190119714e93294,openstack/python-heatclient,master,I9484072c14d2c3c3f1d2e7243190119714e93294,WIP Show all sections in the environment show output,ABANDONED,2018-03-27 12:24:58.000000000,2019-02-11 09:59:33.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-03-27 12:24:58.000000000', 'files': ['heatclient/osc/v1/stack.py', 'heatclient/tests/unit/osc/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/589a50975f6fd302a99a0f2e4c6b073c0f624705', 'message': ""WIP Show all sections in the environment show output\n\nCurrently we don't show some sections such as event_sinks and\nparameter_merge_strategies.\n\nWIP because this breaks the tests so I need to fix them up..\n\nChange-Id: I9484072c14d2c3c3f1d2e7243190119714e93294\n""}]",0,556837,589a50975f6fd302a99a0f2e4c6b073c0f624705,3,1,1,4328,,,0,"WIP Show all sections in the environment show output

Currently we don't show some sections such as event_sinks and
parameter_merge_strategies.

WIP because this breaks the tests so I need to fix them up..

Change-Id: I9484072c14d2c3c3f1d2e7243190119714e93294
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/37/556837/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/stack.py', 'heatclient/tests/unit/osc/v1/test_stack.py']",2,589a50975f6fd302a99a0f2e4c6b073c0f624705,," ENV_SECTIONS = ['parameter_defaults', 'parameters', 'resource_registry'] self.assertEqual(self.ENV_SECTIONS, columns)"," self.assertEqual(['parameters', 'resource_registry', 'parameter_defaults'], columns)",5,3
openstack%2Fpython-tripleoclient~master~I0ffad373937414ce3894bc89fbe6df8388cebb27,openstack/python-tripleoclient,master,I0ffad373937414ce3894bc89fbe6df8388cebb27,Don't merge environments during plan creation,ABANDONED,2017-03-21 17:36:44.000000000,2019-02-11 09:59:24.000000000,,"[{'_account_id': 4328}, {'_account_id': 6926}, {'_account_id': 7065}, {'_account_id': 7509}, {'_account_id': 9712}, {'_account_id': 10112}, {'_account_id': 18575}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-03-21 17:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c9cfb0a22b3199a35929cb15a5ad1542cd8143bc', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 2, 'created': '2017-03-22 16:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f856413b46f110e27cb37c10107823f6e322cc2f', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 3, 'created': '2017-03-29 15:20:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c7725d433ffc8c4a3c8878e1b41b635fc9e345cf', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 4, 'created': '2017-03-29 15:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/935ce8b43e7790b85b2974234e30976900fa7921', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 5, 'created': '2017-03-29 15:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/a9e849aceaaf94123aa0c474306da83431220054', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 6, 'created': '2017-03-29 15:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/76420aff0ebb7b7e9261041a7821a45c03430508', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 7, 'created': '2017-03-29 15:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ff80410f6d6c0f5430c972f53b5e3531db2ce59d', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 8, 'created': '2017-03-29 15:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/eccad96dcbffd493710745e827e5024da456be57', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 9, 'created': '2017-03-31 17:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ab14ea64fb5e3658534a2475c33b130ab6cf1da7', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 10, 'created': '2017-04-04 15:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8a62545ccd7e3c9e411ebfe8447c224bb7300bb1', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\n""}, {'number': 11, 'created': '2018-07-03 11:45:51.000000000', 'files': ['tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/976390502d92482e5e4e0ce261f3c8a58c3f29cd', 'message': ""Don't merge environments during plan creation\n\nCurrently we merge all environment files locally, which means\nwe can't take advantage of the heat environment merging\nfeatures, which require a list of environment files to be\npassed to the heat API, then the merging happens on the\nserver side.\n\nThis requires some significant rework, as we need to upload\neach individual environment file to swift (added under the\nuser-environments path), and rewrite all paths to match\nthe new location in the swift container.\n\nPartial-Bug: #1635409\nChange-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}]",2,448209,976390502d92482e5e4e0ce261f3c8a58c3f29cd,33,8,11,4328,,,0,"Don't merge environments during plan creation

Currently we merge all environment files locally, which means
we can't take advantage of the heat environment merging
features, which require a list of environment files to be
passed to the heat API, then the merging happens on the
server side.

This requires some significant rework, as we need to upload
each individual environment file to swift (added under the
user-environments path), and rewrite all paths to match
the new location in the swift container.

Partial-Bug: #1635409
Change-Id: I0ffad373937414ce3894bc89fbe6df8388cebb27
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/09/448209/8 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/overcloud_deploy.py'],1,c9cfb0a22b3199a35929cb15a5ad1542cd8143bc,bug/1635409," self._password_cache = None clients = self.app.client_manager self.swift_client = clients.tripleoclient.object_store self.mistral_client = clients.workflow_engine def _create_registration_env(self, args, tht_root): parameter_defaults = {""parameter_defaults"": user_env} env_path, swift_path = self._write_user_environment( parameter_defaults , 'tripleoclient-registration-parameters.yaml', tht_root, args.stack) return [registry, env_path] def _create_parameters_env(self, parameters, tht_root, container_name): env_path, swift_path = self._write_user_environment( parameter_defaults , 'tripleoclient-parameters.yaml', tht_root, container_name) return [env_path] def _process_environment_and_files(self, env_path, container_name, tht_root): files, env = template_utils.process_environment_and_files( env_path=env_path) moved_files = {} if files: self.log.debug(""Adding files %s for %s"" % (files.keys(), env_path)) moved_files = self._upload_missing_files( container_name, files, tht_root) self.log.debug(""MOVED Moved files = %s"" % moved_files) return moved_files def _write_user_environment(self, env_map, abs_env_path, tht_root, container_name): # We write the env_map to the local /tmp tht_root and also # to the swift plan container. self.log.debug(""Write %s ENV_MAP: %s"" % (abs_env_path, env_map)) contents = yaml.safe_dump(env_map, default_flow_style=False) env_dirname = os.path.dirname(abs_env_path) self.log.debug(""env_dirname=%s"" % env_dirname) user_env_dir = os.path.join(tht_root, 'user-environments', env_dirname[1:]) self.log.debug(""user_env_dir=%s"" % user_env_dir) user_env_path = os.path.join(user_env_dir, os.path.basename(abs_env_path)) self.log.debug(""user_env_path=%s"" % user_env_path) if not os.path.exists(user_env_dir): self.log.debug(""Creating dir user_env_dir=%s"" % user_env_dir) os.makedirs(user_env_dir) with open(user_env_path, 'w') as f: self.log.debug(""Writing user environment %s"" % user_env_path) f.write(contents) # Upload to swift swift_path = ""user-environments/{}"".format(abs_env_path[1:]) contents = yaml.safe_dump(env_map, default_flow_style=False) self.log.debug(""Uploading %s to swift at %s"" % (abs_env_path, swift_path)) self.log.debug(""Uploading %s to swift contents=%s"" % (abs_env_path, contents)) self.swift_client.put_object(container_name, swift_path, contents) return user_env_path, swift_path def _process_user_environment(self, abs_env_path, tht_root, user_tht_root, container_name): file_prefix = ""file://"" self.log.debug(""Uploading user environment file %s"" % abs_env_path) with open(abs_env_path, 'r') as f: env_map = yaml.safe_load(f) env_registry = env_map.get('resource_registry', {}) self.log.debug(""ENV_MAP: %s"" % env_map) # We have to do the following processing in two passes: # First we rewrite any references to user_tht_root, so that we # can reference values in the resource_registry that may be rendered # via j2.yaml templates, where environment resolution will otherwise # fail because a file doesn't exist in user_tht_root, but it is in tht_root # See bug https://bugs.launchpad.net/tripleo/+bug/1625783 for details tht_rsrc_paths = [] env_dirname = os.path.dirname(abs_env_path) user_env_dir = os.path.join(tht_root, 'user-environments', env_dirname[1:]) for rsrc, rsrc_path in six.iteritems(env_registry): # We need to calculate the absolute path relative to # env_dirname not cwd (which is what abspath uses). abs_rsrc_path = os.path.normpath( os.path.join(env_dirname, rsrc_path)) self.log.debug(""%s %s abs=%s"" % (rsrc, rsrc_path, abs_rsrc_path)) # We rewrite the resource_registry paths to be relative # to the plan container if abs_rsrc_path.startswith(user_tht_root): new_rsrc_path = abs_rsrc_path.replace(user_tht_root, tht_root) rsrc_relpath = os.path.relpath(new_rsrc_path, user_env_dir) self.log.debug(""Calculated relpath(%s, %s) = %s"" % (new_rsrc_path, user_env_dir, rsrc_relpath)) self.log.debug(""Rewriting %s %s path to %s"" % (abs_env_path, rsrc, rsrc_relpath)) env_registry[rsrc] = rsrc_relpath tht_rsrc_paths.append(rsrc_relpath) else: # For files referenced outside user_tht_root we need to # write the absolute path as the env file moved to tht_root env_registry[rsrc] = abs_rsrc_path env_map['resource_registry'] = env_registry user_env_path, swift_path = self._write_user_environment( env_map, abs_env_path, tht_root, container_name) # Second, we do local resolution of the environment to get any # files references, so they can be added to user-files, and we # rewrite the environment references from absolute local paths # to relative paths we can later resolve via heat/swift moved_files = self._process_environment_and_files( user_env_path, container_name, tht_root) for rsrc, rsrc_path in six.iteritems(env_registry): if file_prefix + rsrc_path in moved_files: rsrc_relpath = os.path.join( os.path.relpath(tht_root, user_env_dir), moved_files[file_prefix + rsrc_path]) env_registry[rsrc] = rsrc_relpath self.log.debug(""Rewriting %s %s path to %s"" % (rsrc_path, rsrc, rsrc_relpath)) env_map['resource_registry'] = env_registry user_env_path, swift_path = self._write_user_environment( env_map, abs_env_path, tht_root, container_name) return swift_path def _process_multiple_environments(self, created_env_files, added_files, tht_root, user_tht_root, container_name): new_env_paths = [] for env_path in created_env_files: self.log.debug(""Processing environment file %s"" % str(env_path)) else: # Upload user environment to <plan>/user-environments new_env_path = self._process_user_environment( abs_env_path,tht_root, user_tht_root, container_name) self.log.debug(""User environment %s added as %s"" % (env_path, new_env_path)) # Until we have a well defined plan update workflow in tripleo-common # we need to manually add an environment mistral # See bug: https://bugs.launchpad.net/tripleo/+bug/1623431 mistral_env = self.mistral_client.environments.get(container_name) user_env = {'path': new_env_path} if user_env not in mistral_env.variables['environments']: mistral_env.variables['environments'].append(user_env) self.mistral_client.environments.update( name=container_name, variables=mistral_env.variables) env_files, timeout, tht_root, update_plan_only, env = {} self.log.debug(""SHDEBUG add_breakpoints_cleanup_into_env env =%s"" % env) def do_object_request(method='GET', object_path=None): obj = self.swift_client.get_object(stack_name, object_path) self._upload_missing_files( stack_name, template_files, tht_root) # FIXME(shardy) find another way to do this validation # number_controllers = int(parameters.get('ControllerCount', 0)) # if number_controllers > 1: # if not env.get('parameter_defaults').get('NtpServer'): # raise exceptions.InvalidConfiguration( # 'Specify --ntp-server as parameter or NtpServer in ' # 'environments when using multiple controllers ' # '(with HA).') def _upload_missing_files(self, container_name, files_dict, tht_root): the new paths are stored in the file_relocation dict, which is returned and used by _process_multiple_environments which will rewrite the environments to update paths to the relative Swift path. self.swift_client.put_object(container_name, reloc_path, contents) self.log.debug(""SHDEBUG uploaded %s to %s"" % (orig_path, reloc_path)) plan_list = self.swift_client.get_container(plan_name) added_files = {} f.write(self.swift_client.get_object(plan_name, pf)[1]) added_files[pf] = file_path self.log.debug(""added_files = %s"" % added_files) return added_files added_files = self._download_missing_files_from_plan( param_env_files = self._create_parameters_env( parameters, tht_root, parsed_args.stack) created_env_files.extend(param_env_files) reg_env_files = self._create_registration_env( parsed_args, tht_root) env_files = self._process_multiple_environments( created_env_files, added_files, tht_root, user_tht_root, parsed_args.stack) parsed_args.timeout, parsed_args.update_plan_only, update_plan_only, tht_root, update_plan_only,"," self._password_cache = None def _create_registration_env(self, args): return [registry], {""parameter_defaults"": user_env} def _create_parameters_env(self, parameters): return parameter_defaults def _process_multiple_environments(self, created_env_files, tht_root, user_tht_root, cleanup=True): env_files = {} localenv = {} for env_path in created_env_files: self.log.debug(""Processing environment files %s"" % env_path) env_path = new_env_path try: files, env = template_utils.process_environment_and_files( env_path=env_path) except hc_exc.CommandError as ex: # This provides fallback logic so that we can reference files # inside the resource_registry values that may be rendered via # j2.yaml templates, where the above will fail because the # file doesn't exist in user_tht_root, but it is in tht_root # See bug https://bugs.launchpad.net/tripleo/+bug/1625783 # for details on why this is needed (backwards-compatibility) self.log.debug(""Error %s processing environment file %s"" % (six.text_type(ex), env_path)) with open(abs_env_path, 'r') as f: env_map = yaml.safe_load(f) env_registry = env_map.get('resource_registry', {}) env_dirname = os.path.dirname(os.path.abspath(env_path)) for rsrc, rsrc_path in six.iteritems(env_registry): # We need to calculate the absolute path relative to # env_path not cwd (which is what abspath uses). abs_rsrc_path = os.path.normpath( os.path.join(env_dirname, rsrc_path)) # If the absolute path matches user_tht_root, rewrite # a temporary environment pointing at tht_root instead if abs_rsrc_path.startswith(user_tht_root): new_rsrc_path = abs_rsrc_path.replace(user_tht_root, tht_root) self.log.debug(""Rewriting %s %s path to %s"" % (env_path, rsrc, new_rsrc_path)) env_registry[rsrc] = new_rsrc_path else: env_registry[rsrc] = abs_rsrc_path env_map['resource_registry'] = env_registry f_name = os.path.basename(os.path.splitext(abs_env_path)[0]) with tempfile.NamedTemporaryFile(dir=tht_root, prefix=""env-%s-"" % f_name, suffix="".yaml"", mode=""w"", delete=cleanup) as f: self.log.debug(""Rewriting %s environment to %s"" % (env_path, f.name)) f.write(yaml.safe_dump(env_map, default_flow_style=False)) f.flush() files, env = template_utils.process_environment_and_files( env_path=f.name) if files: self.log.debug(""Adding files %s for %s"" % (files, env_path)) env_files.update(files) # 'env' can be a deeply nested dictionary, so a simple update is # not enough localenv = template_utils.deep_update(localenv, env) return env_files, localenv env_files, timeout, tht_root, env, update_plan_only, # heatclient template_utils needs a function that can # retrieve objects from a container by name/path objectclient = clients.tripleoclient.object_store def do_object_request(method='GET', object_path=None): obj = objectclient.get_object(stack_name, object_path) files = dict(list(template_files.items()) + list(env_files.items())) number_controllers = int(parameters.get('ControllerCount', 0)) if number_controllers > 1: if not env.get('parameter_defaults').get('NtpServer'): raise exceptions.InvalidConfiguration( 'Specify --ntp-server as parameter or NtpServer in ' 'environments when using multiple controllers ' '(with HA).') moved_files = self._upload_missing_files( stack_name, objectclient, files, tht_root) self._process_and_upload_environment( stack_name, objectclient, env, moved_files, tht_root, workflow_client) def _process_and_upload_environment(self, container_name, swift_client, env, moved_files, tht_root, mistral): """"""Process the environment and upload to Swift The environment at this point should be the result of the merged custom user environments. We need to look at the paths in the environment and update any that changed when they were uploaded to swift. """""" file_prefix = ""file://"" if 'resource_registry' in env: for name, path in env['resource_registry'].items(): if not isinstance(path, six.string_types): continue if path in moved_files: new_path = moved_files[path] env['resource_registry'][name] = new_path elif path.startswith(file_prefix): path = path[len(file_prefix):] if path.startswith(tht_root): path = path[len(tht_root):] # We want to make sure all the paths are relative. if path.startswith(""/""): path = path[1:] env['resource_registry'][name] = path # Parameters are removed from the environment and sent to the update # parameters action, this stores them in the Mistral environment and # means the UI can find them. if 'parameter_defaults' in env: params = env.pop('parameter_defaults') workflow_params.update_parameters( mistral, container=container_name, parameters=params) contents = yaml.safe_dump(env) # Until we have a well defined plan update workflow in tripleo-common # we need to manually add an environment in swift and mistral for users # custom environments passed to the deploy command. # See bug: https://bugs.launchpad.net/tripleo/+bug/1623431 swift_path = ""user-environment.yaml"" swift_client.put_object(container_name, swift_path, contents) mistral_env = mistral.environments.get(container_name) user_env = {'path': swift_path} if user_env not in mistral_env.variables['environments']: mistral_env.variables['environments'].append(user_env) mistral.environments.update( name=container_name, variables=mistral_env.variables ) def _upload_missing_files(self, container_name, swift_client, files_dict, tht_root): the new paths are store din the file_relocation dict, which is returned and used by _process_and_upload_environment which will merge the environment and update paths to the relative Swift path. swift_client.put_object(container_name, reloc_path, contents) clients = self.app.client_manager objectclient = clients.tripleoclient.object_store plan_list = objectclient.get_container(plan_name) f.write(objectclient.get_object(plan_name, pf)[1]) self._download_missing_files_from_plan( env = {} env.update(self._create_parameters_env(parameters)) reg_env_files, reg_env = self._create_registration_env(parsed_args) template_utils.deep_update(env, reg_env) env_files, localenv = self._process_multiple_environments( created_env_files, tht_root, user_tht_root, cleanup=not parsed_args.no_cleanup) template_utils.deep_update(env, localenv) parsed_args.timeout, env, parsed_args.update_plan_only, env, update_plan_only, tht_root, env, update_plan_only,",181,159
openstack%2Ftripleo-docs~master~I639c5583b7b355f4b7c6ca5550f778d14f8fcd21,openstack/tripleo-docs,master,I639c5583b7b355f4b7c6ca5550f778d14f8fcd21,Move developer docs to its own top-level section,ABANDONED,2018-10-17 15:59:25.000000000,2019-02-11 09:50:59.000000000,,"[{'_account_id': 3153}, {'_account_id': 8042}, {'_account_id': 10873}, {'_account_id': 11166}, {'_account_id': 14985}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-10-17 15:59:25.000000000', 'files': ['doc/source/developer/upgrades/ci_upgrades.rst', 'doc/source/install/index.rst', 'doc/source/developer/upgrades/minor_update.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.plantuml', 'doc/source/developer/upgrades/minor_update.plantuml', 'doc/source/developer/tht_walkthrough/summary.rst', 'doc/source/developer/tht_walkthrough/changes-tht.rst', 'doc/source/developer/tht_walkthrough/changes-puppet-tripleo.rst', 'doc/source/developer/mistral_workflows/07-give-elevated-privileges-to-Mistral-actions.rst', 'doc/source/developer/mistral_workflows/03-creating-new-cli-option.rst', 'doc/source/developer/upgrades/major_upgrade.plantuml', 'doc/source/developer/tripleo.sh.rst', 'doc/source/developer/mistral_workflows/08-debugging-actions.rst', 'doc/source/developer/mistral_workflows/10-summary.rst', 'doc/source/developer/index.rst', 'doc/source/developer/tht_walkthrough/index.rst', 'doc/source/developer/mistral_workflows/01-introduction.rst', 'doc/source/developer/tht_walkthrough/introduction.rst', 'doc/source/developer/release.rst', 'doc/source/developer/upgrades/links.rst', 'doc/source/developer/upgrades/major_upgrade.rst', 'doc/source/developer/mistral_workflows/06-test-local-changes.rst', 'doc/source/developer/mistral_workflows/09-unit-tests.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.rst', 'doc/source/developer/mistral_workflows/02-undercloud-backups.rst', 'doc/source/developer/mistral_workflows/04-creating-mistral-workflows.rst', 'doc/source/developer/upgrades/index.rst', 'doc/source/developer/upgrades/minor_update.png', 'doc/source/developer/tht_walkthrough/tls_for_services.rst', 'doc/source/index.rst', 'doc/source/developer/tht_walkthrough/design-patterns.rst', 'doc/source/developer/upgrades/major_upgrade.png', 'doc/source/developer/mistral_workflows/00-index.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.png', 'doc/source/developer/mistral_workflows/05-tripleo-environment-variables.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/fbb7cfa8afebca706bab4bd5e6a3d825065eea79', 'message': 'Move developer docs to its own top-level section\n\nDeveloper docs shouldn\'t be under Install Guide. This patch moves\ndeveloper docs from Install Guide to its own top-level section and\nupdates any internal broken links accordingly.\n\nIt\'s worth noting that this move will break external URLs which have\npointed to developer docs until now. I think the change is still worth\nit to bring more clarity both to the internal docs structure and to\nthe docs landing page -- separating the dev docs for more visibility\nin both. This will also generate a ""Developer Guide"" link to the main\ndocumentation sidebar automatically.\n\nI considered using symlinks to keep the old external links alive, but\nthat would break relative internal content links, so this situation\ndoes not seem to be easily unsolvable.\n\nMinor changes included:\n\n* Since we\'re already breaking URLs, change the names of the\n  subcontent index pages:\n\n  developer/developer to developer/index\n  developer/upgrade/upgrade to developer/upgrade/index\n  developer/tht_walkthrough/tht_walkthrough to developer/tht_walkthrough/index\n\n* Rename and capitalize headings for Upgrade, THT walkthrough and\n  Mistral dev docs to make the generated index nicer.\n\nChange-Id: I639c5583b7b355f4b7c6ca5550f778d14f8fcd21\n'}]",2,611374,fbb7cfa8afebca706bab4bd5e6a3d825065eea79,6,8,1,8042,,,0,"Move developer docs to its own top-level section

Developer docs shouldn't be under Install Guide. This patch moves
developer docs from Install Guide to its own top-level section and
updates any internal broken links accordingly.

It's worth noting that this move will break external URLs which have
pointed to developer docs until now. I think the change is still worth
it to bring more clarity both to the internal docs structure and to
the docs landing page -- separating the dev docs for more visibility
in both. This will also generate a ""Developer Guide"" link to the main
documentation sidebar automatically.

I considered using symlinks to keep the old external links alive, but
that would break relative internal content links, so this situation
does not seem to be easily unsolvable.

Minor changes included:

* Since we're already breaking URLs, change the names of the
  subcontent index pages:

  developer/developer to developer/index
  developer/upgrade/upgrade to developer/upgrade/index
  developer/tht_walkthrough/tht_walkthrough to developer/tht_walkthrough/index

* Rename and capitalize headings for Upgrade, THT walkthrough and
  Mistral dev docs to make the generated index nicer.

Change-Id: I639c5583b7b355f4b7c6ca5550f778d14f8fcd21
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/74/611374/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/developer/upgrades/ci_upgrades.rst', 'doc/source/install/index.rst', 'doc/source/developer/upgrades/minor_update.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.plantuml', 'doc/source/developer/upgrades/minor_update.plantuml', 'doc/source/developer/tht_walkthrough/summary.rst', 'doc/source/developer/tht_walkthrough/changes-tht.rst', 'doc/source/developer/tht_walkthrough/changes-puppet-tripleo.rst', 'doc/source/developer/mistral_workflows/07-give-elevated-privileges-to-Mistral-actions.rst', 'doc/source/developer/mistral_workflows/03-creating-new-cli-option.rst', 'doc/source/developer/upgrades/major_upgrade.plantuml', 'doc/source/developer/tripleo.sh.rst', 'doc/source/developer/mistral_workflows/08-debugging-actions.rst', 'doc/source/developer/mistral_workflows/10-summary.rst', 'doc/source/developer/index.rst', 'doc/source/developer/tht_walkthrough/index.rst', 'doc/source/developer/mistral_workflows/01-introduction.rst', 'doc/source/developer/tht_walkthrough/introduction.rst', 'doc/source/developer/release.rst', 'doc/source/developer/upgrades/links.rst', 'doc/source/developer/upgrades/major_upgrade.rst', 'doc/source/developer/mistral_workflows/06-test-local-changes.rst', 'doc/source/developer/mistral_workflows/09-unit-tests.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.rst', 'doc/source/developer/mistral_workflows/02-undercloud-backups.rst', 'doc/source/developer/mistral_workflows/04-creating-mistral-workflows.rst', 'doc/source/developer/upgrades/index.rst', 'doc/source/developer/upgrades/minor_update.png', 'doc/source/developer/tht_walkthrough/tls_for_services.rst', 'doc/source/index.rst', 'doc/source/developer/tht_walkthrough/design-patterns.rst', 'doc/source/developer/upgrades/major_upgrade.png', 'doc/source/developer/mistral_workflows/00-index.rst', 'doc/source/developer/upgrades/fast_fw_upgrade.png', 'doc/source/developer/mistral_workflows/05-tripleo-environment-variables.rst']",35,fbb7cfa8afebca706bab4bd5e6a3d825065eea79,lifecycle-dev-docs-overhaul,,,28,21
openstack%2Fpuppet-tripleo~stable%2Fpike~I2b911370786d503c4a2f0f1d55cc1744d42ee078,openstack/puppet-tripleo,stable/pike,I2b911370786d503c4a2f0f1d55cc1744d42ee078,Restart ovs agent to restore rules,ABANDONED,2018-10-16 11:58:53.000000000,2019-02-11 09:19:07.000000000,,"[{'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-10-16 11:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d7da124cf16113c0ceb48cea77237ae650738940', 'message': 'Restart ovs agent to restore rules\n\nChange-Id: I2b911370786d503c4a2f0f1d55cc1744d42ee078\nCloses-Bug: 1798072\n'}, {'number': 2, 'created': '2018-10-24 12:30:21.000000000', 'files': ['manifests/firewall.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/148126510385e2facb8ef431326ec42308af6d61', 'message': 'Restart ovs agent to restore rules\n\nChange-Id: I2b911370786d503c4a2f0f1d55cc1744d42ee078\nCloses-Bug: 1798072\n'}]",0,610936,148126510385e2facb8ef431326ec42308af6d61,11,3,2,11082,,,0,"Restart ovs agent to restore rules

Change-Id: I2b911370786d503c4a2f0f1d55cc1744d42ee078
Closes-Bug: 1798072
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/36/610936/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/firewall.pp'],1,d7da124cf16113c0ceb48cea77237ae650738940,bug/1798072, Service<| |> -> Service<| title == 'neutron-ovs-agent-service' |>,,1,0
openstack%2Ftripleo-quickstart-extras~master~I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f,openstack/tripleo-quickstart-extras,master,I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f,Added ssh configuration for stack user on the undercloud,ABANDONED,2018-05-29 11:44:32.000000000,2019-02-11 09:14:27.000000000,,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8871}, {'_account_id': 10022}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-05-29 11:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/95aa1b3721ca8d773fa89d27115c29bc4408f5e6', 'message': 'Added ssh configuration for stack user on the undercloud\n\nChange-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f\n'}, {'number': 2, 'created': '2018-05-29 13:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0cae269e4405927941fda78be53c1e62c006612b', 'message': 'Added ssh configuration for stack user on the undercloud\n\nChange-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f\n'}, {'number': 3, 'created': '2018-06-04 04:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/bb6976a20396e3ea34340bc327d234646e6f366b', 'message': 'Added ssh configuration for stack user on the undercloud\n\nChange-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f\n'}, {'number': 4, 'created': '2018-06-04 12:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/aeb857b7ea9eccc99ef8c2997a95697384b2ccbd', 'message': 'Added ssh configuration for stack user on the undercloud\n\nThe issue is mainly related to dev: when you connect to the undercloud,\nyou don\'t really want to have to accept the SSH key each time you\nredeploy the overcloud, nor pass ""heat-admin@"" or ""-l heat-admin"" when\nyou connect to the overcloud nodes.\n\nOf course, you can connect from your quickstart node, but when you work\ndirectly on the undercloud, you don\'t have the facilities the generated\nssh-config file in your quickstart directory provides.\n\nThis simple patch just workaround these issues and allow to work in a\nmore convenient way directly from the undercloud node.\n\nChange-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f\n'}, {'number': 5, 'created': '2018-06-08 07:17:55.000000000', 'files': ['roles/undercloud-deploy/tasks/main.yml', 'roles/undercloud-deploy/tasks/user-tunning.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4bcef77e29658cf512f2ca4194641928573389f9', 'message': 'Added ssh configuration for stack user on the undercloud\n\nThe issue is mainly related to dev: when you connect to the undercloud,\nyou don\'t really want to have to pass ""heat-admin@"" or ""-l heat-admin""\nwhen you connect to the overcloud nodes.\n\nOf course, you can connect from your quickstart node, but when you work\ndirectly on the undercloud, you don\'t have the facilities the generated\nssh-config file in your quickstart directory provides.\n\nThis simple patch just workaround these issues and allow to work in a\nmore convenient way directly from the undercloud node.\n\nThe SSH host key aren\'t accepted by default. Following a discussion,\naccepting them automatically might hide some future issues, as the\nhost keys will be added automatically.\n\nChange-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f\n'}]",2,570913,4bcef77e29658cf512f2ca4194641928573389f9,33,11,5,28223,,,0,"Added ssh configuration for stack user on the undercloud

The issue is mainly related to dev: when you connect to the undercloud,
you don't really want to have to pass ""heat-admin@"" or ""-l heat-admin""
when you connect to the overcloud nodes.

Of course, you can connect from your quickstart node, but when you work
directly on the undercloud, you don't have the facilities the generated
ssh-config file in your quickstart directory provides.

This simple patch just workaround these issues and allow to work in a
more convenient way directly from the undercloud node.

The SSH host key aren't accepted by default. Following a discussion,
accepting them automatically might hide some future issues, as the
host keys will be added automatically.

Change-Id: I7eb27541a72b0bc1c87bfb3ebfcd7c8c43ecb47f
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/13/570913/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/undercloud-deploy/tasks/main.yml', 'roles/undercloud-deploy/tasks/user-tunning.yml']",2,95aa1b3721ca8d773fa89d27115c29bc4408f5e6,undercloud-ssh-setting,"--- # Some tuning for undercloud user - name: set ssh_config for overcloud access copy: dest: ""{{ working_dir }}/.ssh/config"" group: ""{{}}"" mode: 0640 owner: ""{{}}"" content: | Host * User heat-admin StrictHostKeyChecking no UserKnownHostsFile /dev/null ",,18,0
openstack%2Foctavia~master~Ie752aa8e744d54c4909b97876dee450293d29908,openstack/octavia,master,Ie752aa8e744d54c4909b97876dee450293d29908,Support to filter resources by tags,MERGED,2019-01-21 04:09:08.000000000,2019-02-11 08:59:03.000000000,2019-01-24 09:44:15.000000000,"[{'_account_id': 1653}, {'_account_id': 2245}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-21 04:09:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6760c5c195f58a816620631808f994bc95f635dc', 'message': '[WIP] Support to filter resources by tags\n\nChange-Id: Ie752aa8e744d54c4909b97876dee450293d29908\nStory: 2004810\nTask: 28970\n'}, {'number': 2, 'created': '2019-01-21 05:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/1a5229bb99e26cc9ebef90667acb68d5d6dc389b', 'message': ""Support to filter resources by tags\n\nAdd 'tags', 'tags-any', 'not-tags', 'not-tags-any' param keys for\nresource query.\n\nDoc reference:\nhttp://specs.openstack.org/openstack/api-wg/guidelines/tags.html#filtering-and-searching-by-tags\n\nChange-Id: Ie752aa8e744d54c4909b97876dee450293d29908\nStory: 2004810\nTask: 28970\n""}, {'number': 3, 'created': '2019-01-22 00:46:37.000000000', 'files': ['octavia/api/common/pagination.py', 'octavia/tests/functional/api/v2/test_health_monitor.py', 'octavia/tests/functional/api/v2/test_pool.py', 'octavia/tests/functional/api/v2/test_l7rule.py', 'octavia/tests/functional/api/v2/test_member.py', 'octavia/tests/functional/api/v2/test_l7policy.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/functional/api/v2/test_listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/5df9ad49b3414d10b69d431763697a785d89e0ac', 'message': ""Support to filter resources by tags\n\nAdd 'tags', 'tags-any', 'not-tags', 'not-tags-any' param keys for\nresource query.\n\nDoc reference:\nhttp://specs.openstack.org/openstack/api-wg/guidelines/tags.html#filtering-and-searching-by-tags\n\nChange-Id: Ie752aa8e744d54c4909b97876dee450293d29908\nStory: 2004810\nTask: 28970\n""}]",6,632013,5df9ad49b3414d10b69d431763697a785d89e0ac,16,10,3,6732,,,0,"Support to filter resources by tags

Add 'tags', 'tags-any', 'not-tags', 'not-tags-any' param keys for
resource query.

Doc reference:
http://specs.openstack.org/openstack/api-wg/guidelines/tags.html#filtering-and-searching-by-tags

Change-Id: Ie752aa8e744d54c4909b97876dee450293d29908
Story: 2004810
Task: 28970
",git fetch https://review.opendev.org/openstack/octavia refs/changes/13/632013/2 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/api/common/pagination.py', 'octavia/tests/functional/api/v2/test_health_monitor.py']",2,6760c5c195f58a816620631808f994bc95f635dc,support-tags-filtering," def test_get_all_tags_filtering(self): hm1 = self.create_health_monitor( self.pool_id, constants.HEALTH_MONITOR_HTTP, 1, 1, 1, 1, tags=['test_tag1', 'test_tag2']).get(self.root_tag) hm2 = self.create_health_monitor( self.pool_id, constants.HEALTH_MONITOR_HTTP, 1, 1, 1, 1, tags=['test_tag2', 'test_tag3']).get(self.root_tag) hm3 = self.create_health_monitor( self.pool_id, constants.HEALTH_MONITOR_HTTP, 1, 1, 1, 1, tags=['test_tag4', 'test_tag5']).get(self.root_tag) hms = self.get( self.HMS_PATH, params={'tags': 'test_tag2'} ).json.get(self.root_tag_list) self.assertIsInstance(hms, list) self.assertEqual(2, len(hms)) hms = self.get( self.HMS_PATH, params={'tags': ['test_tag2', 'test_tag3']} ).json.get(self.root_tag_list) self.assertIsInstance(hms, list) self.assertEqual(1, len(hms)) hms = self.get( self.HMS_PATH, params={'tags-any': 'test_tag2'} ).json.get(self.root_tag_list) self.assertIsInstance(hms, list) self.assertEqual(2, len(hms)) hms = self.get( self.HMS_PATH, params={'not-tags': 'test_tag2'} ).json.get(self.root_tag_list) self.assertIsInstance(hms, list) self.assertEqual(1, len(hms)) hms = self.get( self.HMS_PATH, params={'not-tags-any': ['test_tag2', 'test_tag4']} ).json.get(self.root_tag_list) self.assertIsInstance(hms, list) self.assertEqual(0, len(hms)) ",,98,0
openstack%2Fmagnum~master~I90acaf010014664879f5c0d2f1a1ef660baf498f,openstack/magnum,master,I90acaf010014664879f5c0d2f1a1ef660baf498f,Fixing container-build job,MERGED,2019-02-11 01:32:22.000000000,2019-02-11 08:57:54.000000000,2019-02-11 08:57:54.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-11 01:32:22.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/82344703cad071417172a5896cd1a372dbc6b84b', 'message': 'Fixing container-build job\n\nWhen the base zuul job moved from openstack-infra to\nopendev the role openstack-zuul-jobs which we depend\non for the swap was removed.\n\nThis patch manually imports that repo.\n\nChange-Id: I90acaf010014664879f5c0d2f1a1ef660baf498f\n'}]",0,636077,82344703cad071417172a5896cd1a372dbc6b84b,7,2,1,22623,,,0,"Fixing container-build job

When the base zuul job moved from openstack-infra to
opendev the role openstack-zuul-jobs which we depend
on for the swap was removed.

This patch manually imports that repo.

Change-Id: I90acaf010014664879f5c0d2f1a1ef660baf498f
",git fetch https://review.opendev.org/openstack/magnum refs/changes/77/636077/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,82344703cad071417172a5896cd1a372dbc6b84b,, roles: - zuul: openstack-infra/openstack-zuul-jobs,,2,0
openstack%2Fnova~master~I5a956513f3485074023e027430cc52ee7a3f92e4,openstack/nova,master,I5a956513f3485074023e027430cc52ee7a3f92e4,Reject unshelve with port having resource request,MERGED,2019-01-14 16:29:33.000000000,2019-02-11 08:37:47.000000000,2019-02-05 13:48:40.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01b88019787f191f889ecdd28c7da33d76418122', 'message': 'Reject unshelve with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server unshelve request on servers that\nwas offload is rejected if it involves a port that has resource request.\nWhen the feature is ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I5a956513f3485074023e027430cc52ee7a3f92e4\n'}, {'number': 2, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e7776fc1eb15000c2eefceb8b5b0a2f600e2039', 'message': 'Reject unshelve with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server unshelve request on servers that\nwas offload is rejected if it involves a port that has resource request.\nWhen the feature is ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I5a956513f3485074023e027430cc52ee7a3f92e4\n'}, {'number': 3, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1f9987c6bc0ef0abb58737824ca5708b199825d', 'message': 'Reject unshelve with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server unshelve request on servers that\nwas offload is rejected if it involves a port that has resource request.\nWhen the feature is ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I5a956513f3485074023e027430cc52ee7a3f92e4\n'}, {'number': 4, 'created': '2019-01-28 14:51:40.000000000', 'files': ['nova/api/openstack/compute/shelve.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0b92325fe14eda062c78de2c3423ca4834861152', 'message': 'Reject unshelve with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server unshelve request on servers that\nwas offload is rejected if it involves a port that has resource request.\nWhen the feature is ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I5a956513f3485074023e027430cc52ee7a3f92e4\n'}]",9,630725,0b92325fe14eda062c78de2c3423ca4834861152,67,16,4,9708,,,0,"Reject unshelve with port having resource request

Nova does not consider the resource request of a Neutron port as of now.
So this patch makes sure that server unshelve request on servers that
was offload is rejected if it involves a port that has resource request.
When the feature is ready on the nova side this limitation will be lifted.

blueprint: bandwidth-resource-provider

Change-Id: I5a956513f3485074023e027430cc52ee7a3f92e4
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/630725/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/openstack/compute/shelve.py', 'nova/tests/unit/api/openstack/compute/test_shelve.py', 'nova/tests/functional/test_servers.py']",3,01b88019787f191f889ecdd28c7da33d76418122,bp/bandwidth-resource-provider," def test_unshelve_offloaded_server_with_port_resource_request_old_version( self): server = self._create_server( flavor=self.flavor, networks=[{'port': self.neutron.port_1['id']}]) self._wait_for_state_change(self.admin_api, server, 'ACTIVE') # with default config shelve means immediate offload as well req = { 'shelve': {} } self.api.post_server_action(server['id'], req) self._wait_for_server_parameter( self.api, server, {'status': 'SHELVED_OFFLOADED'}) # We need to simulate that the above server has a port that has # resource request, we cannot boot with such a port but legacy servers # can exists with such a port. bound_port = self.neutron._ports[self.neutron.port_1['id']] fake_resource_request = self.neutron.port_with_resource_request[ 'resource_request'] bound_port['resource_request'] = fake_resource_request ex = self.assertRaises( client.OpenStackApiException, self.api.post_server_action, server['id'], {'unshelve': {}}) self.assertEqual(400, ex.response.status_code) self.assertIn( 'The unshelve server operation on a shelve offloaded server with ' 'port having QoS policy is not supported.', six.text_type(ex)) def test_unshelve_not_offloaded_server_with_port_resource_request( self): """"""If the server is not offloaded then unshelving does not cause a new resource allocation therefore having port resource request is irrelevant. This test asserts that such unshelve request is not rejected. """""" server = self._create_server( flavor=self.flavor, networks=[{'port': self.neutron.port_1['id']}]) self._wait_for_state_change(self.admin_api, server, 'ACTIVE') # avoid automatic shelve offloading self.flags(shelved_offload_time=-1) req = { 'shelve': {} } self.api.post_server_action(server['id'], req) self._wait_for_server_parameter( self.api, server, {'status': 'SHELVED'}) # We need to simulate that the above server has a port that has # resource request, we cannot boot with such a port but legacy servers # can exists with such a port. bound_port = self.neutron._ports[self.neutron.port_1['id']] fake_resource_request = self.neutron.port_with_resource_request[ 'resource_request'] bound_port['resource_request'] = fake_resource_request self.api.post_server_action(server['id'], {'unshelve': {}}) self._wait_for_state_change(self.admin_api, server, 'ACTIVE')",,102,1
openstack%2Fnova~master~I48e6db9693e470b177bf4c75211d8b883c768433,openstack/nova,master,I48e6db9693e470b177bf4c75211d8b883c768433,Reject migrate with port having resource request,MERGED,2019-01-14 16:29:33.000000000,2019-02-11 08:14:09.000000000,2019-02-04 17:55:30.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-14 16:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14ce7dd18e2ab03ae232a73a089862205fc3c578', 'message': 'Reject migrate with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server migrate and live migrate requests are\nrejected if they involve a port that has resource request. When the feature\nis ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I48e6db9693e470b177bf4c75211d8b883c768433\n'}, {'number': 2, 'created': '2019-01-24 16:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1c1f173e34764e0dfdb57c244f57df94de47dd06', 'message': 'Reject migrate with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server migrate and live migrate requests are\nrejected if they involve a port that has resource request. When the feature\nis ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I48e6db9693e470b177bf4c75211d8b883c768433\n'}, {'number': 3, 'created': '2019-01-26 16:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/763bd7377e1b9bb6ef720c7f03b11df5b86295c8', 'message': 'Reject migrate with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server migrate and live migrate requests are\nrejected if they involve a port that has resource request. When the feature\nis ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I48e6db9693e470b177bf4c75211d8b883c768433\n'}, {'number': 4, 'created': '2019-01-28 14:51:40.000000000', 'files': ['nova/tests/functional/api_sample_tests/test_migrate_server.py', 'nova/tests/functional/compute/test_live_migration.py', 'nova/tests/functional/api_sample_tests/test_server_migrations.py', 'nova/tests/functional/test_servers.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3730bd079104ad14f6992ad55cf8643911c916ab', 'message': 'Reject migrate with port having resource request\n\nNova does not consider the resource request of a Neutron port as of now.\nSo this patch makes sure that server migrate and live migrate requests are\nrejected if they involve a port that has resource request. When the feature\nis ready on the nova side this limitation will be lifted.\n\nblueprint: bandwidth-resource-provider\n\nChange-Id: I48e6db9693e470b177bf4c75211d8b883c768433\n'}]",6,630723,3730bd079104ad14f6992ad55cf8643911c916ab,59,16,4,9708,,,0,"Reject migrate with port having resource request

Nova does not consider the resource request of a Neutron port as of now.
So this patch makes sure that server migrate and live migrate requests are
rejected if they involve a port that has resource request. When the feature
is ready on the nova side this limitation will be lifted.

blueprint: bandwidth-resource-provider

Change-Id: I48e6db9693e470b177bf4c75211d8b883c768433
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/630723/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/test_migrate_server.py', 'nova/tests/functional/compute/test_live_migration.py', 'nova/tests/functional/api_sample_tests/test_server_migrations.py', 'nova/tests/functional/test_servers.py', 'nova/api/openstack/compute/migrate_server.py', 'nova/tests/unit/api/openstack/compute/test_migrate_server.py']",6,14ce7dd18e2ab03ae232a73a089862205fc3c578,bp/bandwidth-resource-provider,"import fixtures self.mock_list_port = self.useFixture( fixtures.MockPatch( 'nova.network.neutronv2.api.API.list_ports')).mock self.mock_list_port.return_value = {'ports': []} def test_migrate_with_port_resource_request_old_microversion(self): self.mock_list_port.return_value = {'ports': [ {'resource_request': { ""resources"": {'CUSTOM_FOO': 1}}}] } method_translations = {'_migrate': 'resize', '_migrate_live': 'live_migrate'} body_map = {'_migrate_live': self._get_migration_body(host='hostname')} args_map = {'_migrate_live': ((False, self.disk_over_commit, 'hostname', self.force, self.async_), {}), '_migrate': ((), {'host_name': self.host_name})} ex = self.assertRaises( webob.exc.HTTPBadRequest, self._test_actions, ['_migrate', '_migrate_live'], body_map=body_map, method_translations=method_translations, args_map=args_map) self.assertIn( 'The migrate server operation with port having QoS policy is not ' 'supported.', six.text_type(ex)) def test_migrate_with_port_resource_request_old_microversion(self): self.mock_list_port.return_value = {'ports': [ {'resource_request': { ""resources"": {'CUSTOM_FOO': 1}}}] } ex = self.assertRaises( webob.exc.HTTPBadRequest, self._test_actions, ['_migrate'], body_map=self.body_map, method_translations=self.method_translations, args_map=self.args_map) self.assertIn( 'The migrate server operation with port having QoS policy is not ' 'supported.', six.text_type(ex)) ",,116,0
openstack%2Fmagnum~master~I53eaab312fa1b3b3f5689aa0147a028ecaeb52f1,openstack/magnum,master,I53eaab312fa1b3b3f5689aa0147a028ecaeb52f1,Fix typo in octavia-ingress-controller doc,MERGED,2019-02-10 22:52:09.000000000,2019-02-11 08:09:35.000000000,2019-02-11 08:09:35.000000000,"[{'_account_id': 8064}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-02-10 22:52:09.000000000', 'files': ['doc/source/user/index.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/87a743ad45b4d52552511260bd44b762e1dd0456', 'message': 'Fix typo in octavia-ingress-controller doc\n\nChange-Id: I53eaab312fa1b3b3f5689aa0147a028ecaeb52f1\n'}]",0,636072,87a743ad45b4d52552511260bd44b762e1dd0456,7,3,1,6732,,,0,"Fix typo in octavia-ingress-controller doc

Change-Id: I53eaab312fa1b3b3f5689aa0147a028ecaeb52f1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/72/636072/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/index.rst'],1,87a743ad45b4d52552511260bd44b762e1dd0456,fix-typo, is configured. For more details about octavia-ingress-controller please refer This label is not used for octavia-ingress-controller. The image tag for octavia-ingress-controller. Stein-default: 1.13.2-alpha, configured. For more details about octavia-ingress-controller please refer This lable is not used for octavia-ingress-controller. The image tag for octavia-ingress-controller. Stain-default: 1.13.2-alpha,3,3
openstack%2Fnova~master~I072b3fa4847db14e5a3f03c775a377e3514224f1,openstack/nova,master,I072b3fa4847db14e5a3f03c775a377e3514224f1,Turn off rp association refresh in nova-next,MERGED,2018-11-06 23:49:25.000000000,2019-02-11 07:57:31.000000000,2019-02-02 04:01:31.000000000,"[{'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-11-06 23:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/659ff4c0a375ba19ff6142d03ae1ba8c00f72455', 'message': 'WIP: Turn off rp association refresh in nova-next\n\nExperimental, for now.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n'}, {'number': 2, 'created': '2018-11-07 17:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e1ac66e281d3e4d5a258e3f4668900c1fa37842d', 'message': 'WIP: Turn off rp association refresh in nova-next\n\nExperimental, for now.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n'}, {'number': 3, 'created': '2018-11-08 23:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/478c4348080cfed0660a9a11acc8bcc9f6b7def8', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 4, 'created': '2018-11-08 23:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/543edac541bb2a49796fc47d374dab83346e3e2b', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 5, 'created': '2018-11-09 22:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d37b63a9f11a3569ff4f4550ca5b7d24e1c5727c', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 6, 'created': '2018-11-10 01:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3c844f893356f2771e02f017a4359a2de4ee3308', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 7, 'created': '2018-11-28 22:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9cad536f9930ef70a2d50837b894a2d0202231db', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 8, 'created': '2018-11-30 17:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f4cda64ef4364c8b73b0d64a8147b600bc8b7e42', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 9, 'created': '2018-12-04 15:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/72e14bfc5627e920f188ed8b9aad58c0ecf9fbe9', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 10, 'created': '2019-01-12 21:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d46262c270d2d93dccfd84eb80cefa7343559dd4', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}, {'number': 11, 'created': '2019-01-17 14:31:31.000000000', 'files': ['playbooks/legacy/nova-next/run.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/4319dc195bb3b0650a58c642e0d74e836265241d', 'message': ""Turn off rp association refresh in nova-next\n\nSet [compute]resource_provider_association_refresh=0 to turn off all\nperiodic refreshing of the provider cache in the report client.\n\nNote that this probably will have zero effect in the nova-next job\nother than making sure that that setting doesn't blow up the world.\nBecause the job is always doing something, there's never a lull long\nenough for the refresh timers to expire anyway, so no periodic\nrefreshing was happening even before this change.\n\nChange-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1\n""}]",1,616033,4319dc195bb3b0650a58c642e0d74e836265241d,159,20,11,14070,,,0,"Turn off rp association refresh in nova-next

Set [compute]resource_provider_association_refresh=0 to turn off all
periodic refreshing of the provider cache in the report client.

Note that this probably will have zero effect in the nova-next job
other than making sure that that setting doesn't blow up the world.
Because the job is always doing something, there's never a lull long
enough for the refresh timers to expire anyway, so no periodic
refreshing was happening even before this change.

Change-Id: I072b3fa4847db14e5a3f03c775a377e3514224f1
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/616033/10 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/nova-next/run.yaml'],1,659ff4c0a375ba19ff6142d03ae1ba8c00f72455,nova-next-no-rp-refresh," # Switch off the provider association refresh, which should reduce the # number of placement calls in steady state. [[post-config|$NOVA_CPU_CONF]] [compute] resource_provider_association_refresh = 0 ",,7,0
openstack%2Fnova~master~Ifdfeadae8b348d788de2cd665544015366271d66,openstack/nova,master,Ifdfeadae8b348d788de2cd665544015366271d66,"Ignore SAWarnings for ""Evaluating non-mapped column expression""",MERGED,2019-02-01 16:41:23.000000000,2019-02-11 07:31:43.000000000,2019-02-01 21:24:47.000000000,"[{'_account_id': 4393}, {'_account_id': 9008}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-02-01 16:41:23.000000000', 'files': ['nova/tests/fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1fa2e9c3a0afcbaeecbb9e336a4711c2e9add189', 'message': 'Ignore SAWarnings for ""Evaluating non-mapped column expression""\n\nThese warnings come from oslo.db code (tracked with bug 1814199)\nso there isn\'t much nova can do about that right now, outside of\nmonkey patching oslo.db which is a bad idea.\n\nLet\'s ignore the warning until the bug in oslo.db is fixed to\navoid blowing up our unit/functional test console output logs\nwhich in turn is intermittently triggering subunit.parser failures.\n\nChange-Id: Ifdfeadae8b348d788de2cd665544015366271d66\nRelated-Bug: #1813147\n'}]",0,634450,1fa2e9c3a0afcbaeecbb9e336a4711c2e9add189,13,8,1,6873,,,0,"Ignore SAWarnings for ""Evaluating non-mapped column expression""

These warnings come from oslo.db code (tracked with bug 1814199)
so there isn't much nova can do about that right now, outside of
monkey patching oslo.db which is a bad idea.

Let's ignore the warning until the bug in oslo.db is fixed to
avoid blowing up our unit/functional test console output logs
which in turn is intermittently triggering subunit.parser failures.

Change-Id: Ifdfeadae8b348d788de2cd665544015366271d66
Related-Bug: #1813147
",git fetch https://review.opendev.org/openstack/nova refs/changes/50/634450/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/fixtures.py'],1,1fa2e9c3a0afcbaeecbb9e336a4711c2e9add189,bug/1814199,"from sqlalchemy import exc as sqla_exc # TODO(mriedem): Change (or remove) this SAWarning to an error once # https://bugs.launchpad.net/oslo.db/+bug/1814199 is fixed. warnings.filterwarnings( 'ignore', message='Evaluating non-mapped column expression', category=sqla_exc.SAWarning) ",,7,0
openstack%2Fnova~master~I614dea09547c8f86f667b1daeb18f69fea7937fb,openstack/nova,master,I614dea09547c8f86f667b1daeb18f69fea7937fb,Switch tempest-slow to be run on python 3,MERGED,2019-01-31 11:15:37.000000000,2019-02-11 07:31:28.000000000,2019-02-07 01:16:11.000000000,"[{'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 11975}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-01-31 11:15:37.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/36efe194fe82f28b8865c62b34c7802a69337af5', 'message': 'Switch tempest-slow to be run on python 3\n\nThis patch switches tempest-slow to new\ntempest-slow-py3 job.\n\nFor coverage of tempest-slow tests on py2,\nTempest check pipeline will continue running\nthis job on check pipeline. As this tempest-slow\njob is not from integrated gate template, it is\nok to run only py3 job on project side.\n\nDepends-On: https://review.openstack.org/633983\nChange-Id: I614dea09547c8f86f667b1daeb18f69fea7937fb\n'}]",0,634204,36efe194fe82f28b8865c62b34c7802a69337af5,18,11,1,8556,,,0,"Switch tempest-slow to be run on python 3

This patch switches tempest-slow to new
tempest-slow-py3 job.

For coverage of tempest-slow tests on py2,
Tempest check pipeline will continue running
this job on check pipeline. As this tempest-slow
job is not from integrated gate template, it is
ok to run only py3 job on project side.

Depends-On: https://review.openstack.org/633983
Change-Id: I614dea09547c8f86f667b1daeb18f69fea7937fb
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/634204/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,36efe194fe82f28b8865c62b34c7802a69337af5,, - tempest-slow-py3: - tempest-slow-py3:, - tempest-slow: - tempest-slow:,2,2
openstack%2Fnova~master~I6e871311a0fa10beaf601ca6912b4a33ba4094e0,openstack/nova,master,I6e871311a0fa10beaf601ca6912b4a33ba4094e0,PCI: do not force remove allocated devices,MERGED,2018-12-19 19:58:40.000000000,2019-02-11 07:28:40.000000000,2019-02-05 23:17:45.000000000,"[{'_account_id': 6873}, {'_account_id': 8768}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11604}, {'_account_id': 12171}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-12-19 19:58:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47daa751efd52767841635bed3062843b96907be', 'message': 'PCI: do not force remove allcoated devices\n\n- This change alter the _set_hvdevs function\n  to not force remove allocated or claimed\n  devices.\n\ncloses-bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n'}, {'number': 2, 'created': '2019-01-28 21:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/96524e18fd2d0a11aa0c3c078a401b72839009d7', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved form the DEFAULT section of the nova.conf\nto the PCI section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmiss type the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regarless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n'}, {'number': 3, 'created': '2019-02-01 12:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/77726e30792ea101c9ca3eb78beed8fd4d64f13e', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved from the [DEFAULT] section of the nova.conf\nto the [pci] section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmisstypes the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regardless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n'}, {'number': 4, 'created': '2019-02-01 16:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1843a14b97c68e7c9d690ec7601db90aa6ec51a', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved from the [DEFAULT] section of the nova.conf\nto the [pci] section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmistypes the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regardless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n'}, {'number': 5, 'created': '2019-02-01 16:58:03.000000000', 'files': ['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/26c41eccade6412f61f9a8721d853b545061adcc', 'message': 'PCI: do not force remove allocated devices\n\nIn the ocata release the pci_passthrough_whitelist\nwas moved from the [DEFAULT] section of the nova.conf\nto the [pci] section and renamed to passthrough_whitelist.\n\nOn upgrading if the operator chooses to migrate the config\nvalue to the new section it is not uncommon\nto forget to rename the config value.\nSimilarly if an operator is updateing the whitelist and\nmistypes the value it can also lead to the whitelist\nbeing ignored.\n\nAs a result of either error the nova compute agent\nwould delete all database entries for a host regardless of\nif the pci device was in use by an instance. If this occurs\nthe only recorse for an operator is to delete and recreate\nthe guest on that host after correcting the error or manually\nrestore the database to backup or otherwise consistent state.\n\nThis change alters the _set_hvdevs function to not force\nremove allocated or claimed devices if they are no longer\npresent in the pci whitelist.\n\nCloses-Bug: #1633120\nChange-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0\n'}]",46,626381,26c41eccade6412f61f9a8721d853b545061adcc,78,16,5,11604,,,0,"PCI: do not force remove allocated devices

In the ocata release the pci_passthrough_whitelist
was moved from the [DEFAULT] section of the nova.conf
to the [pci] section and renamed to passthrough_whitelist.

On upgrading if the operator chooses to migrate the config
value to the new section it is not uncommon
to forget to rename the config value.
Similarly if an operator is updateing the whitelist and
mistypes the value it can also lead to the whitelist
being ignored.

As a result of either error the nova compute agent
would delete all database entries for a host regardless of
if the pci device was in use by an instance. If this occurs
the only recorse for an operator is to delete and recreate
the guest on that host after correcting the error or manually
restore the database to backup or otherwise consistent state.

This change alters the _set_hvdevs function to not force
remove allocated or claimed devices if they are no longer
present in the pci whitelist.

Closes-Bug: #1633120
Change-Id: I6e871311a0fa10beaf601ca6912b4a33ba4094e0
",git fetch https://review.opendev.org/openstack/nova refs/changes/81/626381/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/manager.py', 'nova/tests/unit/pci/test_manager.py']",2,47daa751efd52767841635bed3062843b96907be,bug/1633120," def test_set_hvdev_remove_tree_maintained_with_allocations(self): # Make sure the device tree is properly maintained when there are # devices removed from the system (not reported by the driver but known # from previous scans) all_devs = fake_db_devs_tree[:] self._create_tracker(all_devs) fake_pci_devs = all_devs[:] # we start with 3 devices self.assertEqual( 3, len([dev for dev in self.tracker.pci_devs if dev.status != fields.PciDeviceStatus.REMOVED])) # we then allocate one device last_dev = fake_pci_devs[-1] last_dev['status'] = fields.PciDeviceStatus.ALLOCATED self.tracker._set_hvdevs(fake_pci_devs) # and assert that no devices were removed self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) # we then remove the allocated device form the set reported # by the driver. self.tracker._set_hvdevs(fake_pci_devs[:-1]) # and assert no devices are removed from the tracker self.assertEqual( 0, len([dev for dev in self.tracker.pci_devs if dev.status == fields.PciDeviceStatus.REMOVED])) ",,42,3
