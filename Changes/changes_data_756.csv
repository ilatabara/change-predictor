id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fkolla-ansible~master~I31479d54526cba1ae408126bae3cec06fb52deb8,openstack/kolla-ansible,master,I31479d54526cba1ae408126bae3cec06fb52deb8,Fix wrong module argument name for kolla_toolbox,MERGED,2017-02-19 16:15:15.000000000,2017-02-20 10:17:36.000000000,2017-02-20 10:17:36.000000000,"[{'_account_id': 3}, {'_account_id': 11869}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-02-19 16:15:15.000000000', 'files': ['ansible/roles/ceph/tasks/start_rgw_keystone.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10bc34430861ceb778bb165d0872d1334df5ce54', 'message': 'Fix wrong module argument name for kolla_toolbox\n\nshould be module_extra_vars rather than module_extra_args.\n\nChange-Id: I31479d54526cba1ae408126bae3cec06fb52deb8\nCloses-Bug: #1666026\n'}]",0,435787,10bc34430861ceb778bb165d0872d1334df5ce54,7,3,1,7488,,,0,"Fix wrong module argument name for kolla_toolbox

should be module_extra_vars rather than module_extra_args.

Change-Id: I31479d54526cba1ae408126bae3cec06fb52deb8
Closes-Bug: #1666026
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/87/435787/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/ceph/tasks/start_rgw_keystone.yml'],1,10bc34430861ceb778bb165d0872d1334df5ce54,bug/1666026, module_extra_vars:, module_extra_args:,1,1
openstack%2Fmonasca-agent~master~Iec08f3161148abc2a6dc4d4725c67a2300f986c8,openstack/monasca-agent,master,Iec08f3161148abc2a6dc4d4725c67a2300f986c8,Convert to importutils,ABANDONED,2016-05-24 09:18:54.000000000,2017-02-20 10:00:40.000000000,,"[{'_account_id': 3}, {'_account_id': 14273}, {'_account_id': 16168}, {'_account_id': 17185}]","[{'number': 1, 'created': '2016-05-24 09:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/58eed9a5c745b6ddd8bf49e3a3ad1b062215edbf', 'message': ""Convert to importutils\n\nWe had some remaining users of __import__ that really deserved to\nbe converted to oslo's importutils.\n\nChange-Id: Iec08f3161148abc2a6dc4d4725c67a2300f986c8\n""}, {'number': 2, 'created': '2016-05-24 13:20:58.000000000', 'files': ['monasca_agent/collector/virt/libvirt/inspector.py'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/9ce66f9890da2c249812d7462136fafd110daf64', 'message': ""Convert to importutils\n\nWe had some remaining users of __import__ that really deserved to\nbe converted to oslo's importutils.\n\nChange-Id: Iec08f3161148abc2a6dc4d4725c67a2300f986c8\n""}]",1,320315,9ce66f9890da2c249812d7462136fafd110daf64,9,4,2,8157,,,0,"Convert to importutils

We had some remaining users of __import__ that really deserved to
be converted to oslo's importutils.

Change-Id: Iec08f3161148abc2a6dc4d4725c67a2300f986c8
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/15/320315/1 && git format-patch -1 --stdout FETCH_HEAD,['monasca_agent/collector/virt/libvirt/inspector.py'],1,58eed9a5c745b6ddd8bf49e3a3ad1b062215edbf,import,"import loggingfrom oslo_utils import importutilslog = logging.getLogger(__name__) try: libvirt = importutils.import_module('libvirt') except ImportError: log.warn(""Libvirt module could not be loaded. "" ""LibvirtInspector will not work correctly."")", libvirt = __import__('libvirt'),8,1
openstack%2Fpython-monascaclient~master~I89924278075cc429892245c2a357f4869ad45ec5,openstack/python-monascaclient,master,I89924278075cc429892245c2a357f4869ad45ec5,Updated from global requirements,MERGED,2017-02-10 05:59:07.000000000,2017-02-20 09:57:02.000000000,2017-02-20 09:57:02.000000000,"[{'_account_id': 3}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-02-10 05:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/f0eeafec22b6c543cea0b2a54cb3b2bbef090eb3', 'message': 'Updated from global requirements\n\nChange-Id: I89924278075cc429892245c2a357f4869ad45ec5\n'}, {'number': 2, 'created': '2017-02-11 17:51:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/f45a8729afb48502a7b28360fc68d01d586624e9', 'message': 'Updated from global requirements\n\nChange-Id: I89924278075cc429892245c2a357f4869ad45ec5\n'}, {'number': 3, 'created': '2017-02-15 01:35:19.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/dc69217aea3be4bb0f90b05394f1cdced553441f', 'message': 'Updated from global requirements\n\nChange-Id: I89924278075cc429892245c2a357f4869ad45ec5\n'}]",0,432092,dc69217aea3be4bb0f90b05394f1cdced553441f,10,2,3,11131,,,0,"Updated from global requirements

Change-Id: I89924278075cc429892245c2a357f4869ad45ec5
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/92/432092/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,f0eeafec22b6c543cea0b2a54cb3b2bbef090eb3,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Ftempest~master~I3b9f1b8b0887fcbaf47ffb8b61d4b4881c837e9e,openstack/tempest,master,I3b9f1b8b0887fcbaf47ffb8b61d4b4881c837e9e,Check servers are ACTIVE before creating new images,ABANDONED,2017-02-17 13:42:45.000000000,2017-02-20 09:53:35.000000000,,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 6735}, {'_account_id': 10385}, {'_account_id': 20190}]","[{'number': 1, 'created': '2017-02-17 13:42:45.000000000', 'files': ['tempest/api/compute/images/test_list_image_filters.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/3098bd30edd9f733e1af59861a04f92ed4f1f1ca', 'message': ""Check servers are ACTIVE before creating new images\n\nIn some cases (notably with the XenAPI driver) it's possible that\nthe image is in the ACTIVE state before the server returns from\nthe image_uploading state back into ACTIVE.\nMake sure that servers are fully ACTIVE before creating new\nimages and before returning from the setup method\n\nChange-Id: I3b9f1b8b0887fcbaf47ffb8b61d4b4881c837e9e\n""}]",1,435447,3098bd30edd9f733e1af59861a04f92ed4f1f1ca,7,5,1,6735,,,0,"Check servers are ACTIVE before creating new images

In some cases (notably with the XenAPI driver) it's possible that
the image is in the ACTIVE state before the server returns from
the image_uploading state back into ACTIVE.
Make sure that servers are fully ACTIVE before creating new
images and before returning from the setup method

Change-Id: I3b9f1b8b0887fcbaf47ffb8b61d4b4881c837e9e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/47/435447/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/images/test_list_image_filters.py'],1,3098bd30edd9f733e1af59861a04f92ed4f1f1ca,," # Before we can create a second image, the server must # be active. waiters.wait_for_server_status(cls.servers_client, cls.server1['id'], 'ACTIVE') # Wait for the image to be active after the image upload # While the images are all ACTIVE, make sure the servers # are also ACTIVE before completing resource setup waiters.wait_for_server_status(cls.servers_client, cls.server1['id'], 'ACTIVE') waiters.wait_for_server_status(cls.servers_client, cls.server2['id'], 'ACTIVE') ", # Wait for the server to be active after the image upload,12,1
openstack%2Ftempest~master~I272e364b1b2ed787c09df34839f349cb921254a7,openstack/tempest,master,I272e364b1b2ed787c09df34839f349cb921254a7,Remove wait_for_server from create_image_from_server,MERGED,2017-02-07 22:06:31.000000000,2017-02-20 09:51:00.000000000,2017-02-08 06:51:41.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 8556}]","[{'number': 1, 'created': '2017-02-07 22:06:31.000000000', 'files': ['tempest/api/compute/base.py', 'tempest/api/compute/images/test_images.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/621544cc962b35025d3cbb97e7eb32fa7d9f508a', 'message': ""Remove wait_for_server from create_image_from_server\n\nThis kwarg isn't actually used in practice anymore and it\nclutters up the logic in create_image_from_server so\nthis change removes it.\n\nChange-Id: I272e364b1b2ed787c09df34839f349cb921254a7\n""}]",0,430457,621544cc962b35025d3cbb97e7eb32fa7d9f508a,9,3,1,6873,,,0,"Remove wait_for_server from create_image_from_server

This kwarg isn't actually used in practice anymore and it
clutters up the logic in create_image_from_server so
this change removes it.

Change-Id: I272e364b1b2ed787c09df34839f349cb921254a7
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/430457/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/api/compute/images/test_images.py']",2,621544cc962b35025d3cbb97e7eb32fa7d9f508a,dump-server-details-on-snap-fail, wait_until='ACTIVE')," wait_until='ACTIVE', wait_for_server=False)",1,6
openstack%2Fdragonflow~stable%2Focata~I53b2f7117bccc5e9a43c1971b4588a8a88f82ed0,openstack/dragonflow,stable/ocata,I53b2f7117bccc5e9a43c1971b4588a8a88f82ed0,Fix could sync version 0 object in redis,MERGED,2017-02-16 12:07:12.000000000,2017-02-20 09:50:55.000000000,2017-02-20 09:50:55.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 12:07:12.000000000', 'files': ['dragonflow/db/db_consistent.py', 'dragonflow/tests/unit/test_db_consistent.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a4f14e56eca69f02e419860ba241c58994307b15', 'message': 'Fix could sync version 0 object in redis\n\nChange-Id: I53b2f7117bccc5e9a43c1971b4588a8a88f82ed0\nCloses-bug: #1663983\n(cherry picked from commit 2ec8d47899a81b9c1c8e00eaf37234a0bc3768f4)\n'}]",0,434859,a4f14e56eca69f02e419860ba241c58994307b15,11,4,1,20287,,,0,"Fix could sync version 0 object in redis

Change-Id: I53b2f7117bccc5e9a43c1971b4588a8a88f82ed0
Closes-bug: #1663983
(cherry picked from commit 2ec8d47899a81b9c1c8e00eaf37234a0bc3768f4)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/59/434859/1 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/db/db_consistent.py', 'dragonflow/tests/unit/test_db_consistent.py']",2,a4f14e56eca69f02e419860ba241c58994307b15,bug/1663983," self.lport_id0 = '0' df_obj0 = FakeDfLocalObj(self.lport_id0, 0) self.nb_api.get_all_logical_switches.return_value = \ [df_obj0, df_obj1, df_obj2] self.nb_api.get_all_logical_ports.return_value = \ [df_obj0, df_obj1, df_obj2] self.nb_api.get_routers.return_value = [df_obj0, df_obj1, df_obj2] self.nb_api.get_security_groups.return_value = \ [df_obj0, df_obj1, df_obj2] self.nb_api.get_floatingips.return_value = [df_obj0, df_obj1, df_obj2] self.controller.update_lswitch.assert_any_call(df_obj0) self.controller.update_lport.assert_any_call(df_obj0) self.controller.update_lrouter.assert_any_call(df_obj0) self.controller.update_secgroup.assert_any_call(df_obj0) self.controller.update_floatingip.assert_any_call(df_obj0)"," self.nb_api.get_all_logical_switches.return_value = [df_obj1, df_obj2] self.nb_api.get_all_logical_ports.return_value = [df_obj1, df_obj2] self.nb_api.get_routers.return_value = [df_obj1, df_obj2] self.nb_api.get_security_groups.return_value = [df_obj1, df_obj2] self.nb_api.get_floatingips.return_value = [df_obj1, df_obj2]",16,6
openstack%2Fdragonflow~stable%2Focata~I0eb822be1bd9d2d33adf839ea17f83badcf1a1e6,openstack/dragonflow,stable/ocata,I0eb822be1bd9d2d33adf839ea17f83badcf1a1e6,Add control and data plane config in cassandra,MERGED,2017-02-16 12:05:13.000000000,2017-02-20 09:48:32.000000000,2017-02-20 09:48:32.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 12:05:13.000000000', 'files': ['doc/source/multi-node-conf/cassandra_controller_node.conf', 'doc/source/multi-node-conf/cassandra_compute_node.conf', 'doc/source/single-node-conf/cassandra_local_controller.conf'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/35d1a9d4963255cac4eda304b5035ddc4c425429', 'message': 'Add control and data plane config in cassandra\n\nAs control and data plane config has been added in [1],\nso the new added cassandra should also be concerned\n\n[1] https://review.openstack.org/#/c/415116/\n\nChange-Id: I0eb822be1bd9d2d33adf839ea17f83badcf1a1e6\n(cherry picked from commit dc3a5d34146fd36c7ff3a6ef0bab3e7b5263fd00)\n'}]",0,434853,35d1a9d4963255cac4eda304b5035ddc4c425429,11,4,1,20287,,,0,"Add control and data plane config in cassandra

As control and data plane config has been added in [1],
so the new added cassandra should also be concerned

[1] https://review.openstack.org/#/c/415116/

Change-Id: I0eb822be1bd9d2d33adf839ea17f83badcf1a1e6
(cherry picked from commit dc3a5d34146fd36c7ff3a6ef0bab3e7b5263fd00)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/53/434853/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/multi-node-conf/cassandra_controller_node.conf', 'doc/source/multi-node-conf/cassandra_compute_node.conf', 'doc/source/single-node-conf/cassandra_local_controller.conf']",3,35d1a9d4963255cac4eda304b5035ddc4c425429,mgm-ip,# Node control plane ip address HOST_IP=<node's_management_IP_Address> ,,11,0
openstack%2Fkolla-ansible~master~Ie81206ce62fcab055727a4765351df5cc0c6de46,openstack/kolla-ansible,master,Ie81206ce62fcab055727a4765351df5cc0c6de46,"Update the ""ouput"" to ""output""",MERGED,2017-02-18 12:47:32.000000000,2017-02-20 09:39:49.000000000,2017-02-20 09:39:49.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 19316}, {'_account_id': 20663}]","[{'number': 1, 'created': '2017-02-18 12:47:32.000000000', 'files': ['ansible/roles/common/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/504adc36b589bac43a793420eeafce679930172c', 'message': 'Update the ""ouput"" to ""output""\n\nTrivialFix\n\nChange-Id: Ie81206ce62fcab055727a4765351df5cc0c6de46\n'}]",0,435703,504adc36b589bac43a793420eeafce679930172c,8,4,1,22165,,,0,"Update the ""ouput"" to ""output""

TrivialFix

Change-Id: Ie81206ce62fcab055727a4765351df5cc0c6de46
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/03/435703/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/tasks/config.yml'],1,504adc36b589bac43a793420eeafce679930172c,,- name: Copying over fluentd output config files,- name: Copying over fluentd ouput config files,1,1
openstack%2Fsahara~master~Ibf020370fda799ddd9bea3c6a7df3189dac27d33,openstack/sahara,master,Ibf020370fda799ddd9bea3c6a7df3189dac27d33,"Spelling changed from ""keypair"" to ""key pair"".",ABANDONED,2017-02-17 11:12:30.000000000,2017-02-20 09:37:52.000000000,,"[{'_account_id': 3}, {'_account_id': 16625}, {'_account_id': 17814}]","[{'number': 1, 'created': '2017-02-17 11:12:30.000000000', 'files': ['doc/source/overview.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/49b9668d8bf9a306f58e7e4da346b5ec3c2dcd7b', 'message': 'Spelling changed from ""keypair"" to ""key pair"".\n\nChange-Id: Ibf020370fda799ddd9bea3c6a7df3189dac27d33\n'}]",1,435378,49b9668d8bf9a306f58e7e4da346b5ec3c2dcd7b,6,3,1,25005,,,0,"Spelling changed from ""keypair"" to ""key pair"".

Change-Id: Ibf020370fda799ddd9bea3c6a7df3189dac27d33
",git fetch https://review.opendev.org/openstack/sahara refs/changes/78/435378/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/overview.rst'],1,49b9668d8bf9a306f58e7e4da346b5ec3c2dcd7b,spelling,should specify a key pair.,should specify a keypair.,1,1
openstack%2Ffuel-agent~master~I422159660ee8152ecb7c4b3e901eb2d2237f9ce0,openstack/fuel-agent,master,I422159660ee8152ecb7c4b3e901eb2d2237f9ce0,Get rid of separate configuration partition,ABANDONED,2017-02-16 17:18:09.000000000,2017-02-20 09:34:24.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 16771}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-16 17:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/f0bf5dd1734b939f441a3a2965692f264f99e4a6', 'message': 'Get rid of separate configuration partition\n\nIn our usecases separate partition is not needed. It is enough just to put\ncloudinit configuration into filesystem.\nThis also allows to avoid race condition which sometimes happen: some process\ndeletes the folder in tpm where configuration partition is mounted resulting in\ncloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}, {'number': 2, 'created': '2017-02-16 17:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/ac991fe47ca83cd20165b447de43e3ff45958d73', 'message': 'Get rid of separate configuration partition\n\nIn our usecases separate partition is not needed. It is enough just to put\ncloudinit configuration into filesystem.\nThis also allows to avoid race condition which sometimes happen: some process\ndeletes the folder in tpm where configuration partition is mounted resulting in\ncloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}, {'number': 3, 'created': '2017-02-16 17:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/5a3bbe3232903ae4db9ab49e809d021c7e4477dd', 'message': 'Get rid of separate configuration partition\n\nIn our usecases the separate partition is not needed. It is enough just to put\ncloudinit configuration into the root filesystem.\nThis also allows to avoid a race condition which sometimes happens: some process\ndeletes the folder in tmp where the configuration partition is mounted resulting\nin cloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}, {'number': 4, 'created': '2017-02-17 06:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/fcab3e1e02db64490627c4b61041b63b12b4e573', 'message': 'Get rid of separate configuration partition\n\nIn our usecases the separate partition is not needed. It is enough just to put\ncloudinit configuration into the root filesystem.\nThis also allows to avoid a race condition which sometimes happens: some process\ndeletes the folder in tmp where the configuration partition is mounted resulting\nin cloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}, {'number': 5, 'created': '2017-02-17 07:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/70475fed2d59a07171b80dde22ea4f979225f629', 'message': 'Get rid of separate configuration partition\n\nIn our usecases the separate partition is not needed. It is enough just to put\ncloudinit configuration into the root filesystem.\nThis also allows to avoid a race condition which sometimes happens: some process\ndeletes the folder in tmp where the configuration partition is mounted resulting\nin cloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}, {'number': 6, 'created': '2017-02-17 07:26:26.000000000', 'files': ['contrib/ironic/bootstrap-files/etc/fuel-agent/fuel-agent.conf', 'fuel_agent/drivers/nailgun.py', 'fuel_agent/tests/test_manager.py', 'fuel_agent/tests/test_nailgun.py', 'etc/fuel-agent/fuel-agent.conf.sample', 'fuel_agent/manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/0383e3486f1378d4cb156cdae1e452bc6cf980c7', 'message': 'Get rid of separate configuration partition\n\nIn our usecases the separate partition is not needed. It is enough just to put\ncloudinit configuration into the root filesystem.\nThis also allows to avoid a race condition which sometimes happens: some process\ndeletes the folder in tmp where the configuration partition is mounted resulting\nin cloudinit failure to read its configuration.\n\nChange-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0\nCloses-Bug: #1652002\n'}]",2,435035,0383e3486f1378d4cb156cdae1e452bc6cf980c7,42,6,6,21013,,,0,"Get rid of separate configuration partition

In our usecases the separate partition is not needed. It is enough just to put
cloudinit configuration into the root filesystem.
This also allows to avoid a race condition which sometimes happens: some process
deletes the folder in tmp where the configuration partition is mounted resulting
in cloudinit failure to read its configuration.

Change-Id: I422159660ee8152ecb7c4b3e901eb2d2237f9ce0
Closes-Bug: #1652002
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/35/435035/6 && git format-patch -1 --stdout FETCH_HEAD,['fuel_agent/manager.py'],1,f0bf5dd1734b939f441a3a2965692f264f99e4a6,bug/1652002," def _prepare_cloudinit_config(self, target_dir): md_output_path = os.path.join(target_dir, 'meta-data') ud_output_path = os.path.join(target_dir, 'user-data') os.makedirs(target_dir) def do_inject_cloudinit_config(self): LOG.debug('--- Injecting cloudinit config ' '(do_inject_cloudinit_config) ---') root_fs = self.driver.partition_scheme.fs_by_mount('/') root = fu.mount_fs_temp(root_fs.type, str(root_fs.device)) try: self._prepare_cloudinit_config( os.path.join(root, 'var/lib/cloud/seed/nocloud')) finally: fu.umount_fs(root) self.do_inject_cloudinit_config()"," def _make_configdrive_image(self, src_files): bs = 4096 configdrive_device = self.driver.partition_scheme.configdrive_device() size = utils.execute('blockdev', '--getsize64', configdrive_device)[0] size = int(size.strip()) utils.execute('truncate', '--size=%d' % size, CONF.config_drive_path) fu.make_fs( fs_type='ext2', fs_options=' -b %d -F ' % bs, fs_label='config-2', dev=six.text_type(CONF.config_drive_path)) mount_point = tempfile.mkdtemp(dir=CONF.tmp_path) try: fu.mount_fs('ext2', CONF.config_drive_path, mount_point) for file_path in src_files: name = os.path.basename(file_path) if os.path.isdir(file_path): shutil.copytree(file_path, os.path.join(mount_point, name)) else: shutil.copy2(file_path, mount_point) except Exception as exc: LOG.error('Error copying files to configdrive: %s', exc) raise finally: fu.umount_fs(mount_point) os.rmdir(mount_point) def _prepare_configdrive_files(self): cd_root = tempfile.mkdtemp(dir=CONF.tmp_path) cd_latest = os.path.join(cd_root, 'openstack', 'latest') md_output_path = os.path.join(cd_latest, 'meta_data.json') ud_output_path = os.path.join(cd_latest, 'user_data') os.makedirs(cd_latest) return [os.path.join(cd_root, 'openstack')] def do_configdrive(self): LOG.debug('--- Creating configdrive (do_configdrive) ---') if CONF.prepare_configdrive: files = self._prepare_configdrive_files() self._make_configdrive_image(files) if CONF.prepare_configdrive or os.path.isfile(CONF.config_drive_path): self._add_configdrive_image() def _add_configdrive_image(self): configdrive_device = self.driver.partition_scheme.configdrive_device() if configdrive_device is None: raise errors.WrongPartitionSchemeError( 'Error while trying to get configdrive device: ' 'configdrive device not found') size = os.path.getsize(CONF.config_drive_path) md5 = utils.calculate_md5(CONF.config_drive_path, size) fs_type = fu.get_fs_type(CONF.config_drive_path) self.driver.image_scheme.add_image( uri='file://%s' % CONF.config_drive_path, target_device=configdrive_device, format=fs_type, container='raw', size=size, md5=md5, ) self.do_configdrive()",15,65
openstack%2Fdragonflow~stable%2Focata~I0bef7305fab70d73cc00e4915e8d10cf8425ca5c,openstack/dragonflow,stable/ocata,I0bef7305fab70d73cc00e4915e8d10cf8425ca5c,Fix error method usage in df_local_controller,MERGED,2017-02-16 12:06:51.000000000,2017-02-20 09:27:53.000000000,2017-02-20 09:27:53.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 12:06:51.000000000', 'files': ['dragonflow/tests/unit/test_df_local_controller.py', 'dragonflow/controller/df_local_controller.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a8b1330d7a202743d5a119934290fa0b6e045ec4', 'message': 'Fix error method usage in df_local_controller\n\nChange-Id: I0bef7305fab70d73cc00e4915e8d10cf8425ca5c\n(cherry picked from commit f62895d5f0ecc30429b05585e5eebf82e761513d)\n'}]",0,434857,a8b1330d7a202743d5a119934290fa0b6e045ec4,11,4,1,20287,,,0,"Fix error method usage in df_local_controller

Change-Id: I0bef7305fab70d73cc00e4915e8d10cf8425ca5c
(cherry picked from commit f62895d5f0ecc30429b05585e5eebf82e761513d)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/57/434857/1 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/tests/unit/test_df_local_controller.py', 'dragonflow/controller/df_local_controller.py']",2,a8b1330d7a202743d5a119934290fa0b6e045ec4,error-method, self.delete_lport(port.get_id()), self.logical_port_deleted(port.get_id()),17,1
openstack%2Fec2-api~master~I263d9c52500b32861005e5c2d6a0704d76c9f1e1,openstack/ec2-api,master,I263d9c52500b32861005e5c2d6a0704d76c9f1e1,Use hacking 0.12.x,MERGED,2017-01-04 16:24:02.000000000,2017-02-20 09:24:48.000000000,2017-02-20 09:24:48.000000000,"[{'_account_id': 3}, {'_account_id': 10234}]","[{'number': 1, 'created': '2017-01-04 16:24:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/0853263fd162940ece1315d0f368c4aa3e04304b', 'message': 'Use hacking 0.12.x\n\nChange-Id: I263d9c52500b32861005e5c2d6a0704d76c9f1e1\n'}, {'number': 2, 'created': '2017-02-20 01:42:54.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/4e7b5133ba3f75567271f27b6c52f903efba7adb', 'message': 'Use hacking 0.12.x\n\n0.12.x is the generally usable newest hacking version that\nprovides a couple of newer checks for compliance with OpenStack\nguidelines.\n\nChange-Id: I263d9c52500b32861005e5c2d6a0704d76c9f1e1\n'}]",0,416614,4e7b5133ba3f75567271f27b6c52f903efba7adb,12,2,2,6593,,,0,"Use hacking 0.12.x

0.12.x is the generally usable newest hacking version that
provides a couple of newer checks for compliance with OpenStack
guidelines.

Change-Id: I263d9c52500b32861005e5c2d6a0704d76c9f1e1
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/14/416614/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,0853263fd162940ece1315d0f368c4aa3e04304b,,"hacking!=0.13.0,<0.14,>=0.12.0 # Apache-2.0 ","hacking<0.12,>=0.11.0 # Apache-2.0",2,1
openstack%2Ftripleo-common~master~Id72cefcb7a1bd9baf515dd95f389d206a3ccf01a,openstack/tripleo-common,master,Id72cefcb7a1bd9baf515dd95f389d206a3ccf01a,Update the Nova client creation,MERGED,2017-02-17 14:17:48.000000000,2017-02-20 09:24:37.000000000,2017-02-20 09:24:37.000000000,"[{'_account_id': 3}, {'_account_id': 4978}, {'_account_id': 7065}, {'_account_id': 7509}, {'_account_id': 8532}, {'_account_id': 9712}]","[{'number': 1, 'created': '2017-02-17 14:17:48.000000000', 'files': ['tripleo_common/actions/base.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b3282003f2003d7486a9b284c4c710e90f68cba8', 'message': ""Update the Nova client creation\n\nThe current novaclient creation code passes in a url parameter which\nisn't valid. This change updates the client creation and uses the same\ncode as Mistral does for it's own OpenStack actions.\n\nChange-Id: Id72cefcb7a1bd9baf515dd95f389d206a3ccf01a\nCloses-bug: #1665637\n""}]",0,435467,b3282003f2003d7486a9b284c4c710e90f68cba8,14,6,1,9712,,,0,"Update the Nova client creation

The current novaclient creation code passes in a url parameter which
isn't valid. This change updates the client creation and uses the same
code as Mistral does for it's own OpenStack actions.

Change-Id: Id72cefcb7a1bd9baf515dd95f389d206a3ccf01a
Closes-bug: #1665637
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/67/435467/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/actions/base.py'],1,b3282003f2003d7486a9b284c4c710e90f68cba8,bug/1665637," client = nova_client( 2, username=None, api_key=None, service_type='compute', auth_token=ctx.auth_token, tenant_id=ctx.project_id, region_name=keystone_endpoint.region, auth_url=keystone_endpoint.url, insecure=ctx.insecure ) client.client.management_url = keystone_utils.format_url( nova_endpoint.url, {'tenant_id': ctx.project_id} ) return client"," nc = nova_client(2, username=ctx.user_name, auth_token=ctx.auth_token, auth_url=keystone_endpoint.url, url=nova_endpoint.url, project_id=ctx.project_id) nc.client.management_url = nova_endpoint.url return nc",18,5
openstack%2Fdragonflow~stable%2Focata~I42fb9fed82c59d92134d477051bf943840bc57f6,openstack/dragonflow,stable/ocata,I42fb9fed82c59d92134d477051bf943840bc57f6,Fix typo error in spec doc for df,MERGED,2017-02-16 12:05:48.000000000,2017-02-20 09:24:30.000000000,2017-02-20 09:24:30.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 12:05:48.000000000', 'files': ['doc/source/specs/nb_api_refactor.rst', 'doc/source/specs/vlan_networking.rst', 'doc/source/specs/classification_app.rst', 'doc/source/specs/igmp_application_and_multicast_support.rst', 'doc/source/specs/virtual_tunnel_port.rst', 'doc/source/specs/vm_live_migration.rst', 'doc/source/specs/config_generation.rst', 'doc/source/specs/security_groups.rst', 'doc/source/specs/control_plane_testing.rst', 'doc/source/specs/allowed_address_pairs.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f01b6d9e54db687b8c0223783921c0ebea4ce12f', 'message': 'Fix typo error in spec doc for df\n\nChange-Id: I42fb9fed82c59d92134d477051bf943840bc57f6\n(cherry picked from commit 82436d3f9a235f50efc21fc38ef2814c29d997c9)\n'}]",0,434854,f01b6d9e54db687b8c0223783921c0ebea4ce12f,11,4,1,20287,,,0,"Fix typo error in spec doc for df

Change-Id: I42fb9fed82c59d92134d477051bf943840bc57f6
(cherry picked from commit 82436d3f9a235f50efc21fc38ef2814c29d997c9)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/54/434854/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/nb_api_refactor.rst', 'doc/source/specs/vlan_networking.rst', 'doc/source/specs/classification_app.rst', 'doc/source/specs/igmp_application_and_multicast_support.rst', 'doc/source/specs/virtual_tunnel_port.rst', 'doc/source/specs/vm_live_migration.rst', 'doc/source/specs/config_generation.rst', 'doc/source/specs/security_groups.rst', 'doc/source/specs/control_plane_testing.rst', 'doc/source/specs/allowed_address_pairs.rst']",10,f01b6d9e54db687b8c0223783921c0ebea4ce12f,error-typo,"Dragonflow.latter ""detection way"", and add an option in the configuration for users to","dragonflow.latter ""detectation way"", and add an option in the configuration for users to",22,22
openstack%2Fdragonflow~stable%2Focata~I2bce060013a95c5901ec4f2f87f1a5ebe74a033b,openstack/dragonflow,stable/ocata,I2bce060013a95c5901ec4f2f87f1a5ebe74a033b,Fix the spec format for dragonflow,MERGED,2017-02-16 12:06:29.000000000,2017-02-20 09:20:46.000000000,2017-02-20 09:20:46.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 12:06:29.000000000', 'files': ['doc/source/specs/port_status_update.rst', 'doc/source/usage.rst', 'doc/source/specs/igmp_application_and_multicast_support.rst', 'doc/source/containers.rst', 'doc/source/features.rst', 'doc/source/installation.rst', 'doc/source/specs/ipv6.rst', 'doc/source/specs/allowed_address_pairs.rst', 'doc/source/index.rst', 'doc/source/releasenotes.rst', 'doc/source/specs/selective_topo_dist.rst', 'doc/source/specs/skeleton.rst'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/858ea3789dd28c642f5dcf54b01574911b3a261d', 'message': 'Fix the spec format for dragonflow\n\nChange-Id: I2bce060013a95c5901ec4f2f87f1a5ebe74a033b\n(cherry picked from commit 31d155d9331501ea556f51875d798cf174148640)\n'}]",0,434856,858ea3789dd28c642f5dcf54b01574911b3a261d,11,4,1,20287,,,0,"Fix the spec format for dragonflow

Change-Id: I2bce060013a95c5901ec4f2f87f1a5ebe74a033b
(cherry picked from commit 31d155d9331501ea556f51875d798cf174148640)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/56/434856/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/specs/port_status_update.rst', 'doc/source/usage.rst', 'doc/source/specs/igmp_application_and_multicast_support.rst', 'doc/source/containers.rst', 'doc/source/features.rst', 'doc/source/installation.rst', 'doc/source/specs/ipv6.rst', 'doc/source/specs/allowed_address_pairs.rst', 'doc/source/index.rst', 'doc/source/releasenotes.rst', 'doc/source/specs/selective_topo_dist.rst', 'doc/source/specs/skeleton.rst']",12,858ea3789dd28c642f5dcf54b01574911b3a261d,spec-format,==================================,====================================================================================,22,23
openstack%2Ffuel-library~master~If68de7d52617803b379ed564f07ed6c947315dbd,openstack/fuel-library,master,If68de7d52617803b379ed564f07ed6c947315dbd,Enable proxy headers parsing,MERGED,2017-02-17 16:06:24.000000000,2017-02-20 09:02:48.000000000,2017-02-20 08:47:59.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14200}, {'_account_id': 14985}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-17 16:06:24.000000000', 'files': ['deployment/puppet/openstack_tasks/manifests/openstack_cinder/openstack_cinder.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fcf9c5cdf98b11b91c1919b5167f740cd7276583', 'message': 'Enable proxy headers parsing\n\nAs cinder is placed behind the proxy we need to enable\nproxy headers parsing, so cinder is aware about about\nprotocol used to connect to endpoint.\n\nChange-Id: If68de7d52617803b379ed564f07ed6c947315dbd\nCloses-Bug: #1665361\n'}]",0,435507,fcf9c5cdf98b11b91c1919b5167f740cd7276583,34,7,1,18795,,,0,"Enable proxy headers parsing

As cinder is placed behind the proxy we need to enable
proxy headers parsing, so cinder is aware about about
protocol used to connect to endpoint.

Change-Id: If68de7d52617803b379ed564f07ed6c947315dbd
Closes-Bug: #1665361
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/07/435507/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack_tasks/manifests/openstack_cinder/openstack_cinder.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb']",2,fcf9c5cdf98b11b91c1919b5167f740cd7276583,bug/1665361," 'default_volume_type' => default_volume_type, 'enable_proxy_headers_parsing' => true,"," 'default_volume_type' => default_volume_type,",17,15
openstack%2Fdevstack~master~I0699016fbf5fdc21572964c74c8996b2d991d27d,openstack/devstack,master,I0699016fbf5fdc21572964c74c8996b2d991d27d,Change default Nova admin endpoint to public,ABANDONED,2017-02-17 13:44:54.000000000,2017-02-20 08:25:37.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11904}, {'_account_id': 12408}, {'_account_id': 13431}, {'_account_id': 16376}]","[{'number': 1, 'created': '2017-02-17 13:44:54.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/5f0ceadd82978a5183f9d80bd162dd82526696af', 'message': ""Change default Nova admin endpoint to public\n\nAs default Devstack doesn't create admin Nova endpoint\nsince Ided7a65c81b3a0b56f0184847fc82e17c29a771e landed.\n\nChange-Id: I0699016fbf5fdc21572964c74c8996b2d991d27d\n""}]",0,435448,5f0ceadd82978a5183f9d80bd162dd82526696af,12,10,1,13431,,,0,"Change default Nova admin endpoint to public

As default Devstack doesn't create admin Nova endpoint
since Ided7a65c81b3a0b56f0184847fc82e17c29a771e landed.

Change-Id: I0699016fbf5fdc21572964c74c8996b2d991d27d
",git fetch https://review.opendev.org/openstack/devstack refs/changes/48/435448/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,5f0ceadd82978a5183f9d80bd162dd82526696af,,CINDER_NOVA_CATALOG_ADMIN_INFO=${CINDER_NOVA_CATALOG_ADMIN_INFO:-compute:nova:publicURL},CINDER_NOVA_CATALOG_ADMIN_INFO=${CINDER_NOVA_CATALOG_ADMIN_INFO:-compute:nova:adminURL},1,1
openstack%2Fheat~master~Ibd7a0e005675b55661dfcbaa3912d0b630ddb2d2,openstack/heat,master,Ibd7a0e005675b55661dfcbaa3912d0b630ddb2d2,Fix the incorrect link of the rdo installation guide,MERGED,2017-02-20 07:05:08.000000000,2017-02-20 08:18:23.000000000,2017-02-20 08:18:23.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-20 07:05:08.000000000', 'files': ['doc/source/getting_started/on_fedora.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/f6ad1e85849c1ffa6f594e0a2da450f4941f8620', 'message': 'Fix the incorrect link of the rdo installation guide\n\nChange-Id: Ibd7a0e005675b55661dfcbaa3912d0b630ddb2d2\n'}]",0,435869,f6ad1e85849c1ffa6f594e0a2da450f4941f8620,6,2,1,19779,,,0,"Fix the incorrect link of the rdo installation guide

Change-Id: Ibd7a0e005675b55661dfcbaa3912d0b630ddb2d2
",git fetch https://review.opendev.org/openstack/heat refs/changes/69/435869/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/getting_started/on_fedora.rst'],1,f6ad1e85849c1ffa6f594e0a2da450f4941f8620,incorrect_link,There are instructions for `installing the RDO OpenStack <https://www.rdoproject.org/install/quickstart/>`_ on Fedora and CentOS.,There are instructions for `installing the RDO OpenStack distribution <https://www.rdoproject.org/Quickstart>`_ on Fedora and CentOS.,2,2
openstack%2Fzun~master~Id206a0f66815ae8201a2ff5ca26171e4e95fef8c,openstack/zun,master,Id206a0f66815ae8201a2ff5ca26171e4e95fef8c,Refactor db/api.py,ABANDONED,2017-01-17 07:32:52.000000000,2017-02-20 08:05:39.000000000,,"[{'_account_id': 3}, {'_account_id': 16277}, {'_account_id': 21832}, {'_account_id': 21845}, {'_account_id': 21856}, {'_account_id': 24359}]","[{'number': 1, 'created': '2017-01-17 07:32:52.000000000', 'files': ['zun/db/api.py', 'zun/objects/image.py', 'zun/objects/container.py', 'zun/objects/zun_service.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/64a3f95914430b0b18a116892a71342627c2ffd3', 'message': 'Refactor db/api.py\n\nChange-Id: Id206a0f66815ae8201a2ff5ca26171e4e95fef8c\n'}]",0,421107,64a3f95914430b0b18a116892a71342627c2ffd3,8,6,1,21856,,,0,"Refactor db/api.py

Change-Id: Id206a0f66815ae8201a2ff5ca26171e4e95fef8c
",git fetch https://review.opendev.org/openstack/zun refs/changes/07/421107/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/db/api.py', 'zun/objects/image.py', 'zun/objects/container.py', 'zun/objects/zun_service.py']",4,64a3f95914430b0b18a116892a71342627c2ffd3,, dbapi = dbapi.Connection ,,226,232
openstack%2Fcinder~master~I9b985349ccb61e51a91d47d94393b68d901ac738,openstack/cinder,master,I9b985349ccb61e51a91d47d94393b68d901ac738,[4/4]Reset generic volume group and group snapshot statuses,MERGED,2016-11-09 08:49:32.000000000,2017-02-20 08:03:50.000000000,2017-02-14 07:58:18.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10058}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15054}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17103}, {'_account_id': 17565}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18883}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22381}, {'_account_id': 22450}, {'_account_id': 22510}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24863}]","[{'number': 1, 'created': '2016-11-09 08:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/136d3f9117c764808fe4f68618570051bb85e72b', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(snapshots inclusive),this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API(https://review.openstack.org/#/c/389091/).\n    2. snapshot API(https://review.openstack.org/#/c/389577/).\n    3. cinder client(https://review.openstack.org/390169/).\n    4. documentation(this).\n\nAPIImpact\nDocImpact\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}, {'number': 2, 'created': '2016-12-19 12:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c511b2d4d012271815a5c513533886b30cb3a29', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(include snapshots), this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API [1].\n    2. snapshot API [2].\n    3. cinder client [3].\n    4. documentation(this).\n\n[1] 92bbacdcef302b09d85618644e1dfc4511841274\n[2] 70171dc2ff6b085db90228d98638047bfc6984ba\n[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9\n\nDocImpact\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}, {'number': 3, 'created': '2016-12-20 03:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/59fa89bf811724556d0325cc03015f472c838ba2', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(include snapshots), this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API [1].\n    2. snapshot API [2].\n    3. cinder client [3].\n    4. documentation(this).\n\n[1] 92bbacdcef302b09d85618644e1dfc4511841274\n[2] 70171dc2ff6b085db90228d98638047bfc6984ba\n[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9\n\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}, {'number': 4, 'created': '2017-02-13 09:00:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ee0ee33eb9e1c677f98ece8a00e7907046d3f121', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(include snapshots), this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API [1].\n    2. snapshot API [2].\n    3. cinder client [3].\n    4. documentation(this).\n\n[1] 92bbacdcef302b09d85618644e1dfc4511841274\n[2] 70171dc2ff6b085db90228d98638047bfc6984ba\n[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9\n\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}, {'number': 5, 'created': '2017-02-13 09:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/05d79268788d8bab420769a0a489c7e7f7d02b7b', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(include snapshots), this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API [1].\n    2. snapshot API [2].\n    3. cinder client [3].\n    4. documentation(this).\n\n[1] 92bbacdcef302b09d85618644e1dfc4511841274\n[2] 70171dc2ff6b085db90228d98638047bfc6984ba\n[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9\n\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}, {'number': 6, 'created': '2017-02-13 11:38:16.000000000', 'files': ['api-ref/source/v3/samples/group-snapshot-reset-status-request.json', 'api-ref/source/v3/groups.inc', 'api-ref/source/v3/group-snapshots.inc', 'api-ref/source/v3/parameters.yaml', 'api-ref/source/v3/samples/group-reset-status-request.json'], 'web_link': 'https://opendev.org/openstack/cinder/commit/085d44ba784ffe3e8122fb876ae01f5fcd246b78', 'message': '[4/4]Reset generic volume group and group snapshot statuses\n\nCurrently the administrator could only reset the generic group\nstatus by db operation(include snapshots), this change intends\nto add new admin actions to achieve these.\n\nThe patch list:\n    1. group API [1].\n    2. snapshot API [2].\n    3. cinder client [3].\n    4. documentation(this).\n\n[1] 92bbacdcef302b09d85618644e1dfc4511841274\n[2] 70171dc2ff6b085db90228d98638047bfc6984ba\n[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9\n\nPartial-Implements: blueprint reset-cg-and-cgs-status\n\nChange-Id: I9b985349ccb61e51a91d47d94393b68d901ac738\n'}]",12,395464,085d44ba784ffe3e8122fb876ae01f5fcd246b78,142,52,6,23083,,,0,"[4/4]Reset generic volume group and group snapshot statuses

Currently the administrator could only reset the generic group
status by db operation(include snapshots), this change intends
to add new admin actions to achieve these.

The patch list:
    1. group API [1].
    2. snapshot API [2].
    3. cinder client [3].
    4. documentation(this).

[1] 92bbacdcef302b09d85618644e1dfc4511841274
[2] 70171dc2ff6b085db90228d98638047bfc6984ba
[3] 9820cb6f38b6a68351776c333e5deacd38c5afc9

Partial-Implements: blueprint reset-cg-and-cgs-status

Change-Id: I9b985349ccb61e51a91d47d94393b68d901ac738
",git fetch https://review.opendev.org/openstack/cinder refs/changes/64/395464/6 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/v3/samples/group-snapshot-reset-status-request.json', 'api-ref/source/v3/groups.inc', 'api-ref/source/v3/group-snapshots.inc', 'api-ref/source/v3/parameters.yaml', 'api-ref/source/v3/samples/group-reset-status-request.json']",5,136d3f9117c764808fe4f68618570051bb85e72b,bp/reset-cg-and-cgs-status,"{ ""reset_status"": { ""status"": ""available"" } }",,84,0
openstack%2Fkeystone~master~I3095fe4bd7dbe6a6fb056819cd68d952570a0f02,openstack/keystone,master,I3095fe4bd7dbe6a6fb056819cd68d952570a0f02,Fix typo in config doc,MERGED,2017-02-20 02:43:36.000000000,2017-02-20 07:28:41.000000000,2017-02-20 07:28:41.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 20382}]","[{'number': 1, 'created': '2017-02-20 02:43:36.000000000', 'files': ['doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6748673948cdd7625ddac2f5f3fa162d9b07e68c', 'message': 'Fix typo in config doc\n\nChange-Id: I3095fe4bd7dbe6a6fb056819cd68d952570a0f02\n'}]",0,435830,6748673948cdd7625ddac2f5f3fa162d9b07e68c,8,3,1,17645,,,0,"Fix typo in config doc

Change-Id: I3095fe4bd7dbe6a6fb056819cd68d952570a0f02
",git fetch https://review.opendev.org/openstack/keystone refs/changes/30/435830/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/configuration.rst'],1,6748673948cdd7625ddac2f5f3fa162d9b07e68c,fix-typo,"sha256 generator as default, which produces regenerable public IDs. Theincluding any of the reserved characters specified in section 2.2 of","sha256 generator as default, which produces regeneratable public IDs. Theincluding any of the reserverd characters specified in section 2.2 of",2,2
openstack%2Fnova~stable%2Focata~I2285005098b7dab7753366f53667ff8d4532d668,openstack/nova,stable/ocata,I2285005098b7dab7753366f53667ff8d4532d668,Skip soft-deleted records in 330_enforce_mitaka_online_migrations,MERGED,2017-02-17 22:42:29.000000000,2017-02-20 07:11:58.000000000,2017-02-20 07:11:58.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 10118}]","[{'number': 1, 'created': '2017-02-17 22:42:29.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/10a32ddcf85076266c3ede6e8ca2e9776d64d32e', 'message': ""Skip soft-deleted records in 330_enforce_mitaka_online_migrations\n\nThe 330_enforce_mitaka_online_migrations migration considers\nsoft-deleted records as unmigrated (the blocker migration uses the\nselect function from sqlalchemy), but the online migrations only\nmigrate non-deleted records (the migrations use the model_query\nfunction which defaults to read_deleted='no'). So even after running\nall of the online migrations, operators can get stuck until they can\nhard delete any soft-deleted compute_nodes, aggregates, and\npci_devices records they have.\n\nCloses-Bug: #1665719\n\nChange-Id: I2285005098b7dab7753366f53667ff8d4532d668\n(cherry picked from commit 6d64b7274410ae45b95bd7ac7f702c16daaa0fcd)\n""}]",0,435619,10a32ddcf85076266c3ede6e8ca2e9776d64d32e,24,4,1,4690,,,0,"Skip soft-deleted records in 330_enforce_mitaka_online_migrations

The 330_enforce_mitaka_online_migrations migration considers
soft-deleted records as unmigrated (the blocker migration uses the
select function from sqlalchemy), but the online migrations only
migrate non-deleted records (the migrations use the model_query
function which defaults to read_deleted='no'). So even after running
all of the online migrations, operators can get stuck until they can
hard delete any soft-deleted compute_nodes, aggregates, and
pci_devices records they have.

Closes-Bug: #1665719

Change-Id: I2285005098b7dab7753366f53667ff8d4532d668
(cherry picked from commit 6d64b7274410ae45b95bd7ac7f702c16daaa0fcd)
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/435619/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py']",2,10a32ddcf85076266c3ede6e8ca2e9776d64d32e,bug/1665719," def test_deleted_not_migrated(self): cn_values = dict(vcpus=1, memory_mb=512, local_gb=10, vcpus_used=0, memory_mb_used=256, local_gb_used=5, hypervisor_type='HyperDanVM', hypervisor_version='34', cpu_info='foo') cn = db_api.compute_node_create(self.context, cn_values) agg_values = dict(name='foo') agg = db_api.aggregate_create(self.context, agg_values) pd = db_api.pci_device_update(self.context, 1, 'foo:bar', {'parent_addr': None, 'compute_node_id': 1, 'address': 'foo:bar', 'vendor_id': '123', 'product_id': '456', 'dev_type': 'foo', 'label': 'foobar', 'status': 'whatisthis?'}) db_api.compute_node_delete(self.context, cn['id']) db_api.aggregate_delete(self.context, agg['id']) db_api.pci_device_destroy(self.context, pd['compute_node_id'], pd['address']) # blocker should not block on soft-deleted records self.migration.upgrade(self.engine) ",,32,5
openstack%2Fsenlin~master~Ia7a0296929ab2b17250128fee808846d9222e9d3,openstack/senlin,master,Ia7a0296929ab2b17250128fee808846d9222e9d3,Remove context from service db apis,MERGED,2017-02-20 03:01:19.000000000,2017-02-20 07:05:11.000000000,2017-02-20 07:05:11.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-20 03:01:19.000000000', 'files': ['senlin/objects/service.py', 'senlin/engine/service.py', 'senlin/tests/unit/db/test_registry_api.py', 'senlin/tests/unit/db/test_lock_api.py', 'senlin/tests/unit/engine/test_engine_startstop.py', 'senlin/tests/unit/db/test_service_api.py', 'senlin/db/api.py', 'senlin/cmd/manage.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/58ed4484dc840f6f91a16136f1c03faabb612ee4', 'message': 'Remove context from service db apis\n\nThis also adds service create call to the service start up procedure.\n\nChange-Id: Ia7a0296929ab2b17250128fee808846d9222e9d3\n'}]",0,435831,58ed4484dc840f6f91a16136f1c03faabb612ee4,7,3,1,8246,,,0,"Remove context from service db apis

This also adds service create call to the service start up procedure.

Change-Id: Ia7a0296929ab2b17250128fee808846d9222e9d3
",git fetch https://review.opendev.org/openstack/senlin refs/changes/31/435831/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/objects/service.py', 'senlin/engine/service.py', 'senlin/tests/unit/db/test_registry_api.py', 'senlin/tests/unit/db/test_lock_api.py', 'senlin/tests/unit/engine/test_engine_startstop.py', 'senlin/tests/unit/db/test_service_api.py', 'senlin/cmd/manage.py', 'senlin/db/api.py', 'senlin/db/sqlalchemy/api.py']",9,58ed4484dc840f6f91a16136f1c03faabb612ee4,create-service,"def service_create(service_id, host=None, binary=None, topic=None):def service_update(service_id, values=None):def service_delete(service_id):def service_get(service_id): with session_for_read() as session: return session.query(models.Service).get(service_id) def service_get_all(): with session_for_read() as session: return session.query(models.Service).all() def gc_by_engine(engine_id):","def service_create(context, service_id, host=None, binary=None, topic=None):def service_update(context, service_id, values=None):def service_delete(context, service_id):def service_get(context, service_id): return model_query(context, models.Service).get(service_id) def service_get_all(context): return model_query(context, models.Service).all() def gc_by_engine(context, engine_id):",69,88
openstack%2Fmagnum~master~Iec98aaee2c72bee81937b9554ddcb0abd880c34c,openstack/magnum,master,Iec98aaee2c72bee81937b9554ddcb0abd880c34c,[suse] Fix flanneld overlay network configuration,MERGED,2016-11-18 08:30:57.000000000,2017-02-20 06:59:22.000000000,2017-02-20 06:59:22.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 6593}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 12404}, {'_account_id': 13861}, {'_account_id': 15123}, {'_account_id': 20498}]","[{'number': 1, 'created': '2016-11-18 08:30:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5aa8ffbf2be21b8d6ab45d760aa2092da96a9a94', 'message': '[suse] Fix flanneld overlay network configuration\n\nChange-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c\n'}, {'number': 2, 'created': '2016-11-22 12:14:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/811c754bd1f9a9b2edd5517b0ee646f9711f72d9', 'message': '[suse] Fix flanneld overlay network configuration\n\nChange-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c\n'}, {'number': 3, 'created': '2016-12-13 09:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b4243d1f309514868c5c8cf1487e62892001fdea', 'message': '[suse] Fix flanneld overlay network configuration\n\nChange-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c\n'}, {'number': 4, 'created': '2016-12-17 09:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/accdb024d4bf1094a72ba396c5416206d265edd6', 'message': '[suse] Fix flanneld overlay network configuration\n\nChange-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c\n'}, {'number': 5, 'created': '2017-01-14 21:02:26.000000000', 'files': ['contrib/drivers/k8s_opensuse_v1/templates/kubemaster.yaml', 'contrib/drivers/k8s_opensuse_v1/templates/kubeminion.yaml', 'contrib/drivers/k8s_opensuse_v1/templates/kubecluster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a9a5381b597581967caf71d8610f0d5eca555c38', 'message': '[suse] Fix flanneld overlay network configuration\n\nChange-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c\n'}]",7,399436,a9a5381b597581967caf71d8610f0d5eca555c38,32,9,5,6593,,,0,"[suse] Fix flanneld overlay network configuration

Change-Id: Iec98aaee2c72bee81937b9554ddcb0abd880c34c
",git fetch https://review.opendev.org/openstack/magnum refs/changes/36/399436/3 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/drivers/k8s_opensuse_v1/templates/kubemaster.yaml', 'contrib/drivers/k8s_opensuse_v1/templates/kubeminion.yaml', 'contrib/drivers/k8s_opensuse_v1/templates/kubecluster.yaml']",3,5aa8ffbf2be21b8d6ab45d760aa2092da96a9a94,upstream_k8s, type: number - protocol: tcp port_range_min: 30000 port_range_max: 32767 flannel_backend: {get_param: flannel_backend}, type: string flannel_backend: {get_param: flannel_backend},19,9
openstack%2Fkeystoneauth~master~I2b204c9dfac1b6578620048ebbdf2c2b00ab5248,openstack/keystoneauth,master,I2b204c9dfac1b6578620048ebbdf2c2b00ab5248,Fixed multiple target Auth warning in docstring,MERGED,2017-02-08 21:30:42.000000000,2017-02-20 06:48:02.000000000,2017-02-20 06:48:02.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-08 21:30:42.000000000', 'files': ['keystoneauth1/identity/v3/base.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/fe5ded5e80ba237efa2db2c6f7487e460257378b', 'message': ""Fixed multiple target Auth warning in docstring\n\nWhen building keystoneauth docs, the following warning would be\nemitted:\n\ndocstring of\nkeystoneauth1.identity.v3.base.AuthMethod.get_auth_data:None:\nWARNING: more than one target found for cross-reference u'Auth':\nkeystoneauth1.identity.v2.Auth,\nkeystoneauth1.identity.v3.base.Auth,\nkeystoneauth1.identity.v3.Auth\n\nfor the following files:\n\nkeystoneauth/keystoneauth1/identity/v3/base.py:docstring of\nkeystoneauth/keystoneauth1/identity/v3/__init__.py\n\nThis change specifies the correct Auth object in get_auth_data's\ndocstring and the two warnings no longer appear\n\nChange-Id: I2b204c9dfac1b6578620048ebbdf2c2b00ab5248\n""}]",0,431184,fe5ded5e80ba237efa2db2c6f7487e460257378b,7,2,1,21420,,,0,"Fixed multiple target Auth warning in docstring

When building keystoneauth docs, the following warning would be
emitted:

docstring of
keystoneauth1.identity.v3.base.AuthMethod.get_auth_data:None:
WARNING: more than one target found for cross-reference u'Auth':
keystoneauth1.identity.v2.Auth,
keystoneauth1.identity.v3.base.Auth,
keystoneauth1.identity.v3.Auth

for the following files:

keystoneauth/keystoneauth1/identity/v3/base.py:docstring of
keystoneauth/keystoneauth1/identity/v3/__init__.py

This change specifies the correct Auth object in get_auth_data's
docstring and the two warnings no longer appear

Change-Id: I2b204c9dfac1b6578620048ebbdf2c2b00ab5248
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/84/431184/1 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/identity/v3/base.py'],1,fe5ded5e80ba237efa2db2c6f7487e460257378b,doc-fix, :param base.Auth auth: The auth plugin calling the method., :param Auth auth: The auth plugin calling the method.,1,1
openstack%2Fkeystoneauth~master~Ibf2b4d1f742b7ea6bda394da7512b544904055a4,openstack/keystoneauth,master,Ibf2b4d1f742b7ea6bda394da7512b544904055a4,Updated from global requirements,MERGED,2017-02-10 05:50:13.000000000,2017-02-20 06:47:56.000000000,2017-02-20 06:47:56.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-10 05:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/205620b84279ba4ffc11cca83cee8f2c42965af9', 'message': 'Updated from global requirements\n\nChange-Id: Ibf2b4d1f742b7ea6bda394da7512b544904055a4\n'}, {'number': 2, 'created': '2017-02-11 17:43:23.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/207c348d54cd2b19a03de0376bc233af4faa9c4b', 'message': 'Updated from global requirements\n\nChange-Id: Ibf2b4d1f742b7ea6bda394da7512b544904055a4\n'}]",0,431958,207c348d54cd2b19a03de0376bc233af4faa9c4b,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ibf2b4d1f742b7ea6bda394da7512b544904055a4
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/58/431958/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,205620b84279ba4ffc11cca83cee8f2c42965af9,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Fceilometer~master~I7e6f6a131ef1cd300d516e71f41c495cf122ea54,openstack/ceilometer,master,I7e6f6a131ef1cd300d516e71f41c495cf122ea54,add note about batching+gnocchi,MERGED,2017-02-09 22:27:48.000000000,2017-02-20 06:47:00.000000000,2017-02-20 06:47:00.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 8290}]","[{'number': 1, 'created': '2017-02-09 22:27:48.000000000', 'files': ['doc/source/configuration.rst', 'ceilometer/dispatcher/gnocchi.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7f69f5abdabf855530a629b54c1733dcc6334722', 'message': 'add note about batching+gnocchi\n\nnotification agents will bucketise samples into groups and thus\nallow us to batch more efficiently.\n\nChange-Id: I7e6f6a131ef1cd300d516e71f41c495cf122ea54\n'}]",0,431761,7f69f5abdabf855530a629b54c1733dcc6334722,12,3,1,6537,,,0,"add note about batching+gnocchi

notification agents will bucketise samples into groups and thus
allow us to batch more efficiently.

Change-Id: I7e6f6a131ef1cd300d516e71f41c495cf122ea54
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/431761/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/configuration.rst', 'ceilometer/dispatcher/gnocchi.py']",2,7f69f5abdabf855530a629b54c1733dcc6334722,deprecate,, # FIXME(sileht): This method bulk the processing of samples # grouped by resource_id and metric_name but this is not # efficient yet because the data received here doesn't often # contains a lot of different kind of samples # So perhaps the next step will be to pool the received data from # message bus.,3,11
openstack%2Fopenstack-manuals~master~I9b1aa9afa29985f02beac97f078a60359a9a033b,openstack/openstack-manuals,master,I9b1aa9afa29985f02beac97f078a60359a9a033b,Adding release notes,MERGED,2017-02-20 01:32:22.000000000,2017-02-20 06:27:49.000000000,2017-02-20 06:27:49.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-20 01:32:22.000000000', 'files': ['releasenotes/source/ocata.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e28579aeb93a2c5583b2217085dab745e4feb531', 'message': 'Adding release notes\n\nAdded Installation Tutorials, Deployment Guides, and Contributor Guide\nrelease notes.\n\nChange-Id: I9b1aa9afa29985f02beac97f078a60359a9a033b\n'}]",0,435817,e28579aeb93a2c5583b2217085dab745e4feb531,8,5,1,9162,,,0,"Adding release notes

Added Installation Tutorials, Deployment Guides, and Contributor Guide
release notes.

Change-Id: I9b1aa9afa29985f02beac97f078a60359a9a033b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/435817/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/ocata.rst'],1,e28579aeb93a2c5583b2217085dab745e4feb531,InstallGuideRelnotes/loquacity,Contributor Guide ~~~~~~~~~~~~~~~~~ * Added content about building documentation from end-of-life releases. * General bug fixes and updates. Deployment Guides ~~~~~~~~~~~~~~~~~ * Created new section for project-specific Deployment Guides (guides for using automated installation tools) * OpenStack-Ansible Deployment guide created Installation Tutorials ~~~~~~~~~~~~~~~~~~~~~~ * Updated landing page to improve ease of use. * Deleted references to default flavors. * Updated commands to use openstackclient where possible. * General bug fixes and updates. ,,21,0
openstack%2Fkeystoneauth~master~If73df85768866fb93d90ff95479f29f64aabe73f,openstack/keystoneauth,master,If73df85768866fb93d90ff95479f29f64aabe73f,Fix ClientException message property not set properly,MERGED,2016-02-28 03:41:47.000000000,2017-02-20 06:23:06.000000000,2017-02-20 06:23:06.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8866}, {'_account_id': 10046}, {'_account_id': 10873}, {'_account_id': 13055}, {'_account_id': 13478}, {'_account_id': 17860}, {'_account_id': 18338}, {'_account_id': 20466}, {'_account_id': 21420}]","[{'number': 1, 'created': '2016-02-28 03:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/94a393b245869165906d02121978e138f3e71faa', 'message': 'ClientException message does not set properly\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 2, 'created': '2016-02-28 03:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/c131a921e72aae7d3437047769e98377c357711c', 'message': 'ClientException message does not set properly\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 3, 'created': '2016-02-28 19:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/c849327a681b5a032a48f1cd7d6365d3c725090f', 'message': 'ClientException message does not set properly\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 4, 'created': '2016-02-28 19:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/c3483240dea5fd1899526108dbcac0993cf811ef', 'message': 'ClientException message does not set properly\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 5, 'created': '2016-02-28 21:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/60925aabea2be55fe20bc8ac3d647531dc1c6b27', 'message': 'ClientException message does not set properly\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 6, 'created': '2016-02-29 18:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/3f0b06a8681a3c9d1e2b2a42c42cf2afa4a4d138', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 7, 'created': '2016-03-03 15:21:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/0d151983be8401d30d51a1b99d794a1cf00126b8', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 8, 'created': '2016-03-10 01:13:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/a13f83a1c78970e90c20ced27e9c96109aadb047', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 9, 'created': '2016-04-02 20:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/25b9d3d35349b83f3f0e5ce13e5dd4943d31acc8', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 10, 'created': '2016-04-02 20:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/79f7c9ec1b39ec62f54fd479b2bc8a49694413c9', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 11, 'created': '2016-04-15 03:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/3be44f8d3d8ae50b1ad770f9166ecfe787f35a93', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 12, 'created': '2016-04-15 03:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/5e6b3ef758d923fcd5763bc8d64aef1ae0fde9d1', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 13, 'created': '2016-04-17 22:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/0987c2bffc61188b31419dba65476dbc6effe194', 'message': 'Properly set ClientException message\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 14, 'created': '2016-04-19 23:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/d6ee43ffa688f598f7b9e6afc0fc8b26c61c4cb6', 'message': 'Remove ClientException duplicate message property from BaseException\n\nFix an issue where the child ClientException\'s message field overwrites\nthe message set by super().__init__(message).\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 15, 'created': '2016-05-03 05:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/15197ae2a5b8b30ab4b0bc48b71e8a3c87c94ea4', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 16, 'created': '2016-06-07 01:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ced86812490c6c3d2e3a32bff789240f50feda09', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 17, 'created': '2016-06-12 04:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/ea316f27ff65fab0c19418c4e38d3d476e41191b', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 18, 'created': '2016-07-10 12:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/b07bc30598459f214d176d0be50922bc8e080156', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCloses-Bug: #1534363\n'}, {'number': 19, 'created': '2017-01-25 21:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/d610afe6f8a417012b3911836009230aa7b86711', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCo-Authored-By: Gage Hugo <gagehugo@gmail.com>\nCloses-Bug: #1534363\n'}, {'number': 20, 'created': '2017-01-26 04:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/9b410e828a93e81bd7766444cd917288defa13d7', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCo-Authored-By: Gage Hugo <gagehugo@gmail.com>\nCloses-Bug: #1534363\n'}, {'number': 21, 'created': '2017-01-26 12:28:20.000000000', 'files': ['keystoneauth1/exceptions/base.py', 'keystoneauth1/tests/unit/exceptions/test_exceptions.py', 'keystoneauth1/tests/unit/exceptions/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/062dcc9cb29556b82ca7182458fac3038dd64c62', 'message': 'Fix ClientException message property not set properly\n\nTo reproduce:\n\n    >>> from keystoneauth1 import exceptions\n    >>> e = exceptions.ClientException(message=""test"")\n    >>> print(e.message)\n    None\n\nChange-Id: If73df85768866fb93d90ff95479f29f64aabe73f\nCo-Authored-By: Gage Hugo <gagehugo@gmail.com>\nCloses-Bug: #1534363\n'}]",35,285757,062dcc9cb29556b82ca7182458fac3038dd64c62,114,17,21,20466,,,0,"Fix ClientException message property not set properly

To reproduce:

    >>> from keystoneauth1 import exceptions
    >>> e = exceptions.ClientException(message=""test"")
    >>> print(e.message)
    None

Change-Id: If73df85768866fb93d90ff95479f29f64aabe73f
Co-Authored-By: Gage Hugo <gagehugo@gmail.com>
Closes-Bug: #1534363
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/57/285757/9 && git format-patch -1 --stdout FETCH_HEAD,['keystoneauth1/exceptions/base.py'],1,94a393b245869165906d02121978e138f3e71faa,bug/1534363," super(ClientException, self).__init__(message)"," message = None super(Exception, self).__init__(message)",1,2
openstack%2Fkeystone~master~Ibe3650732dab999ed2f07dc6c949f197a0d4a38c,openstack/keystone,master,Ibe3650732dab999ed2f07dc6c949f197a0d4a38c,Updated from global requirements,MERGED,2017-02-10 04:45:26.000000000,2017-02-20 06:22:22.000000000,2017-02-20 06:22:22.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8119}, {'_account_id': 17666}]","[{'number': 1, 'created': '2017-02-10 04:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1cbd22cdb298ff07b27159d816ae6b86900a5d6f', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 2, 'created': '2017-02-10 05:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f4d7d68d16368ad31c3c642a3781abf8b7b88d52', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 3, 'created': '2017-02-10 09:41:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a47ec7a62fed3b5da35da6412ca01fd73e1a906d', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 4, 'created': '2017-02-11 00:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6e7a4c991a5d29e463341ee05f8ca3bea330bd12', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 5, 'created': '2017-02-11 17:43:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/a347fb68df5d670b3de39bec8ab3fb2edceb28d7', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 6, 'created': '2017-02-16 23:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fe1dd9843d116f9b238b5fd90ca36aeb6323c023', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 7, 'created': '2017-02-17 20:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0df6d9676021e4ec5bafffb7ee666f329f0a359f', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}, {'number': 8, 'created': '2017-02-19 21:21:47.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a55f267bb98046dd7edd17156fe2ca289b26cbd2', 'message': 'Updated from global requirements\n\nChange-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c\n'}]",0,431886,a55f267bb98046dd7edd17156fe2ca289b26cbd2,20,4,8,11131,,,0,"Updated from global requirements

Change-Id: Ibe3650732dab999ed2f07dc6c949f197a0d4a38c
",git fetch https://review.opendev.org/openstack/keystone refs/changes/86/431886/7 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1cbd22cdb298ff07b27159d816ae6b86900a5d6f,openstack/requirements,tempest>=14.0.0 # Apache-2.0,tempest>=12.1.0 # Apache-2.0,1,1
openstack%2Fkeystonemiddleware~master~Id74368e2b0b7421c2cc1ad498a008b33df38f39a,openstack/keystonemiddleware,master,Id74368e2b0b7421c2cc1ad498a008b33df38f39a,Updated from global requirements,MERGED,2017-02-10 05:50:15.000000000,2017-02-20 06:19:38.000000000,2017-02-20 06:19:38.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-10 05:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/d647f77b058b3eb2ad59b6ddb0df5196e314910b', 'message': 'Updated from global requirements\n\nChange-Id: Id74368e2b0b7421c2cc1ad498a008b33df38f39a\n'}, {'number': 2, 'created': '2017-02-10 09:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/2b99680708963e70552c30bfe281c22458ff97d9', 'message': 'Updated from global requirements\n\nChange-Id: Id74368e2b0b7421c2cc1ad498a008b33df38f39a\n'}, {'number': 3, 'created': '2017-02-11 17:43:26.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/8221869f4e2e2bd71785eb1f12618fc4348116ff', 'message': 'Updated from global requirements\n\nChange-Id: Id74368e2b0b7421c2cc1ad498a008b33df38f39a\n'}]",0,431959,8221869f4e2e2bd71785eb1f12618fc4348116ff,10,2,3,11131,,,0,"Updated from global requirements

Change-Id: Id74368e2b0b7421c2cc1ad498a008b33df38f39a
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/59/431959/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,d647f77b058b3eb2ad59b6ddb0df5196e314910b,openstack/requirements,"docutils>=0.11 # OSI-Approved Open Source, Public Domainsphinx>=1.5.1 # BSD","docutils!=0.13.1,>=0.11 # OSI-Approved Open Source, Public Domainsphinx!=1.3b1,<1.4,>=1.2.1 # BSD",2,2
openstack%2Fkeystonemiddleware~master~I0c4ef3ecbacc3968344659de47be6b2cb483c074,openstack/keystonemiddleware,master,I0c4ef3ecbacc3968344659de47be6b2cb483c074,Remove unused logging import,MERGED,2017-02-17 03:04:34.000000000,2017-02-20 06:19:28.000000000,2017-02-20 06:19:28.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-17 03:04:34.000000000', 'files': ['keystonemiddleware/auth_token/_auth.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/3ac8cdff3f849479d5c703689474692eb448abad', 'message': 'Remove unused logging import\n\nChange-Id: I0c4ef3ecbacc3968344659de47be6b2cb483c074\n'}]",0,435203,3ac8cdff3f849479d5c703689474692eb448abad,6,2,1,19935,,,0,"Remove unused logging import

Change-Id: I0c4ef3ecbacc3968344659de47be6b2cb483c074
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/03/435203/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/_auth.py'],1,3ac8cdff3f849479d5c703689474692eb448abad,,,from oslo_log import log as logging_LOG = logging.getLogger(__name__) ,0,4
openstack%2Fzun~master~I9cb9ad539c69a1547a20acc78d453027943a5a4d,openstack/zun,master,I9cb9ad539c69a1547a20acc78d453027943a5a4d,Define a ResourceClassField in object,MERGED,2017-02-14 20:38:32.000000000,2017-02-20 06:03:17.000000000,2017-02-20 06:03:17.000000000,"[{'_account_id': 3}, {'_account_id': 12407}, {'_account_id': 16277}]","[{'number': 1, 'created': '2017-02-14 20:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/666cd7f2d72cdf35cbe9c939600907cbe557c697', 'message': 'Define a ResourceClassField in object\n\nThis field defines a list of valid values for resource name.\n\nChange-Id: I9cb9ad539c69a1547a20acc78d453027943a5a4d\n'}, {'number': 2, 'created': '2017-02-20 02:28:51.000000000', 'files': ['zun/tests/unit/db/utils.py', 'zun/objects/resource_class.py', 'zun/tests/unit/objects/test_resource_class.py', 'zun/objects/fields.py', 'zun/tests/unit/objects/test_fields.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/51409e39f7cd3243ca4e287295f10011141dbe94', 'message': 'Define a ResourceClassField in object\n\nThis field defines a list of valid values for resource name.\n\nChange-Id: I9cb9ad539c69a1547a20acc78d453027943a5a4d\n'}]",0,433920,51409e39f7cd3243ca4e287295f10011141dbe94,9,3,2,11536,,,0,"Define a ResourceClassField in object

This field defines a list of valid values for resource name.

Change-Id: I9cb9ad539c69a1547a20acc78d453027943a5a4d
",git fetch https://review.opendev.org/openstack/zun refs/changes/20/433920/1 && git format-patch -1 --stdout FETCH_HEAD,"['zun/tests/unit/db/utils.py', 'zun/objects/resource_class.py', 'zun/tests/unit/objects/test_resource_class.py', 'zun/objects/fields.py', 'zun/tests/unit/objects/test_fields.py']",5,666cd7f2d72cdf35cbe9c939600907cbe557c697,bp/expose-host-capabilities," class TestResourceClass(test_fields.TestField): def setUp(self): super(TestResourceClass, self).setUp() self.field = fields.ResourceClass() self.coerce_good_values = [ ('VCPU', 'VCPU'), ('MEMORY_MB', 'MEMORY_MB'), ('DISK_GB', 'DISK_GB'), ('PCI_DEVICE', 'PCI_DEVICE'), ('SRIOV_NET_VF', 'SRIOV_NET_VF'), ('NUMA_SOCKET', 'NUMA_SOCKET'), ('NUMA_CORE', 'NUMA_CORE'), ('NUMA_THREAD', 'NUMA_THREAD'), ('NUMA_MEMORY_MB', 'NUMA_MEMORY_MB'), ('IPV4_ADDRESS', 'IPV4_ADDRESS'), ] self.coerce_bad_values = ['bad_value'] self.to_primitive_values = self.coerce_good_values[0:1] self.from_primitive_values = self.coerce_good_values[0:1] def test_stringify(self): self.assertEqual(""'VCPU'"", self.field.stringify('VCPU')) def test_stringify_invalid(self): self.assertRaises(ValueError, self.field.stringify, 'bad_value')",,54,5
openstack%2Fdragonflow~master~I6a4396d2315e45b35f69f24fdfdf3f365552d7b4,openstack/dragonflow,master,I6a4396d2315e45b35f69f24fdfdf3f365552d7b4,redis: Raise DbKeyNotFound when get_key fails,MERGED,2017-02-16 10:05:23.000000000,2017-02-20 05:18:29.000000000,2017-02-20 05:18:29.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20153}, {'_account_id': 20229}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-16 10:05:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/39a22ef58c12bc523ebd5aac896726975e0af3a1', 'message': 'redis: Raise DbKeyNotFound when get_key fails\n\nDragonflow DB API states an exception should be raised in case a key is\nnot found, but Redis driver was return None value in those cases.\n\nChange-Id: I6a4396d2315e45b35f69f24fdfdf3f365552d7b4\n'}, {'number': 2, 'created': '2017-02-16 10:25:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8867f90873b9b7d0398735ee1db93796dc9aa758', 'message': 'redis: Raise DbKeyNotFound when get_key fails\n\nDragonflow DB API states an exception should be raised in case a key is\nnot found, but Redis driver was return None value in those cases.\n\nChange-Id: I6a4396d2315e45b35f69f24fdfdf3f365552d7b4\n'}, {'number': 3, 'created': '2017-02-16 12:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a0593b066191d50308b062b3f21a685c738c196e', 'message': 'redis: Raise DbKeyNotFound when get_key fails\n\nDragonflow DB API states an exception should be raised in case a key is\nnot found, but Redis driver was return None value in those cases.\n\nChange-Id: I6a4396d2315e45b35f69f24fdfdf3f365552d7b4\n'}, {'number': 4, 'created': '2017-02-19 20:21:59.000000000', 'files': ['dragonflow/tests/unit/test_redis_db.py', 'dragonflow/db/drivers/redis_db_driver.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3a3a586ff16b7332284557152433f411a57ba60a', 'message': 'redis: Raise DbKeyNotFound when get_key fails\n\nDragonflow DB API states an exception should be raised in case a key is\nnot found, but Redis driver was return None value in those cases.\n\nChange-Id: I6a4396d2315e45b35f69f24fdfdf3f365552d7b4\n'}]",0,434794,3a3a586ff16b7332284557152433f411a57ba60a,18,6,4,23766,,,0,"redis: Raise DbKeyNotFound when get_key fails

Dragonflow DB API states an exception should be raised in case a key is
not found, but Redis driver was return None value in those cases.

Change-Id: I6a4396d2315e45b35f69f24fdfdf3f365552d7b4
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/94/434794/4 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/drivers/redis_db_driver.py'],1,39a22ef58c12bc523ebd5aac896726975e0af3a1,redis_get_key,"from dragonflow.common import exceptions as df_exceptions def _find_topicless_key(self, table, key): local_key = self._uuid_to_key(table, key, '*') self._sync_master_list() for client in self.clients.values(): local_keys = client.keys(local_key) if len(local_keys) == 1: return local_keys[0] def get_key(self, table, key, topic=None): if topic is not None: else: local_key = self._find_topicless_key(table, key) if local_key is None: raise df_exceptions.DBKeyNotFound(key=key) try: res = self._execute_cmd(""GET"", local_key) if res is not None: return res except Exception: LOG.exception(_LE(""exception when get_key: %(key)s""), {'key': local_key}) raise df_exceptions.DBKeyNotFound(key=key)"," def get_key(self, table, key, topic=None): if not topic: local_key = self._uuid_to_key(table, key, '*') self._sync_master_list() try: for host, client in self.clients.items(): local_keys = client.keys(local_key) if len(local_keys) == 1: return self._execute_cmd(""GET"", local_keys[0]) except Exception: LOG.exception(_LE(""exception when get_key: %(key)s""), {'key': local_key}) else: try: # return nil if not found return self._execute_cmd(""GET"", local_key) except Exception: LOG.exception(_LE(""exception when get_key: %(key)s""), {'key': local_key})",24,19
openstack%2Fdragonflow~stable%2Focata~I55e0d6876f32aed886e7fa51894a265ebd364e20,openstack/dragonflow,stable/ocata,I55e0d6876f32aed886e7fa51894a265ebd364e20,Use neutron stable/ocata branch in ocata test,MERGED,2017-02-18 12:43:44.000000000,2017-02-20 05:10:28.000000000,2017-02-20 05:10:28.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 20229}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-18 12:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/61a5263733fc70ac43cff4515f5e5e130f85e59c', 'message': '[Test] Use neutron stable/ocata branch ocata test\n\nChange-Id: I55e0d6876f32aed886e7fa51894a265ebd364e20\n'}, {'number': 2, 'created': '2017-02-18 14:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/94b41ed2d60ccb5a47f04e45eee9c1c5d0610cce', 'message': '[Test] Use neutron stable/ocata branch in ocata test\n\nSince df uses neutron as a lib, the version should match.\n\nChange-Id: I55e0d6876f32aed886e7fa51894a265ebd364e20\n'}, {'number': 3, 'created': '2017-02-18 14:30:32.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b26c457d52590e060a99d0c2440628d7345cd375', 'message': 'Use neutron stable/ocata branch in ocata test\n\nSince df uses neutron as a lib, the version should match.\n\nChange-Id: I55e0d6876f32aed886e7fa51894a265ebd364e20\n'}]",0,435702,b26c457d52590e060a99d0c2440628d7345cd375,11,4,3,11159,,,0,"Use neutron stable/ocata branch in ocata test

Since df uses neutron as a lib, the version should match.

Change-Id: I55e0d6876f32aed886e7fa51894a265ebd364e20
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/02/435702/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,61a5263733fc70ac43cff4515f5e5e130f85e59c,,BRANCH_NAME=stable/ocata,BRANCH_NAME=master,1,1
openstack%2Fopenstack-manuals~master~Ic406b4585a75b60574aace336ae8a871d5a0bcd0,openstack/openstack-manuals,master,Ic406b4585a75b60574aace336ae8a871d5a0bcd0,Remove content of verbose config option,MERGED,2017-02-20 03:10:36.000000000,2017-02-20 04:39:34.000000000,2017-02-20 04:39:34.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-20 03:10:36.000000000', 'files': ['doc/admin-guide/source/ts-cinder-config.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5511b48baff43e0d448cc513fc3b70f219f5d837', 'message': 'Remove content of verbose config option\n\nverbose had been deprecated and set True by default a year ago[1]. Now\nremove config option verbose without using for a long time.\n[1] https://review.openstack.org/#/c/206437/\n\nChange-Id: Ic406b4585a75b60574aace336ae8a871d5a0bcd0\n'}]",0,435833,5511b48baff43e0d448cc513fc3b70f219f5d837,7,3,1,22752,,,0,"Remove content of verbose config option

verbose had been deprecated and set True by default a year ago[1]. Now
remove config option verbose without using for a long time.
[1] https://review.openstack.org/#/c/206437/

Change-Id: Ic406b4585a75b60574aace336ae8a871d5a0bcd0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/33/435833/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/ts-cinder-config.rst'],1,5511b48baff43e0d448cc513fc3b70f219f5d837,lhx/log,, # Print more verbose output (set logging level to INFO instead # of default WARNING level). (boolean value) # verbose=false ,0,4
openstack%2Fopenstack-manuals~master~I26faeca78159d258f904c0e7ee8e04b822e7a59c,openstack/openstack-manuals,master,I26faeca78159d258f904c0e7ee8e04b822e7a59c,Fix case inconsistency in Neutron on Ubuntu installation,MERGED,2017-02-17 16:46:59.000000000,2017-02-20 04:36:48.000000000,2017-02-20 04:36:48.000000000,"[{'_account_id': 3}, {'_account_id': 6804}, {'_account_id': 9162}, {'_account_id': 10607}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-02-17 16:46:59.000000000', 'files': ['doc/install-guide/source/neutron-controller-install-option1.rst', 'doc/install-guide/source/neutron-compute-install-option2.rst', 'doc/install-guide/source/neutron-controller-install.rst', 'doc/install-guide/source/neutron-controller-install-option2.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/55533225c1f7acffb3b34eede2deb8026c2b285a', 'message': 'Fix case inconsistency in Neutron on Ubuntu installation\n\nMatch case in code block to case in config files\n\nChange-Id: I26faeca78159d258f904c0e7ee8e04b822e7a59c\nCloses-Bug: #1665675\n'}]",0,435524,55533225c1f7acffb3b34eede2deb8026c2b285a,10,5,1,15993,,,0,"Fix case inconsistency in Neutron on Ubuntu installation

Match case in code block to case in config files

Change-Id: I26faeca78159d258f904c0e7ee8e04b822e7a59c
Closes-Bug: #1665675
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/435524/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/neutron-compute-install-option2.rst', 'doc/install-guide/source/neutron-controller-install-option1.rst', 'doc/install-guide/source/neutron-controller-install.rst', 'doc/install-guide/source/neutron-controller-install-option2.rst']",4,55533225c1f7acffb3b34eede2deb8026c2b285a,bug/1665675, allow_overlapping_ips = true notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true enable_ipset = true enable_vxlan = true l2_population = true enable_security_group = true enable_isolated_metadata = true, allow_overlapping_ips = True notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True enable_ipset = True enable_vxlan = True l2_population = True enable_security_group = True enable_isolated_metadata = True,13,13
openstack%2Fopenstack-manuals~master~I7eedc9e11bde9c94041a110bb1227b810969070a,openstack/openstack-manuals,master,I7eedc9e11bde9c94041a110bb1227b810969070a,[User Guide] Update links to Ocata,MERGED,2017-02-14 23:51:50.000000000,2017-02-20 04:32:24.000000000,2017-02-20 04:32:24.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-14 23:51:50.000000000', 'files': ['doc/user-guide/source/cli-stop-and-start-an-instance.rst', 'doc/user-guide/source/index.rst', 'doc/user-guide/source/cli-reboot-an-instance.rst', 'doc/user-guide/source/cli-change-the-size-of-your-server.rst', 'doc/user-guide/source/cli-swift-static-website.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d512406149d0e874a3e3c4606cca6103af939d5d', 'message': '[User Guide] Update links to Ocata\n\nChange-Id: I7eedc9e11bde9c94041a110bb1227b810969070a\n'}]",0,433984,d512406149d0e874a3e3c4606cca6103af939d5d,10,5,1,12686,,,0,"[User Guide] Update links to Ocata

Change-Id: I7eedc9e11bde9c94041a110bb1227b810969070a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/84/433984/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/source/cli-stop-and-start-an-instance.rst', 'doc/user-guide/source/index.rst', 'doc/user-guide/source/cli-reboot-an-instance.rst', 'doc/user-guide/source/cli-change-the-size-of-your-server.rst', 'doc/user-guide/source/cli-swift-static-website.rst']",5,d512406149d0e874a3e3c4606cca6103af939d5d,update-UG-links,See the Cloud Administrator Guide for an example of the `static web configuration syntax <https://docs.openstack.org/ocata/config-reference/object-storage/features.html#static-web-sites>`_. See the Cloud Administrator Guide for a complete example of the `/etc/swift/proxy-server.conf file <https://docs.openstack.org/ocata/config-reference/object-storage/proxy-server.html#sample-proxy-server-configuration-file>`_,See the Cloud Administrator Guide for an example of the `static web configuration syntax <https://docs.openstack.org/newton/config-reference/object-storage/features.html#static-web-sites>`_. See the Cloud Administrator Guide for a complete example of the `/etc/swift/proxy-server.conf file <https://docs.openstack.org/newton/config-reference/object-storage/proxy-server.html#sample-proxy-server-configuration-file>`_,6,7
openstack%2Fopenstack-manuals~master~I9a29f392eb15bc87cd37f9b13f2a82d853d96847,openstack/openstack-manuals,master,I9a29f392eb15bc87cd37f9b13f2a82d853d96847,[Newtworking Guide] Update links to Ocata,MERGED,2017-02-15 00:07:07.000000000,2017-02-20 04:31:14.000000000,2017-02-20 04:31:14.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-15 00:07:07.000000000', 'files': ['doc/networking-guide/source/fwaas.rst', 'doc/networking-guide/source/index.rst', 'doc/networking-guide/source/config.rst', 'doc/networking-guide/source/deploy-lb-provider.rst', 'doc/networking-guide/source/deploy-ovs-provider.rst', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/config-ml2.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c6ee4dc4761a611ba160ca1868d8b2fa67aaf1f9', 'message': '[Newtworking Guide] Update links to Ocata\n\nChange-Id: I9a29f392eb15bc87cd37f9b13f2a82d853d96847\n'}]",0,433989,c6ee4dc4761a611ba160ca1868d8b2fa67aaf1f9,10,5,1,12686,,,0,"[Newtworking Guide] Update links to Ocata

Change-Id: I9a29f392eb15bc87cd37f9b13f2a82d853d96847
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/89/433989/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/networking-guide/source/fwaas.rst', 'doc/networking-guide/source/index.rst', 'doc/networking-guide/source/config.rst', 'doc/networking-guide/source/deploy-lb-provider.rst', 'doc/networking-guide/source/deploy-ovs-provider.rst', 'doc/networking-guide/source/deploy.rst', 'doc/networking-guide/source/config-ml2.rst']",7,c6ee4dc4761a611ba160ca1868d8b2fa67aaf1f9,update-net-links,`Networking configuration options <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-plug-in-configuration-options>`__ `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-flat-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vlan-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vlan-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-gre-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vxlan-type-configuration-options>`__.`Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-plug-in-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-sr-iov-mechanism-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-l2-population-mechanism-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#open-vswitch-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#linux-bridge-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#sr-iov-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-macvtap-mechanism-configuration-options>`__.`Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#l3-agent>`__.`Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#dhcp-agent>`__.`Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#metadata-agent>`__.`Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#metering-agent>`__. `Configuration Reference <https://docs.openstack.org/ocata/config-reference/networking/networking_options_reference.html#security-groups>`__.,`Networking configuration options <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-plug-in-configuration-options>`__ `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-flat-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vlan-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vlan-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-gre-type-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-vxlan-type-configuration-options>`__.`Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-plug-in-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-sr-iov-mechanism-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-l2-population-mechanism-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#open-vswitch-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#linux-bridge-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#sr-iov-agent-configuration-options>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#modular-layer-2-ml2-macvtap-mechanism-configuration-options>`__.`Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#l3-agent>`__.`Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#dhcp-agent>`__.`Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#metadata-agent>`__.`Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#metering-agent>`__. `Configuration Reference <https://docs.openstack.org/newton/config-reference/networking/networking_options_reference.html#security-groups>`__.,26,26
openstack%2Fopenstack-manuals~master~I877488ab816a077101c43eb5f01c0dbaf08393d1,openstack/openstack-manuals,master,I877488ab816a077101c43eb5f01c0dbaf08393d1,[admin-guide] Fix the incorrect output format,MERGED,2017-02-18 10:10:02.000000000,2017-02-20 04:31:08.000000000,2017-02-20 04:31:08.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10705}, {'_account_id': 19298}, {'_account_id': 23205}]","[{'number': 1, 'created': '2017-02-18 10:10:02.000000000', 'files': ['doc/admin-guide/source/compute-live-migration-usage.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3b5f875798af30eb5cb5570a3677f921b467af6f', 'message': '[admin-guide] Fix the incorrect output format\n\nChange-Id: I877488ab816a077101c43eb5f01c0dbaf08393d1\nCloses-Bug: #1665867\n'}]",0,435688,3b5f875798af30eb5cb5570a3677f921b467af6f,9,5,1,19779,,,0,"[admin-guide] Fix the incorrect output format

Change-Id: I877488ab816a077101c43eb5f01c0dbaf08393d1
Closes-Bug: #1665867
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/88/435688/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/compute-live-migration-usage.rst'],1,3b5f875798af30eb5cb5570a3677f921b467af6f,bug/1665867, +--------------------------------------+------+--------+-----------------+------------+ | ID | Name | Status | Networks | Image Name | +--------------------------------------+------+--------+-----------------+------------+ | d1df1b5a-70c4-4fed-98b7-423362f2c47c | vm1 | ACTIVE | private=a.b.c.d | ... | +--------------------------------------+------+--------+-----------------+------------+ | d693db9e-a7cf-45ef-a7c9-b3ecb5f22645 | vm2 | ACTIVE | private=e.f.g.h | ... | +--------------------------------------+------+--------+-----------------+------------+ +----------------------+--------------------------------------+ | Field | Value | +----------------------+--------------------------------------+ | ... | ... | | OS-EXT-SRV-ATTR:host | HostB | | ... | ... | | addresses | a.b.c.d | | flavor | m1.tiny | | id | d1df1b5a-70c4-4fed-98b7-423362f2c47c | | name | vm1 | | status | ACTIVE | | ... | ... | +----------------------+--------------------------------------+ .. code-block:: console $ openstack compute service list +----+------------------+-------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+------------------+-------+----------+---------+-------+----------------------------+ | 3 | nova-conductor | HostA | internal | enabled | up | 2017-02-18T09:42:29.000000 | | 4 | nova-scheduler | HostA | internal | enabled | up | 2017-02-18T09:42:26.000000 | | 5 | nova-consoleauth | HostA | internal | enabled | up | 2017-02-18T09:42:29.000000 | | 6 | nova-compute | HostB | nova | enabled | up | 2017-02-18T09:42:29.000000 | | 7 | nova-compute | HostC | nova | enabled | up | 2017-02-18T09:42:29.000000 | +----+------------------+-------+----------+---------+-------+----------------------------+ +-------+------------+-----+-----------+---------+ | Host | Project | CPU | Memory MB | Disk GB | +-------+------------+-----+-----------+---------+ | HostC | (total) | 16 | 32232 | 878 | | HostC | (used_now) | 22 | 21284 | 422 | | HostC | (used_max) | 22 | 21284 | 422 | | HostC | p1 | 22 | 21284 | 422 | | HostC | p2 | 22 | 21284 | 422 | +-------+------------+-----+-----------+---------+, .. list-table:: :header-rows: 1 :widths: 46 12 13 22 * - ID - Name - Status - Networks * - d1df1b5a-70c4-4fed-98b7-423362f2c47c - vm1 - ACTIVE - private=a.b.c.d * - d693db9e-a7cf-45ef-a7c9-b3ecb5f22645 - vm2 - ACTIVE - private=e.f.g.h .. list-table:: :widths: 30 45 :header-rows: 1 * - Property - Value * - ... OS-EXT-SRV-ATTR:host ... flavor id name private network status ... - ... HostB ... m1.tiny d1df1b5a-70c4-4fed-98b7-423362f2c47c vm1 a.b.c.d ACTIVE ... .. list-table:: **openstack compute service list** :widths: 20 9 12 11 9 30 :header-rows: 1 * - Binary - Host - Zone - Status - State - Updated_at * - nova-consoleauth - HostA - internal - enabled - up - 2014-03-25T10:33:25.000000 * - nova-scheduler - HostA - internal - enabled - up - 2014-03-25T10:33:25.000000 * - nova-conductor - HostA - internal - enabled - up - 2014-03-25T10:33:27.000000 * - nova-compute - HostB - nova - enabled - up - 2014-03-25T10:33:31.000000 * - nova-compute - HostC - nova - enabled - up - 2014-03-25T10:33:31.000000 * - nova-cert - HostA - internal - enabled - up - 2014-03-25T10:33:31.000000 .. list-table:: :header-rows: 1 :widths: 14 14 7 15 12 * - HOST - PROJECT - cpu - memory_mb - disk_gb * - HostC - (total) - 16 - 32232 - 878 * - HostC - (used_now) - 22 - 21284 - 442 * - HostC - (used_max) - 22 - 21284 - 422 * - HostC - p1 - 22 - 21284 - 422 * - HostC - p2 - 22 - 21284 - 422,41,138
openstack%2Fopenstack-manuals~master~Iae5171ad0f05e9e46cc76928c9f2d93cc9d37a38,openstack/openstack-manuals,master,Iae5171ad0f05e9e46cc76928c9f2d93cc9d37a38,[Config Ref] Update links for Ocata,MERGED,2017-02-15 00:17:43.000000000,2017-02-20 04:31:01.000000000,2017-02-20 04:31:01.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-15 00:17:43.000000000', 'files': ['doc/config-reference/source/identity.rst', 'doc/config-reference/source/orchestration.rst', 'doc/config-reference/source/identity/federated-identity.rst', 'doc/config-reference/source/telemetry.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/72fccfc75182c8772e3dcbdfc8d666c8b850d5ce', 'message': '[Config Ref] Update links for Ocata\n\nChange-Id: Iae5171ad0f05e9e46cc76928c9f2d93cc9d37a38\n'}]",0,433993,72fccfc75182c8772e3dcbdfc8d666c8b850d5ce,10,5,1,12686,,,0,"[Config Ref] Update links for Ocata

Change-Id: Iae5171ad0f05e9e46cc76928c9f2d93cc9d37a38
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/93/433993/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/identity.rst', 'doc/config-reference/source/orchestration.rst', 'doc/config-reference/source/identity/federated-identity.rst', 'doc/config-reference/source/telemetry.rst']",4,72fccfc75182c8772e3dcbdfc8d666c8b850d5ce,config-links,"To install Telemetry, see the `Ocata Installation Tutorials and Guides <https://docs.openstack.org/project-install-guide/ocata/>`_ for your distribution.","To install Telemetry, see the `Newton Installation Tutorials and Guides <https://docs.openstack.org/project-install-guide/newton/>`_ for your distribution.",11,8
openstack%2Fopenstack-manuals~master~I8240c41a5a8b378d57370af8ef61f04fc8295181,openstack/openstack-manuals,master,I8240c41a5a8b378d57370af8ef61f04fc8295181,[Ops Guide] Update links for Ocata,MERGED,2017-02-15 00:25:03.000000000,2017-02-20 04:28:41.000000000,2017-02-20 04:28:41.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-15 00:25:03.000000000', 'files': ['doc/ops-guide/source/preface.rst', 'doc/ops-guide/source/arch-example-thoughts.rst', 'doc/ops-guide/source/arch-compute-nodes.rst', 'doc/ops-guide/source/arch-example-nova-network.rst', 'doc/ops-guide/source/ops-advanced-configuration.rst', 'doc/ops-guide/source/ops-upgrades.rst', 'doc/ops-guide/source/app-resources.rst', 'doc/ops-guide/source/ops-customize-compute.rst', 'doc/ops-guide/source/operations.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a22ff99d23bee7ae5d6f8fc0402284915e2e40e2', 'message': '[Ops Guide] Update links for Ocata\n\nChange-Id: I8240c41a5a8b378d57370af8ef61f04fc8295181\n'}]",0,433995,a22ff99d23bee7ae5d6f8fc0402284915e2e40e2,10,5,1,12686,,,0,"[Ops Guide] Update links for Ocata

Change-Id: I8240c41a5a8b378d57370af8ef61f04fc8295181
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/95/433995/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ops-guide/source/preface.rst', 'doc/ops-guide/source/arch-compute-nodes.rst', 'doc/ops-guide/source/arch-example-thoughts.rst', 'doc/ops-guide/source/arch-example-nova-network.rst', 'doc/ops-guide/source/ops-advanced-configuration.rst', 'doc/ops-guide/source/app-resources.rst', 'doc/ops-guide/source/ops-upgrades.rst', 'doc/ops-guide/source/ops-customize-compute.rst', 'doc/ops-guide/source/operations.rst']",9,a22ff99d23bee7ae5d6f8fc0402284915e2e40e2,ops-links,"<https://docs.openstack.org/project-install-guide/ocata/>`_, which contains a","<https://docs.openstack.org/project-install-guide/newton/>`_, which contains a",20,20
openstack%2Fopenstack-manuals~master~Ic8dc1e142aa43a048d7779696401bb2c4ebb889c,openstack/openstack-manuals,master,Ic8dc1e142aa43a048d7779696401bb2c4ebb889c,Unity driver: Add IO ports option detail,MERGED,2017-02-17 06:35:04.000000000,2017-02-20 04:28:34.000000000,2017-02-20 04:28:34.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10897}, {'_account_id': 18742}]","[{'number': 1, 'created': '2017-02-17 06:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/36dc671bb252c3f578a796bcaf137f52fa3f56af', 'message': 'Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 2, 'created': '2017-02-17 06:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ee7dd635818b13cc711b411068c3b038f54d60cc', 'message': 'Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 3, 'created': '2017-02-17 06:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/588c76bd83df483b3fbd064e9b5424ce79ae6c5f', 'message': 'Unity driver: Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 4, 'created': '2017-02-17 08:26:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/23a25cdf372c5269dadc1560952bde612c55d93d', 'message': 'Unity driver: Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 5, 'created': '2017-02-17 09:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ce18d4f8ead029abdad4495a49c82a154cccb1d4', 'message': 'Unity driver: Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nCloses-Bug: #1657649\nCloses-Bug: #1659126\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 6, 'created': '2017-02-17 10:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cac87748a5c68f3b6e1598c38f8c8febaf661866', 'message': 'Unity driver: Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nCloses-Bug: #1657649\nCloses-Bug: #1659126\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}, {'number': 7, 'created': '2017-02-20 02:32:29.000000000', 'files': ['doc/config-reference/source/shared-file-systems/drivers/emc-vnx-driver.rst', 'doc/config-reference/source/block-storage/drivers/dell-emc-unity-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ff64fda83d1ecad51b7a1cf1a6660ea50207dff3', 'message': 'Unity driver: Add IO ports option detail\n\n1. Add description of the IO ports ports.\n2. Add description of back-up using snapshot.\n3. Fix typos.\n\nCloses-Bug: #1657649\nCloses-Bug: #1659126\nCloses-Bug: #1655299\nChange-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c\n'}]",5,435268,ff64fda83d1ecad51b7a1cf1a6660ea50207dff3,24,6,7,18742,,,0,"Unity driver: Add IO ports option detail

1. Add description of the IO ports ports.
2. Add description of back-up using snapshot.
3. Fix typos.

Closes-Bug: #1657649
Closes-Bug: #1659126
Closes-Bug: #1655299
Change-Id: Ic8dc1e142aa43a048d7779696401bb2c4ebb889c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/68/435268/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/block-storage/drivers/dell-emc-unity-driver.rst', 'tox.ini']",2,36dc671bb252c3f578a796bcaf137f52fa3f56af,bug/1657649, REQUESTS_CA_BUNDLE=/etc/ssl/certs/pip_cacert.pem,,46,1
openstack%2Fopenstack-manuals~master~I4b84defa4a80ab22bd6d3f99e4ff6c117ca12bdd,openstack/openstack-manuals,master,I4b84defa4a80ab22bd6d3f99e4ff6c117ca12bdd,[HA Guide] Update links for Ocata,MERGED,2017-02-15 00:30:29.000000000,2017-02-20 04:28:28.000000000,2017-02-20 04:28:28.000000000,"[{'_account_id': 3}, {'_account_id': 9162}, {'_account_id': 10497}, {'_account_id': 12686}, {'_account_id': 14947}]","[{'number': 1, 'created': '2017-02-15 00:30:29.000000000', 'files': ['doc/ha-guide/source/environment-memcached.rst', 'doc/ha-guide/source/environment-hardware.rst', 'doc/ha-guide/source/environment-ntp.rst', 'doc/ha-guide/source/storage-ha-image.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/source/index.rst', 'doc/ha-guide/source/environment-operatingsystem.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst', 'doc/ha-guide/source/networking-ha.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/36790753f9b996399296b67bf9724d3b2f912296', 'message': '[HA Guide] Update links for Ocata\n\nChange-Id: I4b84defa4a80ab22bd6d3f99e4ff6c117ca12bdd\n'}]",0,433999,36790753f9b996399296b67bf9724d3b2f912296,10,5,1,12686,,,0,"[HA Guide] Update links for Ocata

Change-Id: I4b84defa4a80ab22bd6d3f99e4ff6c117ca12bdd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/99/433999/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/environment-memcached.rst', 'doc/ha-guide/source/environment-hardware.rst', 'doc/ha-guide/source/environment-ntp.rst', 'doc/ha-guide/source/storage-ha-image.rst', 'doc/ha-guide/source/compute-node-ha.rst', 'doc/ha-guide/source/index.rst', 'doc/ha-guide/source/environment-operatingsystem.rst', 'doc/ha-guide/source/controller-ha-telemetry.rst', 'doc/ha-guide/source/networking-ha.rst']",9,36790753f9b996399296b67bf9724d3b2f912296,ha-links,"`Install Tutorials and Guides <https://docs.openstack.org/project-install-guide/ocata>`_,","`Install Tutorials and Guides <https://docs.openstack.org/project-install-guide/newton>`_,",14,14
openstack%2Fopenstack-manuals~master~Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff,openstack/openstack-manuals,master,Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff,VMAX driver - remove generic volume group from documentation,MERGED,2017-02-16 17:12:24.000000000,2017-02-20 04:17:44.000000000,2017-02-20 04:17:44.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 10705}, {'_account_id': 12670}]","[{'number': 1, 'created': '2017-02-16 17:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d28f65b09aeba8afb95c7f5ad6f7619552078fa6', 'message': 'VMAX driver - remove generic volume group from documentation\n\nGeneric Volume group did not make the Ocata feature freeze so\nis bound for Pike instead. Removing this section. Other minor\namendments also.\n\nChange-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff\nCloses-Bug: #1665374\n'}, {'number': 2, 'created': '2017-02-17 07:18:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0c4b44dfef276c368a8821be9dd341ffd32d4666', 'message': 'VMAX driver - remove generic volume group from documentation\n\nGeneric Volume group did not make the Ocata feature freeze so\nis bound for Pike instead. Removing this section. Other minor\namendments also.\n\nChange-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff\nCloses-Bug: #1665374\n'}, {'number': 3, 'created': '2017-02-17 07:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fe96d3c39b5919af87d6fc6eb3b8faf4ec3ae897', 'message': 'VMAX driver - remove generic volume group from documentation\n\nGeneric Volume group did not make the Ocata feature freeze so\nis bound for Pike instead. Removing this section. Other minor\namendments also.\n\nChange-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff\nCloses-Bug: #1665374\n'}, {'number': 4, 'created': '2017-02-17 17:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/be2f376873eb7de5f3d56cbf20a711f7e15d779f', 'message': 'VMAX driver - remove generic volume group from documentation\n\nGeneric Volume group did not make the Ocata feature freeze so\nis bound for Pike instead. Removing this section. Other minor\namendments also.\n\nChange-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff\nCloses-Bug: #1665374\n'}, {'number': 5, 'created': '2017-02-17 18:06:51.000000000', 'files': ['doc/config-reference/source/block-storage/drivers/emc-vmax-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ee562eeaf7bf633f822743ff15fcf6d985b41b00', 'message': 'VMAX driver - remove generic volume group from documentation\n\nGeneric Volume group did not make the Ocata feature freeze so\nis bound for Pike instead. Removing this section. Other minor\namendments also.\n\nChange-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff\nCloses-Bug: #1665374\n'}]",6,435027,ee562eeaf7bf633f822743ff15fcf6d985b41b00,17,5,5,12670,,,0,"VMAX driver - remove generic volume group from documentation

Generic Volume group did not make the Ocata feature freeze so
is bound for Pike instead. Removing this section. Other minor
amendments also.

Change-Id: Ibce0dab7db4af4ba3183c8b3fdd63cfab1a120ff
Closes-Bug: #1665374
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/435027/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/block-storage/drivers/emc-vmax-driver.rst'],1,d28f65b09aeba8afb95c7f5ad6f7619552078fa6,bug/1665374,".. note:: A potential issue can exist with the python-pywbem dependency package, especially M2crypto. To troubleshot and resolve these types of issues, follow these steps - On Ubuntu: .. code-block:: console # apt-get remove --purge -y python-m2crypto # pip uninstall pywbem # apt-get install python-pywbem - On openSUSE: .. code-block:: console # zypper remove --clean-deps python-m2crypto # pip uninstall pywbem # zypper install python-pywbem - On Red Hat Enterprise Linux, CentOS, and Fedora: .. code-block:: console # yum remove python-m2crypto # sudo pip uninstall pywbem # yum install pywbem Intervals and Retries --------------------- By default, ``Intervals`` and ``Retries`` are ``10`` seconds and ``60`` retries respectively. These determine how long (``Intervals``) and how many times (``Retries``) a user is willing to wait for a single SMIS call, e.g. ``10*60=300seconds``. Depending on usage, these may need to be overriden. If performance is a factor, then the ``Intervals`` should be decreased. If multiple concurrent provisioning requests are issued then ``Retries`` should be increased so calls will not timeout prematurely. In the example below, the driver checks every 5 seconds for the status of the job. It will continue checking for 120 retries before it times out. Add the following lines to the XML file: VMAX All Flash and Hybrid .. code-block:: xml <?xml version=""1.0"" encoding=""UTF-8"" ?> <EMC> <EcomServerIp>1.1.1.1</EcomServerIp> <EcomServerPort>00</EcomServerPort> <EcomUserName>user1</EcomUserName> <EcomPassword>password1</EcomPassword> <PortGroups> <PortGroup>OS-PORTGROUP1-PG</PortGroup> <PortGroup>OS-PORTGROUP2-PG</PortGroup> </PortGroups> <Array>111111111111</Array> <Pool>SRP_1</Pool> <Intervals>5</Intervals> <Retries>120</Retries> </EMC> Consistency Group which is an SRDF feature. The Storage Group is not associated with any Service Level.* Create a Consistency group from source: .. code-block:: console $ cinder consisgroup-create-from-src --cgsnapshot 618d962d-2917-4cca-a3ee-9699373e6625 $ openstack volume type set --property volume_backend_name=FC_backend VMAX_FC_DIAMOND_OLTP $ openstack volume type set --property pool_name=Diamond+OLTP+SRP_1+111111111111"," Consistency Group which is an SRDF construct. The Storage Group is not associated with any FAST policy.* Create a Consistency group from source (the source can only be a CG snapshot):Generic volume group support ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Generic volume group operations are performed through the CLI using API version 3.1x of the cinder API. Generic volume groups are multi-purpose groups which can be used for various features. The only feature supported currently by the ``VMAX`` plugin is the ability to take group snapshots, which can either be consistent or not based on the group specs. Generic volume groups will eventually replace the consistency groups in a future release. .. note:: Generic volume groups are supported for ``VMAX3`` arrays only. The consistent group snapshot should not be confused with the ``VMAX`` consistency which primarily applies to SRDF. Operations ---------- #. Create a group type: .. code-block:: console cinder --os-volume-api-version 3.11 group-type-create [--description DESCRIPTION] [--is-public IS_PUBLIC] NAME #. Show a group type: .. code-block:: console cinder --os-volume-api-version 3.11 group-type-show GROUP_TYPE #. List group types: .. code-block:: console cinder --os-volume-api-version 3.11 group-type-list #. Delete group type: .. code-block:: console cinder --os-volume-api-version 3.11 group-type-delete GROUP_TYPE [GROUP_TYPE ...] #. Set/unset a group spec: .. code-block:: console cinder --os-volume-api-version 3.11 group-type-key GROUP_TYPE ACTION KEY = VALUE [KEY = VALUE ...] .. note:: For creating a consistent group snapshot, a group-spec, set the key ``consistent_group_snapshot_enabled`` to ``True``. #. List group types and group specs: .. code-block:: console cinder --os-volume-api-version 3.11 group-specs-list #. Create a group: .. code-block:: console cinder --os-volume-api-version 3.13 group-create [--name NAME] [--description DESCRIPTION] [--availability-zone AVAILABILITY_ZONE] GROUP_TYPE VOLUME_TYPES #. Show a group: .. code-block:: console cinder --os-volume-api-version 3.13 group-show GROUP #. List all groups: .. code-block:: console cinder --os-volume-api-version 3.13 group-list [--all-tenants [<0|1>]] #. Create a volume and add it to a group at the time of creation: .. code-block:: console cinder --os-volume-api-version 3.13 create --volume-type VOLUME_TYPE --group-id GROUP_ID SIZE #. Modify a group to add or remove volumes: .. code-block:: console cinder --os-volume-api-version 3.13 group-update [--name NAME] [--description DESCRIPTION] [--add-volumes UUID1,UUID2,......] [--remove-volumes UUID3,UUID4,......] GROUP #. Create a group snapshot: .. code-block:: console cinder --os-volume-api-version 3.14 group-snapshot-create [--name NAME] [--description DESCRIPTION] GROUP .. note:: If the group snapshot has to be consistent then both group type and volume type, configure the specs with the key ``consistent_group_snapshot_enabled`` set to ``True``. #. Delete group snapshot(s): .. code-block:: console cinder --os-volume-api-version 3.14 group-snapshot-delete GROUP_SNAPSHOT [GROUP_SNAPSHOT ...] #. Create a group from a group snapshot: .. code-block:: console cinder --os-volume-api-version 3.14 group-create-from-src [--group-snapshot GROUP_SNAPSHOT] [--name NAME] [--description DESCRIPTION] .. note:: Creating group from a source group is not supported #. Delete a group: .. code-block:: console cinder --os-volume-api-version 3.13 group-delete [--delete-volumes] GROUP [GROUP ...] $ openstack volume type set --property volume_backend_name = FC_backend VMAX_FC_DIAMOND $ openstack volume type set --property pool_name = Diamond+OLTP+SRP_1+111111111111",72,131
openstack%2Fdragonflow~stable%2Focata~Iaa3ea64eabf71681c9220c215fe655c055912e65,openstack/dragonflow,stable/ocata,Iaa3ea64eabf71681c9220c215fe655c055912e65,Add _nested_txn property to DFOvsdbApi,ABANDONED,2017-02-18 03:25:02.000000000,2017-02-20 04:13:54.000000000,,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-18 03:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/30fb907292673c2125ccdf2baf40f8d1a2ea1221', 'message': ""Add _nested_txn property to DFOvsdbApi\n\nIn change I55dd417cae7ebbe0668ba5606949ce4ab045d251 , _nested_txn\nproperty was added to neutron.agent.ovsdb.api.API. DFOvsdbApi inherits\nfrom this class, but does not call the parent super, in order to\noverride the creation of the internal idl instance.\n\nThis means that the property is not created, but is later read in the\n'transaction' method in the parent class, which causes an error.\n\nThis change fixes this error.\n\nChange-Id: Iaa3ea64eabf71681c9220c215fe655c055912e65\n(cherry picked from commit 6cc1ced246c235ab98dea437aaf03094f025f314)\n""}, {'number': 2, 'created': '2017-02-18 05:04:25.000000000', 'files': ['dragonflow/ovsdb/impl_idl.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9f4128e7f70e903fca212c6c16afa949260d1ec3', 'message': ""Add _nested_txn property to DFOvsdbApi\n\nIn change I55dd417cae7ebbe0668ba5606949ce4ab045d251 , _nested_txn\nproperty was added to neutron.agent.ovsdb.api.API. DFOvsdbApi inherits\nfrom this class, but does not call the parent super, in order to\noverride the creation of the internal idl instance.\n\nThis means that the property is not created, but is later read in the\n'transaction' method in the parent class, which causes an error.\n\nThis change fixes this error.\n\nChange-Id: Iaa3ea64eabf71681c9220c215fe655c055912e65\n(cherry picked from commit 6cc1ced246c235ab98dea437aaf03094f025f314)\n""}]",0,435645,9f4128e7f70e903fca212c6c16afa949260d1ec3,5,4,2,20287,,,0,"Add _nested_txn property to DFOvsdbApi

In change I55dd417cae7ebbe0668ba5606949ce4ab045d251 , _nested_txn
property was added to neutron.agent.ovsdb.api.API. DFOvsdbApi inherits
from this class, but does not call the parent super, in order to
override the creation of the internal idl instance.

This means that the property is not created, but is later read in the
'transaction' method in the parent class, which causes an error.

This change fixes this error.

Change-Id: Iaa3ea64eabf71681c9220c215fe655c055912e65
(cherry picked from commit 6cc1ced246c235ab98dea437aaf03094f025f314)
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/45/435645/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/ovsdb/impl_idl.py'],1,30fb907292673c2125ccdf2baf40f8d1a2ea1221,nested_txn, self._nested_txn = None,,1,0
openstack%2Fzun~master~Ie2534fa1297f5260257bd5fc063af0629115a51f,openstack/zun,master,Ie2534fa1297f5260257bd5fc063af0629115a51f,Add tests for custom object fields,MERGED,2017-02-14 20:13:08.000000000,2017-02-20 04:01:45.000000000,2017-02-20 04:01:45.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 22076}]","[{'number': 1, 'created': '2017-02-14 20:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8e0e10f1e928880d722f11d662790d120835e385', 'message': 'Add tests for custom object fields\n\nChange-Id: Ie2534fa1297f5260257bd5fc063af0629115a51f\n'}, {'number': 2, 'created': '2017-02-20 02:28:51.000000000', 'files': ['zun/tests/unit/objects/test_fields.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/c0cebba170b8e3ea5e62e335536cf974bbbf08ec', 'message': 'Add tests for custom object fields\n\nChange-Id: Ie2534fa1297f5260257bd5fc063af0629115a51f\n'}]",0,433915,c0cebba170b8e3ea5e62e335536cf974bbbf08ec,13,4,2,11536,,,0,"Add tests for custom object fields

Change-Id: Ie2534fa1297f5260257bd5fc063af0629115a51f
",git fetch https://review.opendev.org/openstack/zun refs/changes/15/433915/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/tests/unit/objects/test_fields.py'],1,8e0e10f1e928880d722f11d662790d120835e385,unittests,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_versionedobjects.tests import test_fields from zun.objects import fields class TestContainerStatus(test_fields.TestField): def setUp(self): super(TestContainerStatus, self).setUp() self.field = fields.ContainerStatus() self.coerce_good_values = [ ('Error', 'Error'), ('Running', 'Running'), ('Stopped', 'Stopped'), ('Paused', 'Paused'), ('Unknown', 'Unknown'), ('Creating', 'Creating'), ] self.coerce_bad_values = ['bad_value'] self.to_primitive_values = self.coerce_good_values[0:1] self.from_primitive_values = self.coerce_good_values[0:1] def test_stringify(self): self.assertEqual(""'Error'"", self.field.stringify('Error')) def test_stringify_invalid(self): self.assertRaises(ValueError, self.field.stringify, 'bad_value') class TestTaskState(test_fields.TestField): def setUp(self): super(TestTaskState, self).setUp() self.field = fields.TaskState() self.coerce_good_values = [ ('image_pulling', 'image_pulling'), ('container_creating', 'container_creating'), ('sandbox_creating', 'sandbox_creating'), ] self.coerce_bad_values = ['bad_value'] self.to_primitive_values = self.coerce_good_values[0:1] self.from_primitive_values = self.coerce_good_values[0:1] def test_stringify(self): self.assertEqual(""'image_pulling'"", self.field.stringify('image_pulling')) def test_stringify_invalid(self): self.assertRaises(ValueError, self.field.stringify, 'bad_value') ",,60,0
openstack%2Fopenstack-manuals~master~Iab464db80aec656d3c315a8a52e3129f0ed60ca3,openstack/openstack-manuals,master,Iab464db80aec656d3c315a8a52e3129f0ed60ca3,[arch-design-draft] Compute design structure work - overcommit/instance,ABANDONED,2017-02-17 08:34:43.000000000,2017-02-20 03:10:52.000000000,,"[{'_account_id': 3}, {'_account_id': 14870}]","[{'number': 1, 'created': '2017-02-17 08:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/787a88f6459d12efc151919f65e5eb78d228a21c', 'message': '[arch-design-draft] Compute design structure work - overcommit/instance\n\n-Added instance storage solutions\n-Added overcommitting\n\nChange-Id: Iab464db80aec656d3c315a8a52e3129f0ed60ca3\nImplements: blueprint arch-guide-restructure\n'}, {'number': 2, 'created': '2017-02-17 08:50:11.000000000', 'files': ['doc/arch-design-draft/source/design-compute/design-compute-overcommitting.rst', 'doc/arch-design-draft/source/design-compute.rst', 'doc/arch-design-draft/source/design-compute/design-compute-instance.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0abd1dd9855d61b2695f28e29c1fcd235a434669', 'message': '[arch-design-draft] Compute design structure work - overcommit/instance\n\n-Added instance storage solutions\n-Added overcommitting\n\nChange-Id: Iab464db80aec656d3c315a8a52e3129f0ed60ca3\nImplements: blueprint arch-guide-restructure\n'}]",0,435305,0abd1dd9855d61b2695f28e29c1fcd235a434669,6,2,2,14870,,,0,"[arch-design-draft] Compute design structure work - overcommit/instance

-Added instance storage solutions
-Added overcommitting

Change-Id: Iab464db80aec656d3c315a8a52e3129f0ed60ca3
Implements: blueprint arch-guide-restructure
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/05/435305/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/arch-design-draft/source/design-compute/design-compute-overcommitting.rst', 'doc/arch-design-draft/source/design-compute.rst', 'doc/arch-design-draft/source/design-compute/design-compute-instance.rst']",3,787a88f6459d12efc151919f65e5eb78d228a21c,bp/arch-guide-restructure,====================== Instance storage solutions ====================== ,,8,0
openstack%2Fsenlin~stable%2Focata~I3ac9115f29cca40d3b16132a5e0afa76f502ec1a,openstack/senlin,stable/ocata,I3ac9115f29cca40d3b16132a5e0afa76f502ec1a,revise dumping event notifications,MERGED,2017-02-20 01:34:19.000000000,2017-02-20 03:10:49.000000000,2017-02-20 03:10:49.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-20 01:34:19.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/tempest/functional/test_scaling_policy.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4bdafc9963527cb0a403f9cef8810a44865cf69a', 'message': 'revise dumping event notifications\n\nTo prevent dumping duplicated event notifications to rabbitMQ, we will only\ndump it at the beginning of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471\n\nand at the end of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492\n\nChange-Id: I3ac9115f29cca40d3b16132a5e0afa76f502ec1a\n(cherry picked from commit a17d0d351d5b21a578fa1c0bda4b63dbfb97e5d0)\n'}]",0,435818,4bdafc9963527cb0a403f9cef8810a44865cf69a,6,2,1,8246,,,0,"revise dumping event notifications

To prevent dumping duplicated event notifications to rabbitMQ, we will only
dump it at the beginning of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471

and at the end of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492

Change-Id: I3ac9115f29cca40d3b16132a5e0afa76f502ec1a
(cherry picked from commit a17d0d351d5b21a578fa1c0bda4b63dbfb97e5d0)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/18/435818/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/tempest/functional/test_scaling_policy.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/engine/actions/base.py']",5,4bdafc9963527cb0a403f9cef8810a44865cf69a,revise-event," self.data['reason'] = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason}"," reason = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason} EVENT.error(self, consts.PHASE_ERROR, reason)",37,33
openstack%2Fopenstacksdk~master~Iaea6683aec7c036b6561c33d2bce03055d74d07d,openstack/openstacksdk,master,Iaea6683aec7c036b6561c33d2bce03055d74d07d,Fix the nextwork agent add remove test,MERGED,2017-02-18 16:46:18.000000000,2017-02-20 02:43:43.000000000,2017-02-20 02:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-18 16:46:18.000000000', 'files': ['openstack/tests/functional/network/v2/test_agent_add_remove_network.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/93f21be04ab9462481e5ebd4f42d97a1a2630a69', 'message': 'Fix the nextwork agent add remove test\n\nThere are some obvious errors in the network agent add and remove\ntest.\n\nPartial-bug: #1665495\n\nChange-Id: Iaea6683aec7c036b6561c33d2bce03055d74d07d\n'}]",3,435720,93f21be04ab9462481e5ebd4f42d97a1a2630a69,11,3,1,8736,,,0,"Fix the nextwork agent add remove test

There are some obvious errors in the network agent add and remove
test.

Partial-bug: #1665495

Change-Id: Iaea6683aec7c036b6561c33d2bce03055d74d07d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/435720/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_agent_add_remove_network.py'],1,93f21be04ab9462481e5ebd4f42d97a1a2630a69,bug/1665495," NETWORK_NAME = 'network-' + uuid.uuid4().hex cls.conn.network.delete_network(cls.NETWORK_ID) self.assertIn(self.NETWORK_ID, net_ids) def _verify_remove(self, network):"," NETWORK_NAME = 'network-name'.join(uuid.uuid4().hex) net = cls.conn.network.delete_router(cls.NETWORK_ID, ignore_missing=False) cls.assertIs(None, net) self.asserIn(self.NETWORK_ID, net_ids) def _verify_network(self, network):",4,6
openstack%2Fzun~master~Ide12f6e2da3b161300c93a292ae01bda3f9352b5,openstack/zun,master,Ide12f6e2da3b161300c93a292ae01bda3f9352b5,Remove gate_hook.sh from /devstack folder,MERGED,2017-02-13 05:21:05.000000000,2017-02-20 02:43:03.000000000,2017-02-20 02:43:03.000000000,"[{'_account_id': 3}, {'_account_id': 16277}, {'_account_id': 22076}]","[{'number': 1, 'created': '2017-02-13 05:21:05.000000000', 'files': ['devstack/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/zun/commit/ae65dae1db63d81e049d3f39b9d98a823169ab07', 'message': 'Remove gate_hook.sh from /devstack folder\n\nThis script has moved to /zun/tests/contrib\nhttps://review.openstack.org/#/c/432843/\nhttps://review.openstack.org/#/c/432844/\n\nChange-Id: Ide12f6e2da3b161300c93a292ae01bda3f9352b5\nDepends-On: I957c5b3ecabfe634623179bb84496bc1bcb67e30\n'}]",0,432846,ae65dae1db63d81e049d3f39b9d98a823169ab07,15,3,1,11536,,,0,"Remove gate_hook.sh from /devstack folder

This script has moved to /zun/tests/contrib
https://review.openstack.org/#/c/432843/
https://review.openstack.org/#/c/432844/

Change-Id: Ide12f6e2da3b161300c93a292ae01bda3f9352b5
Depends-On: I957c5b3ecabfe634623179bb84496bc1bcb67e30
",git fetch https://review.opendev.org/openstack/zun refs/changes/46/432846/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/gate_hook.sh'],1,ae65dae1db63d81e049d3f39b9d98a823169ab07,,,"#!/bin/bash -x # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # This script is executed inside gate_hook function in devstack gate. # Keep all devstack settings here instead of project-config for easy # maintain if we want to change devstack config settings in future. driver=$1 db=$2 if [ ""$driver"" = ""docker"" ]; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""ZUN_DRIVER=docker"" elif [ ""$driver"" = ""nova-docker"" ]; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""ZUN_DRIVER=nova-docker"" export DEVSTACK_LOCAL_CONFIG+=$'\n'""IP_VERSION=4"" fi if [ ""$db"" = ""etcd"" ]; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""ZUN_DB_TYPE=etcd"" elif [ ""$db"" = ""sql"" ]; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""ZUN_DB_TYPE=sql"" fi $BASE/new/devstack-gate/devstack-vm-gate.sh ",0,37
openstack%2Fopenstacksdk~master~I9738b9283de2e731510f6ed5ff208c075ea48940,openstack/openstacksdk,master,I9738b9283de2e731510f6ed5ff208c075ea48940,Fix the network quota tests,MERGED,2017-02-19 00:11:35.000000000,2017-02-20 02:30:50.000000000,2017-02-20 02:30:50.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-19 00:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/2e79102bda95652b99181272be4f13cdaaf3a46e', 'message': 'Fix the network quota tests\n\nThese network quota tests were badly broken.  I simplified them\nup a lot so they will require less maintenance.\n\nChange-Id: I9738b9283de2e731510f6ed5ff208c075ea48940\nPartial-bug: #1665495\n'}, {'number': 2, 'created': '2017-02-19 14:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f3ae912422e8a4db65208258935fced15c409595', 'message': 'Fix the network quota tests\n\nThese network quota tests were badly broken.  I simplified them\nup a lot so they will require less maintenance.\n\nChange-Id: I9738b9283de2e731510f6ed5ff208c075ea48940\nPartial-bug: #1665495\n'}, {'number': 3, 'created': '2017-02-19 15:22:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/058e812f6b68b5f8be48b2894f27d7c03fd10f61', 'message': 'Fix the network quota tests\n\nThese network quota tests were badly broken.  I simplified them\nup a lot so they will require less maintenance.\n\nChange-Id: I9738b9283de2e731510f6ed5ff208c075ea48940\nPartial-bug: #1665495\n'}, {'number': 4, 'created': '2017-02-19 16:47:08.000000000', 'files': ['create_yaml.sh', 'openstack/tests/functional/network/v2/test_quota.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f5e77c6be9b3c33b8031c310526bbebbfbd7aee8', 'message': 'Fix the network quota tests\n\nThese network quota tests were badly broken.  I simplified them\nup a lot so they will require less maintenance.\n\nChange-Id: I9738b9283de2e731510f6ed5ff208c075ea48940\nPartial-bug: #1665495\n'}]",0,435740,f5e77c6be9b3c33b8031c310526bbebbfbd7aee8,16,4,4,8736,,,0,"Fix the network quota tests

These network quota tests were badly broken.  I simplified them
up a lot so they will require less maintenance.

Change-Id: I9738b9283de2e731510f6ed5ff208c075ea48940
Partial-bug: #1665495
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/40/435740/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_quota.py'],1,2e79102bda95652b99181272be4f13cdaaf3a46e,bug/1665495," qot = self.conn.network.quotas().next() self.assertIsNotNone(qot.project_id) self.assertIsNotNone(qot.networks) attrs = {'networks': 123456789} project_quota = self.conn.network.quotas().next() self.conn.network.update_quota(project_quota, **attrs) new_quota = self.conn.network.get_quota(project_quota.project_id) self.assertEqual(123456789, new_quota.networks)"," sot = self.conn.network.quotas() for qot in sot: self.assertIn('subnet', qot) self.assertIn('network', qot) self.assertIn('router', qot) self.assertIn('port', qot) self.assertIn('floatingip', qot) self.assertIn('security_group_rule', qot) self.assertIn('security_group', qot) self.assertIn('subnetpool', qot) self.assertIn('rbac_policy', qot) attrs = {'network': 123456789} self.conn.network.update_quota(**attrs) quota_list = self.conn.network.get_quota() for quota in quota_list: self.assertIn('123456789', quota)",8,16
openstack%2Fopenstacksdk~master~Ia681498916e19b959183bb591f95c71263c94e3b,openstack/openstacksdk,master,Ia681498916e19b959183bb591f95c71263c94e3b,Fix the network floating ip test for get,MERGED,2017-02-19 17:12:59.000000000,2017-02-20 02:30:45.000000000,2017-02-20 02:30:44.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-19 17:12:59.000000000', 'files': ['openstack/tests/functional/network/v2/test_floating_ip.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/04430af53366795c47c52920864334d4220f4214', 'message': 'Fix the network floating ip test for get\n\nGet test was expecting dictionary like resource.\n\nPartial-bug: #1665495\n\nChange-Id: Ia681498916e19b959183bb591f95c71263c94e3b\n'}]",0,435798,04430af53366795c47c52920864334d4220f4214,8,4,1,8736,,,0,"Fix the network floating ip test for get

Get test was expecting dictionary like resource.

Partial-bug: #1665495

Change-Id: Ia681498916e19b959183bb591f95c71263c94e3b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/98/435798/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_floating_ip.py'],1,04430af53366795c47c52920864334d4220f4214,bug/1665495," FIP = None cls.FIP = fip sot = cls.conn.network.delete_ip(cls.FIP.id, ignore_missing=False) sot = self.conn.network.find_ip(self.FIP.id) self.assertEqual(self.FIP.id, sot.id) sot = self.conn.network.get_ip(self.FIP.id) self.assertEqual(self.FIP.id, sot.id) self.assertEqual(self.FIP.floating_ip_address, sot.floating_ip_address) self.assertEqual(self.FIP.fixed_ip_address, sot.fixed_ip_address) self.assertEqual(self.FIP.port_id, sot.port_id) self.assertEqual(self.FIP.router_id, sot.router_id) self.assertIn(self.FIP.id, ids) sot = self.conn.network.update_ip(self.FIP.id, port_id=self.PORT_ID) self.assertEqual(self.FIP.id, sot.id)"," FIP_ID = None cls.FIP_ID = fip.id sot = cls.conn.network.delete_ip(cls.FIP_ID, ignore_missing=False) sot = self.conn.network.find_ip(self.FIP_ID) self.assertEqual(self.FIP_ID, sot.id) sot = self.conn.network.get_ip(self.FIP_ID) self.assertEqual(self.FIP_ID, sot.id) self.assertIn('floating_ip_address', sot) self.assertIn('fixed_ip_address', sot) self.assertIn('port_id', sot) self.assertIn('router_id', sot) self.assertIn(self.FIP_ID, ids) sot = self.conn.network.update_ip(self.FIP_ID, port_id=self.PORT_ID) self.assertEqual(self.FIP_ID, sot.id)",14,14
openstack%2Fopenstacksdk~master~Ief96558770d81dca81091e235b8d370883b14b94,openstack/openstacksdk,master,Ief96558770d81dca81091e235b8d370883b14b94,Fix the network service provider test,MERGED,2017-02-19 17:00:33.000000000,2017-02-20 02:28:37.000000000,2017-02-20 02:28:37.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-19 17:00:33.000000000', 'files': ['openstack/tests/functional/network/v2/test_service_provider.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eadf481f352e4277001f3b9e83c7ffbbd58c789c', 'message': 'Fix the network service provider test\n\nThis test was pretty lame before since it just verified that\nthe result was a string.  Now it verifies that at least one\nservice provider exists and I think I picked one that should\nbe aroudn for a while.  The test failure message also prints\nthe list of providers now so it should be easier to debug.\n\nPartial-bug: #1665495\n\nChange-Id: Ief96558770d81dca81091e235b8d370883b14b94\n'}]",2,435795,eadf481f352e4277001f3b9e83c7ffbbd58c789c,11,4,1,8736,,,0,"Fix the network service provider test

This test was pretty lame before since it just verified that
the result was a string.  Now it verifies that at least one
service provider exists and I think I picked one that should
be aroudn for a while.  The test failure message also prints
the list of providers now so it should be easier to debug.

Partial-bug: #1665495

Change-Id: Ief96558770d81dca81091e235b8d370883b14b94
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/95/435795/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_service_provider.py'],1,eadf481f352e4277001f3b9e83c7ffbbd58c789c,bug/1665495," names = [o.name for o in providers] service_types = [o.service_type for o in providers] self.assertIn('ha', names) self.assertIn('L3_ROUTER_NAT', service_types)","import six for provide in providers: self.assertIsInstance(provide.name, six.string_type) self.assertIsInstance(provide.service_type, six.string_types)",4,6
openstack%2Fpython-zunclient~master~I0e41193c242270e38f4f0bf745264477f86d1ab0,openstack/python-zunclient,master,I0e41193c242270e38f4f0bf745264477f86d1ab0,"Support the command ""zun top""",MERGED,2017-01-23 07:57:29.000000000,2017-02-20 02:18:36.000000000,2017-02-20 02:18:36.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 16277}, {'_account_id': 20858}, {'_account_id': 22076}, {'_account_id': 23365}]","[{'number': 1, 'created': '2017-01-23 07:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/aa295fd7ed25d3a7ff887c24f8563e105155ab0c', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 2, 'created': '2017-01-23 11:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/a8d1ee51b90a6ac10a2bdf49467c82bc5391e384', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 3, 'created': '2017-01-24 07:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/e67557a84eab276c94e1bbec979ad14dc4556749', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 4, 'created': '2017-01-24 08:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/d0c3ec8287749337f69a74537b92c8d84727256b', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 5, 'created': '2017-02-10 08:14:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/6cb88d4fe5bd8040e475417f38e6429a3ae98d7d', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 6, 'created': '2017-02-10 08:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/20b541a9721d5b8aeecfcef3ff2ddb04d442afbd', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 7, 'created': '2017-02-11 04:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/52fe452f3daf257d8062ade4454b7463d3fc2ee8', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 8, 'created': '2017-02-11 06:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/fe54a1a4c56898963462d5474b498ef468ddd7e6', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}, {'number': 9, 'created': '2017-02-14 11:59:32.000000000', 'files': ['zunclient/v1/containers_shell.py', 'setup.cfg', 'zunclient/tests/unit/v1/test_containers.py', 'zunclient/osc/v1/containers.py', 'zunclient/v1/containers.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/bf954a5aa4e9672e4fea46ab0422fd6b0757bb1a', 'message': 'Support the command ""zun top""\n\nThe BP adds ""zun top"" which can display progress in container.\n\nChange-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0\nImplements: blueprint support-zun-top\n'}]",6,423974,bf954a5aa4e9672e4fea46ab0422fd6b0757bb1a,29,6,9,23365,,,0,"Support the command ""zun top""

The BP adds ""zun top"" which can display progress in container.

Change-Id: I0e41193c242270e38f4f0bf745264477f86d1ab0
Implements: blueprint support-zun-top
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/74/423974/7 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/v1/containers_shell.py', 'setup.cfg', 'zunclient/tests/unit/v1/test_containers.py', 'zunclient/osc/v1/containers.py', 'zunclient/v1/containers.py']",5,aa295fd7ed25d3a7ff887c24f8563e105155ab0c,bp/adds," def top(self, id, ps=None): return self._action(id, '/top', method='GET', qparams={'ps': ps})[1]",,58,0
openstack%2Fpython-zunclient~master~I5037c4b812e53966a2fdd1033e74bfe19656bf03,openstack/python-zunclient,master,I5037c4b812e53966a2fdd1033e74bfe19656bf03,Added stdout&stderr for openstack appcontainer logs,MERGED,2017-02-16 07:04:48.000000000,2017-02-20 02:13:06.000000000,2017-02-20 02:13:06.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 22076}]","[{'number': 1, 'created': '2017-02-16 07:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/f8fe8cb5c4cd0e2eb1d25c13f221e3bfd7501f62', 'message': 'Added stdout&stderr for openstack appcontainer logs\n\nChange-Id: I5037c4b812e53966a2fdd1033e74bfe19656bf03\n'}, {'number': 2, 'created': '2017-02-16 21:22:04.000000000', 'files': ['zunclient/osc/v1/containers.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/53efad98149785e5d295c15a2d04bf86a08416f2', 'message': 'Added stdout&stderr for openstack appcontainer logs\n\nCloses-Bug: #1661749\nChange-Id: I5037c4b812e53966a2fdd1033e74bfe19656bf03\n'}]",0,434675,53efad98149785e5d295c15a2d04bf86a08416f2,10,3,2,23365,,,0,"Added stdout&stderr for openstack appcontainer logs

Closes-Bug: #1661749
Change-Id: I5037c4b812e53966a2fdd1033e74bfe19656bf03
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/75/434675/2 && git format-patch -1 --stdout FETCH_HEAD,['zunclient/osc/v1/containers.py'],1,f8fe8cb5c4cd0e2eb1d25c13f221e3bfd7501f62,," parser.add_argument( '--stdout', action='store_true', help='Only stdout logs of container.') parser.add_argument( '--stderr', action='store_true', help='Only stderr logs of container.') stdout = parsed_args.stdout stderr = parsed_args.stderr logs = client.containers.logs(container, stdout, stderr)", logs = client.containers.logs(container),11,1
openstack%2Fzun~master~I58bb55319aa005837eba5e0b047dc6f196be01b4,openstack/zun,master,I58bb55319aa005837eba5e0b047dc6f196be01b4,Fixup the manual devstack guide,MERGED,2017-02-17 00:34:35.000000000,2017-02-20 02:10:56.000000000,2017-02-20 02:10:56.000000000,"[{'_account_id': 3}, {'_account_id': 3211}, {'_account_id': 16277}, {'_account_id': 22076}]","[{'number': 1, 'created': '2017-02-17 00:34:35.000000000', 'files': ['doc/source/dev/manual-devstack.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/95403d183a640587233bcc6dc5710355c1897d3f', 'message': ""Fixup the manual devstack guide\n\nThe guide has been outdated and a contributor reported that it\ndidn't work. This commit is for fixing it.\n\nChange-Id: I58bb55319aa005837eba5e0b047dc6f196be01b4\n""}]",0,435163,95403d183a640587233bcc6dc5710355c1897d3f,8,4,1,11536,,,0,"Fixup the manual devstack guide

The guide has been outdated and a contributor reported that it
didn't work. This commit is for fixing it.

Change-Id: I58bb55319aa005837eba5e0b047dc6f196be01b4
",git fetch https://review.opendev.org/openstack/zun refs/changes/63/435163/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dev/manual-devstack.rst'],1,95403d183a640587233bcc6dc5710355c1897d3f,, sudo pip install -c /opt/stack/requirements/upper-constraints.txt -e . iniset $ZUN_CONF keystone_authtoken auth_uri ${OS_AUTH_URL/v2.0/v3} sudo pip install -c /opt/stack/requirements/upper-constraints.txt -e . openstack endpoint create --region RegionOne container public \ http://127.0.0.1:9512/v1 openstack endpoint create --region RegionOne container internal \ http://127.0.0.1:9512/v1 openstack endpoint create --region RegionOne container admin \ http://127.0.0.1:9512/v1, sudo pip install -e . sudo pip install -e . openstack endpoint create --publicurl http://127.0.0.1:9512/v1 \ --adminurl http://127.0.0.1:9512/v1 \ --internalurl http://127.0.0.1:9512/v1 \ --region=RegionOne \ container,9,7
openstack%2Fzun~master~Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c,openstack/zun,master,Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c,Spec for Kuryr integration,MERGED,2017-01-26 20:10:59.000000000,2017-02-20 02:10:46.000000000,2017-02-20 02:10:46.000000000,"[{'_account_id': 3}, {'_account_id': 8580}, {'_account_id': 9775}, {'_account_id': 10206}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 12407}, {'_account_id': 16277}, {'_account_id': 22076}, {'_account_id': 25026}]","[{'number': 1, 'created': '2017-01-26 20:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/63e5300f25a215b6675092fef2b0eba0c91c51f8', 'message': '[WIP] Spec for Kuryr integration\n\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 2, 'created': '2017-01-26 23:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4df6fd205a0717945294c107fbcc1279f43f6c35', 'message': '[WIP] Spec for Kuryr integration\n\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 3, 'created': '2017-01-26 23:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/de60c7191bbf34195fbd377b18fd9bc3406b8433', 'message': '[WIP] Spec for Kuryr integration\n\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 4, 'created': '2017-01-28 18:01:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/05cd2116450cb671d36286ad62f88aa0c4b8d1fc', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 5, 'created': '2017-01-31 00:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/f3a3ccd5fea6e6158db2e35d3ea7fa1833a598c7', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 6, 'created': '2017-02-01 19:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/ab14f7c046e3ec0c9742b0864f0105cb958d4126', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 7, 'created': '2017-02-03 16:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/4f002bfb0e46dcbb1001f7c24e5f3d9aec6046ed', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 8, 'created': '2017-02-06 22:11:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/78f5e7ce296a93b4365dc1e9983d49c0d125e871', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 9, 'created': '2017-02-10 22:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/8676b3ef68b4435e4a9deec09d44e67fb0ef77ea', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}, {'number': 10, 'created': '2017-02-16 19:59:02.000000000', 'files': ['specs/kuryr-integration.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/7aecebd45933ac66def48eba33003ed0445e029b', 'message': 'Spec for Kuryr integration\n\nThis spec proposed to leverage Kuryr-libnetwork for providing\nnetworking for containers.\n\nImplements: blueprint kuryr-integration\nChange-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c\n'}]",33,425883,7aecebd45933ac66def48eba33003ed0445e029b,44,10,10,11536,,,0,"Spec for Kuryr integration

This spec proposed to leverage Kuryr-libnetwork for providing
networking for containers.

Implements: blueprint kuryr-integration
Change-Id: Ic95299aafe43403cb58bbdf0c2776bb91a52fa4c
",git fetch https://review.opendev.org/openstack/zun refs/changes/83/425883/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/kuryr-integration.rst'],1,63e5300f25a215b6675092fef2b0eba0c91c51f8,bp/kuryr-integration,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================= Kuryr Integration ================= Related Launchpad Blueprint: https://blueprints.launchpad.net/zun/+spec/kuryr-integration Zun provides APIs for managing application containers, and the implementation of the APIs is provided by drivers. Currently, Zun has two built-in drivers: the native Docker driver and the Nova Docker driver. The Nova driver leverages existing Nova capability to provide networking for containers. However, the native Docker driver doesn't have an ideal solution for networking yet. This spec proposed to leverage Kuryr-libnetwork [1] for providing networking for containers. Generally speaking, Kuryr-libnetwork is a remote Docker networking plugin that interfaces with Neutron for container networking. Kuryr-libnetwork provides several features, such as IPAM, port binding, etc. all of which could be leveraged by Zun. Problem description =================== Currently, the native Docker driver doesn't integrate with Neutron. It uses the default networking capability provided by Docker engine. Containers created by that driver has limited networking capabilities, and they are not able to communicate with other OpenStack resources (i.e. Nova instances). Proposed change =============== TBD Alternatives ------------ 1. Directly integrate with Neutron (without Kuryr-libnetwork). This approach basically re-invented Kuryr-libnetwork in Zun, which is unnecessary. 2. Use alternative networking solution (i.e. Flannel) instead of Neutron. Data model impact ----------------- TBD REST API impact --------------- TBD Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ TBD Other deployer impact --------------------- TBD Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Hongbin Lu Other contributors: Work Items ---------- TBD Dependencies ============ Add a dependency to Kuryr-libnetwork Testing ======= Each patch will have unit tests, and Tempest functional tests covered. Documentation Impact ==================== A set of documentation for this new feature will be required. References ========== [1] https://github.com/openstack/kuryr-libnetwork ",,120,0
openstack%2Fpython-zunclient~master~Ib07507ed5a76e87cb0f5465f7e66bf6c4ab04676,openstack/python-zunclient,master,Ib07507ed5a76e87cb0f5465f7e66bf6c4ab04676,[NOT_FOR_REVIEW] Test the py35 gate failure,ABANDONED,2017-02-18 21:06:31.000000000,2017-02-20 02:09:29.000000000,,"[{'_account_id': 3}, {'_account_id': 11536}]","[{'number': 1, 'created': '2017-02-18 21:06:31.000000000', 'files': ['zunclient/tests/unit/utils.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/45a793682c9b6e63a3c3f5ba726bfc9680f37663', 'message': '[NOT_FOR_REVIEW] Test the py35 gate failure\n\nChange-Id: Ib07507ed5a76e87cb0f5465f7e66bf6c4ab04676\n'}]",0,435732,45a793682c9b6e63a3c3f5ba726bfc9680f37663,17,2,1,11536,,,0,"[NOT_FOR_REVIEW] Test the py35 gate failure

Change-Id: Ib07507ed5a76e87cb0f5465f7e66bf6c4ab04676
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/32/435732/1 && git format-patch -1 --stdout FETCH_HEAD,['zunclient/tests/unit/utils.py'],1,45a793682c9b6e63a3c3f5ba726bfc9680f37663,," print(""url: "" + repr(url)) print(""self.responses: "" + repr(self.responses))",,2,0
openstack%2Fcinder~master~I7674848d4464205c5fd0f7669e74154961319f1a,openstack/cinder,master,I7674848d4464205c5fd0f7669e74154961319f1a,Removes getfattr from Quobyte Cinder driver,MERGED,2017-02-01 17:45:35.000000000,2017-02-20 02:00:50.000000000,2017-02-17 02:08:29.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13915}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17103}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 18827}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21990}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 23613}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}, {'_account_id': 24863}]","[{'number': 1, 'created': '2017-02-01 17:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/08f15e9f397609db61b230522f9dcb9021d8828a', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds a range of\nunit tests to verify the different check results.\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\nPartial-Bug: 1659328\n'}, {'number': 2, 'created': '2017-02-02 08:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fb92094886db8a4d046510dcf8fc8dc6300817fb', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds serveral\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 3, 'created': '2017-02-02 22:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2cbab4efe5ddaa473d3dde1a65d187b7922d7d00', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds serveral\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 4, 'created': '2017-02-03 07:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a03a6d955ad7e13857121a7f08561642dcd0fccb', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds serveral\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 5, 'created': '2017-02-03 07:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/db1ed9312e2be4e19328d65cb731570682ec207c', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds serveral\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 6, 'created': '2017-02-07 10:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1b5bfb3b882845ab1d45a008cb88279112af1f66', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds several\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 7, 'created': '2017-02-07 14:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/fcab99fbae3bebfbbf2ab74f1c2756caefacae95', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds several\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 8, 'created': '2017-02-10 08:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a02f7c590c9812e6367a36c7af875cf74e312a39', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds several\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}, {'number': 9, 'created': '2017-02-13 07:58:45.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters', 'cinder/volume/drivers/quobyte.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7585a09bdfd1f6197638928b46b377f13956bfda', 'message': 'Removes getfattr from Quobyte Cinder driver\n\nReplaces reading quobyte.info xarg with a range\nof checks on a given mountpoint. Adds several\nunit tests to verify the different check results.\n\nPartial-Bug: 1659328\n\nChange-Id: I7674848d4464205c5fd0f7669e74154961319f1a\n'}]",4,427833,7585a09bdfd1f6197638928b46b377f13956bfda,244,50,9,13915,,,0,"Removes getfattr from Quobyte Cinder driver

Replaces reading quobyte.info xarg with a range
of checks on a given mountpoint. Adds several
unit tests to verify the different check results.

Partial-Bug: 1659328

Change-Id: I7674848d4464205c5fd0f7669e74154961319f1a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/33/427833/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/quobyte.py', 'cinder/tests/unit/volume/drivers/test_quobyte.py']",2,08f15e9f397609db61b230522f9dcb9021d8828a,bug/1659328,"import shutilimport tempfile '.read_proc_mount') as mock_open, \ mock.patch('cinder.volume.drivers.quobyte.QuobyteDriver' '._validate_volume') as mock_validate: [mkdir_call, mount_call], any_order=False) mock_validate.called_once_with(self.TEST_MNT_POINT) with mock.patch('cinder.volume.drivers.quobyte.QuobyteDriver' '.read_proc_mount') as mock_open, \ '._validate_volume') as mock_validate: mock_validate.assert_called_once_with(self.TEST_MNT_POINT) @mock.patch.object(os, ""stat"") def test_validate_volume_all_good(self, stat_mock): test_mp = tempfile.mkdtemp() try: test_mtab = tempfile.NamedTemporaryFile() test_mtab.write(""quobyte@ "" + test_mp) test_mtab.flush() drv = self._driver drv.MTAB_LOCATION = test_mtab.name def statMockCall(*args): if args[0] == test_mp: stat_result = mock.Mock() stat_result.st_size = 0 return stat_result return os.stat(args) stat_mock.side_effect = statMockCall drv._validate_volume(test_mp) stat_mock.assert_called_once_with(test_mp) finally: shutil.rmtree(test_mp) @mock.patch.object(os, ""stat"") def test_validate_volume_mount_not_working(self, stat_mock): test_mtab = tempfile.NamedTemporaryFile() test_mtab.write(""quobyte@ "" + self.TEST_MNT_POINT) test_mtab.flush() drv = self._driver drv.MTAB_LOCATION = test_mtab.name def statMockCall(*args): if args[0] == self.TEST_MNT_POINT: raise exception.VolumeDriverException() return os.stat(args) stat_mock.side_effect = statMockCall self.assertRaises( exception.VolumeDriverException, self._driver._validate_volume, self.TEST_MNT_POINT) stat_mock.assert_called_once_with(self.TEST_MNT_POINT) def test_validate_volume_no_mtab_entry(self): msg = (""Volume driver reported an error: "" ""No matching Quobyte mount entry for %(mpt)s"" "" could be found for validation in mtab."" % {'mpt': self.TEST_MNT_POINT}) self.assertRaisesAndMessageMatches( exception.VolumeDriverException, msg, self._driver._validate_volume, self.TEST_MNT_POINT) def test_validate_volume_wrong_mount_type(self): msg = (""Volume driver reported an error: "" ""The mount %(mpt)s is not a valid"" "" Quobyte volume according to mtab."" % {'mpt': self.TEST_MNT_POINT}) test_mtab = tempfile.NamedTemporaryFile() test_mtab.write(""not-quobyte "" + self.TEST_MNT_POINT) test_mtab.flush() drv = self._driver drv.MTAB_LOCATION = test_mtab.name self.assertRaisesAndMessageMatches( exception.VolumeDriverException, msg, self._driver._validate_volume, self.TEST_MNT_POINT) def test_validate_volume_stale_mount(self): test_mp = tempfile.mkdtemp() try: test_mtab = tempfile.NamedTemporaryFile() test_mtab.write((""quobyte@ %s"", test_mp)) test_mtab.flush() drv = self._driver drv.MTAB_LOCATION = test_mtab.name # As this uses a local fs dir size is >0, raising an exception self.assertRaises( exception.VolumeDriverException, self._driver._validate_volume, test_mp) finally: shutil.rmtree(test_mp)"," '.read_proc_mount') as mock_open: getfattr_call = mock.call( 'getfattr', '-n', 'quobyte.info', self.TEST_MNT_POINT, run_as_root=False) [mkdir_call, mount_call, getfattr_call], any_order=False) with mock.patch.object(self._driver, '_execute') as mock_execute, \ '.read_proc_mount') as mock_open: mock_execute.assert_called_once_with( 'getfattr', '-n', 'quobyte.info', self.TEST_MNT_POINT, run_as_root=False)",142,25
openstack%2Fironic~master~I947800a7a1affbc37c1614036d51b6cedb86089d,openstack/ironic,master,I947800a7a1affbc37c1614036d51b6cedb86089d,Fix some typos,ABANDONED,2017-02-16 09:03:13.000000000,2017-02-20 01:58:28.000000000,,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 10118}, {'_account_id': 10453}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19339}, {'_account_id': 21511}, {'_account_id': 22226}]","[{'number': 1, 'created': '2017-02-16 09:03:13.000000000', 'files': ['ironic/api/controllers/v1/driver.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f2d88f04a7f08195af6a379013146650c1d0165b', 'message': 'Fix some typos\n\nFix some typos in ironic/api/controllers/v1/driver.py.\n\nChange-Id: I947800a7a1affbc37c1614036d51b6cedb86089d\n'}]",4,434754,f2d88f04a7f08195af6a379013146650c1d0165b,12,9,1,21511,,,0,"Fix some typos

Fix some typos in ironic/api/controllers/v1/driver.py.

Change-Id: I947800a7a1affbc37c1614036d51b6cedb86089d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/54/434754/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/api/controllers/v1/driver.py'],1,f2d88f04a7f08195af6a379013146650c1d0165b,ironic0216, :returns: an API-serializable driver object. This controller allows vendors to expose cross-node functionality in the, :returns: API-serializable driver object. This controller allow vendors to expose cross-node functionality in the,2,2
openstack%2Fsenlin~master~I3ac9115f29cca40d3b16132a5e0afa76f502ec1a,openstack/senlin,master,I3ac9115f29cca40d3b16132a5e0afa76f502ec1a,revise dumping event notifications,MERGED,2017-02-19 06:38:00.000000000,2017-02-20 01:34:20.000000000,2017-02-19 15:36:29.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-19 06:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f3a3db8113acc758ce2e0d32e3960433159e92c0', 'message': 'revise dumping event notifications\n\nTo prevent dumping duplicated event notifications to rabbitMQ, we will only\ndump it at the beginning of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471\n\nand at the end of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492\n\nChange-Id: I3ac9115f29cca40d3b16132a5e0afa76f502ec1a\n'}, {'number': 2, 'created': '2017-02-19 07:58:55.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/tempest/functional/test_scaling_policy.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a17d0d351d5b21a578fa1c0bda4b63dbfb97e5d0', 'message': 'revise dumping event notifications\n\nTo prevent dumping duplicated event notifications to rabbitMQ, we will only\ndump it at the beginning of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471\n\nand at the end of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492\n\nChange-Id: I3ac9115f29cca40d3b16132a5e0afa76f502ec1a\n'}]",0,435749,a17d0d351d5b21a578fa1c0bda4b63dbfb97e5d0,10,3,2,23401,,,0,"revise dumping event notifications

To prevent dumping duplicated event notifications to rabbitMQ, we will only
dump it at the beginning of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471

and at the end of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492

Change-Id: I3ac9115f29cca40d3b16132a5e0afa76f502ec1a
",git fetch https://review.opendev.org/openstack/senlin refs/changes/49/435749/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/tempest/functional/test_scaling_policy.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/engine/actions/base.py']",5,f3a3db8113acc758ce2e0d32e3960433159e92c0,revise-event," self.data['reason'] = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason}"," reason = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason} EVENT.error(self, consts.PHASE_ERROR, reason)",33,24
openstack%2Fcinder~master~Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1,openstack/cinder,master,Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1,VNX: Handle error during volume deletion,MERGED,2017-02-08 09:23:00.000000000,2017-02-20 01:23:21.000000000,2017-02-13 07:12:01.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14624}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18752}, {'_account_id': 18827}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-08 09:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a072c3300c33cdf973ac463a8ea288055608d475', 'message': 'Handle error during volume deletion\n\nIn some circumstances, deleting a async-cloned migration may cause\nerror below:\n\nMigration cannot be cancelled because data sychronization is completed\n(0x714a8021)\n\nThis error is expected and harmful to the volume.\nDriver should bypass this error and allow for volume deletion.\n\nChange-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1\nCloses-bug: #1662747\n'}, {'number': 2, 'created': '2017-02-08 10:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d25dbf816972e34f1e678a59c7b203f242877fe3', 'message': 'Handle error during volume deletion\n\nIn some circumstances, deleting a async-cloned migration may cause\nerror below:\n\nMigration cannot be cancelled because data sychronization is completed\n(0x714a8021)\n\nThis error is expected and harmless to the volume.\nDriver should bypass this error and allow for volume deletion.\n\nChange-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1\nCloses-bug: #1662747\n'}, {'number': 3, 'created': '2017-02-09 06:14:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3dc45c7b3dbf70b8e259bd9aa8c1b3c0082cf9a6', 'message': 'VNX: Handle error during volume deletion\n\nIn some circumstances, deleting a async-cloned migration may cause\nerror below:\n\nMigration cannot be cancelled because data sychronization is completed\n(0x714a8021)\n\nThis error is expected and harmless to the volume.\nDriver should bypass this error and allow for volume deletion.\n\nChange-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1\nCloses-bug: #1662747\n'}, {'number': 4, 'created': '2017-02-10 01:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ff53a6a622970d87bd18370273e2293d16cc30e6', 'message': 'VNX: Handle error during volume deletion\n\nIn some circumstances, deleting a async-cloned migration may cause\nerror below:\n\nMigration cannot be cancelled because data sychronization is completed\n(0x714a8021)\n\nThis error is expected and harmless to the volume.\nDriver should bypass this error and allow for volume deletion.\n\nChange-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1\nCloses-bug: #1662747\n'}, {'number': 5, 'created': '2017-02-10 05:57:51.000000000', 'files': ['cinder/tests/unit/volume/drivers/dell_emc/vnx/fake_exception.py', 'cinder/tests/unit/volume/drivers/dell_emc/vnx/mocked_vnx.yaml', 'cinder/tests/unit/volume/drivers/dell_emc/vnx/test_client.py', 'cinder/volume/drivers/dell_emc/vnx/client.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/39d0d2b3baaa20a98302c0913231a9e142cf7944', 'message': 'VNX: Handle error during volume deletion\n\nIn some circumstances, deleting a async-cloned migration may cause\nerror below:\n\nMigration cannot be cancelled because data sychronization is completed\n(0x714a8021)\n\nThis error is expected and harmless to the volume.\nDriver should bypass this error and allow for volume deletion.\n\nChange-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1\nCloses-bug: #1662747\n'}]",0,430675,39d0d2b3baaa20a98302c0913231a9e142cf7944,135,39,5,10628,,,0,"VNX: Handle error during volume deletion

In some circumstances, deleting a async-cloned migration may cause
error below:

Migration cannot be cancelled because data sychronization is completed
(0x714a8021)

This error is expected and harmless to the volume.
Driver should bypass this error and allow for volume deletion.

Change-Id: Ia6203ce02c779a5f107d42bdc9a17fa16f6830c1
Closes-bug: #1662747
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/430675/5 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/dell_emc/vnx/fake_exception.py', 'cinder/volume/drivers/dell_emc/vnx/client.py']",2,a072c3300c33cdf973ac463a8ea288055608d475,bug/1662747," except (storops_ex.VNXLunNotMigratingError, storops_ex.VNXLunSyncCompletedError): LOG.info(_LI('The LUN is not migrating or completed, ' 'this message can be safely ignored'))"," except storops_ex.VNXLunNotMigratingError: LOG.info(_LI('The LUN is not migrating, this message can be' ' safely ignored'))",8,3
openstack%2Fheat~master~I2557abe296d0ef0a0ed80f3a178c91566dbc3654,openstack/heat,master,I2557abe296d0ef0a0ed80f3a178c91566dbc3654,Improved the descriptions of funtion parameters.,MERGED,2016-10-04 17:28:03.000000000,2017-02-20 00:45:21.000000000,2017-02-20 00:45:20.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 10487}]","[{'number': 1, 'created': '2016-10-04 17:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/19855dcde11399d1b93a5a32c3e832916f53542f', 'message': 'Improved the descriptions of funtion parameters.\n\nChange-Id: I2557abe296d0ef0a0ed80f3a178c91566dbc3654\nCloses-Bug: #1630234\n'}, {'number': 2, 'created': '2016-10-04 19:18:58.000000000', 'files': ['heat/rpc/client.py', 'heat/engine/service.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/43752000aaf5cff99e86bcfaabed2e054f87f631', 'message': 'Improved the descriptions of funtion parameters.\n\nChange-Id: I2557abe296d0ef0a0ed80f3a178c91566dbc3654\nCloses-Bug: #1630234\n'}]",0,382004,43752000aaf5cff99e86bcfaabed2e054f87f631,9,3,2,20826,,,0,"Improved the descriptions of funtion parameters.

Change-Id: I2557abe296d0ef0a0ed80f3a178c91566dbc3654
Closes-Bug: #1630234
",git fetch https://review.opendev.org/openstack/heat refs/changes/04/382004/2 && git format-patch -1 --stdout FETCH_HEAD,"['heat/rpc/client.py', 'heat/engine/service.py']",2,19855dcde11399d1b93a5a32c3e832916f53542f,bug/1630234," :param tags: show stacks containing these tags. If multiple tags are passed, they will be combined using the boolean AND expression :param tags_any: show stacks containing these tags. If multiple tags are passed, they will be combined using the boolean OR expression :param not_tags: show stacks not containing these tags. If multiple tags are passed, they will be combined using the boolean AND expression :param not_tags_any: show stacks not containing these tags. If multiple tags are passed, they will be combined using the boolean OR expression :param tags: count stacks containing these tags. If multiple tags are passed, they will be combined using the boolean AND expression :param tags_any: count stacks containing these tags. If multiple tags are passed, they will be combined using the boolean OR expression :param not_tags: count stacks not containing these tags. If multiple tags are passed, they will be combined using the boolean AND expression :param not_tags_any: count stacks not containing these tags. If multiple tags are passed, they will be combined using the boolean OR expression"," :param tags: show stacks containing these tags, combine multiple tags using the boolean AND expression :param tags_any: show stacks containing these tags, combine multiple tags using the boolean OR expression :param not_tags: show stacks not containing these tags, combine multiple tags using the boolean AND expression :param not_tags_any: show stacks not containing these tags, combine multiple tags using the boolean OR expression :param tags: count stacks containing these tags, combine multiple tags using the boolean AND expression :param tags_any: count stacks containing these tags, combine multiple tags using the boolean OR expression :param not_tags: count stacks not containing these tags, combine multiple tags using the boolean AND expression :param not_tags_any: count stacks not containing these tags, combine multiple tags using the boolean OR expression",39,32
openstack%2Fheat~master~I31d7046f343987ca3803cfc95c189e5c9f6dcc8e,openstack/heat,master,I31d7046f343987ca3803cfc95c189e5c9f6dcc8e,Fix swift key generation in python3,MERGED,2017-02-01 12:54:39.000000000,2017-02-20 00:45:13.000000000,2017-02-20 00:45:13.000000000,"[{'_account_id': 3}, {'_account_id': 8833}, {'_account_id': 10487}]","[{'number': 1, 'created': '2017-02-01 12:54:39.000000000', 'files': ['heat_integrationtests/functional/test_aws_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ff6d5b291ed3c25dbe330548347e9519823bf0ba', 'message': ""Fix swift key generation in python3\n\nThe swift key used in aws tests is generated in a fashion that doesn't\nwork in python3. This fixes it.\n\nChange-Id: I31d7046f343987ca3803cfc95c189e5c9f6dcc8e\n""}]",0,427676,ff6d5b291ed3c25dbe330548347e9519823bf0ba,7,3,1,7385,,,0,"Fix swift key generation in python3

The swift key used in aws tests is generated in a fashion that doesn't
work in python3. This fixes it.

Change-Id: I31d7046f343987ca3803cfc95c189e5c9f6dcc8e
",git fetch https://review.opendev.org/openstack/heat refs/changes/76/427676/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/functional/test_aws_stack.py'],1,ff6d5b291ed3c25dbe330548347e9519823bf0ba,py3-encode-tests, str(random.getrandbits(256)).encode('ascii')).hexdigest()[:32], str(random.getrandbits(256))).hexdigest()[:32],1,1
openstack%2Fopenstacksdk~master~Ie67c240e3caa5e100ce07db3862718195c894748,openstack/openstacksdk,master,Ie67c240e3caa5e100ce07db3862718195c894748,"Revert ""Privatize session instance on Proxy subclasses""",ABANDONED,2017-02-17 20:15:25.000000000,2017-02-19 23:21:07.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-17 20:15:25.000000000', 'files': ['openstack/proxy2.py', 'openstack/message/v2/_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/cluster/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/message/v1/_proxy.py', 'openstack/proxy.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/compute/v2/_proxy.py', 'openstack/object_store/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a10fb917e874258d4f3d8621fb61b12cd5287571', 'message': 'Revert ""Privatize session instance on Proxy subclasses""\n\nThis reverts commit 87c253c03f4c931e01d2c26e531902e4f8f89401.\n\nThis broke a number of commands in OSC...\n\nChange-Id: Ie67c240e3caa5e100ce07db3862718195c894748\n'}]",0,435584,a10fb917e874258d4f3d8621fb61b12cd5287571,8,4,1,970,,,0,"Revert ""Privatize session instance on Proxy subclasses""

This reverts commit 87c253c03f4c931e01d2c26e531902e4f8f89401.

This broke a number of commands in OSC...

Change-Id: Ie67c240e3caa5e100ce07db3862718195c894748
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/84/435584/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/proxy2.py', 'openstack/message/v2/_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/cluster/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/message/v1/_proxy.py', 'openstack/proxy.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/compute/v2/_proxy.py', 'openstack/object_store/v1/_proxy.py']",11,a10fb917e874258d4f3d8621fb61b12cd5287571,privatize_proxy_session," account.set_metadata(self.session, metadata) account.delete_metadata(self.session, keys) return _container.Container.list(self.session, **query) res.set_metadata(self.session, metadata) res.delete_metadata(self.session, keys) objs = _obj.Object.list(self.session, res.set_metadata(self.session, metadata) res.delete_metadata(self.session, keys)"," account.set_metadata(self._session, metadata) account.delete_metadata(self._session, keys) return _container.Container.list(self._session, **query) res.set_metadata(self._session, metadata) res.delete_metadata(self._session, keys) objs = _obj.Object.list(self._session, res.set_metadata(self._session, metadata) res.delete_metadata(self._session, keys)",111,112
openstack%2Ftacker~stable%2Fmitaka~Ib208c7d345281329174b8ce210b2a17272fe3a3a,openstack/tacker,stable/mitaka,Ib208c7d345281329174b8ce210b2a17272fe3a3a,Updated from global requirements,MERGED,2016-11-10 09:42:36.000000000,2017-02-19 23:08:28.000000000,2017-02-19 23:08:28.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 10487}, {'_account_id': 16511}]","[{'number': 1, 'created': '2016-11-10 09:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/8a84efab4b925406279c65658dd43a2cc5b8b606', 'message': 'Updated from global requirements\n\nChange-Id: Ib208c7d345281329174b8ce210b2a17272fe3a3a\n'}, {'number': 2, 'created': '2016-12-12 10:17:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/e053fec1bad643c2cc8c8626beca95a1a2f9872d', 'message': 'Updated from global requirements\n\nChange-Id: Ib208c7d345281329174b8ce210b2a17272fe3a3a\n'}, {'number': 3, 'created': '2017-02-17 18:03:58.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tacker/commit/f668fbb0bfa95bde5a51a0ec5b2471c4293cf219', 'message': 'Updated from global requirements\n\nChange-Id: Ib208c7d345281329174b8ce210b2a17272fe3a3a\n'}]",0,396045,f668fbb0bfa95bde5a51a0ec5b2471c4293cf219,14,4,3,11131,,,0,"Updated from global requirements

Change-Id: Ib208c7d345281329174b8ce210b2a17272fe3a3a
",git fetch https://review.opendev.org/openstack/tacker refs/changes/45/396045/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,8a84efab4b925406279c65658dd43a2cc5b8b606,openstack/requirements,"kombu!=4.0.0,>=3.0.25 # BSD",kombu>=3.0.25 # BSD,1,1
openstack%2Frequirements~master~Ie406b3743c296905c8db196797b5c632d4d91dca,openstack/requirements,master,Ie406b3743c296905c8db196797b5c632d4d91dca,Add Ocata branch remove Liberty,MERGED,2017-02-15 02:20:30.000000000,2017-02-19 21:18:20.000000000,2017-02-19 21:18:20.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-15 02:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/7ae44154fdbd6749930eb7c66a9d48568ecd2e61', 'message': 'Add Ocata branch remove Liberty\n\nChnage the branches looked at to match the current tracked releases.\n\nChange-Id: Ie406b3743c296905c8db196797b5c632d4d91dca\n'}, {'number': 2, 'created': '2017-02-16 21:26:33.000000000', 'files': ['tools/grep-all.sh'], 'web_link': 'https://opendev.org/openstack/requirements/commit/a4edd9d11a333b75d8d638e411f2ba3a01bc32ab', 'message': 'Add Ocata branch remove Liberty\n\nChange the branches looked at to match the current tracked releases.\n\nChange-Id: Ie406b3743c296905c8db196797b5c632d4d91dca\n'}]",2,434025,a4edd9d11a333b75d8d638e411f2ba3a01bc32ab,19,6,2,12898,,,0,"Add Ocata branch remove Liberty

Change the branches looked at to match the current tracked releases.

Change-Id: Ie406b3743c296905c8db196797b5c632d4d91dca
",git fetch https://review.opendev.org/openstack/requirements refs/changes/25/434025/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/grep-all.sh'],1,7ae44154fdbd6749930eb7c66a9d48568ecd2e61,feature/enhance-grep-all, origin/stable/ocata, origin/stable/liberty,1,1
openstack%2Fcinder~master~Ib1d1e31239f408ed1af9ac2c625d517aa9f6ff4c,openstack/cinder,master,Ib1d1e31239f408ed1af9ac2c625d517aa9f6ff4c,Fix duplicate lvs2 entry in rootwrap volume filter,MERGED,2017-02-12 22:38:35.000000000,2017-02-19 20:14:40.000000000,2017-02-13 21:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 15386}, {'_account_id': 16941}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-12 22:38:35.000000000', 'files': ['etc/cinder/rootwrap.d/volume.filters'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b05cf6a007b12d9af0f4470b942da4f8b12db8c4', 'message': 'Fix duplicate lvs2 entry in rootwrap volume filter\n\nlooks like it should be lvdisplay2, fails to load otherwise\n\nChange-Id: Ib1d1e31239f408ed1af9ac2c625d517aa9f6ff4c\n'}]",0,432794,b05cf6a007b12d9af0f4470b942da4f8b12db8c4,41,7,1,14288,,,0,"Fix duplicate lvs2 entry in rootwrap volume filter

looks like it should be lvdisplay2, fails to load otherwise

Change-Id: Ib1d1e31239f408ed1af9ac2c625d517aa9f6ff4c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/432794/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/cinder/rootwrap.d/volume.filters'],1,b05cf6a007b12d9af0f4470b942da4f8b12db8c4,fix-dup-rootwrap-filter,"lvdisplay2: EnvFilter, env, root, LC_ALL=C, LVM_SUPPRESS_FD_WARNINGS=, lvdisplay","lvs2: EnvFilter, env, root, LC_ALL=C, LVM_SUPPRESS_FD_WARNINGS=, lvdisplay",1,1
openstack%2Ftripleo-heat-templates~master~I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc,openstack/tripleo-heat-templates,master,I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc,Support for ScaleIO Cinder backend,ABANDONED,2016-12-17 14:33:13.000000000,2017-02-19 19:29:33.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 20775}, {'_account_id': 24245}]","[{'number': 1, 'created': '2016-12-17 14:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f29c0e1c1aae1d900f574f315a01000fae9e109e', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\n\nThis depends on puppet-cinder Related-Bug: 1650571\n https://bugs.launchpad.net/puppet-cinder/+bug/1650571\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 2, 'created': '2016-12-17 19:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4461718b4070d144ee28214892ad878fd38c8799', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\n\nThis depends on puppet-cinder Related-Bug: 1650571\n https://bugs.launchpad.net/puppet-cinder/+bug/1650571\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 3, 'created': '2016-12-17 19:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/32d9404a543941b1e5a7bfd37990815e00febb87', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\n\nThis depends on puppet-cinder Related-Bug: 1650571\n https://bugs.launchpad.net/puppet-cinder/+bug/1650571\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 4, 'created': '2016-12-17 21:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fba2c134e76f6c1d0f46b5062d1015b996013dfd', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\nDepends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 5, 'created': '2017-01-10 08:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/def60204757677e3d42bd3c9bfd4e33e8a9459ca', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\nDepends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 6, 'created': '2017-01-10 15:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6185be40d11e431da2666be4e91346dd35c4a893', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\nDepends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 7, 'created': '2017-01-10 15:31:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55c5a133c094d1f5d58e0376f819b694bc2a968e', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\nDepends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}, {'number': 8, 'created': '2017-01-11 07:47:51.000000000', 'files': ['capabilities-map.yaml', 'environments/cinder-scaleio-config.yaml', 'puppet/extraconfig/pre_deploy/controller/cinder-scaleio.yaml', 'puppet/controller-role.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c29be2ce81094d7f7f865f0e7991941b40cd06a8', 'message': 'Support for ScaleIO Cinder backend\n\nEMC ScaleIO Block Storage as cinder backend.\n\nCloses-Bug: 1650428\nDepends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e\n\nChange-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc\n'}]",4,412089,c29be2ce81094d7f7f865f0e7991941b40cd06a8,29,4,8,24245,,,0,"Support for ScaleIO Cinder backend

EMC ScaleIO Block Storage as cinder backend.

Closes-Bug: 1650428
Depends-on: Id77d2981fbfd16155f67d9c4e52e3869e68e805e

Change-Id: I2258f766e6e54241ce0d54ad7bed2e2d0d6e04fc
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/412089/6 && git format-patch -1 --stdout FETCH_HEAD,"['capabilities-map.yaml', 'environments/cinder-scaleio-config.yaml', 'puppet/extraconfig/pre_deploy/controller/cinder-scaleio.yaml', 'puppet/controller-role.yaml']",4,f29c0e1c1aae1d900f574f315a01000fae9e109e,bug/1650428, - cinder_scaleio_data # Optionally provided by ControllerExtraConfigPre,,149,0
openstack%2Fmagnum~stable%2Focata~I124670a3f141b7fd691f111d71d57467a6f82909,openstack/magnum,stable/ocata,I124670a3f141b7fd691f111d71d57467a6f82909,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-17 20:32:53.000000000,2017-02-19 18:44:50.000000000,2017-02-19 18:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-17 20:32:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6c9ef6768248984f2c232020e0d71e8d4b88f7de', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I124670a3f141b7fd691f111d71d57467a6f82909\n'}]",0,435592,6c9ef6768248984f2c232020e0d71e8d4b88f7de,6,2,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: I124670a3f141b7fd691f111d71d57467a6f82909
",git fetch https://review.opendev.org/openstack/magnum refs/changes/92/435592/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6c9ef6768248984f2c232020e0d71e8d4b88f7de,create-ocata, pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} -U {opts} {packages}, pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -U {opts} {packages},1,1
openstack%2Fmagnum~stable%2Focata~Ieccd4ae695760f0b7f09c6c628fa577767e8ecaa,openstack/magnum,stable/ocata,Ieccd4ae695760f0b7f09c6c628fa577767e8ecaa,Update .gitreview for stable/ocata,MERGED,2017-02-17 20:32:52.000000000,2017-02-19 18:44:32.000000000,2017-02-19 18:44:32.000000000,"[{'_account_id': 3}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-17 20:32:52.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8fd822ac90dc5c79511ed016324bafbcf26e44af', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: Ieccd4ae695760f0b7f09c6c628fa577767e8ecaa\n'}]",0,435591,8fd822ac90dc5c79511ed016324bafbcf26e44af,6,2,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: Ieccd4ae695760f0b7f09c6c628fa577767e8ecaa
",git fetch https://review.opendev.org/openstack/magnum refs/changes/91/435591/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,8fd822ac90dc5c79511ed016324bafbcf26e44af,create-ocata,defaultbranch=stable/ocata,,1,0
openstack%2Fmagnum-ui~master~Iabe73955372a8fad646ba38ff49db06da2c9c855,openstack/magnum-ui,master,Iabe73955372a8fad646ba38ff49db06da2c9c855,Imported Translations from Zanata,MERGED,2017-02-17 06:05:56.000000000,2017-02-19 17:42:43.000000000,2017-02-19 17:42:43.000000000,"[{'_account_id': 3}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-17 06:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/97d7bc4e7b9cab62d1fe5c6f265049c06649046c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Iabe73955372a8fad646ba38ff49db06da2c9c855\n'}, {'number': 2, 'created': '2017-02-19 06:08:26.000000000', 'files': ['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/zh_CN/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/magnum-ui/commit/de09078ec8e9ea18d475dd118e9c41bfab60eb17', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Iabe73955372a8fad646ba38ff49db06da2c9c855\n'}]",0,435259,de09078ec8e9ea18d475dd118e9c41bfab60eb17,8,2,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Iabe73955372a8fad646ba38ff49db06da2c9c855
",git fetch https://review.opendev.org/openstack/magnum-ui refs/changes/59/435259/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/ja/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po']",2,97d7bc4e7b9cab62d1fe5c6f265049c06649046c,zanata/translations,"""Project-Id-Version: Magnum UI Release Notes 2.2.1\n""""POT-Creation-Date: 2017-02-16 10:02+0000\n""""PO-Revision-Date: 2017-02-16 02:26+0000\n""msgid ""2.2.0"" msgstr ""2.2.0"" msgid ""Ocata Series Release Notes"" msgstr ""Ocata Serie Releasenotes"" msgid ""Ocata release summary."" msgstr ""Ocata Release Zusammenfassung."" ""We removed the Xstatic packages from requirements, as those are not needed "" ""anymore. Horizon includes what it needs."" msgstr """" ""Xstatic Pakete wurden aus den Anforderungen entfernt, denn sie werden nicht "" ""mehr benötigt. Horizon beinhaltet alles, was es braucht."" msgid """"","""Project-Id-Version: Magnum UI Release Notes 2.1.1\n""""POT-Creation-Date: 2017-02-13 19:28+0000\n""""PO-Revision-Date: 2017-02-01 11:03+0000\n""msgid ""2.1.0-108"" msgstr ""2.1.0-108"" ",21,11
openstack%2Fcinder~master~Ie886124e626e4883b81d5a1ba203621f104e5ef7,openstack/cinder,master,Ie886124e626e4883b81d5a1ba203621f104e5ef7,netapp image cache cleaning start thresholds does not work,MERGED,2016-09-15 03:28:51.000000000,2017-02-19 17:19:44.000000000,2017-02-12 23:30:52.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 15386}, {'_account_id': 16941}, {'_account_id': 18444}, {'_account_id': 21517}, {'_account_id': 22248}, {'_account_id': 23602}]","[{'number': 1, 'created': '2016-09-15 03:28:51.000000000', 'files': ['cinder/volume/drivers/netapp/dataontap/nfs_base.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/da7a668137f6b955d69e87aa6e8b1cde50855fc8', 'message': 'netapp image cache cleaning start thresholds does not work\n\nFix avl_percent value.\n\nChange-Id: Ie886124e626e4883b81d5a1ba203621f104e5ef7\nCloses-Bug: #1623739\n'}]",0,370524,da7a668137f6b955d69e87aa6e8b1cde50855fc8,63,12,1,7096,,,0,"netapp image cache cleaning start thresholds does not work

Fix avl_percent value.

Change-Id: Ie886124e626e4883b81d5a1ba203621f104e5ef7
Closes-Bug: #1623739
",git fetch https://review.opendev.org/openstack/cinder refs/changes/24/370524/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/netapp/dataontap/nfs_base.py'],1,da7a668137f6b955d69e87aa6e8b1cde50855fc8,bug/1623739, avl_percent = int((float(total_avl) / total_size) * 100), avl_percent = int((total_avl / total_size) * 100),1,1
openstack%2Fpython-openstackclient~master~I89732c49e73ac5a789fdbe19536389f7e93ac0e6,openstack/python-openstackclient,master,I89732c49e73ac5a789fdbe19536389f7e93ac0e6,Remove quota set workaround for SDK <0.9.13,MERGED,2017-02-17 19:28:57.000000000,2017-02-19 16:58:01.000000000,2017-02-19 16:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 22218}]","[{'number': 1, 'created': '2017-02-17 19:28:57.000000000', 'files': ['openstackclient/common/quota.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b399b0406ce4c55345c8f11064a5e85ef73dd8fd', 'message': 'Remove quota set workaround for SDK <0.9.13\n\nChange-Id: I89732c49e73ac5a789fdbe19536389f7e93ac0e6\n'}]",0,435574,b399b0406ce4c55345c8f11064a5e85ef73dd8fd,11,4,1,970,,,0,"Remove quota set workaround for SDK <0.9.13

Change-Id: I89732c49e73ac5a789fdbe19536389f7e93ac0e6
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/74/435574/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/common/quota.py'],1,b399b0406ce4c55345c8f11064a5e85ef73dd8fd,quota-set-borken-again," network_client.update_quota( project, **network_kwargs)"," if hasattr(_quota.Quota, 'allow_get'): # TODO(huanxuan): Remove this block once the fixed # SDK Quota class is the minimum required version. # This is expected to be SDK release 0.9.13 res = network_client._get_resource( _quota.Quota, project, **network_kwargs) if any([res._body.dirty, res._header.dirty]): request = res._prepare_request(prepend_key=True) # remove the id in the body if 'id' in request.body[res.resource_key]: del request.body[res.resource_key]['id'] if res.patch_update: response = network_client.session.patch( request.uri, endpoint_filter=res.service, json=request.body, headers=request.headers ) else: response = network_client.session.put( request.uri, endpoint_filter=res.service, json=request.body, headers=request.headers ) res._translate_response(response, has_body=True) else: network_client.update_quota( project, **network_kwargs)",3,30
openstack%2Fnetworking-sfc~master~Iebf370beaedcee490a98200af046504e88ee71a3,openstack/networking-sfc,master,Iebf370beaedcee490a98200af046504e88ee71a3,Optimize unit test test_sfc_extensions,ABANDONED,2017-02-17 00:48:03.000000000,2017-02-19 16:57:52.000000000,,"[{'_account_id': 3}, {'_account_id': 9396}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14037}]","[{'number': 1, 'created': '2017-02-17 00:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/386813b0a1d609dedea8b91bbab1de606851f9c2', 'message': 'Optimize unit test test_sfc_extensions\n\nReplace set function calls with set litrals could improve the\nperformance, the litral construction is faster.\n\nChange-Id: Iebf370beaedcee490a98200af046504e88ee71a3\n'}, {'number': 2, 'created': '2017-02-17 23:49:03.000000000', 'files': ['networking_sfc/tests/tempest_plugin/tests/api/test_sfc_extensions.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/d192bbb353a9b9afe3d83a9856679b4ac81c51b4', 'message': 'Optimize unit test test_sfc_extensions\n\nReplace set function calls with set litrals could improve the\nperformance, the litral construction is faster.\n\nChange-Id: Iebf370beaedcee490a98200af046504e88ee71a3\n'}]",1,435178,d192bbb353a9b9afe3d83a9856679b4ac81c51b4,13,5,2,14037,,,0,"Optimize unit test test_sfc_extensions

Replace set function calls with set litrals could improve the
performance, the litral construction is faster.

Change-Id: Iebf370beaedcee490a98200af046504e88ee71a3
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/78/435178/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/tests/tempest_plugin/tests/api/test_sfc_extensions.py'],1,386813b0a1d609dedea8b91bbab1de606851f9c2,optimize_extensions," {pg['port_pairs']}, {m['port_pairs']} {pg['port_pairs']}, {m['port_pairs']} {pc['flow_classifiers']} {m['flow_classifiers']} {pc['flow_classifiers']} {m['flow_classifiers']}"," set(pg['port_pairs']), set(m['port_pairs']) set(pg['port_pairs']), set(m['port_pairs']) set(pc['flow_classifiers']) set(m['flow_classifiers']) set(pc['flow_classifiers']) set(m['flow_classifiers'])",8,8
openstack%2Fopenstacksdk~master~I4b6d7471f2d5cf4296c9c1244cef94e17f176799,openstack/openstacksdk,master,I4b6d7471f2d5cf4296c9c1244cef94e17f176799,Fix the service profile meta info test,MERGED,2017-02-18 21:46:45.000000000,2017-02-19 16:08:31.000000000,2017-02-19 16:08:31.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-18 21:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bc23fff21765faf5c5e3e2a36f4148f034cb519e', 'message': 'Fix the service profile meta info test\n\nAt some point metainfo was changed to meta_info\nand the functional test was not updated.\n\nPartial-bug: #1665495\n\nChange-Id: I4b6d7471f2d5cf4296c9c1244cef94e17f176799\n'}, {'number': 2, 'created': '2017-02-19 15:39:23.000000000', 'files': ['openstack/tests/functional/network/v2/test_service_profile.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7bfae5d76be175a743631dea74613813ceba4df9', 'message': 'Fix the service profile meta info test\n\nAt some point metainfo was changed to meta_info\nand the functional test was not updated.\n\nPartial-bug: #1665495\n\nChange-Id: I4b6d7471f2d5cf4296c9c1244cef94e17f176799\n'}]",0,435734,7bfae5d76be175a743631dea74613813ceba4df9,12,3,2,8736,,,0,"Fix the service profile meta info test

At some point metainfo was changed to meta_info
and the functional test was not updated.

Partial-bug: #1665495

Change-Id: I4b6d7471f2d5cf4296c9c1244cef94e17f176799
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/34/435734/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_service_profile.py'],1,bc23fff21765faf5c5e3e2a36f4148f034cb519e,bug/1665495," cls.assertIs(cls.METAINFO, service_profiles.meta_info) service_profiles.meta_info) self.assertEqual(self.METAINFO, service_profiles.meta_info) metainfos = [f.meta_info for f in self.conn.network.service_profiles()]"," cls.assertIs(cls.METAINFO, service_profiles.metainfo) service_profiles.metainfo) self.assertEqual(self.METAINFO, service_profiles.metainfo) metainfos = [f.metainfo for f in self.conn.network.service_profiles()]",4,4
openstack%2Fopenstacksdk~master~Icef5cb0ce2816a10e990945af0baf60e215b1d28,openstack/openstacksdk,master,Icef5cb0ce2816a10e990945af0baf60e215b1d28,Fix the agent add remove test,MERGED,2017-02-18 18:11:07.000000000,2017-02-19 16:06:04.000000000,2017-02-19 16:06:04.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-18 18:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e9b3cdcd1aefa5adadab4ebb9d413804a8208467', 'message': 'Fix the agent add remove test\n\nThese tests should use the proxy first off and there must of been\nsome api change in the past that broke the test.\n\nPartial-bug: #1665495\n\nChange-Id: Icef5cb0ce2816a10e990945af0baf60e215b1d28\n'}, {'number': 2, 'created': '2017-02-18 19:21:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7e4f4d519e3cd22c27312a7dae43f7015ec0ff9b', 'message': 'Fix the agent add remove test\n\nThese tests should use the proxy first off and there must of been\nsome api change in the past that broke the test.\n\nPartial-bug: #1665495\n\nChange-Id: Icef5cb0ce2816a10e990945af0baf60e215b1d28\n'}, {'number': 3, 'created': '2017-02-18 19:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3f09d47789f0e74116ea372d083a6e7fcac32150', 'message': 'Fix the agent add remove test\n\nThese tests should use the proxy first off and there must of been\nsome api change in the past that broke the test.\n\nPartial-bug: #1665495\n\nChange-Id: Icef5cb0ce2816a10e990945af0baf60e215b1d28\n'}, {'number': 4, 'created': '2017-02-19 15:38:35.000000000', 'files': ['openstack/tests/functional/network/v2/test_agent_add_remove_router.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e5a07834f8c6d7e15bb63d711d58b345663b33cc', 'message': 'Fix the agent add remove test\n\nThese tests should use the proxy first off and there must of been\nsome api change in the past that broke the test.\n\nPartial-bug: #1665495\n\nChange-Id: Icef5cb0ce2816a10e990945af0baf60e215b1d28\n'}]",0,435723,e5a07834f8c6d7e15bb63d711d58b345663b33cc,19,4,4,8736,,,0,"Fix the agent add remove test

These tests should use the proxy first off and there must of been
some api change in the past that broke the test.

Partial-bug: #1665495

Change-Id: Icef5cb0ce2816a10e990945af0baf60e215b1d28
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/23/435723/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/network/v2/test_agent_add_remove_router.py'],1,e9b3cdcd1aefa5adadab4ebb9d413804a8208467,bug/1665495," ROUTER = None cls.ROUTER = cls.conn.network.create_router(name=cls.ROUTER_NAME) assert isinstance(cls.ROUTER, router.Router) rot = cls.conn.network.delete_router(cls.ROUTER, sot = self.conn.network.add_router_to_agent(self.AGENT, self.ROUTER) sot = self.conn.network.remove_router_from_agent(self.conn.session, self.ROUTER) rots = self.conn.network.agent_hosted_routers(self.AGENT.id) self.assertIn(self.ROUTER, routers) rots = self.conn.network.agent_hosted_routers(self.AGENT.id) self.assertNotIn(self.ROUTER, routers)"," ROUTER_ID = None AGENT_ID = None rot = cls.conn.network.create_router(name=cls.ROUTER_NAME) assert isinstance(rot, router.Router) cls.ROUTER_ID = rot.id cls.AGENT_ID = cls.AGENT.id rot = cls.conn.network.delete_router(cls.ROUTER_ID, sot = self.AGENT.add_router_to_agent(self.conn.session, router_id=self.ROUTER_ID) sot = self.AGENT.remove_router_from_agent(self.conn.session, router_id=self.ROUTER_ID) rots = self.conn.network.agent_hosted_routers(self.AGENT_ID) self.assertIn(self.ROUTER_ID, routers) rots = self.conn.network.agent_hosted_routers(self.AGENT_ID) self.assertNotIn(self.ROUTER_ID, routers)",11,15
openstack%2Fpuppet-panko~stable%2Focata~I2619293f3cc6363d1edaa791a8672424cdc76aed,openstack/puppet-panko,stable/ocata,I2619293f3cc6363d1edaa791a8672424cdc76aed,Set the user and domain name to default,MERGED,2017-02-19 12:39:09.000000000,2017-02-19 15:40:53.000000000,2017-02-19 15:40:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-19 12:39:09.000000000', 'files': ['spec/classes/panko_keystone_authtoken_spec.rb', 'releasenotes/notes/set-user-domain-default-3da3f24dfe35e9c0.yaml', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-panko/commit/ff0c94f731f368b0d0720cffe98d8a6804f62c3b', 'message': 'Set the user and domain name to default\n\nChange-Id: I2619293f3cc6363d1edaa791a8672424cdc76aed\n(cherry picked from commit e9922a82a78ab9bd8d43d1c7bd5625f85f828fd6)\n'}]",0,435764,ff0c94f731f368b0d0720cffe98d8a6804f62c3b,6,3,1,3153,,,0,"Set the user and domain name to default

Change-Id: I2619293f3cc6363d1edaa791a8672424cdc76aed
(cherry picked from commit e9922a82a78ab9bd8d43d1c7bd5625f85f828fd6)
",git fetch https://review.opendev.org/openstack/puppet-panko refs/changes/64/435764/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/panko_keystone_authtoken_spec.rb', 'releasenotes/notes/set-user-domain-default-3da3f24dfe35e9c0.yaml', 'manifests/keystone/authtoken.pp']",3,ff0c94f731f368b0d0720cffe98d8a6804f62c3b,," $user_domain_name = 'Default', $project_domain_name = 'Default',"," $user_domain_name = $::os_service_default, $project_domain_name = $::os_service_default,",7,4
openstack%2Fnova~master~I87d5497307fa1610b4c340fe562d65cd25a93feb,openstack/nova,master,I87d5497307fa1610b4c340fe562d65cd25a93feb,Handle oslo.serialization type error and binascii error,MERGED,2017-01-17 20:08:33.000000000,2017-02-19 15:39:44.000000000,2017-01-20 01:50:22.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 13692}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17292}, {'_account_id': 20040}, {'_account_id': 22255}]","[{'number': 1, 'created': '2017-01-17 20:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ccf7a23969ec0e11452eccce0ec8fbe34ef27d5', 'message': 'Handle oslo.serialization type error and binascii error\n\nA upcoming oslo.serialization release will unify these\nbut for now just handle both so that the release of that\nlibrary can proceed with breaking nova.\n\nChange-Id: I87d5497307fa1610b4c340fe562d65cd25a93feb\n'}, {'number': 2, 'created': '2017-01-17 21:27:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/62ccab940621d9d728ef490384808c9a025163ee', 'message': 'Handle oslo.serialization type error and binascii error\n\nA upcoming oslo.serialization release will unify these\nbut for now just handle both so that the release of that\nlibrary can proceed without breaking nova.\n\nChange-Id: I87d5497307fa1610b4c340fe562d65cd25a93feb\n'}, {'number': 3, 'created': '2017-01-18 00:34:23.000000000', 'files': ['nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/161799edaab21ea7b4f577766764768fa6c39e5d', 'message': 'Handle oslo.serialization type error and binascii error\n\nA upcoming oslo.serialization release will unify these\nbut for now just handle both so that the release of that\nlibrary can proceed without breaking nova.\n\nChange-Id: I87d5497307fa1610b4c340fe562d65cd25a93feb\n'}]",5,421482,161799edaab21ea7b4f577766764768fa6c39e5d,57,19,3,1297,,,0,"Handle oslo.serialization type error and binascii error

A upcoming oslo.serialization release will unify these
but for now just handle both so that the release of that
library can proceed without breaking nova.

Change-Id: I87d5497307fa1610b4c340fe562d65cd25a93feb
",git fetch https://review.opendev.org/openstack/nova refs/changes/82/421482/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/api.py'],1,4ccf7a23969ec0e11452eccce0ec8fbe34ef27d5,," base64utils.decode_as_bytes(user_data) except (base64.binascii.Error, TypeError): # TODO(harlowja): reduce the above exceptions caught to # only type error once we get a new oslo.serialization # release that captures and makes only one be output.", # TODO(gcb): Just use base64utils.decode_as_bytes(user_data) # when https://review.openstack.org/#/c/410797/ is merged and # ensure oslo.serialization >=2.15.0 in Nova requirements.txt. if six.PY3: base64utils.decode_as_bytes(user_data) else: base64.decodestring(user_data) except base64.binascii.Error:,5,8
openstack%2Ftripleo-quickstart-extras~master~If5d13648a9b631d710a0fb205a037e3f0d14fb5e,openstack/tripleo-quickstart-extras,master,If5d13648a9b631d710a0fb205a037e3f0d14fb5e,remove duplicate network_environment from undercloud-deploy role,MERGED,2017-02-16 14:00:20.000000000,2017-02-19 15:33:52.000000000,2017-02-19 15:33:52.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 10969}, {'_account_id': 11589}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-02-16 14:00:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/855ea4e46030f65dbd6b9a1aabb0000b593fa3d7', 'message': 'remove duplicate network_environment from undercloud-deploy role\n\nThis is not being used in this role.\n\nChange-Id: If5d13648a9b631d710a0fb205a037e3f0d14fb5e\n'}, {'number': 2, 'created': '2017-02-17 11:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b51dc1c0de530406d3eba489cf12d3f18ca87c1e', 'message': 'remove duplicate network_environment from undercloud-deploy role\n\nThis is not being used in this role. Also, the relevant documentation\nwas moved from the undercloud-deploy role to the overcloud-prep-config\nrole.\n\nChange-Id: If5d13648a9b631d710a0fb205a037e3f0d14fb5e\n'}, {'number': 3, 'created': '2017-02-17 14:46:09.000000000', 'files': ['roles/overcloud-prep-config/README.md', 'roles/undercloud-deploy/README.md', 'roles/undercloud-deploy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c38e2d0a21f0089e16567d1ac42a16f0f1ca4556', 'message': 'remove duplicate network_environment from undercloud-deploy role\n\nThis is not being used in this role. Also, the relevant documentation\nwas moved from the undercloud-deploy role to the overcloud-prep-config\nrole.\n\nChange-Id: If5d13648a9b631d710a0fb205a037e3f0d14fb5e\n'}]",0,434924,c38e2d0a21f0089e16567d1ac42a16f0f1ca4556,28,7,3,10873,,,0,"remove duplicate network_environment from undercloud-deploy role

This is not being used in this role. Also, the relevant documentation
was moved from the undercloud-deploy role to the overcloud-prep-config
role.

Change-Id: If5d13648a9b631d710a0fb205a037e3f0d14fb5e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/24/434924/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/undercloud-deploy/defaults/main.yml'],1,855ea4e46030f65dbd6b9a1aabb0000b593fa3d7,remove-duplicate,,"network_environment_args: ExternalNetCidr: ""{{ undercloud_external_network_cidr }}"" ExternalAllocationPools: > [{'start': '{{ undercloud_external_network_cidr|nthhost(4) }}', 'end': '{{ undercloud_external_network_cidr|nthhost(250) }}'}] NeutronExternalNetworkBridge: """" ControlPlaneSubnetCidr: ""{{ undercloud_network_cidr|ipaddr('prefix') }}"" ControlPlaneDefaultRoute: ""{{ undercloud_network_cidr|nthhost(1) }}"" EC2MetadataIp: ""{{ undercloud_network_cidr|nthhost(1) }}"" DnsServers: [ '{{ external_network_cidr|nthhost(1) }}' ] ",0,11
openstack%2Fkolla~master~If7a5ece045d9e108dc8b07bcbc254018f4f13932,openstack/kolla,master,If7a5ece045d9e108dc8b07bcbc254018f4f13932,[TEST] test patch https://review.openstack.org/#/c/413861,ABANDONED,2017-02-16 14:57:17.000000000,2017-02-19 14:51:58.000000000,,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 24013}]","[{'number': 1, 'created': '2017-02-16 14:57:17.000000000', 'files': ['docker/macros.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1e1fae5c8b7019ad78d29cb6beb50bc61ac5dc5b', 'message': '[TEST] test patch https://review.openstack.org/#/c/413861\n\nChange-Id: If7a5ece045d9e108dc8b07bcbc254018f4f13932\n'}]",0,434954,1e1fae5c8b7019ad78d29cb6beb50bc61ac5dc5b,6,3,1,7488,,,0,"[TEST] test patch https://review.openstack.org/#/c/413861

Change-Id: If7a5ece045d9e108dc8b07bcbc254018f4f13932
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/434954/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/macros.j2'],1,1e1fae5c8b7019ad78d29cb6beb50bc61ac5dc5b,, pip --no-cache-dir install --upgrade{{ ' ' }}," PIP=pip \ && if [ -x /var/lib/kolla/venv/bin/pip ]; then PIP=""/var/lib/kolla/venv/bin/pip""; fi \ && ${PIP} --no-cache-dir install --upgrade{{ ' ' }}",1,3
openstack%2Fpuppet-panko~master~I2619293f3cc6363d1edaa791a8672424cdc76aed,openstack/puppet-panko,master,I2619293f3cc6363d1edaa791a8672424cdc76aed,Set the user and domain name to default,MERGED,2017-02-16 13:56:33.000000000,2017-02-19 12:39:10.000000000,2017-02-19 00:14:35.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-16 13:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-panko/commit/c11e0921ea36fa5ce94a9dd6a5c0aa8990c99272', 'message': 'Set the user and domain name to default\n\nChange-Id: I2619293f3cc6363d1edaa791a8672424cdc76aed\n'}, {'number': 2, 'created': '2017-02-16 15:02:10.000000000', 'files': ['spec/classes/panko_keystone_authtoken_spec.rb', 'releasenotes/notes/set-user-domain-default-3da3f24dfe35e9c0.yaml', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-panko/commit/e9922a82a78ab9bd8d43d1c7bd5625f85f828fd6', 'message': 'Set the user and domain name to default\n\nChange-Id: I2619293f3cc6363d1edaa791a8672424cdc76aed\n'}]",0,434920,e9922a82a78ab9bd8d43d1c7bd5625f85f828fd6,39,3,2,6924,,,0,"Set the user and domain name to default

Change-Id: I2619293f3cc6363d1edaa791a8672424cdc76aed
",git fetch https://review.opendev.org/openstack/puppet-panko refs/changes/20/434920/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/set-user-domain-default-3da3f24dfe35e9c0.yaml', 'manifests/keystone/authtoken.pp']",2,c11e0921ea36fa5ce94a9dd6a5c0aa8990c99272,," $user_domain_name = 'Default', $project_domain_name = 'Default',"," $user_domain_name = $::os_service_default, $project_domain_name = $::os_service_default,",5,2
openstack%2Fnova~master~I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1,openstack/nova,master,I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1,Add service_token for nova-neutron interaction,MERGED,2016-12-13 21:07:07.000000000,2017-02-19 12:27:37.000000000,2017-01-18 02:24:40.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 19590}, {'_account_id': 20040}, {'_account_id': 23310}]","[{'number': 1, 'created': '2016-12-13 21:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b16feaf0e00e06708fd6701c27d4defec42ce210', 'message': '[WIP] Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 2, 'created': '2016-12-15 17:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0fe7885ad33b362ddf098dfa9175370f05df70b', 'message': '[WIP] Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 3, 'created': '2016-12-15 18:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d273e13b5cf303d8ccabee4da59d1b04c1d6fa7', 'message': '[WIP] Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 4, 'created': '2016-12-16 16:12:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b6287cb7cc632da31bcd65893057c36d79c1870', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 5, 'created': '2016-12-20 18:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86ef2f0eb92ee666bed7e404829d173d12f39233', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 6, 'created': '2017-01-06 20:11:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ed13abb445d090c52b5e951f406d33eaef05acbe', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 7, 'created': '2017-01-09 18:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58abf3e37379d5f32d965e45512762b3bee4ccfc', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 8, 'created': '2017-01-09 20:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df6d148cb2b51a92deb1b22fda7e85660d2e03e2', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 9, 'created': '2017-01-10 22:06:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/81db6ddcd37a91e6944d00d0efd6194501e56004', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 10, 'created': '2017-01-10 22:18:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f8ebbaddec8ed7934511cd3b4353bebfa93b706', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 11, 'created': '2017-01-11 18:09:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f59ca1dfd29c642c40653e0a8f32c04359b2447', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}, {'number': 12, 'created': '2017-01-12 20:45:33.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'releasenotes/notes/validate-expired-user-tokens-57a265cb4ee4ba6f.yaml', 'nova/conf/service_token.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/596e8de5ebd261b2b6610830641d23728b006f53', 'message': 'Add service_token for nova-neutron interaction\n\nService token will be passed along with user token to communicate with\nservices when dealing with long running tasks like live migration.\n\nThis change addresses adding service_token to the request when nova\nrequests neutron session.\n\nImplements: blueprint use-service-tokens\nChange-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1\n'}]",16,410394,596e8de5ebd261b2b6610830641d23728b006f53,151,17,12,19590,,,0,"Add service_token for nova-neutron interaction

Service token will be passed along with user token to communicate with
services when dealing with long running tasks like live migration.

This change addresses adding service_token to the request when nova
requests neutron session.

Implements: blueprint use-service-tokens
Change-Id: I5e6d6dfeda3673d38bab0bc692c50ca74eb90fc1
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/410394/8 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,b16feaf0e00e06708fd6701c27d4defec42ce210,bp/use-service-tokens,"from keystoneauth1 import service_token if CONF.service_user.send_service_user_token: service_auth = ks_loading.load_auth_from_conf_options( CONF, group=nova.conf.service_token.SERVICE_USER_GROUP) user_auth = context.get_auth_plugin() auth_plugin = service_token.ServiceTokenAuthWrapper( user_auth=user_auth, service_auth=service_auth) else: auth_plugin = context.get_auth_plugin()", auth_plugin = context.get_auth_plugin(),12,1
openstack%2Fsenlin~master~I5111666eeb907e174df0cc59c09d72cd0884955b,openstack/senlin,master,I5111666eeb907e174df0cc59c09d72cd0884955b,"Fix doc command error, command miss cluster name",MERGED,2017-02-19 03:27:25.000000000,2017-02-19 12:04:44.000000000,2017-02-19 12:04:44.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-19 03:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5f793e3443fc38257e98deed908e77559c16bd88', 'message': 'Doc command error, command miss cluster name\nThe ""openstack cluster policy binding list --sort enabled:desc""\n\nChange-Id: I5111666eeb907e174df0cc59c09d72cd0884955b\nSigned-off-by: chenyb4 <cybing4@gmail.com>\n'}, {'number': 2, 'created': '2017-02-19 04:14:47.000000000', 'files': ['doc/source/user/bindings.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/cc515a77afd9897d7f06475b615037e201d5f278', 'message': 'Fix doc command error, command miss cluster name\n\nChange-Id: I5111666eeb907e174df0cc59c09d72cd0884955b\nSigned-off-by: chenyb4 <cybing4@gmail.com>\n'}]",2,435745,cc515a77afd9897d7f06475b615037e201d5f278,10,3,2,23517,,,0,"Fix doc command error, command miss cluster name

Change-Id: I5111666eeb907e174df0cc59c09d72cd0884955b
Signed-off-by: chenyb4 <cybing4@gmail.com>
",git fetch https://review.opendev.org/openstack/senlin refs/changes/45/435745/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/bindings.rst'],1,5f793e3443fc38257e98deed908e77559c16bd88,fix_doc_policy_bind_error, $ openstack cluster policy binding list --sort enabled:desc c3, $ openstack cluster policy binding list --sort enabled:desc,1,1
openstack%2Fec2-api~master~I9a6846585db45b4861e3d3eec6b42f20f870bb6c,openstack/ec2-api,master,I9a6846585db45b4861e3d3eec6b42f20f870bb6c,describe-security-groups by name in default VPC mode describes security groups in default vpc only,ABANDONED,2017-02-13 08:17:41.000000000,2017-02-19 12:00:13.000000000,,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 19065}]","[{'number': 1, 'created': '2017-02-13 08:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/29ad845cd972e88e360abd6f8f8b5f2190c93be3', 'message': 'describe-security-groups by name in default VPC mode describes\nsecurity groups in default vpc only\n\nChange-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c\n'}, {'number': 2, 'created': '2017-02-13 12:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e78a917e08752087509790fa08437b104944434b', 'message': 'describe-security-groups by name in default VPC mode describes\nsecurity groups in default vpc only\n\nChange-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c\n'}, {'number': 3, 'created': '2017-02-13 16:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/85c3d65b68ba839d3b9325665175b7926c047bf9', 'message': 'describe-security-groups by name in default VPC mode describes\nsecurity groups in default vpc only\n\nChange-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c\n'}, {'number': 4, 'created': '2017-02-13 16:27:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/22deeacc68acfca08cfb810bbd19fc9f34337dd4', 'message': 'describe-security-groups by name in default VPC mode describes\nsecurity groups in default vpc only\n\nChange-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c\n'}, {'number': 5, 'created': '2017-02-14 11:33:05.000000000', 'files': ['ec2api/api/common.py', 'ec2api/api/security_group.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/92dbadfe7023276f9eac1f6a94ef668c2ee6613d', 'message': 'describe-security-groups by name in default VPC mode describes\nsecurity groups in default vpc only\n\nChange-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c\n'}]",5,432908,92dbadfe7023276f9eac1f6a94ef668c2ee6613d,19,4,5,19065,,,0,"describe-security-groups by name in default VPC mode describes
security groups in default vpc only

Change-Id: I9a6846585db45b4861e3d3eec6b42f20f870bb6c
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/08/432908/3 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/common.py', 'ec2api/api/security_group.py']",2,29ad845cd972e88e360abd6f8f8b5f2190c93be3,," def check_selective_describe(self, context, os_item_name, item): item_in_vpc = True if CONF.disable_ec2_classic: default_vpc_id = ec2utils.get_default_vpc(context)['id'] item_in_vpc = item['vpc_id'] == default_vpc_id return (self.selective_describe and not (os_item_name in self.names or (item and item['id'] in self.ids and item_in_vpc))) ",,15,3
openstack%2Ftripleo-heat-templates~stable%2Focata~I966b96c50224656b152045c97aa23b9495618a18,openstack/tripleo-heat-templates,stable/ocata,I966b96c50224656b152045c97aa23b9495618a18,Switch to net-config-multinode,MERGED,2017-02-18 21:32:20.000000000,2017-02-19 11:51:29.000000000,2017-02-19 11:51:29.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-18 21:32:20.000000000', 'files': ['ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0d348d1777ef9cfcba74d0767790ea7f5cdeeed7', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n(cherry picked from commit 4061dfe790f2614f253a6f0e14bf3dd056e20ce1)\n""}]",0,435733,0d348d1777ef9cfcba74d0767790ea7f5cdeeed7,12,2,1,3153,,,0,"Switch to net-config-multinode

Because of this bug:
https://bugs.launchpad.net/tripleo/+bug/1661412

We are unable to upgrade from Newton.
Until we figure this out, let's re-enable the previous SoftwareConfig.

Change-Id: I966b96c50224656b152045c97aa23b9495618a18
(cherry picked from commit 4061dfe790f2614f253a6f0e14bf3dd056e20ce1)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/33/435733/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml']",4,0d348d1777ef9cfcba74d0767790ea7f5cdeeed7,scenario001/upgrade, OS::TripleO::Controller::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Compute::Net::SoftwareConfig: ../common/net-config-multinode.yaml, OS::TripleO::Controller::Net::SoftwareConfig: ../common/net-config-multinode-os-net-config.yaml OS::TripleO::Compute::Net::SoftwareConfig: ../common/net-config-multinode-os-net-config.yaml,8,8
openstack%2Ftripleo-quickstart-extras~master~If85ffcba3f02131bb931eff465a23f4233ec4877,openstack/tripleo-quickstart-extras,master,If85ffcba3f02131bb931eff465a23f4233ec4877,Don't output the PublicVip separately to /etc/hosts,MERGED,2017-02-15 07:16:37.000000000,2017-02-19 09:51:42.000000000,2017-02-19 09:51:41.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-02-15 07:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/26688341e9a0d08de366d6117d9d44188d6453a9', 'message': ""Don't output the PublicVip separately to /etc/hosts\n\nThis is not necessary, as the relevant entries are already in the\nHostsEntry output of the heat stack. This has been available for a\nwhile, so for releases from newton and above I'm disabling this output.\n\nChange-Id: If85ffcba3f02131bb931eff465a23f4233ec4877\n""}, {'number': 2, 'created': '2017-02-16 16:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2b2e58182b80787f0336c0f739ab5dbd6f566018', 'message': ""Don't output the PublicVip separately to /etc/hosts\n\nThis is not necessary, as the relevant entries are already in the\nHostsEntry output of the heat stack. This has been available for a\nwhile, so for releases from newton and above I'm disabling this output.\n\nChange-Id: If85ffcba3f02131bb931eff465a23f4233ec4877\n""}, {'number': 3, 'created': '2017-02-18 05:34:40.000000000', 'files': ['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0207b6010b4524cf40420582e95ad167b5ff9c1e', 'message': ""Don't output the PublicVip separately to /etc/hosts\n\nThis is not necessary, as the relevant entries are already in the\nHostsEntry output of the heat stack. This has been available for a\nwhile, so for releases from newton and above I'm disabling this output.\n\nChange-Id: If85ffcba3f02131bb931eff465a23f4233ec4877\n""}]",0,434105,0207b6010b4524cf40420582e95ad167b5ff9c1e,25,8,3,10873,,,0,"Don't output the PublicVip separately to /etc/hosts

This is not necessary, as the relevant entries are already in the
HostsEntry output of the heat stack. This has been available for a
while, so for releases from newton and above I'm disabling this output.

Change-Id: If85ffcba3f02131bb931eff465a23f4233ec4877
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/05/434105/3 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-deploy/templates/overcloud-deploy-post.sh.j2'],1,26688341e9a0d08de366d6117d9d44188d6453a9,overcloud-vip,{% if enable_pacemaker|bool and release == 'mitaka' %},{% if enable_pacemaker|bool %},1,1
openstack%2Fnetworking-midonet~master~Ie3ebc4c2035f8c17910895236874327d5fff70c5,openstack/networking-midonet,master,Ie3ebc4c2035f8c17910895236874327d5fff70c5,Remove unused logging import,MERGED,2017-02-17 06:00:03.000000000,2017-02-19 09:43:23.000000000,2017-02-19 09:11:55.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 9925}]","[{'number': 1, 'created': '2017-02-17 06:00:03.000000000', 'files': ['midonet/neutron/db/logging_resource_db.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/562ed7a1d4154f95c1f183865aa4f3de1c0fe669', 'message': 'Remove unused logging import\n\nChange-Id: Ie3ebc4c2035f8c17910895236874327d5fff70c5\n'}]",0,435253,562ed7a1d4154f95c1f183865aa4f3de1c0fe669,16,4,1,19935,,,0,"Remove unused logging import

Change-Id: Ie3ebc4c2035f8c17910895236874327d5fff70c5
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/53/435253/1 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/db/logging_resource_db.py'],1,562ed7a1d4154f95c1f183865aa4f3de1c0fe669,,,from oslo_log import log as loggingLOG = logging.getLogger(__name__) ,0,3
openstack%2Fsenlin~master~Ie5924b285d386c974b326430e05243549db919f1,openstack/senlin,master,Ie5924b285d386c974b326430e05243549db919f1,Remove unused pylintrc,MERGED,2017-02-17 07:48:13.000000000,2017-02-19 09:29:05.000000000,2017-02-19 09:29:05.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-17 07:48:13.000000000', 'files': ['pylintrc'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a7b875260f34eb58fa2cd0ee66ed004a97143f56', 'message': ""Remove unused pylintrc\n\nWe didn't use it,so clean it.\n\nChange-Id: Ie5924b285d386c974b326430e05243549db919f1\n""}]",0,435286,a7b875260f34eb58fa2cd0ee66ed004a97143f56,8,4,1,21550,,,0,"Remove unused pylintrc

We didn't use it,so clean it.

Change-Id: Ie5924b285d386c974b326430e05243549db919f1
",git fetch https://review.opendev.org/openstack/senlin refs/changes/86/435286/1 && git format-patch -1 --stdout FETCH_HEAD,['pylintrc'],1,a7b875260f34eb58fa2cd0ee66ed004a97143f56,,,"[Messages Control] # W0511: TODOs in code comments are fine. # W0142: *args and **kwargs are fine. # W0622: Redefining id is fine. disable-msg=W0511,W0142,W0622 [Basic] # Variable names can be 1 to 31 characters long, with lowercase and underscores variable-rgx=[a-z_][a-z0-9_]{0,30}$ # Argument names can be 2 to 31 characters long, with lowercase and underscores argument-rgx=[a-z_][a-z0-9_]{1,30}$ # Method names should be at least 3 characters long # and be lowecased with underscores method-rgx=[a-z_][a-z0-9_]{2,50}$ # Module names matching nova-* are ok (files in bin/) module-rgx=(([a-z_][a-z0-9_]*)|([A-Z][a-zA-Z0-9]+)|(nova-[a-z0-9_-]+))$ # Don't require docstrings on tests. no-docstring-rgx=((__.*__)|([tT]est.*)|setUp|tearDown)$ # Exclude variable names that conflict with debugger bad-names=c [Design] max-public-methods=100 min-public-methods=0 max-args=6 ",0,29
openstack%2Fnetworking-midonet~stable%2Focata~I201213e4c2d87bcdfd327425ef0c01f88e38314e,openstack/networking-midonet,stable/ocata,I201213e4c2d87bcdfd327425ef0c01f88e38314e,Update tox_install for stable/ocata,MERGED,2017-02-15 01:18:06.000000000,2017-02-19 09:28:19.000000000,2017-02-19 09:28:19.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 748}]","[{'number': 1, 'created': '2017-02-15 01:18:06.000000000', 'files': ['tools/tox_install_project.sh'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/5b9b5d019785086873bf432f91b4ad07989c306d', 'message': 'Update tox_install for stable/ocata\n\nChange-Id: I201213e4c2d87bcdfd327425ef0c01f88e38314e\n'}]",0,434005,5b9b5d019785086873bf432f91b4ad07989c306d,13,3,1,6854,,,0,"Update tox_install for stable/ocata

Change-Id: I201213e4c2d87bcdfd327425ef0c01f88e38314e
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/05/434005/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install_project.sh'],1,5b9b5d019785086873bf432f91b4ad07989c306d,create-ocata,BRANCH_NAME=stable/ocata,BRANCH_NAME=master,1,1
openstack%2Fnetworking-midonet~stable%2Focata~Ia5a153fc1303774f5013d2080b97e113db1180ee,openstack/networking-midonet,stable/ocata,Ia5a153fc1303774f5013d2080b97e113db1180ee,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-14 15:30:06.000000000,2017-02-19 09:28:13.000000000,2017-02-19 09:28:13.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 748}, {'_account_id': 6854}]","[{'number': 1, 'created': '2017-02-14 15:30:06.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/4617658489b33344fb06dff878bd8bb525676b55', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: Ia5a153fc1303774f5013d2080b97e113db1180ee\n'}]",0,433712,4617658489b33344fb06dff878bd8bb525676b55,15,4,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: Ia5a153fc1303774f5013d2080b97e113db1180ee
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/12/433712/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,4617658489b33344fb06dff878bd8bb525676b55,create-ocata,install_command = {toxinidir}/tools/tox_install.sh -c {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages},install_command = {toxinidir}/tools/tox_install.sh -c {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fdragonflow~master~I82993143c0d4485b89a2ba90e52f3d6dc61e1113,openstack/dragonflow,master,I82993143c0d4485b89a2ba90e52f3d6dc61e1113,Fix identation l3_proactive unit test,ABANDONED,2017-02-14 09:11:50.000000000,2017-02-19 08:42:07.000000000,,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 11159}]","[{'number': 1, 'created': '2017-02-14 09:11:50.000000000', 'files': ['dragonflow/tests/unit/test_l3_proactive_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/25b885401629ce202229a7c0bee49d4381ccbf6d', 'message': 'Fix identation l3_proactive unit test\n\nChange-Id: I82993143c0d4485b89a2ba90e52f3d6dc61e1113\n'}]",0,433512,25b885401629ce202229a7c0bee49d4381ccbf6d,5,3,1,18347,,,0,"Fix identation l3_proactive unit test

Change-Id: I82993143c0d4485b89a2ba90e52f3d6dc61e1113
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/12/433512/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/tests/unit/test_l3_proactive_app.py'],1,25b885401629ce202229a7c0bee49d4381ccbf6d,l3-bug-test1," self.router.inner_obj['routes'] = [ {""destination"": ""10.100.0.0/16"", ""nexthop"": ""10.0.0.8""}]"," self.router.inner_obj['routes'] = [{""destination"": ""10.100.0.0/16"", ""nexthop"": ""10.0.0.8""}]",3,2
openstack%2Fcinder~master~I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5,openstack/cinder,master,I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5,Updated from global requirements,MERGED,2017-02-10 04:43:13.000000000,2017-02-19 08:18:41.000000000,2017-02-11 23:09:59.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16422}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21990}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 23613}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}, {'_account_id': 24863}]","[{'number': 1, 'created': '2017-02-10 04:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/208cdb8af54bf31e23561b8ff15814a525f4948f', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 2, 'created': '2017-02-10 05:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb73c13ae1ae5dd5d53ca253b858d4a02634b299', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 3, 'created': '2017-02-10 09:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/004cc014e0288df2330d4a2f18a9d833fe50d059', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 4, 'created': '2017-02-10 12:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3d8213271b6f772f140d98de928fb681d1a1e3f', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 5, 'created': '2017-02-11 00:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d304b8f866ebecc4b5ba8ddb980f9e7ea209f469', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 6, 'created': '2017-02-11 02:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a99a3c85677a533d37c88fce4632c56cdd45edfe', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 7, 'created': '2017-02-11 17:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd0bef8f3a1dade2bee42c9a76ac3b60ef2075dd', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}, {'number': 8, 'created': '2017-02-11 17:40:56.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/399295fce29048854cd8c85a2178d89738276f57', 'message': 'Updated from global requirements\n\nChange-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5\n'}]",0,431882,399295fce29048854cd8c85a2178d89738276f57,160,37,8,11131,,,0,"Updated from global requirements

Change-Id: I4856be1a6d1ba4cc3adeebbb1adac70c1ab5dca5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/82/431882/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,208cdb8af54bf31e23561b8ff15814a525f4948f,openstack/requirements,tempest>=14.0.0 # Apache-2.0,tempest>=12.1.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~I640226851e5bb268a6961ac6ab52d97a8860f150,openstack/openstack-manuals,master,I640226851e5bb268a6961ac6ab52d97a8860f150,[cli-ref] Update python-magnumclient to 2.5.0,MERGED,2017-02-18 22:42:11.000000000,2017-02-19 07:46:33.000000000,2017-02-19 07:46:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-18 22:42:11.000000000', 'files': ['doc/cli-reference/source/magnum.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eff615ccd3d175af815574029620f3d8630bddea', 'message': '[cli-ref] Update python-magnumclient to 2.5.0\n\nChange-Id: I640226851e5bb268a6961ac6ab52d97a8860f150\n'}]",0,435739,eff615ccd3d175af815574029620f3d8630bddea,6,2,1,10497,,,0,"[cli-ref] Update python-magnumclient to 2.5.0

Change-Id: I640226851e5bb268a6961ac6ab52d97a8860f150
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/435739/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/source/magnum.rst'],1,eff615ccd3d175af815574029620f3d8630bddea,cli-reference,This chapter documents :command:`magnum` version ``2.5.0``.,This chapter documents :command:`magnum` version ``2.4.0``.,1,1
openstack%2Fnova~master~I7141eef6a1c85ec6d6e8ee170911572535652978,openstack/nova,master,I7141eef6a1c85ec6d6e8ee170911572535652978,Add query parameters white list for server list/detail,MERGED,2016-12-08 11:25:36.000000000,2017-02-19 07:39:15.000000000,2017-01-18 23:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}, {'_account_id': 21279}, {'_account_id': 21784}]","[{'number': 1, 'created': '2016-12-08 11:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aa000f4224309a94e48599bbf103ce0f14c97d91', 'message': 'Add query parameter schema for server list/detail in microversion 2.1\n\nThis patch enables a white list for query parameter in microversion 2.1.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 2, 'created': '2016-12-09 08:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1923bb813c7164e6e2862f559f227b18e3809204', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 3, 'created': '2016-12-09 10:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4022cf3a88fe5cdb1c2c44327ee5727963e313be', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 4, 'created': '2016-12-09 12:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90d87a44f883723bbd5c1e3cf196da378bd95430', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 5, 'created': '2016-12-09 14:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/56e09a6f47ebe3ec9889274cf01ee1b5f6c1a471', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 6, 'created': '2016-12-13 14:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/673ad84eac6b95dbcae4420e621e8f4ee5fba995', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 7, 'created': '2016-12-14 11:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ec08bf66eac967ce3766ce5d24a997775beea82e', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 8, 'created': '2016-12-16 03:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a2e520dbdf62f761065efa3bba0cb320ddf9dc4', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 9, 'created': '2016-12-16 06:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/694edf962d5bf53895f7c04fca3bb8002c22c9bd', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 10, 'created': '2016-12-16 08:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/83b851593a48ec4eaa031a624de103398613d232', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 11, 'created': '2016-12-22 07:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb87ae9a1f15d040c2de26f849db9f1465cf1301', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 12, 'created': '2016-12-26 01:41:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc13d32dc03086434eb04bb3c8dd75953972a448', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 13, 'created': '2016-12-26 01:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b9ac07625978d3a9889b730d07c7839bf7c7d2a', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 14, 'created': '2016-12-26 08:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68178791b69d1b669acaa4cf4e620b39990c9eb6', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 15, 'created': '2016-12-26 09:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45b1d4144ae36fa265ad862b22a2fd950af584ac', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 16, 'created': '2016-12-27 03:12:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e029d7408affb7ae52e066c767f951b0c417a01', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 17, 'created': '2016-12-27 06:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/80c755dd732b958484b3552cabaf062aa543b65e', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 18, 'created': '2016-12-27 07:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7b0162c6f3674601147731f49236c6247e80dcf9', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 19, 'created': '2016-12-28 09:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e0c5cdb935977fb45b2a62f41553240a114d35e9', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 20, 'created': '2016-12-29 04:01:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92835feb04891f5c0a424d9834d13037dcc389e4', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 21, 'created': '2016-12-29 06:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/852d34c1bd30a5ae0c5a155eb6e59df78348b838', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 22, 'created': '2016-12-29 07:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f5a06fd60fdf6f8488e3914abd0181989aae65f4', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 23, 'created': '2016-12-29 08:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cc5e552d745e7f4aea99f54287c33fb9124ec2bb', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 24, 'created': '2017-01-04 00:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a1dddd1725408f80d8efcfc4f26fc03ada41cdef', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 25, 'created': '2017-01-04 12:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9494eabdc7c6af23bf00a3b7c019a60dc7ab8e3a', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 26, 'created': '2017-01-04 13:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/01929647916a536d5b02006378440cc82cc14ae6', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 27, 'created': '2017-01-05 01:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/470dd0490b7a0c5cc897a5c070d55d96495ac658', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 28, 'created': '2017-01-05 10:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7068128654a98ace61f32b7f0c94884b4cd9aa3b', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 29, 'created': '2017-01-05 12:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a086294a1899568982d0fa1c2863fb95547927de', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 30, 'created': '2017-01-06 02:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f038bea34ff20674b6fe8a1048876bc05b34e49', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 31, 'created': '2017-01-06 08:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a84231193f75e4e2e6572c0f49e7859ac6db435', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 32, 'created': '2017-01-08 02:44:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e4480d67f363355417f70da9c23db16fb81514f2', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 33, 'created': '2017-01-08 06:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18ce528d97bf55bfdac3fb9350170547aaf68223', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 34, 'created': '2017-01-10 02:36:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b48f90376c5bf4b243ce9fa47b30bbb172e09e80', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 35, 'created': '2017-01-11 03:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f195fc77ce453358d0747f74200c3d5107e9f0f4', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 36, 'created': '2017-01-11 08:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7a955343d9e6d88cd6af48ef8bcd677955cf2c00', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 37, 'created': '2017-01-11 10:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d78389cbbf51800cbbb2bf915019d2c2c5d77caf', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 38, 'created': '2017-01-11 11:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3edbd2736ebad0f78a44a214abf5204276ee5a5', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 39, 'created': '2017-01-14 01:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60d90a1fcdf846db88d3e531c559a00bbbe297b2', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 40, 'created': '2017-01-17 14:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8341f7cc241dbf4f3ec3574b41b170c3b90cbebc', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}, {'number': 41, 'created': '2017-01-17 15:54:30.000000000', 'files': ['nova/api/validation/validators.py', 'nova/api/openstack/compute/schemas/servers.py', 'nova/tests/unit/api/openstack/compute/test_serversV21.py', 'nova/tests/unit/test_api_validation.py', 'nova/api/openstack/compute/servers.py', 'nova/api/validation/__init__.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/134c19faeb12ed81f13d84e83d96872d58843d72', 'message': 'Add query parameters white list for server list/detail\n\nThis patch enables a white list for query parameter.\nThe parameters, which are out of white list, will be ignored.\n\nThe sort_key still accepts open value. The later patch will add white\nlist to it.\n\nCo-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>\n\npartial implement of bp add-whitelist-for-server-list-filter-sort-parameters\n\nChange-Id: I7141eef6a1c85ec6d6e8ee170911572535652978\n'}]",135,408571,134c19faeb12ed81f13d84e83d96872d58843d72,498,26,41,5754,,,0,"Add query parameters white list for server list/detail

This patch enables a white list for query parameter.
The parameters, which are out of white list, will be ignored.

The sort_key still accepts open value. The later patch will add white
list to it.

Co-Authored-By: Zhenyu Zheng <zhengzhenyu@huawei.com>

partial implement of bp add-whitelist-for-server-list-filter-sort-parameters

Change-Id: I7141eef6a1c85ec6d6e8ee170911572535652978
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/408571/40 && git format-patch -1 --stdout FETCH_HEAD,"['nova/api/validation/validators.py', 'nova/api/openstack/compute/schemas/servers.py', 'nova/compute/api.py', 'nova/api/openstack/compute/servers.py']",4,aa000f4224309a94e48599bbf103ce0f14c97d91,bp/add-whitelist-for-server-list-filter-sort-parameters," @validation.query_params_schema(schema_servers.query_parameters_v21, ""2.1"", ""2.1"") @validation.query_params_schema(schema_servers.query_parameters_v21, ""2.1"", ""2.1"")"," # Verify the value of the 'name' option is a correct regex. if 'name' in search_opts: try: re.compile(search_opts['name']) except re.error: msg = _(""The regex for server name is incorrect"") raise exc.HTTPBadRequest(explanation=msg) ",42,10
openstack%2Fgnocchi~master~I3a7d73881c12b502dd3ec9ce535524b907871ed2,openstack/gnocchi,master,I3a7d73881c12b502dd3ec9ce535524b907871ed2,Remove unused logging import,MERGED,2017-02-16 08:22:35.000000000,2017-02-19 07:15:04.000000000,2017-02-19 07:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-16 08:22:35.000000000', 'files': ['gnocchi/storage/ceph.py', 'gnocchi/storage/s3.py', 'gnocchi/storage/incoming/s3.py', 'gnocchi/storage/swift.py', 'gnocchi/storage/incoming/swift.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/cc5c9f3e0d3b967dcf60c1b85063bfd72cf7f8c1', 'message': 'Remove unused logging import\n\nChange-Id: I3a7d73881c12b502dd3ec9ce535524b907871ed2\n'}]",0,434724,cc5c9f3e0d3b967dcf60c1b85063bfd72cf7f8c1,18,4,1,19935,,,0,"Remove unused logging import

Change-Id: I3a7d73881c12b502dd3ec9ce535524b907871ed2
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/24/434724/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/ceph.py', 'gnocchi/storage/s3.py', 'gnocchi/storage/incoming/s3.py', 'gnocchi/storage/swift.py', 'gnocchi/storage/incoming/swift.py']",5,cc5c9f3e0d3b967dcf60c1b85063bfd72cf7f8c1,,,from oslo_log import logLOG = log.getLogger(__name__) ,0,15
openstack%2Fsenlin~master~I3696ca7d786764e025465670c0eb26a6f2cc023e,openstack/senlin,master,I3696ca7d786764e025465670c0eb26a6f2cc023e,revise dumping event notifications,ABANDONED,2017-02-19 03:22:48.000000000,2017-02-19 06:38:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-19 03:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3197f50e32fefd38002199a7a150e1ecf3f6d246', 'message': 'revise dumping event notifications\n\nTo prevent dumping duplicated event notifications to rabbitMQ, we will only\ndump it at the beginning of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471\n\nand at the end of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492\n\nChange-Id: I3696ca7d786764e025465670c0eb26a6f2cc023e\n'}, {'number': 2, 'created': '2017-02-19 05:20:12.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/tempest/functional/test_scaling_policy.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/bfae46e3c135cb3d24d9a2763f1192078608c603', 'message': 'revise dumping event notifications\n\nTo prevent dumping duplicated event notifications to rabbitMQ, we will only\ndump it at the beginning of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471\n\nand at the end of processing the action:\nhttps://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492\n\nChange-Id: I3696ca7d786764e025465670c0eb26a6f2cc023e\n'}]",0,435744,bfae46e3c135cb3d24d9a2763f1192078608c603,5,1,2,23401,,,0,"revise dumping event notifications

To prevent dumping duplicated event notifications to rabbitMQ, we will only
dump it at the beginning of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n471

and at the end of processing the action:
https://git.openstack.org/cgit/openstack/senlin/tree/senlin/engine/actions/base.py#n492

Change-Id: I3696ca7d786764e025465670c0eb26a6f2cc023e
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/435744/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/cluster_action.py', 'senlin/engine/actions/base.py']",3,3197f50e32fefd38002199a7a150e1ecf3f6d246,revise-event-dump," self.data['reason'] = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason}"," reason = _(""Failed policy '%(name)s': %(reason)s"" ) % {'name': name, 'reason': reason} EVENT.error(self, consts.PHASE_ERROR, reason)",27,21
openstack%2Foslo.messaging~master~I1a5882d3fe0189ab3e651155681a1410c37d8a82,openstack/oslo.messaging,master,I1a5882d3fe0189ab3e651155681a1410c37d8a82,Updated from global requirements,MERGED,2017-01-20 01:53:40.000000000,2017-02-19 06:04:23.000000000,2017-02-19 06:04:23.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2017-01-20 01:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/657021f65c1768be4736f8075282b437830b71ce', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 2, 'created': '2017-01-23 23:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/adb382ae55ba06046b49ef4d88c0e122f91d0010', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 3, 'created': '2017-01-26 10:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e423998392ee4c240200284cc0c51ace6045633a', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 4, 'created': '2017-01-28 11:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e26a4f7a39ffa227e52219c6f9e4b21fde98c59c', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 5, 'created': '2017-02-01 13:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/0846c913d395ceecdc2d24cdd2b16f9b7760540e', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 6, 'created': '2017-02-08 17:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4504bfdad3e52c08c19448c9140b0cb9bfa70fe8', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 7, 'created': '2017-02-10 05:57:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8898dfa2ee4889aa5deeb21093e10c2b9de8ed8b', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 8, 'created': '2017-02-10 09:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a680561798834d02789ca98ac63125b265d94484', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 9, 'created': '2017-02-11 00:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c8b293c98e7621ee31534311a4a4ab9ec2edcae4', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 10, 'created': '2017-02-11 00:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6b78d538b72fb37a798bfc07af27ff847034747a', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 11, 'created': '2017-02-15 01:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/adb7e663c4d457edf6c48d49c6ef71c6b8a5811c', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 12, 'created': '2017-02-15 14:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a2cc1e2abd72125b8054e543ca75f23f93db1316', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 13, 'created': '2017-02-16 20:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4296f26c7b4788b6d120584f184cb06fc7f7c763', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}, {'number': 14, 'created': '2017-02-16 23:17:37.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3e727ea71581e81d6b62e1d9cf5e90e68d7646ee', 'message': 'Updated from global requirements\n\nChange-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82\n'}]",0,422964,3e727ea71581e81d6b62e1d9cf5e90e68d7646ee,61,3,14,11131,,,0,"Updated from global requirements

Change-Id: I1a5882d3fe0189ab3e651155681a1410c37d8a82
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/64/422964/13 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,657021f65c1768be4736f8075282b437830b71ce,openstack/requirements,"mox3!=0.19.0,>=0.7.0 # Apache-2.0",mox3>=0.7.0 # Apache-2.0,1,1
openstack%2Farch-wg~master~Ib33e78ff25636430677a6d487110f23424620b7b,openstack/arch-wg,master,Ib33e78ff25636430677a6d487110f23424620b7b,Add proposal for nova-compute-api,MERGED,2016-12-15 22:47:19.000000000,2017-02-19 05:08:16.000000000,2017-01-11 08:36:11.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 308}, {'_account_id': 782}, {'_account_id': 970}, {'_account_id': 1063}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 10511}, {'_account_id': 11564}]","[{'number': 1, 'created': '2016-12-15 22:47:19.000000000', 'files': ['proposals/nova-compute-api.rst'], 'web_link': 'https://opendev.org/openstack/arch-wg/commit/7086083711b0c1ecdb66d62429aa986220dd2602', 'message': 'Add proposal for nova-compute-api\n\nChange-Id: Ib33e78ff25636430677a6d487110f23424620b7b\n'}]",6,411527,7086083711b0c1ecdb66d62429aa986220dd2602,19,10,1,6488,,,0,"Add proposal for nova-compute-api

Change-Id: Ib33e78ff25636430677a6d487110f23424620b7b
",git fetch https://review.opendev.org/openstack/arch-wg refs/changes/27/411527/1 && git format-patch -1 --stdout FETCH_HEAD,['proposals/nova-compute-api.rst'],1,7086083711b0c1ecdb66d62429aa986220dd2602,,"Introduction ============ In the beginning there was Nova. It included volumes, networking, hypervisors, and scheduling. Since then, Nova components have either been replaced (nova-network with Neutron) or forklifted out and enhanced (Cinder). In so doing, interfaces were defined for how Nova would continue to make use of these now-external services, but nova-compute, the place where the proverbial rubber meets the road, was left inside Nova. This meant that agents for Cinder and Neutron had to interact with nova-compute through the high level message bus, despite being right on the same physical machine in many (but not all) cases. Likewise, some cases take advantage of that, and require operator cooperation in configuring for certain drivers. This has led to implementation details leaking all over the API's that these services use to interact. Neutron and Nova do a sort of haphazard dance to plug ports in, and Cinder has drivers which require locking files on the local filesystem a certain way. These implementation details are leaking into public API's because it turns out nova-compute is actually a shared service that should not belong to any of the three services, and which should define a more clear API which Nova, Cinder, and Neutron, should be able to use to access the physical resources of machines from an equal footing. proposed next steps =================== * Produce an accurate analysis on the current state of nova-compute's interaction with other OpenStack services. * Produce a cross-project spec for moving nova-compute out of Nova and defining an API for it that meets the needs of all other projects. ",,33,0
openstack%2Fnetworking-sfc~master~I701d03a7aa6459d03062856ae77046990b5a257c,openstack/networking-sfc,master,I701d03a7aa6459d03062856ae77046990b5a257c,Symmetric Chain Support for OVS driver and agent,MERGED,2016-12-14 01:08:03.000000000,2017-02-19 04:59:13.000000000,2017-02-19 04:59:13.000000000,"[{'_account_id': 3}, {'_account_id': 9375}, {'_account_id': 9396}, {'_account_id': 10068}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14037}, {'_account_id': 14605}, {'_account_id': 19948}, {'_account_id': 20434}, {'_account_id': 20560}, {'_account_id': 21798}, {'_account_id': 23142}]","[{'number': 1, 'created': '2016-12-14 01:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/02b40fa21b45184ee03a0ee46befee69022c93f4', 'message': 'Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable SF chain.\n* Create unit test and tempest cases for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 2, 'created': '2016-12-14 22:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/064665e44dee3544094a63150010f13de62a3c50', 'message': 'Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable SF chain.\n* Create unit test and tempest cases for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 3, 'created': '2017-01-31 19:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/9936148899f20fccec47bf4dd6e8ab925cf2ac4a', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 4, 'created': '2017-02-01 23:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/8c61c4a808f3292bf484ac9b620146816564cd7d', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 5, 'created': '2017-02-03 22:23:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/8503435091e80e7fdecd759258ccde76a0f16459', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 6, 'created': '2017-02-09 23:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/a7a159a2878a8ae2a802590a248ba507648669d1', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 7, 'created': '2017-02-09 23:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/77b9d25e19dcd0f348d903d3d4cc48e4b468f346', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 8, 'created': '2017-02-14 00:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/f0e37803ddddb102c1e1ddc325489b59dc770484', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 9, 'created': '2017-02-14 08:06:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/a7e076ef5a971f72369a1ea957236d92b1ae4588', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 10, 'created': '2017-02-15 11:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/202849c662207a93d69defbe610a8cf18ce2e350', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nImplements: blueprint symmetric-port-chain-ovs-agent\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 11, 'created': '2017-02-15 11:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/a2cb01900a71d70e3566a12046ea39ad1869dee3', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nImplements: blueprint symmetric-port-chain-ovs-agent\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 12, 'created': '2017-02-17 20:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/254a914f66a3c32018640bf63062971793a708a1', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nImplements: blueprint symmetric-port-chain-ovs-agent\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}, {'number': 13, 'created': '2017-02-18 02:02:50.000000000', 'files': ['networking_sfc/tests/unit/db/test_flowclassifier_db.py', 'networking_sfc/services/sfc/common/exceptions.py', 'networking_sfc/tests/unit/services/flowclassifier/drivers/ovs/test_driver.py', 'networking_sfc/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'networking_sfc/services/sfc/drivers/ovs/driver.py', 'networking_sfc/tests/unit/services/sfc/test_plugin.py', 'networking_sfc/db/migration/alembic_migrations/versions/ocata/expand/b3adaf631bab__add_fwd_path_and_in_mac_column.py', 'networking_sfc/services/sfc/driver_manager.py', 'networking_sfc/services/sfc/drivers/dummy/dummy.py', 'networking_sfc/tests/unit/cli/test_port_chain.py', 'networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/tests/unit/extensions/test_sfc.py', 'networking_sfc/services/flowclassifier/drivers/ovs/driver.py', 'networking_sfc/services/sfc/drivers/ovs/db.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py', 'networking_sfc/tests/unit/services/sfc/drivers/ovs/test_driver.py', 'networking_sfc/tests/unit/db/test_sfc_db.py', 'networking_sfc/tests/unit/services/sfc/test_driver_manager.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/dd346d0565857b90683169e7d8c3bd1f592e1af2', 'message': 'Symmetric Chain Support for OVS driver and agent\n\n  Changes for symmetric chain support for OVS driver and agent\n\n* Add fwd_path column in sfc_path_nodes table and in_mac_address\n  column in sfc_portpair_details table in Database.\n* Edit normalize_chain_parameters for parameters update to keep\n  correlation when updating symmetric in extensions/sfc.py\n* Add symmetric chain function in OVS driver and agent to enable\n  SF chain.\n* Create unit test for symmetric chain function\n\nImplements: blueprint symmetric-port-chain-ovs-agent\n\nChange-Id: I701d03a7aa6459d03062856ae77046990b5a257c\nCo-Authored-By: Louis Fourie <louis.fourie@huawei.com>\nCo-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n'}]",74,410482,dd346d0565857b90683169e7d8c3bd1f592e1af2,112,13,13,23142,,,0,"Symmetric Chain Support for OVS driver and agent

  Changes for symmetric chain support for OVS driver and agent

* Add fwd_path column in sfc_path_nodes table and in_mac_address
  column in sfc_portpair_details table in Database.
* Edit normalize_chain_parameters for parameters update to keep
  correlation when updating symmetric in extensions/sfc.py
* Add symmetric chain function in OVS driver and agent to enable
  SF chain.
* Create unit test for symmetric chain function

Implements: blueprint symmetric-port-chain-ovs-agent

Change-Id: I701d03a7aa6459d03062856ae77046990b5a257c
Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>
Co-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/82/410482/3 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/db/migration/alembic_migrations/versions/CONTRACT_HEAD', 'networking_sfc/tests/unit/db/test_flowclassifier_db.py', 'networking_sfc/tests/tempest_plugin/tests/scenario/test_sfc.py', 'networking_sfc/db/migration/alembic_migrations/versions/newton/expand/b3adaf631bab__add_fwd_path_and_in_mac_column.py', 'networking_sfc/extensions/sfc.py', 'networking_sfc/tests/unit/services/flowclassifier/drivers/ovs/test_driver.py', 'networking_sfc/tests/tempest_plugin/tests/api/test_flowclassifier_extensions.py', 'networking_sfc/tests/tempest_plugin/tests/api/test_sfc_extensions.py', 'networking_sfc/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'networking_sfc/services/sfc/drivers/ovs/driver.py', 'networking_sfc/tests/tempest_plugin/tests/api/base.py', 'networking_sfc/tests/unit/cli/test_port_chain.py', 'networking_sfc/db/migration/alembic_migrations/versions/newton/contract/9ddc949e6f23__add_fwd_path_and_in_mac_column.py', 'networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/tests/unit/extensions/test_sfc.py', 'networking_sfc/services/flowclassifier/drivers/ovs/driver.py', 'networking_sfc/services/sfc/drivers/ovs/db.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py', 'networking_sfc/tests/unit/services/sfc/drivers/ovs/test_driver.py', 'networking_sfc/tests/unit/db/test_sfc_db.py', 'networking_sfc/tests/unit/extensions/test_flowclassifier.py']",21,02b40fa21b45184ee03a0ee46befee69022c93f4,bp/symmetric-port-chain-ovs-agent," 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(), 'logical_destination_port': 'unknown', 'logical_destination_port': _uuid(), 'logical_destination_port': _uuid(),",,2145,438
openstack%2Foslo.db~master~I6f4f439928588cff954e749dfa938425892e0931,openstack/oslo.db,master,I6f4f439928588cff954e749dfa938425892e0931,"Establish flush() for ""sub"" facade contexts",MERGED,2017-02-14 16:28:48.000000000,2017-02-19 04:08:37.000000000,2017-02-19 04:08:36.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 11816}]","[{'number': 1, 'created': '2017-02-14 16:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7e528064684ac57187407bf276ecc732bbd83d5e', 'message': 'do the things\n\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 2, 'created': '2017-02-14 17:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7125c798c6aa489e6611a8e86a812162402f6825', 'message': '[wip]: Add flag to allow flush on nested ctx mgr exits\n\nneeds tests\n\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 3, 'created': '2017-02-14 21:55:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/3a818d921c5336ac10cec97cb9a08c2758ec68ca', 'message': 'Establish flush() for nested facade contexts\n\nWhen converting existing session context manager code to\nuse enginefacade, normally a flush() is implicit on\na ""subtransaction"" when it closes.  Enginefacade\nhas not maintained this behavior.  Ideally, this should\nhave been on by default when enginefacade was first\nreleased, but for now add this as a behavioral\noption for projects that require it.\n\nCo-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 4, 'created': '2017-02-15 15:11:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d0086f6f50bfad13659f4d6cb97ec1f2bd394667', 'message': 'Establish flush() for ""sub"" facade contexts\n\nWhen converting existing session context manager code to\nuse enginefacade, normally a flush() is implicit on\na ""subtransaction"" when it closes.  Enginefacade\nhas not maintained this behavior.  Ideally, this should\nhave been on by default when enginefacade was first\nreleased, but for now add this as a behavioral\noption for projects that require it.\n\nCo-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 5, 'created': '2017-02-15 16:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/7c92bdd84299db178373443a766b539c1f44da6b', 'message': 'Establish flush() for ""sub"" facade contexts\n\nWhen converting existing session context manager code to\nuse enginefacade, normally a flush() is implicit on\na ""subtransaction"" when it closes.  Enginefacade\nhas not maintained this behavior.  Ideally, this should\nhave been on by default when enginefacade was first\nreleased, but for now add this as a behavioral\noption for projects that require it.\n\nCo-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 6, 'created': '2017-02-15 17:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/d595158f2aff97be5781684f1add952503352518', 'message': 'Establish flush() for ""sub"" facade contexts\n\nWhen converting existing session context manager code to\nuse enginefacade, normally a flush() is implicit on\na ""subtransaction"" when it closes.  Enginefacade\nhas not maintained this behavior.  Ideally, this should\nhave been on by default when enginefacade was first\nreleased, but for now add this as a behavioral\noption for projects that require it.\n\nCo-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}, {'number': 7, 'created': '2017-02-18 20:45:01.000000000', 'files': ['oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/b430b5858a33a5c22c9595fa8da4830d1e1d6223', 'message': 'Establish flush() for ""sub"" facade contexts\n\nWhen converting existing session context manager code to\nuse enginefacade, normally a flush() is implicit on\na ""subtransaction"" when it closes.  Enginefacade\nhas not maintained this behavior.  Ideally, this should\nhave been on by default when enginefacade was first\nreleased, but for now add this as a behavioral\noption for projects that require it.\n\nCo-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>\nCloses-Bug: #1664643\nChange-Id: I6f4f439928588cff954e749dfa938425892e0931\n'}]",13,433758,b430b5858a33a5c22c9595fa8da4830d1e1d6223,29,6,7,7787,,,0,"Establish flush() for ""sub"" facade contexts

When converting existing session context manager code to
use enginefacade, normally a flush() is implicit on
a ""subtransaction"" when it closes.  Enginefacade
has not maintained this behavior.  Ideally, this should
have been on by default when enginefacade was first
released, but for now add this as a behavioral
option for projects that require it.

Co-authored-by: Mike Bayer <mike_mp@zzzcomputing.com>
Closes-Bug: #1664643
Change-Id: I6f4f439928588cff954e749dfa938425892e0931
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/58/433758/3 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py']",2,7e528064684ac57187407bf276ecc732bbd83d5e,bug/1664643, self.session.flush(),,11,0
openstack%2Fsenlin-dashboard~master~I161a510fe10de61a56783242ab4cc510aeac6e44,openstack/senlin-dashboard,master,I161a510fe10de61a56783242ab4cc510aeac6e44,Update reno for stable/ocata,MERGED,2017-02-16 10:00:39.000000000,2017-02-19 03:55:11.000000000,2017-02-19 03:55:11.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-16 10:00:39.000000000', 'files': ['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/7c15859f73ad8396ad391794b0c4d4fa24d6af30', 'message': 'Update reno for stable/ocata\n\nChange-Id: I161a510fe10de61a56783242ab4cc510aeac6e44\n'}]",0,434789,7c15859f73ad8396ad391794b0c4d4fa24d6af30,7,2,1,22816,,,0,"Update reno for stable/ocata

Change-Id: I161a510fe10de61a56783242ab4cc510aeac6e44
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/89/434789/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst']",2,7c15859f73ad8396ad391794b0c4d4fa24d6af30,reno-ocata, ocata,,7,0
openstack%2Fsenlin~master~Id9895be72b226a74d5cd57a8fc8d0f0adde4a629,openstack/senlin,master,Id9895be72b226a74d5cd57a8fc8d0f0adde4a629,Clean action records after deleting cluster/node,MERGED,2017-02-09 09:16:26.000000000,2017-02-19 02:50:53.000000000,2017-02-19 02:50:53.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-09 09:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2bef6eee53468eccb94058679eb7d60743a5331b', 'message': 'Clean action records after deleting cluster/node\n\nThis patch revises do_delete method of of cluster_action\nand node_action. Now all action records target on deleted\ncluster/node except the on-going CLUSTER/NODE_DELETE\naction will be removed from DB after cluster/node is\ndeleted successfully. The purpose is to prevent action\nhistory increasing too fast.\n\nChange-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629\n'}, {'number': 2, 'created': '2017-02-09 14:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/c8a0f965a0e9f703f3fff38b26ffec0d21439511', 'message': 'Clean action records after deleting cluster/node\n\nThis patch revises do_delete method of of cluster_action\nand node_action. Now all action records target on deleted\ncluster/node except the on-going CLUSTER/NODE_DELETE\naction will be removed from DB after cluster/node is\ndeleted successfully. The purpose is to prevent action\nhistory increasing too fast.\n\nImplements: blueprint improve-action-event\nChange-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629\n'}, {'number': 3, 'created': '2017-02-18 07:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3f83070068a1c66e322418bd4cb070bd7e0cfbdc', 'message': 'Clean action records after deleting cluster/node\n\nThis patch revises do_delete method of of cluster_action\nand node_action. Now all action records target on deleted\ncluster/node except the on-going CLUSTER/NODE_DELETE\naction will be removed from DB after cluster/node is\ndeleted successfully. The purpose is to prevent action\nhistory increasing too fast.\n\nImplements: blueprint improve-action-event\nChange-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629\n'}, {'number': 4, 'created': '2017-02-18 13:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/586d7a952bd5d6022a084ce91fb45ae1e8afc944', 'message': 'Clean action records after deleting cluster/node\n\nThis patch revises do_delete method of of cluster_action\nand node_action. Now all action records target on deleted\ncluster/node except the on-going CLUSTER/NODE_DELETE\naction will be removed from DB after cluster/node is\ndeleted successfully. The purpose is to prevent action\nhistory increasing too fast.\n\nImplements: blueprint improve-action-event\nChange-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629\n'}, {'number': 5, 'created': '2017-02-18 15:03:29.000000000', 'files': ['senlin/engine/actions/node_action.py', 'senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_node_action.py', 'senlin/tests/unit/engine/actions/test_delete.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/969990f6b721bc4d561e4738cf5906c517d0e3c9', 'message': 'Clean action records after deleting cluster/node\n\nThis patch revises do_delete method of of cluster_action\nand node_action. Now all action records target on deleted\ncluster/node except the on-going CLUSTER/NODE_DELETE\naction will be removed from DB after cluster/node is\ndeleted successfully. The purpose is to prevent action\nhistory increasing too fast.\n\nImplements: blueprint improve-action-event\nChange-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629\n'}]",10,431401,969990f6b721bc4d561e4738cf5906c517d0e3c9,25,4,5,22998,,,0,"Clean action records after deleting cluster/node

This patch revises do_delete method of of cluster_action
and node_action. Now all action records target on deleted
cluster/node except the on-going CLUSTER/NODE_DELETE
action will be removed from DB after cluster/node is
deleted successfully. The purpose is to prevent action
history increasing too fast.

Implements: blueprint improve-action-event
Change-Id: Id9895be72b226a74d5cd57a8fc8d0f0adde4a629
",git fetch https://review.opendev.org/openstack/senlin refs/changes/01/431401/5 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/objects/action.py', 'senlin/engine/actions/cluster_action.py', 'senlin/engine/actions/node_action.py', 'senlin/db/api.py', 'senlin/tests/unit/engine/actions/test_delete.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/db/sqlalchemy/api.py']",7,2bef6eee53468eccb94058679eb7d60743a5331b,bp/improve-action-event,"def action_delete_by_target(context, target, action=None, action_excluded=None, status=None, if action and action_excluded: raise exception.NotSupport( _(""action and action_excluded cannot be specified "" ""both."")) if action_excluded: q = q.filter(~models.Action.action.in_(action_excluded)) if status: q = q.filter(models.Action.status.in_(status))","def action_delete_by_target(context, target, action=None, status=None, if status: q = q.filter(models.Action.status.in_(status))",58,6
openstack%2Fneutron~master~Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6,openstack/neutron,master,Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6,Add a tempest scenario for floating-ip,MERGED,2017-01-23 10:16:57.000000000,2017-02-19 02:35:16.000000000,2017-02-19 02:35:16.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 19307}, {'_account_id': 20330}]","[{'number': 1, 'created': '2017-01-23 10:16:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5fb503fc6e8bd7e8638b1f4afeaea41f5fa821ab', 'message': 'test_floatingip\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 2, 'created': '2017-01-23 10:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d29cad2ff71326d982d75040810425fd98366fe', 'message': 'test_floatingip\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 3, 'created': '2017-01-23 22:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc913d41101c24281ac7b59c328d69a9fee6ebce', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 4, 'created': '2017-01-24 00:16:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8788787e0fa9d0475606d94acf9af809a81244c', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 5, 'created': '2017-01-24 06:07:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b9ad5d437e6abc2318943d39e90fe919ab31b88', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 6, 'created': '2017-01-24 22:39:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93174dfc8950a92a79281cf2be7cd9acc4e6f5c4', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 7, 'created': '2017-01-25 03:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d1ac2893191426ac5555dc87a389def22a8cd4e', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 8, 'created': '2017-01-25 06:59:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2817f9fe54063ab1a3df6a0c3b653d14cace07b5', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 9, 'created': '2017-01-26 05:07:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/095612ba733edd45f25a21ed7440a491e348b044', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}, {'number': 10, 'created': '2017-02-15 05:15:07.000000000', 'files': ['neutron/tests/tempest/scenario/base.py', 'neutron/tests/tempest/scenario/test_floatingip.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e9d4ed079e3f24ad8d285d02abe7bed30576a5e', 'message': 'Add a tempest scenario for floating-ip\n\nExamine E-W traffic with or without floating-ip.\n\nChange-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6\n'}]",26,424043,2e9d4ed079e3f24ad8d285d02abe7bed30576a5e,102,14,10,6854,,,0,"Add a tempest scenario for floating-ip

Examine E-W traffic with or without floating-ip.

Change-Id: Ibc480d8b8f09c978f874e1e74bd52e3d615a57f6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/424043/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/tempest/scenario/base.py', 'neutron/tests/tempest/scenario/test_floatingip.py']",2,5fb503fc6e8bd7e8638b1f4afeaea41f5fa821ab,fip,"# Copyright (c) 2017 Midokura SARL # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import netaddr import testscenarios from testscenarios.scenarios import multiply_scenarios from tempest.common import waiters from tempest.lib.common import ssh from tempest.lib.common.utils import data_utils from tempest import test from neutron.tests.tempest import config from neutron.tests.tempest.scenario import base from neutron.tests.tempest.scenario import constants CONF = config.CONF load_tests = testscenarios.load_tests_apply_scenarios class FloatingIp(base.BaseTempestTestCase): # REVISIT(yamamoto): 'SRC without FIP' case is possible? scenarios = multiply_scenarios([ ('DEST with FIP', dict(dest_has_fip=True)), ('DEST without FIP', dict(dest_has_fip=False)), ], [ ('Same network', dict(same_network=True)), ('Separate network', dict(same_network=False)), ]) credentials = ['primary', 'admin'] _fip_ip_version = 4 @classmethod @test.requires_ext(extension=""router"", service=""network"") def resource_setup(cls): super(FloatingIp, cls).resource_setup() cls.network = cls.create_network() cls.subnet = cls.create_subnet(cls.network) cls.router = cls.create_router_by_client() cls.create_router_interface(cls.router['id'], cls.subnet['id']) cls.keypair = cls.create_keypair() cls.secgroup = cls.manager.network_client.create_security_group( name=data_utils.rand_name('secgroup-'))['security_group'] cls.security_groups.append(cls.secgroup) cls.create_loginable_secgroup_rule(secgroup_id=cls.secgroup['id']) cls.create_pingable_secgroup_rule(secgroup_id=cls.secgroup['id']) def _create_extra_network(self): network = self.create_network() self.addCleanup(self.client.delete_network, network['id']) subnet = self.create_subnet(network, cidr=netaddr.IPNetwork('10.10.0.0/24')) self.addCleanup(self.client.delete_subnet, subnet['id']) self.create_router_interface(self.router['id'], subnet['id']) self.addCleanup(self.client.add_router_interface_with_subnet_id, self.router['id'], subnet['id']) return network def _find_suitable_subnet(self, network_id): subnets = self.admin_manager.network_client.list_subnets( network_id=network_id)['subnets'] for subnet in subnets: if subnet['ip_version'] == self._fip_ip_version: return subnet['id'] msg = ""No suitable subnets on public network"" raise self.skipException(msg) def _create_and_associate_floatingip(self, port_id): network_id = CONF.network.public_network_id subnet_id = self._find_suitable_subnet(network_id) fip = self.manager.network_client.create_floatingip( floating_network_id=network_id, subnet_id=subnet_id, port_id=port_id)['floatingip'] self.floating_ips.append(fip) self.assertEqual(self._fip_ip_version, netaddr.IPAddress(fip['floating_ip_address']).version) return fip def _create_server(self, floating_ip=True, network=None): if network is None: network = self.network port = self.create_port(network, security_groups=[self.secgroup['id']]) if floating_ip: fip = self._create_and_associate_floatingip(port['id']) else: fip = None server = self.create_server( flavor_ref=CONF.compute.flavor_ref, image_ref=CONF.compute.image_ref, key_name=self.keypair['name'], networks=[{'port': port['id']}])['server'] waiters.wait_for_server_status(self.manager.servers_client, server['id'], constants.SERVER_STATUS_ACTIVE) return {'port': port, 'fip': fip, 'server': server} @test.idempotent_id('05c4e3b3-7319-4052-90ad-e8916436c23b') def test_fip(self): server1 = self._create_server() # self.check_connectivity(server1['fip']['floating_ip_address'], # CONF.validation.image_ssh_user, # self.keypair['private_key']) ssh_client = ssh.Client(server1['fip']['floating_ip_address'], CONF.validation.image_ssh_user, pkey=self.keypair['private_key']) if self.same_network: network2 = self.network else: network2 = self._create_extra_network() server2 = self._create_server(network=network2, floating_ip=self.dest_has_fip) self._check_remote_connectivity(ssh_client, server2['port']['fixed_ips'][0]['ip_address']) if self.dest_has_fip: self._check_remote_connectivity(ssh_client, server2['fip']['floating_ip_address']) ",,186,0
openstack%2Foslo.rootwrap~stable%2Focata~I3e364e9d3ad4e2fcd6f4d8f52f847ec9fa944572,openstack/oslo.rootwrap,stable/ocata,I3e364e9d3ad4e2fcd6f4d8f52f847ec9fa944572,[daemon] Close inherited filedescriptors after forking,MERGED,2017-02-16 21:55:27.000000000,2017-02-19 02:17:33.000000000,2017-02-19 02:17:33.000000000,"[{'_account_id': 3}, {'_account_id': 2062}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2017-02-16 21:55:27.000000000', 'files': ['oslo_rootwrap/client.py'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/f080dffdfd6b91b4fe99029fbd7a867b6e1141cf', 'message': ""[daemon] Close inherited filedescriptors after forking\n\nWe don't want to keep listening on the parent's sockets (e.g. when\nstarted by neutron-openvswitch agent) after forking the rootwrap\ndaemon.\n\nCloses-Bug: #1658973\nChange-Id: I3e364e9d3ad4e2fcd6f4d8f52f847ec9fa944572\n(cherry picked from commit 458d79b61abb1a9ad36ce4868cf248ddb21c80a7)\n""}]",0,435134,f080dffdfd6b91b4fe99029fbd7a867b6e1141cf,8,4,1,9656,,,0,"[daemon] Close inherited filedescriptors after forking

We don't want to keep listening on the parent's sockets (e.g. when
started by neutron-openvswitch agent) after forking the rootwrap
daemon.

Closes-Bug: #1658973
Change-Id: I3e364e9d3ad4e2fcd6f4d8f52f847ec9fa944572
(cherry picked from commit 458d79b61abb1a9ad36ce4868cf248ddb21c80a7)
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/34/435134/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_rootwrap/client.py'],1,f080dffdfd6b91b4fe99029fbd7a867b6e1141cf,bug/1658973," stderr=subprocess.PIPE, close_fds=True)", stderr=subprocess.PIPE),2,1
openstack%2Fkolla-kubernetes~master~I1d3b2a1342518b6c67f45f07a4936b09f5490f18,openstack/kolla-kubernetes,master,I1d3b2a1342518b6c67f45f07a4936b09f5490f18,Updated version number from 0.5.0 to 0.6.0,MERGED,2017-02-18 02:14:44.000000000,2017-02-19 01:49:51.000000000,2017-02-19 01:49:51.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 19384}, {'_account_id': 23717}]","[{'number': 1, 'created': '2017-02-18 02:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/ad0481c59a8ad62b80bc225ea940277e445e559d', 'message': 'Updated version number from 0.5.0 to 0.6.0\n\nUpdated version number from 0.5.0 to 0.6.0\n\nChange-Id: I1d3b2a1342518b6c67f45f07a4936b09f5490f18\n'}, {'number': 2, 'created': '2017-02-18 02:22:23.000000000', 'files': ['helm/microservice/helm-repo-svc/Chart.yaml', 'helm/microservice/nova-compute-daemonset/Chart.yaml', 'helm/service/mariadb/Chart.yaml', 'helm/service/keystone/requirements.yaml', 'helm/microservice/ceph-rbd-daemonset/Chart.yaml', 'helm/microservice/nova-create-db-job/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-internal-job/Chart.yaml', 'helm/service/cinder-cleanup/Chart.yaml', 'helm/service/neutron/Chart.yaml', 'helm/service/keystone-cleanup/Chart.yaml', 'helm/service/openvswitch/requirements.yaml', 'helm/microservice/nova-consoleauth-statefulset/Chart.yaml', 'helm/microservice/nova-create-keystone-service-job/Chart.yaml', 'helm/microservice/cinder-volume-ceph-statefulset/Chart.yaml', 'helm/microservice/mariadb-statefulset/Chart.yaml', 'helm/microservice/glance-create-db-job/Chart.yaml', 'helm/service/openvswitch/Chart.yaml', 'helm/microservice/rabbitmq-statefulset/Chart.yaml', 'helm/microservice/glance-pv/Chart.yaml', 'helm/microservice/cinder-api-svc/Chart.yaml', 'helm/microservice/nova-metadata-svc/Chart.yaml', 'helm/service/mariadb/requirements.yaml', 'helm/compute-kits/compute-kit/requirements.yaml', 'helm/service/memcached/requirements.yaml', 'helm/microservice/neutron-openvswitch-agent-daemonset/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-internal-job/Chart.yaml', 'tools/setup_gate.sh', 'helm/microservice/mariadb-svc/Chart.yaml', 'helm/microservice/nova-api-delete-db-job/Chart.yaml', 'helm/microservice/heat-cfn-api-svc/Chart.yaml', 'tests/bin/ceph_workflow_service.sh', 'helm/microservice/cinder-create-keystone-endpoint-public-job/Chart.yaml', 'helm/service/horizon/requirements.yaml', 'helm/microservice/nova-api-svc/Chart.yaml', 'helm/microservice/cinder-delete-keystone-service-job/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/service/nova-control/Chart.yaml', 'helm/microservice/neutron-delete-keystone-user-job/Chart.yaml', 'helm/service/keystone/Chart.yaml', 'helm/service/horizon/Chart.yaml', 'helm/microservice/helm-repo-deployment/Chart.yaml', 'helm/microservice/keystone-internal-svc/Chart.yaml', 'helm/microservice/cinder-create-keystone-servicev2-job/Chart.yaml', 'helm/microservice/cinder-api-deployment/Chart.yaml', 'helm/service/neutron-cleanup/requirements.yaml', 'helm/microservice/cinder-delete-keystone-servicev2-job/Chart.yaml', 'helm/microservice/helm-repo-pvc/Chart.yaml', 'helm/compute-kits/compute-kit/Chart.yaml', 'helm/microservice/mariadb-pvc/Chart.yaml', 'helm/microservice/neutron-create-keystone-service-job/Chart.yaml', 'helm/microservice/rabbitmq-init-element-job/Chart.yaml', 'helm/microservice/nova-scheduler-statefulset/Chart.yaml', 'helm/service/neutron-cleanup/Chart.yaml', 'helm/microservice/cinder-scheduler-statefulset/Chart.yaml', 'helm/microservice/neutron-manage-db-job/Chart.yaml', 'helm/service/nova-compute/requirements.yaml', 'helm/microservice/heat-engine-statefulset/Chart.yaml', 'tools/setup_gate_ceph.sh', 'helm/microservice/cinder-backup-statefulset/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-publicv2-job/Chart.yaml', 'helm/microservice/ceph-admin-pod/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/keystone-delete-db-job/Chart.yaml', 'helm/microservice/keystone-manage-db-job/Chart.yaml', 'helm/microservice/nova-api-deployment/Chart.yaml', 'helm/microservice/glance-api-deployment/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-public-job/Chart.yaml', 'helm/microservice/neutron-delete-db-job/Chart.yaml', 'helm/microservice/cinder-manage-db-job/Chart.yaml', 'helm/microservice/cinder-delete-db-job/Chart.yaml', 'helm/microservice/glance-manage-db-job/Chart.yaml', 'helm/microservice/glance-create-keystone-service-job/Chart.yaml', 'helm/microservice/horizon-deployment/Chart.yaml', 'helm/microservice/tgtd-daemonset/Chart.yaml', 'helm/kolla-common/Chart.yaml', 'helm/microservice/helm-repo-pv/Chart.yaml', 'helm/microservice/neutron-delete-keystone-service-job/Chart.yaml', 'helm/microservice/glance-registry-svc/Chart.yaml', 'helm/microservice/heat-api-svc/Chart.yaml', 'helm/microservice/glance-api-svc/Chart.yaml', 'helm/microservice/rabbitmq-svc/Chart.yaml', 'helm/microservice/glance-registry-deployment/Chart.yaml', 'helm/microservice/neutron-server-deployment/Chart.yaml', 'helm/microservice/nova-api-create-db-job/Chart.yaml', 'helm/microservice/memcached-deployment/Chart.yaml', 'helm/service/glance/requirements.yaml', 'helm/service/memcached/Chart.yaml', 'helm/microservice/glance-delete-keystone-user-job/Chart.yaml', 'helm/microservice/neutron-l3-agent-daemonset/Chart.yaml', 'helm/microservice/keystone-public-svc/Chart.yaml', 'helm/microservice/glance-delete-db-job/Chart.yaml', 'helm/microservice/nova-delete-db-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-service-job/Chart.yaml', 'helm/microservice/horizon-svc/Chart.yaml', 'helm/microservice/cinder-create-keystone-user-job/Chart.yaml', 'helm/microservice/mariadb-init-element-job/Chart.yaml', 'helm/microservice/mariadb-pv/Chart.yaml', 'helm/microservice/nova-delete-keystone-user-job/Chart.yaml', 'helm/microservice/neutron-dhcp-agent-daemonset/Chart.yaml', 'helm/microservice/neutron-metadata-agent-daemonset/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-internalv2-job/Chart.yaml', 'helm/service/cinder-volume-lvm/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-internal-job/Chart.yaml', 'tools/setup_gate_iscsi.sh', 'helm/service/cinder-cleanup/requirements.yaml', 'tests/bin/iscsi_workflow.sh', 'helm/microservice/nova-create-keystone-user-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-adminv2-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-internal-job/Chart.yaml', 'helm/service/keystone-cleanup/requirements.yaml', 'helm/microservice/nova-api-manage-db-job/Chart.yaml', 'helm/microservice/openvswitch-vswitchd-daemonset/Chart.yaml', 'helm/service/glance-cleanup/Chart.yaml', 'helm/microservice/nova-novncproxy-deployment/Chart.yaml', 'tests/bin/deploy_compute_kit.sh', 'helm/service/neutron/requirements.yaml', 'helm/microservice/nova-delete-keystone-service-job/Chart.yaml', 'helm/microservice/test-ceph-init-mon-job/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/openvswitch-ovsdb-daemonset/Chart.yaml', 'helm/service/cinder-control/requirements.yaml', 'helm/microservice/neutron-create-keystone-user-job/Chart.yaml', 'helm/microservice/nova-libvirt-daemonset/Chart.yaml', 'helm/microservice/keystone-create-db-job/Chart.yaml', 'helm/microservice/keystone-api-deployment/Chart.yaml', 'helm/microservice/nova-novncproxy-svc/Chart.yaml', 'tests/bin/build_test_ceph.sh', 'helm/microservice/keystone-create-endpoints-job/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-public-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/neutron-server-svc/Chart.yaml', 'helm/microservice/glance-delete-keystone-service-job/Chart.yaml', 'helm/service/glance-cleanup/requirements.yaml', 'helm/microservice/glance-create-keystone-user-job/Chart.yaml', 'helm/microservice/rabbitmq-pv/Chart.yaml', 'helm/service/cinder-control/Chart.yaml', 'helm/microservice/iscsid-daemonset/Chart.yaml', 'helm/microservice/rabbitmq-pvc/Chart.yaml', 'helm/microservice/cinder-volume-lvm-daemonset/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-public-job/Chart.yaml', 'helm/service/cinder-volume-lvm/requirements.yaml', 'helm/service/glance/Chart.yaml', 'helm/service/nova-cleanup/Chart.yaml', 'helm/service/nova-cleanup/requirements.yaml', 'tests/bin/ceph_workflow.sh', 'helm/microservice/cinder-delete-keystone-user-job/Chart.yaml', 'helm/microservice/keystone-admin-svc/Chart.yaml', 'helm/service/nova-compute/Chart.yaml', 'helm/microservice/cinder-create-db-job/Chart.yaml', 'helm/service/rabbitmq/Chart.yaml', 'helm/microservice/heat-api-deployment/Chart.yaml', 'helm/microservice/memcached-svc/Chart.yaml', 'helm/microservice/nova-conductor-statefulset/Chart.yaml', 'helm/microservice/heat-api-cfn-deployment/Chart.yaml', 'helm/service/rabbitmq/requirements.yaml', 'helm/microservice/neutron-create-db-job/Chart.yaml', 'helm/microservice/glance-pvc/Chart.yaml', 'helm/service/nova-control/requirements.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/c31ad02aeb1604550b98b5bc31ec68fa234b5173', 'message': 'Updated version number from 0.5.0 to 0.6.0\n\nUpdated version number from 0.5.0 to 0.6.0\n\nChange-Id: I1d3b2a1342518b6c67f45f07a4936b09f5490f18\n'}]",1,435635,c31ad02aeb1604550b98b5bc31ec68fa234b5173,10,4,2,16520,,,0,"Updated version number from 0.5.0 to 0.6.0

Updated version number from 0.5.0 to 0.6.0

Change-Id: I1d3b2a1342518b6c67f45f07a4936b09f5490f18
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/35/435635/2 && git format-patch -1 --stdout FETCH_HEAD,"['helm/microservice/helm-repo-svc/Chart.yaml', 'helm/microservice/nova-compute-daemonset/Chart.yaml', 'helm/service/mariadb/Chart.yaml', 'helm/service/keystone/requirements.yaml', 'helm/microservice/ceph-rbd-daemonset/Chart.yaml', 'helm/microservice/nova-create-db-job/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-internal-job/Chart.yaml', 'helm/service/cinder-cleanup/Chart.yaml', 'helm/service/neutron/Chart.yaml', 'helm/service/keystone-cleanup/Chart.yaml', 'helm/service/openvswitch/requirements.yaml', 'helm/microservice/nova-consoleauth-statefulset/Chart.yaml', 'helm/microservice/nova-create-keystone-service-job/Chart.yaml', 'helm/microservice/cinder-volume-ceph-statefulset/Chart.yaml', 'helm/microservice/mariadb-statefulset/Chart.yaml', 'helm/microservice/glance-create-db-job/Chart.yaml', 'helm/service/openvswitch/Chart.yaml', 'helm/microservice/rabbitmq-statefulset/Chart.yaml', 'helm/microservice/glance-pv/Chart.yaml', 'helm/microservice/cinder-api-svc/Chart.yaml', 'helm/microservice/nova-metadata-svc/Chart.yaml', 'helm/service/mariadb/requirements.yaml', 'helm/compute-kits/compute-kit/requirements.yaml', 'helm/service/memcached/requirements.yaml', 'helm/microservice/neutron-openvswitch-agent-daemonset/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-internal-job/Chart.yaml', 'tools/setup_gate.sh', 'helm/microservice/mariadb-svc/Chart.yaml', 'helm/microservice/nova-api-delete-db-job/Chart.yaml', 'helm/microservice/heat-cfn-api-svc/Chart.yaml', 'tests/bin/ceph_workflow_service.sh', 'helm/microservice/cinder-create-keystone-endpoint-public-job/Chart.yaml', 'helm/service/horizon/requirements.yaml', 'helm/microservice/nova-api-svc/Chart.yaml', 'helm/microservice/cinder-delete-keystone-service-job/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/service/nova-control/Chart.yaml', 'helm/microservice/neutron-delete-keystone-user-job/Chart.yaml', 'helm/service/keystone/Chart.yaml', 'helm/service/horizon/Chart.yaml', 'helm/microservice/helm-repo-deployment/Chart.yaml', 'helm/microservice/keystone-internal-svc/Chart.yaml', 'helm/microservice/cinder-create-keystone-servicev2-job/Chart.yaml', 'helm/microservice/cinder-api-deployment/Chart.yaml', 'helm/service/neutron-cleanup/requirements.yaml', 'helm/microservice/cinder-delete-keystone-servicev2-job/Chart.yaml', 'helm/microservice/helm-repo-pvc/Chart.yaml', 'helm/compute-kits/compute-kit/Chart.yaml', 'helm/microservice/mariadb-pvc/Chart.yaml', 'helm/microservice/neutron-create-keystone-service-job/Chart.yaml', 'helm/microservice/rabbitmq-init-element-job/Chart.yaml', 'helm/microservice/nova-scheduler-statefulset/Chart.yaml', 'helm/service/neutron-cleanup/Chart.yaml', 'helm/microservice/cinder-scheduler-statefulset/Chart.yaml', 'helm/microservice/neutron-manage-db-job/Chart.yaml', 'helm/service/nova-compute/requirements.yaml', 'helm/microservice/heat-engine-statefulset/Chart.yaml', 'tools/setup_gate_ceph.sh', 'helm/microservice/cinder-backup-statefulset/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-publicv2-job/Chart.yaml', 'helm/microservice/ceph-admin-pod/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/keystone-delete-db-job/Chart.yaml', 'helm/microservice/keystone-manage-db-job/Chart.yaml', 'helm/microservice/nova-api-deployment/Chart.yaml', 'helm/microservice/glance-api-deployment/Chart.yaml', 'helm/microservice/glance-create-keystone-endpoint-public-job/Chart.yaml', 'helm/microservice/neutron-delete-db-job/Chart.yaml', 'helm/microservice/cinder-manage-db-job/Chart.yaml', 'helm/microservice/cinder-delete-db-job/Chart.yaml', 'helm/microservice/glance-manage-db-job/Chart.yaml', 'helm/microservice/glance-create-keystone-service-job/Chart.yaml', 'helm/microservice/horizon-deployment/Chart.yaml', 'helm/microservice/tgtd-daemonset/Chart.yaml', 'helm/kolla-common/Chart.yaml', 'helm/microservice/helm-repo-pv/Chart.yaml', 'helm/microservice/neutron-delete-keystone-service-job/Chart.yaml', 'helm/microservice/glance-registry-svc/Chart.yaml', 'helm/microservice/heat-api-svc/Chart.yaml', 'helm/microservice/glance-api-svc/Chart.yaml', 'helm/microservice/rabbitmq-svc/Chart.yaml', 'helm/microservice/glance-registry-deployment/Chart.yaml', 'helm/microservice/neutron-server-deployment/Chart.yaml', 'helm/microservice/nova-api-create-db-job/Chart.yaml', 'helm/microservice/memcached-deployment/Chart.yaml', 'helm/service/glance/requirements.yaml', 'helm/service/memcached/Chart.yaml', 'helm/microservice/glance-delete-keystone-user-job/Chart.yaml', 'helm/microservice/neutron-l3-agent-daemonset/Chart.yaml', 'helm/microservice/keystone-public-svc/Chart.yaml', 'helm/microservice/glance-delete-db-job/Chart.yaml', 'helm/microservice/nova-delete-db-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-service-job/Chart.yaml', 'helm/microservice/horizon-svc/Chart.yaml', 'helm/microservice/cinder-create-keystone-user-job/Chart.yaml', 'helm/microservice/mariadb-init-element-job/Chart.yaml', 'helm/microservice/mariadb-pv/Chart.yaml', 'helm/microservice/nova-delete-keystone-user-job/Chart.yaml', 'helm/microservice/neutron-dhcp-agent-daemonset/Chart.yaml', 'helm/microservice/neutron-metadata-agent-daemonset/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-internalv2-job/Chart.yaml', 'helm/service/cinder-volume-lvm/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-internal-job/Chart.yaml', 'tools/setup_gate_iscsi.sh', 'helm/service/cinder-cleanup/requirements.yaml', 'tests/bin/iscsi_workflow.sh', 'helm/microservice/nova-create-keystone-user-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-adminv2-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-internal-job/Chart.yaml', 'helm/service/keystone-cleanup/requirements.yaml', 'helm/microservice/nova-api-manage-db-job/Chart.yaml', 'helm/microservice/openvswitch-vswitchd-daemonset/Chart.yaml', 'helm/service/glance-cleanup/Chart.yaml', 'helm/microservice/nova-novncproxy-deployment/Chart.yaml', 'tests/bin/deploy_compute_kit.sh', 'helm/service/neutron/requirements.yaml', 'helm/microservice/nova-delete-keystone-service-job/Chart.yaml', 'helm/microservice/test-ceph-init-mon-job/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/openvswitch-ovsdb-daemonset/Chart.yaml', 'helm/service/cinder-control/requirements.yaml', 'helm/microservice/neutron-create-keystone-user-job/Chart.yaml', 'helm/microservice/nova-libvirt-daemonset/Chart.yaml', 'helm/microservice/keystone-create-db-job/Chart.yaml', 'helm/microservice/keystone-api-deployment/Chart.yaml', 'helm/microservice/nova-novncproxy-svc/Chart.yaml', 'tests/bin/build_test_ceph.sh', 'helm/microservice/keystone-create-endpoints-job/Chart.yaml', 'helm/microservice/nova-create-keystone-endpoint-public-job/Chart.yaml', 'helm/microservice/cinder-create-keystone-endpoint-admin-job/Chart.yaml', 'helm/microservice/neutron-server-svc/Chart.yaml', 'helm/microservice/glance-delete-keystone-service-job/Chart.yaml', 'helm/service/glance-cleanup/requirements.yaml', 'helm/microservice/glance-create-keystone-user-job/Chart.yaml', 'helm/microservice/rabbitmq-pv/Chart.yaml', 'helm/service/cinder-control/Chart.yaml', 'helm/microservice/iscsid-daemonset/Chart.yaml', 'helm/microservice/rabbitmq-pvc/Chart.yaml', 'helm/microservice/cinder-volume-lvm-daemonset/Chart.yaml', 'helm/microservice/neutron-create-keystone-endpoint-public-job/Chart.yaml', 'helm/service/cinder-volume-lvm/requirements.yaml', 'helm/service/glance/Chart.yaml', 'helm/service/nova-cleanup/Chart.yaml', 'helm/service/nova-cleanup/requirements.yaml', 'tests/bin/ceph_workflow.sh', 'helm/microservice/cinder-delete-keystone-user-job/Chart.yaml', 'helm/microservice/keystone-admin-svc/Chart.yaml', 'helm/service/nova-compute/Chart.yaml', 'helm/microservice/cinder-create-db-job/Chart.yaml', 'helm/service/rabbitmq/Chart.yaml', 'helm/microservice/heat-api-deployment/Chart.yaml', 'helm/microservice/memcached-svc/Chart.yaml', 'helm/microservice/nova-conductor-statefulset/Chart.yaml', 'helm/microservice/heat-api-cfn-deployment/Chart.yaml', 'helm/service/rabbitmq/requirements.yaml', 'helm/microservice/neutron-create-db-job/Chart.yaml', 'helm/microservice/glance-pvc/Chart.yaml', 'helm/service/nova-control/requirements.yaml', 'helm/test/devenv/templates/keystone.yaml']",159,ad0481c59a8ad62b80bc225ea940277e445e559d,bump_version, Listen 0.0.0.0.6.00, Listen 0.0.0.0:5000,252,252
openstack%2Fnetworking-bgpvpn~master~I099faee06bc3d4d634a96f45560a070f2a23bb56,openstack/networking-bgpvpn,master,I099faee06bc3d4d634a96f45560a070f2a23bb56,"Revert ""Add OpenStack client BGP VPN extension""",MERGED,2016-12-15 10:12:09.000000000,2017-02-19 01:38:49.000000000,2017-02-19 01:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 748}, {'_account_id': 2888}, {'_account_id': 6854}, {'_account_id': 7018}, {'_account_id': 12021}]","[{'number': 1, 'created': '2016-12-15 10:12:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/2535f0400e40d470f5a8a1b9483f1dc879800158', 'message': 'Revert ""Add OpenStack client BGP VPN extension""\n\nThis reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.\n\nChange-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56\nPartial-Bug: #1650204\n'}, {'number': 2, 'created': '2016-12-15 10:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/e1c19c3f3a853cc67b5fbc431b1043e42f534f5e', 'message': 'Revert ""Add OpenStack client BGP VPN extension""\n\nThis reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.\n\nChange-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56\nPartial-Bug: #1650204\n'}, {'number': 3, 'created': '2017-01-03 19:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/617e240c29aee989c64990071766dd8cd7ce971e', 'message': 'Revert ""Add OpenStack client BGP VPN extension""\n\nThis reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.\n\nChange-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56\nDepends-On: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea\nPartial-Bug: #1650204\n'}, {'number': 4, 'created': '2017-01-24 16:45:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/b28388d3b5b2df9dca2da94e188bb2a6fbb2ed95', 'message': 'Revert ""Add OpenStack client BGP VPN extension""\n\nThis reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.\n\nChange-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56\nDepends-On: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea\nPartial-Bug: #1650204\n'}, {'number': 5, 'created': '2017-02-09 11:20:23.000000000', 'files': ['test-requirements.txt', 'networking_bgpvpn/osc/network_association.py', 'networking_bgpvpn/osc/__init__.py', 'networking_bgpvpn/tests/unit/osc/test_bgpvpn.py', 'requirements.txt', 'networking_bgpvpn/tests/unit/osc/__init__.py', 'networking_bgpvpn/osc/router_association.py', 'networking_bgpvpn/tests/unit/osc/fakes.py', 'networking_bgpvpn/osc/bgpvpn.py', 'setup.cfg', 'networking_bgpvpn/osc/resource_association.py', 'networking_bgpvpn/tests/unit/osc/test_resource_association.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/d912922514fbe6d56ca45943fd71140535168b61', 'message': 'Revert ""Add OpenStack client BGP VPN extension""\n\nThis reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.\n\nAs explain in that last version of the neutron client documentation [1]\n(from review [2]) and to follow the OpenStack Client (OSC) and the\nOpenStack Python SDK migration, Neutron stadium projects CLI extensions\nshould reside in the python-neutronclient project under the repository\n\'neutronclient/osc/v2/<extension>\'\n\n[1] http://docs-draft.openstack.org/71/407271/2/check/gate-python-neutronclient-docs-ubuntu-xenial/d30c3c8//doc/build/html/devref/transition_to_osc.html#developer-guide\n[2] https://review.openstack.org/#/c/407271/\n\nChange-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56\nDepends-On: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea\nPartial-Bug: #1650204\n'}]",1,411205,d912922514fbe6d56ca45943fd71140535168b61,34,7,5,55,,,0,"Revert ""Add OpenStack client BGP VPN extension""

This reverts commit 205452bfff767dbe0d552227d77846fb49c6cfb0.

As explain in that last version of the neutron client documentation [1]
(from review [2]) and to follow the OpenStack Client (OSC) and the
OpenStack Python SDK migration, Neutron stadium projects CLI extensions
should reside in the python-neutronclient project under the repository
'neutronclient/osc/v2/<extension>'

[1] http://docs-draft.openstack.org/71/407271/2/check/gate-python-neutronclient-docs-ubuntu-xenial/d30c3c8//doc/build/html/devref/transition_to_osc.html#developer-guide
[2] https://review.openstack.org/#/c/407271/

Change-Id: I099faee06bc3d4d634a96f45560a070f2a23bb56
Depends-On: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea
Partial-Bug: #1650204
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/05/411205/2 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'networking_bgpvpn/osc/network_association.py', 'networking_bgpvpn/osc/__init__.py', 'networking_bgpvpn/tests/unit/osc/test_bgpvpn.py', 'requirements.txt', 'networking_bgpvpn/tests/unit/osc/__init__.py', 'networking_bgpvpn/osc/router_association.py', 'networking_bgpvpn/tests/unit/osc/fakes.py', 'networking_bgpvpn/osc/bgpvpn.py', 'setup.cfg', 'networking_bgpvpn/osc/resource_association.py', 'networking_bgpvpn/tests/unit/osc/test_resource_association.py']",12,2535f0400e40d470f5a8a1b9483f1dc879800158,bug/1650204,,"# Copyright (c) 2016 Juniper Networks Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import copy import mock from osc_lib import exceptions from osc_lib import utils from networking_bgpvpn.tests.unit.osc import fakes columns = list(col for _, col in fakes.BgpvpnFakeAssoc._columns_map) headers = list(head for head, _ in fakes.BgpvpnFakeAssoc._columns_map) def _get_data(attrs): return utils.get_dict_properties(attrs, columns) class TestCreateResAssoc(fakes.TestNeutronClientOSCV2): def setUp(self): super(TestCreateResAssoc, self).setUp() self.cmd = fakes.CreateBgpvpnFakeResAssoc(self.app, self.namespace) def test_create_resource_association(self): fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_res = fakes.FakeResource.create_one_resource() fake_res_assoc = fakes.FakeResAssoc.create_one_resource_association( fake_res) self.neutronclient.create_ext = mock.Mock( return_value={fakes.BgpvpnFakeAssoc._resource: fake_res_assoc}) arglist = [ fake_bgpvpn['id'], fake_res['id'], '--project', fake_bgpvpn['tenant_id'], ] verifylist = [ ('bgpvpn', fake_bgpvpn['id']), ('resource', fake_res['id']), ('project', fake_bgpvpn['tenant_id']) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) cols, data = self.cmd.take_action(parsed_args) fake_res_assoc_call = copy.deepcopy(fake_res_assoc) fake_res_assoc_call.pop('id') self.neutronclient.create_ext.assert_called_once_with( fakes.BgpvpnFakeAssoc._object_path % fake_bgpvpn['id'], {fakes.BgpvpnFakeAssoc._resource: fake_res_assoc_call}) self.assertEqual(columns, cols) self.assertEqual(_get_data(fake_res_assoc), data) class TestUpdateResAssoc(fakes.TestNeutronClientOSCV2): def setUp(self): super(TestUpdateResAssoc, self).setUp() self.cmd = fakes.UpdateBgpvpnFakeResAssoc(self.app, self.namespace) def test_update_resource_association(self): fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_res = fakes.FakeResource.create_one_resource() fake_res_assoc = fakes.FakeResAssoc.create_one_resource_association( fake_res) arglist = [ fake_res_assoc['id'], fake_bgpvpn['id'], ] verifylist = [ ('resource_association', fake_res_assoc['id']), ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.assertRaises(exceptions.UnsupportedVersion, self.cmd.take_action, parsed_args) class TestDeleteResAssoc(fakes.TestNeutronClientOSCV2): def setUp(self): super(TestDeleteResAssoc, self).setUp() self.cmd = fakes.DeleteBgpvpnFakeResAssoc(self.app, self.namespace) def test_delete_one_association(self): fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_res = fakes.FakeResource.create_one_resource() fake_res_assoc = fakes.FakeResAssoc.create_one_resource_association( fake_res) self.neutronclient.delete_ext = mock.Mock() arglist = [ fake_res_assoc['id'], fake_bgpvpn['id'], ] verifylist = [ ('resource_associations', [fake_res_assoc['id']]), ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) self.neutronclient.delete_ext.assert_called_once_with( fakes.BgpvpnFakeAssoc._resource_path % fake_bgpvpn['id'], fake_res_assoc['id']) self.assertIsNone(result) def test_delete_multi_bpgvpn(self): count = 3 fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_ress = fakes.FakeResource.create_resources(count=count) fake_res_assocs = fakes.FakeResAssoc.create_resource_associations( fake_ress) fake_res_assoc_ids = [ fake_res_assoc['id'] for fake_res_assoc in fake_res_assocs[fakes.BgpvpnFakeAssoc._resource_plural] ] self.neutronclient.delete_ext = mock.Mock() arglist = \ fake_res_assoc_ids + [ fake_bgpvpn['id'] ] verifylist = [ ('resource_associations', fake_res_assoc_ids), ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) self.neutronclient.delete_ext.assert_has_calls( [mock.call( fakes.BgpvpnFakeAssoc._resource_path % fake_bgpvpn['id'], id) for id in fake_res_assoc_ids]) self.assertIsNone(result) def test_delete_multi_bpgvpn_with_unknown(self): count = 3 fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_ress = fakes.FakeResource.create_resources(count=count) fake_res_assocs = fakes.FakeResAssoc.create_resource_associations( fake_ress) fake_res_assoc_ids = [ fake_res_assoc['id'] for fake_res_assoc in fake_res_assocs[fakes.BgpvpnFakeAssoc._resource_plural] ] def raise_unknonw_resource(resource_path, name_or_id): if str(count - 2) in name_or_id: raise Exception() self.neutronclient.delete_ext = mock.Mock( side_effect=raise_unknonw_resource) arglist = \ fake_res_assoc_ids + [ fake_bgpvpn['id'] ] verifylist = [ ('resource_associations', fake_res_assoc_ids), ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.assertRaises(exceptions.CommandError, self.cmd.take_action, parsed_args) self.neutronclient.delete_ext.assert_has_calls( [mock.call( fakes.BgpvpnFakeAssoc._resource_path % fake_bgpvpn['id'], id) for id in fake_res_assoc_ids]) class TestListResAssoc(fakes.TestNeutronClientOSCV2): def setUp(self): super(TestListResAssoc, self).setUp() self.cmd = fakes.ListBgpvpnFakeResAssoc(self.app, self.namespace) def test_list_bgpvpn_associations(self): count = 3 fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_ress = fakes.FakeResource.create_resources(count=count) fake_res_assocs = fakes.FakeResAssoc.create_resource_associations( fake_ress) self.neutronclient.list_ext = mock.Mock(return_value=fake_res_assocs) arglist = [ fake_bgpvpn['id'], ] verifylist = [ ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) col_headers, data = self.cmd.take_action(parsed_args) self.neutronclient.list_ext.assert_called_once_with( collection=fakes.BgpvpnFakeAssoc._resource_plural, path=fakes.BgpvpnFakeAssoc._object_path % fake_bgpvpn['id'], retrieve_all=True) self.assertEqual(col_headers, headers) self.assertEqual( list(data), [_get_data(fake_res_assoc) for fake_res_assoc in fake_res_assocs[fakes.BgpvpnFakeAssoc._resource_plural]]) class TestShowResAssoc(fakes.TestNeutronClientOSCV2): def setUp(self): super(TestShowResAssoc, self).setUp() self.cmd = fakes.ShowBgpvpnFakeResAssoc(self.app, self.namespace) def test_show_resource_association(self): fake_bgpvpn = fakes.FakeBgpvpn.create_one_bgpvpn() fake_res = fakes.FakeResource.create_one_resource() fake_res_assoc = fakes.FakeResAssoc.create_one_resource_association( fake_res) self.neutronclient.show_ext = mock.Mock( return_value={fakes.BgpvpnFakeAssoc._resource: fake_res_assoc}) arglist = [ fake_res_assoc['id'], fake_bgpvpn['id'], ] verifylist = [ ('resource_association', fake_res_assoc['id']), ('bgpvpn', fake_bgpvpn['id']), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) cols, data = self.cmd.take_action(parsed_args) self.neutronclient.show_ext.assert_called_once_with( fakes.BgpvpnFakeAssoc._resource_path % fake_bgpvpn['id'], fake_res_assoc['id']) self.assertEqual(list(cols), columns) self.assertEqual(data, _get_data(fake_res_assoc)) ",1,1408
openstack%2Fopenstack-ansible~stable%2Focata~Ie1435e6cc05eea840e121ce66935aed8ca879c7a,openstack/openstack-ansible,stable/ocata,Ie1435e6cc05eea840e121ce66935aed8ca879c7a,Integration of dragonflow in integrated gate,MERGED,2017-02-18 09:41:11.000000000,2017-02-19 01:06:34.000000000,2017-02-19 01:06:34.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 15993}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-18 09:41:11.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0dce016d8a6eb9b8119d067d2f05910ea7d7c132', 'message': 'Integration of dragonflow in integrated gate\n\nInventory needs a change of env.d/nova and neutron, and will be\ndocumented in the neutron role.\n\nThis only makes possible to install the pip packages required by\ndragonflow. It should be enough to allow the installation of dragonflow.\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n(cherry picked from commit f5d6475260150ed44a08f002c528170c82643973)\n'}]",0,435686,0dce016d8a6eb9b8119d067d2f05910ea7d7c132,7,4,1,6816,,,0,"Integration of dragonflow in integrated gate

Inventory needs a change of env.d/nova and neutron, and will be
documented in the neutron role.

This only makes possible to install the pip packages required by
dragonflow. It should be enough to allow the installation of dragonflow.

Depends-On: Id5184845d18461c6c37a560cdc0404c8a487c020
Co-Authored-By: Omer Anson <omer.anson@toganetworks.com>
Change-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a
(cherry picked from commit f5d6475260150ed44a08f002c528170c82643973)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/435686/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,0dce016d8a6eb9b8119d067d2f05910ea7d7c132,dragonflow_initial_work,"## Dragonflow service dragonflow_git_repo: https://git.openstack.org/openstack/dragonflow dragonflow_git_install_branch: 3018c4db7d827157667559e23f7c27ff48aa4863 # HEAD of ""master"" as of 23.01.2017 dragonflow_git_dest: ""/opt/dragonflow_{{ dragonflow_git_install_branch | replace('/', '_') }}"" dragonflow_git_project_group: neutron_all ",,7,0
openstack%2Fopenstack-ansible-os_magnum~master~I40b7848a8cb5f0ee5cf33ed91c1984e68cadde0d,openstack/openstack-ansible-os_magnum,master,I40b7848a8cb5f0ee5cf33ed91c1984e68cadde0d,Update test image sha1sum to latest,MERGED,2017-02-18 11:54:56.000000000,2017-02-19 00:41:29.000000000,2017-02-19 00:41:29.000000000,"[{'_account_id': 3}, {'_account_id': 14805}, {'_account_id': 15993}]","[{'number': 1, 'created': '2017-02-18 11:54:56.000000000', 'files': ['tests/magnum-test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/04ed6e50ff00aa132c9c48a844495acecf1b0788', 'message': 'Update test image sha1sum to latest\n\nChange-Id: I40b7848a8cb5f0ee5cf33ed91c1984e68cadde0d\n'}]",0,435698,04ed6e50ff00aa132c9c48a844495acecf1b0788,7,3,1,6816,,,0,"Update test image sha1sum to latest

Change-Id: I40b7848a8cb5f0ee5cf33ed91c1984e68cadde0d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/98/435698/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/magnum-test-vars.yml'],1,04ed6e50ff00aa132c9c48a844495acecf1b0788,," checksum: ""sha1:eba0fa9a8f03de3c646ef7cb080872634497463a"""," checksum: ""sha1:edbaeb0ece775dff88c5fa2fdf3bbdad79bd2b4d""",1,1
openstack%2Fops-tags-team~master~I6cbe6e9d6299551d64c938d23f294178737a720a,openstack/ops-tags-team,master,I6cbe6e9d6299551d64c938d23f294178737a720a,Add Production Use data for Ocata,MERGED,2017-02-18 04:13:08.000000000,2017-02-19 00:30:08.000000000,2017-02-19 00:30:08.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2017-02-18 04:13:08.000000000', 'files': ['ocata/ops-production-use.json'], 'web_link': 'https://opendev.org/openstack/ops-tags-team/commit/282f1385d47003963c48d6761dde6be0833f3dcd', 'message': 'Add Production Use data for Ocata\n\nUsing (early/unreleased) survey data for deployments updated between 2017-01-17 and 2017-02-17,\n* Isolate deployments in ""Production or Full Operational Use""\n* Look for project usage either in ""Production"" or ""Testing""\n* Count the project use, and calculate an overall percentage by dividing by the number of deployments (253)\n\nKeystone (Identity Service)\t225\t95.74%\nNova (Compute)\t224\t95.32%\nGlance (Image Service)\t222\t94.47%\nNeutron (Networking)\t218\t92.77%\nCinder (Block Storage)\t207\t88.09%\nHorizon (Dashboard)\t205\t87.23%\nHeat (Orchestration)\t157\t66.81%\nCeilometer (Metering & Monitoring)\t131\t55.74%\nSwift (Object Storage)\t121\t51.49%\nRally (Benchmark Service)\t52\t22.13%\nIronic (Bare Metal)\t48\t20.43%\nDesignate (DNS Service)\t38\t16.17%\nManila (Shared File Systems)\t33\t14.04%\nTrove (Database Service)\t30\t12.77%\nKolla (Containerized Deployment)\t30\t12.77%\nMurano (Application Catalog)\t29\t12.34%\nMagnum(Containers Service)\t26\t11.06%\nSahara (Data Processing)\t24\t10.21%\nBarbican (Key Management)\t20\t8.51%\nTripleO (Deployment)\t20\t8.51%\nMistral (Workflow Service)\t13\t5.53%\nZaqar (Message Service)\t9\t3.83%\nCongress (Governance Service)\t5\t2.13%\nMagnetodb (Key-Value Store as a Service)\t5\t2.13%\nSolum (Software Dev Lifecycle Mgmt)\t5\t2.13%\nCue (Message Broker Service)\t4\t1.70%\n\nChange-Id: I6cbe6e9d6299551d64c938d23f294178737a720a\n'}]",0,435652,282f1385d47003963c48d6761dde6be0833f3dcd,7,2,1,612,,,0,"Add Production Use data for Ocata

Using (early/unreleased) survey data for deployments updated between 2017-01-17 and 2017-02-17,
* Isolate deployments in ""Production or Full Operational Use""
* Look for project usage either in ""Production"" or ""Testing""
* Count the project use, and calculate an overall percentage by dividing by the number of deployments (253)

Keystone (Identity Service)	225	95.74%
Nova (Compute)	224	95.32%
Glance (Image Service)	222	94.47%
Neutron (Networking)	218	92.77%
Cinder (Block Storage)	207	88.09%
Horizon (Dashboard)	205	87.23%
Heat (Orchestration)	157	66.81%
Ceilometer (Metering & Monitoring)	131	55.74%
Swift (Object Storage)	121	51.49%
Rally (Benchmark Service)	52	22.13%
Ironic (Bare Metal)	48	20.43%
Designate (DNS Service)	38	16.17%
Manila (Shared File Systems)	33	14.04%
Trove (Database Service)	30	12.77%
Kolla (Containerized Deployment)	30	12.77%
Murano (Application Catalog)	29	12.34%
Magnum(Containers Service)	26	11.06%
Sahara (Data Processing)	24	10.21%
Barbican (Key Management)	20	8.51%
TripleO (Deployment)	20	8.51%
Mistral (Workflow Service)	13	5.53%
Zaqar (Message Service)	9	3.83%
Congress (Governance Service)	5	2.13%
Magnetodb (Key-Value Store as a Service)	5	2.13%
Solum (Software Dev Lifecycle Mgmt)	5	2.13%
Cue (Message Broker Service)	4	1.70%

Change-Id: I6cbe6e9d6299551d64c938d23f294178737a720a
",git fetch https://review.opendev.org/openstack/ops-tags-team refs/changes/52/435652/1 && git format-patch -1 --stdout FETCH_HEAD,['ocata/ops-production-use.json'],1,282f1385d47003963c48d6761dde6be0833f3dcd,prod-use-ocata,"{ ""Compute service (Nova)"": { ""status"": ""96%"" }, ""Object Storage service (Swift)"": { ""status"": ""51%"" }, ""Image service (Glance)"": { ""status"": ""94%"" }, ""Identity service (Keystone)"": { ""status"": ""96%"" }, ""Dashboard (Horizon)"": { ""status"": ""87%"" }, ""Networking service (Neutron)"": { ""status"": ""93%"" }, ""Block Storage service (Cinder)"": { ""status"": ""88%"" }, ""Telemetry service (Ceilometer)"": { ""status"": ""56%"" }, ""Orchestration service (Heat)"": { ""status"": ""67%"" }, ""Database service (Trove)"": { ""status"": ""13%"" }, ""Data Processing service (Sahara)"": { ""status"": ""10%"" }, ""Bare Metal service (Ironic)"": { ""status"": ""20%"" }, ""Message service (Zaqar)"": { ""status"": ""4%"" }, ""Key Management service (Barbican)"": { ""status"": ""9%"" }, ""DNS service (Designate)"": { ""status"": ""16%"" }, ""Shared File Systems service (Manila)"": { ""status"": ""14%"" }, ""Benchmark service (Rally)"": { ""status"": ""22%"" }, ""Containers service (Magnum)"": { ""status"": ""11%"" }, ""Application Catalog service (Murano)"": { ""status"": ""12%"" }, ""Deployment service (TripleO)"": { ""status"": ""9%"" }, ""Governance service (Congress)"": { ""status"": ""2%"" }, ""Container-based deployment tools (Kolla)"": { ""status"": ""13%"" }, ""Workflow service (Mistral)"": { ""status"": ""6%"" }, ""Message Broker service (Cue)"": { ""status"": ""2%"" }, ""Software Dev Lifecycle Management service (Solum)"": { ""status"": ""2%"" }, ""Key-Value Store as a Service (Magnetodb)"": { ""status"": ""2%"" } } ",,106,0
openstack%2Ffuel-devops~master~I15770841ee1c886544cc734ee1ff1674ce2aa3af,openstack/fuel-devops,master,I15770841ee1c886544cc734ee1ff1674ce2aa3af,Discard time-sync for some envs,MERGED,2017-02-17 12:30:09.000000000,2017-02-19 00:08:19.000000000,2017-02-19 00:08:19.000000000,"[{'_account_id': 3}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2017-02-17 12:30:09.000000000', 'files': ['devops/shell.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/891559577e19793d319cde370cbcc4ab62c50b79', 'message': ""Discard time-sync for some envs\n\nIf env is not Fuel, we can't know slaves IPs,\nthat is why we should not start time-sync procedure.\n\nChange-Id: I15770841ee1c886544cc734ee1ff1674ce2aa3af\nCloses-Bug: 1609006\n""}]",0,435418,891559577e19793d319cde370cbcc4ab62c50b79,6,3,1,19884,,,0,"Discard time-sync for some envs

If env is not Fuel, we can't know slaves IPs,
that is why we should not start time-sync procedure.

Change-Id: I15770841ee1c886544cc734ee1ff1674ce2aa3af
Closes-Bug: 1609006
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/18/435418/1 && git format-patch -1 --stdout FETCH_HEAD,['devops/shell.py'],1,891559577e19793d319cde370cbcc4ab62c50b79,bug/1609006, if not self.env.has_admin(): print('There is no FuelAdmin node. It is impossible to sync time') return,,3,0
openstack%2Fcinder~master~I52dd2d8c55afccb6734742a7ca4fe916eba0142d,openstack/cinder,master,I52dd2d8c55afccb6734742a7ca4fe916eba0142d,fix create_consistencygroup in xiv,MERGED,2017-02-09 20:07:29.000000000,2017-02-18 23:22:29.000000000,2017-02-11 03:16:56.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10213}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13047}, {'_account_id': 13144}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14532}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17565}, {'_account_id': 17947}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 20050}, {'_account_id': 20310}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21990}, {'_account_id': 22248}, {'_account_id': 22381}, {'_account_id': 23613}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}, {'_account_id': 24863}]","[{'number': 1, 'created': '2017-02-09 20:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6a6d5ccd4e3d7dfc85751408136b8947b25fb692', 'message': ""create_consistencygroup in xiv stopped working\n\ncreate_consistencygroup failed when extracting extra_specs. This was the\nresult of ConsistencyGroup.volume_type_id having an extra comma at the end\n(e.g. u'2ec11e39-881a-4392-a0dd-2254ec4b39a0,').\n\nChange-Id: I52dd2d8c55afccb6734742a7ca4fe916eba0142d\ncloses-bug: 1663356\n""}, {'number': 2, 'created': '2017-02-09 20:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/93aa9acfed3e730b7d521df9c0d2d36626136be8', 'message': ""fix create_consistencygroup in xiv\n\ncreate_consistencygroup failed when extracting extra_specs. This is the\ndue to ConsistencyGroup.volume_type_id having an extra comma at the\nend (e.g. u'2ec11e39-881a-4392-a0dd-2254ec4b39a0,').\n\nChange-Id: I52dd2d8c55afccb6734742a7ca4fe916eba0142d\ncloses-bug: 1663356\n""}, {'number': 3, 'created': '2017-02-10 14:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/77cf889a6ce64504949ea1539f21be3bd151f811', 'message': ""fix create_consistencygroup in xiv\n\ncreate_consistencygroup failed when extracting extra_specs. This is\ndue to ConsistencyGroup.volume_type_id having an extra comma at the\nend (e.g. u'2ec11e39-881a-4392-a0dd-2254ec4b39a0,').\n\nChange-Id: I52dd2d8c55afccb6734742a7ca4fe916eba0142d\ncloses-bug: 1663356\n""}, {'number': 4, 'created': '2017-02-10 21:37:54.000000000', 'files': ['cinder/tests/unit/volume/drivers/ibm/test_xiv_proxy.py', 'cinder/volume/drivers/ibm/ibm_storage/xiv_proxy.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/7487e706426d74555d639146a188618fc1e103f2', 'message': ""fix create_consistencygroup in xiv\n\ncreate_consistencygroup failed when extracting extra_specs. This is\ndue to ConsistencyGroup.volume_type_id having an extra comma at the\nend (e.g. u'2ec11e39-881a-4392-a0dd-2254ec4b39a0,').\n\nChange-Id: I52dd2d8c55afccb6734742a7ca4fe916eba0142d\ncloses-bug: 1663356\n""}]",12,431732,7487e706426d74555d639146a188618fc1e103f2,93,45,4,10213,,,0,"fix create_consistencygroup in xiv

create_consistencygroup failed when extracting extra_specs. This is
due to ConsistencyGroup.volume_type_id having an extra comma at the
end (e.g. u'2ec11e39-881a-4392-a0dd-2254ec4b39a0,').

Change-Id: I52dd2d8c55afccb6734742a7ca4fe916eba0142d
closes-bug: 1663356
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/431732/3 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/ibm/ibm_storage/xiv_proxy.py'],1,6a6d5ccd4e3d7dfc85751408136b8947b25fb692,bug/1663356," volume_type_ids = [filter(None, group.volume_type_id.split("",""))] LOG.debug(""volume_type_ids: %s"" % volume_type_ids)", volume_type_ids = [group.volume_type_id],2,1
openstack%2Fpython-tripleoclient~stable%2Fmitaka~I1c219a3547ca48e5c4a649441632eabc326081f9,openstack/python-tripleoclient,stable/mitaka,I1c219a3547ca48e5c4a649441632eabc326081f9,Fix mitaka unit tests,MERGED,2017-01-17 21:31:14.000000000,2017-02-18 23:15:55.000000000,2017-02-18 22:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 6928}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 10239}]","[{'number': 1, 'created': '2017-01-17 21:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d8990de822b177241446381c1d036692a12a3437', 'message': 'Fix mitaka unit tests\n\nThere are a couple of issues here.  First, we have an uncapped\nopenstackclient dependency, which means we are now pulling in a\ntoo-new version of osc without the utils module.  The solution to\nthis is to start using upper-constraints, but that brings us to\nproblem two.\n\nProblem two is that we had some requirements that pointed directly\nat git repos in mitaka, which is incompatible with upper-constraints.\nTo fix this, we can now use the released versions of these deps.\nos-cloud-config is in global-requirements without a version\nspecified, and tripleo-common is not in g-r for mitaka at all, so\nwe can use whatever we want.  The mitaka release of tripleo-common\nwas 2.1.0, so set the range to >2.0.0 and <3.0.0.\n\nChange-Id: I1c219a3547ca48e5c4a649441632eabc326081f9\nCloses-Bug: 1656871\n'}, {'number': 2, 'created': '2017-01-17 21:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/af57e46d6a25a1529bc3eaed7d655726161104cf', 'message': 'Fix mitaka unit tests\n\nThere are a couple of issues here.  First, we have an uncapped\nopenstackclient dependency, which means we are now pulling in a\ntoo-new version of osc without the utils module.  The solution to\nthis is to start using upper-constraints, but that brings us to\nproblem two.\n\nProblem two is that we had some requirements that pointed directly\nat git repos in mitaka, which is incompatible with upper-constraints.\nTo fix this, we can now use the released versions of these deps.\nos-cloud-config is in global-requirements without a version\nspecified, and tripleo-common is added as a dependency of this\npatch.\n\nChange-Id: I1c219a3547ca48e5c4a649441632eabc326081f9\nCloses-Bug: 1656871\nDepends-On: I34ae312f6e92787c9724f14d5b37e7965ff0d5eb\n'}, {'number': 3, 'created': '2017-01-17 22:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ab3816308cb45ae049b13925272faf5cb4e6c668', 'message': 'Fix mitaka unit tests\n\nThere are a couple of issues here.  First, we have an uncapped\nopenstackclient dependency, which means we are now pulling in a\ntoo-new version of osc without the utils module.  The solution to\nthis is to start using upper-constraints, but that brings us to\nproblem two.\n\nProblem two is that we had some requirements that pointed directly\nat git repos in mitaka, which is incompatible with upper-constraints.\nTo fix this, we can now use the released versions of these deps.\nos-cloud-config is in global-requirements without a version\nspecified, and tripleo-common is added as a dependency of this\npatch.\n\nChange-Id: I1c219a3547ca48e5c4a649441632eabc326081f9\nCloses-Bug: 1656871\nDepends-On: I34ae312f6e92787c9724f14d5b37e7965ff0d5eb\n'}, {'number': 4, 'created': '2017-02-18 21:30:56.000000000', 'files': ['requirements.txt', 'tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/105df7b2a2a237445398dd86552f5d53a8f23b23', 'message': 'Fix mitaka unit tests\n\nThere are a couple of issues here.  First, we have an uncapped\nopenstackclient dependency, which means we are now pulling in a\ntoo-new version of osc without the utils module.  The solution to\nthis is to start using upper-constraints, but that brings us to\nproblem two.\n\nProblem two is that we had some requirements that pointed directly\nat git repos in mitaka, which is incompatible with upper-constraints.\nTo fix this, we can now use the released versions of these deps.\nos-cloud-config is in global-requirements without a version\nspecified, and tripleo-common is added as a dependency of this\npatch.\n\nChange-Id: I1c219a3547ca48e5c4a649441632eabc326081f9\nCloses-Bug: 1656871'}]",0,421537,105df7b2a2a237445398dd86552f5d53a8f23b23,27,7,4,6928,,,0,"Fix mitaka unit tests

There are a couple of issues here.  First, we have an uncapped
openstackclient dependency, which means we are now pulling in a
too-new version of osc without the utils module.  The solution to
this is to start using upper-constraints, but that brings us to
problem two.

Problem two is that we had some requirements that pointed directly
at git repos in mitaka, which is incompatible with upper-constraints.
To fix this, we can now use the released versions of these deps.
os-cloud-config is in global-requirements without a version
specified, and tripleo-common is added as a dependency of this
patch.

Change-Id: I1c219a3547ca48e5c4a649441632eabc326081f9
Closes-Bug: 1656871",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/37/421537/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tools/tox_install.sh', 'tox.ini']",3,d8990de822b177241446381c1d036692a12a3437,bug/1656871,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/mitaka} {opts} {packages} CLIENT_NAME=python-tripleoclient,install_command = pip install -U {opts} {packages},34,6
openstack%2Ftripleo-ci~master~I93a911cc37b99bcab0d227d8a442ef5fe2514ff6,openstack/tripleo-ci,master,I93a911cc37b99bcab0d227d8a442ef5fe2514ff6,DNM Test with heat-agents instead of heat-templates,ABANDONED,2017-02-18 11:05:10.000000000,2017-02-18 23:12:37.000000000,,"[{'_account_id': 3}, {'_account_id': 16312}]","[{'number': 1, 'created': '2017-02-18 11:05:10.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/19e99e3449d79b13a4b264209e527cfb88bceb5b', 'message': 'DNM Test with heat-agents instead of heat-templates\n\nChange-Id: I93a911cc37b99bcab0d227d8a442ef5fe2514ff6\n'}]",0,435693,19e99e3449d79b13a4b264209e527cfb88bceb5b,7,2,1,16312,,,0,"DNM Test with heat-agents instead of heat-templates

Change-Id: I93a911cc37b99bcab0d227d8a442ef5fe2514ff6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/93/435693/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,19e99e3449d79b13a4b264209e527cfb88bceb5b,DNM-TEST,"export DELOREAN_REPO_URL=""https://trunk.rdoproject.org/centos7/ef/db/efdb00d6285be9e70731d96ece33a1ee1a73dadc_bd92dc5b_test/"" sudo curl -Lvo $REPO_PREFIX/delorean-current.repo https://trunk.rdoproject.org/centos7/ef/db/efdb00d6285be9e70731d96ece33a1ee1a73dadc_bd92dc5b_test/delorean.repo", sudo curl -Lvo $REPO_PREFIX/delorean-current.repo http://trunk.rdoproject.org/centos7/current/delorean.repo,3,1
openstack%2Fpuppet-openstack-integration~master~Ie6c96b6d2919b2259d9b985b0ce9a9049cb54bb9,openstack/puppet-openstack-integration,master,Ie6c96b6d2919b2259d9b985b0ce9a9049cb54bb9,Updated from Puppet OpenStack modules constraints,MERGED,2017-02-18 08:16:14.000000000,2017-02-18 23:09:56.000000000,2017-02-18 23:09:56.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-18 08:16:14.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/8d93f1645309d9ac17df02d52454ad212cc92dd6', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: Ie6c96b6d2919b2259d9b985b0ce9a9049cb54bb9\n'}]",0,435671,8d93f1645309d9ac17df02d52454ad212cc92dd6,7,2,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: Ie6c96b6d2919b2259d9b985b0ce9a9049cb54bb9
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/71/435671/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,8d93f1645309d9ac17df02d52454ad212cc92dd6,openstack/puppet/constraints,"mod 'vitrage', :git => 'https://git.openstack.org/openstack/puppet-vitrage', :ref => 'master' ","mod 'vitrage', :git => 'https://git.openstack.org/openstack/puppet-vitrage', :ref => 'master' ",4,4
openstack%2Fpuppet-tripleo~stable%2Focata~I513303bf82dca53e2291ab66f2385a2985a1846e,openstack/puppet-tripleo,stable/ocata,I513303bf82dca53e2291ab66f2385a2985a1846e,Enable languages in UI config,MERGED,2017-02-18 15:19:32.000000000,2017-02-18 23:09:50.000000000,2017-02-18 23:09:50.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-18 15:19:32.000000000', 'files': ['templates/ui/tripleo_ui_config.js.erb', 'manifests/ui.pp', 'releasenotes/notes/enable-languages-in-ui-88a8caa6db9b4dd7.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/83d8153666f1e6502240651dc5d63633603fb5b4', 'message': ""Enable languages in UI config\n\nWhich language options to offer to the UI users is determined in the\nconfiguration file. Let's show all possible languages by default,\nunless specified otherwise.\n\nChange-Id: I513303bf82dca53e2291ab66f2385a2985a1846e\nRelated-Bug: #1663279\n(cherry picked from commit 053ee06787539f6da07985968d6c3b0194e56008)\n""}]",0,435709,83d8153666f1e6502240651dc5d63633603fb5b4,8,4,1,3153,,,0,"Enable languages in UI config

Which language options to offer to the UI users is determined in the
configuration file. Let's show all possible languages by default,
unless specified otherwise.

Change-Id: I513303bf82dca53e2291ab66f2385a2985a1846e
Related-Bug: #1663279
(cherry picked from commit 053ee06787539f6da07985968d6c3b0194e56008)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/09/435709/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/ui.pp', 'templates/ui/tripleo_ui_config.js.erb', 'releasenotes/notes/enable-languages-in-ui-88a8caa6db9b4dd7.yaml']",3,83d8153666f1e6502240651dc5d63633603fb5b4,bug/1663279,"--- features: - The undercloud UI is available in multiple languages, which can now be configured via the manifest. All available languages are enabled by default. ",,13,2
openstack%2Fpuppet-ironic~stable%2Focata~I7a9a78521c3495f04ca0a9f625b0d844ee56c56a,openstack/puppet-ironic,stable/ocata,I7a9a78521c3495f04ca0a9f625b0d844ee56c56a,Add separate manifest for configuring access to neutron,MERGED,2017-02-18 15:26:42.000000000,2017-02-18 23:09:45.000000000,2017-02-18 23:09:45.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-18 15:26:42.000000000', 'files': ['manifests/neutron.pp', 'spec/classes/ironic_init_spec.rb', 'spec/classes/ironic_api_spec.rb', 'manifests/api.pp', 'manifests/init.pp', 'releasenotes/notes/neutron-manifest-8fbe400720ffc60e.yaml', 'spec/classes/ironic_neutron_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/1853d2805151f818333daba635d5d01c4cb0b86b', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nReset [neutron]url to os_service_default to allow ironic to guess it,\nrather then using a value that it probably wrong.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n(cherry picked from commit ee74484b3aedcda52521440d7b75bf39f33635a1)\n'}]",0,435715,1853d2805151f818333daba635d5d01c4cb0b86b,7,2,1,3153,,,0,"Add separate manifest for configuring access to neutron

Without these parameters ironic uses keystone_authtoken credentials.
This is deprecated since Newton and can be removed at any moment.

This patch provides a manifest to configure separate credentials
and moves other related parameters to it.

Reset [neutron]url to os_service_default to allow ironic to guess it,
rather then using a value that it probably wrong.

Change-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a
Partial-Bug: #1661250
(cherry picked from commit ee74484b3aedcda52521440d7b75bf39f33635a1)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/15/435715/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/neutron.pp', 'spec/classes/ironic_api_spec.rb', 'spec/classes/ironic_init_spec.rb', 'manifests/api.pp', 'manifests/init.pp', 'releasenotes/notes/neutron-manifest-8fbe400720ffc60e.yaml', 'spec/classes/ironic_neutron_spec.rb']",7,1853d2805151f818333daba635d5d01c4cb0b86b,bug/1661250,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Unit tests for ironic::neutron # require 'spec_helper' describe 'ironic::neutron' do let :default_params do { :auth_type => 'password', :project_name => 'services', :username => 'ironic', } end let :params do {} end shared_examples_for 'ironic neutron configuration' do let :p do default_params.merge(params) end it 'configures ironic.conf' do is_expected.to contain_ironic_config('neutron/url').with_value('<SERVICE DEFAULT>') is_expected.to contain_ironic_config('neutron/auth_type').with_value(p[:auth_type]) is_expected.to contain_ironic_config('neutron/auth_url').with_value('<SERVICE DEFAULT>') is_expected.to contain_ironic_config('neutron/project_name').with_value(p[:project_name]) is_expected.to contain_ironic_config('neutron/username').with_value(p[:username]) is_expected.to contain_ironic_config('neutron/password').with_value('<SERVICE DEFAULT>').with_secret(true) end context 'when overriding parameters' do before :each do params.merge!( :api_endpoint => 'http://neutron.example.com', :auth_type => 'noauth', :auth_url => 'http://example.com', :project_name => 'project1', :username => 'admin', :password => 'pa$$w0rd', ) end it 'should replace default parameter with new value' do is_expected.to contain_ironic_config('neutron/url').with_value(p[:api_endpoint]) is_expected.to contain_ironic_config('neutron/auth_type').with_value(p[:auth_type]) is_expected.to contain_ironic_config('neutron/auth_url').with_value(p[:auth_url]) is_expected.to contain_ironic_config('neutron/project_name').with_value(p[:project_name]) is_expected.to contain_ironic_config('neutron/username').with_value(p[:username]) is_expected.to contain_ironic_config('neutron/password').with_value(p[:password]).with_secret(true) end end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end it_behaves_like 'ironic neutron configuration' end end end ",,173,7
openstack%2Fpuppet-ironic~stable%2Focata~I072cd20c7027ceb9aa0260428d6df136a25263eb,openstack/puppet-ironic,stable/ocata,I072cd20c7027ceb9aa0260428d6df136a25263eb,Add separate manifest for configuring access to swift,MERGED,2017-02-18 15:26:58.000000000,2017-02-18 23:09:39.000000000,2017-02-18 23:09:39.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-18 15:26:58.000000000', 'files': ['releasenotes/notes/swift-manifest-3e64c5cf13de40e7.yaml', 'spec/classes/ironic_swift_spec.rb', 'manifests/swift.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/9eb74cb35880905575e5b382c5992befbc692beb', 'message': 'Add separate manifest for configuring access to swift\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nChange-Id: I072cd20c7027ceb9aa0260428d6df136a25263eb\nPartial-Bug: #1661250\n(cherry picked from commit 57e997515bd545659f0e25346e38748911e1a246)\n'}]",0,435716,9eb74cb35880905575e5b382c5992befbc692beb,7,2,1,3153,,,0,"Add separate manifest for configuring access to swift

Without these parameters ironic uses keystone_authtoken credentials.
This is deprecated since Newton and can be removed at any moment.

Change-Id: I072cd20c7027ceb9aa0260428d6df136a25263eb
Partial-Bug: #1661250
(cherry picked from commit 57e997515bd545659f0e25346e38748911e1a246)
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/16/435716/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/swift-manifest-3e64c5cf13de40e7.yaml', 'spec/classes/ironic_swift_spec.rb', 'manifests/swift.pp']",3,9eb74cb35880905575e5b382c5992befbc692beb,bug/1661250,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # == Class: ironic::swift # # [*auth_type*] # The authentication plugin to use when connecting to swift. # Defaults to 'password' # # [*auth_url*] # The address of the keystone api endpoint. # Defaults to $::os_service_default # # [*project_name*] # The Keystone project name. # Defaults to 'services' # # [*username*] # The admin username for ironic to connect to swift. # Defaults to 'ironic'. # # [*password*] # The admin password for ironic to connect to swift. # Defaults to $::os_service_default # class ironic::swift ( $auth_type = 'password', $auth_url = $::os_service_default, $project_name = 'services', $username = 'ironic', $password = $::os_service_default, ) { ironic_config { 'swift/auth_type': value => $auth_type; 'swift/username': value => $username; 'swift/password': value => $password, secret => true; 'swift/auth_url': value => $auth_url; 'swift/project_name': value => $project_name; } } ",,135,0
openstack%2Ftripleo-ci~master~I0257945500400c0ec69a0da99ec0f31178d0f70e,openstack/tripleo-ci,master,I0257945500400c0ec69a0da99ec0f31178d0f70e,upgrades: switch 'newton' to $UPGRADE_RELEASE,MERGED,2017-02-13 17:33:42.000000000,2017-02-18 23:09:16.000000000,2017-02-18 23:09:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6924}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-02-13 17:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/33af4b1bb968e76e3bca5b7e6af6db8506c4cf7a', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 2, 'created': '2017-02-14 16:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0f34747cbb465a2cfd4f7101bb50dae16ff8a309', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 3, 'created': '2017-02-14 17:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/626266dfeaf77d5fe453c319f316737c6283c235', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 4, 'created': '2017-02-16 20:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1bd17ebad3d5dba27a01b7707404107b527a38b', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 5, 'created': '2017-02-16 23:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7e54000fe9df780cdcc6b1ae2210e42c34f0d255', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 6, 'created': '2017-02-17 10:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/74d8df5aa34b012164315439e24f2cc94919bc3e', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 7, 'created': '2017-02-17 11:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1ee2ccdf3d2613b8bc5bd46b493a9275f5091daf', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}, {'number': 8, 'created': '2017-02-18 03:06:54.000000000', 'files': ['scripts/deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/885882a3d247f8ad89cf4fceabc0be61683e6f9d', 'message': ""upgrades: switch 'newton' to $UPGRADE_RELEASE\n\nIn order to support upgrade testing from stable to stable +1 releases,\nwe need to stop hardcoding newton keyword and use $UPGRADE_RELEASE\neverywhere we can.\n\nChange-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e\n""}]",2,433209,885882a3d247f8ad89cf4fceabc0be61683e6f9d,44,5,8,3153,,,0,"upgrades: switch 'newton' to $UPGRADE_RELEASE

In order to support upgrade testing from stable to stable +1 releases,
we need to stop hardcoding newton keyword and use $UPGRADE_RELEASE
everywhere we can.

Change-Id: I0257945500400c0ec69a0da99ec0f31178d0f70e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/09/433209/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/deploy.sh'],1,33af4b1bb968e76e3bca5b7e6af6db8506c4cf7a,upgrade_env_tht," OLD_THT=$(curl https://trunk.rdoproject.org/centos7-$UPGRADE_RELEASE/current/ | grep ""openstack-tripleo-heat-templates"" | grep ""noarch.rpm"" | grep -v ""tripleo-heat-templates-compat"" | sed ""s/^.*>openstack-tripleo-heat-templates/openstack-tripleo-heat-templates/"" | cut -d ""<"" -f1) echo ""Downloading https://trunk.rdoproject.org/centos7-$UPGRADE_RELEASE/current/$OLD_THT"" curl -o $TRIPLEO_ROOT/$UPGRADE_RELEASE/$OLD_THT https://trunk.rdoproject.org/centos7-$UPGRADE_RELEASE/current/$OLD_THT # Set deploy args for stable deployment: # Set deploy args for stable deployment: # update-from-deployed-server-$UPGRADE_RELEASE.yaml environment when upgrading from # $UPGRADE_RELEASE. export OVERCLOUD_DEPLOY_ARGS=""$CURRENT_OVERCLOUD_DEPLOY_ARGS -e /usr/share/openstack-tripleo-heat-templates/environments/deployed-server-environment.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/updates/update-from-deployed-server-$UPGRADE_RELEASE.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/services/sahara.yaml"""," # TODO: This whole block is not release agnostic and Newton is hardcoded. We'll need to detect which release we want to test. OLD_THT=$(curl https://trunk.rdoproject.org/centos7-newton/current/ | grep ""openstack-tripleo-heat-templates"" | grep ""noarch.rpm"" | grep -v ""tripleo-heat-templates-compat"" | sed ""s/^.*>openstack-tripleo-heat-templates/openstack-tripleo-heat-templates/"" | cut -d ""<"" -f1) echo ""Downloading https://trunk.rdoproject.org/centos7-newton/current/$OLD_THT"" curl -o $TRIPLEO_ROOT/$UPGRADE_RELEASE/$OLD_THT https://trunk.rdoproject.org/centos7-newton/current/$OLD_THT # Set deploy args for newton deployment:# TODO: This whole block is not release agnostic and Newton is hardcoded. We'll need to detect which release we want to test. # Set deploy args for newton deployment: # update-from-deployed-server-newton.yaml environment when upgrading from # newton. export OVERCLOUD_DEPLOY_ARGS=""$CURRENT_OVERCLOUD_DEPLOY_ARGS -e /usr/share/openstack-tripleo-heat-templates/environments/deployed-server-environment.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/updates/update-from-deployed-server-newton.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/services/sahara.yaml""",8,10
openstack%2Finstack-undercloud~stable%2Focata~I5c2734e77a16360f9688a0a389211e3882941eb0,openstack/instack-undercloud,stable/ocata,I5c2734e77a16360f9688a0a389211e3882941eb0,Install Ironic inspector plugins,MERGED,2017-02-18 15:21:11.000000000,2017-02-18 22:59:33.000000000,2017-02-18 22:59:33.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-18 15:21:11.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template', 'releasenotes/notes/inspector-additional-hooks-9a5c8f5aad2bac31.yaml'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/ecc2306fecfdb217775cd4a4a81481fb9a00a8f1', 'message': 'Install Ironic inspector plugins\n\nThis change installs two Ironic inspector plugins.  The ``lldp_basic``\nplugin was added to Ironic inspector in Ocata to process LLDP packets\nstored in swift (https://review.openstack.org/#/c/406496/).  The\n``local_link_connection`` plugin was added in Newton but had not been\ninstalled (https://review.openstack.org/#/c/321082/). It sets the\nport_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n(cherry picked from commit c55910d40c454937d4e75e94fbdb17927330f506)\n'}]",0,435710,ecc2306fecfdb217775cd4a4a81481fb9a00a8f1,8,3,1,3153,,,0,"Install Ironic inspector plugins

This change installs two Ironic inspector plugins.  The ``lldp_basic``
plugin was added to Ironic inspector in Ocata to process LLDP packets
stored in swift (https://review.openstack.org/#/c/406496/).  The
``local_link_connection`` plugin was added in Newton but had not been
installed (https://review.openstack.org/#/c/321082/). It sets the
port_id and switch_id on Ironic ports from LLDP data.

Change-Id: I5c2734e77a16360f9688a0a389211e3882941eb0
(cherry picked from commit c55910d40c454937d4e75e94fbdb17927330f506)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/10/435710/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-stack-config/puppet-stack-config.yaml.template', 'releasenotes/notes/inspector-additional-hooks-9a5c8f5aad2bac31.yaml']",2,ecc2306fecfdb217775cd4a4a81481fb9a00a8f1,inspector-hooks,--- features: - | Add new plugins for lldp processing (``lldp_basic``) and switch port link information (``local_link_connection``) to ``processing_hooks`` in inspector.conf. ,,7,1
openstack%2Fpython-openstackclient~master~Ic9563bd86feb1f7afd403e49499205a499f0c142,openstack/python-openstackclient,master,Ic9563bd86feb1f7afd403e49499205a499f0c142,Finish converting server functional tests to JSON format,MERGED,2017-02-18 00:03:57.000000000,2017-02-18 22:36:28.000000000,2017-02-18 22:36:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 18332}, {'_account_id': 21514}]","[{'number': 1, 'created': '2017-02-18 00:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e02e066b56ca6518968479ddb8ecabe21ace3a60', 'message': 'Finish converting server functional tests to JSON format\n\nChange-Id: Ic9563bd86feb1f7afd403e49499205a499f0c142\n'}, {'number': 2, 'created': '2017-02-18 00:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4ece16dd21244cb87277a7d04a22c4e38d89b345', 'message': 'Finish converting server functional tests to JSON format\n\nChange-Id: Ic9563bd86feb1f7afd403e49499205a499f0c142\n'}, {'number': 3, 'created': '2017-02-18 17:50:53.000000000', 'files': ['openstackclient/tests/functional/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/74a35fb005aff18455d4606115a25892c4d6aa7c', 'message': 'Finish converting server functional tests to JSON format\n\nChange-Id: Ic9563bd86feb1f7afd403e49499205a499f0c142\n'}]",0,435629,74a35fb005aff18455d4606115a25892c4d6aa7c,14,5,3,970,,,0,"Finish converting server functional tests to JSON format

Change-Id: Ic9563bd86feb1f7afd403e49499205a499f0c142
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/29/435629/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/compute/v2/test_server.py'],1,e02e066b56ca6518968479ddb8ecabe21ace3a60,server-func-json,"import uuid flavors = json.loads(cls.openstack( ""flavor list -f json "" )) if flavor['Name'] in ['m1.tiny', 'cirros256']: server_flavor = flavor['Name'] images = json.loads(cls.openstack( for image in images: cmd_output = json.loads(cls.openstack( 'network show private -f json' )) return '--nic net-id=' + cmd_output['id'] """"""Create server, with cleanup"""""" name = name or uuid.uuid4().hex '--wait ' + name if not cmd_output: self.fail('Server has not been created!') self.addCleanup(self.server_delete, name) name, return cmd_output def server_delete(self, name): """"""Delete server by name"""""" self.openstack('server delete ' + name) def setUp(self): """"""Select common resources"""""" super(ServerTests, self).setUp() self.flavor_name = self.get_flavor() self.image_name = self.get_image() self.network_arg = self.get_network() def test_server_list(self): """"""Test server list, set"""""" cmd_output = self.server_create() name1 = cmd_output['name'] cmd_output = self.server_create() name2 = cmd_output['name'] self.wait_for_status(name1, ""ACTIVE"") self.wait_for_status(name2, ""ACTIVE"") cmd_output = json.loads(self.openstack( 'server list -f json' )) col_name = [x[""Name""] for x in cmd_output] self.assertIn(name1, col_name) self.assertIn(name2, col_name) # Test list --status PAUSED raw_output = self.openstack('server pause ' + name2) self.assertEqual("""", raw_output) self.wait_for_status(name2, ""PAUSED"") cmd_output = json.loads(self.openstack( 'server list -f json ' + '--status ACTIVE' )) col_name = [x[""Name""] for x in cmd_output] self.assertIn(name1, col_name) self.assertNotIn(name2, col_name) cmd_output = json.loads(self.openstack( 'server list -f json ' + '--status PAUSED' )) col_name = [x[""Name""] for x in cmd_output] self.assertNotIn(name1, col_name) self.assertIn(name2, col_name) def test_server_set(self): """"""Test server create, delete, set, show"""""" cmd_output = self.server_create() name = cmd_output['name'] # self.wait_for_status(name, ""ACTIVE"") # Test properties set 'server set ' + '--property a=b --property c=d ' + name ) self.assertOutput('', raw_output) cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) # Really, shouldn't this be a list? self.assertEqual( ""a='b', c='d'"", cmd_output['properties'], ) 'server unset ' + '--property a ' + name ) cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) self.assertEqual( ""c='d'"", cmd_output['properties'], ) # Test set --name new_name = uuid.uuid4().hex raw_output = self.openstack( 'server set ' + '--name ' + new_name + ' ' + name ) self.assertOutput("""", raw_output) cmd_output = json.loads(self.openstack( 'server show -f json ' + new_name )) self.assertEqual( new_name, cmd_output[""name""], ) # Put it back so we clean up properly raw_output = self.openstack( 'server set ' + '--name ' + name + ' ' + new_name ) self.assertOutput("""", raw_output) def test_server_actions(self): """"""Test server action pairs suspend/resume pause/unpause rescue/unrescue lock/unlock cmd_output = self.server_create() name = cmd_output['name'] raw_output = self.openstack('server suspend ' + name) self.wait_for_status(name, ""SUSPENDED"") raw_output = self.openstack('server resume ' + name) self.wait_for_status(name, ""ACTIVE"") raw_output = self.openstack('server pause ' + name) self.wait_for_status(name, ""PAUSED"") raw_output = self.openstack('server unpause ' + name) self.wait_for_status(name, ""ACTIVE"") raw_output = self.openstack('server rescue ' + name) self.wait_for_status(name, ""RESCUE"") raw_output = self.openstack('server unrescue ' + name) self.wait_for_status(name, ""ACTIVE"") # lock raw_output = self.openstack('server lock ' + name) self.assertEqual("""", raw_output) # NOTE(dtroyer): No way to verify this status??? # unlock raw_output = self.openstack('server unlock ' + name) self.assertEqual("""", raw_output) # NOTE(dtroyer): No way to verify this status??? """"""Test floating ip create/delete; server add/remove floating ip"""""" cmd_output = self.server_create() name = cmd_output['name'] self.wait_for_status(name, ""ACTIVE"") cmd_output = json.loads(self.openstack( 'floating ip create -f json ' + self.IP_POOL )) floating_ip = cmd_output['floating_ip_address'] self.assertNotEqual('', cmd_output['id']) self.assertNotEqual('', floating_ip) self.addCleanup( self.openstack, 'floating ip delete ' + cmd_output['id'] ) raw_output = self.openstack( 'server add floating ip ' + name + ' ' + floating_ip ) cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) self.assertIn( floating_ip, cmd_output['addresses'], ) raw_output = self.openstack( 'server remove floating ip ' + name + ' ' + floating_ip ) cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) self.assertNotIn( floating_ip, cmd_output['addresses'], ) """"""Test server reboot"""""" cmd_output = self.server_create() name = cmd_output['name'] raw_output = self.openstack('server reboot ' + name) self.wait_for_status(name, ""ACTIVE"") """"""Test server create from volume, server delete"""""" volume_name = uuid.uuid4().hex empty_volume_name = uuid.uuid4().hex server_name = uuid.uuid4().hex '--wait ' + def wait_for_status( self, name=None, expected_status='ACTIVE', wait=900, interval=10, ): while total_sleep < wait: cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) status = cmd_output['status'] print('Waiting for {}, current status: {}'.format( expected_status, status, )) cmd_output = json.loads(self.openstack( 'server show -f json ' + name )) status = cmd_output['status']"," from tempest.lib.common.utils import data_utils flavors = cls.openstack('flavor list -c Name -f value').split('\n') if flavor in ['m1.tiny', 'cirros256']: server_flavor = flavor cmd_output = json.loads(cls.openstack( for image in cmd_output: raw_output = cls.openstack('network show private -c id -f value') return ' --nic net-id=' + raw_output.strip('\n') """"""Create server. Add cleanup."""""" name = name or data_utils.rand_uuid() opts = self.get_opts(self.FIELDS) raw_output = self.openstack('--debug server create --flavor ' + self.flavor_name + ' --image ' + self.image_name + self.network_arg + ' ' + name + opts) if not raw_output: self.fail('Server has not been created!') self.addCleanup(self.server_delete, name) def server_list(self, params=[]): """"""List servers."""""" opts = self.get_opts(params) return self.openstack('server list' + opts) def server_delete(self, name): """"""Delete server by name."""""" self.openstack('server delete ' + name) def setUp(self): """"""Set necessary variables and create server."""""" super(ServerTests, self).setUp() self.flavor_name = self.get_flavor() self.image_name = self.get_image() self.network_arg = self.get_network() self.NAME = data_utils.rand_name('TestServer') self.OTHER_NAME = data_utils.rand_name('TestServer') self.HEADERS = ['""Name""'] self.FIELDS = ['name'] self.IP_POOL = 'public' self.server_create(self.NAME) def test_server_rename(self): """"""Test server rename command. Test steps: 1) Boot server in setUp 2) Rename server 3) Check output 4) Rename server back to original name """""" raw_output = self.openstack('server set --name ' + self.OTHER_NAME + ' ' + self.NAME) self.assertOutput("""", raw_output) self.assertNotIn(self.NAME, self.server_list(['Name'])) self.assertIn(self.OTHER_NAME, self.server_list(['Name'])) self.openstack('server set --name ' + self.NAME + ' ' + self.OTHER_NAME) def test_server_list(self): """"""Test server list command. Test steps: 1) Boot server in setUp 2) List servers 3) Check output """""" opts = self.get_opts(self.HEADERS) raw_output = self.openstack('server list' + opts) self.assertIn(self.NAME, raw_output) def test_server_show(self): """"""Test server create, server delete commands"""""" name1 = data_utils.rand_name('TestServer') name1 self.assertIsNotNone(cmd_output[""id""]) self.addCleanup(self.openstack, 'server delete ' + name1) name1, def test_server_metadata(self): """"""Test command to set server metadata. Test steps: 1) Boot server in setUp 2) Set properties for server 3) Check server properties in server show output 4) Unset properties for server 5) Check server properties in server show output """""" self.wait_for_status(""ACTIVE"") # metadata 'server set --property a=b --property c=d ' + self.NAME) opts = self.get_opts([""name"", ""properties""]) raw_output = self.openstack('server show ' + self.NAME + opts) self.assertEqual(self.NAME + ""\na='b', c='d'\n"", raw_output) 'server unset --property a ' + self.NAME) opts = self.get_opts([""name"", ""properties""]) raw_output = self.openstack('server show ' + self.NAME + opts) self.assertEqual(self.NAME + ""\nc='d'\n"", raw_output) def test_server_suspend_resume(self): """"""Test server suspend and resume commands. Test steps: 1) Boot server in setUp 2) Suspend server 3) Check for SUSPENDED server status 4) Resume server 5) Check for ACTIVE server status self.wait_for_status(""ACTIVE"") raw_output = self.openstack('server suspend ' + self.NAME) self.wait_for_status(""SUSPENDED"") raw_output = self.openstack('server resume ' + self.NAME) self.wait_for_status(""ACTIVE"") def test_server_lock_unlock(self): """"""Test server lock and unlock commands. Test steps: 1) Boot server in setUp 2) Lock server 3) Check output 4) Unlock server 5) Check output """""" self.wait_for_status(""ACTIVE"") # lock raw_output = self.openstack('server lock ' + self.NAME) self.assertEqual("""", raw_output) # unlock raw_output = self.openstack('server unlock ' + self.NAME) self.assertEqual("""", raw_output) def test_server_pause_unpause(self): """"""Test server pause and unpause commands. Test steps: 1) Boot server in setUp 2) Pause server 3) Check for PAUSED server status 4) Unpause server 5) Check for ACTIVE server status """""" self.wait_for_status(""ACTIVE"") raw_output = self.openstack('server pause ' + self.NAME) self.wait_for_status(""PAUSED"") raw_output = self.openstack('server unpause ' + self.NAME) self.wait_for_status(""ACTIVE"") def test_server_rescue_unrescue(self): """"""Test server rescue and unrescue commands. Test steps: 1) Boot server in setUp 2) Rescue server 3) Check for RESCUE server status 4) Unrescue server 5) Check for ACTIVE server status """""" self.wait_for_status(""ACTIVE"") opts = self.get_opts([""adminPass""]) raw_output = self.openstack('server rescue ' + self.NAME + opts) self.wait_for_status(""RESCUE"") raw_output = self.openstack('server unrescue ' + self.NAME) self.wait_for_status(""ACTIVE"") """"""Test commands to attach and detach floating IP for server. Test steps: 1) Boot server in setUp 2) Create floating IP 3) Add floating IP to server 4) Check for floating IP in server show output 5) Remove floating IP from server 6) Check that floating IP is not in server show output 7) Delete floating IP 8) Check output """""" self.wait_for_status(""ACTIVE"") opts = self.get_opts([""id"", ""floating_ip_address""]) raw_output = self.openstack('floating ip create ' + self.IP_POOL + opts) ip, ipid, rol = tuple(raw_output.split('\n')) self.assertNotEqual("""", ipid) self.assertNotEqual("""", ip) raw_output = self.openstack('server add floating ip ' + self.NAME + ' ' + ip) raw_output = self.openstack('server show ' + self.NAME) self.assertIn(ip, raw_output) raw_output = self.openstack('server remove floating ip ' + self.NAME + ' ' + ip) raw_output = self.openstack('server show ' + self.NAME) self.assertNotIn(ip, raw_output) raw_output = self.openstack('floating ip delete ' + ipid) self.assertEqual("""", raw_output) """"""Test server reboot command. Test steps: 1) Boot server in setUp 2) Reboot server 3) Check for ACTIVE server status """""" self.wait_for_status(""ACTIVE"") raw_output = self.openstack('server reboot ' + self.NAME) self.wait_for_status(""ACTIVE"") """"""Test server create from volume, server delete Test steps: 1) Create volume from image 2) Create empty volume 3) Create server from new volumes 4) Check for ACTIVE new server status 5) Check volumes attached to server """""" # server_image = self.get_image() volume_name = data_utils.rand_name('volume', self.image_name) empty_volume_name = data_utils.rand_name('TestVolume') server_name = data_utils.rand_name('TestServer') volume_wait_for(""server"", server_name, ""ACTIVE"") def wait_for_status(self, expected_status='ACTIVE', wait=900, interval=30): opts = self.get_opts(['status']) while total_sleep < wait: status = self.openstack('server show ' + self.NAME + opts) status = status.rstrip() print('Waiting for {} current status: {}'.format(expected_status, status)) status = self.openstack('server show ' + self.NAME + opts) status = status.rstrip()",233,222
openstack%2Ffuxi~master~Id987c252ad78e37fae07cb1b1ec3e413de962572,openstack/fuxi,master,Id987c252ad78e37fae07cb1b1ec3e413de962572,Enable Fuxi to use Manila share,MERGED,2016-09-23 12:53:44.000000000,2017-02-18 21:57:14.000000000,2017-02-08 08:10:19.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 11538}, {'_account_id': 14352}, {'_account_id': 14867}]","[{'number': 1, 'created': '2016-09-23 12:53:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/a4d5556418c65fb012f7a3bc95338b98787dc4b3', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 2, 'created': '2016-09-24 00:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/c23968896252679953dc3cc0506d44c3363eafd2', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 3, 'created': '2016-09-27 00:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/e6f2bf2084708a856b33386c90e485c04f7ae52c', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 4, 'created': '2016-09-29 00:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/508da10f68b24e00e155d4c733a18cb2684ee59e', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 5, 'created': '2016-10-09 11:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/8155e63aba3a9a93f3199fc37d52f443ef5bfa56', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 6, 'created': '2016-12-21 05:07:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/23374be0c718eb6a35a3769ef54f4effabe1b8ea', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 7, 'created': '2016-12-21 06:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/bea742692d2a42e83e2b14599aaf007051add8e7', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 8, 'created': '2016-12-24 00:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/bd2e3a10fd42292e647ef6c294155f10ad1e3600', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 9, 'created': '2016-12-28 05:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/7b5fc675cb53a6719a9d04fd882881d57a8acf02', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 10, 'created': '2016-12-28 06:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/cd1ecb9f765f2d7d3efb239acf39d7a98b9edd62', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 11, 'created': '2016-12-28 07:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/adf1dfea0841f882b664cd403366f4a6d526ca2f', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 12, 'created': '2016-12-28 10:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/898ce42f90207a2b95f8e3fbba97b10ca054bebc', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 13, 'created': '2017-01-10 14:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/5c5ab4cc265ac34b74bee460b70659a257b2bca9', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 14, 'created': '2017-01-10 14:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/924383c5914b488aab01fd41e8f8b790c65feece', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 15, 'created': '2017-01-12 00:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/edd3b49f11fe9313814e018aa975c7c0916897b8', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 16, 'created': '2017-01-18 08:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/017a9d85a05ee1caac495fdaff6a8e8980863072', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 17, 'created': '2017-01-18 14:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/f2780c5d561cc44edd325fc0afbba963b71e54bb', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS, GLUSTERFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 18, 'created': '2017-02-03 01:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuxi/commit/041a62fbe8fd7d0acaa847833736e93aed298fa9', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS, GLUSTERFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}, {'number': 19, 'created': '2017-02-03 01:28:44.000000000', 'files': ['fuxi/tests/unit/common/test_state_monitor.py', 'fuxi/controllers.py', 'fuxi/common/config.py', 'fuxi/common/constants.py', 'fuxi/opts.py', 'fuxi/connector/osbrickconnector.py', 'fuxi/tests/unit/connector/test_osbrickconnector.py', 'fuxi/tests/unit/fake_client.py', 'fuxi/exceptions.py', 'fuxi/tests/unit/volumeprovider/test_manila.py', 'fuxi/utils.py', 'fuxi/tests/unit/fake_object.py', 'requirements.txt', 'fuxi/common/state_monitor.py', 'fuxi/volumeprovider/manila.py'], 'web_link': 'https://opendev.org/openstack/fuxi/commit/8f27b9ed1879ee55055d58eb7a7803e3486dec44', 'message': 'Enable Fuxi to use Manila share\n\nSupport Docker use Manila share as a shared persistent volume.\nFor Manila, it supports many driver backends and share_proto,\nin this bp, NFS, GLUSTERFS share_proto will be supported while other\nshare_proto are not supported temporarily\n\nChange-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572\nblueprint: enable-fuxi-to-use-manila-share\n'}]",4,375452,8f27b9ed1879ee55055d58eb7a7803e3486dec44,52,5,19,11538,,,0,"Enable Fuxi to use Manila share

Support Docker use Manila share as a shared persistent volume.
For Manila, it supports many driver backends and share_proto,
in this bp, NFS, GLUSTERFS share_proto will be supported while other
share_proto are not supported temporarily

Change-Id: Id987c252ad78e37fae07cb1b1ec3e413de962572
blueprint: enable-fuxi-to-use-manila-share
",git fetch https://review.opendev.org/openstack/fuxi refs/changes/52/375452/16 && git format-patch -1 --stdout FETCH_HEAD,"['fuxi/controllers.py', 'fuxi/common/config.py', 'fuxi/common/constants.py', 'fuxi/opts.py', 'fuxi/tests/common/test_state_monitor.py', 'fuxi/connector/osbrickconnector.py', 'fuxi/tests/connector/test_osbrickconnector.py', 'fuxi/utils.py', 'fuxi/common/state_monitor.py', 'fuxi/tests/volumeprovider/test_manila.py', 'fuxi/tests/fake_client.py', 'fuxi/tests/fake_object.py', 'fuxi/volumeprovider/manila.py']",13,a4d5556418c65fb012f7a3bc95338b98787dc4b3,bp/enable-fuxi-to-use-manila-share,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # Current supported and checked Manila share protocol # NFS import time from oslo_config import cfg from oslo_log import log as logging from oslo_utils import importutils from manilaclient.openstack.common.apiclient import exceptions \ as manila_exception from fuxi.common import constants as consts from fuxi.common import state_monitor from fuxi import exceptions from fuxi.i18n import _LI, _LW, _LE from fuxi import utils from fuxi.volumeprovider import provider CONF = cfg.CONF manila_conf = CONF.manila NOT_ATTACH = consts.NOT_ATTACH ATTACH_TO_THIS = consts.ATTACH_TO_THIS OSBRICK = 'osbrick' volume_connector_conf = { OSBRICK: 'fuxi.connector.osbrickconnector.ManilaConnector'} LOG = logging.getLogger(__name__) def extract_share_kwargs(docker_volume_name, docker_volume_opts): """"""Extract parameters for creating manila share. Retrieve required parameters and remove unsupported arguments from client input. These parameters are used to create a Cinder volume. :param docker_volume_name: Name for Manila share. :param docker_volume_opts: Optional parameters for Manila share. :rtype: dict """""" options = ['share_proto', 'size', 'snapshot_id', 'description', 'share_network', 'share_type', 'is_public', 'availability_zone', 'consistency_group_id'] kwargs = {} if 'size' in docker_volume_opts: try: size = int(docker_volume_opts.pop('size')) except ValueError: msg = _LE(""Volume size must able to convert to int type"") LOG.error(msg) raise exceptions.InvalidInput(msg) else: size = CONF.default_volume_size LOG.info(_LI(""Volume size doesn't provide from command, so use "" ""default size %sG""), size) kwargs['size'] = size share_proto = docker_volume_opts.pop('share_proto', None) \ or manila_conf.share_proto kwargs['share_proto'] = share_proto for key, value in docker_volume_opts.items(): if key in options: kwargs[key] = value kwargs['name'] = docker_volume_name kwargs['metadata'] = {consts.VOLUME_FROM: CONF.volume_from} return kwargs class Manila(provider.Provider): volume_provider_type = 'manila' def __init__(self): super(Manila, self).__init__() self.manilaclient = utils.get_manilaclient() conn_conf = manila_conf.volume_connector if not conn_conf or conn_conf not in volume_connector_conf: msg = _LE(""Must provide a valid volume connector"") LOG.error(msg) raise exceptions.InvalidInput(msg) self.connector = importutils.import_object( volume_connector_conf[conn_conf], manilaclient=self.manilaclient) def set_client(self): self.manilaclient = utils.get_manilaclient() def _get_docker_volume(self, docker_volume_name): search_opts = {'name': docker_volume_name, 'status': 'available', 'metadata': {consts.VOLUME_FROM: CONF.volume_from}} try: docker_shares = self.manilaclient.shares.list( search_opts=search_opts) except manila_exception.ClientException as e: LOG.error(_LE(""Could not retrieve Manila share list. Error: %s""), e) raise if not docker_shares: raise exceptions.NotFound(""Could not find share with "" ""search_opts: {0}"".format(search_opts)) elif len(docker_shares) > 1: raise exceptions.TooManyResources( ""Find too many shares with search_opts: {0}, while "" ""for Fuxi, should get only one share with provided "" ""search_opts"".format(docker_shares)) docker_share = docker_shares[0] if self.connector.check_access_allowed(docker_share): return docker_share, ATTACH_TO_THIS else: return docker_share, NOT_ATTACH def _create_share_network(self, volume_opts=None): neutron_net_id = volume_opts.get('neutron_net_id', None) neutron_subnet_id = volume_opts.get('neutron_subnet_id', None) if not neutron_net_id or not neutron_subnet_id: raise exceptions.InvalidInput( ""Must provide share_network or both neutron_net_id "" ""and neutron_subnet_id"") # If Share network already exists in Manila with provided neutron # net_info, then use it, otherwise create an new share network. share_nets = self.manilaclient.share_networks.list() for share_net in share_nets: if share_net.neutron_net_id == neutron_net_id \ and share_net.neutron_subnet_id == neutron_subnet_id: msg = _LW(""Find matched share_network %(s_net)s with "" ""neutron_net_id %(n_net)s and "" ""neutron_subnet_id %(n_subnet)s"") LOG.warn(msg, {'s_net': share_net, 'n_net': neutron_net_id, 'n_subnet': neutron_subnet_id}) return share_net try: share_network = self.manilaclient.share_networks.create( neutron_net_id=neutron_net_id, neutron_subnet_id=neutron_subnet_id) except manila_exception.ClientException as e: LOG.error(_LE('Create Manila network share failed. Error: %s'), e) raise return share_network def _create_share(self, docker_volume_name, share_opts): share_network_id = share_opts.get('share_network', None) if not share_network_id: share_network = self._create_share_network(share_opts) share_opts['share_network'] = share_network.id share_kwargs = extract_share_kwargs(docker_volume_name, share_opts) try: LOG.debug(""Start to create share from Manila"") share = self.manilaclient.shares.create(**share_kwargs) except manila_exception.ClientException as e: LOG.error(_LE(""Create Manila share failed. Error: {0}""), e) raise LOG.info(_LI(""Waiting for share %s status to be available""), share) share_monitor = state_monitor.StateMonitor(self.manilaclient, share, 'available', ('creating',)) share = share_monitor.monitor_manila_share() LOG.info(_LI(""Creating share %s successfully""), share) return share def _create_from_existing_share(self, docker_volume_name, share_id, share_opts): try: share = self.manilaclient.shares.get(share_id) except manila_exception.NotFound: LOG.error(_LE(""Could not find share %s""), share_id) raise if share.status != 'available': raise exceptions.UnexpectedStateException( ""Manila share is unavailable"") if share.name != docker_volume_name: LOG.error(_LE(""Provided volume name %(d_name)s does not match "" ""with existing share name %(s_name)s""), {'d_name': docker_volume_name, 's_name': share.name}) raise exceptions.InvalidInput('Volume name does not match') metadata = {consts.VOLUME_FROM: CONF.volume_from} self.manilaclient.shares.update_all_metadata(share, metadata) return share @utils.wrap_check_authorized def create(self, docker_volume_name, volume_opts): try: share, state = self._get_docker_volume(docker_volume_name) if share: LOG.warn(_LW(""Volume %(vol)s already exists in Manila, and "" ""the related Manila share is %(share)s""), {'vol': docker_volume_name, 'share': share}) if state == NOT_ATTACH: return self.connector.connect_volume(share) else: return {'path': self.connector.get_device_path(share)} except exceptions.NotFound: pass if 'volume_id' in volume_opts: share = self._create_from_existing_share( docker_volume_name, volume_opts.pop('volume_id'), volume_opts) else: share = self._create_share(docker_volume_name, volume_opts) return self.connector.connect_volume(share) def _delete_share(self, share): try: share_access_list = self.manilaclient.shares.access_list(share) if len(share_access_list) > 0: LOG.warn(_LE(""Share %s is still used by other server, so "" ""should not delete it.""), share) return self.manilaclient.shares.delete(share) except manila_exception.ClientException as e: LOG.error(_LE(""Error happened when delete Volume %(vol)s (Manila "" ""share: %(share)s). Error: %(err)s""), {'vol': share.name, 'share': share, 'err': e}) raise start_time = time.time() while True: try: self.manilaclient.shares.get(share.id) except manila_exception.NotFound: break if time.time() - start_time > consts.DESTROY_SHARE_TIMEOUT: raise exceptions.TimeoutException time.sleep(consts.SHARE_SCAN_INTERVAL) LOG.debug(""Delete share %s from Manila successfully"", share) @utils.wrap_check_authorized def delete(self, docker_volume_name): try: share, state = self._get_docker_volume(docker_volume_name) if state == NOT_ATTACH: self._delete_share(share) return True except exceptions.NotFound: return False mountpoint = self.connector.get_mountpoint(share) self.connector.disconnect_volume(share) self._clear_mountpoint(mountpoint) self._delete_share(share) return True @utils.wrap_check_authorized def mount(self, docker_volume_name): share, state = self._get_docker_volume(docker_volume_name) if state == NOT_ATTACH: LOG.warn(_LW(""Find share %s, but not attach to this server, "" ""so connect it""), share) self.connector.connect_volume(share) mountpoint = self.connector.get_mountpoint(share) if not mountpoint: self.connector.connect_volume(share) return mountpoint def unmount(self, docker_volume_name): return @utils.wrap_check_authorized def show(self, docker_volume_name): share, state = self._get_docker_volume(docker_volume_name) mountpoint = self.connector.get_mountpoint(share) return {'Name': docker_volume_name, 'Mountpoint': mountpoint} def _get_docker_volumes(self, search_opts=None): try: docker_shares = self.manilaclient.shares.list( search_opts=search_opts) except manila_exception.ClientException as e: LOG.error(_LE('Could not retrieve Manila shares. Error: %s'), e) raise docker_volumes = [] for share in docker_shares: docker_volumes.append( {'Name': share.name, 'Mountpoint': self.connector.get_mountpoint(share)}) LOG.info(_LI(""Retrieve docker volumes %s from Manila "" ""successfully""), docker_volumes) return docker_volumes @utils.wrap_check_authorized def list(self): search_opts = {'status': 'available', 'metadata': {consts.VOLUME_FROM: CONF.volume_from}} return self._get_docker_volumes(search_opts) @utils.wrap_check_authorized def check_exist(self, docker_volume_name): try: self._get_docker_volume(docker_volume_name) except exceptions.NotFound: return False return True ",,1093,85
openstack%2Fpuppet-ovn~stable%2Focata~I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e,openstack/puppet-ovn,stable/ocata,I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e,Input DB listen IP address for the ovn-northd,MERGED,2017-02-18 15:26:24.000000000,2017-02-18 21:51:02.000000000,2017-02-18 21:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-18 15:26:24.000000000', 'files': ['manifests/northd.pp', 'spec/classes/ovn_northd_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/9af37f4ceb3c264f530392747fc353f99dd9ecfd', 'message': ""Input DB listen IP address for the ovn-northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\novn-northd service, the DB servers will be listenting on 0.0.0.0.\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service. It also sets the other options\ndb-nb-create-insecure-remote and db-sb-create-insecure-remote which\nare required to start the ovsdb-server's  listening on TCP\nconnections. Please see this commit [1] for more details.\n\n[1] -\nhttps://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149\n\nCo-authored-by: Numan Siddique <nusiddiq@redhat.com>\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n(cherry picked from commit 4e9e55987d3c21ce99d50969f227e5055fe6bd3c)\n""}]",0,435714,9af37f4ceb3c264f530392747fc353f99dd9ecfd,6,2,1,3153,,,0,"Input DB listen IP address for the ovn-northd

When ovn-northd is started, along with it ovsdb servers for the southbound
and northbound databases are also started. Without additional options for the
ovn-northd service, the DB servers will be listenting on 0.0.0.0.

This patch creates a systemd environment file that will create the db listen
options for the northd service. It also sets the other options
db-nb-create-insecure-remote and db-sb-create-insecure-remote which
are required to start the ovsdb-server's  listening on TCP
connections. Please see this commit [1] for more details.

[1] -
https://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149

Co-authored-by: Numan Siddique <nusiddiq@redhat.com>
Change-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e
(cherry picked from commit 4e9e55987d3c21ce99d50969f227e5055fe6bd3c)
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/14/435714/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/northd.pp', 'spec/classes/ovn_northd_spec.rb']",2,9af37f4ceb3c264f530392747fc353f99dd9ecfd,db_listen_ip," shared_examples_for 'systemd env' do it 'creates systemd conf' do is_expected.to contain_file('/etc/sysconfig/ovn-northd').with( :ensure => 'file', :mode => '0644', :owner => 'root', :group => 'root', :content => ""OVN_NORTHD_OPTS=--db-nb-addr=0.0.0.0 --db-sb-addr=0.0.0.0 --db-nb-create-insecure-remote=yes --db-sb-create-insecure-remote=yes"", :before => 'Service[northd]', ) end end it_behaves_like 'systemd env'",,28,1
openstack%2Fpython-tripleoclient~stable%2Focata~I6738d864af3b3a6120daa22d505fc0a6ff6c891a,openstack/python-tripleoclient,stable/ocata,I6738d864af3b3a6120daa22d505fc0a6ff6c891a,stable/ocata CI run - do not merge,ABANDONED,2017-01-27 13:34:13.000000000,2017-02-18 21:38:31.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 13294}]","[{'number': 1, 'created': '2017-01-27 13:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5e982bf8b172f850814c76219b46e7e641237f13', 'message': 'stable/ocata CI run - do not merge\n\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}, {'number': 2, 'created': '2017-01-31 12:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c6f2f8ac6ac91f8ee58701f24c93bbfc7274a017', 'message': 'stable/ocata CI run - do not merge\n\nDepends-On: I1cb26fbecaf1871401774933642b309c79b35fee\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}, {'number': 3, 'created': '2017-01-31 17:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/48a83763abceb8652b38e28084255c2c7848f28b', 'message': 'stable/ocata CI run - do not merge\n\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}, {'number': 4, 'created': '2017-02-13 15:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/248d6c413796c5e32f711f81145806ac43e9549e', 'message': 'stable/ocata CI run - do not merge\n\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}, {'number': 5, 'created': '2017-02-14 02:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b786197ecb064aaa5e1a59ddb43e8db2632556e6', 'message': 'stable/ocata CI run - do not merge\n\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}, {'number': 6, 'created': '2017-02-17 00:04:33.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c39b8c9d9e4b09f2dcda5153bdf668eec6b7bf04', 'message': 'stable/ocata CI run - do not merge\n\nDepends-On: I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83\nChange-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a\n'}]",0,426231,c39b8c9d9e4b09f2dcda5153bdf668eec6b7bf04,79,3,6,3153,,,0,"stable/ocata CI run - do not merge

Depends-On: I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83
Change-Id: I6738d864af3b3a6120daa22d505fc0a6ff6c891a
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/31/426231/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,5e982bf8b172f850814c76219b46e7e641237f13,cirun,test ,,1,0
openstack%2Ftripleo-heat-templates~master~I966b96c50224656b152045c97aa23b9495618a18,openstack/tripleo-heat-templates,master,I966b96c50224656b152045c97aa23b9495618a18,Switch to net-config-multinode,MERGED,2017-01-27 19:40:20.000000000,2017-02-18 21:32:20.000000000,2017-02-18 20:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-01-27 19:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4352748bd502a06927494a97815c58353cf50478', 'message': 'DNM - test scnario001-upgrade experimental job\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 2, 'created': '2017-01-27 20:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/214bd325b2ae6d396675cc40e78ee067a930ef0b', 'message': 'DNM - test scnario001-upgrade experimental job\n\nbla\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 3, 'created': '2017-01-27 21:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc6140ebe9dbf9d15272377fb9bd5d6e6afb90bc', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 4, 'created': '2017-01-28 03:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dba67c84cac0b0a78c3e5d667263e52220c13aba', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 5, 'created': '2017-01-30 19:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d7a1e61c33e1ad2de2445871e4959579cd38b454', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 6, 'created': '2017-02-01 22:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d0cee278b0598dca32ffd96937586b42360303c9', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 7, 'created': '2017-02-02 08:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/48b5d326a35795efff17f8b3e7b41958ea67d041', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 8, 'created': '2017-02-02 15:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/98bdd3feb100b16f17dd328ba3e14706d54afaf9', 'message': 'DNM - test scnario001-upgrade experimental job\n\nblaaa\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n'}, {'number': 9, 'created': '2017-02-02 22:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ab1a872b54d3b25c184ff5d0c659f81446e81a76', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 10, 'created': '2017-02-03 22:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/027484c80c3f2685c2eeb3ef03d88f1aed452c1c', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 11, 'created': '2017-02-09 14:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ade67bba98420e83a22841d8e0759d0805ec0f3', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 12, 'created': '2017-02-10 15:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fde1982e53bdecaff4b01726aecc799a7a520deb', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 13, 'created': '2017-02-11 01:28:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68ef621036043b50fc29acbf055b16343148a292', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 14, 'created': '2017-02-13 14:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e7a3ab535389fe8234d6ab20646dcc1b3ec7d5d3', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I24afa8f56ed9bcdcad0888ba480099ec5beb2961\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 15, 'created': '2017-02-14 02:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/53ae2c2942b189f8c01dcfb85caa4bf5f9fc16e0', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 16, 'created': '2017-02-14 02:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/670955731dd059bee8fbd09edf655b3b30a9ad73', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 17, 'created': '2017-02-14 16:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf5ac8b43662eef13071f4acfd9df0acd161195a', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I6e800ec41e0abf600c88a24c2895906d4c77180c\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 18, 'created': '2017-02-14 16:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/735d60896eb1a7f70b6ef7aee35a6771b1a6b52b', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nDepends-On: I6e800ec41e0abf600c88a24c2895906d4c77180c\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 19, 'created': '2017-02-16 20:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a67492e89d7c8edbd2c1ff9ca0856fead6ae212', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 20, 'created': '2017-02-16 20:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c4dc50f0f6f223f7c07ba35df218a878d99e1a9', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}, {'number': 21, 'created': '2017-02-17 12:10:22.000000000', 'files': ['ci/environments/scenario004-multinode.yaml', 'ci/environments/scenario001-multinode.yaml', 'ci/environments/scenario002-multinode.yaml', 'ci/environments/scenario003-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4061dfe790f2614f253a6f0e14bf3dd056e20ce1', 'message': ""Switch to net-config-multinode\n\nBecause of this bug:\nhttps://bugs.launchpad.net/tripleo/+bug/1661412\n\nWe are unable to upgrade from Newton.\nUntil we figure this out, let's re-enable the previous SoftwareConfig.\n\nChange-Id: I966b96c50224656b152045c97aa23b9495618a18\n""}]",0,426372,4061dfe790f2614f253a6f0e14bf3dd056e20ce1,127,4,21,3153,,,0,"Switch to net-config-multinode

Because of this bug:
https://bugs.launchpad.net/tripleo/+bug/1661412

We are unable to upgrade from Newton.
Until we figure this out, let's re-enable the previous SoftwareConfig.

Change-Id: I966b96c50224656b152045c97aa23b9495618a18
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/426372/21 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,4352748bd502a06927494a97815c58353cf50478,scenario001/upgrade,test ,,1,0
openstack%2Fstackviz~master~I5ca5b7d0c2c4c2242d0738762ede3b24202a1e52,openstack/stackviz,master,I5ca5b7d0c2c4c2242d0738762ede3b24202a1e52,Fix docs build,MERGED,2017-02-18 21:05:56.000000000,2017-02-18 21:29:02.000000000,2017-02-18 21:29:02.000000000,"[{'_account_id': 3}, {'_account_id': 17001}]","[{'number': 1, 'created': '2017-02-18 21:05:56.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/stackviz/commit/61cc01edbbc8e5d8fb2f24e6ff059bb464a39acf', 'message': 'Fix docs build\n\nThis ports over the change from [1] that fixes the docs build, caused\nby a bad docutils version.\n\n[1] https://review.openstack.org/#/c/410038/\n\nChange-Id: I5ca5b7d0c2c4c2242d0738762ede3b24202a1e52\n'}]",0,435730,61cc01edbbc8e5d8fb2f24e6ff059bb464a39acf,6,2,1,17001,,,0,"Fix docs build

This ports over the change from [1] that fixes the docs build, caused
by a bad docutils version.

[1] https://review.openstack.org/#/c/410038/

Change-Id: I5ca5b7d0c2c4c2242d0738762ede3b24202a1e52
",git fetch https://review.opendev.org/openstack/stackviz refs/changes/30/435730/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,61cc01edbbc8e5d8fb2f24e6ff059bb464a39acf,,"docutils>=0.11,!=0.13.1 # OSI-Approved Open Source, Public Domain",,1,0
openstack%2Fpython-zunclient~master~Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a,openstack/python-zunclient,master,Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a,Add more container related test,MERGED,2017-02-10 10:06:49.000000000,2017-02-18 21:28:54.000000000,2017-02-18 21:28:54.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11536}, {'_account_id': 22076}]","[{'number': 1, 'created': '2017-02-10 10:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/eb98a07c643477a987484040a21f1f98c189e8fd', 'message': 'Add more container related test\n\nChange-Id: Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a\n'}, {'number': 2, 'created': '2017-02-14 12:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/8fd30b17e28386f935645736506bc1f6bdd1c6df', 'message': 'Add more container related test\n\nChange-Id: Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a\n'}, {'number': 3, 'created': '2017-02-18 17:55:33.000000000', 'files': ['zunclient/tests/functional/osc/v1/test_container.py', 'zunclient/tests/functional/osc/v1/base.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/c78933754b8996701dbef30c9729d4f7ba89f75a', 'message': 'Add more container related test\n\nChange-Id: Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a\n'}]",0,432221,c78933754b8996701dbef30c9729d4f7ba89f75a,21,4,3,21785,,,0,"Add more container related test

Change-Id: Ic7ebdb3f57ce44d15fabcacd9a26661dd9da384a
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/21/432221/3 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/tests/functional/base.py', 'zunclient/tests/functional/osc/v1/test_container.py', 'zunclient/tests/functional/osc/v1/base.py']",3,eb98a07c643477a987484040a21f1f98c189e8fd,more_test," def container_create(self, image='cirros', name=None, params=''): """"""Create container and add cleanup. :param String image: Image for a new container :param String name: Name for a new container :param String params: Additional args and kwargs :return: JSON object of created container """""" if not name: name = data_utils.rand_name('container') opts = self.get_opts() output = self.openstack('appcontainer create {0}' ' {1} --name {2} {3}' .format(opts, image, name, params)) container = json.loads(output) #self.addCleanup(self.container_delete, container['uuid'], True) if not output: self.fail('Container has not been created!') return container def container_delete(self, identifier, ignore_exceptions=False): """"""Try to delete container by name or UUID. :param String identifier: Name or UUID of the container :param Bool ignore_exceptions: Ignore exception (needed for cleanUp) :return: raw values output :raise: CommandFailed exception when command fails to delete a container """""" try: return self.openstack('appcontainer delete {0}' .format(identifier)) except exceptions.CommandFailed: if not ignore_exceptions: raise ",,96,4
openstack%2Ftripleo-heat-templates~master~I43a564a1e19510baa26a9e3067ec266def10e1d6,openstack/tripleo-heat-templates,master,I43a564a1e19510baa26a9e3067ec266def10e1d6,Change hyperconverged-ceph merge strategy,ABANDONED,2016-10-20 20:30:40.000000000,2017-02-18 20:46:21.000000000,,"[{'_account_id': 3}, {'_account_id': 6796}]","[{'number': 1, 'created': '2016-10-20 20:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ba977118a6a4289dac2514cb5da7364f087cfa65', 'message': 'Change hyperconverged-ceph merge strategy\n\nChange parameter_merge_strategies in hyperconverged-ceph.yaml\nfrom merge to deep_merge.\n\nChange-Id: I43a564a1e19510baa26a9e3067ec266def10e1d6\nCloses-Bug: bug/1635409\n'}, {'number': 2, 'created': '2016-10-20 20:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/26ddfd2a2e564e1008d9e645bd113a1d8cb4e6bc', 'message': 'Change hyperconverged-ceph merge strategy\n\nChange parameter_merge_strategies in hyperconverged-ceph.yaml\nfrom merge to deep_merge.\n\nChange-Id: I43a564a1e19510baa26a9e3067ec266def10e1d6\nCloses-Bug: 1635409\n'}, {'number': 3, 'created': '2016-10-20 20:42:41.000000000', 'files': ['environments/hyperconverged-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04170d44130c242511a0487fe0927060db05a18e', 'message': 'Change hyperconverged-ceph merge strategy\n\nChange parameter_merge_strategies in hyperconverged-ceph.yaml\nfrom merge to deep_merge.\n\nChange-Id: I43a564a1e19510baa26a9e3067ec266def10e1d6\nCloses-Bug: 1635409\n'}]",2,389342,04170d44130c242511a0487fe0927060db05a18e,9,2,3,18002,,,0,"Change hyperconverged-ceph merge strategy

Change parameter_merge_strategies in hyperconverged-ceph.yaml
from merge to deep_merge.

Change-Id: I43a564a1e19510baa26a9e3067ec266def10e1d6
Closes-Bug: 1635409
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/389342/3 && git format-patch -1 --stdout FETCH_HEAD,['environments/hyperconverged-ceph.yaml'],1,ba977118a6a4289dac2514cb5da7364f087cfa65,bug/1635409, ComputeServices: deep_merge , ComputeServices: merge,1,1
openstack%2Fopenstack-ansible-os_magnum~stable%2Focata~If913ce20622f13c1e5a73e5a010ad421568c681c,openstack/openstack-ansible-os_magnum,stable/ocata,If913ce20622f13c1e5a73e5a010ad421568c681c,Update repo for stable/ocata,MERGED,2017-02-08 10:43:27.000000000,2017-02-18 20:43:28.000000000,2017-02-18 20:43:28.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-08 10:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/76bc327c61eeb503ea91ca884640aa69e0a514ec', 'message': 'Update repo for stable/ocata\n\nChange-Id: If913ce20622f13c1e5a73e5a010ad421568c681c\n'}, {'number': 2, 'created': '2017-02-08 10:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/289deb4ab58e5eb7b381b65678f055035dcdb211', 'message': 'Update repo for stable/ocata\n\nChange-Id: If913ce20622f13c1e5a73e5a010ad421568c681c\n'}, {'number': 3, 'created': '2017-02-10 13:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/cf581f22f97a7e00190e592f91e707d9f99a4d12', 'message': 'Update repo for stable/ocata\n\nChange-Id: If913ce20622f13c1e5a73e5a010ad421568c681c\n'}, {'number': 4, 'created': '2017-02-14 19:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/550aa11c29e875d99f4ba253c3c1a49687f58df8', 'message': 'Update repo for stable/ocata\n\nChange-Id: If913ce20622f13c1e5a73e5a010ad421568c681c\n'}, {'number': 5, 'created': '2017-02-18 11:55:59.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tests/magnum-test-vars.yml', 'tox.ini', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/1870169ba5704b954bfcc7ef021919ddf14af4b4', 'message': 'Update repo for stable/ocata\n\nChange-Id: If913ce20622f13c1e5a73e5a010ad421568c681c\n'}]",0,430744,1870169ba5704b954bfcc7ef021919ddf14af4b4,25,4,5,6816,,,0,"Update repo for stable/ocata

Change-Id: If913ce20622f13c1e5a73e5a010ad421568c681c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/44/430744/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tox.ini', 'defaults/main.yml']",3,76bc327c61eeb503ea91ca884640aa69e0a514ec,create-ocata,magnum_git_install_branch: stable/ocata,magnum_git_install_branch: master,22,22
openstack%2Finstack-undercloud~stable%2Focata~I0ccc38ab2792bb77be283fb2fecdb389ef40003d,openstack/instack-undercloud,stable/ocata,I0ccc38ab2792bb77be283fb2fecdb389ef40003d,Allow to teardown Telemetry services,MERGED,2017-02-18 15:21:19.000000000,2017-02-18 20:38:34.000000000,2017-02-18 20:38:34.000000000,"[{'_account_id': 3}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-18 15:21:19.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/44169b1e9ac0cac2a80ad1eb803b3876bae2cf71', 'message': 'Allow to teardown Telemetry services\n\nWhen enable_telemetry=false, make sure all Telemetry resources are down:\n\n- remove packages\n- remove services (note: removing packages will stop services not started in httpd)\n- remove config files\n\nChange-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d\nCloses-bug: #1664654\n(cherry picked from commit 2887601a2eb01991d4ed999d7383f7ae538290eb)\n'}]",0,435711,44169b1e9ac0cac2a80ad1eb803b3876bae2cf71,7,2,1,3153,,,0,"Allow to teardown Telemetry services

When enable_telemetry=false, make sure all Telemetry resources are down:

- remove packages
- remove services (note: removing packages will stop services not started in httpd)
- remove config files

Change-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d
Closes-bug: #1664654
(cherry picked from commit 2887601a2eb01991d4ed999d7383f7ae538290eb)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/11/435711/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,44169b1e9ac0cac2a80ad1eb803b3876bae2cf71,bug/1664654,"} else { # If Telemetry is disabled, ensure we tear down everything: # packages, services, configuration files. Package { [ 'python-aodh', 'python-ceilometer', 'python-gnocchi', 'python-panko' ]: ensure => 'purged', notify => Service['httpd'], } File { [ '/etc/httpd/conf.d/10-aodh_wsgi.conf', '/etc/httpd/conf.d/10-ceilometer_wsgi.conf', '/etc/httpd/conf.d/10-gnocchi_wsgi.conf', '/etc/httpd/conf.d/10-panko_wsgi.conf', ]: ensure => absent, notify => Service['httpd'], }",,21,0
openstack%2Finstack-undercloud~stable%2Focata~I40faf8f07a74f7a33f304c8aff6d43a903a42b9e,openstack/instack-undercloud,stable/ocata,I40faf8f07a74f7a33f304c8aff6d43a903a42b9e,Set instance audit settings so nova sends notifications,MERGED,2017-02-18 15:21:25.000000000,2017-02-18 20:38:29.000000000,2017-02-18 20:38:29.000000000,"[{'_account_id': 3}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-18 15:21:25.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b5925eb783072fec358df0a22369ad82b9c925c2', 'message': 'Set instance audit settings so nova sends notifications\n\nCeilometer is not receiving notifications on undercloud. This is\nbecause the instance usage audit settings are missing.\n\nChange-Id: I40faf8f07a74f7a33f304c8aff6d43a903a42b9e\nCloses-bug: #1665636\n(cherry picked from commit 4c5335e896d7dbc621ddb994ea954c42c41d2e6c)\n'}]",0,435712,b5925eb783072fec358df0a22369ad82b9c925c2,7,2,1,3153,,,0,"Set instance audit settings so nova sends notifications

Ceilometer is not receiving notifications on undercloud. This is
because the instance usage audit settings are missing.

Change-Id: I40faf8f07a74f7a33f304c8aff6d43a903a42b9e
Closes-bug: #1665636
(cherry picked from commit 4c5335e896d7dbc621ddb994ea954c42c41d2e6c)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/12/435712/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,b5925eb783072fec358df0a22369ad82b9c925c2,bug/1665636,nova::compute::instance_usage_audit: true nova::compute::instance_usage_audit_period: 'hour',,2,0
openstack%2Fcinder~master~I7574c6eefddb8f085422387f9d4892b8dbe9977d,openstack/cinder,master,I7574c6eefddb8f085422387f9d4892b8dbe9977d,Output the driver info as json,MERGED,2017-02-10 18:18:39.000000000,2017-02-18 20:34:22.000000000,2017-02-11 01:25:41.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14208}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 16941}, {'_account_id': 18444}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21990}, {'_account_id': 23613}, {'_account_id': 24578}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-10 18:18:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1fa92d5723ae339f376bac31c4bf58c17ffb2a7d', 'message': 'Output the driver info as json\n\nThis patch fixes the output of the dict format to json, so it can be\nconsumed a bit easier.\n\nChange-Id: I7574c6eefddb8f085422387f9d4892b8dbe9977d\n'}, {'number': 2, 'created': '2017-02-10 21:24:20.000000000', 'files': ['tools/generate_driver_list.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/76304ef091588651c801c573567a6c3e7c8ec886', 'message': 'Output the driver info as json\n\nThis patch fixes the output of the dict format to json, so it can be\nconsumed a bit easier.\n\nChange-Id: I7574c6eefddb8f085422387f9d4892b8dbe9977d\n'}]",1,432414,76304ef091588651c801c573567a6c3e7c8ec886,43,23,2,5997,,,0,"Output the driver info as json

This patch fixes the output of the dict format to json, so it can be
consumed a bit easier.

Change-Id: I7574c6eefddb8f085422387f9d4892b8dbe9977d
",git fetch https://review.opendev.org/openstack/cinder refs/changes/14/432414/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/generate_driver_list.py'],1,1fa92d5723ae339f376bac31c4bf58c17ffb2a7d,driver_list_json,"import json """"""Output the results as a json dict."" print(json.dumps(driver_list))", import pprint pprint.pprint(driver_list),3,2
openstack%2Ftaskflow~master~I133cd4cbcc518a903b061768b7fb9a91a6fe44e6,openstack/taskflow,master,I133cd4cbcc518a903b061768b7fb9a91a6fe44e6,Updated from global requirements,MERGED,2017-02-11 00:39:41.000000000,2017-02-18 19:36:09.000000000,2017-02-18 19:36:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2017-02-11 00:39:41.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/96228d861633ab5d33add270e556a6f2e01aee40', 'message': 'Updated from global requirements\n\nChange-Id: I133cd4cbcc518a903b061768b7fb9a91a6fe44e6\n'}]",0,432505,96228d861633ab5d33add270e556a6f2e01aee40,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I133cd4cbcc518a903b061768b7fb9a91a6fe44e6
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/05/432505/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,96228d861633ab5d33add270e556a6f2e01aee40,openstack/requirements, kombu>=3.0.25 # BSD," kombu<4.0.0,>=3.0.25 # BSD",1,1
openstack%2Ftaskflow~stable%2Fmitaka~Ie24c528938e892136cf46151d27cbbfa6711fcd4,openstack/taskflow,stable/mitaka,Ie24c528938e892136cf46151d27cbbfa6711fcd4,Updated from global requirements,MERGED,2016-09-06 09:22:22.000000000,2017-02-18 19:36:03.000000000,2017-02-18 19:36:03.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2016-09-06 09:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3939cdea067965b0656a2c4d42bf7205a1db4f05', 'message': 'Updated from global requirements\n\nChange-Id: Ie24c528938e892136cf46151d27cbbfa6711fcd4\n'}, {'number': 2, 'created': '2016-11-10 09:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f608454464935b2596afdd38d7c840f0c1e536ff', 'message': 'Updated from global requirements\n\nChange-Id: Ie24c528938e892136cf46151d27cbbfa6711fcd4\n'}, {'number': 3, 'created': '2016-12-12 10:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e6516d43afbdb44efd08c5d1924769f1a0d09df1', 'message': 'Updated from global requirements\n\nChange-Id: Ie24c528938e892136cf46151d27cbbfa6711fcd4\n'}, {'number': 4, 'created': '2017-02-17 18:04:04.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d4da5911cd535f4fc9a2c246e72eb063d51650d0', 'message': 'Updated from global requirements\n\nChange-Id: Ie24c528938e892136cf46151d27cbbfa6711fcd4\n'}]",0,365991,d4da5911cd535f4fc9a2c246e72eb063d51650d0,12,2,4,11131,,,0,"Updated from global requirements

Change-Id: Ie24c528938e892136cf46151d27cbbfa6711fcd4
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/91/365991/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,3939cdea067965b0656a2c4d42bf7205a1db4f05,openstack/requirements,"PyMySQL!=0.7.7,>=0.6.2 # MIT License",PyMySQL>=0.6.2 # MIT License,1,1
openstack%2Ftaskflow~stable%2Focata~I0c9d00b73522cbb2015540575bc5750cce0ccca5,openstack/taskflow,stable/ocata,I0c9d00b73522cbb2015540575bc5750cce0ccca5,Change BRANCH_NAME to stable/ocata in tox.ini,MERGED,2017-02-16 06:39:57.000000000,2017-02-18 19:25:01.000000000,2017-02-18 19:25:01.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2017-02-16 06:39:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/101d6d0d37b53e4782ec211aa7e8ecb545091a96', 'message': 'Change BRANCH_NAME to stable/ocata in tox.ini\n\nEnsure env variable BRANCH_NAME with right value.\n\nChange-Id: I0c9d00b73522cbb2015540575bc5750cce0ccca5\n'}]",0,434672,101d6d0d37b53e4782ec211aa7e8ecb545091a96,6,2,1,9796,,,0,"Change BRANCH_NAME to stable/ocata in tox.ini

Ensure env variable BRANCH_NAME with right value.

Change-Id: I0c9d00b73522cbb2015540575bc5750cce0ccca5
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/72/434672/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,101d6d0d37b53e4782ec211aa7e8ecb545091a96,, BRANCH_NAME=stable/ocata, BRANCH_NAME=master,1,1
openstack%2Fec2-api~master~Ibe1ed969dd223eee623ce7d2fdbc765fc880bb2d,openstack/ec2-api,master,Ibe1ed969dd223eee623ce7d2fdbc765fc880bb2d,increase version for master branch,MERGED,2017-02-17 15:31:21.000000000,2017-02-18 19:10:14.000000000,2017-02-18 19:10:14.000000000,"[{'_account_id': 3}, {'_account_id': 10224}]","[{'number': 1, 'created': '2017-02-17 15:31:21.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/d2c146e6935c95cabb394e5161cab4750e66feaa', 'message': 'increase version for master branch\n\nstable/ocata has been created\n\nChange-Id: Ibe1ed969dd223eee623ce7d2fdbc765fc880bb2d\n'}]",0,435489,d2c146e6935c95cabb394e5161cab4750e66feaa,6,2,1,10234,,,0,"increase version for master branch

stable/ocata has been created

Change-Id: Ibe1ed969dd223eee623ce7d2fdbc765fc880bb2d
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/89/435489/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,d2c146e6935c95cabb394e5161cab4750e66feaa,master-2,version = 5.0.0,version = 4.0.0,1,1
openstack%2Fproject-config~master~I4d0eba12415aa820ac38d5a0f02f3ed058f54af7,openstack/project-config,master,I4d0eba12415aa820ac38d5a0f02f3ed058f54af7,Normalize projects.yaml,MERGED,2017-02-17 08:13:09.000000000,2017-02-18 19:03:56.000000000,2017-02-18 19:03:56.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-17 08:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/84b4cf53fd91aeb1a3cdf462b747c39dcdf189b6', 'message': 'Normalize projects.yaml\n\nChange-Id: I4d0eba12415aa820ac38d5a0f02f3ed058f54af7\n'}, {'number': 2, 'created': '2017-02-18 08:14:32.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8fd38ede70031f2a69b16fb1151fef4b37edc023', 'message': 'Normalize projects.yaml\n\nChange-Id: I4d0eba12415aa820ac38d5a0f02f3ed058f54af7\n'}]",0,435298,8fd38ede70031f2a69b16fb1151fef4b37edc023,10,2,2,11131,,,0,"Normalize projects.yaml

Change-Id: I4d0eba12415aa820ac38d5a0f02f3ed058f54af7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/435298/2 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,84b4cf53fd91aeb1a3cdf462b747c39dcdf189b6,project-yaml-normalization,, upstream: https://github.com/rgerganov/vmware-vspc,0,1
openstack%2Fgnocchi~master~I1ddc78f64f3d909b1fa917e04717f2ccbd194d1d,openstack/gnocchi,master,I1ddc78f64f3d909b1fa917e04717f2ccbd194d1d,sqlalchemy: factorize retry on transaction issue/table def change,MERGED,2017-01-26 21:40:58.000000000,2017-02-18 18:40:45.000000000,2017-02-18 18:40:45.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2017-01-26 21:40:58.000000000', 'files': ['gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/9ea432183772767634d61218bbba48508c960c9b', 'message': 'sqlalchemy: factorize retry on transaction issue/table def change\n\nThis moves the retry condition to a common code for MySQL and PostgreSQL.\n\nChange-Id: I1ddc78f64f3d909b1fa917e04717f2ccbd194d1d\n'}]",0,425939,9ea432183772767634d61218bbba48508c960c9b,9,3,1,1669,,,0,"sqlalchemy: factorize retry on transaction issue/table def change

This moves the retry condition to a common code for MySQL and PostgreSQL.

Change-Id: I1ddc78f64f3d909b1fa917e04717f2ccbd194d1d
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/39/425939/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/sqlalchemy.py'],1,9ea432183772767634d61218bbba48508c960c9b,jd/mysql-retry-new-error-lol," if not isinstance(exc, exception.DBError): return False inn_e = exception.inner_exception if not isinstance(inn_e, sqlalchemy.exc.InternalError): return False return (( isinstance(inn_e.orig, pymysql.err.InternalError) and (inn_e.orig.args[0] == pymysql.constants.ER.TABLE_DEF_CHANGED) ) or ( # HACK(jd) Sometimes, PostgreSQL raises an error such as ""current # transaction is aborted, commands ignored until end of transaction # block"" on its own catalog, so we need to retry, but this is not # caught by oslo.db as a deadlock. This is likely because when we use # Base.metadata.create_all(), sqlalchemy itself gets an error it does # not catch or something. So this is why this function exists. To # paperover I guess. psycopg2 and isinstance(inn_e.orig, psycopg2.InternalError) # current transaction is aborted and inn_e.orig.pgcode == '25P02' )) with facade.writer_connection() as connection: Base.metadata.create_all(connection, tables=tables) for table in tables: for fk in table.foreign_key_constraints: try: self._safe_execute( connection, sqlalchemy.schema.DropConstraint(fk)) except exception.DBNonExistentConstraint: for table in tables: try: self._safe_execute(connection, sqlalchemy.schema.DropTable(table)) except exception.DBNonExistentTable: pass"," return ( isinstance(exc, exception.DBError) and isinstance(exc.inner_exception, sqlalchemy.exc.InternalError) and isinstance(exc.inner_exception.orig, pymysql.err.InternalError) and (exc.inner_exception.orig.args[0] == pymysql.constants.ER.TABLE_DEF_CHANGED) ) try: with facade.writer_connection() as connection: Base.metadata.create_all(connection, tables=tables) except exception.DBError as e: if self._is_current_transaction_aborted(e): raise exception.RetryRequest(e) raise @staticmethod def _is_current_transaction_aborted(exception): # HACK(jd) Sometimes, PostgreSQL raises an error such as ""current # transaction is aborted, commands ignored until end of transaction # block"" on its own catalog, so we need to retry, but this is not # caught by oslo.db as a deadlock. This is likely because when we use # Base.metadata.create_all(), sqlalchemy itself gets an error it does # not catch or something. So this is why this function exists. To # paperover I guess. inn_e = exception.inner_exception return (psycopg2 and isinstance(inn_e, sqlalchemy.exc.InternalError) and isinstance(inn_e.orig, psycopg2.InternalError) # current transaction is aborted and inn_e.orig.pgcode == '25P02') try: for table in tables: for fk in table.foreign_key_constraints: try: self._safe_execute( connection, sqlalchemy.schema.DropConstraint(fk)) except exception.DBNonExistentConstraint: pass for table in tables: try: self._safe_execute(connection, sqlalchemy.schema.DropTable(table)) except exception.DBNonExistentTable: except exception.DBError as e: if self._is_current_transaction_aborted(e): raise exception.RetryRequest(e) raise",35,47
openstack%2Fkolla-kubernetes~master~I161c7716337a588a895fd7a890f9e032889aa46f,openstack/kolla-kubernetes,master,I161c7716337a588a895fd7a890f9e032889aa46f,Fix spell error: the 'Waitng' is lack of letter 'i'.,MERGED,2017-02-13 08:41:07.000000000,2017-02-18 18:32:22.000000000,2017-02-18 18:32:22.000000000,"[{'_account_id': 3}, {'_account_id': 11869}, {'_account_id': 17591}, {'_account_id': 19384}, {'_account_id': 22368}, {'_account_id': 22959}]","[{'number': 1, 'created': '2017-02-13 08:41:07.000000000', 'files': ['tools/wait_for_pods_termination.sh'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b7f249e630835b1a5cf2b4c3089baf8268dba986', 'message': ""Fix spell error: the 'Waitng' is lack of letter 'i'.\n\nChange-Id: I161c7716337a588a895fd7a890f9e032889aa46f\n""}]",0,432916,b7f249e630835b1a5cf2b4c3089baf8268dba986,12,6,1,21618,,,0,"Fix spell error: the 'Waitng' is lack of letter 'i'.

Change-Id: I161c7716337a588a895fd7a890f9e032889aa46f
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/16/432916/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/wait_for_pods_termination.sh'],1,b7f249e630835b1a5cf2b4c3089baf8268dba986,fix_spell_err, echo 'Waiting for pod to terminate: ' $now, echo 'Waitng for pod to terminate: ' $now,1,1
openstack%2Fopenstack-doc-tools~master~I7a2f198846a279f2191bdf17e53b582e07e000cd,openstack/openstack-doc-tools,master,I7a2f198846a279f2191bdf17e53b582e07e000cd,[cli-ref] support required arguments option,MERGED,2017-02-10 11:56:12.000000000,2017-02-18 18:29:18.000000000,2017-02-18 18:29:18.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2017-02-10 11:56:12.000000000', 'files': ['os_doc_tools/commands.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/c73092d3989d7acb0548041671a8766ea5bf79d6', 'message': '[cli-ref] support required arguments option\n\nChange-Id: I7a2f198846a279f2191bdf17e53b582e07e000cd\nPartial-Bug: #1643540\n'}]",0,432269,c73092d3989d7acb0548041671a8766ea5bf79d6,8,3,1,10497,,,0,"[cli-ref] support required arguments option

Change-Id: I7a2f198846a279f2191bdf17e53b582e07e000cd
Partial-Bug: #1643540
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/69/432269/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/commands.py'],1,c73092d3989d7acb0548041671a8766ea5bf79d6,bug/1643540," if line.startswith(('Arguments:', 'Positional arguments:', 'positional arguments', 'Optional arguments', 'optional arguments', 'Required arguments', 'required arguments')): skip_lines = True continue elif line.startswith(('Required arguments:', 'required arguments')): format_help('Required arguments', help_lines[line_index + 1:], os_file) skip_lines = True continue"," if line.startswith(('Arguments:', 'Positional arguments:', 'positional arguments', 'Optional arguments', 'optional arguments')): break",12,4
openstack%2Fproject-config~master~If353670fb82976e04a972de068d066941cda6303,openstack/project-config,master,If353670fb82976e04a972de068d066941cda6303,Leverage zuul-cloner (instead of git) in diskimage-builder,ABANDONED,2016-08-30 20:28:17.000000000,2017-02-18 18:17:04.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-08-30 20:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/472e8a466ca3fd85b264b286dca1de6c0b4e6a5e', 'message': 'Leverage zuul-cloner (instead of git) in diskimage-builder\n\nCurrently, diskimage-builder directly uses git clone for cloning source\nrepositories. This prevents the usage of the ""Depends-On:"" notation.\n\nDiskimage-builder now supports a special flag, \'-z\', to use zuul-cloner\ninstead of git clone in the source-repositories element. This commit\nmakes use of it by passing the new flag.\n\nChange-Id: If353670fb82976e04a972de068d066941cda6303\nDepends-On: Ic74fbe340e45d46f2545a2c7401493f183199030\n'}, {'number': 2, 'created': '2016-08-30 20:30:34.000000000', 'files': ['jenkins/jobs/diskimage-builder.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/db58829d3658c89320aba1ac59b27f59d0400481', 'message': 'Leverage zuul-cloner (instead of git) in diskimage-builder\n\nCurrently, diskimage-builder directly uses git clone for cloning source\nrepositories. This prevents the usage of the ""Depends-On:"" notation.\n\nDiskimage-builder now supports a special flag, \'-z\', to use zuul-cloner\ninstead of git clone in the source-repositories element. This commit\nmakes use of it by passing the new flag.\n\nChange-Id: If353670fb82976e04a972de068d066941cda6303\nDepends-On: Ic74fbe340e45d46f2545a2c7401493f183199030\nCloses-bug: #1616999\n'}]",0,363190,db58829d3658c89320aba1ac59b27f59d0400481,5,2,2,7080,,,0,"Leverage zuul-cloner (instead of git) in diskimage-builder

Currently, diskimage-builder directly uses git clone for cloning source
repositories. This prevents the usage of the ""Depends-On:"" notation.

Diskimage-builder now supports a special flag, '-z', to use zuul-cloner
instead of git clone in the source-repositories element. This commit
makes use of it by passing the new flag.

Change-Id: If353670fb82976e04a972de068d066941cda6303
Depends-On: Ic74fbe340e45d46f2545a2c7401493f183199030
Closes-bug: #1616999
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/363190/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/diskimage-builder.yaml'],1,472e8a466ca3fd85b264b286dca1de6c0b4e6a5e,bug/1616999, ./openstack/diskimage-builder/tests/run_functests.sh -z {tests}, ./openstack/diskimage-builder/tests/run_functests.sh {tests},1,1
openstack%2Fproject-config~master~I30c0cf58f81eee0fdf1e121e5a0877abd38b1387,openstack/project-config,master,I30c0cf58f81eee0fdf1e121e5a0877abd38b1387,networking-odl: experimental job for netwon + ODL carbon,ABANDONED,2016-12-08 19:10:19.000000000,2017-02-18 18:13:53.000000000,,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 6547}, {'_account_id': 10980}, {'_account_id': 13995}]","[{'number': 1, 'created': '2016-12-08 19:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e1c6f3327026ab85ec8332ed736338278f6ad110', 'message': ""networking-odl: experimental job for netwon + ODL carbon\n\nIn order to detect breakage due to opendaylight update, periodic job\nwould be run against stable/newton + opendaylight master.\nAdd the job as experimental at first.\nOnce we're confident, it will be made periodic job.\nAlso add periodic job of mitaka + ODL boron to experimental\nfor debug.\n\nChange-Id: I30c0cf58f81eee0fdf1e121e5a0877abd38b1387\n""}, {'number': 2, 'created': '2016-12-15 17:53:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cc18b2f8f5059f8dafa92ad8de67833f469c6110', 'message': ""networking-odl: experimental job for netwon + ODL carbon\n\nIn order to detect breakage due to opendaylight update, periodic job\nwould be run against stable/newton + opendaylight master.\nAdd the job as experimental at first.\nOnce we're confident, it will be made periodic job.\nAlso add periodic job of mitaka + ODL boron to experimental\nfor debug.\n\nChange-Id: I30c0cf58f81eee0fdf1e121e5a0877abd38b1387\n""}, {'number': 3, 'created': '2016-12-15 22:41:59.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/03687b5b56846d13c5757e25136a76c7b0383876', 'message': ""networking-odl: experimental job for netwon + ODL carbon\n\nIn order to detect breakage due to opendaylight update, periodic job\nwould be run against stable/newton + opendaylight master.\nAdd the job as experimental at first.\nOnce we're confident, it will be made periodic job.\nAlso add periodic job of mitaka + ODL boron to experimental\nfor debug.\n\nChange-Id: I30c0cf58f81eee0fdf1e121e5a0877abd38b1387\n""}]",6,408780,03687b5b56846d13c5757e25136a76c7b0383876,14,6,3,333,,,0,"networking-odl: experimental job for netwon + ODL carbon

In order to detect breakage due to opendaylight update, periodic job
would be run against stable/newton + opendaylight master.
Add the job as experimental at first.
Once we're confident, it will be made periodic job.
Also add periodic job of mitaka + ODL boron to experimental
for debug.

Change-Id: I30c0cf58f81eee0fdf1e121e5a0877abd38b1387
",git fetch https://review.opendev.org/openstack/project-config refs/changes/80/408780/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,e1c6f3327026ab85ec8332ed736338278f6ad110,netwokring-odl-periodic-experimental, experimental: - periodic-tempest-dsvm-networking-odl-boron-snapshot-mitaka - periodic-tempest-dsvm-networking-odl-carbon-snapshot-newton,,9,0
openstack%2Fgnocchi~stable%2F3.1~Idbd0de3452828d0b19946c09b31c27656a1d959b,openstack/gnocchi,stable/3.1,Idbd0de3452828d0b19946c09b31c27656a1d959b,s3: fix new metric listing,MERGED,2017-02-17 21:27:56.000000000,2017-02-18 17:58:35.000000000,2017-02-18 17:58:35.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-02-17 21:27:56.000000000', 'files': ['gnocchi/storage/incoming/s3.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/5b2820ac14631c0d5e8ac1cd129056c59a5ce039', 'message': ""s3: fix new metric listing\n\nIt's impossible to index a set\n\nChange-Id: Idbd0de3452828d0b19946c09b31c27656a1d959b\n(cherry picked from commit e8139066612e2958e29c75befcbdf2583ca273cb)\n""}]",0,435605,5b2820ac14631c0d5e8ac1cd129056c59a5ce039,10,2,1,1669,,,0,"s3: fix new metric listing

It's impossible to index a set

Change-Id: Idbd0de3452828d0b19946c09b31c27656a1d959b
(cherry picked from commit e8139066612e2958e29c75befcbdf2583ca273cb)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/05/435605/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/incoming/s3.py'],1,5b2820ac14631c0d5e8ac1cd129056c59a5ce039,jd/fix-s3, return sorted(list(metrics))[size * part:], return metrics[size * part:],1,1
openstack%2Ftripleo-common~stable%2Focata~Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e,openstack/tripleo-common,stable/ocata,Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e,Open log in utf-8 to prevent UnicodeEncodeError,MERGED,2017-02-17 19:22:34.000000000,2017-02-18 17:48:56.000000000,2017-02-18 16:21:47.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}]","[{'number': 1, 'created': '2017-02-17 19:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a48951e47a418543ad939b4a242c077162352982', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n(cherry picked from commit 9d2a6dae35de3987aded8d4611040d7130d6dc91)\n'}, {'number': 2, 'created': '2017-02-18 15:22:22.000000000', 'files': ['tripleo_common/tests/image/test_image_builder.py', 'tripleo_common/image/image_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/346461d51d35eeadb6fc5dc97b4e4992e027d2d8', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n(cherry picked from commit 9d2a6dae35de3987aded8d4611040d7130d6dc91)\n'}]",0,435572,346461d51d35eeadb6fc5dc97b4e4992e027d2d8,11,3,2,14985,,,0,"Open log in utf-8 to prevent UnicodeEncodeError

In python2 opens files as ascii by default, we were getting errors when
trying to write out unicode to log files. This change pulls in the
codecs module for python2 to support writing unicode out to files. In
python3, all strings are unicode so there is no issues when writing them
out to a file.

Change-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e
Closes-Bug: #1665114
(cherry picked from commit 9d2a6dae35de3987aded8d4611040d7130d6dc91)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/72/435572/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_builder.py', 'tripleo_common/image/image_builder.py']",2,a48951e47a418543ad939b4a242c077162352982,bug/1665114,"if sys.version_info[0] < 3: import codecs _open = open open = codecs.open with open(log_file, 'w', encoding='utf-8') as f:"," with open(log_file, 'w') as f:",10,3
openstack%2Fcinder~master~Idec9f5138cd453e92b882bb33d508c2ee907a233,openstack/cinder,master,Idec9f5138cd453e92b882bb33d508c2ee907a233,Dell EMC Ps: Report discard support,MERGED,2017-02-09 20:14:10.000000000,2017-02-18 17:46:56.000000000,2017-02-12 19:17:00.000000000,"[{'_account_id': 3}, {'_account_id': 7160}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12112}, {'_account_id': 12369}, {'_account_id': 14208}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16595}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17565}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19852}, {'_account_id': 21863}, {'_account_id': 23613}, {'_account_id': 24502}, {'_account_id': 24578}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-09 20:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7221ab7dee741b686400e4abec6a87b481877dc2', 'message': 'Dell EMC Ps: Report discard support\n\nChanged the Dell EMC Ps volume driver to report\ndiscard support.\n\nCloses Bug: #1663030\n\nChange-Id: Idec9f5138cd453e92b882bb33d508c2ee907a233\n'}, {'number': 2, 'created': '2017-02-09 20:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/b632c821cdd155385549ec330a86ea1b2dff6af6', 'message': 'Dell EMC Ps: Report discard support\n\nChanged the Dell EMC PS Series volume driver to report\ndiscard support.\n\nCloses Bug: #1663030\n\nChange-Id: Idec9f5138cd453e92b882bb33d508c2ee907a233\n'}, {'number': 3, 'created': '2017-02-10 16:44:24.000000000', 'files': ['cinder/volume/drivers/dell_emc/ps.py', 'cinder/tests/unit/volume/drivers/dell_emc/test_ps.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/a9e91586d97c7aa7024a181e04d0076f7d5c274a', 'message': 'Dell EMC Ps: Report discard support\n\nChanged the Dell EMC PS Series volume driver to report\ndiscard support.\n\nCloses Bug: #1663030\n\nChange-Id: Idec9f5138cd453e92b882bb33d508c2ee907a233\n'}]",3,431734,a9e91586d97c7aa7024a181e04d0076f7d5c274a,71,23,3,10379,,,0,"Dell EMC Ps: Report discard support

Changed the Dell EMC PS Series volume driver to report
discard support.

Closes Bug: #1663030

Change-Id: Idec9f5138cd453e92b882bb33d508c2ee907a233
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/431734/3 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/ps.py', 'cinder/tests/unit/volume/drivers/dell_emc/test_ps.py']",2,7221ab7dee741b686400e4abec6a87b481877dc2,bug/1663030," 'volume_id': 1, 'discard': True} self.assertTrue(properties['data']['discard'])", 'volume_id': 1},6,2
openstack%2Fopenstacksdk~master~I45c3310e62d520018a523ef6524604f868d94136,openstack/openstacksdk,master,I45c3310e62d520018a523ef6524604f868d94136,[WIP] Fix test failures for image metadata,ABANDONED,2016-07-20 22:15:45.000000000,2017-02-18 17:11:19.000000000,,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2016-07-20 22:15:45.000000000', 'files': ['openstack/tests/functional/compute/v2/test_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e408267328d9b0c9ec3650a19dda92f89bfee3a6', 'message': ""[WIP] Fix test failures for image metadata\n\nThe following fixes the test failures. I haven't looked into if this is\nactually how it's supposed to work, so hold off until that is actually\nunderstood.\n\nChange-Id: I45c3310e62d520018a523ef6524604f868d94136\n""}]",0,345074,e408267328d9b0c9ec3650a19dda92f89bfee3a6,4,2,1,8257,,,0,"[WIP] Fix test failures for image metadata

The following fixes the test failures. I haven't looked into if this is
actually how it's supposed to work, so hold off until that is actually
understood.

Change-Id: I45c3310e62d520018a523ef6524604f868d94136
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/74/345074/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_image.py'],1,e408267328d9b0c9ec3650a19dda92f89bfee3a6,metadata_fail,"from openstack import exceptions # delete pre-existing metadata if there is any try: self.conn.compute.delete_image_metadata(image, image.metadata.keys()) except exceptions.NotFoundException: pass self.assertEqual({}, image.metadata) #self.assertRaises(exceptions.NotFoundException, # self.conn.compute.get_image_metadata, image) self.assertEqual({}, image.metadata)"," # delete pre-existing metadata self.conn.compute.delete_image_metadata(image, image.metadata.keys()) image = self.conn.compute.get_image_metadata(image) self.assertFalse(image.metadata) self.assertFalse(image.metadata) self.assertFalse(image.metadata)",11,6
openstack%2Fnetworking-calico~master~I36b9c1aa4adfaf3a9e0284709e3b2432bba41132,openstack/networking-calico,master,I36b9c1aa4adfaf3a9e0284709e3b2432bba41132,Replace basestring with six.string_types,MERGED,2016-11-23 07:16:45.000000000,2017-02-18 16:45:28.000000000,2017-02-18 16:45:28.000000000,"[{'_account_id': 3}, {'_account_id': 7787}, {'_account_id': 11898}, {'_account_id': 13734}]","[{'number': 1, 'created': '2016-11-23 07:16:45.000000000', 'files': ['networking_calico/common/__init__.py', 'networking_calico/etcdutils.py'], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/5f9d1cedab22319b6e5cecbd9bc874c3c5c127bc', 'message': 'Replace basestring with six.string_types\n\nhttps://wiki.openstack.org/wiki/Python3\n\nChange-Id: I36b9c1aa4adfaf3a9e0284709e3b2432bba41132\n'}]",0,401094,5f9d1cedab22319b6e5cecbd9bc874c3c5c127bc,37,4,1,20256,,,0,"Replace basestring with six.string_types

https://wiki.openstack.org/wiki/Python3

Change-Id: I36b9c1aa4adfaf3a9e0284709e3b2432bba41132
",git fetch https://review.opendev.org/openstack/networking-calico refs/changes/94/401094/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_calico/common/__init__.py', 'networking_calico/etcdutils.py']",2,5f9d1cedab22319b6e5cecbd9bc874c3c5c127bc,replace_basestring,"import six if isinstance(etcd_addrs, six.string_types):"," if isinstance(etcd_addrs, basestring):",4,2
openstack%2Ftooz~master~I12cdd455ea233233bbcd6e3c46db3d8d6077c6af,openstack/tooz,master,I12cdd455ea233233bbcd6e3c46db3d8d6077c6af,support unicode node name,MERGED,2017-02-14 18:07:50.000000000,2017-02-18 16:40:58.000000000,2017-02-18 16:40:58.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-02-14 18:07:50.000000000', 'files': ['tooz/hashring.py', 'tooz/tests/test_hashring.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/fbfa1c1162955ca13c61929d58b921dd1473427b', 'message': 'support unicode node name\n\nhashring fails if node name is unicode in python2\n\nChange-Id: I12cdd455ea233233bbcd6e3c46db3d8d6077c6af\n'}]",0,433836,fbfa1c1162955ca13c61929d58b921dd1473427b,12,2,1,6537,,,0,"support unicode node name

hashring fails if node name is unicode in python2

Change-Id: I12cdd455ea233233bbcd6e3c46db3d8d6077c6af
",git fetch https://review.opendev.org/openstack/tooz refs/changes/36/433836/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/hashring.py', 'tooz/tests/test_hashring.py']",2,fbfa1c1162955ca13c61929d58b921dd1473427b,unicode," def test_add_node_unicode(self): nodes = {'foo', 'bar'} ring = hashring.HashRing(nodes) self.assertEqual(nodes, set(ring.nodes.keys())) self.assertEqual(2 ** 5 * len(nodes), len(ring)) nodes.add(u'\u0634\u0628\u06a9\u0647') ring.add_node(u'\u0634\u0628\u06a9\u0647') self.assertEqual(nodes, set(ring.nodes.keys())) self.assertEqual(2 ** 5 * len(nodes), len(ring)) ",,12,2
openstack%2Fnetworking-midonet~stable%2Focata~I9d56698008cb5ef669fa2b7fb327ee5621bcc1b9,openstack/networking-midonet,stable/ocata,I9d56698008cb5ef669fa2b7fb327ee5621bcc1b9,Update .gitreview for stable/ocata,MERGED,2017-02-14 15:30:05.000000000,2017-02-18 16:39:36.000000000,2017-02-18 16:39:36.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 748}, {'_account_id': 6854}]","[{'number': 1, 'created': '2017-02-14 15:30:05.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/82049dfa6e0e5895e4c953220708a63cfd98a94d', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: I9d56698008cb5ef669fa2b7fb327ee5621bcc1b9\n'}]",0,433711,82049dfa6e0e5895e4c953220708a63cfd98a94d,12,4,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: I9d56698008cb5ef669fa2b7fb327ee5621bcc1b9
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/11/433711/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,82049dfa6e0e5895e4c953220708a63cfd98a94d,create-ocata,defaultbranch=stable/ocata,,1,0
openstack%2Ftripleo-ui~master~I1b19beb4882a7893229753954d863f2e0a13811e,openstack/tripleo-ui,master,I1b19beb4882a7893229753954d863f2e0a13811e,Imported Translations from Zanata,MERGED,2017-02-18 08:03:37.000000000,2017-02-18 16:22:56.000000000,2017-02-18 16:22:55.000000000,"[{'_account_id': 3}, {'_account_id': 4978}]","[{'number': 1, 'created': '2017-02-18 08:03:37.000000000', 'files': ['i18n/locales/zh-CN.json'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/dcac4053997e0f3dac91ce45fe2e6e3f545d0c92', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I1b19beb4882a7893229753954d863f2e0a13811e\n'}]",0,435669,dcac4053997e0f3dac91ce45fe2e6e3f545d0c92,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I1b19beb4882a7893229753954d863f2e0a13811e
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/69/435669/1 && git format-patch -1 --stdout FETCH_HEAD,['i18n/locales/zh-CN.json'],1,dcac4053997e0f3dac91ce45fe2e6e3f545d0c92,zanata/translations," ""Nodes.nodes"": ""\u8282\u70b9"", ""Nodes.registerNodes"": ""\u6ce8\u518c\u8282\u70b9"", ""RegisterNodeForm.name"": ""\u540d\u79f0"", ""RegisterNodesDialog.cancel"": ""\u53d6\u6d88"", ""RegisterNodesDialog.registerNodes"": ""\u6ce8\u518c\u8282\u70b9"",",,5,0
openstack%2Finstack-undercloud~master~If7fdf189fadd39cd6380c15a35f4b7d49cc42a96,openstack/instack-undercloud,master,If7fdf189fadd39cd6380c15a35f4b7d49cc42a96,Include swap in memory check,MERGED,2017-02-17 16:56:52.000000000,2017-02-18 16:20:27.000000000,2017-02-18 16:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-17 16:56:52.000000000', 'files': ['releasenotes/notes/include-swap-in-memory-check-fe378284f06aae1a.yaml', 'instack_undercloud/undercloud.py', 'instack_undercloud/tests/test_undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/0b20c8f119374b5c00765f5945d9b735a548219f', 'message': ""Include swap in memory check\n\nIt's not uncommon for developers to use SSD-backed swap to allow\nfor more instances on a limited memory baremetal system.  Previously\nthis was not allowed by the memory check because it only looked at\nphysical memory.  This change includes swap in the memory check so\nthat use case is supported out of the box.\n\nChange-Id: If7fdf189fadd39cd6380c15a35f4b7d49cc42a96\n""}]",0,435532,0b20c8f119374b5c00765f5945d9b735a548219f,8,3,1,6928,,,0,"Include swap in memory check

It's not uncommon for developers to use SSD-backed swap to allow
for more instances on a limited memory baremetal system.  Previously
this was not allowed by the memory check because it only looked at
physical memory.  This change includes swap in the memory check so
that use case is supported out of the box.

Change-Id: If7fdf189fadd39cd6380c15a35f4b7d49cc42a96
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/32/435532/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/include-swap-in-memory-check-fe378284f06aae1a.yaml', 'instack_undercloud/undercloud.py', 'instack_undercloud/tests/test_undercloud.py']",3,0b20c8f119374b5c00765f5945d9b735a548219f,," @mock.patch('psutil.swap_memory') def test_sufficient_memory(self, mock_vm, mock_sm): mock_sm.return_value = mock.Mock() mock_sm.return_value.total = 0 @mock.patch('psutil.swap_memory') def test_insufficient_memory(self, mock_vm, mock_sm): mock_sm.return_value = mock.Mock() mock_sm.return_value.total = 0 @mock.patch('psutil.swap_memory') @mock.patch('psutil.virtual_memory') def test_sufficient_swap(self, mock_vm, mock_sm): mock_vm.return_value = mock.Mock() mock_vm.return_value.total = 6442450944 mock_sm.return_value = mock.Mock() mock_sm.return_value.total = 2147483648 undercloud._check_memory() "," def test_sufficient_memory(self, mock_vm): def test_insufficient_memory(self, mock_vm):",26,3
openstack%2Fpuppet-aodh~stable%2Focata~Iefe933f45353810200ec9c76ffc92f051db7a5e6,openstack/puppet-aodh,stable/ocata,Iefe933f45353810200ec9c76ffc92f051db7a5e6,Install python-redis if coordination url uses it,MERGED,2017-02-17 23:51:10.000000000,2017-02-18 16:17:08.000000000,2017-02-18 16:17:08.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 9414}]","[{'number': 1, 'created': '2017-02-17 23:51:10.000000000', 'files': ['manifests/params.pp', 'spec/classes/aodh_evaluator_spec.rb', 'manifests/evaluator.pp', 'releasenotes/notes/install-python-redis-d695b95171f6c392.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/8ebca0800d0ae79a77c9f7128de2026369c95d14', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n(cherry picked from commit e50308cc6da360cbe1fdfdfa5ae4a3593a6949f7)\n'}]",0,435628,8ebca0800d0ae79a77c9f7128de2026369c95d14,9,4,1,3153,,,0,"Install python-redis if coordination url uses it

If tooz coordination is enabled and url is using redis
lets ensure python-redis is installed.

Change-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6
(cherry picked from commit e50308cc6da360cbe1fdfdfa5ae4a3593a6949f7)
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/28/435628/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/params.pp', 'spec/classes/aodh_evaluator_spec.rb', 'manifests/evaluator.pp', 'releasenotes/notes/install-python-redis-d695b95171f6c392.yaml']",4,8ebca0800d0ae79a77c9f7128de2026369c95d14,install-redis,--- fixes: - Install python-redis if the coordination backend url is redis. This is an indirect dependency on evaluator coordination to work. ,,23,2
openstack%2Ftripleo-ui~master~If488ebe6c12c720fd0a626d3fa3d2eac22bb5303,openstack/tripleo-ui,master,If488ebe6c12c720fd0a626d3fa3d2eac22bb5303,Add i18n to Register Nodes form,MERGED,2017-02-15 12:54:53.000000000,2017-02-18 15:53:26.000000000,2017-02-17 19:15:35.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 10112}, {'_account_id': 20970}]","[{'number': 1, 'created': '2017-02-15 12:54:53.000000000', 'files': ['src/js/components/nodes/RegisterNodesDialog.js', 'src/js/components/nodes/RegisterNodeForm.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/5314e047fd25a80ff9c407df09b882a2ff332a71', 'message': 'Add i18n to Register Nodes form\n\nChange-Id: If488ebe6c12c720fd0a626d3fa3d2eac22bb5303\nPartial-Bug: #1662964\n'}]",0,434259,5314e047fd25a80ff9c407df09b882a2ff332a71,11,4,1,4978,,,0,"Add i18n to Register Nodes form

Change-Id: If488ebe6c12c720fd0a626d3fa3d2eac22bb5303
Partial-Bug: #1662964
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/59/434259/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/js/components/nodes/RegisterNodesDialog.js', 'src/js/components/nodes/RegisterNodeForm.js']",2,5314e047fd25a80ff9c407df09b882a2ff332a71,bug/1662964,"import { defineMessages, FormattedMessage, injectIntl } from 'react-intl';const messages = defineMessages({ enterValidMacAddress: { id: 'RegisterNodeForm.enterValidMacAddress', defaultMessage: 'Please enter a valid MAC Address.' }, nodeNameRegexp: { id: 'RegisterNodeForm.nodeNameRegexp', defaultMessage: 'Name may only consist of RFC3986 unreserved characters, to wit: ' + 'ALPHA / DIGIT / ""-"" / ""."" / ""_"" / ""~"".' }, nodeNameMaxLength: { id: 'RegisterNodeForm.nodeNameMaxLength', defaultMessage: 'Node name can have up to 255 characters.' }, nodeDetail: { id: 'RegisterNodeForm.nodeDetail', defaultMessage: 'Node Detail' }, general: { id: 'RegisterNodeForm.General', defaultMessage: 'General' }, name: { id: 'RegisterNodeForm.name', defaultMessage: 'Name' }, management: { id: 'RegisterNodeForm.management', defaultMessage: 'Management' }, driver: { id: 'RegisterNodeForm.driver', defaultMessage: 'Driver' }, hardware: { id: 'RegisterNodeForm.hardware', defaultMessage: 'Hardware' }, architecture: { id: 'RegisterNodeForm.architecture', defaultMessage: 'Architecture' }, cpuCount: { id: 'RegisterNodeForm.cpuCount', defaultMessage: 'CPU count' }, memoryMb: { id: 'RegisterNodeForm.memoryMb', defaultMessage: 'Memory (MB)' }, diskGb: { id: 'RegisterNodeForm.diskGb', defaultMessage: 'Disk (GB)' }, networking: { id: 'RegisterNodeForm.networking', defaultMessage: 'Networking' }, nicMacAddresses: { id: 'RegisterNodeForm.nicMacAddresses', defaultMessage: 'NIC MAC Addresses' }, macAddressesDescription: { id: 'RegisterNodeForm.macAddressesDescription', defaultMessage: 'Comma separated list of MAC Addresses' } }); class RegisterNodeForm extends React.Component { this.macAddressValidatorMessage = this.props.intl.formatMessage(messages.enterValidMacAddress); matchRegexp: this.props.intl.formatMessage(messages.nodeNameRegexp), maxLength: this.props.intl.formatMessage(messages.nodeNameMaxLength) <h4><FormattedMessage {...messages.nodeDetail}/></h4> <legend><FormattedMessage {...messages.general}/></legend> title={this.props.intl.formatMessage(messages.name)} <legend><FormattedMessage {...messages.management}/></legend> title={this.props.intl.formatMessage(messages.driver)} <legend><FormattedMessage {...messages.hardware}/></legend> title={this.props.intl.formatMessage(messages.architecture)} title={this.props.intl.formatMessage(messages.cpuCount)} title={this.props.intl.formatMessage(messages.memoryMb)} title={this.props.intl.formatMessage(messages.diskGb)} <legend><FormattedMessage {...messages.networking}/></legend> title={this.props.intl.formatMessage(messages.nicMacAddresses)} description={ this.props.intl.formatMessage(messages.macAddressesDescription)} intl: React.PropTypes.object, export default injectIntl(RegisterNodeForm);","export default class RegisterNodeForm extends React.Component { this.macAddressValidatorMessage = 'Please enter a valid MAC Addresses'; matchRegexp: `Name may only consist of RFC3986 unreserved characters, to wit: ALPHA / DIGIT / ""-"" / ""."" / ""_"" / ""~""`, maxLength: 'Node name can have up to 255 characters' <h4>Node Detail</h4> <legend>General</legend> title=""Name"" <legend>Management</legend> title=""Driver"" <legend>Hardware</legend> title=""Architecture"" title=""CPU count"" title=""Memory (MB)"" title=""Disk (GB)"" <legend>Networking</legend> title=""NIC MAC Addresses"" description=""Comma separated list of MAC Addresses""",172,34
openstack%2Fopenstacksdk~master~I60967b6da183ae88270c541abdb4d93913f45558,openstack/openstacksdk,master,I60967b6da183ae88270c541abdb4d93913f45558,Update the image used for functional tests,MERGED,2017-02-18 04:56:51.000000000,2017-02-18 15:39:27.000000000,2017-02-18 15:39:27.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-18 04:56:51.000000000', 'files': ['openstack/tests/functional/base.py', 'examples/connect.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/52bd73e45dfe9436daef3237a2f4fa969344cff4', 'message': 'Update the image used for functional tests\n\nThe image used for functional tests is out of date.  This simeple\nchanges gets more tests to pass.\n\nChange-Id: I60967b6da183ae88270c541abdb4d93913f45558\nPartial-bug: #1665495\n'}]",0,435656,52bd73e45dfe9436daef3237a2f4fa969344cff4,7,3,1,8736,,,0,"Update the image used for functional tests

The image used for functional tests is out of date.  This simeple
changes gets more tests to pass.

Change-Id: I60967b6da183ae88270c541abdb4d93913f45558
Partial-bug: #1665495
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/56/435656/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/base.py', 'examples/connect.py']",2,52bd73e45dfe9436daef3237a2f4fa969344cff4,bug/1665495,"IMAGE_NAME = _get_resource_value('image_name', 'cirros-0.3.5-x86_64-disk')","IMAGE_NAME = _get_resource_value('image_name', 'cirros-0.3.4-x86_64-uec')",2,2
openstack%2Fpuppet-ironic~master~I072cd20c7027ceb9aa0260428d6df136a25263eb,openstack/puppet-ironic,master,I072cd20c7027ceb9aa0260428d6df136a25263eb,Add separate manifest for configuring access to swift,MERGED,2017-02-07 16:07:36.000000000,2017-02-18 15:26:58.000000000,2017-02-08 16:38:59.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9414}, {'_account_id': 10239}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-07 16:07:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/ee7bed38a149f1263a087024ec78c5551b48bcd2', 'message': 'Add separate manifest for configuring access to swift\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nChange-Id: I072cd20c7027ceb9aa0260428d6df136a25263eb\nPartial-Bug: #1661250\n'}, {'number': 2, 'created': '2017-02-08 08:50:04.000000000', 'files': ['releasenotes/notes/swift-manifest-3e64c5cf13de40e7.yaml', 'spec/classes/ironic_swift_spec.rb', 'manifests/swift.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/57e997515bd545659f0e25346e38748911e1a246', 'message': 'Add separate manifest for configuring access to swift\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nChange-Id: I072cd20c7027ceb9aa0260428d6df136a25263eb\nPartial-Bug: #1661250\n'}]",1,430333,57e997515bd545659f0e25346e38748911e1a246,20,5,2,10239,,,0,"Add separate manifest for configuring access to swift

Without these parameters ironic uses keystone_authtoken credentials.
This is deprecated since Newton and can be removed at any moment.

Change-Id: I072cd20c7027ceb9aa0260428d6df136a25263eb
Partial-Bug: #1661250
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/33/430333/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/swift-manifest-3e64c5cf13de40e7.yaml', 'spec/classes/ironic_swift_spec.rb', 'manifests/swift.pp']",3,ee7bed38a149f1263a087024ec78c5551b48bcd2,bug/1661250,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # == Class: ironic::swift # # [*auth_type*] # The authentication plugin to use when connecting to swift. # Defaults to 'password' # # [*auth_url*] # The address of the keystone api endpoint. # Defaults to $::os_service_default # # [*project_name*] # The Keystone project name. # Defaults to 'services' # # [*username*] # The admin username for ironic to connect to swift. # Defaults to 'ironic'. # # [*password*] # The admin password for ironic to connect to swift. # Defaults to $::os_service_default # class ironic::swift ( $auth_type = 'password', $auth_url = $::os_service_default, $project_name = 'services', $username = 'ironic', $password = $::os_service_default, ) { ironic_config { 'swift/auth_type': value => $auth_type; 'swift/username': value => $username; 'swift/password': value => $password, secret => true; 'swift/auth_url': value => $auth_url; 'swift/project_name': value => $project_name; } } ",,135,0
openstack%2Fpuppet-ironic~master~I7a9a78521c3495f04ca0a9f625b0d844ee56c56a,openstack/puppet-ironic,master,I7a9a78521c3495f04ca0a9f625b0d844ee56c56a,Add separate manifest for configuring access to neutron,MERGED,2017-02-03 16:15:38.000000000,2017-02-18 15:26:42.000000000,2017-02-09 08:50:20.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9414}, {'_account_id': 10239}, {'_account_id': 14525}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-03 16:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/0ce72c02c77cb22579d183ee9d4e0b2cd58d0133', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n'}, {'number': 2, 'created': '2017-02-06 11:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/9bbf23d67da1ed6481f24d934fd6e4f2ca521876', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n'}, {'number': 3, 'created': '2017-02-06 14:06:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/296896e4ea022b9c3fb7a4731ff03321d8ff8a06', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n'}, {'number': 4, 'created': '2017-02-06 17:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/ee672afe4cef6e2a1279d8b2977dc698ef492173', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nReset [neutron]url to os_service_default to allow ironic to guess it,\nrather then using a value that it probably wrong.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n'}, {'number': 5, 'created': '2017-02-07 09:52:39.000000000', 'files': ['manifests/neutron.pp', 'spec/classes/ironic_init_spec.rb', 'spec/classes/ironic_api_spec.rb', 'manifests/api.pp', 'manifests/init.pp', 'releasenotes/notes/neutron-manifest-8fbe400720ffc60e.yaml', 'spec/classes/ironic_neutron_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ironic/commit/ee74484b3aedcda52521440d7b75bf39f33635a1', 'message': 'Add separate manifest for configuring access to neutron\n\nWithout these parameters ironic uses keystone_authtoken credentials.\nThis is deprecated since Newton and can be removed at any moment.\n\nThis patch provides a manifest to configure separate credentials\nand moves other related parameters to it.\n\nReset [neutron]url to os_service_default to allow ironic to guess it,\nrather then using a value that it probably wrong.\n\nChange-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a\nPartial-Bug: #1661250\n'}]",8,428795,ee74484b3aedcda52521440d7b75bf39f33635a1,46,6,5,10239,,,0,"Add separate manifest for configuring access to neutron

Without these parameters ironic uses keystone_authtoken credentials.
This is deprecated since Newton and can be removed at any moment.

This patch provides a manifest to configure separate credentials
and moves other related parameters to it.

Reset [neutron]url to os_service_default to allow ironic to guess it,
rather then using a value that it probably wrong.

Change-Id: I7a9a78521c3495f04ca0a9f625b0d844ee56c56a
Partial-Bug: #1661250
",git fetch https://review.opendev.org/openstack/puppet-ironic refs/changes/95/428795/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/neutron.pp', 'spec/classes/ironic_init_spec.rb', 'manifests/api.pp', 'manifests/init.pp', 'releasenotes/notes/neutron-manifest-8fbe400720ffc60e.yaml', 'spec/classes/ironic_neutron_spec.rb']",6,0ce72c02c77cb22579d183ee9d4e0b2cd58d0133,bug/1661250,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Unit tests for ironic::neutron # require 'spec_helper' describe 'ironic::neutron' do let :default_params do { :auth_type => 'password', :auth_url => 'http://127.0.0.1:35357/', :project_name => 'services', :username => 'ironic', :api_endpoint => 'http://127.0.0.1:9696/', } end let :params do {} end shared_examples_for 'ironic neutron configuration' do let :p do default_params.merge(params) end it 'configures ironic.conf' do is_expected.to contain_ironic_config('neutron/url').with_value(p[:api_endpoint]) is_expected.to contain_ironic_config('neutron/auth_type').with_value(p[:auth_type]) is_expected.to contain_ironic_config('neutron/auth_url').with_value(p[:auth_url]) is_expected.to contain_ironic_config('neutron/project_name').with_value(p[:project_name]) is_expected.to contain_ironic_config('neutron/username').with_value(p[:username]) is_expected.to contain_ironic_config('neutron/password').with_value('<SERVICE DEFAULT>').with_secret(true) end context 'when overriding parameters' do before :each do params.merge!( :api_endpoint => 'http://neutron.example.com', :auth_type => 'noauth', :auth_url => 'http://example.com', :project_name => 'project1', :username => 'admin', :password => 'pa$$w0rd', ) end it 'should replace default parameter with new value' do is_expected.to contain_ironic_config('neutron/url').with_value(p[:api_endpoint]) is_expected.to contain_ironic_config('neutron/auth_type').with_value(p[:auth_type]) is_expected.to contain_ironic_config('neutron/auth_url').with_value(p[:auth_url]) is_expected.to contain_ironic_config('neutron/project_name').with_value(p[:project_name]) is_expected.to contain_ironic_config('neutron/username').with_value(p[:username]) is_expected.to contain_ironic_config('neutron/password').with_value(p[:password]).with_secret(true) end end end on_supported_os({ :supported_os => OSDefaults.get_supported_os }).each do |os,facts| context ""on #{os}"" do let (:facts) do facts.merge!(OSDefaults.get_facts()) end it_behaves_like 'ironic neutron configuration' end end end ",,169,6
openstack%2Fgnocchi~master~Ic3db6fcc6ace226230ce8a51863b57450df40e06,openstack/gnocchi,master,Ic3db6fcc6ace226230ce8a51863b57450df40e06,devstack: do not install gnocchiclient,MERGED,2017-02-01 15:25:24.000000000,2017-02-18 15:26:38.000000000,2017-02-18 15:26:38.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-01 15:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d45469f0cf418d86391504d420e77c2e0474a444', 'message': 'devstack: do not install gnocchiclient\n\nThis is not needed anymore for devstack, and this brings more problem that it\nsolves.\n\nChange-Id: Ic3db6fcc6ace226230ce8a51863b57450df40e06\n'}, {'number': 2, 'created': '2017-02-01 16:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/a0bade485c13464fa125270bf804849d551db91a', 'message': 'devstack: do not install gnocchiclient\n\nThis is not needed anymore for devstack, and this brings more problem that it\nsolves.\n\nChange-Id: Ic3db6fcc6ace226230ce8a51863b57450df40e06\n'}, {'number': 3, 'created': '2017-02-01 17:08:51.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/66526b295be1a2d80a33f96c0297fad1d2520f59', 'message': 'devstack: do not install gnocchiclient\n\nThis is not needed anymore for devstack, and this brings more problem that it\nsolves.\n\nChange-Id: Ic3db6fcc6ace226230ce8a51863b57450df40e06\n'}]",2,427770,66526b295be1a2d80a33f96c0297fad1d2520f59,11,3,3,1669,,,0,"devstack: do not install gnocchiclient

This is not needed anymore for devstack, and this brings more problem that it
solves.

Change-Id: Ic3db6fcc6ace226230ce8a51863b57450df40e06
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/70/427770/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,d45469f0cf418d86391504d420e77c2e0474a444,jd/devstack-no-gnocchiclient,,"# Defaults # -------- GITDIR[""python-gnocchiclient""]=$DEST/python-gnocchiclient GITREPO[""python-gnocchiclient""]=${GNOCCHICLIENT_REPO:-${GIT_BASE}/openstack/python-gnocchiclient.git} function install_gnocchiclient { if use_library_from_git python-gnocchiclient; then git_clone_by_name python-gnocchiclient setup_dev_lib python-gnocchiclient else pip_install gnocchiclient fi } install_gnocchiclient ",0,16
openstack%2Fpuppet-ovn~master~I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e,openstack/puppet-ovn,master,I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e,Input DB listen IP address for the ovn-northd,MERGED,2016-11-15 11:08:59.000000000,2017-02-18 15:26:24.000000000,2017-02-13 18:49:01.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 3153}, {'_account_id': 5792}, {'_account_id': 8298}, {'_account_id': 10237}, {'_account_id': 14985}, {'_account_id': 18795}]","[{'number': 1, 'created': '2016-11-15 11:08:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/a3aea889216c8fec4eb8d788c0ea4c898a8a4bb4', 'message': 'Input DB listen IP address for the northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\nnorthd service, the DB servers will be listenting on 0.0.0.0\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service.\n\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n'}, {'number': 2, 'created': '2016-11-15 11:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/27c6662ff72dd33f3296553eb18b7c4a5f2e2a63', 'message': 'Input DB listen IP address for the northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\nnorthd service, the DB servers will be listenting on 0.0.0.0\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service.\n\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n'}, {'number': 3, 'created': '2016-11-17 07:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/f8ed0ef30cf7ac71718cb143b5c1068659fdd8ae', 'message': 'Input DB listen IP address for the northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\nnorthd service, the DB servers will be listenting on 0.0.0.0\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service.\n\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n'}, {'number': 4, 'created': '2016-11-17 18:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/19df073a243905996d67dcb6f99cfd986a89a3cb', 'message': 'Input DB listen IP address for the northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\nnorthd service, the DB servers will be listenting on 0.0.0.0\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service.\n\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n'}, {'number': 5, 'created': '2016-11-23 10:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/4d2fba8fb986ae851811a917aa36e8a24f285f18', 'message': 'Input DB listen IP address for the northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\nnorthd service, the DB servers will be listenting on 0.0.0.0\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service.\n\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n'}, {'number': 6, 'created': '2017-02-03 10:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/bef1fa1cc6f6cc7acfc10b605f229462613dd3fd', 'message': ""Input DB listen IP address for the ovn-northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\novn-northd service, the DB servers will be listenting on 0.0.0.0.\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service. It also sets the other options\ndb-nb-create-insecure-remote and db-sb-create-insecure-remote which\nare required to start the ovsdb-server's  listening on TCP\nconnections. Please see this commit [1] for more details.\n\n[1] -\nhttps://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149\n\nCo-authored-by: Numan Siddique <nusiddiq@redhat.com>\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n""}, {'number': 7, 'created': '2017-02-03 11:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/d34c96b20e7cef3dc3956a396671a93ee1c182b1', 'message': ""Input DB listen IP address for the ovn-northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\novn-northd service, the DB servers will be listenting on 0.0.0.0.\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service. It also sets the other options\ndb-nb-create-insecure-remote and db-sb-create-insecure-remote which\nare required to start the ovsdb-server's  listening on TCP\nconnections. Please see this commit [1] for more details.\n\n[1] -\nhttps://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149\n\nCo-authored-by: Numan Siddique <nusiddiq@redhat.com>\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n""}, {'number': 8, 'created': '2017-02-03 11:59:08.000000000', 'files': ['manifests/northd.pp', 'spec/classes/ovn_northd_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-ovn/commit/4e9e55987d3c21ce99d50969f227e5055fe6bd3c', 'message': ""Input DB listen IP address for the ovn-northd\n\nWhen ovn-northd is started, along with it ovsdb servers for the southbound\nand northbound databases are also started. Without additional options for the\novn-northd service, the DB servers will be listenting on 0.0.0.0.\n\nThis patch creates a systemd environment file that will create the db listen\noptions for the northd service. It also sets the other options\ndb-nb-create-insecure-remote and db-sb-create-insecure-remote which\nare required to start the ovsdb-server's  listening on TCP\nconnections. Please see this commit [1] for more details.\n\n[1] -\nhttps://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149\n\nCo-authored-by: Numan Siddique <nusiddiq@redhat.com>\nChange-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e\n""}]",11,397687,4e9e55987d3c21ce99d50969f227e5055fe6bd3c,48,8,8,8298,,,0,"Input DB listen IP address for the ovn-northd

When ovn-northd is started, along with it ovsdb servers for the southbound
and northbound databases are also started. Without additional options for the
ovn-northd service, the DB servers will be listenting on 0.0.0.0.

This patch creates a systemd environment file that will create the db listen
options for the northd service. It also sets the other options
db-nb-create-insecure-remote and db-sb-create-insecure-remote which
are required to start the ovsdb-server's  listening on TCP
connections. Please see this commit [1] for more details.

[1] -
https://github.com/openvswitch/ovs/commit/84d0ca5d00fe01b29163236d48fa0f9105687149

Co-authored-by: Numan Siddique <nusiddiq@redhat.com>
Change-Id: I99b1c3e0fe89b763be81db9b8c1c3b257be42e6e
",git fetch https://review.opendev.org/openstack/puppet-ovn refs/changes/87/397687/5 && git format-patch -1 --stdout FETCH_HEAD,['manifests/northd.pp'],1,a3aea889216c8fec4eb8d788c0ea4c898a8a4bb4,db_listen_ip,"# Installs ovn package starts the ovn-northd service# [*dbs_listen_ip*] # The IP-Address where OVN DBs should be listening # Defaults to '0.0.0.0' # class ovn::northd($dbs_listen_ip = ""0.0.0.0"") { file { '/etc/sysconfig/ovn-northd': ensure => file, mode => '0600', owner => 'root', group => 'root', content => ""NORTHD_OPTS=--db-nb-addr=${dbs_listen_ip} --db-sb-addr=${dbs_listen_ip}"", before => Service['northd'] } ",# installs ovn package starts the ovn-northd serviceclass ovn::northd() {,15,2
openstack%2Foslo.db~master~I15f85a0ebfd732c09d7cb92d885c1773c393aabd,openstack/oslo.db,master,I15f85a0ebfd732c09d7cb92d885c1773c393aabd,"Support facade arguments, unstarted facade for patch_engine()",MERGED,2017-02-14 21:54:46.000000000,2017-02-18 15:26:04.000000000,2017-02-18 15:26:04.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 11816}]","[{'number': 1, 'created': '2017-02-14 21:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/e29cca3cc2eae5b0b5ac16e6bafbd4feca2ddaba', 'message': 'Support facade arguments, unstarted facade for patch_engine()\n\nFixed two issues in patch_engine() as used in test suites\nwhere facade-level arguments would not be propagated to the\ninternal _TestTransactionFactory, and also if the parent\nfactory weren\'t ""started"" the patch operation would fail\nas it assumes a started factory.\n\nThis removes the ""synchronous_reader"" argument from\n_TestTransactionFactory as this is propagated from the parent\n_TransactionFactory, where synchronous_reader defaults to True.\n\nChange-Id: I15f85a0ebfd732c09d7cb92d885c1773c393aabd\n'}, {'number': 2, 'created': '2017-02-15 15:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/c1a0dc07ecdbe41ee098da0de5ac7f66f6677bbd', 'message': 'Support facade arguments, unstarted facade for patch_engine()\n\nFixed two issues in patch_engine() as used in test suites\nwhere facade-level arguments would not be propagated to the\ninternal _TestTransactionFactory, and also if the parent\nfactory weren\'t ""started"" the patch operation would fail\nas it assumes a started factory.\n\nThis removes the ""synchronous_reader"" argument from\n_TestTransactionFactory as this is propagated from the parent\n_TransactionFactory, where synchronous_reader defaults to True.\nHowever, arbitrary keyword arguments are currently allowed to\nallow for outside projects calling _TestTransactionFactory\n(currently Neutron).\n\nChange-Id: I15f85a0ebfd732c09d7cb92d885c1773c393aabd\n'}, {'number': 3, 'created': '2017-02-16 11:26:52.000000000', 'files': ['oslo_db/sqlalchemy/test_base.py', 'oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/1a41b77ba649b67b7684dab60c9c0869de986c8b', 'message': 'Support facade arguments, unstarted facade for patch_engine()\n\nFixed two issues in patch_engine() as used in test suites\nwhere facade-level arguments would not be propagated to the\ninternal _TestTransactionFactory, and also if the parent\nfactory weren\'t ""started"" the patch operation would fail\nas it assumes a started factory.\n\nThis removes the ""synchronous_reader"" argument from\n_TestTransactionFactory as this is propagated from the parent\n_TransactionFactory, where synchronous_reader defaults to True.\nHowever, arbitrary keyword arguments are currently allowed to\nallow for outside projects calling _TestTransactionFactory\n(currently Neutron).\n\nChange-Id: I15f85a0ebfd732c09d7cb92d885c1773c393aabd\n'}]",1,433946,1a41b77ba649b67b7684dab60c9c0869de986c8b,16,4,3,11816,,,0,"Support facade arguments, unstarted facade for patch_engine()

Fixed two issues in patch_engine() as used in test suites
where facade-level arguments would not be propagated to the
internal _TestTransactionFactory, and also if the parent
factory weren't ""started"" the patch operation would fail
as it assumes a started factory.

This removes the ""synchronous_reader"" argument from
_TestTransactionFactory as this is propagated from the parent
_TransactionFactory, where synchronous_reader defaults to True.
However, arbitrary keyword arguments are currently allowed to
allow for outside projects calling _TestTransactionFactory
(currently Neutron).

Change-Id: I15f85a0ebfd732c09d7cb92d885c1773c393aabd
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/46/433946/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_db/sqlalchemy/test_base.py', 'oslo_db/tests/sqlalchemy/test_enginefacade.py', 'oslo_db/sqlalchemy/enginefacade.py']",3,e29cca3cc2eae5b0b5ac16e6bafbd4feca2ddaba,support_args_patch_on_nested," def __init__(self, engine, maker, apply_global, from_factory=None): if from_factory is None: from_factory = _context_manager._factory self._facade_cfg = from_factory._facade_cfg self._transaction_ctx_cfg = from_factory._transaction_ctx_cfg self.synchronous_reader = self._facade_cfg['synchronous_reader'] if not existing_factory._started: existing_factory._start() from_factory=existing_factory"," def __init__(self, engine, maker, apply_global, synchronous_reader): self.synchronous_reader = synchronous_reader self._facade_cfg = _context_manager._factory._facade_cfg self._transaction_ctx_cfg = \ _context_manager._factory._transaction_ctx_cfg synchronous_reader=existing_factory. _facade_cfg['synchronous_reader']",62,10
openstack%2Finstack-undercloud~master~I40faf8f07a74f7a33f304c8aff6d43a903a42b9e,openstack/instack-undercloud,master,I40faf8f07a74f7a33f304c8aff6d43a903a42b9e,Set instance audit settings so nova sends notifications,MERGED,2017-02-17 13:53:18.000000000,2017-02-18 15:21:25.000000000,2017-02-18 00:01:54.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-17 13:53:18.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/4c5335e896d7dbc621ddb994ea954c42c41d2e6c', 'message': 'Set instance audit settings so nova sends notifications\n\nCeilometer is not receiving notifications on undercloud. This is\nbecause the instance usage audit settings are missing.\n\nChange-Id: I40faf8f07a74f7a33f304c8aff6d43a903a42b9e\nCloses-bug: #1665636\n'}]",0,435452,4c5335e896d7dbc621ddb994ea954c42c41d2e6c,14,3,1,6924,,,0,"Set instance audit settings so nova sends notifications

Ceilometer is not receiving notifications on undercloud. This is
because the instance usage audit settings are missing.

Change-Id: I40faf8f07a74f7a33f304c8aff6d43a903a42b9e
Closes-bug: #1665636
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/52/435452/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,4c5335e896d7dbc621ddb994ea954c42c41d2e6c,bug/1665636,nova::compute::instance_usage_audit: true nova::compute::instance_usage_audit_period: 'hour',,2,0
openstack%2Finstack-undercloud~master~I0ccc38ab2792bb77be283fb2fecdb389ef40003d,openstack/instack-undercloud,master,I0ccc38ab2792bb77be283fb2fecdb389ef40003d,Allow to teardown Telemetry services,MERGED,2017-02-17 00:27:32.000000000,2017-02-18 15:21:19.000000000,2017-02-18 00:43:04.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 7144}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-17 00:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/596a0c50b88dcbde895fa85b420bad18e9abf78d', 'message': 'Allow to teardown Telemetry services\n\nWhen enable_telemetry=false, make sure all Telemetry resources are down:\n\n- remove packages\n- remove services (note: removing packages will stop services not started in httpd)\n- remove config files\n- remove databases\n\nChange-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d\nCloses-bug: #1664654\n'}, {'number': 2, 'created': '2017-02-17 00:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/fed4e476f2a506197fb9513ed0dfd32d9d624295', 'message': 'Allow to teardown Telemetry services\n\nWhen enable_telemetry=false, make sure all Telemetry resources are down:\n\n- remove packages\n- remove services (note: removing packages will stop services not started in httpd)\n- remove config files\n\nChange-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d\nCloses-bug: #1664654\n'}, {'number': 3, 'created': '2017-02-17 03:00:07.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/2887601a2eb01991d4ed999d7383f7ae538290eb', 'message': 'Allow to teardown Telemetry services\n\nWhen enable_telemetry=false, make sure all Telemetry resources are down:\n\n- remove packages\n- remove services (note: removing packages will stop services not started in httpd)\n- remove config files\n\nChange-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d\nCloses-bug: #1664654\n'}]",1,435159,2887601a2eb01991d4ed999d7383f7ae538290eb,19,5,3,3153,,,0,"Allow to teardown Telemetry services

When enable_telemetry=false, make sure all Telemetry resources are down:

- remove packages
- remove services (note: removing packages will stop services not started in httpd)
- remove config files

Change-Id: I0ccc38ab2792bb77be283fb2fecdb389ef40003d
Closes-bug: #1664654
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/59/435159/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,596a0c50b88dcbde895fa85b420bad18e9abf78d,bug/1664654,"} else { # If Telemetry is disabled, ensure we tear down everything: # packages, services, configuration files. Package { [ 'openstack-aodh-common', 'openstack-ceilometer-common', 'openstack-gnocchi-common', 'openstack-panko-common' ]: ensure => 'purged', notify => Service['httpd'], } File { [ '/etc/httpd/conf.d/10-aodh_wsgi.conf', '/etc/httpd/conf.d/10-ceilometer_wsgi.conf', '/etc/httpd/conf.d/10-gnocchi_wsgi.conf', '/etc/httpd/conf.d/10-panko_wsgi.conf', ]: ensure => absent, notify => Service['httpd'], }",,21,0
openstack%2Finstack-undercloud~master~I5c2734e77a16360f9688a0a389211e3882941eb0,openstack/instack-undercloud,master,I5c2734e77a16360f9688a0a389211e3882941eb0,Install Ironic inspector plugins,MERGED,2017-02-15 15:54:00.000000000,2017-02-18 15:21:11.000000000,2017-02-18 10:21:16.000000000,"[{'_account_id': 3}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 21909}]","[{'number': 1, 'created': '2017-02-15 15:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/0b62225aace95081eac3610f9062e8d8ad363397', 'message': 'This change installs two Ironic inspector plugins.  The ``lldp_basic`` plugin was added to Ironic inspector in Ocata to process LLDP packets stored in swift (https://review.openstack.org/#/c/406496/).  The ``local_link_connection`` plugin was added in Newton but had not been installed (https://review.openstack.org/#/c/321082/). It sets the port_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n'}, {'number': 2, 'created': '2017-02-15 15:55:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/af7f89a29dc62d553a138291ab40f91eeaf55ec7', 'message': 'Install Ironic inspector plugins\n\nThis change installs two Ironic inspector plugins.  The ``lldp_basic`` plugin was added to Ironic inspector in Ocata to process LLDP packets stored in swift (https://review.openstack.org/#/c/406496/).  The ``local_link_connection`` plugin was added in Newton but had not been installed (https://review.openstack.org/#/c/321082/). It sets the port_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n'}, {'number': 3, 'created': '2017-02-15 15:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/75d8de4612cd2bdaf28c0717883d3d57d4ac65b3', 'message': 'Install Ironic inspector plugins\n\nThis change installs two Ironic inspector plugins.  The ``lldp_basic``\nplugin was added to Ironic inspector in Ocata to process LLDP packets\nstored in swift (https://review.openstack.org/#/c/406496/).  The\n``local_link_connection`` plugin was added in Newton but had not been\ninstalled (https://review.openstack.org/#/c/321082/). It sets the\nport_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n'}, {'number': 4, 'created': '2017-02-16 19:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/c0f57ba9d88e76229bcc0c0e6586a7f7b2f7074b', 'message': 'Install Ironic inspector plugins\n\nThis change installs two Ironic inspector plugins.  The ``lldp_basic``\nplugin was added to Ironic inspector in Ocata to process LLDP packets\nstored in swift (https://review.openstack.org/#/c/406496/).  The\n``local_link_connection`` plugin was added in Newton but had not been\ninstalled (https://review.openstack.org/#/c/321082/). It sets the\nport_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n'}, {'number': 5, 'created': '2017-02-16 19:01:43.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.yaml.template', 'releasenotes/notes/inspector-additional-hooks-9a5c8f5aad2bac31.yaml'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/c55910d40c454937d4e75e94fbdb17927330f506', 'message': 'Install Ironic inspector plugins\n\nThis change installs two Ironic inspector plugins.  The ``lldp_basic``\nplugin was added to Ironic inspector in Ocata to process LLDP packets\nstored in swift (https://review.openstack.org/#/c/406496/).  The\n``local_link_connection`` plugin was added in Newton but had not been\ninstalled (https://review.openstack.org/#/c/321082/). It sets the\nport_id and switch_id on Ironic ports from LLDP data.\n\nChange-Id: I5c2734e77a16360f9688a0a389211e3882941eb0\n'}]",0,434356,c55910d40c454937d4e75e94fbdb17927330f506,24,5,5,21909,,,0,"Install Ironic inspector plugins

This change installs two Ironic inspector plugins.  The ``lldp_basic``
plugin was added to Ironic inspector in Ocata to process LLDP packets
stored in swift (https://review.openstack.org/#/c/406496/).  The
``local_link_connection`` plugin was added in Newton but had not been
installed (https://review.openstack.org/#/c/321082/). It sets the
port_id and switch_id on Ironic ports from LLDP data.

Change-Id: I5c2734e77a16360f9688a0a389211e3882941eb0
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/56/434356/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.yaml.template'],1,0b62225aace95081eac3610f9062e8d8ad363397,inspector-hooks,"ironic::inspector::additional_processing_hooks: 'extra_hardware,lldp_basic,local_link_connection'",ironic::inspector::additional_processing_hooks: 'extra_hardware',1,1
openstack%2Fpuppet-tripleo~master~I513303bf82dca53e2291ab66f2385a2985a1846e,openstack/puppet-tripleo,master,I513303bf82dca53e2291ab66f2385a2985a1846e,Enable languages in UI config,MERGED,2017-02-10 14:39:14.000000000,2017-02-18 15:19:32.000000000,2017-02-18 04:52:24.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4978}, {'_account_id': 13344}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-10 14:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ec896e715a9250ab2659b757d8562f3efc3b3a02', 'message': ""Enable languages in UI config\n\nWhich language options to offer to the UI users is determined in the\nconfiguration file. Let's show all possible languages by default,\nunless specified otherwise.\n\nChange-Id: I513303bf82dca53e2291ab66f2385a2985a1846e\nRelated-Bug: #1663279\nDepends-On: I5a9a40734e9e4322169d186d5a31f153736287d3\n""}, {'number': 2, 'created': '2017-02-14 14:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f4e31264fc4cd4d70feff0bc657e1e9b0eb1e191', 'message': ""Enable languages in UI config\n\nWhich language options to offer to the UI users is determined in the\nconfiguration file. Let's show all possible languages by default,\nunless specified otherwise.\n\nChange-Id: I513303bf82dca53e2291ab66f2385a2985a1846e\nRelated-Bug: #1663279\nDepends-On: Ib471c6dcc969cdd488a9d9e812fab00cc906ff79\n""}, {'number': 3, 'created': '2017-02-15 10:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/a0aaef33d9660b259295aec977dcf0e48114021b', 'message': ""Enable languages in UI config\n\nWhich language options to offer to the UI users is determined in the\nconfiguration file. Let's show all possible languages by default,\nunless specified otherwise.\n\nChange-Id: I513303bf82dca53e2291ab66f2385a2985a1846e\nRelated-Bug: #1663279\n""}, {'number': 4, 'created': '2017-02-17 13:14:13.000000000', 'files': ['templates/ui/tripleo_ui_config.js.erb', 'manifests/ui.pp', 'releasenotes/notes/enable-languages-in-ui-88a8caa6db9b4dd7.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/053ee06787539f6da07985968d6c3b0194e56008', 'message': ""Enable languages in UI config\n\nWhich language options to offer to the UI users is determined in the\nconfiguration file. Let's show all possible languages by default,\nunless specified otherwise.\n\nChange-Id: I513303bf82dca53e2291ab66f2385a2985a1846e\nRelated-Bug: #1663279\n""}]",5,432328,053ee06787539f6da07985968d6c3b0194e56008,30,5,4,4978,,,0,"Enable languages in UI config

Which language options to offer to the UI users is determined in the
configuration file. Let's show all possible languages by default,
unless specified otherwise.

Change-Id: I513303bf82dca53e2291ab66f2385a2985a1846e
Related-Bug: #1663279
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/28/432328/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/ui.pp', 'templates/ui/tripleo_ui_config.js.erb']",2,ec896e715a9250ab2659b757d8562f3efc3b3a02,bug/1663279," ""zaqar_default_queue"": ""<%= @zaqar_default_queue %>"", // Languages // If you choose more than one language, a language switcher will appear in the navigation bar. <% if @enabled_languages %> ""languages"": ['<%= @enabled_languages.join(""', '"") %>'] <% else %> ""languages"": [""en-GB"", ""en"", ""ja"", ""ko-KR"", ""zh-CN"", ""es""] <% end %>"," ""zaqar_default_queue"": ""<%= @zaqar_default_queue %>""",15,1
openstack%2Fceilometer~master~I0dc67280a4df4e7c33737d0c7bc89c91d2860529,openstack/ceilometer,master,I0dc67280a4df4e7c33737d0c7bc89c91d2860529,Remove useless metric name,MERGED,2017-02-17 09:28:55.000000000,2017-02-18 15:18:39.000000000,2017-02-18 15:18:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-17 09:28:55.000000000', 'files': ['ceilometer/dispatcher/data/gnocchi_resources.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f8c77099381a5da548beb180d1e6cc207ea6817', 'message': 'Remove useless metric name\n\nChange-Id: I0dc67280a4df4e7c33737d0c7bc89c91d2860529\n'}]",0,435327,5f8c77099381a5da548beb180d1e6cc207ea6817,8,3,1,2813,,,0,"Remove useless metric name

Change-Id: I0dc67280a4df4e7c33737d0c7bc89c91d2860529
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/27/435327/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/dispatcher/data/gnocchi_resources.yaml'],1,5f8c77099381a5da548beb180d1e6cc207ea6817,sileht/network-fix,, - 'network' - 'network.create' - 'network.update' - 'subnet' - 'subnet.create' - 'subnet.update' - 'port' - 'port.create' - 'port.update' - 'router' - 'router.create' - 'router.update' - 'ip.floating.create' - 'ip.floating.update',0,14
openstack%2Fceilometer~master~Ib1da71a0fad06c844b75683193a10e774a1c94e3,openstack/ceilometer,master,Ib1da71a0fad06c844b75683193a10e774a1c94e3,nova: track flavor name,MERGED,2017-01-06 08:33:20.000000000,2017-02-18 15:18:33.000000000,2017-02-18 15:18:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8871}, {'_account_id': 15843}]","[{'number': 1, 'created': '2017-01-06 08:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/66aef9e2cffc0ee9914ccc2025e9a68ccd01ebe7', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 2, 'created': '2017-01-06 13:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f8ab4ce657f4400b19baa55961fc23699f3bba67', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 3, 'created': '2017-01-07 06:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cc4b808d38ddd3bfeb14b3bec189932f6a72e28b', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 4, 'created': '2017-01-07 10:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/eac9d6c6ca590a7c4f334995ca834a2a770de1fb', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 5, 'created': '2017-01-10 09:37:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0ce2acefc3c9ab28fec31612119c37788329ea47', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 6, 'created': '2017-01-19 08:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2aeb8451497f89a7d55df52177d1d517c6f4cb12', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nDepends-On: If0bd609ed586b6fbe4fe7877ece237e55baa7d45\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 7, 'created': '2017-01-25 07:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dc97c0c87a9e760a9652269f307de5ac6a627c40', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 8, 'created': '2017-02-01 07:37:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8992d06292200a6d74990f0d70f6ab0ce06e3623', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}, {'number': 9, 'created': '2017-02-15 15:31:52.000000000', 'files': ['ceilometer/gnocchi_client.py', 'ceilometer/dispatcher/data/gnocchi_resources.yaml'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c07fd33b6aa05974d87b38754ed7600a567ee5e1', 'message': 'nova: track flavor name\n\nWe currently track only the flavor id, but this one can disapear over\nthe time. When the name is always present.\n\nChange-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3\n'}]",4,417313,c07fd33b6aa05974d87b38754ed7600a567ee5e1,58,6,9,2813,,,0,"nova: track flavor name

We currently track only the flavor id, but this one can disapear over
the time. When the name is always present.

Change-Id: Ib1da71a0fad06c844b75683193a10e774a1c94e3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/13/417313/9 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/gnocchi_client.py', 'ceilometer/dispatcher/data/gnocchi_resources.yaml']",2,66aef9e2cffc0ee9914ccc2025e9a68ccd01ebe7,sileht/track-flavorname, flavor_name: resource_metadata.(instance_type|(flavor.name)),,9,0
openstack%2Fcinder~master~I064d842a6869d50fe232c7edf2b2202933027ec6,openstack/cinder,master,I064d842a6869d50fe232c7edf2b2202933027ec6,Switch and/or to ternary operator,MERGED,2017-02-10 16:19:01.000000000,2017-02-18 14:56:30.000000000,2017-02-14 07:53:52.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 15386}, {'_account_id': 16941}, {'_account_id': 20191}, {'_account_id': 23602}]","[{'number': 1, 'created': '2017-02-10 16:19:01.000000000', 'files': ['cinder/api/contrib/services.py', 'cinder/test.py', 'cinder/api/contrib/hosts.py', 'cinder/tests/unit/volume/test_volume_migration.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/35ee53216776e571ef5f2dc70219d9d5b123370f', 'message': 'Switch and/or to ternary operator\n\nSince version 2.5 Python has had an official ternary operator, this\ncommit switches out the old and/or style for the more predictable\nand readable official version.\n\nPartial-Bug: #1663631\n\nChange-Id: I064d842a6869d50fe232c7edf2b2202933027ec6\n'}]",0,432372,35ee53216776e571ef5f2dc70219d9d5b123370f,42,8,1,23276,,,0,"Switch and/or to ternary operator

Since version 2.5 Python has had an official ternary operator, this
commit switches out the old and/or style for the more predictable
and readable official version.

Partial-Bug: #1663631

Change-Id: I064d842a6869d50fe232c7edf2b2202933027ec6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/72/432372/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/contrib/services.py', 'cinder/test.py', 'cinder/api/contrib/hosts.py', 'cinder/tests/unit/volume/test_volume_migration.py']",4,35ee53216776e571ef5f2dc70219d9d5b123370f,bug/1663631, initial_status = 'retyping' if retyping else status, initial_status = retyping and 'retyping' or status,4,4
openstack%2Fsenlin~stable%2Focata~Ia480110e7a8eac6cb730e48fba0d397034d52d28,openstack/senlin,stable/ocata,Ia480110e7a8eac6cb730e48fba0d397034d52d28,More release notes for the Ocata RC,MERGED,2017-02-18 11:46:43.000000000,2017-02-18 14:56:10.000000000,2017-02-18 14:56:10.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2017-02-18 11:46:43.000000000', 'files': ['releasenotes/notes/scaling-policy-validation-e2a1d3049e03c316.yaml', 'releasenotes/notes/param-check-cluster-update-58d4712a33f74c6e.yaml', 'releasenotes/notes/health-reboot-9f74c263f7fb6767.yaml', 'releasenotes/notes/az-info-9344b8d54c0b2665.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/70ea7f4789478745f3160c186b8ab3245884ae7b', 'message': 'More release notes for the Ocata RC\n\nThis adds some missing release notes items for the Ocata RC version.\n\nChange-Id: Ia480110e7a8eac6cb730e48fba0d397034d52d28\n(cherry picked from commit 09115f1f47fd09faa2b83ef14a9348e2a606f758)\n'}]",0,435697,70ea7f4789478745f3160c186b8ab3245884ae7b,10,3,1,8246,,,0,"More release notes for the Ocata RC

This adds some missing release notes items for the Ocata RC version.

Change-Id: Ia480110e7a8eac6cb730e48fba0d397034d52d28
(cherry picked from commit 09115f1f47fd09faa2b83ef14a9348e2a606f758)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/97/435697/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/scaling-policy-validation-e2a1d3049e03c316.yaml', 'releasenotes/notes/param-check-cluster-update-58d4712a33f74c6e.yaml', 'releasenotes/notes/health-reboot-9f74c263f7fb6767.yaml', 'releasenotes/notes/az-info-9344b8d54c0b2665.yaml']",4,70ea7f4789478745f3160c186b8ab3245884ae7b,relnotes-rc,--- fixes: - The bug where the availability zone info from a nova server deployment was not available has been fixed. ,,15,0
openstack%2Fgnocchi~stable%2F2.1~I1b207b3ec2f04bba6ef8b397c3822e462fde4332,openstack/gnocchi,stable/2.1,I1b207b3ec2f04bba6ef8b397c3822e462fde4332,tests: extend the test timeout to 120s for migration sync testing,ABANDONED,2016-07-28 11:19:53.000000000,2017-02-18 14:52:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 8358}, {'_account_id': 22739}, {'_account_id': 22752}]","[{'number': 1, 'created': '2016-07-28 11:19:53.000000000', 'files': ['gnocchi/tests/indexer/sqlalchemy/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/f9967611b39aafb496ae5327ee3c8b784420191b', 'message': 'tests: extend the test timeout to 120s for migration sync testing\n\nMySQL is long to inspect, and usually take up to more than 60s on slow\nsystem, which is the default value for OS_TEST_TIMEOUT. This extends it\nto 120s so we avoid random test failure.\n\nChange-Id: I1b207b3ec2f04bba6ef8b397c3822e462fde4332\n'}]",1,348253,f9967611b39aafb496ae5327ee3c8b784420191b,34,7,1,1669,,,0,"tests: extend the test timeout to 120s for migration sync testing

MySQL is long to inspect, and usually take up to more than 60s on slow
system, which is the default value for OS_TEST_TIMEOUT. This extends it
to 120s so we avoid random test failure.

Change-Id: I1b207b3ec2f04bba6ef8b397c3822e462fde4332
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/53/348253/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/tests/indexer/sqlalchemy/test_migrations.py'],1,f9967611b39aafb496ae5327ee3c8b784420191b,jd/timeout-model-sync-test,"import fixtures def _set_timeout(self): self.useFixture(fixtures.Timeout(120, gentle=True)) ",,4,0
openstack%2Fsenlin~stable%2Focata~I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1,openstack/senlin,stable/ocata,I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1,Fixed inappropriate event generation in action base,MERGED,2017-02-18 11:44:16.000000000,2017-02-18 14:48:57.000000000,2017-02-18 14:48:57.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 11:44:16.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/61e4fc718edabbbdfa46cdf4cf30d973d534fdc5', 'message': 'Fixed inappropriate event generation in action base\n\nWhen policy check succeeds, we are not supposed to emit an event (either\nto database or to message queue) because the success of such a check is\nnot interesting to users at all. They only care about the abnormal\nbehaviors, aka. errors or warnings.\n\nChange-Id: I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1\n(cherry picked from commit 340a0d3b9e6f97ca2832eb575b0a4993330a9419)\n'}]",0,435696,61e4fc718edabbbdfa46cdf4cf30d973d534fdc5,6,2,1,8246,,,0,"Fixed inappropriate event generation in action base

When policy check succeeds, we are not supposed to emit an event (either
to database or to message queue) because the success of such a check is
not interesting to users at all. They only care about the abnormal
behaviors, aka. errors or warnings.

Change-Id: I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1
(cherry picked from commit 340a0d3b9e6f97ca2832eb575b0a4993330a9419)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/96/435696/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py']",2,61e4fc718edabbbdfa46cdf4cf30d973d534fdc5,fix-event-log,," EVENT.debug(self, 'check', reason)",1,3
openstack%2Fsenlin~stable%2Focata~I93052cf93184bb1cd82d2550657d2ed878ec5f1d,openstack/senlin,stable/ocata,I93052cf93184bb1cd82d2550657d2ed878ec5f1d,Add tags to newly created heat stacks,MERGED,2017-02-18 11:43:36.000000000,2017-02-18 14:48:52.000000000,2017-02-18 14:48:52.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 11:43:36.000000000', 'files': ['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/da110e4854a6fdde7548512d887ec2aa04a99488', 'message': 'Add tags to newly created heat stacks\n\nThese tags will be used for event listeners that filter irrelevant\nstacks when checking stack failures. Previous commit has added\nstack listeners to health manager.\n\nPartial-Bug: 1657983\nChange-Id: I93052cf93184bb1cd82d2550657d2ed878ec5f1d\n(cherry picked from commit 03933be4bcbdad4ac8dbadb60e58aa1df5279ea0)\n'}]",0,435694,da110e4854a6fdde7548512d887ec2aa04a99488,6,2,1,8246,,,0,"Add tags to newly created heat stacks

These tags will be used for event listeners that filter irrelevant
stacks when checking stack failures. Previous commit has added
stack listeners to health manager.

Partial-Bug: 1657983
Change-Id: I93052cf93184bb1cd82d2550657d2ed878ec5f1d
(cherry picked from commit 03933be4bcbdad4ac8dbadb60e58aa1df5279ea0)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/94/435694/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py']",2,da110e4854a6fdde7548512d887ec2aa04a99488,bug/1657983," node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ]", test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) stack_node = mock.Mock() stack_node.name = 'test_stack' stack_node) stack_node = mock.Mock() stack_node.name = 'test_stack' stack_node),46,15
openstack%2Fsenlin~stable%2Focata~I24a6142d322954a0b8256118d8248e8d250bad6f,openstack/senlin,stable/ocata,I24a6142d322954a0b8256118d8248e8d250bad6f,Enable heat stack event listener,MERGED,2017-02-18 11:43:53.000000000,2017-02-18 14:37:34.000000000,2017-02-18 14:37:34.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 11:43:53.000000000', 'files': ['senlin/engine/health_manager.py', 'releasenotes/notes/heat-listener-b908d0988840e1f3.yaml', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/38b44b5ed7f8e1ff2ffae64809bdff25da183e4d', 'message': 'Enable heat stack event listener\n\nThis hooks the heat stack event listener for failure detection.\n\nCloses-Bug: 1657983\nChange-Id: I24a6142d322954a0b8256118d8248e8d250bad6f\n(cherry picked from commit e832fcffcf4997ad36b8a7990ae6c9bec772d80d)\n'}]",0,435695,38b44b5ed7f8e1ff2ffae64809bdff25da183e4d,6,2,1,8246,,,0,"Enable heat stack event listener

This hooks the heat stack event listener for failure detection.

Closes-Bug: 1657983
Change-Id: I24a6142d322954a0b8256118d8248e8d250bad6f
(cherry picked from commit e832fcffcf4997ad36b8a7990ae6c9bec772d80d)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/95/435695/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'releasenotes/notes/heat-listener-b908d0988840e1f3.yaml', 'senlin/tests/unit/engine/test_health_manager.py']",3,38b44b5ed7f8e1ff2ffae64809bdff25da183e4d,bug/1657983,"@mock.patch('senlin.engine.health_manager.HeatNotificationEndpoint') mock_target, mock_novaendpoint, mock_heatendpoint): mock_novaendpoint.return_value = x_endpoint mock_novaendpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') def test_listener_proc_heat(self, mock_listener, mock_transport, mock_target, mock_novaendpoint, mock_heatendpoint): x_listener = mock.Mock() mock_listener.return_value = x_listener x_target = mock.Mock() mock_target.return_value = x_target x_endpoint = mock.Mock() mock_heatendpoint.return_value = x_endpoint res = hm.ListenerProc('heat', 'PROJECT_ID', 'CLUSTER_ID') mock_target.assert_called_once_with(topic=""notifications"", exchange='heat') mock_heatendpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') mock_listener.assert_called_once_with( x_transport, [x_target], [x_endpoint], executor='threading', pool=""senlin-listeners"") x_listener.start.assert_called_once_with()"," mock_target, mock_endpoint): mock_endpoint.return_value = x_endpoint mock_endpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') def test_listener_proc_others(self, mock_listener, mock_transport, mock_target, mock_endpoint): res = hm.ListenerProc('BOGUS', 'PROJECT_ID', 'CLUSTER_ID') self.assertFalse(mock_listener.called) self.assertFalse(mock_target.called) self.assertFalse(mock_endpoint.called)",32,12
openstack%2Fopenstack-manuals~master~Ieec5f006afcebd8f99b0f779f97f922a7d7af0d5,openstack/openstack-manuals,master,Ieec5f006afcebd8f99b0f779f97f922a7d7af0d5,Image API configuration in Configuration Reference,MERGED,2017-02-17 18:12:59.000000000,2017-02-18 14:22:46.000000000,2017-02-18 14:22:46.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 8803}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-02-17 18:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/50b1eaad01469258af32657745c3b2a132bd6357', 'message': 'Image API configuration in Configuration Reference\n\nCorrect small grammar typo as v2 to as of v2\n\nChange-Id: Ieec5f006afcebd8f99b0f779f97f922a7d7af0d5\nCloses-Bug: #1665728\n'}, {'number': 2, 'created': '2017-02-18 02:44:37.000000000', 'files': ['doc/config-reference/source/image/api.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0b50c844391d26e3955464d00e3add40e59c6c69', 'message': 'Image API configuration in Configuration Reference\n\nCorrect small grammar typo as v2 to as of v2\n\nChange-Id: Ieec5f006afcebd8f99b0f779f97f922a7d7af0d5\nCloses-Bug: #1665728\n'}]",1,435558,0b50c844391d26e3955464d00e3add40e59c6c69,13,5,2,15993,,,0,"Image API configuration in Configuration Reference

Correct small grammar typo as v2 to as of v2

Change-Id: Ieec5f006afcebd8f99b0f779f97f922a7d7af0d5
Closes-Bug: #1665728
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/58/435558/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/image/api.rst'],1,50b1eaad01469258af32657745c3b2a132bd6357,bug/1665728,as of v2 ``glance-api`` can connect directly to the database.,as v2 of ``glance-api`` can connect directly to the database.,1,1
openstack%2Fkolla~stable%2Focata~If78b96f217c2ed4538196f64ccaa3c7471174b98,openstack/kolla,stable/ocata,If78b96f217c2ed4538196f64ccaa3c7471174b98,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-15 10:33:31.000000000,2017-02-18 14:19:47.000000000,2017-02-18 14:19:47.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 19316}]","[{'number': 1, 'created': '2017-02-15 10:33:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/454e027aa17b8630941e289bf7e8d9033a8b7f80', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: If78b96f217c2ed4538196f64ccaa3c7471174b98\n'}]",0,434206,454e027aa17b8630941e289bf7e8d9033a8b7f80,14,4,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: If78b96f217c2ed4538196f64ccaa3c7471174b98
",git fetch https://review.opendev.org/openstack/kolla refs/changes/06/434206/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,454e027aa17b8630941e289bf7e8d9033a8b7f80,create-ocata,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fopenstack-manuals~master~I95608991c780334d378f0c6ff59353a9b9a434bd,openstack/openstack-manuals,master,I95608991c780334d378f0c6ff59353a9b9a434bd,[config-ref] update conf changes tables for Ocata,MERGED,2017-02-18 12:16:01.000000000,2017-02-18 14:18:10.000000000,2017-02-18 14:18:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-18 12:16:01.000000000', 'files': ['doc/config-reference/source/tables/conf-changes/zaqar.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7461ded89b2f9a18ecba87fc91155f940b220c49', 'message': '[config-ref] update conf changes tables for Ocata\n\nChange-Id: I95608991c780334d378f0c6ff59353a9b9a434bd\n'}]",0,435699,7461ded89b2f9a18ecba87fc91155f940b220c49,6,2,1,10497,,,0,"[config-ref] update conf changes tables for Ocata

Change-Id: I95608991c780334d378f0c6ff59353a9b9a434bd
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/99/435699/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/source/tables/conf-changes/zaqar.rst'],1,7461ded89b2f9a18ecba87fc91155f940b220c49,config-reference,"New, updated, and deprecated options in Ocata for Message service ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * - ``[DEFAULT] conn_pool_min_size = 2`` - (IntOpt) The pool size limit for connections expiration policy * - ``[DEFAULT] conn_pool_ttl = 1200`` - (IntOpt) The time-to-live in sec of idle connections in the pool * - ``[DEFAULT] control_exchange = openstack`` - (StrOpt) The default exchange under which topics are scoped. May be overridden by an exchange name specified in the transport_url option. * - ``[DEFAULT] executor_thread_pool_size = 64`` - (IntOpt) Size of executor thread pool. * - ``[DEFAULT] rpc_ack_timeout_base = 15`` - (IntOpt) Number of seconds to wait for an ack from a cast/call. After each retry attempt this timeout is multiplied by some specified multiplier. * - ``[DEFAULT] rpc_ack_timeout_multiplier = 2`` - (IntOpt) Number to multiply base ack timeout by after each retry attempt. * - ``[DEFAULT] rpc_backend = rabbit`` - (StrOpt) The messaging driver to use, defaults to rabbit. Other drivers include amqp and zmq. * - ``[DEFAULT] rpc_conn_pool_size = 30`` - (IntOpt) Size of RPC connection pool. * - ``[DEFAULT] rpc_message_ttl = 300`` - (IntOpt) Expiration timeout in seconds of a sent/received message after which it is not tracked anymore by a client/server. * - ``[DEFAULT] rpc_poll_timeout = 1`` - (IntOpt) The default number of seconds that poll should wait. Poll raises timeout exception when timeout expired. * - ``[DEFAULT] rpc_response_timeout = 60`` - (IntOpt) Seconds to wait for a response from a call. * - ``[DEFAULT] rpc_retry_attempts = 3`` - (IntOpt) Default number of message sending attempts in case of any problems occurred: positive value N means at most N retries, 0 means no retries, None or -1 (or any other negative values) mean to retry forever. This option is used only if acknowledgments are enabled. * - ``[DEFAULT] rpc_thread_pool_size = 100`` - (IntOpt) Maximum number of (green) threads to work concurrently. * - ``[DEFAULT] rpc_use_acks = False`` - (BoolOpt) Wait for message acknowledgements from receivers. This mechanism works only via proxy without PUB/SUB. * - ``[DEFAULT] rpc_zmq_bind_address = *`` - (StrOpt) ZeroMQ bind address. Should be a wildcard (*), an ethernet interface, or IP. The ""host"" option should point or resolve to this address. * - ``[DEFAULT] rpc_zmq_bind_port_retries = 100`` - (IntOpt) Number of retries to find free port number before fail with ZMQBindError. * - ``[DEFAULT] rpc_zmq_contexts = 1`` - (IntOpt) Number of ZeroMQ contexts, defaults to 1. * - ``[DEFAULT] rpc_zmq_host = localhost`` - (StrOpt) Name of this node. Must be a valid hostname, FQDN, or IP address. Must match ""host"" option, if running Nova. * - ``[DEFAULT] rpc_zmq_ipc_dir = /var/run/openstack`` - (StrOpt) Directory for holding IPC sockets. * - ``[DEFAULT] rpc_zmq_matchmaker = redis`` - (StrOpt) MatchMaker driver. * - ``[DEFAULT] rpc_zmq_max_port = 65536`` - (IntOpt) Maximal port number for random ports range. * - ``[DEFAULT] rpc_zmq_min_port = 49153`` - (PortOpt) Minimal port number for random ports range. * - ``[DEFAULT] rpc_zmq_serialization = json`` - (StrOpt) Default serialization mechanism for serializing/deserializing outgoing/incoming messages * - ``[DEFAULT] rpc_zmq_topic_backlog = None`` - (IntOpt) Maximum number of ingress messages to locally buffer per topic. Default is unlimited. * - ``[DEFAULT] subscribe_on =`` - (ListOpt) List of publisher hosts SubConsumer can subscribe on. This option has higher priority then the default publishers list taken from the matchmaker. * - ``[DEFAULT] transport_url = None`` - (StrOpt) A URL representing the messaging driver to use and its full configuration. * - ``[DEFAULT] use_dynamic_connections = False`` - (BoolOpt) This option makes direct connections dynamic or static. It makes sense only with use_router_proxy=False which means to use direct connections for direct message types (ignored otherwise). * - ``[DEFAULT] use_pub_sub = False`` - (BoolOpt) Use PUB/SUB pattern for fanout methods. PUB/SUB always uses proxy. * - ``[DEFAULT] use_router_proxy = False`` - (BoolOpt) Use ROUTER remote proxy. * - ``[DEFAULT] zmq_failover_connections = 2`` - (IntOpt) How many additional connections to a host will be made for failover reasons. This option is actual only in dynamic connections mode. * - ``[DEFAULT] zmq_immediate = True`` - (BoolOpt) This option configures round-robin mode in zmq socket. True means not keeping a queue when server side disconnects. False means to keep queue and messages even if server is disconnected, when the server appears we send all accumulated messages to it. * - ``[DEFAULT] zmq_linger = -1`` - (IntOpt) Number of seconds to wait before all pending messages will be sent after closing a socket. The default value of -1 specifies an infinite linger period. The value of 0 specifies no linger period. Pending messages shall be discarded immediately when the socket is closed. Positive values specify an upper bound for the linger period. * - ``[DEFAULT] zmq_target_expire = 300`` - (IntOpt) Expiration timeout in seconds of a name service record about existing target ( < 0 means no timeout). * - ``[DEFAULT] zmq_target_update = 180`` - (IntOpt) Update period in seconds of a name service record about existing target. * - ``[DEFAULT] zmq_tcp_keepalive = -1`` - (IntOpt) Enable/disable TCP keepalive (KA) mechanism. The default value of -1 (or any other negative value) means to skip any overrides and leave it to OS default; 0 and 1 (or any other positive value) mean to disable and enable the option respectively. * - ``[DEFAULT] zmq_tcp_keepalive_cnt = -1`` - (IntOpt) The number of retransmissions to be carried out before declaring that remote end is not available. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[DEFAULT] zmq_tcp_keepalive_idle = -1`` - (IntOpt) The duration between two keepalive transmissions in idle condition. The unit is platform dependent, for example, seconds in Linux, milliseconds in Windows etc. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[DEFAULT] zmq_tcp_keepalive_intvl = -1`` - (IntOpt) The duration between two successive keepalive retransmissions, if acknowledgement to the previous keepalive transmission is not received. The unit is platform dependent, for example, seconds in Linux, milliseconds in Windows etc. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[drivers:message_store:swift] auth_url = http://127.0.0.1:5000/v3/`` - (StrOpt) URI of Keystone endpoint to discover Swift * - ``[drivers:message_store:swift] insecure = False`` - (StrOpt) Don't check SSL certificate * - ``[drivers:message_store:swift] uri = swift://demo:nomoresecrete@/demo`` - (StrOpt) Custom URI describing the swift connection. * - ``[matchmaker_redis] check_timeout = 20000`` - (IntOpt) Time in ms to wait before the transaction is killed. * - ``[matchmaker_redis] host = 127.0.0.1`` - (StrOpt) Host to locate redis. * - ``[matchmaker_redis] password =`` - (StrOpt) Password for Redis server (optional). * - ``[matchmaker_redis] port = 6379`` - (PortOpt) Use this port to connect to redis host. * - ``[matchmaker_redis] sentinel_group_name = oslo-messaging-zeromq`` - (StrOpt) Redis replica set name. * - ``[matchmaker_redis] sentinel_hosts =`` - (ListOpt) List of Redis Sentinel hosts (fault tolerance mode), e.g., [host:port, host1:port ... ] * - ``[matchmaker_redis] socket_timeout = 10000`` - (IntOpt) Timeout in ms on blocking socket operations. * - ``[matchmaker_redis] wait_timeout = 2000`` - (IntOpt) Time in ms to wait between connection attempts. * - ``[notification] external_confirmation_url = None`` - (StrOpt) The confirmation page url that will be used in email subscription confirmation before notification. * - ``[notification] subscription_confirmation_email_template = {'topic': 'Zaqar Notification - Subscription Confirmation', 'body': 'You have chosen to subscribe to the queue: {0}. This queue belongs to project: {1}. To confirm this subscription, click or visit this link below: {2}', 'sender': 'Zaqar Notifications <no-reply@openstack.org>'}`` - (DictOpt) Defines the set of subscription confirmation email content, including topic, body and sender. There is a mapping is {0} -> queue name, {1} ->project id, {2}-> confirm url in body string. User can use any of the three value. But they can't use more than three. * - ``[notification] unsubscribe_confirmation_email_template = {'topic': 'Zaqar Notification - Unsubscribe Confirmation', 'body': 'You have unsubscribed successfully to the queue: {0}. This queue belongs to project: {1}. To resubscribe this subscription, click or visit this link below: {2}', 'sender': 'Zaqar Notifications <no-reply@openstack.org>'}`` - (DictOpt) Defines the set of unsubscribe confirmation email content, including topic, body and sender. There is a mapping is {0} -> queue name, {1} ->project id, {2}-> confirm url in body string. User can use any of the three value. But they can't use more than three. * - ``[oslo_concurrency] disable_process_locking = False`` - (BoolOpt) Enables or disables inter-process locks. * - ``[oslo_concurrency] lock_path = None`` - (StrOpt) Directory to use for lock files. For security, the specified directory should only be writable by the user running the processes that need locking. Defaults to environment variable OSLO_LOCK_PATH. If external locks are used, a lock path must be set. * - ``[oslo_messaging_amqp] addressing_mode = dynamic`` - (StrOpt) Indicates the addressing mode used by the driver. Permitted values: 'legacy' - use legacy non-routable addressing 'routable' - use routable addresses 'dynamic' - use legacy addresses if the message bus does not support routing otherwise use routable addressing * - ``[oslo_messaging_amqp] allow_insecure_clients = False`` - (BoolOpt) Accept clients using either SSL or plain TCP * - ``[oslo_messaging_amqp] anycast_address = anycast`` - (StrOpt) Appended to the address prefix when sending to a group of consumers. Used by the message bus to identify messages that should be delivered in a round-robin fashion across consumers. * - ``[oslo_messaging_amqp] broadcast_prefix = broadcast`` - (StrOpt) address prefix used when broadcasting to all servers * - ``[oslo_messaging_amqp] connection_retry_backoff = 2`` - (IntOpt) Increase the connection_retry_interval by this many seconds after each unsuccessful failover attempt. * - ``[oslo_messaging_amqp] connection_retry_interval = 1`` - (IntOpt) Seconds to pause before attempting to re-connect. * - ``[oslo_messaging_amqp] connection_retry_interval_max = 30`` - (IntOpt) Maximum limit for connection_retry_interval + connection_retry_backoff * - ``[oslo_messaging_amqp] container_name = None`` - (StrOpt) Name for the AMQP container. must be globally unique. Defaults to a generated UUID * - ``[oslo_messaging_amqp] default_notification_exchange = None`` - (StrOpt) Exchange name used in notification addresses. Exchange name resolution precedence: Target.exchange if set else default_notification_exchange if set else control_exchange if set else 'notify' * - ``[oslo_messaging_amqp] default_notify_timeout = 30`` - (IntOpt) The deadline for a sent notification message delivery. Only used when caller does not provide a timeout expiry. * - ``[oslo_messaging_amqp] default_reply_retry = 0`` - (IntOpt) The maximum number of attempts to re-send a reply message which failed due to a recoverable error. * - ``[oslo_messaging_amqp] default_reply_timeout = 30`` - (IntOpt) The deadline for an rpc reply message delivery. * - ``[oslo_messaging_amqp] default_rpc_exchange = None`` - (StrOpt) Exchange name used in RPC addresses. Exchange name resolution precedence: Target.exchange if set else default_rpc_exchange if set else control_exchange if set else 'rpc' * - ``[oslo_messaging_amqp] default_send_timeout = 30`` - (IntOpt) The deadline for an rpc cast or call message delivery. Only used when caller does not provide a timeout expiry. * - ``[oslo_messaging_amqp] default_sender_link_timeout = 600`` - (IntOpt) The duration to schedule a purge of idle sender links. Detach link after expiry. * - ``[oslo_messaging_amqp] group_request_prefix = unicast`` - (StrOpt) address prefix when sending to any server in group * - ``[oslo_messaging_amqp] idle_timeout = 0`` - (IntOpt) Timeout for inactive connections (in seconds) * - ``[oslo_messaging_amqp] link_retry_delay = 10`` - (IntOpt) Time to pause between re-connecting an AMQP 1.0 link that failed due to a recoverable error. * - ``[oslo_messaging_amqp] multicast_address = multicast`` - (StrOpt) Appended to the address prefix when sending a fanout message. Used by the message bus to identify fanout messages. * - ``[oslo_messaging_amqp] notify_address_prefix = openstack.org/om/notify`` - (StrOpt) Address prefix for all generated Notification addresses * - ``[oslo_messaging_amqp] notify_server_credit = 100`` - (IntOpt) Window size for incoming Notification messages * - ``[oslo_messaging_amqp] password =`` - (StrOpt) Password for message broker authentication * - ``[oslo_messaging_amqp] pre_settled = ['rpc-cast', 'rpc-reply']`` - (MultiStrOpt) Send messages of this type pre-settled. Pre-settled messages will not receive acknowledgement from the peer. Note well: pre-settled messages may be silently discarded if the delivery fails. Permitted values: 'rpc-call' - send RPC Calls pre-settled 'rpc-reply'- send RPC Replies pre-settled 'rpc-cast' - Send RPC Casts pre-settled 'notify' - Send Notifications pre-settled * - ``[oslo_messaging_amqp] reply_link_credit = 200`` - (IntOpt) Window size for incoming RPC Reply messages. * - ``[oslo_messaging_amqp] rpc_address_prefix = openstack.org/om/rpc`` - (StrOpt) Address prefix for all generated RPC addresses * - ``[oslo_messaging_amqp] rpc_server_credit = 100`` - (IntOpt) Window size for incoming RPC Request messages * - ``[oslo_messaging_amqp] sasl_config_dir =`` - (StrOpt) Path to directory that contains the SASL configuration * - ``[oslo_messaging_amqp] sasl_config_name =`` - (StrOpt) Name of configuration file (without .conf suffix) * - ``[oslo_messaging_amqp] sasl_mechanisms =`` - (StrOpt) Space separated list of acceptable SASL mechanisms * - ``[oslo_messaging_amqp] server_request_prefix = exclusive`` - (StrOpt) address prefix used when sending to a specific server * - ``[oslo_messaging_amqp] ssl_ca_file =`` - (StrOpt) CA certificate PEM file used to verify the server's certificate * - ``[oslo_messaging_amqp] ssl_cert_file =`` - (StrOpt) Self-identifying certificate PEM file for client authentication * - ``[oslo_messaging_amqp] ssl_key_file =`` - (StrOpt) Private key PEM file used to sign ssl_cert_file certificate (optional) * - ``[oslo_messaging_amqp] ssl_key_password = None`` - (StrOpt) Password for decrypting ssl_key_file (if encrypted) * - ``[oslo_messaging_amqp] trace = False`` - (BoolOpt) Debug: dump AMQP frames to stdout * - ``[oslo_messaging_amqp] unicast_address = unicast`` - (StrOpt) Appended to the address prefix when sending to a particular RPC/Notification server. Used by the message bus to identify messages sent to a single destination. * - ``[oslo_messaging_amqp] username =`` - (StrOpt) User name for message broker authentication * - ``[oslo_messaging_kafka] conn_pool_min_size = 2`` - (IntOpt) The pool size limit for connections expiration policy * - ``[oslo_messaging_kafka] conn_pool_ttl = 1200`` - (IntOpt) The time-to-live in sec of idle connections in the pool * - ``[oslo_messaging_kafka] consumer_group = oslo_messaging_consumer`` - (StrOpt) Group id for Kafka consumer. Consumers in one group will coordinate message consumption * - ``[oslo_messaging_kafka] kafka_consumer_timeout = 1.0`` - (IntOpt) Default timeout(s) for Kafka consumers * - ``[oslo_messaging_kafka] kafka_default_host = localhost`` - (StrOpt) Default Kafka broker Host * - ``[oslo_messaging_kafka] kafka_default_port = 9092`` - (PortOpt) Default Kafka broker Port * - ``[oslo_messaging_kafka] kafka_max_fetch_bytes = 1048576`` - (IntOpt) Max fetch bytes of Kafka consumer * - ``[oslo_messaging_kafka] pool_size = 10`` - (IntOpt) Pool Size for Kafka Consumers * - ``[oslo_messaging_kafka] producer_batch_size = 16384`` - (IntOpt) Size of batch for the producer async send * - ``[oslo_messaging_kafka] producer_batch_timeout = 0.0`` - (FloatOpt) Upper bound on the delay for KafkaProducer batching in seconds * - ``[oslo_messaging_notifications] driver = []`` - (MultiStrOpt) The Drivers(s) to handle sending notifications. Possible values are messaging, messagingv2, routing, log, test, noop * - ``[oslo_messaging_notifications] topics = notifications`` - (ListOpt) AMQP topic used for OpenStack notifications. * - ``[oslo_messaging_notifications] transport_url = None`` - (StrOpt) A URL representing the messaging driver to use for notifications. If not set, we fall back to the same configuration used for RPC. * - ``[oslo_messaging_rabbit] amqp_auto_delete = False`` - (BoolOpt) Auto-delete queues in AMQP. * - ``[oslo_messaging_rabbit] amqp_durable_queues = False`` - (BoolOpt) Use durable queues in AMQP. * - ``[oslo_messaging_rabbit] channel_max = None`` - (IntOpt) Maximum number of channels to allow * - ``[oslo_messaging_rabbit] connection_factory = single`` - (StrOpt) Connection factory implementation * - ``[oslo_messaging_rabbit] default_notification_exchange = ${control_exchange}_notification`` - (StrOpt) Exchange name for sending notifications * - ``[oslo_messaging_rabbit] default_notification_retry_attempts = -1`` - (IntOpt) Reconnecting retry count in case of connectivity problem during sending notification, -1 means infinite retry. * - ``[oslo_messaging_rabbit] default_rpc_exchange = ${control_exchange}_rpc`` - (StrOpt) Exchange name for sending RPC messages * - ``[oslo_messaging_rabbit] default_rpc_retry_attempts = -1`` - (IntOpt) Reconnecting retry count in case of connectivity problem during sending RPC message, -1 means infinite retry. If actual retry attempts in not 0 the rpc request could be processed more than one time * - ``[oslo_messaging_rabbit] default_serializer_type = json`` - (StrOpt) Default serialization mechanism for serializing/deserializing outgoing/incoming messages * - ``[oslo_messaging_rabbit] fake_rabbit = False`` - (BoolOpt) Deprecated, use rpc_backend=kombu+memory or rpc_backend=fake * - ``[oslo_messaging_rabbit] frame_max = None`` - (IntOpt) The maximum byte size for an AMQP frame * - ``[oslo_messaging_rabbit] heartbeat_interval = 3`` - (IntOpt) How often to send heartbeats for consumer's connections * - ``[oslo_messaging_rabbit] heartbeat_rate = 2`` - (IntOpt) How often times during the heartbeat_timeout_threshold we check the heartbeat. * - ``[oslo_messaging_rabbit] heartbeat_timeout_threshold = 60`` - (IntOpt) Number of seconds after which the Rabbit broker is considered down if heartbeat's keep-alive fails (0 disable the heartbeat). EXPERIMENTAL * - ``[oslo_messaging_rabbit] host_connection_reconnect_delay = 0.25`` - (FloatOpt) Set delay for reconnection to some host which has connection error * - ``[oslo_messaging_rabbit] kombu_compression = None`` - (StrOpt) EXPERIMENTAL: Possible values are: gzip, bz2. If not set compression will not be used. This option may not be available in future versions. * - ``[oslo_messaging_rabbit] kombu_failover_strategy = round-robin`` - (StrOpt) Determines how the next RabbitMQ node is chosen in case the one we are currently connected to becomes unavailable. Takes effect only if more than one RabbitMQ node is provided in config. * - ``[oslo_messaging_rabbit] kombu_missing_consumer_retry_timeout = 60`` - (IntOpt) How long to wait a missing client before abandoning to send it its replies. This value should not be longer than rpc_response_timeout. * - ``[oslo_messaging_rabbit] kombu_reconnect_delay = 1.0`` - (FloatOpt) How long to wait before reconnecting in response to an AMQP consumer cancel notification. * - ``[oslo_messaging_rabbit] kombu_ssl_ca_certs =`` - (StrOpt) SSL certification authority file (valid only if SSL enabled). * - ``[oslo_messaging_rabbit] kombu_ssl_certfile =`` - (StrOpt) SSL cert file (valid only if SSL enabled). * - ``[oslo_messaging_rabbit] kombu_ssl_keyfile =`` - (StrOpt) SSL key file (valid only if SSL enabled). * - ``[oslo_messaging_rabbit] kombu_ssl_version =`` - (StrOpt) SSL version to use (valid only if SSL enabled). Valid values are TLSv1 and SSLv23. SSLv2, SSLv3, TLSv1_1, and TLSv1_2 may be available on some distributions. * - ``[oslo_messaging_rabbit] notification_listener_prefetch_count = 100`` - (IntOpt) Max number of not acknowledged message which RabbitMQ can send to notification listener. * - ``[oslo_messaging_rabbit] notification_persistence = False`` - (BoolOpt) Persist notification messages. * - ``[oslo_messaging_rabbit] notification_retry_delay = 0.25`` - (FloatOpt) Reconnecting retry delay in case of connectivity problem during sending notification message * - ``[oslo_messaging_rabbit] pool_max_overflow = 0`` - (IntOpt) Maximum number of connections to create above `pool_max_size`. * - ``[oslo_messaging_rabbit] pool_max_size = 30`` - (IntOpt) Maximum number of connections to keep queued. * - ``[oslo_messaging_rabbit] pool_recycle = 600`` - (IntOpt) Lifetime of a connection (since creation) in seconds or None for no recycling. Expired connections are closed on acquire. * - ``[oslo_messaging_rabbit] pool_stale = 60`` - (IntOpt) Threshold at which inactive (since release) connections are considered stale in seconds or None for no staleness. Stale connections are closed on acquire. * - ``[oslo_messaging_rabbit] pool_timeout = 30`` - (IntOpt) Default number of seconds to wait for a connections to available * - ``[oslo_messaging_rabbit] rabbit_ha_queues = False`` - (BoolOpt) Try to use HA queues in RabbitMQ (x-ha-policy: all). If you change this option, you must wipe the RabbitMQ database. In RabbitMQ 3.0, queue mirroring is no longer controlled by the x-ha-policy argument when declaring a queue. If you just want to make sure that all queues (except those with auto-generated names) are mirrored across all nodes, run: ""rabbitmqctl set_policy HA '^(?!amq\.).*' '{""ha-mode"": ""all""}' "" * - ``[oslo_messaging_rabbit] rabbit_host = localhost`` - (StrOpt) The RabbitMQ broker address where a single node is used. * - ``[oslo_messaging_rabbit] rabbit_hosts = $rabbit_host:$rabbit_port`` - (ListOpt) RabbitMQ HA cluster host:port pairs. * - ``[oslo_messaging_rabbit] rabbit_interval_max = 30`` - (IntOpt) Maximum interval of RabbitMQ connection retries. Default is 30 seconds. * - ``[oslo_messaging_rabbit] rabbit_login_method = AMQPLAIN`` - (StrOpt) The RabbitMQ login method. * - ``[oslo_messaging_rabbit] rabbit_max_retries = 0`` - (IntOpt) Maximum number of RabbitMQ connection retries. Default is 0 (infinite retry count). * - ``[oslo_messaging_rabbit] rabbit_password = guest`` - (StrOpt) The RabbitMQ password. * - ``[oslo_messaging_rabbit] rabbit_port = 5672`` - (PortOpt) The RabbitMQ broker port where a single node is used. * - ``[oslo_messaging_rabbit] rabbit_qos_prefetch_count = 0`` - (IntOpt) Specifies the number of messages to prefetch. Setting to zero allows unlimited messages. * - ``[oslo_messaging_rabbit] rabbit_retry_backoff = 2`` - (IntOpt) How long to backoff for between retries when connecting to RabbitMQ. * - ``[oslo_messaging_rabbit] rabbit_retry_interval = 1`` - (IntOpt) How frequently to retry connecting with RabbitMQ. * - ``[oslo_messaging_rabbit] rabbit_transient_queues_ttl = 1800`` - (IntOpt) Positive integer representing duration in seconds for queue TTL (x-expires). Queues which are unused for the duration of the TTL are automatically deleted. The parameter affects only reply and fanout queues. * - ``[oslo_messaging_rabbit] rabbit_use_ssl = False`` - (BoolOpt) Connect over SSL for RabbitMQ. * - ``[oslo_messaging_rabbit] rabbit_userid = guest`` - (StrOpt) The RabbitMQ userid. * - ``[oslo_messaging_rabbit] rabbit_virtual_host = /`` - (StrOpt) The RabbitMQ virtual host. * - ``[oslo_messaging_rabbit] rpc_listener_prefetch_count = 100`` - (IntOpt) Max number of not acknowledged message which RabbitMQ can send to rpc listener. * - ``[oslo_messaging_rabbit] rpc_queue_expiration = 60`` - (IntOpt) Time to live for rpc queues without consumers in seconds. * - ``[oslo_messaging_rabbit] rpc_reply_exchange = ${control_exchange}_rpc_reply`` - (StrOpt) Exchange name for receiving RPC replies * - ``[oslo_messaging_rabbit] rpc_reply_listener_prefetch_count = 100`` - (IntOpt) Max number of not acknowledged message which RabbitMQ can send to rpc reply listener. * - ``[oslo_messaging_rabbit] rpc_reply_retry_attempts = -1`` - (IntOpt) Reconnecting retry count in case of connectivity problem during sending reply. -1 means infinite retry during rpc_timeout * - ``[oslo_messaging_rabbit] rpc_reply_retry_delay = 0.25`` - (FloatOpt) Reconnecting retry delay in case of connectivity problem during sending reply. * - ``[oslo_messaging_rabbit] rpc_retry_delay = 0.25`` - (FloatOpt) Reconnecting retry delay in case of connectivity problem during sending RPC message * - ``[oslo_messaging_rabbit] socket_timeout = 0.25`` - (FloatOpt) Set socket timeout in seconds for connection's socket * - ``[oslo_messaging_rabbit] ssl = None`` - (BoolOpt) Enable SSL * - ``[oslo_messaging_rabbit] ssl_options = None`` - (DictOpt) Arguments passed to ssl.wrap_socket * - ``[oslo_messaging_rabbit] tcp_user_timeout = 0.25`` - (FloatOpt) Set TCP_USER_TIMEOUT in seconds for connection's socket * - ``[oslo_messaging_zmq] rpc_ack_timeout_base = 15`` - (IntOpt) Number of seconds to wait for an ack from a cast/call. After each retry attempt this timeout is multiplied by some specified multiplier. * - ``[oslo_messaging_zmq] rpc_ack_timeout_multiplier = 2`` - (IntOpt) Number to multiply base ack timeout by after each retry attempt. * - ``[oslo_messaging_zmq] rpc_message_ttl = 300`` - (IntOpt) Expiration timeout in seconds of a sent/received message after which it is not tracked anymore by a client/server. * - ``[oslo_messaging_zmq] rpc_poll_timeout = 1`` - (IntOpt) The default number of seconds that poll should wait. Poll raises timeout exception when timeout expired. * - ``[oslo_messaging_zmq] rpc_retry_attempts = 3`` - (IntOpt) Default number of message sending attempts in case of any problems occurred: positive value N means at most N retries, 0 means no retries, None or -1 (or any other negative values) mean to retry forever. This option is used only if acknowledgments are enabled. * - ``[oslo_messaging_zmq] rpc_thread_pool_size = 100`` - (IntOpt) Maximum number of (green) threads to work concurrently. * - ``[oslo_messaging_zmq] rpc_use_acks = False`` - (BoolOpt) Wait for message acknowledgements from receivers. This mechanism works only via proxy without PUB/SUB. * - ``[oslo_messaging_zmq] rpc_zmq_bind_address = *`` - (StrOpt) ZeroMQ bind address. Should be a wildcard (*), an ethernet interface, or IP. The ""host"" option should point or resolve to this address. * - ``[oslo_messaging_zmq] rpc_zmq_bind_port_retries = 100`` - (IntOpt) Number of retries to find free port number before fail with ZMQBindError. * - ``[oslo_messaging_zmq] rpc_zmq_contexts = 1`` - (IntOpt) Number of ZeroMQ contexts, defaults to 1. * - ``[oslo_messaging_zmq] rpc_zmq_host = localhost`` - (StrOpt) Name of this node. Must be a valid hostname, FQDN, or IP address. Must match ""host"" option, if running Nova. * - ``[oslo_messaging_zmq] rpc_zmq_ipc_dir = /var/run/openstack`` - (StrOpt) Directory for holding IPC sockets. * - ``[oslo_messaging_zmq] rpc_zmq_matchmaker = redis`` - (StrOpt) MatchMaker driver. * - ``[oslo_messaging_zmq] rpc_zmq_max_port = 65536`` - (IntOpt) Maximal port number for random ports range. * - ``[oslo_messaging_zmq] rpc_zmq_min_port = 49153`` - (PortOpt) Minimal port number for random ports range. * - ``[oslo_messaging_zmq] rpc_zmq_serialization = json`` - (StrOpt) Default serialization mechanism for serializing/deserializing outgoing/incoming messages * - ``[oslo_messaging_zmq] rpc_zmq_topic_backlog = None`` - (IntOpt) Maximum number of ingress messages to locally buffer per topic. Default is unlimited. * - ``[oslo_messaging_zmq] subscribe_on =`` - (ListOpt) List of publisher hosts SubConsumer can subscribe on. This option has higher priority then the default publishers list taken from the matchmaker. * - ``[oslo_messaging_zmq] use_dynamic_connections = False`` - (BoolOpt) This option makes direct connections dynamic or static. It makes sense only with use_router_proxy=False which means to use direct connections for direct message types (ignored otherwise). * - ``[oslo_messaging_zmq] use_pub_sub = False`` - (BoolOpt) Use PUB/SUB pattern for fanout methods. PUB/SUB always uses proxy. * - ``[oslo_messaging_zmq] use_router_proxy = False`` - (BoolOpt) Use ROUTER remote proxy. * - ``[oslo_messaging_zmq] zmq_failover_connections = 2`` - (IntOpt) How many additional connections to a host will be made for failover reasons. This option is actual only in dynamic connections mode. * - ``[oslo_messaging_zmq] zmq_immediate = True`` - (BoolOpt) This option configures round-robin mode in zmq socket. True means not keeping a queue when server side disconnects. False means to keep queue and messages even if server is disconnected, when the server appears we send all accumulated messages to it. * - ``[oslo_messaging_zmq] zmq_linger = -1`` - (IntOpt) Number of seconds to wait before all pending messages will be sent after closing a socket. The default value of -1 specifies an infinite linger period. The value of 0 specifies no linger period. Pending messages shall be discarded immediately when the socket is closed. Positive values specify an upper bound for the linger period. * - ``[oslo_messaging_zmq] zmq_target_expire = 300`` - (IntOpt) Expiration timeout in seconds of a name service record about existing target ( < 0 means no timeout). * - ``[oslo_messaging_zmq] zmq_target_update = 180`` - (IntOpt) Update period in seconds of a name service record about existing target. * - ``[oslo_messaging_zmq] zmq_tcp_keepalive = -1`` - (IntOpt) Enable/disable TCP keepalive (KA) mechanism. The default value of -1 (or any other negative value) means to skip any overrides and leave it to OS default; 0 and 1 (or any other positive value) mean to disable and enable the option respectively. * - ``[oslo_messaging_zmq] zmq_tcp_keepalive_cnt = -1`` - (IntOpt) The number of retransmissions to be carried out before declaring that remote end is not available. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[oslo_messaging_zmq] zmq_tcp_keepalive_idle = -1`` - (IntOpt) The duration between two keepalive transmissions in idle condition. The unit is platform dependent, for example, seconds in Linux, milliseconds in Windows etc. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[oslo_messaging_zmq] zmq_tcp_keepalive_intvl = -1`` - (IntOpt) The duration between two successive keepalive retransmissions, if acknowledgement to the previous keepalive transmission is not received. The unit is platform dependent, for example, seconds in Linux, milliseconds in Windows etc. The default value of -1 (or any other negative value and 0) means to skip any overrides and leave it to OS default. * - ``[profiler] connection_string = messaging://`` - (StrOpt) Connection string for a notifier backend. Default value is messaging:// which sets the notifier to oslo_messaging. Examples of possible values: * messaging://: use oslo_messaging driver for sending notifications. * mongodb://127.0.0.1:27017 : use mongodb driver for sending notifications. * elasticsearch://127.0.0.1:9200 : use elasticsearch driver for sending notifications. * - ``[profiler] enabled = False`` - (BoolOpt) Enables the profiling for all services on this node. Default value is False (fully disable the profiling feature). Possible values: * True: Enables the feature * False: Disables the feature. The profiling cannot be started via this project operations. If the profiling is triggered by another project, this project part will be empty. * - ``[profiler] es_doc_type = notification`` - (StrOpt) Document type for notification indexing in elasticsearch. * - ``[profiler] es_scroll_size = 10000`` - (IntOpt) Elasticsearch splits large requests in batches. This parameter defines maximum size of each batch (for example: es_scroll_size=10000). * - ``[profiler] es_scroll_time = 2m`` - (StrOpt) This parameter is a time value parameter (for example: es_scroll_time=2m), indicating for how long the nodes that participate in the search will maintain relevant resources in order to continue and support it. * - ``[profiler] hmac_keys = SECRET_KEY`` - (StrOpt) Secret key(s) to use for encrypting context data for performance profiling. This string value should have the following format: <key1>[,<key2>,...<keyn>], where each key is some random string. A user who triggers the profiling via the REST API has to set one of these keys in the headers of the REST API call to include profiling results of this node for this particular project. Both ""enabled"" flag and ""hmac_keys"" config options should be set to enable profiling. Also, to generate correct profiling information across all services at least one key needs to be consistent between OpenStack projects. This ensures it can be used from client side to generate the trace, containing information from all possible resources. * - ``[profiler] sentinel_service_name = mymaster`` - (StrOpt) Redissentinel uses a service name to identify a master redis service. This parameter defines the name (for example: sentinal_service_name=mymaster). * - ``[profiler] socket_timeout = 0.1`` - (FloatOpt) Redissentinel provides a timeout option on the connections. This parameter defines that timeout (for example: socket_timeout=0.1). * - ``[profiler] trace_management_store = False`` - (BoolOpt) If False doesn't trace any management store requests. * - ``[profiler] trace_message_store = False`` - (BoolOpt) If False doesn't trace any message store requests. * - ``[profiler] trace_sqlalchemy = False`` - (BoolOpt) Enables SQL requests profiling in services. Default value is False (SQL requests won't be traced). Possible values: * True: Enables SQL requests profiling. Each SQL query will be part of the trace and can the be analyzed by how much time was spent for that. * False: Disables SQL requests profiling. The spent time is only shown on a higher level of operations. Single SQL queries cannot be analyzed this way. * - ``[profiler] trace_wsgi_transport = False`` - (BoolOpt) If False doesn't trace any transport requests.Please note that it doesn't work for websocket now. * - ``[transport] max_flavors_per_page = 20`` - (IntOpt) Defines the maximum number of flavors per page. * - ``[transport] max_pools_per_page = 20`` - (IntOpt) Defines the maximum number of pools per page. ","New, updated, and deprecated options in Newton for Message service ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * - ``[DEFAULT] enable_deprecated_api_versions =`` - (ListOpt) List of deprecated API versions to enable. * - ``[notification] max_notifier_workers = 10`` - (IntOpt) The max amount of the notification workers. * - ``[notification] require_confirmation = False`` - (BoolOpt) Whether the http/https/email subscription need to be confirmed before notification. * - ``[trustee] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[trustee] auth_type = None`` - (Opt) Authentication type to load * - ``[trustee] auth_url = None`` - (Opt) Authentication URL * - ``[trustee] default_domain_id = None`` - (Opt) Optional domain ID to use with v3 and v2 parameters. It will be used for both the user and project domain in v3 and ignored in v2 authentication. * - ``[trustee] default_domain_name = None`` - (Opt) Optional domain name to use with v3 API and v2 parameters. It will be used for both the user and project domain in v3 and ignored in v2 authentication. * - ``[trustee] domain_id = None`` - (Opt) Domain ID to scope to * - ``[trustee] domain_name = None`` - (Opt) Domain name to scope to * - ``[trustee] password = None`` - (Opt) User's password * - ``[trustee] project_domain_id = None`` - (Opt) Domain ID containing project * - ``[trustee] project_domain_name = None`` - (Opt) Domain name containing project * - ``[trustee] project_id = None`` - (Opt) Project ID to scope to * - ``[trustee] project_name = None`` - (Opt) Project name to scope to * - ``[trustee] trust_id = None`` - (Opt) Trust ID * - ``[trustee] user_domain_id = None`` - (Opt) User's domain id * - ``[trustee] user_domain_name = None`` - (Opt) User's domain name * - ``[trustee] user_id = None`` - (Opt) User id * - ``[trustee] username = None`` - (Opt) Username .. list-table:: New default values :header-rows: 1 :class: config-ref-table * - Option - Previous default value - New default value * - ``[transport] subscriber_types`` - ``http, https, mailto`` - ``http, https, mailto, trust+http, trust+https``",412,52
openstack%2Fopenstack-manuals~master~I4e9ef63e69e2c6a4081807f6a9725d6c56addeb6,openstack/openstack-manuals,master,I4e9ef63e69e2c6a4081807f6a9725d6c56addeb6,[config-ref] update ironic config options for Ocata,MERGED,2017-02-18 13:39:38.000000000,2017-02-18 14:17:54.000000000,2017-02-18 14:17:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-18 13:39:38.000000000', 'files': ['doc/config-reference/source/tables/ironic-pxe.rst', 'doc/config-reference/source/tables/ironic-neutron.rst', 'doc/config-reference/source/tables/ironic-audit.rst', 'doc/config-reference/source/tables/ironic-irmc.rst', 'tools/autogenerate-config-flagmappings/ironic.flagmappings', 'doc/config-reference/source/tables/ironic-inspector.rst', 'doc/config-reference/source/tables/ironic-redis.rst', 'doc/config-reference/source/tables/ironic-common.rst', 'doc/config-reference/source/tables/ironic-conductor.rst', 'doc/config-reference/source/tables/ironic-glance.rst', 'doc/config-reference/source/tables/ironic-deploy.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f3df83f0d485cb808d6a05320f80b5bb7cd62cd', 'message': '[config-ref] update ironic config options for Ocata\n\nChange-Id: I4e9ef63e69e2c6a4081807f6a9725d6c56addeb6\n'}]",0,435707,0f3df83f0d485cb808d6a05320f80b5bb7cd62cd,6,2,1,10497,,,0,"[config-ref] update ironic config options for Ocata

Change-Id: I4e9ef63e69e2c6a4081807f6a9725d6c56addeb6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/07/435707/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/tables/ironic-pxe.rst', 'doc/config-reference/source/tables/ironic-neutron.rst', 'doc/config-reference/source/tables/ironic-audit.rst', 'doc/config-reference/source/tables/ironic-irmc.rst', 'doc/config-reference/source/tables/ironic-inspector.rst', 'tools/autogenerate-config-flagmappings/ironic.flagmappings', 'doc/config-reference/source/tables/ironic-common.rst', 'doc/config-reference/source/tables/ironic-redis.rst', 'doc/config-reference/source/tables/ironic-conductor.rst', 'doc/config-reference/source/tables/ironic-glance.rst', 'doc/config-reference/source/tables/ironic-deploy.rst']",11,0f3df83f0d485cb808d6a05320f80b5bb7cd62cd,," * - ``default_boot_option`` = ``None`` - (String) Default boot option to use when no boot option is requested in node's driver_info. Currently the default is ""netboot"", but it will be changed to ""local"" in the future. It is recommended to set an explicit value for this option.",,169,27
openstack%2Fceilometer~master~I790e36c7daefb07eefe68298f91c14211f9a8df0,openstack/ceilometer,master,I790e36c7daefb07eefe68298f91c14211f9a8df0,drop kwapi pollster,MERGED,2017-02-10 21:21:26.000000000,2017-02-18 14:17:41.000000000,2017-02-18 14:17:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 15843}, {'_account_id': 22752}, {'_account_id': 23122}]","[{'number': 1, 'created': '2017-02-10 21:21:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/53ce8a35558f9a3ab55b865a77af51b166628a9a', 'message': ""drop kwapi pollster\n\nwe deprecated this in kwapi and it's been dead for far longer.\n\nChange-Id: I790e36c7daefb07eefe68298f91c14211f9a8df0\n""}, {'number': 2, 'created': '2017-02-10 21:30:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9d1bb208ccef70dab771296f920d9289d6e967a9', 'message': ""drop kwapi pollster\n\nwe deprecated this in newton and it's been dead for far longer.\n\nChange-Id: I790e36c7daefb07eefe68298f91c14211f9a8df0\n""}, {'number': 3, 'created': '2017-02-13 15:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/2e0e39e168f01f876101a4bf5fcdbcb02260209c', 'message': ""drop kwapi pollster\n\nwe deprecated this in kwapi and it's been dead for far longer.\n\nChange-Id: I790e36c7daefb07eefe68298f91c14211f9a8df0\n""}, {'number': 4, 'created': '2017-02-13 17:15:10.000000000', 'files': ['ceilometer/energy/__init__.py', 'ceilometer/tests/unit/energy/__init__.py', 'ceilometer/opts.py', 'releasenotes/notes/drop-kwapi-b687bc476186d01b.yaml', 'ceilometer/energy/kwapi.py', 'ceilometer/tests/unit/energy/test_kwapi.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/47ae182b4dbada1beb4e1b9017fad102d9549aec', 'message': ""drop kwapi pollster\n\nwe deprecated this in newton and it's been dead for far longer.\n\nChange-Id: I790e36c7daefb07eefe68298f91c14211f9a8df0\n""}]",2,432461,47ae182b4dbada1beb4e1b9017fad102d9549aec,20,7,4,6537,,,0,"drop kwapi pollster

we deprecated this in newton and it's been dead for far longer.

Change-Id: I790e36c7daefb07eefe68298f91c14211f9a8df0
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/61/432461/4 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/energy/__init__.py', 'ceilometer/tests/unit/energy/__init__.py', 'ceilometer/opts.py', 'ceilometer/energy/kwapi.py', 'ceilometer/tests/unit/energy/test_kwapi.py', 'setup.cfg']",6,53ce8a35558f9a3ab55b865a77af51b166628a9a,kwapi,, energy = ceilometer.energy.kwapi:EnergyPollster power = ceilometer.energy.kwapi:PowerPollster,1,265
openstack%2Fceilometer~master~I1cb1e4fdddfb9ec7dac321b9e70f688c575a7775,openstack/ceilometer,master,I1cb1e4fdddfb9ec7dac321b9e70f688c575a7775,cleanup devstack cache initialisation,MERGED,2017-02-09 22:32:21.000000000,2017-02-18 14:17:37.000000000,2017-02-18 14:17:37.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8290}, {'_account_id': 17848}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-09 22:32:21.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e44ff4da484ff88144ead52c4638cd4b449f471b', 'message': 'cleanup devstack cache initialisation\n\ndevstack has issues setting multiple value options. it does not\nknow how to replace properly and ends up just replacing everything.\njust delete all previous options if they exist to avoid unexpected\nresidual values.\n\nChange-Id: I1cb1e4fdddfb9ec7dac321b9e70f688c575a7775\n'}]",0,431762,e44ff4da484ff88144ead52c4638cd4b449f471b,10,5,1,6537,,,0,"cleanup devstack cache initialisation

devstack has issues setting multiple value options. it does not
know how to replace properly and ends up just replacing everything.
just delete all previous options if they exist to avoid unexpected
residual values.

Change-Id: I1cb1e4fdddfb9ec7dac321b9e70f688c575a7775
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/62/431762/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,e44ff4da484ff88144ead52c4638cd4b449f471b,devstack-clean, inidelete $CEILOMETER_CONF cache backend_argument iniadd $CEILOMETER_CONF cache backend_argument url:$CEILOMETER_CACHE_URL iniadd $CEILOMETER_CONF cache backend_argument distributed_lock:True iniadd $CEILOMETER_CONF cache backend_argument db:0 iniadd $CEILOMETER_CONF cache backend_argument redis_expiration_time:600, iniset $CEILOMETER_CONF cache backend_argument url:$CEILOMETER_CACHE_URL iniadd_literal $CEILOMETER_CONF cache backend_argument distributed_lock:True iniadd_literal $CEILOMETER_CONF cache backend_argument db:0 iniadd_literal $CEILOMETER_CONF cache backend_argument redis_expiration_time:600,6,4
openstack%2Fopenstack-manuals~master~I4ccd8edcf5cb1e5dc8a79e8f3d94358de3139f21,openstack/openstack-manuals,master,I4ccd8edcf5cb1e5dc8a79e8f3d94358de3139f21,[config-ref] update conf changes tables for Ocata,MERGED,2017-02-18 11:01:13.000000000,2017-02-18 14:12:36.000000000,2017-02-18 14:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-02-18 11:01:13.000000000', 'files': ['doc/config-reference/source/tables/conf-changes/murano.rst', 'doc/config-reference/source/tables/conf-changes/ironic.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/72f6c74cc1a09cdd88e5218c55e52ff69a5fc4d8', 'message': '[config-ref] update conf changes tables for Ocata\n\nChange-Id: I4ccd8edcf5cb1e5dc8a79e8f3d94358de3139f21\n'}]",0,435692,72f6c74cc1a09cdd88e5218c55e52ff69a5fc4d8,7,3,1,10497,,,0,"[config-ref] update conf changes tables for Ocata

Change-Id: I4ccd8edcf5cb1e5dc8a79e8f3d94358de3139f21
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/435692/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/tables/conf-changes/murano.rst', 'doc/config-reference/source/tables/conf-changes/ironic.rst']",2,72f6c74cc1a09cdd88e5218c55e52ff69a5fc4d8,config-reference,"New, updated, and deprecated options in Ocata for Bare Metal service ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * - ``[DEFAULT] default_boot_interface = None`` - (StrOpt) Default boot interface to be used for nodes that do not have boot_interface field set. A complete list of boot interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.boot"" entrypoint. * - ``[DEFAULT] default_console_interface = None`` - (StrOpt) Default console interface to be used for nodes that do not have console_interface field set. A complete list of console interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.console"" entrypoint. * - ``[DEFAULT] default_deploy_interface = None`` - (StrOpt) Default deploy interface to be used for nodes that do not have deploy_interface field set. A complete list of deploy interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.deploy"" entrypoint. * - ``[DEFAULT] default_inspect_interface = None`` - (StrOpt) Default inspect interface to be used for nodes that do not have inspect_interface field set. A complete list of inspect interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.inspect"" entrypoint. * - ``[DEFAULT] default_management_interface = None`` - (StrOpt) Default management interface to be used for nodes that do not have management_interface field set. A complete list of management interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.management"" entrypoint. * - ``[DEFAULT] default_portgroup_mode = active-backup`` - (StrOpt) Default mode for portgroups. Allowed values can be found in the linux kernel documentation on bonding: https://www.kernel.org/doc/Documentation/networking/bonding.txt. * - ``[DEFAULT] default_power_interface = None`` - (StrOpt) Default power interface to be used for nodes that do not have power_interface field set. A complete list of power interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.power"" entrypoint. * - ``[DEFAULT] default_raid_interface = None`` - (StrOpt) Default raid interface to be used for nodes that do not have raid_interface field set. A complete list of raid interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.raid"" entrypoint. * - ``[DEFAULT] default_storage_interface = None`` - (ListOpt) Default storage interface to be used for nodes that do not have storage_interface field set. A complete list of storage interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.storage"" entrypoint. * - ``[DEFAULT] default_vendor_interface = None`` - (StrOpt) Default vendor interface to be used for nodes that do not have vendor_interface field set. A complete list of vendor interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.vendor"" entrypoint. * - ``[DEFAULT] enabled_boot_interfaces = pxe`` - (ListOpt) Specify the list of boot interfaces to load during service initialization. Missing boot interfaces, or boot interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one boot interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented boot interfaces. A complete list of boot interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.boot"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled boot interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_console_interfaces = no-console`` - (ListOpt) Specify the list of console interfaces to load during service initialization. Missing console interfaces, or console interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one console interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented console interfaces. A complete list of console interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.console"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled console interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_deploy_interfaces = iscsi, direct`` - (ListOpt) Specify the list of deploy interfaces to load during service initialization. Missing deploy interfaces, or deploy interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one deploy interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented deploy interfaces. A complete list of deploy interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.deploy"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled deploy interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_hardware_types = ipmi`` - (ListOpt) Specify the list of hardware types to load during service initialization. Missing hardware types, or hardware types which fail to initialize, will prevent the conductor service from starting. This option defaults to a recommended set of production-oriented hardware types. A complete list of hardware types present on your system may be found by enumerating the ""ironic.hardware.types"" entrypoint. * - ``[DEFAULT] enabled_inspect_interfaces = no-inspect`` - (ListOpt) Specify the list of inspect interfaces to load during service initialization. Missing inspect interfaces, or inspect interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one inspect interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented inspect interfaces. A complete list of inspect interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.inspect"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled inspect interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_management_interfaces = ipmitool`` - (ListOpt) Specify the list of management interfaces to load during service initialization. Missing management interfaces, or management interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one management interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented management interfaces. A complete list of management interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.management"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled management interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_power_interfaces = ipmitool`` - (ListOpt) Specify the list of power interfaces to load during service initialization. Missing power interfaces, or power interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one power interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented power interfaces. A complete list of power interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.power"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled power interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_raid_interfaces = agent, no-raid`` - (ListOpt) Specify the list of raid interfaces to load during service initialization. Missing raid interfaces, or raid interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one raid interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented raid interfaces. A complete list of raid interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.raid"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled raid interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_storage_interfaces = noop`` - (ListOpt) Specify the list of storage interfaces to load during service initialization. Missing storage interfaces, or storage interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one storage interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented storage interfaces. A complete list of storage interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.storage"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled storage interfaces on every ironic-conductor service. * - ``[DEFAULT] enabled_vendor_interfaces = no-vendor`` - (ListOpt) Specify the list of vendor interfaces to load during service initialization. Missing vendor interfaces, or vendor interfaces which fail to initialize, will prevent the ironic-conductor service from starting. At least one vendor interface that is supported by each enabled hardware type must be enabled here, or the ironic-conductor service will not start. Must not be an empty list. The default value is a recommended set of production-oriented vendor interfaces. A complete list of vendor interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.vendor"" entrypoint. When setting this value, please make sure that every enabled hardware type will have the same set of enabled vendor interfaces on every ironic-conductor service. * - ``[conductor] send_sensor_data_wait_timeout = 300`` - (IntOpt) The time in seconds to wait for send sensors data periodic task to be finished before allowing periodic call to happen again. Should be less than send_sensor_data_interval value. * - ``[conductor] send_sensor_data_workers = 4`` - (IntOpt) The maximum number of workers that can be started simultaneously for send data from sensors periodic task. * - ``[conductor] soft_power_off_timeout = 600`` - (IntOpt) Timeout (in seconds) of soft reboot and soft power off operation. This value always has to be positive. * - ``[deploy] default_boot_option = None`` - (StrOpt) Default boot option to use when no boot option is requested in node's driver_info. Currently the default is ""netboot"", but it will be changed to ""local"" in the future. It is recommended to set an explicit value for this option. * - ``[glance] glance_api_version = 2`` - (IntOpt) Glance API version (1 or 2) to use. * - ``[irmc] snmp_polling_interval = 10`` - (IntOpt) SNMP polling interval in seconds * - ``[neutron] cleaning_network = None`` - (StrOpt) Neutron network UUID or name for the ramdisk to be booted into for cleaning nodes. Required for ""neutron"" network interface. It is also required if cleaning nodes when using ""flat"" network interface or ""neutron"" DHCP provider. If a name is provided, it must be unique among all networks or cleaning will fail. * - ``[neutron] cleaning_network_security_groups =`` - (ListOpt) List of Neutron Security Group UUIDs to be applied during cleaning of the nodes. Optional for the ""neutron"" network interface and not used for the ""flat"" or ""noop"" network interfaces. If not specified, default security group is used. * - ``[neutron] provisioning_network = None`` - (StrOpt) Neutron network UUID or name for the ramdisk to be booted into for provisioning nodes. Required for ""neutron"" network interface. If a name is provided, it must be unique among all networks or deploy will fail. * - ``[neutron] provisioning_network_security_groups =`` - (ListOpt) List of Neutron Security Group UUIDs to be applied during provisioning of the nodes. Optional for the ""neutron"" network interface and not used for the ""flat"" or ""noop"" network interfaces. If not specified, default security group is used. * - ``[pxe] pxe_bootfile_name_by_arch = {}`` - (DictOpt) Bootfile DHCP parameter per node architecture. For example: aarch64:grubaa64.efi * - ``[pxe] pxe_config_template_by_arch = {}`` - (DictOpt) On ironic-conductor node, template file for PXE configuration per node architecture. For example: aarch64:/opt/share/grubaa64_pxe_config.template * - ``[audit] audit_map_file`` - ``/etc/ironic/ironic_api_audit_map.conf`` - ``/etc/ironic/api_audit_map.conf`` * - ``[audit] ignore_req_list`` - * - ``[DEFAULT] rpc_thread_pool_size`` - ``[DEFAULT] executor_thread_pool_size`` - ``[swift] cafile`` * - ``[keystone_authtoken] cafile``","New, updated, and deprecated options in Newton for Bare Metal service ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ * - ``[DEFAULT] default_network_interface = None`` - (StrOpt) Default network interface to be used for nodes that do not have network_interface field set. A complete list of network interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.network"" entrypoint. * - ``[DEFAULT] enabled_network_interfaces = flat, noop`` - (ListOpt) Specify the list of network interfaces to load during service initialization. Missing network interfaces, or network interfaces which fail to initialize, will prevent the conductor service from starting. The option default is a recommended set of production-oriented network interfaces. A complete list of network interfaces present on your system may be found by enumerating the ""ironic.hardware.interfaces.network"" entrypoint. This value must be the same on all ironic-conductor and ironic-api services, because it is used by ironic-api service to validate a new or updated node's network_interface value. * - ``[DEFAULT] notification_level = None`` - (StrOpt) Specifies the minimum level for which to send notifications. If not set, no notifications will be sent. The default is for this option to be unset. * - ``[agent] deploy_logs_collect = on_failure`` - (StrOpt) Whether Ironic should collect the deployment logs on deployment failure (on_failure), always or never. * - ``[agent] deploy_logs_local_path = /var/log/ironic/deploy`` - (StrOpt) The path to the directory where the logs should be stored, used when the deploy_logs_storage_backend is configured to ""local"". * - ``[agent] deploy_logs_storage_backend = local`` - (StrOpt) The name of the storage backend where the logs will be stored. * - ``[agent] deploy_logs_swift_container = ironic_deploy_logs_container`` - (StrOpt) The name of the Swift container to store the logs, used when the deploy_logs_storage_backend is configured to ""swift"". * - ``[agent] deploy_logs_swift_days_to_expire = 30`` - (IntOpt) Number of days before a log object is marked as expired in Swift. If None, the logs will be kept forever or until manually deleted. Used when the deploy_logs_storage_backend is configured to ""swift"". * - ``[api] ramdisk_heartbeat_timeout = 300`` - (IntOpt) Maximum interval (in seconds) for agent heartbeats. * - ``[api] restrict_lookup = True`` - (BoolOpt) Whether to restrict the lookup API to only nodes in certain states. * - ``[audit] audit_map_file = /etc/ironic/ironic_api_audit_map.conf`` - (StrOpt) Path to audit map file for ironic-api service. Used only when API audit is enabled. * - ``[audit] enabled = False`` - (BoolOpt) Enable auditing of API requests (for ironic-api service). * - ``[audit] ignore_req_list = None`` - (StrOpt) Comma separated list of Ironic REST API HTTP methods to be ignored during audit. For example: auditing will not be done on any GET or POST requests if this is set to ""GET,POST"". It is used only when API audit is enabled. * - ``[audit] namespace = openstack`` - (StrOpt) namespace prefix for generated id * - ``[audit_middleware_notifications] driver = None`` - (StrOpt) The Driver to handle sending notifications. Possible values are messaging, messagingv2, routing, log, test, noop. If not specified, then value from oslo_messaging_notifications conf section is used. * - ``[audit_middleware_notifications] topics = None`` - (ListOpt) List of AMQP topics used for OpenStack notifications. If not specified, then value from oslo_messaging_notifications conf section is used. * - ``[audit_middleware_notifications] transport_url = None`` - (StrOpt) A URL representing messaging driver to use for notification. If not specified, we fall back to the same configuration used for RPC. * - ``[deploy] continue_if_disk_secure_erase_fails = False`` - (BoolOpt) Defines what to do if an ATA secure erase operation fails during cleaning in the Ironic Python Agent. If False, the cleaning operation will fail and the node will be put in ``clean failed`` state. If True, shred will be invoked and cleaning will continue. * - ``[deploy] erase_devices_metadata_priority = None`` - (IntOpt) Priority to run in-band clean step that erases metadata from devices, via the Ironic Python Agent ramdisk. If unset, will use the priority set in the ramdisk (defaults to 99 for the GenericHardwareManager). If set to 0, will not run during cleaning. * - ``[deploy] power_off_after_deploy_failure = True`` - (BoolOpt) Whether to power off a node after deploy failure. Defaults to True. * - ``[deploy] shred_final_overwrite_with_zeros = True`` - (BoolOpt) Whether to write zeros to a node's block devices after writing random data. This will write zeros to the device even when deploy.shred_random_overwrite_iterations is 0. This option is only used if a device could not be ATA Secure Erased. Defaults to True. * - ``[deploy] shred_random_overwrite_iterations = 1`` - (IntOpt) During shred, overwrite all block devices N times with random data. This is only used if a device could not be ATA Secure Erased. Defaults to 1. * - ``[drac] query_raid_config_job_status_interval = 120`` - (IntOpt) Interval (in seconds) between periodic RAID job status checks to determine whether the asynchronous RAID configuration was successfully finished or not. * - ``[glance] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[glance] auth_type = None`` - (Opt) Authentication type to load * - ``[glance] cafile = None`` - (StrOpt) PEM encoded Certificate Authority to use when verifying HTTPs connections. * - ``[glance] certfile = None`` - (StrOpt) PEM encoded client certificate cert file * - ``[glance] insecure = False`` - (BoolOpt) Verify HTTPS connections. * - ``[glance] keyfile = None`` - (StrOpt) PEM encoded client certificate key file * - ``[glance] timeout = None`` - (IntOpt) Timeout value for http requests * - ``[ilo] ca_file = None`` - (StrOpt) CA certificate file to validate iLO. * - ``[ilo] default_boot_mode = auto`` - (StrOpt) Default boot mode to be used in provisioning when ""boot_mode"" capability is not provided in the ""properties/capabilities"" of the node. The default is ""auto"" for backward compatibility. When ""auto"" is specified, default boot mode will be selected based on boot mode settings on the system. * - ``[inspector] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[inspector] auth_type = None`` - (Opt) Authentication type to load * - ``[inspector] cafile = None`` - (StrOpt) PEM encoded Certificate Authority to use when verifying HTTPs connections. * - ``[inspector] certfile = None`` - (StrOpt) PEM encoded client certificate cert file * - ``[inspector] insecure = False`` - (BoolOpt) Verify HTTPS connections. * - ``[inspector] keyfile = None`` - (StrOpt) PEM encoded client certificate key file * - ``[inspector] timeout = None`` - (IntOpt) Timeout value for http requests * - ``[iscsi] portal_port = 3260`` - (PortOpt) The port number on which the iSCSI portal listens for incoming connections. * - ``[metrics] agent_backend = noop`` - (StrOpt) Backend for the agent ramdisk to use for metrics. Default possible backends are ""noop"" and ""statsd"". * - ``[metrics] agent_global_prefix = None`` - (StrOpt) Prefix all metric names sent by the agent ramdisk with this value. The format of metric names is [global_prefix.][uuid.][host_name.]prefix.metric_name. * - ``[metrics] agent_prepend_host = False`` - (BoolOpt) Prepend the hostname to all metric names sent by the agent ramdisk. The format of metric names is [global_prefix.][uuid.][host_name.]prefix.metric_name. * - ``[metrics] agent_prepend_host_reverse = True`` - (BoolOpt) Split the prepended host value by ""."" and reverse it for metrics sent by the agent ramdisk (to better match the reverse hierarchical form of domain names). * - ``[metrics] agent_prepend_uuid = False`` - (BoolOpt) Prepend the node's Ironic uuid to all metric names sent by the agent ramdisk. The format of metric names is [global_prefix.][uuid.][host_name.]prefix.metric_name. * - ``[metrics] backend = noop`` - (StrOpt) Backend to use for the metrics system. * - ``[metrics] global_prefix = None`` - (StrOpt) Prefix all metric names with this value. By default, there is no global prefix. The format of metric names is [global_prefix.][host_name.]prefix.metric_name. * - ``[metrics] prepend_host = False`` - (BoolOpt) Prepend the hostname to all metric names. The format of metric names is [global_prefix.][host_name.]prefix.metric_name. * - ``[metrics] prepend_host_reverse = True`` - (BoolOpt) Split the prepended host value by ""."" and reverse it (to better match the reverse hierarchical form of domain names). * - ``[metrics_statsd] agent_statsd_host = localhost`` - (StrOpt) Host for the agent ramdisk to use with the statsd backend. This must be accessible from networks the agent is booted on. * - ``[metrics_statsd] agent_statsd_port = 8125`` - (PortOpt) Port for the agent ramdisk to use with the statsd backend. * - ``[metrics_statsd] statsd_host = localhost`` - (StrOpt) Host for use with the statsd backend. * - ``[metrics_statsd] statsd_port = 8125`` - (PortOpt) Port to use with the statsd backend. * - ``[neutron] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[neutron] auth_type = None`` - (Opt) Authentication type to load * - ``[neutron] cafile = None`` - (StrOpt) PEM encoded Certificate Authority to use when verifying HTTPs connections. * - ``[neutron] certfile = None`` - (StrOpt) PEM encoded client certificate cert file * - ``[neutron] insecure = False`` - (BoolOpt) Verify HTTPS connections. * - ``[neutron] keyfile = None`` - (StrOpt) PEM encoded client certificate key file * - ``[neutron] port_setup_delay = 0`` - (IntOpt) Delay value to wait for Neutron agents to setup sufficient DHCP configuration for port. * - ``[neutron] provisioning_network_uuid = None`` - (StrOpt) Neutron network UUID for the ramdisk to be booted into for provisioning nodes. Required for ""neutron"" network interface. * - ``[neutron] timeout = None`` - (IntOpt) Timeout value for http requests * - ``[oneview] enable_periodic_tasks = True`` - (BoolOpt) Whether to enable the periodic tasks for OneView driver be aware when OneView hardware resources are taken and released by Ironic or OneView users and proactively manage nodes in clean fail state according to Dynamic Allocation model of hardware resources allocation in OneView. * - ``[oneview] periodic_check_interval = 300`` - (IntOpt) Period (in seconds) for periodic tasks to be executed when enable_periodic_tasks=True. * - ``[pxe] ipxe_use_swift = False`` - (BoolOpt) Download deploy images directly from swift using temporary URLs. If set to false (default), images are downloaded to the ironic-conductor node and served over its local HTTP server. Applicable only when 'ipxe_enabled' option is set to true. * - ``[service_catalog] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[service_catalog] auth_type = None`` - (Opt) Authentication type to load * - ``[service_catalog] cafile = None`` - (StrOpt) PEM encoded Certificate Authority to use when verifying HTTPs connections. * - ``[service_catalog] certfile = None`` - (StrOpt) PEM encoded client certificate cert file * - ``[service_catalog] insecure = False`` - (BoolOpt) Verify HTTPS connections. * - ``[service_catalog] keyfile = None`` - (StrOpt) PEM encoded client certificate key file * - ``[service_catalog] timeout = None`` - (IntOpt) Timeout value for http requests * - ``[swift] auth_section = None`` - (Opt) Config Section from which to load plugin specific options * - ``[swift] auth_type = None`` - (Opt) Authentication type to load * - ``[swift] cafile = None`` - (StrOpt) PEM encoded Certificate Authority to use when verifying HTTPs connections. * - ``[swift] certfile = None`` - (StrOpt) PEM encoded client certificate cert file * - ``[swift] insecure = False`` - (BoolOpt) Verify HTTPS connections. * - ``[swift] keyfile = None`` - (StrOpt) PEM encoded client certificate key file * - ``[swift] timeout = None`` - (IntOpt) Timeout value for http requests * - ``[DEFAULT] my_ip`` - ``10.0.0.1`` - ``127.0.0.1`` * - ``[neutron] url`` - ``http://$my_ip:9696`` * - ``[pxe] uefi_pxe_bootfile_name`` - ``elilo.efi`` - ``bootx64.efi`` * - ``[pxe] uefi_pxe_config_template`` - ``$pybasedir/drivers/modules/elilo_efi_pxe_config.template`` - ``$pybasedir/drivers/modules/pxe_grub_config.template`` * - ``[agent] heartbeat_timeout`` - ``[api] ramdisk_heartbeat_timeout`` * - ``[deploy] erase_devices_iterations`` - ``[deploy] shred_random_overwrite_iterations`` - ``[swift] cafile`` * - ``[keystone_authtoken] cafile``",91,189
openstack%2Fopenstack-manuals~master~Ic5e905821381ae5f1286ba310f36a28740599250,openstack/openstack-manuals,master,Ic5e905821381ae5f1286ba310f36a28740599250,[config-ref] update murano config options for Ocata,MERGED,2017-02-18 13:04:53.000000000,2017-02-18 14:12:26.000000000,2017-02-18 14:12:26.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-18 13:04:53.000000000', 'files': ['doc/config-reference/source/application-catalog/config-options.rst', 'doc/config-reference/source/tables/murano-redis.rst', 'tools/autogenerate-config-flagmappings/murano.headers', 'doc/config-reference/source/tables/murano-common.rst', 'doc/config-reference/source/tables/murano-glance.rst', 'tools/autogenerate-config-flagmappings/murano.flagmappings', 'doc/config-reference/source/tables/murano-api.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/39075e7eb0668bdf303bf831b8544b68a8e80620', 'message': '[config-ref] update murano config options for Ocata\n\nChange-Id: Ic5e905821381ae5f1286ba310f36a28740599250\n'}]",0,435704,39075e7eb0668bdf303bf831b8544b68a8e80620,6,2,1,10497,,,0,"[config-ref] update murano config options for Ocata

Change-Id: Ic5e905821381ae5f1286ba310f36a28740599250
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/04/435704/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-reference/source/application-catalog/config-options.rst', 'doc/config-reference/source/tables/murano-redis.rst', 'tools/autogenerate-config-flagmappings/murano.headers', 'doc/config-reference/source/tables/murano-common.rst', 'doc/config-reference/source/tables/murano-glance.rst', 'tools/autogenerate-config-flagmappings/murano.flagmappings', 'doc/config-reference/source/tables/murano-api.rst']",7,39075e7eb0668bdf303bf831b8544b68a8e80620,, - (String) The file that defines policies., - (String) The JSON file that defines policies.,108,6
openstack%2Fceilometer~master~I25a6e0b9221844adb4412f1829d9e290b6e198a3,openstack/ceilometer,master,I25a6e0b9221844adb4412f1829d9e290b6e198a3,Deprecate collector,MERGED,2016-12-22 06:14:04.000000000,2017-02-18 13:58:01.000000000,2017-02-18 13:58:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 15843}, {'_account_id': 22752}]","[{'number': 1, 'created': '2016-12-22 06:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d4f309174f40051e1296a999ce7cdad4bb6c7275', 'message': 'Remove collector\n\nTo optimise performance, We have to udpate ceilometer architecture. The\nmost important step is to deprecate collector. From now on, we can configure\nmultiple publishers in pipline for pushing data to internal or external system.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 2, 'created': '2016-12-22 06:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e40aabd41d316d46f95bcdbb310cb34d9dc9ebc3', 'message': 'Remove collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipline for pushing data to\ninternal or external system.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 3, 'created': '2017-01-18 09:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8f68fd2c50218ed8c29eb798cb98645b57ae1717', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipline for pushing data to\ninternal or external system.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 4, 'created': '2017-01-18 14:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d6b4111e25e5bc7a0c6e21200bc1f9b07abc7de3', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nFix a typo in manual document.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 5, 'created': '2017-01-18 16:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e0ed581fb14de958f6dcb8be605b6ba803a98c84', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nFix an inappropiate usage in manual document.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 6, 'created': '2017-01-20 11:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8bf2cd546d8c14f59741a6e91d98a64bfb658fd3', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nFix an inappropiate usage in manual document.\n\nChange pipeline default publisher.\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 7, 'created': '2017-01-20 13:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/70d4400bc153a57568ab88e42749227b6aca4fce', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nFix an inappropiate word in manual document.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 8, 'created': '2017-01-20 14:00:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/92db2df627e7c15f0a3428918deca708eb3dfdd6', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nFix an inappropiate word in manual document.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 9, 'created': '2017-01-21 07:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b72094073f80495c90ebfde888871e4dfc77974b', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 10, 'created': '2017-01-21 14:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/628c022644c1e37ed8930e6a211798f8f76de753', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 11, 'created': '2017-01-21 15:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f8bee2c29f4ae973c48cfd81f4550d7c77c64bbb', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 12, 'created': '2017-01-22 00:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/43897c3798db41cbec8669d3d9faa6ed8e4b701c', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 13, 'created': '2017-01-22 03:37:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/18d9d97f7155f9ce070364c1309912efb593368f', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 14, 'created': '2017-01-22 04:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4bbe5b9ce6299aa8b510eab724d2d010aa5ab69d', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 15, 'created': '2017-02-08 08:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1a118346ff9c75a1848065f61d0f730ef7df44b7', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 16, 'created': '2017-02-08 08:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3f7d9470c2e5e202932fee609746ad12c7b9be06', 'message': 'WIP Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 17, 'created': '2017-02-08 15:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cf9a4c9fcca0f3a0f19cb15c76866bb49edb2dd0', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 18, 'created': '2017-02-08 18:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/25eb37f94ffeabd1537f2ecbea51c1be0a1865e6', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 19, 'created': '2017-02-08 19:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a996ebabf619a86e746cf04a0d8d5086e4a7bf3c', 'message': 'Deprecate collector\n\nTo optimise performance, We have to udpate ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default\n\nCo-Authored-By: gordon chung <gord@live.ca>\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}, {'number': 20, 'created': '2017-02-09 02:25:54.000000000', 'files': ['ceilometer/collector.py', 'doc/source/install/custom.rst', 'doc/source/install/manual.rst', 'etc/ceilometer/pipeline.yaml', 'doc/source/configuration.rst', 'etc/ceilometer/event_pipeline.yaml', 'devstack/plugin.sh', 'releasenotes/notes/deprecate-ceilometer-collector-b793b91cd28b9e7f.yaml', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/11191a4612e424c02a5d90a1337141c26f79c098', 'message': 'Deprecate collector\n\nTo optimise performance, We have to update ceilometer architecture.\nThe most important step is to deprecate collector. From now on, we\ncan configure multiple publishers in pipeline for pushing data to\ninternal or external system.\n\nHighlight using multiple dispatchers.\n\nChange pipeline publisher and disable ceilometer-collector by default.\n\nCo-Authored-By: gordon chung <gord@live.ca>\nChange-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3\n'}]",36,413920,11191a4612e424c02a5d90a1337141c26f79c098,115,6,20,22752,,,0,"Deprecate collector

To optimise performance, We have to update ceilometer architecture.
The most important step is to deprecate collector. From now on, we
can configure multiple publishers in pipeline for pushing data to
internal or external system.

Highlight using multiple dispatchers.

Change pipeline publisher and disable ceilometer-collector by default.

Co-Authored-By: gordon chung <gord@live.ca>
Change-Id: I25a6e0b9221844adb4412f1829d9e290b6e198a3
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/20/413920/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/cmd/collector.py', 'ceilometer/tests/functional/test_collector.py', 'ceilometer/publisher/udp.py', 'ceilometer/opts.py', 'ceilometer/tests/unit/publisher/test_udp.py', 'ceilometer/tests/unit/test_collector.py', 'setup.cfg']",7,d4f309174f40051e1296a999ce7cdad4bb6c7275,lhx/deprecate-collector,, ceilometer-collector = ceilometer.cmd.collector:main,2,339
openstack%2Faodh~master~Ic9f97f47a1cc9af91048dc98e4b6b1cc23933726,openstack/aodh,master,Ic9f97f47a1cc9af91048dc98e4b6b1cc23933726,gabbi: use history,MERGED,2017-02-09 17:23:24.000000000,2017-02-18 13:36:23.000000000,2017-02-18 13:36:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8290}]","[{'number': 1, 'created': '2017-02-09 17:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/947501081eaad41951b0ca7bae33d2a1ecadb358', 'message': ""gabbi: use history\n\ngabbi supports grabbing historical queries. leverage that so we\ndon't need to make redundant requests to grab same data.\n\nChange-Id: Ic9f97f47a1cc9af91048dc98e4b6b1cc23933726\n""}, {'number': 2, 'created': '2017-02-09 17:24:18.000000000', 'files': ['aodh/tests/functional/gabbi/gabbits-live/alarms.yaml', 'aodh/tests/functional/gabbi/gabbits/alarms.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/aodh/commit/687205ecebdb316c349c7db8087c06f8b2fd2436', 'message': ""gabbi: use history\n\ngabbi supports grabbing historical queries. leverage that so we\ndon't need to make redundant requests to grab same data.\n\nChange-Id: Ic9f97f47a1cc9af91048dc98e4b6b1cc23933726\n""}]",0,431650,687205ecebdb316c349c7db8087c06f8b2fd2436,8,3,2,6537,,,0,"gabbi: use history

gabbi supports grabbing historical queries. leverage that so we
don't need to make redundant requests to grab same data.

Change-Id: Ic9f97f47a1cc9af91048dc98e4b6b1cc23933726
",git fetch https://review.opendev.org/openstack/aodh refs/changes/50/431650/2 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/tests/functional/gabbi/gabbits-live/alarms.yaml', 'aodh/tests/functional/gabbi/gabbits/alarms.yaml']",2,947501081eaad41951b0ca7bae33d2a1ecadb358,,- name: list alarms DELETE: /v2/alarms/$HISTORY['list alarms'].$RESPONSE['$[0].alarm_id'],"- name: list alarms for data- name: list alarms one desc: Lists alarms, only one GET: /v2/alarms response_json_paths: $[0].name: added_alarm_defaults DELETE: /v2/alarms/$RESPONSE['$[0].alarm_id']",4,16
openstack%2Fpython-aodhclient~master~I2cad2629dc14e5842e7f2edc1ea08a36e8d0c35d,openstack/python-aodhclient,master,I2cad2629dc14e5842e7f2edc1ea08a36e8d0c35d,Trivial-fix: make the capabilities help message more specific in OSC,MERGED,2017-02-14 01:44:55.000000000,2017-02-18 13:33:22.000000000,2017-02-18 13:33:22.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-14 01:44:55.000000000', 'files': ['aodhclient/v2/capabilities_cli.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/929103779ac6316b05bcc5f6ccc8b3f638dcb977', 'message': 'Trivial-fix: make the capabilities help message more specific in OSC\n\nThis change make the capabilities message more specific in OpenStackclient\nCLI.\n\nChange-Id: I2cad2629dc14e5842e7f2edc1ea08a36e8d0c35d\n'}]",0,433385,929103779ac6316b05bcc5f6ccc8b3f638dcb977,7,3,1,8290,,,0,"Trivial-fix: make the capabilities help message more specific in OSC

This change make the capabilities message more specific in OpenStackclient
CLI.

Change-Id: I2cad2629dc14e5842e7f2edc1ea08a36e8d0c35d
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/85/433385/1 && git format-patch -1 --stdout FETCH_HEAD,['aodhclient/v2/capabilities_cli.py'],1,929103779ac6316b05bcc5f6ccc8b3f638dcb977,help-msg," """"""List capabilities of alarming service"""""""," """"""List capabilities""""""",1,1
openstack%2Fgnocchi~stable%2F2.1~I06989336f90ae74f38a23276eda4ed688b5a51bd,openstack/gnocchi,stable/2.1,I06989336f90ae74f38a23276eda4ed688b5a51bd,block oslo.db 4.13.2,ABANDONED,2016-09-08 15:27:42.000000000,2017-02-18 13:30:51.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 22752}]","[{'number': 1, 'created': '2016-09-08 15:27:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/bf03896df363c725d475c0529b0f6d47bcdc8dcf', 'message': ""block oslo.db 4.13.2\n\nit's broken.\n\nChange-Id: I06989336f90ae74f38a23276eda4ed688b5a51bd\nPartial-Bug: #1620848\n(cherry picked from commit b2d64d26acd0f525ef45721f3a07b269eec48e3d)\n""}]",0,367463,bf03896df363c725d475c0529b0f6d47bcdc8dcf,6,4,1,1669,,,0,"block oslo.db 4.13.2

it's broken.

Change-Id: I06989336f90ae74f38a23276eda4ed688b5a51bd
Partial-Bug: #1620848
(cherry picked from commit b2d64d26acd0f525ef45721f3a07b269eec48e3d)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/63/367463/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,bf03896df363c725d475c0529b0f6d47bcdc8dcf,bug/1620848," oslo.db>=1.8.0,!=4.13.1,!=4.13.2 oslo.db>=1.8.0,!=4.13.1,!=4.13.2"," oslo.db>=1.8.0,!=4.13.1 oslo.db>=1.8.0,!=4.13.1",2,2
openstack%2Fgnocchi~stable%2F2.1~I679a958e7b95f594118c2061fa19469ba6ef59dd,openstack/gnocchi,stable/2.1,I679a958e7b95f594118c2061fa19469ba6ef59dd,Pin oslo.db<=4.13.0,ABANDONED,2016-09-08 15:27:42.000000000,2017-02-18 13:30:47.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8064}]","[{'number': 1, 'created': '2016-09-08 15:27:42.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/fdb8d7e59921dde11d4682f3d8da5ce1e3247604', 'message': 'Pin oslo.db<=4.13.0\n\noslo.db==4.13.1 introduced some changes causing the tests to fail\n\nFile ""/xxx/lib/python2.7/site-packages/oslo_db/sqlalchemy/utils.py"",\n line 77, in _get_unique_keys\n    info = model.__table__.info\nAttributeError: type object \'Result\' has no attribute \'__table__\'\n\nSeems to be introduced in:\nhttps://github.com/openstack/oslo.db/blame/4.13.1/oslo_db/sqlalchemy/utils.py#L77\n\nChange-Id: I679a958e7b95f594118c2061fa19469ba6ef59dd\n(cherry picked from commit c062916a81af2961a1fbebda82ac8bef88ba62cc)\n'}]",0,367462,fdb8d7e59921dde11d4682f3d8da5ce1e3247604,12,4,1,1669,,,0,"Pin oslo.db<=4.13.0

oslo.db==4.13.1 introduced some changes causing the tests to fail

File ""/xxx/lib/python2.7/site-packages/oslo_db/sqlalchemy/utils.py"",
 line 77, in _get_unique_keys
    info = model.__table__.info
AttributeError: type object 'Result' has no attribute '__table__'

Seems to be introduced in:
https://github.com/openstack/oslo.db/blame/4.13.1/oslo_db/sqlalchemy/utils.py#L77

Change-Id: I679a958e7b95f594118c2061fa19469ba6ef59dd
(cherry picked from commit c062916a81af2961a1fbebda82ac8bef88ba62cc)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/62/367462/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fdb8d7e59921dde11d4682f3d8da5ce1e3247604,bug/1620848," oslo.db>=1.8.0,!=4.13.1 oslo.db>=1.8.0,!=4.13.1", oslo.db>=1.8.0 oslo.db>=1.8.0,2,2
openstack%2Fgnocchi~master~I56291d04d7db5ff7fda547ad817c3dace0a5889e,openstack/gnocchi,master,I56291d04d7db5ff7fda547ad817c3dace0a5889e,tests: make gabbi test no rely on legacy resources types,MERGED,2017-02-03 13:50:49.000000000,2017-02-18 13:29:33.000000000,2017-02-18 13:29:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 11564}]","[{'number': 1, 'created': '2017-02-03 13:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/01aff81dd83a4431b0a5d195200b8c7a861be862', 'message': 'tests: make gabbi test no rely on legacy resources types\n\nChange-Id: I56291d04d7db5ff7fda547ad817c3dace0a5889e\n'}, {'number': 2, 'created': '2017-02-11 21:33:13.000000000', 'files': ['gnocchi/tests/functional/gabbits/resource.yaml', 'gnocchi/tests/functional/fixtures.py', 'gnocchi/tests/functional/gabbits/resource-type.yaml'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8a51f1f4e833aada36487250d27d33e2eb2744cf', 'message': 'tests: make gabbi test no rely on legacy resources types\n\nChange-Id: I56291d04d7db5ff7fda547ad817c3dace0a5889e\n'}]",0,428733,8a51f1f4e833aada36487250d27d33e2eb2744cf,10,3,2,1669,,,0,"tests: make gabbi test no rely on legacy resources types

Change-Id: I56291d04d7db5ff7fda547ad817c3dace0a5889e
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/33/428733/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/gabbi/fixtures.py', 'gnocchi/tests/gabbi/gabbits/resource-type.yaml', 'gnocchi/tests/gabbi/gabbits/resource.yaml']",3,01aff81dd83a4431b0a5d195200b8c7a861be862,jd/remove-ceilometer-legacy-resources," $.generic: $SCHEME://$NETLOC/v1/resource/generic - name: generic resource list desc: there are no generic resources yet GET: /v1/resource/generic - name: generic resource bad accept - name: generic resource complex accept# Create a new generic resource, demonstrate that including no data - name: post generic resource no data POST: /v1/resource/generic - name: post generic with invalid metric name - name: post generic resource to modify# PATCH that generic resource to change its attributes and to - name: patch generic resource user_id: foobar user_id: foobar - name: patch generic resource with same data PATCH: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9 user_id: foobar user_id: foobar - name: patch generic resource with id - name: patch generic with metrics - name: get generic history GET: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9/history?sort=revision_end:asc-nullslast - name: patch generic bad metric association PATCH: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9 - name: patch generic with bad archive policy - name: patch generic with no archive policy rule - name: patch generic with archive policy rule user_id: foobar user_id: foobar - name: patch generic with invalid metric name - name: post generic history POST: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9/history - name: delete generic history PATCH: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9 PATCH: /v1/resource/generic/77777777-CC60-4033-804E-2D3098C7D2E9 GET: /v1/resource/generic/noexist GET: /v1/resource/generic/77777777-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util - name: list generic resources no auth GET: /v1/resource/generic - name: list generic resources $[0].user_id: 0fbb231484614b1a80131fc22f6afc9c $[-1].user_id: foobar - name: post new generic with non-existent metrics POST: /v1/resource/generic - name: post new generic with metrics bad policy - name: post new generic with metrics no policy rule - name: post new generic with metrics using policy rule - name: post new generic with metrics - name: post new generic with metrics and un-normalized user/project id from keystone middleware GET: /v1/resource/generic/$RESPONSE['$.id']/metric/cpu.util/measures - name: list the generics GET: /v1/resource/generic - name: request metrics from one of the generics GET: /v1/resource/generic/$RESPONSE['$[-1].id']/metric GET: /v1/resource/generic/not.a.uuid/metric - name: request cpuutil metric from generic GET: /v1/resource/generic/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util - name: try post cpuutil metric to generic - name: request cpuutil measures from generic GET: /v1/resource/generic/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util/measures - name: post metric at generic POST: /v1/resource/generic/85C44741-CC60-4033-804E-2D3098C7D2E9/metric - name: post metric at generic with empty definition - name: post metric at generic using archive policy rule - name: duplicate metrics at generic - name: post metrics at generic bad policy - name: post new generic with bad timestamp POST: /v1/resource/generic POST: /v1/resource/generic/not.a.uuid/metric POST: /v1/resource/generic/d5a5994e-ee90-11e4-88cf-685b35afa334/metric POST: /v1/resource/generic/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/unknown/measures# DELETE-ing generics - name: delete generic DELETE: /v1/resource/generic/75C44741-CC60-4033-804E-2D3098C7D2E9 - name: delete noexist generic DELETE: /v1/resource/generic/77777777-CC60-4033-804E-2D3098C7D2E9"," $.volume: $SCHEME://$NETLOC/v1/resource/volume - name: instance resource desc: there are no instance resources yet GET: /v1/resource/instance - name: instance resource bad accept - name: instance resource complex accept# Create a new instance resource, demonstrate that including no data - name: post instance resource no data POST: /v1/resource/instance - name: post instance resource with missing data POST: $LAST_URL request_headers: x-user-id: 0fbb231484614b1a80131fc22f6afc9c x-project-id: f3d41b770cc14f0bb94a1d5be9c0e3ea content-type: application/json data: id: 75C44741-CC60-4033-804E-2D3098C7D2E9 user_id: 0fbb231484614b1a80131fc22f6afc9c project_id: f3d41b770cc14f0bb94a1d5be9c0e3ea flavor_id: ""2"" image_ref: http://image host: compute1 status: 400 response_strings: - ""Invalid input: required key not provided @ data["" - ""'display_name']"" - name: post instance with invalid metric name - name: post instance resource flavor_id: ""2"" image_ref: http://image host: compute1 display_name: myvm# PATCH that instance resource to change its attributes and to - name: patch instance resource host: compute2 host: compute2 - name: patch instance resource with same data PATCH: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9 host: compute2 host: compute2 - name: patch instance resource with id - name: patch instance with metrics - name: get instance history GET: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9/history?sort=revision_end:asc-nullslast $[0].host: compute1 $[1].host: compute2 - name: patch instance bad metric association PATCH: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9 - name: patch instance with bad archive policy - name: patch instance with no archive policy rule - name: patch instance with archive policy rule host: compute2 host: compute2 - name: patch instance with invalid metric name - name: post instance history POST: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9/history - name: delete instance history PATCH: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9 PATCH: /v1/resource/instance/77777777-CC60-4033-804E-2D3098C7D2E9 GET: /v1/resource/instance/noexist GET: /v1/resource/instance/77777777-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util - name: list instance resources no auth GET: /v1/resource/instance - name: list instance resources $[0].host: compute2 $[-1].host: compute2 - name: post new instance with non-existent metrics POST: /v1/resource/instance flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 - name: post new instance with metrics bad policy flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 - name: post new instance with metrics no policy rule flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 - name: post new instance with metrics using policy rule flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 - name: post new instance with metrics flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 - name: post new instance with metrics and un-normalized user/project id from keystone middleware flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 GET: /v1/resource/instance/$RESPONSE['$.id']/metric/cpu.util/measures - name: list the instances GET: /v1/resource/instance - name: request metrics from one of the instances GET: /v1/resource/instance/$RESPONSE['$[-1].id']/metric GET: /v1/resource/instance/not.a.uuid/metric - name: request cpuutil metric from instance GET: /v1/resource/instance/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util - name: try post cpuutil metric to instance - name: request cpuutil measures from instance GET: /v1/resource/instance/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/cpu.util/measures - name: post metric at instance POST: /v1/resource/instance/85C44741-CC60-4033-804E-2D3098C7D2E9/metric - name: post metric at instance with empty definition - name: post metric at instance using archive policy rule - name: duplicate metrics at instance - name: post metrics at instance bad policy - name: post new instance with bad timestamp POST: /v1/resource/instance flavor_id: ""2"" image_ref: http://image host: compute3 display_name: myvm2 POST: /v1/resource/instance/not.a.uuid/metric POST: /v1/resource/instance/d5a5994e-ee90-11e4-88cf-685b35afa334/metric POST: /v1/resource/instance/85C44741-CC60-4033-804E-2D3098C7D2E9/metric/unknown/measures# DELETE-ing instances - name: delete instance DELETE: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9 - name: delete noexist instance DELETE: /v1/resource/instance/77777777-CC60-4033-804E-2D3098C7D2E9",82,134
openstack%2Fpython-aodhclient~master~I98e5bad0eff7f93609a1a81bb51045fa37c42062,openstack/python-aodhclient,master,I98e5bad0eff7f93609a1a81bb51045fa37c42062,Remove the duplicated __version__ definition,MERGED,2017-02-08 09:46:43.000000000,2017-02-18 13:28:59.000000000,2017-02-18 13:28:59.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-08 09:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/5f1e8b9e14d9c266b4a494a0d4508ac79343dfd9', 'message': 'Remove the duplicated __version__ definition\n\nChange-Id: I98e5bad0eff7f93609a1a81bb51045fa37c42062\n'}, {'number': 2, 'created': '2017-02-09 01:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/eafd5fd8f17ad9fa5fd73729409c07a7c7077e44', 'message': 'Remove the duplicated __version__ definition\n\nChange-Id: I98e5bad0eff7f93609a1a81bb51045fa37c42062\n'}, {'number': 3, 'created': '2017-02-10 00:45:56.000000000', 'files': ['aodhclient/version.py', 'aodhclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/62559471f41fe93ae3a5606da7c63360be2c67fb', 'message': 'Remove the duplicated __version__ definition\n\nChange-Id: I98e5bad0eff7f93609a1a81bb51045fa37c42062\n'}]",0,430689,62559471f41fe93ae3a5606da7c63360be2c67fb,16,5,3,8290,,,0,"Remove the duplicated __version__ definition

Change-Id: I98e5bad0eff7f93609a1a81bb51045fa37c42062
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/89/430689/3 && git format-patch -1 --stdout FETCH_HEAD,"['aodhclient/version.py', 'aodhclient/shell.py']",2,5f1e8b9e14d9c266b4a494a0d4508ac79343dfd9,clean-version,from aodhclient import __version__,from aodhclient.version import __version__ # FIXME(sileht): get version from pbr,1,20
openstack%2Fneutron~master~I948132924ec5021a9db78cf17efbba96b2500e8e,openstack/neutron,master,I948132924ec5021a9db78cf17efbba96b2500e8e,Skip native DHCP notifications on status change,MERGED,2017-02-16 07:10:17.000000000,2017-02-18 13:24:26.000000000,2017-02-18 05:10:49.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5948}, {'_account_id': 9732}, {'_account_id': 10184}, {'_account_id': 13734}, {'_account_id': 23804}]","[{'number': 1, 'created': '2017-02-16 07:10:17.000000000', 'files': ['neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/840e04b6f122f022f67b600ed2f96ae5e92eabe0', 'message': ""Skip native DHCP notifications on status change\n\nOn profiling the get_devices_details communications between\nthe agent and the server, a significant amount of time\n(60% in my dev env) is being spent in the AFTER_UPDATE events\nfor the port updates resulting from the port status changes.\n\nOne of the major offenders is the native DHCP agent notifier.\nOn each port update it ends up retrieving the network for the\nport, the DHCP agents for the network, and the segments.\n\nThis patch addresses this particular issue by adding logic to\nskip a DHCP notification if the only thing that changed on the\nport was the status. The DHCP agent doesn't do anything based on\nthe status field so there is no need to update it when this is\nthe only change.\n\nChange-Id: I948132924ec5021a9db78cf17efbba96b2500e8e\nPartial-Bug: #1665215\n""}]",8,434677,840e04b6f122f022f67b600ed2f96ae5e92eabe0,23,8,1,7787,,,0,"Skip native DHCP notifications on status change

On profiling the get_devices_details communications between
the agent and the server, a significant amount of time
(60% in my dev env) is being spent in the AFTER_UPDATE events
for the port updates resulting from the port status changes.

One of the major offenders is the native DHCP agent notifier.
On each port update it ends up retrieving the network for the
port, the DHCP agents for the network, and the segments.

This patch addresses this particular issue by adding logic to
skip a DHCP notification if the only thing that changed on the
port was the status. The DHCP agent doesn't do anything based on
the status field so there is no need to update it when this is
the only change.

Change-Id: I948132924ec5021a9db78cf17efbba96b2500e8e
Partial-Bug: #1665215
",git fetch https://review.opendev.org/openstack/neutron refs/changes/77/434677/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/api/rpc/agentnotifiers/test_dhcp_rpc_agent_api.py']",2,840e04b6f122f022f67b600ed2f96ae5e92eabe0,bug/1665215," def test__only_status_changed(self): p1 = {'id': 1, 'status': 'DOWN', 'updated_at': '10:00:00', 'revision_number': 1} p2 = dict(p1) p2['status'] = 'ACTIVE' p2['revision_number'] = 2 p2['updated_at'] = '10:00:01' self.assertTrue(self.notifier._only_status_changed(p1, p2)) p2['name'] = 'test' self.assertFalse(self.notifier._only_status_changed(p1, p2)) p1['name'] = 'test' self.assertTrue(self.notifier._only_status_changed(p1, p2)) p1['name'] = 'test1' self.assertFalse(self.notifier._only_status_changed(p1, p2))",,35,0
openstack%2Fos-brick~master~I31b2cba2380b203aa2ef891442056416c4f75061,openstack/os-brick,master,I31b2cba2380b203aa2ef891442056416c4f75061,RBD: Can not delete temporary configuration file.,ABANDONED,2017-02-13 08:15:04.000000000,2017-02-18 13:23:07.000000000,,"[{'_account_id': 3}, {'_account_id': 9236}, {'_account_id': 9732}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17565}, {'_account_id': 19852}, {'_account_id': 22796}]","[{'number': 1, 'created': '2017-02-13 08:15:04.000000000', 'files': ['os_brick/initiator/linuxrbd.py', 'os_brick/initiator/connectors/rbd.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/a43892f9216a71f34096c8ad1b345f980aea4933', 'message': ""RBD: Can not delete temporary configuration file.\n\nIn rbd.py, We should not delete temporary configuration\nin method '_get_rbd_handle', if we do so, the rbd commands\nusing this configuration file as an argument will repoort\nerror. I delete this file when the rbd_handle is closed.\n\nChange-Id: I31b2cba2380b203aa2ef891442056416c4f75061\nCloses-Bug: #1658885\n""}]",0,432905,a43892f9216a71f34096c8ad1b345f980aea4933,12,11,1,24741,,,0,"RBD: Can not delete temporary configuration file.

In rbd.py, We should not delete temporary configuration
in method '_get_rbd_handle', if we do so, the rbd commands
using this configuration file as an argument will repoort
error. I delete this file when the rbd_handle is closed.

Change-Id: I31b2cba2380b203aa2ef891442056416c4f75061
Closes-Bug: #1658885
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/05/432905/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/initiator/linuxrbd.py', 'os_brick/initiator/connectors/rbd.py']",2,a43892f9216a71f34096c8ad1b345f980aea4933,bug/1658885," rbd_client = linuxrbd.RBDClient(user, pool, conffile=conf, rbd_cluster_name=str(cluster_name)) rbd_volume = linuxrbd.RBDVolume(rbd_client, volume) rbd_handle = linuxrbd.RBDVolumeIOWrapper( linuxrbd.RBDImageMetadata(rbd_volume, pool, user, conf))","from oslo_utils import fileutils try: rbd_client = linuxrbd.RBDClient(user, pool, conffile=conf, rbd_cluster_name=str(cluster_name)) rbd_volume = linuxrbd.RBDVolume(rbd_client, volume) rbd_handle = linuxrbd.RBDVolumeIOWrapper( linuxrbd.RBDImageMetadata(rbd_volume, pool, user, conf)) finally: fileutils.delete_if_exists(conf)",12,9
openstack%2Fkolla~master~Ib5da7897a423eb225fb67d0e0d1e31b20e6961e2,openstack/kolla,master,Ib5da7897a423eb225fb67d0e0d1e31b20e6961e2,Fix some typos,MERGED,2017-02-16 07:53:48.000000000,2017-02-18 12:56:52.000000000,2017-02-18 12:56:52.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 17666}, {'_account_id': 17812}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 23717}, {'_account_id': 24013}]","[{'number': 1, 'created': '2017-02-16 07:53:48.000000000', 'files': ['kolla/template/methods.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9d9800530f43668ac33d19df0baaf0ca0103e450', 'message': ""Fix some typos\n\nFix the word 'contruct' -> 'construct'.\n\nChange-Id: Ib5da7897a423eb225fb67d0e0d1e31b20e6961e2\n""}]",0,434706,9d9800530f43668ac33d19df0baaf0ca0103e450,14,8,1,21511,,,0,"Fix some typos

Fix the word 'contruct' -> 'construct'.

Change-Id: Ib5da7897a423eb225fb67d0e0d1e31b20e6961e2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/06/434706/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/template/methods.py'],1,9d9800530f43668ac33d19df0baaf0ca0103e450,kolla2017," installed, and cleaned up is complicated. This method will construct the easier to follow."," installed, and cleaned up is complicated. This method will contruct the easier to follow",2,2
openstack%2Fkolla~master~Ib60e2e26841d011aef7fdf1fab936bcdc79eb336,openstack/kolla,master,Ib60e2e26841d011aef7fdf1fab936bcdc79eb336,Add helm_repository_source_install_python_pip block to helm-repository Dockerfile,MERGED,2017-02-17 15:47:18.000000000,2017-02-18 12:56:45.000000000,2017-02-18 12:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}]","[{'number': 1, 'created': '2017-02-17 15:47:18.000000000', 'files': ['docker/helm-repository/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4d2cffbd893fe6caa17c43277d21a169a4bfc0b6', 'message': 'Add helm_repository_source_install_python_pip block to helm-repository Dockerfile\n\nAllow overriding the pip installation so that it can\nbe easily customised if needed.\n\nChange-Id: Ib60e2e26841d011aef7fdf1fab936bcdc79eb336\n'}]",0,435499,4d2cffbd893fe6caa17c43277d21a169a4bfc0b6,7,3,1,16704,,,0,"Add helm_repository_source_install_python_pip block to helm-repository Dockerfile

Allow overriding the pip installation so that it can
be easily customised if needed.

Change-Id: Ib60e2e26841d011aef7fdf1fab936bcdc79eb336
",git fetch https://review.opendev.org/openstack/kolla refs/changes/99/435499/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/helm-repository/Dockerfile.j2'],1,4d2cffbd893fe6caa17c43277d21a169a4bfc0b6,,{% block helm_repository_source_install_python_pip %}{% endblock %},,2,0
openstack%2Fdragonflow~master~I703f41da478abd25a333fa78390a16d3614f7b4c,openstack/dragonflow,master,I703f41da478abd25a333fa78390a16d3614f7b4c,[Test] Use neutron stable/ocata branch ocata test,ABANDONED,2017-02-18 12:38:09.000000000,2017-02-18 12:44:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-18 12:38:09.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c8044f5b1da14b57463a3e3378cbca50455793b6', 'message': '[Test] Use neutron stable/ocata branch ocata test\n\nChange-Id: I703f41da478abd25a333fa78390a16d3614f7b4c\n'}]",0,435701,c8044f5b1da14b57463a3e3378cbca50455793b6,3,1,1,11159,,,0,"[Test] Use neutron stable/ocata branch ocata test

Change-Id: I703f41da478abd25a333fa78390a16d3614f7b4c
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/01/435701/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,c8044f5b1da14b57463a3e3378cbca50455793b6,stable/ocata,BRANCH_NAME=stable/ocata,BRANCH_NAME=master,1,1
openstack%2Fnetworking-calico~master~I8afd704a881c3df5799a96e77be94f9de8181774,openstack/networking-calico,master,I8afd704a881c3df5799a96e77be94f9de8181774,Get Felix from Calico master PPA,MERGED,2017-02-15 00:37:54.000000000,2017-02-18 12:41:03.000000000,2017-02-18 12:41:03.000000000,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 13734}, {'_account_id': 19461}]","[{'number': 1, 'created': '2017-02-15 00:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/dea353d06b1df2790c4598e27674bbbaefa36b06', 'message': ""Try using the Felix 2.1 release candidate instead of 2.0\n\nThis should reduce networking-calico's exposure to\nhttps://bugs.launchpad.net/neutron/+bug/1664782, because Felix 2.1 includes\nunique hash comments in the iptables rules that it generates, which should mean\nthat the Neutron iptables manager never detects (and removes) 'duplicate' Felix\n2.1 rules.\n\nChange-Id: I8afd704a881c3df5799a96e77be94f9de8181774\n""}, {'number': 2, 'created': '2017-02-15 00:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/4f27e5ea1f73d075a5f639da6d4cc38cf89318d7', 'message': ""Try using the Felix 2.1 release candidate instead of 2.0\n\nThis should reduce networking-calico's exposure to\nhttps://bugs.launchpad.net/neutron/+bug/1664782, because Felix 2.1\nincludes unique hash comments in the iptables rules that it generates,\nwhich should mean that the Neutron iptables manager never detects (and\nremoves) 'duplicate' Felix 2.1 rules.\n\nChange-Id: I8afd704a881c3df5799a96e77be94f9de8181774\n""}, {'number': 3, 'created': '2017-02-18 09:36:11.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-calico/commit/91b06ded8f49fb778cb15ca1aa4094135ee07132', 'message': ""Get Felix from Calico master PPA\n\nThe Calico 'master' PPA contains packages built from the latest Felix\nmaster code, regardless of whether that code has yet been released.  So\nusing that PPA is consistent with how OpenStack CI of the master\nnetworking-calico code uses master Neutron, neutron-lib etc.\n\nAs a side effect, this should reduce or eliminate networking-calico's\nexposure to https://bugs.launchpad.net/neutron/+bug/1664782, because\nFelix master now includes unique hash comments in the iptables rules\nthat it generates, which should mean that the Neutron iptables manager\nnever sees (and removes) rules that it thinks are duplicates.\n\nChange-Id: I8afd704a881c3df5799a96e77be94f9de8181774\n""}]",0,434000,91b06ded8f49fb778cb15ca1aa4094135ee07132,15,4,3,13734,,,0,"Get Felix from Calico master PPA

The Calico 'master' PPA contains packages built from the latest Felix
master code, regardless of whether that code has yet been released.  So
using that PPA is consistent with how OpenStack CI of the master
networking-calico code uses master Neutron, neutron-lib etc.

As a side effect, this should reduce or eliminate networking-calico's
exposure to https://bugs.launchpad.net/neutron/+bug/1664782, because
Felix master now includes unique hash comments in the iptables rules
that it generates, which should mean that the Neutron iptables manager
never sees (and removes) rules that it thinks are duplicates.

Change-Id: I8afd704a881c3df5799a96e77be94f9de8181774
",git fetch https://review.opendev.org/openstack/networking-calico refs/changes/00/434000/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,dea353d06b1df2790c4598e27674bbbaefa36b06,use-felix-2.1, sudo apt-add-repository -y ppa:project-calico/felix-2.1-testing, sudo apt-add-repository -y ppa:project-calico/calico-2.0,1,1
openstack%2Fnova-specs~master~I117ad3ee845f9986bbd724a004d77ad130bb0a06,openstack/nova-specs,master,I117ad3ee845f9986bbd724a004d77ad130bb0a06,Add Host Details,ABANDONED,2017-02-02 10:08:23.000000000,2017-02-18 12:17:12.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 15334}, {'_account_id': 15834}]","[{'number': 1, 'created': '2017-02-02 10:08:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/56cc91248aba8320a84f5e777572b106b47d6bc6', 'message': 'Add Host Details\n\nUser needs to know more detailed information about maintenance that is\neffecting to his servers.\n\nAPIImpact\n\nChange-Id: I117ad3ee845f9986bbd724a004d77ad130bb0a06\nImplements: blueprint maintenance-reason-to-server\n'}, {'number': 2, 'created': '2017-02-10 07:37:58.000000000', 'files': ['specs/pike/approved/add-host-details.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4334ba31686b9795c81cfcd06d490e3c2103c3b4', 'message': 'Add Host Details\n\nUser needs to know more detailed information about maintenance that is\neffecting to his servers.\n\nAPIImpact\n\nChange-Id: I117ad3ee845f9986bbd724a004d77ad130bb0a06\nImplements: blueprint maintenance-reason-to-server\n'}]",8,428070,4334ba31686b9795c81cfcd06d490e3c2103c3b4,11,4,2,15834,,,0,"Add Host Details

User needs to know more detailed information about maintenance that is
effecting to his servers.

APIImpact

Change-Id: I117ad3ee845f9986bbd724a004d77ad130bb0a06
Implements: blueprint maintenance-reason-to-server
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/70/428070/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/add-host-details.rst'],1,56cc91248aba8320a84f5e777572b106b47d6bc6,bp/maintenance-reason-to-server,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add Host Details ========================================== https://blueprints.launchpad.net/nova/+spec/maintenance-reason-to-server User needs to obtain more detailed information about compute host maintenance which is affecting his servers. Problem description =================== Some applications need to prepare for an impacting maintenance by routing work to other non-impacted servers, so users are not impacted by the maintenance. We need a way for Nova to make this kind of information available to the application. There could also be other details helpful to know about the host state which can be obtained via link to external service. Use Cases --------- As a user I want to know when maintenance is going to happen. As a user I want to have time for my application to be ready for maintenance. As a user I want to get all needed state information through an API. As an admin I want to have an external tool supporting more complex maintenance flows and more specific state for maintenance. As an admin I want to know maintenance state of different hosts. As an admin I want to know if hypervisor forced down. Proposed change =============== It is seen that more detailed maintenance awareness should not be extended into Nova, but there could be an external tool to have more detailed host information. A free text field should be added to have an URL link to be opened to get more details relating to the maintenance and host in general. There needs to be a different link for admin and owner of servers on compute host. New ``host_details`` field should be added to services table in Nova DB. This could be set by adding a new API:: PUT /v2.1/{tenant_id}/os-services/host-details ``host_details`` should have an URL linking to external service having detail about the host. URL should end to /{hostname}:: ""http://myhostdetailsurl/{hostname}"" This link could be used with admin privileges. New version of ``service.update`` notification should be made with ``host_details`` parameter and also triggered when value changes. The ``host_details`` field should also be visible as parameter in response of APIs:: GET /v2.1/{tenant_id}/servers/{server_id} GET /v2.1/{tenant_id}/servers/detail Here ``host_details`` should have a diffrent URL than is service sid above. URL should end to /{hostid} that is already found from server data:: ""http://myhostdetailsurl/{hostid}"" Nova can internally change ``host_details`` URL set to nova-compute service to ``host_details`` URL visible in servers API, by replacing /{hostname} with /{hostid}. Having it like this, the ``hostname`` will not be exposed to all users, just for admin. Also content seen behing url can contain more detailed information for admin that should not be exposed to other users. A new policy is needed to have this visible in the above APIs:: ""os_compute_api:servers:show:host_""details: ""rule:admin_or_owner"" The new ``host_details`` field should be added as parameter together with ``forced_down`` to response message of:: GET /v2.1/{tenant_id}/os-hypervisors/{hypervisor_id} GET /v2.1/{tenant_id}/os-hypervisors/detail ``forced_down`` is already in os-services, but would be consistent to have it also in os-hypervisors. The new ``host_details`` need to be also visible as response parameters in:: GET /v2.1/{tenant_id}/os-services Alternatives ------------ Maintenance state is being implemented to external service having configuration management DB for hosts. It would not be feasible to read information straight from there as it need not not to know anything about servers on host. That is in nova content. Data model impact ----------------- New columns should be added to the ``services`` table in Nova DB by migration script:: Column('host_details', String(255), nullable=True) REST API impact --------------- A single new microversion is needed for new API to set host details and showing it in relevant API responses. API for setting host details:: PUT /v2.1/{tenant_id}/os-services/host-details { ""host"": ""host1"", ""binary"": ""nova-compute"", ""host_details"": ""http://myhostdetailsurl/{hostname}"", } 200 OK { ""service"": { ""host"": ""host1"", ""binary"": ""nova-compute"", ""host_details"": ""http://myhostdetailsurl/{hostname}"", } } Servers APIs that will have ``host_details`` shown in response message:: GET /v2.1/{tenant_id}/servers/{server_id} GET /v2.1/{tenant_id}/servers/detail Example of showing ``host_details`` parameter in the above APIs response:: GET /v2.1/{tenant_id}/servers/{server_id} 200 OK { ""server"": { ... ""host_details"": ""http://myhostdetailsurl/{hostid}"", ... } } Hypervisors APIs showing ``host_details`` and ``forced_down`` in response message:: GET /v2.1/{tenant_id}/os-hypervisors/{hypervisor_id} GET /v2.1/{tenant_id}/os-hypervisors/detail Example of showing these parameters in the above APIs response:: GET /v2.1/{tenant_id}/os-hypervisors/{hypervisor_id} 200 OK { ""hypervisor"": { ""status"": disabled"", ""service"": { ""host"": host1"", ""disabled_reason"": ""Maintenance"", ""id"": 6, ""forced_down"": False, ""host_details"": ""http://myhostdetailsurl/{hostname}"", }, ... } Example of showing ``host_details`` parameter in ``GET /v2.1/{tenant_id}/os-services`` response:: GET /v2.1/{tenant_id}/os-services 200 OK { ""services"": [ ... { ""id"": 2, ""binary"": ""nova-compute"", ""disabled_reason"": ""Maintenance"", ""host"": ""host1"", ""state"": ""up"", ""status"": ""disabled"", ""updated_at"": ""2016-03-22T00:46:25.211575"", ""forced_down"": false, ""zone"": ""nova"", ""host_details"": ""http://myhostdetailsurl/{hostname}"", }, ... ] } Novaclient will need support for setting host details. Response for APIs just showing the new field should be straightforward, but for setting host details there needs to be a new CLI command:: $ nova service-host-details <hostname> <binary> <host details> +--------------+------------------------------------+ | Property | Value | +--------------+------------------------------------+ | Host | host1 | +--------------+------------------------------------+ | Binary | nova-compute | +--------------+------------------------------------+ | host_details | http://myhostdetailsurl/{hostname} | +-------------------------+-------------------------+ Security impact --------------- None Notifications impact -------------------- New version of the ``service.update`` notification should be sent including the new ``host_details`` parameter:: { ""priority"": ""INFO"", ""payload"": { ""nova_object.namespace"": ""nova"", ""nova_object.name"": ""ServiceStatusPayload"", ""nova_object.version"": ""1.1"", ""nova_object.data"": { ""host"": ""host1"", ""disabled"": true, ""last_seen_up"": ""2016-03-22T00:46:25Z"", ""binary"": ""nova-compute"", ""topic"": ""compute"", ""disabled_reason"": ""Maintenance"", ""report_count"": 1, ""forced_down"": false, ""version"": 16, ""host_details"": ""http://myhostdetailsurl/{hostname}"" } }, ""event_type"": ""service.update"", ""publisher_id"": ""nova-compute:host1"" } Other end user impact --------------------- None Performance Impact ------------------ APIs exposed to new field are already having the services table exposed, so there should not be a major performance hit. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: tomi-juvonen-q Work Items ---------- - API changes with microversion. - DB change. - Notification. - Novaclient to support microversion. - Documentation. Dependencies ============ None Testing ======= Unit and functional test cases need to be added. Documentation Impact ==================== API reference documentation needs to be changed. References ========== * This spec is as result of the OPNFV Doctor requirements for maintenance: http://artifacts.opnfv.org/doctor/docs/requirements/02-use_cases.html#nvfi-maintenance http://artifacts.opnfv.org/doctor/docs/requirements/03-architecture.html#nfvi-maintenance http://artifacts.opnfv.org/doctor/docs/requirements/05-implementation.html#nfvi-maintenance * Also relevant for user story: http://specs.openstack.org/openstack/openstack-user-stories/user-stories/proposed/ha_vm.html History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Pike - Introduced ",,326,0
openstack%2Fkolla-ansible~master~I4b7d573cc684d28515fa944186a04bc26efab521,openstack/kolla-ansible,master,I4b7d573cc684d28515fa944186a04bc26efab521,Fixed a typo in tg-agent,MERGED,2017-02-17 04:36:03.000000000,2017-02-18 12:03:09.000000000,2017-02-18 12:03:09.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 17812}, {'_account_id': 19316}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-17 04:36:03.000000000', 'files': ['ansible/roles/common/tasks/config.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/be6d9e8aa5403603136a1c59ec7bae219662cc41', 'message': 'Fixed a typo in tg-agent\n\nIt should be td-agent.\n\nTrivialFix\n\nChange-Id: I4b7d573cc684d28515fa944186a04bc26efab521\n'}]",0,435235,be6d9e8aa5403603136a1c59ec7bae219662cc41,9,5,1,16620,,,0,"Fixed a typo in tg-agent

It should be td-agent.

TrivialFix

Change-Id: I4b7d573cc684d28515fa944186a04bc26efab521
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/35/435235/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/tasks/config.yml'],1,be6d9e8aa5403603136a1c59ec7bae219662cc41,bug/tg-agent,- name: Copying over td-agent.conf,- name: Copying over tg-agent.conf,1,1
openstack%2Fopenstack-ansible-os_keystone~master~Ic47f5b4fe259302d7aa56c5c0b6fce3670b7bf06,openstack/openstack-ansible-os_keystone,master,Ic47f5b4fe259302d7aa56c5c0b6fce3670b7bf06,[WIP] Role based artifact,ABANDONED,2016-10-08 23:07:49.000000000,2017-02-18 12:00:31.000000000,,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12000}]","[{'number': 1, 'created': '2016-10-08 23:07:49.000000000', 'files': ['tests/image-artifact.sh', '.gitignore', 'tests/image-artifact.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/f0382f0e3bc80d715745b09a295846b4bf61ef87', 'message': '[WIP] Role based artifact\n\nThis change implements a role based artifact create and test. With this\nchange we should be able to collect versioned image artifacts on a per\ncommit basis.\n\nChange-Id: Ic47f5b4fe259302d7aa56c5c0b6fce3670b7bf06\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,384137,f0382f0e3bc80d715745b09a295846b4bf61ef87,8,5,1,7353,,,0,"[WIP] Role based artifact

This change implements a role based artifact create and test. With this
change we should be able to collect versioned image artifacts on a per
commit basis.

Change-Id: Ic47f5b4fe259302d7aa56c5c0b6fce3670b7bf06
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/37/384137/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/image-artifact.sh', '.gitignore', 'tests/image-artifact.yml', 'tox.ini']",4,f0382f0e3bc80d715745b09a295846b4bf61ef87,," [testenv:artifact_image] # Ignore_errors is set to true so that the logs are collected at the # end of the run. This will not produce a false positive. Any # exception will be mark the run as ""failed"" and exit 1 after all of # the commands have been iterated through. ignore_errors = True # NOTE(andymccr): this will test keystone with uwsgi & nginx install_command = {[testenv:func_base]install_command} deps = {[testenv:ansible]deps} commands = {[testenv:ansible]commands} bash -c 'tests/image-artifact.sh'",,177,2
openstack%2Fopenstack-ansible~master~I2284e3b2f837ee951666d1918e1625c298c279bb,openstack/openstack-ansible,master,I2284e3b2f837ee951666d1918e1625c298c279bb,[WIP] example playbook to build container images,ABANDONED,2016-12-11 02:25:53.000000000,2017-02-18 12:00:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 17068}]","[{'number': 1, 'created': '2016-12-11 02:25:53.000000000', 'files': ['playbooks/utility-playbooks/artifact-build.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bb1ca8a6c75ab3b101fff36de8e3f4e21988904b', 'message': '[WIP] example playbook to build container images\n\nThis pr builds container images based on a provided role using standard\nansible configurations across ``lxc_hosts`` using the arch and distro as\ncategories. This will allow us to construct images on a per-role basis\nfor all distros and architectures within a given deployment.\n\nThis is a work in progress, very incomplete, but a potential idea.\nI tested this using the following function:\nhttp://paste.openstack.org/show/592040/\n\nlike so:\nansible_tag_filter ""openstack-ansible\nutility-playbooks/artifact-build.yml -e role_name=os_keystone -e\ndev_mode=true"" ""install"" ""config""\n\nWhich will execute the openstack-ansible using the ""os_keystone""\nbuilding the image with all of the ""install"" tags and skipping all of\nthe ""config"" tags. The process creates the container images on the\nremote hosts. In the future state we can pull back the various images\ninto the potential repo_server container or push the built images\nelsewhere. The build process is using the standard ssh connection\nplugin and container transport strategy already found in OSA.\n\nChange-Id: I2284e3b2f837ee951666d1918e1625c298c279bb\n'}]",11,409490,bb1ca8a6c75ab3b101fff36de8e3f4e21988904b,7,3,1,7353,,,0,"[WIP] example playbook to build container images

This pr builds container images based on a provided role using standard
ansible configurations across ``lxc_hosts`` using the arch and distro as
categories. This will allow us to construct images on a per-role basis
for all distros and architectures within a given deployment.

This is a work in progress, very incomplete, but a potential idea.
I tested this using the following function:
http://paste.openstack.org/show/592040/

like so:
ansible_tag_filter ""openstack-ansible
utility-playbooks/artifact-build.yml -e role_name=os_keystone -e
dev_mode=true"" ""install"" ""config""

Which will execute the openstack-ansible using the ""os_keystone""
building the image with all of the ""install"" tags and skipping all of
the ""config"" tags. The process creates the container images on the
remote hosts. In the future state we can pull back the various images
into the potential repo_server container or push the built images
elsewhere. The build process is using the standard ssh connection
plugin and container transport strategy already found in OSA.

Change-Id: I2284e3b2f837ee951666d1918e1625c298c279bb
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/90/409490/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/utility-playbooks/artifact-build.yml'],1,bb1ca8a6c75ab3b101fff36de8e3f4e21988904b,artifacts,"--- # Copyright 2016, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Group servers by architecture and distro hosts: lxc_hosts tasks: - name: Group servers by architecture group_by: key: ""{{ lxc_key_group }}"" vars: lxc_key_group: ""lxc_hosts_{{ ansible_distribution | lower }}_{{ ansible_distribution_release | lower }}_{{ ansible_architecture }}"" tags: - always - name: Create servers single group by architecture and distro hosts: lxc_hosts tasks: # Use the 'add_host' module to create the repo_nodes group. The add_hosts module # bypasses the play host loop of ansible and runs only once referencing the first # host. To run it on each host we have to use with_items. Also note, we have # to manually lookup the ansible_architecture for the 'item' host. - name: Prepare group of unique lxc hosts local_action: module: ""add_host"" name: ""{{ groups[lxc_key_group_item][0] }}"" groups: ""lxc_artifact_hosts"" # Process all nodes that don't match the architecture of repo_all[0] when: - hostvars[item].ansible_architecture != hostvars[groups[""lxc_hosts""][0]].ansible_architecture - hostvars[item].ansible_distribution_release != hostvars[groups[""lxc_hosts""][0]].ansible_distribution_release - hostvars[item].ansible_distribution != hostvars[groups[""lxc_hosts""][0]].ansible_distribution with_items: ""{{ groups['lxc_hosts'][1:] }}"" tags: - always vars: lxc_key_group_item: ""lxc_hosts_{{ hostvars[item]['ansible_distribution'] | lower }}_{{ hostvars[item]['ansible_distribution_release'] | lower }}_{{ hostvars[item]['ansible_architecture'] }}"" tags: - always - name: Create artifact container hosts: lxc_artifact_hosts, lxc_hosts[0] post_tasks: - name: Remove base container lxc_container: name: ""LXC_NAME"" state: absent - name: Create base container lxc_container: name: ""LXC_NAME"" template: ""download"" state: ""started"" backing_store: ""dir"" template_options: > --dist {{ ansible_distribution | lower }} --release {{ ansible_distribution_release | lower }} --arch ""{{ architecture_mapping.get( ansible_architecture ) }}"" --force-cache --server images.linuxcontainers.org --keyserver hkp://p80.pool.sks-keyservers.net:80 - name: Prepare group of master lxc hosts add_host: name: ""LXC_NAME"" groups: ""lxc_container_artifact_hosts"" container_name: ""LXC_NAME"" physical_host: ""{{ inventory_hostname }}"" vars: architecture_mapping: x86_64: amd64 ppc64le: ppc64el tags: - always - name: Run role hosts: lxc_container_artifact_hosts gather_facts: True pre_tasks: - name: Set dev mode fact set_fact: '{{ item.key }}=""{{ item.value }}""' with_dict: ""{{ dev_mode_vars }}"" when: dev_mode | bool tags: - always roles: - role: ""{{ role_name }}"" vars: image_name: ""{{ role_name | replace('os_', '') }}"" dev_mode: false dev_mode_vars: pip_lock_to_internal_repo: False '{{ image_name }}_developer_mode': true pip_install_upper_constraints: ""https://raw.githubusercontent.com/openstack/requirements/master/upper-constraints.txt"" tags: - role_run - name: Create artifact container hosts: lxc_artifact_hosts, lxc_hosts[0] tasks: - name: Set artifact facts set_fact: image_path: ""{{ lxc_image_folder }}/{{ lxc_index_path }}/{{ image_name }}/{{ openstack_release }}"" - name: Container image directories file: path: ""{{ item }}"" state: ""directory"" recurse: true with_items: - ""{{ image_path }}"" - ""{{ lxc_image_folder }}/"" - name: Create lxc image shell: | tar -Opc -C /var/lib/lxc/LXC_NAME/rootfs . | \ {{ xz_bin[ansible_distribution | lower] }} -{{ compression_ratio }} \ -c - > rootfs.tar.xz args: chdir: ""{{ image_path }}"" creates: ""{{ image_path }}/rootfs.tar.xz"" - name: Create lxc image meta shell: | tar -Opc -C ""{{ lxc_container_cache_path }}/{{ lxc_index_path }}/default/{build_id,config,config-user,create-message,excludes-user,expiry,templates}"" . | \ {{ xz_bin[ansible_distribution | lower] }} -{{ compression_ratio }} \ -c - > meta.tar.xz args: chdir: ""{{ image_path }}"" creates: ""{{ image_path }}/meta.tar.xz"" - name: Create release index entries lineinfile: dest: ""{{ lxc_image_folder }}/{{ image_name }}-{{ openstack_release }}-entry"" line: ""{{ lxc_index_entry }};{{ image_name }};{{ openstack_release }};/lxc-images/{{ lxc_index_path }}/{{ image_name }}/{{ openstack_release }}"" create: yes state: present - name: create sha256sums shell: | echo ""$(sha256sum {{ image_path }}/rootfs.tar.xz | awk '{print $1}') rootfs.tar.xz"" | tee SHA256SUMS echo ""$(sha256sum {{ image_path }}/meta.tar.xz | awk '{print $1}') meta.tar.xz"" | tee -a SHA256SUMS args: chdir: ""{{ image_path }}"" post_tasks: - name: Remove base container lxc_container: name: ""LXC_NAME"" state: absent vars: lxc_index_path: ""{{ ansible_distribution | lower }}/{{ ansible_distribution_release | lower }}/{{ architecture_mapping.get( ansible_architecture ) }}"" lxc_index_entry: ""{{ ansible_distribution | lower }};{{ ansible_distribution_release | lower }};{{ architecture_mapping.get( ansible_architecture ) }}"" lxc_image_folder: ""/var/cache/artifacts"" lxc_container_cache_path: ""/var/cache/lxc/download"" image_name: ""{{ role_name | replace('os_', '') }}"" compression_ratio: 7 xz_bin: centos: xz ubuntu: pxz architecture_mapping: x86_64: amd64 ppc64le: ppc64el tags: - always ",,169,0
openstack%2Fcinder~master~I79074a29eedf083dee21fd1798ed595cbfb2b2b8,openstack/cinder,master,I79074a29eedf083dee21fd1798ed595cbfb2b2b8,Add maximum microversion for Ocata,MERGED,2017-02-10 17:21:10.000000000,2017-02-18 11:59:38.000000000,2017-02-11 00:05:06.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 13144}, {'_account_id': 15386}, {'_account_id': 16941}, {'_account_id': 18444}, {'_account_id': 19933}, {'_account_id': 21884}, {'_account_id': 21990}, {'_account_id': 23613}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-10 17:21:10.000000000', 'files': ['cinder/api/openstack/rest_api_version_history.rst'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c59b4e0788c670fb6e4db17fa81f7c71abd4bc9d', 'message': 'Add maximum microversion for Ocata\n\nMicroversion continues bumping with new features, that is great thing.\nThis patch adds the maximum microversion for Ocata to let users know\nwhat features are available on each release.\n\nThe following github history is an evidence of this microversion:\nhttps://github.com/openstack/cinder/blob/stable/ocata/cinder/api/openstack/rest_api_version_history.rst#327\n\nChange-Id: I79074a29eedf083dee21fd1798ed595cbfb2b2b8\n'}]",0,432393,c59b4e0788c670fb6e4db17fa81f7c71abd4bc9d,37,15,1,6167,,,0,"Add maximum microversion for Ocata

Microversion continues bumping with new features, that is great thing.
This patch adds the maximum microversion for Ocata to let users know
what features are available on each release.

The following github history is an evidence of this microversion:
https://github.com/openstack/cinder/blob/stable/ocata/cinder/api/openstack/rest_api_version_history.rst#327

Change-Id: I79074a29eedf083dee21fd1798ed595cbfb2b2b8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/93/432393/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/openstack/rest_api_version_history.rst'],1,c59b4e0788c670fb6e4db17fa81f7c71abd4bc9d,microversion-history,3.27 (Maximum in Ocata) -----------------------,3.27 ----,2,2
openstack%2Fsenlin~master~Ia480110e7a8eac6cb730e48fba0d397034d52d28,openstack/senlin,master,Ia480110e7a8eac6cb730e48fba0d397034d52d28,More release notes for the Ocata RC,MERGED,2017-02-17 02:25:14.000000000,2017-02-18 11:46:45.000000000,2017-02-17 02:51:05.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-17 02:25:14.000000000', 'files': ['releasenotes/notes/scaling-policy-validation-e2a1d3049e03c316.yaml', 'releasenotes/notes/param-check-cluster-update-58d4712a33f74c6e.yaml', 'releasenotes/notes/health-reboot-9f74c263f7fb6767.yaml', 'releasenotes/notes/az-info-9344b8d54c0b2665.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/09115f1f47fd09faa2b83ef14a9348e2a606f758', 'message': 'More release notes for the Ocata RC\n\nThis adds some missing release notes items for the Ocata RC version.\n\nChange-Id: Ia480110e7a8eac6cb730e48fba0d397034d52d28\n'}]",0,435199,09115f1f47fd09faa2b83ef14a9348e2a606f758,8,3,1,8246,,,0,"More release notes for the Ocata RC

This adds some missing release notes items for the Ocata RC version.

Change-Id: Ia480110e7a8eac6cb730e48fba0d397034d52d28
",git fetch https://review.opendev.org/openstack/senlin refs/changes/99/435199/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/scaling-policy-validation-e2a1d3049e03c316.yaml', 'releasenotes/notes/param-check-cluster-update-58d4712a33f74c6e.yaml', 'releasenotes/notes/health-reboot-9f74c263f7fb6767.yaml', 'releasenotes/notes/az-info-9344b8d54c0b2665.yaml']",4,09115f1f47fd09faa2b83ef14a9348e2a606f758,relnotes-rc,--- fixes: - The bug where the availability zone info from a nova server deployment was not available has been fixed. ,,15,0
openstack%2Fsenlin~master~I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1,openstack/senlin,master,I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1,Fixed inappropriate event generation in action base,MERGED,2017-02-17 05:45:54.000000000,2017-02-18 11:44:16.000000000,2017-02-17 08:28:49.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2017-02-17 05:45:54.000000000', 'files': ['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/340a0d3b9e6f97ca2832eb575b0a4993330a9419', 'message': 'Fixed inappropriate event generation in action base\n\nWhen policy check succeeds, we are not supposed to emit an event (either\nto database or to message queue) because the success of such a check is\nnot interesting to users at all. They only care about the abnormal\nbehaviors, aka. errors or warnings.\n\nChange-Id: I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1\n'}]",0,435249,340a0d3b9e6f97ca2832eb575b0a4993330a9419,8,3,1,8246,,,0,"Fixed inappropriate event generation in action base

When policy check succeeds, we are not supposed to emit an event (either
to database or to message queue) because the success of such a check is
not interesting to users at all. They only care about the abnormal
behaviors, aka. errors or warnings.

Change-Id: I4cfbb8fb90aeefc3750365c9d3998bd3246c21d1
",git fetch https://review.opendev.org/openstack/senlin refs/changes/49/435249/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/actions/test_action_base.py', 'senlin/engine/actions/base.py']",2,340a0d3b9e6f97ca2832eb575b0a4993330a9419,fix-event-log,," EVENT.debug(self, 'check', reason)",1,3
openstack%2Fsenlin~master~I24a6142d322954a0b8256118d8248e8d250bad6f,openstack/senlin,master,I24a6142d322954a0b8256118d8248e8d250bad6f,Enable heat stack event listener,MERGED,2017-02-17 05:26:30.000000000,2017-02-18 11:43:53.000000000,2017-02-17 08:28:57.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 17812}]","[{'number': 1, 'created': '2017-02-17 05:26:30.000000000', 'files': ['senlin/engine/health_manager.py', 'releasenotes/notes/heat-listener-b908d0988840e1f3.yaml', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/e832fcffcf4997ad36b8a7990ae6c9bec772d80d', 'message': 'Enable heat stack event listener\n\nThis hooks the heat stack event listener for failure detection.\n\nCloses-Bug: 1657983\nChange-Id: I24a6142d322954a0b8256118d8248e8d250bad6f\n'}]",2,435243,e832fcffcf4997ad36b8a7990ae6c9bec772d80d,9,3,1,8246,,,0,"Enable heat stack event listener

This hooks the heat stack event listener for failure detection.

Closes-Bug: 1657983
Change-Id: I24a6142d322954a0b8256118d8248e8d250bad6f
",git fetch https://review.opendev.org/openstack/senlin refs/changes/43/435243/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'releasenotes/notes/heat-listener-b908d0988840e1f3.yaml', 'senlin/tests/unit/engine/test_health_manager.py']",3,e832fcffcf4997ad36b8a7990ae6c9bec772d80d,bug/1657983,"@mock.patch('senlin.engine.health_manager.HeatNotificationEndpoint') mock_target, mock_novaendpoint, mock_heatendpoint): mock_novaendpoint.return_value = x_endpoint mock_novaendpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') def test_listener_proc_heat(self, mock_listener, mock_transport, mock_target, mock_novaendpoint, mock_heatendpoint): x_listener = mock.Mock() mock_listener.return_value = x_listener x_target = mock.Mock() mock_target.return_value = x_target x_endpoint = mock.Mock() mock_heatendpoint.return_value = x_endpoint res = hm.ListenerProc('heat', 'PROJECT_ID', 'CLUSTER_ID') mock_target.assert_called_once_with(topic=""notifications"", exchange='heat') mock_heatendpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') mock_listener.assert_called_once_with( x_transport, [x_target], [x_endpoint], executor='threading', pool=""senlin-listeners"") x_listener.start.assert_called_once_with()"," mock_target, mock_endpoint): mock_endpoint.return_value = x_endpoint mock_endpoint.assert_called_once_with('PROJECT_ID', 'CLUSTER_ID') def test_listener_proc_others(self, mock_listener, mock_transport, mock_target, mock_endpoint): res = hm.ListenerProc('BOGUS', 'PROJECT_ID', 'CLUSTER_ID') self.assertFalse(mock_listener.called) self.assertFalse(mock_target.called) self.assertFalse(mock_endpoint.called)",32,12
openstack%2Fsenlin~master~I93052cf93184bb1cd82d2550657d2ed878ec5f1d,openstack/senlin,master,I93052cf93184bb1cd82d2550657d2ed878ec5f1d,Add tags to newly created heat stacks,MERGED,2017-02-17 03:33:44.000000000,2017-02-18 11:43:36.000000000,2017-02-17 06:01:38.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 17639}]","[{'number': 1, 'created': '2017-02-17 03:33:44.000000000', 'files': ['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/03933be4bcbdad4ac8dbadb60e58aa1df5279ea0', 'message': 'Add tags to newly created heat stacks\n\nThese tags will be used for event listeners that filter irrelevant\nstacks when checking stack failures. Previous commit has added\nstack listeners to health manager.\n\nPartial-Bug: 1657983\nChange-Id: I93052cf93184bb1cd82d2550657d2ed878ec5f1d\n'}]",0,435207,03933be4bcbdad4ac8dbadb60e58aa1df5279ea0,9,4,1,8246,,,0,"Add tags to newly created heat stacks

These tags will be used for event listeners that filter irrelevant
stacks when checking stack failures. Previous commit has added
stack listeners to health manager.

Partial-Bug: 1657983
Change-Id: I93052cf93184bb1cd82d2550657d2ed878ec5f1d
",git fetch https://review.opendev.org/openstack/senlin refs/changes/07/435207/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/heat/stack.py', 'senlin/tests/unit/profiles/test_heat_stack.py']",2,03933be4bcbdad4ac8dbadb60e58aa1df5279ea0,bug/1657983," node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' res = profile.do_create(node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ] node = mock.Mock(id='NODE_ID', cluster_id='CLUSTER_ID', index=123) node.name = 'test_node' node) 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID', 'cluster_node_index=123' ]", test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) test_stack = mock.Mock() test_stack.name = 'test_stack' res = profile.do_create(test_stack) stack_node = mock.Mock() stack_node.name = 'test_stack' stack_node) stack_node = mock.Mock() stack_node.name = 'test_stack' stack_node),46,15
openstack%2Fkolla~master~Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff,openstack/kolla,master,Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff,Updated from global requirements,MERGED,2017-02-10 05:50:22.000000000,2017-02-18 11:21:14.000000000,2017-02-18 11:21:14.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11869}]","[{'number': 1, 'created': '2017-02-10 05:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fb88865ff9491b44650c65cff9e44e1773ccc74e', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 2, 'created': '2017-02-11 00:16:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/c2806a5d4398144ac74bcebd512bafa42d884a9c', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 3, 'created': '2017-02-12 23:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ed53bf3a060e9b94d127a8761b78889daffd693f', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 4, 'created': '2017-02-14 09:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d5eef847e201664ccff723378650cd6996012496', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 5, 'created': '2017-02-15 01:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dee24b7425a9459e545cf34d28c3092fd3f99a9a', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 6, 'created': '2017-02-16 23:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bb7513aa3b2558edcde047b6e164c2014ec9aa5e', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 7, 'created': '2017-02-17 15:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/643d2daa7b16ec5b6b80d8fa4f6ffca5c5e8a12d', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}, {'number': 8, 'created': '2017-02-17 20:35:58.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6fd6c96c1451f7583f43ece096aa56f2329db721', 'message': 'Updated from global requirements\n\nChange-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff\n'}]",0,431961,6fd6c96c1451f7583f43ece096aa56f2329db721,22,3,8,11131,,,0,"Updated from global requirements

Change-Id: Ia0f519032e2d5e6b582e1f6fa56ed67b56c007ff
",git fetch https://review.opendev.org/openstack/kolla refs/changes/61/431961/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,fb88865ff9491b44650c65cff9e44e1773ccc74e,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Fopenstack-ansible-galera_server~stable%2Focata~I22d2f73ed97ce8e164c806b02cafdbe2d81ea893,openstack/openstack-ansible-galera_server,stable/ocata,I22d2f73ed97ce8e164c806b02cafdbe2d81ea893,Update repo for stable/ocata,MERGED,2017-02-08 10:39:45.000000000,2017-02-18 11:01:14.000000000,2017-02-18 11:01:14.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-08 10:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/edc3c6c2d0bf7a2cf3b5919dd15753ee12c5b10a', 'message': 'Update repo for stable/ocata\n\nChange-Id: I22d2f73ed97ce8e164c806b02cafdbe2d81ea893\n'}, {'number': 2, 'created': '2017-02-16 12:30:36.000000000', 'files': ['tests/ansible-role-requirements.yml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/a0cda27532845bec0361e7f6572f191eab8040bb', 'message': 'Update repo for stable/ocata\n\nChange-Id: I22d2f73ed97ce8e164c806b02cafdbe2d81ea893\n'}]",0,430722,a0cda27532845bec0361e7f6572f191eab8040bb,49,3,2,6816,,,0,"Update repo for stable/ocata

Change-Id: I22d2f73ed97ce8e164c806b02cafdbe2d81ea893
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/22/430722/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tox.ini']",2,edc3c6c2d0bf7a2cf3b5919dd15753ee12c5b10a,create-ocata, git clone -b stable/ocata https://git.openstack.org/openstack/openstack-ansible-tests {toxinidir}/tests/common; \ -rhttp://git.openstack.org/cgit/openstack/openstack-ansible-tests/plain/test-ansible-deps.txt?h=stable/ocata, git clone https://git.openstack.org/openstack/openstack-ansible-tests {toxinidir}/tests/common; \ -rhttp://git.openstack.org/cgit/openstack/openstack-ansible-tests/plain/test-ansible-deps.txt,8,8
openstack%2Fopenstack-ansible~stable%2Focata~I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b,openstack/openstack-ansible,stable/ocata,I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b,Cinder use correct glance API when RBD enabled,MERGED,2017-02-17 20:35:29.000000000,2017-02-18 11:00:35.000000000,2017-02-18 11:00:35.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 11268}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-17 20:35:29.000000000', 'files': ['playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/93e9ed78fb86f60e34744f017b9459c67142926f', 'message': 'Cinder use correct glance API when RBD enabled\n\nThe syntax of the jinja block was broken and outputted a line break\nalways, like this:\nok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {\n    ""msg"": ""True\\n""\n}\n\nSo the resulting evaluation was always false, and glance API v1 was\nused by cinder-volume, breaking the ceph CoW functionality.\n\nThis fixes the variable to eval properly as a boolean and make\nCinder use the correct glance API version.\n\nChange-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b\n'}]",0,435594,93e9ed78fb86f60e34744f017b9459c67142926f,8,4,1,7353,,,0,"Cinder use correct glance API when RBD enabled

The syntax of the jinja block was broken and outputted a line break
always, like this:
ok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {
    ""msg"": ""True\n""
}

So the resulting evaluation was always false, and glance API v1 was
used by cinder-volume, breaking the ceph CoW functionality.

This fixes the variable to eval properly as a boolean and make
Cinder use the correct glance API version.

Change-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/435594/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/group_vars/all.yml'],1,93e9ed78fb86f60e34744f017b9459c67142926f,cinder-rbd-fix,cinder_backends_rbd_inuse: >-,cinder_backends_rbd_inuse: >,1,1
openstack%2Fsenlin~stable%2Focata~Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e,openstack/senlin,stable/ocata,Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e,Validating adjustment properties for scaling policy,MERGED,2017-02-18 05:29:18.000000000,2017-02-18 10:44:25.000000000,2017-02-18 10:44:25.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 05:29:18.000000000', 'files': ['senlin/policies/scaling_policy.py', 'senlin/tests/unit/policies/test_scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/d67f0ef463c20545a854ce497b93f369cadcf9d6', 'message': ""Validating adjustment properties for scaling policy\n\nThis adds some logics to validate the property values specified for a\nscaling policy. When we migrate the policy schema to use, e.g. oslo\nversioned objects, we don't need to re-invent all these checks again and\nagain.\n\nChange-Id: Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e\n(cherry picked from commit 373cf4cf8aa0c75501af1cb35556fa034a5fda02)\n""}]",0,435660,d67f0ef463c20545a854ce497b93f369cadcf9d6,6,2,1,8246,,,0,"Validating adjustment properties for scaling policy

This adds some logics to validate the property values specified for a
scaling policy. When we migrate the policy schema to use, e.g. oslo
versioned objects, we don't need to re-invent all these checks again and
again.

Change-Id: Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e
(cherry picked from commit 373cf4cf8aa0c75501af1cb35556fa034a5fda02)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/60/435660/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/scaling_policy.py', 'senlin/tests/unit/policies/test_scaling_policy.py']",2,d67f0ef463c20545a854ce497b93f369cadcf9d6,validation-scaling-policy,"import sixfrom senlin.common import exception as exc def test_validate(self): self.spec['properties']['adjustment'] = {} policy = sp.ScalingPolicy('p1', self.spec) policy.validate(self.context) def test_validate_bad_number(self): self.spec['properties']['adjustment'] = {""number"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'number' for 'adjustment' must be > 0"", six.text_type(ex)) def test_validate_bad_min_step(self): self.spec['properties']['adjustment'] = {""min_step"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'min_step' for 'adjustment' must be >= 0"", six.text_type(ex)) def test_validate_bad_cooldown(self): self.spec['properties']['adjustment'] = {""cooldown"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'cooldown' for 'adjustment' must be >= 0"", six.text_type(ex)) ",,52,0
openstack%2Fsenlin~stable%2Focata~Iab6c93149c5c86dfe859caed3591bf7ec5592f85,openstack/senlin,stable/ocata,Iab6c93149c5c86dfe859caed3591bf7ec5592f85,Add support to REBOOT as a recovery action,MERGED,2017-02-18 05:29:32.000000000,2017-02-18 10:44:19.000000000,2017-02-18 10:44:19.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 05:29:32.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/common/consts.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/faa322be7156714ddc0071e78991f424fd9cb264', 'message': 'Add support to REBOOT as a recovery action\n\nThis adds REBOOT as a recovery action for health policy. The reboot\noperation has been added to the nova server profile type a while ago.\n\nChange-Id: Iab6c93149c5c86dfe859caed3591bf7ec5592f85\n(cherry picked from commit e029863372dcbae158b610152da090db1ddd2d4f)\n'}]",0,435661,faa322be7156714ddc0071e78991f424fd9cb264,6,2,1,8246,,,0,"Add support to REBOOT as a recovery action

This adds REBOOT as a recovery action for health policy. The reboot
operation has been added to the nova server profile type a while ago.

Change-Id: Iab6c93149c5c86dfe859caed3591bf7ec5592f85
(cherry picked from commit e029863372dcbae158b610152da090db1ddd2d4f)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/61/435661/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/common/consts.py']",3,faa322be7156714ddc0071e78991f424fd9cb264,health-policy-reboot,"DETECTION_TYPES = ( LIFECYCLE_EVENTS, NODE_STATUS_POLLING, # LB_STATUS_POLLING, 'LIFECYCLE_EVENTS', 'NODE_STATUS_POLLING', # 'LB_STATUS_POLLING',RECOVERY_ACTIONS = ( RECOVER_REBOOT, RECOVER_REBUILD, RECOVER_RECREATE, ) = ( 'REBOOT', 'REBUILD', 'RECREATE', )","DETECTION_TYPES = ( LIFECYCLE_EVENTS, NODE_STATUS_POLLING, # LB_STATUS_POLLING, ) = ( 'LIFECYCLE_EVENTS', 'NODE_STATUS_POLLING', # 'LB_STATUS_POLLING', ) RECOVER_OPERATIONS = ( RECOVER_RECREATE, RECOVER_REBUILD, 'RECREATE', 'REBUILD',",34,23
openstack%2Fsenlin~stable%2Focata~Ie0d3383a201635648ac8d90a25a200c9bec1257b,openstack/senlin,stable/ocata,Ie0d3383a201635648ac8d90a25a200c9bec1257b,Fix node get bug in docker profile,MERGED,2017-02-18 05:30:07.000000000,2017-02-18 10:44:14.000000000,2017-02-18 10:44:14.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-18 05:30:07.000000000', 'files': ['senlin/profiles/container/docker.py', 'senlin/tests/unit/profiles/test_container_docker.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/15def56965495f06ba4ba27bf2c0e30254778fe5', 'message': 'Fix node get bug in docker profile\n\nThis patch fixes node get bug in docker profile.\n\nCo-Authored-By: Qiming Teng (tengqim@cn.ibm.com)\nCloses-Bug: #1661862\n\nChange-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b\n(cherry picked from commit 3b42887a4d1e938b474cb96024e5427bee07c07a)\n'}]",0,435662,15def56965495f06ba4ba27bf2c0e30254778fe5,7,3,1,8246,,,0,"Fix node get bug in docker profile

This patch fixes node get bug in docker profile.

Co-Authored-By: Qiming Teng (tengqim@cn.ibm.com)
Closes-Bug: #1661862

Change-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b
(cherry picked from commit 3b42887a4d1e938b474cb96024e5427bee07c07a)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/62/435662/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/container/docker.py', 'senlin/tests/unit/profiles/test_container_docker.py']",2,15def56965495f06ba4ba27bf2c0e30254778fe5,bug/1661862," def test__get_host_node_found_by_node(self, mock_load): @mock.patch.object(dp.DockerProfile, '_get_random_node') def test__get_host_node_found_by_cluster(self, mock_get): node = mock.Mock() mock_get.return_value = node ctx = mock.Mock() profile = dp.DockerProfile('container', self.spec) res = profile._get_host(ctx, None, 'host_cluster') self.assertEqual(node, res) mock_get.assert_called_once_with(ctx, 'host_cluster') mock_cluster.assert_called_once_with(ctx, cluster_id='host_cluster') @mock.patch.object(context, 'get_service_context') @mock.patch.object(context, 'get_service_context') def test_do_create_failed(self, mock_docker, mock_ctx): mock_ctx.return_value = mock.Mock() mock_ctx.assert_called_once_with(project=obj.project, user=obj.user) "," def test__get_host_node_found(self, mock_load): @mock.patch.object(context, 'get_admin_context') def test_do_create_failed(self, mock_docker):",26,4
openstack%2Fsecurity-doc~master~Iab30228cc070cfbe7d263bde2ba93244596eb418,openstack/security-doc,master,Iab30228cc070cfbe7d263bde2ba93244596eb418,Updated from openstack-manuals,MERGED,2017-02-18 10:11:12.000000000,2017-02-18 10:29:54.000000000,2017-02-18 10:29:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-18 10:11:12.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/8342d6237ae9bf19ea67c15660067ad74929da04', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iab30228cc070cfbe7d263bde2ba93244596eb418\n'}]",0,435689,8342d6237ae9bf19ea67c15660067ad74929da04,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Iab30228cc070cfbe7d263bde2ba93244596eb418
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/89/435689/1 && git format-patch -1 --stdout FETCH_HEAD,['common/source/locale/ja/LC_MESSAGES/common.po'],1,8342d6237ae9bf19ea67c15660067ad74929da04,openstack/openstack-manuals,"""POT-Creation-Date: 2017-02-17 23:19+0000\n""","""POT-Creation-Date: 2017-02-14 22:14+0000\n""""An open source community project by Dell that aims to provide all necessary "" ""services to quickly deploy clouds."" msgstr """" ""クラウドの迅速なデプロイ用に全ての必要なサービスを提供する用途の、Dell による"" ""オープンソースコミュニティプロジェクト。"" msgid """"",1,8
openstack%2Fec2-api~stable%2Focata~I32f15a66bddecf6be8bb308b4930756c88b4ab2e,openstack/ec2-api,stable/ocata,I32f15a66bddecf6be8bb308b4930756c88b4ab2e,initial commit to stable/ocata,MERGED,2017-02-17 15:28:55.000000000,2017-02-18 10:27:13.000000000,2017-02-18 10:27:13.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}]","[{'number': 1, 'created': '2017-02-17 15:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/36ff47149563fcc820850450092beeabb986b9b7', 'message': 'initial commit to stable/ocata\n\nChange-Id: I32f15a66bddecf6be8bb308b4930756c88b4ab2e\n'}, {'number': 2, 'created': '2017-02-18 06:58:50.000000000', 'files': ['requirements.txt', '.gitreview', 'README.rst'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/c52d7b945840899199f7d599cbf2dfe25e108926', 'message': 'initial commit to stable/ocata\n\nChange-Id: I32f15a66bddecf6be8bb308b4930756c88b4ab2e\n'}]",0,435488,c52d7b945840899199f7d599cbf2dfe25e108926,17,4,2,10234,,,0,"initial commit to stable/ocata

Change-Id: I32f15a66bddecf6be8bb308b4930756c88b4ab2e
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/88/435488/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', '.gitreview']",2,36ff47149563fcc820850450092beeabb986b9b7,,defaultbranch=stable/ocata,,2,1
openstack%2Fkolla~master~Iae3c4973d7bca406ca13c4db858f5258ae30b08a,openstack/kolla,master,Iae3c4973d7bca406ca13c4db858f5258ae30b08a,Update reno for stable/ocata,MERGED,2017-02-15 10:33:32.000000000,2017-02-18 10:26:29.000000000,2017-02-18 10:26:29.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 11869}, {'_account_id': 22165}]","[{'number': 1, 'created': '2017-02-15 10:33:32.000000000', 'files': ['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/238050d24f5f27f6166a505a0044524c8bcd6002', 'message': 'Update reno for stable/ocata\n\nChange-Id: Iae3c4973d7bca406ca13c4db858f5258ae30b08a\n'}]",0,434207,238050d24f5f27f6166a505a0044524c8bcd6002,8,4,1,22816,,,0,"Update reno for stable/ocata

Change-Id: Iae3c4973d7bca406ca13c4db858f5258ae30b08a
",git fetch https://review.opendev.org/openstack/kolla refs/changes/07/434207/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst']",2,238050d24f5f27f6166a505a0044524c8bcd6002,reno-ocata, ocata,,7,0
openstack%2Fdragonflow~master~I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6,openstack/dragonflow,master,I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6,Refactor port-status-update NB API,MERGED,2016-11-13 03:31:26.000000000,2017-02-18 10:24:01.000000000,2017-02-18 10:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 9044}, {'_account_id': 11159}, {'_account_id': 13912}, {'_account_id': 18903}, {'_account_id': 20229}, {'_account_id': 20287}, {'_account_id': 20297}, {'_account_id': 22060}, {'_account_id': 23766}]","[{'number': 1, 'created': '2016-11-13 03:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bb8151e18d07b5aef259e31209f799de97deb690', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\n'}, {'number': 2, 'created': '2016-11-13 03:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dc617e30eb3496b12cd20412590aa93863571dd2', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: refactor-port-status-update\n'}, {'number': 3, 'created': '2016-11-13 03:34:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/48fe55622d4cd5d2778be84b1699d5e70d3003d1', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: https://blueprints.launchpad.net/dragonflow/+spec/refactor-port-status-update\n'}, {'number': 4, 'created': '2016-11-13 03:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a34d9d38678ef0bbb7ae202de41408617582812d', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 5, 'created': '2016-11-13 14:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ba5ff21107cbc771781ad6f951756d15a6f55976', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 6, 'created': '2016-11-14 14:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3f7943e2f1491231e79884d3edb05f367f0410a8', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n4. Implement neutron heart-beat\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 7, 'created': '2016-11-15 16:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/99276c74edcb95fabaec019f09d724e08c1a5b16', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n4. Implement neutron heart-beat\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 8, 'created': '2016-11-16 15:08:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bdbedacb023e4e34994474ffe7381e110566ff41', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n4. Implement neutron heart-beat\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 9, 'created': '2016-11-16 15:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e9efc1b7b8a4c4d21105082b31e977049a3e056d', 'message': 'Refactor port-status-update NB API\n\n1. Rename table portstats to n_listener, which means neutron\nlistener\n2. Make the port-status API consistent with other APIs\n3. Add timestamp to n_listener table\n4. Implement neutron heart-beat\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n'}, {'number': 10, 'created': '2016-11-19 08:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dab64b17b0e047d55d8aa987a98ff510e169fb1f', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 11, 'created': '2016-11-19 08:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5b34293ce7b77bde0b2dbfda11df0dc354743497', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 12, 'created': '2016-11-20 05:57:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1dca2db3ac5e5b905dd6d91d7487a958f4ad7611', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 13, 'created': '2016-11-21 15:17:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/169ace831e36304671bd6d9c58215c071fa64ba6', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 14, 'created': '2016-11-21 15:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/be7ea4fc3e503e1cda9a013193c7e5ee015c9f6f', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 15, 'created': '2016-11-22 06:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ca6a0a7e6f68ac5b664060364fe9179a9d18aced', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 16, 'created': '2016-11-22 06:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/78a17f82e1b297cc25dfde8530cd53bcc4de47f5', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\n3. redis_port_status_notifier.py does not call redis client directly,\nand it calls api_nb.py. This is not correct, because api_nb is the\nabstract of all df-db drivers.\n\nThis patch remove redis_port_status_notifier.py and makes api_nb\nsupport neutron listener(port-status), this means all df-db backends\nsupport neutron listener and port-status\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\n""}, {'number': 17, 'created': '2016-11-27 16:03:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2a5dc17f335983dbfb745efe3e9b239f63767c15', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 18, 'created': '2016-11-27 16:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bdab26474971f5c07c6f2ab95a108176c4280289', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 19, 'created': '2016-11-27 16:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d9206a45d2f03362a43cbc230711f26b9bf9f2d7', 'message': ""Refactor port-status-update NB API\n\n1. Currently, when there are more than one neutron-server workers\non a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Currently neutron-servers only register itself to df-db, but\nwill not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 20, 'created': '2016-11-30 14:07:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c8d74a62157bf75651cdba0925e348a609d4fea6', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 21, 'created': '2016-11-30 15:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f7aa2dc7bba5f4a493ef222b100f081d2dcdc471', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribe the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 22, 'created': '2016-11-30 15:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6c15d3f9fd3aac8b523c174ba0bdef382dcc45e9', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, The df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 23, 'created': '2016-11-30 15:59:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f45287f3f9eb6d9b16a08c7062e25aab8a40051d', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 24, 'created': '2016-12-01 01:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/34d84aee3c0565799607c294528547283d372a2f', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 25, 'created': '2016-12-03 14:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/47360f09ab6cf97189f3e70f0dc97ed0e98c42e7', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 26, 'created': '2016-12-03 14:12:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b700a52e1d9c88fb7b32ed04d8c66f7d366d22b7', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 27, 'created': '2016-12-05 10:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c19b0722566e2b2f27b7b62f112a4a90c5cef1cf', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 28, 'created': '2016-12-05 11:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c33a9edaf249b093b080fbd9995857cc69a8611a', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 29, 'created': '2016-12-05 11:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/060b8706726a00afc950a5fb4defbdbf1cf58972', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 30, 'created': '2016-12-08 01:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6126462f32cb66030b29ce47b110552a2c3ed5cc', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 31, 'created': '2016-12-09 01:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/dc19b81b171d1788e968b97f725ee4d76f26ef22', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 32, 'created': '2016-12-09 01:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/82cd01f25cccc7f767b75f29e970d8c46841b6e3', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 33, 'created': '2016-12-13 09:56:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8c77e2bda9c91a7ebd37d0a8fa693a40ba008515', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 34, 'created': '2016-12-13 12:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9083fa662581b9fc4ce344282ae4aec244c80030', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 35, 'created': '2016-12-14 11:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e3fcc592d1051516786f5772498e6be7049b7efb', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 36, 'created': '2016-12-15 01:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b89aa93301b111c465af0c387fb3b69be8716355', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 37, 'created': '2016-12-15 01:25:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/19284410a627ccbddcc12e627bc8ffd02e3e2e82', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 38, 'created': '2016-12-18 06:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c6a404fe654607b03eb4801847bd5e2e5c3ab03e', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 39, 'created': '2016-12-18 07:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0d98a7e341765d440be63dfda8ee360a814ddf08', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every each worker holds a port_status_notifier\ninstance and each of them subscribes the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 40, 'created': '2016-12-19 11:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1bd8e07ea29df60f013183483774daf641a0abd0', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 41, 'created': '2016-12-20 05:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/042cfb1a5e3e707c712353d6a1debf71aba5a8eb', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 42, 'created': '2016-12-20 05:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/303cea878e087a21d358f98684bfa56477dc24aa', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 43, 'created': '2016-12-20 10:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a055a14b0f6b86c98dbc36871b6ee13eb3b880d6', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 44, 'created': '2016-12-21 13:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0f54a6a6f1278fb60c900428f6cfd21213842589', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 45, 'created': '2016-12-28 06:49:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3f11126f32c652a206fcd09b9eae8971c86ea8c5', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 46, 'created': '2016-12-29 12:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f4ee72e08e5cc1b7df00dbb8c3648df41b94bbec', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 47, 'created': '2016-12-29 12:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/052a47b932af5a93efa2cc71e35f2a16854cca48', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 48, 'created': '2017-01-03 07:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/87d153f475748272a5851fffc934044fa6276577', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 49, 'created': '2017-01-03 08:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5a6f94a66e5a936f4a16d83827500185d7aeae6d', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 50, 'created': '2017-01-08 03:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/677ea2f4776aeaeb71788c4868e6f9d49e61228e', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 51, 'created': '2017-01-10 12:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2ed8c5588298ac7eae27bff91cf08de224b60beb', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 52, 'created': '2017-01-18 09:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d675f6b75f5faafb22d34544f0c7ac3e9362408a', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 53, 'created': '2017-01-18 11:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bc2ecbe81c1bb0116f0c58a26f9d5fbeb68e4ebd', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 54, 'created': '2017-02-03 07:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a3ada5c807a391b7a8e2b46757d997efb20d2af7', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 55, 'created': '2017-02-10 07:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bc0767ff66406e0ff41d16b9aaeac2943ac94cd7', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 56, 'created': '2017-02-11 23:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/144785601c702b125e41dc292cf1ea2427d32791', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 57, 'created': '2017-02-13 09:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/45d2561bcf58beba120b88c7c6c5868afb0fcb06', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 58, 'created': '2017-02-14 00:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f2f2e710009faa625583b345fd6ad00676c88006', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 59, 'created': '2017-02-15 02:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/184500dcc63b77c298ce5d23c8278bd6c36e3d54', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 60, 'created': '2017-02-15 06:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/691349943424a1f16048ad2bbaf38dde43e9303d', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 61, 'created': '2017-02-16 02:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/de9447060d1aba5a56c0ce881c6d825c7cad6a8a', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 62, 'created': '2017-02-16 03:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a8f6d4fb422fb00eff28a0d8a28964feeeb0c149', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}, {'number': 63, 'created': '2017-02-16 12:16:26.000000000', 'files': ['dragonflow/db/api_nb.py', 'dragonflow/conf/df_common_params.py', 'dragonflow/db/neutron/lockedobjects_db.py', 'dragonflow/tests/unit/test_redis_port_status.py', 'dragonflow/controller/topology.py', 'dragonflow/db/port_status_api.py', 'dragonflow/tests/common/utils.py', 'dragonflow/db/models.py', 'dragonflow/tests/unit/test_mech_driver.py', 'dragonflow/neutron/ml2/mech_driver.py', 'dragonflow/controller/df_local_controller.py', 'dragonflow/tests/fullstack/test_api_nb.py', 'dragonflow/db/pubsub_drivers/redis_port_status_notifier.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7b98d1e573288475e28d058d74feb7e238c23c4b', 'message': ""Refactor port-status-update NB API\n\n1. Before this patch, when there are more than one neutron-server\nworkers on a single node, every worker holds a port_status_notifier\ninstance and each of them subscribes to the same topic because they\nare on the same node. This is not necessary.\n\nThis patch makes sure there is only one neutron-server worker\nsubscribe to the topic(hostname of the node) no matter how many\nworkers are created. Say this neutron-server is neutron listener\non the node\n\n2. Before this patch, neutron-servers only register itself to df-db,\nbut not update it with a timestamp periodically. When there is a\nevent(e.g port-status up/down) to send, the df controller chooses\na neutron-server randomly without caring it is dead or alive.\n\nThis patch makes the neutron listeners reports its heart-beat with\na timestamp periodically. When a df controller wants to send a\nnotification, it gets all the listeners from df-db and sort them by\nthe timestamp, then chooses from the lastest 50% neutron listeners.\nThis can help to avoid chooing a dead one as far as possible\n\nFor now, we don't remove neutron listeners from df-db automatically.\nBut admins can do it manually.\n\nCo-Authored-By: hujie <mike.hu@huawei.com>\n\nChange-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6\nPartially-implements: blueprint refactor-port-status-update\nCloses-Bug: #1636714\n""}]",131,396915,7b98d1e573288475e28d058d74feb7e238c23c4b,201,12,63,9044,,,0,"Refactor port-status-update NB API

1. Before this patch, when there are more than one neutron-server
workers on a single node, every worker holds a port_status_notifier
instance and each of them subscribes to the same topic because they
are on the same node. This is not necessary.

This patch makes sure there is only one neutron-server worker
subscribe to the topic(hostname of the node) no matter how many
workers are created. Say this neutron-server is neutron listener
on the node

2. Before this patch, neutron-servers only register itself to df-db,
but not update it with a timestamp periodically. When there is a
event(e.g port-status up/down) to send, the df controller chooses
a neutron-server randomly without caring it is dead or alive.

This patch makes the neutron listeners reports its heart-beat with
a timestamp periodically. When a df controller wants to send a
notification, it gets all the listeners from df-db and sort them by
the timestamp, then chooses from the lastest 50% neutron listeners.
This can help to avoid chooing a dead one as far as possible

For now, we don't remove neutron listeners from df-db automatically.
But admins can do it manually.

Co-Authored-By: hujie <mike.hu@huawei.com>

Change-Id: I9f643e95dc4da1d9ff5b2ee27729a293ff7f47e6
Partially-implements: blueprint refactor-port-status-update
Closes-Bug: #1636714
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/15/396915/21 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/cli/df_db.py', 'dragonflow/db/api_nb.py', 'dragonflow/db/pubsub_drivers/redis_port_status_notifier.py']",3,bb8151e18d07b5aef259e31209f799de97deb690,bug/1636714,"import random listeners = self.nb_api.get_all_neutron_listener() topic = random.choice(listeners) # In n_listerner table, there are key value pairs like this: # port_status_192.168.1.10 : {'ip':192.168.1.10, timestamp: 100} # where timestamp is seconds since the epoch. # TODO(wangjian): df-controllers can sort neutron-listeners by timestamp, # so that it can avoid to choose a dead neutron-listerner as far as possible self.nb_api.create_neutron_listener(server_ip, int(time.time()))"," topic = self.nb_api.get_all_port_status_keys() # In portstats table, there are key value pairs like this: # port_status_192.168.1.10 : 192.168.1.10 self.nb_api.create_port_status(server_ip)",30,13
openstack%2Fdragonflow~master~I285683253a909247553b2c3abb93b7428b874cbc,openstack/dragonflow,master,I285683253a909247553b2c3abb93b7428b874cbc,Add get_number_of_agents_for_scheduling to DFL3RouterPlugin,MERGED,2017-02-16 15:58:37.000000000,2017-02-18 10:23:55.000000000,2017-02-18 10:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}]","[{'number': 1, 'created': '2017-02-16 15:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4f29afac44455fc3d528b56be22e62ef6da653d8', 'message': ""Add get_number_of_agents_for_scheduling to DFL3RouterPlugin\n\nThe method `get_number_of_agents_for_scheduling` is expected by Neutron\ncode, but does not exist in DFL3RouterPlugin. It does exist in\nL3_HA_NAT_db_mixin, but that includes a DVR mixin which shouldn't be\nused.\n\nThis change re-implements get_number_of_agents_for_scheduling as it\nappears in L3_HA_NAT_db_mixin. That should resolve the related bug\ncomplaining that it doesn't exist.\n\nChange-Id: I285683253a909247553b2c3abb93b7428b874cbc\nCloses-Bug: #1664922\n""}, {'number': 2, 'created': '2017-02-16 19:11:47.000000000', 'files': ['dragonflow/neutron/services/l3_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a64ebabcb0f2e0d84986fef22f76f32e7e6d972d', 'message': ""Add get_number_of_agents_for_scheduling to DFL3RouterPlugin\n\nThe method `get_number_of_agents_for_scheduling` is expected by Neutron\ncode, but does not exist in DFL3RouterPlugin. It does exist in\nL3_HA_NAT_db_mixin, but that includes a DVR mixin which shouldn't be\nused.\n\nThis change re-implements get_number_of_agents_for_scheduling as it\nappears in L3_HA_NAT_db_mixin. That should resolve the related bug\ncomplaining that it doesn't exist.\n\nChange-Id: I285683253a909247553b2c3abb93b7428b874cbc\nCloses-Bug: #1664922\n""}]",0,434983,a64ebabcb0f2e0d84986fef22f76f32e7e6d972d,11,4,2,20229,,,0,"Add get_number_of_agents_for_scheduling to DFL3RouterPlugin

The method `get_number_of_agents_for_scheduling` is expected by Neutron
code, but does not exist in DFL3RouterPlugin. It does exist in
L3_HA_NAT_db_mixin, but that includes a DVR mixin which shouldn't be
used.

This change re-implements get_number_of_agents_for_scheduling as it
appears in L3_HA_NAT_db_mixin. That should resolve the related bug
complaining that it doesn't exist.

Change-Id: I285683253a909247553b2c3abb93b7428b874cbc
Closes-Bug: #1664922
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/83/434983/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/neutron/services/l3_router_plugin.py'],1,4f29afac44455fc3d528b56be22e62ef6da653d8,bug/1664922,"from dragonflow._i18n import _LE, _LI def get_number_of_agents_for_scheduling(self, context): """"""Return number of agents on which the router will be scheduled. Taken from Neutron's L3_HA_NAT_db_mixin. """""" l3_agents_filters = {'agent_modes': [const.L3_AGENT_MODE_LEGACY, const.L3_AGENT_MODE_DVR_SNAT]} num_agents = len(self.get_l3_agents(context, active=True, filters=l3_agents_filters)) max_agents = cfg.CONF.max_l3_agents_per_router if max_agents: if max_agents > num_agents: LOG.info(_LI(""Number of active agents lower than "" ""max_l3_agents_per_router. L3 agents "" ""available: %s""), num_agents) else: num_agents = max_agents return num_agents",from dragonflow._i18n import _LE,21,1
openstack%2Fopenstack-manuals~master~I67f7fdb66dc8af699b57128a4812d663bf5df57c,openstack/openstack-manuals,master,I67f7fdb66dc8af699b57128a4812d663bf5df57c,Imported Translations from Zanata,MERGED,2017-02-18 09:17:38.000000000,2017-02-18 10:05:59.000000000,2017-02-18 10:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-18 09:17:38.000000000', 'files': ['doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/common/source/locale/zh_CN/LC_MESSAGES/common.po', 'doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/common/source/locale/vi_VN/LC_MESSAGES/common.po', 'doc/common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/30527d6d7896b09a51764b6799693f0503932cef', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: I67f7fdb66dc8af699b57128a4812d663bf5df57c\n'}]",0,435676,30527d6d7896b09a51764b6799693f0503932cef,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: I67f7fdb66dc8af699b57128a4812d663bf5df57c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/76/435676/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/source/locale/id/LC_MESSAGES/common.po', 'doc/ops-guide/source/locale/ja/LC_MESSAGES/ops-guide.po', 'doc/common/source/locale/ru/LC_MESSAGES/common.po', 'doc/common/source/locale/zh_CN/LC_MESSAGES/common.po', 'doc/common/source/locale/ko_KR/LC_MESSAGES/common.po', 'doc/common/source/locale/de/LC_MESSAGES/common.po', 'doc/common/source/locale/vi_VN/LC_MESSAGES/common.po', 'doc/common/source/locale/ja/LC_MESSAGES/common.po']",8,30527d6d7896b09a51764b6799693f0503932cef,zanata/translations,"""POT-Creation-Date: 2017-02-17 23:19+0000\n""","""POT-Creation-Date: 2017-02-14 22:14+0000\n""""An open source community project by Dell that aims to provide all necessary "" ""services to quickly deploy clouds."" msgstr """" ""クラウドの迅速なデプロイ用に全ての必要なサービスを提供する用途の、Dell による"" ""オープンソースコミュニティプロジェクト。"" msgid """"",211,81
openstack%2Fopenstack-manuals~stable%2Fnewton~Ice87086b32996c84750e493912e4ef2c46786607,openstack/openstack-manuals,stable/newton,Ice87086b32996c84750e493912e4ef2c46786607,Imported Translations from Zanata,MERGED,2017-02-18 09:22:59.000000000,2017-02-18 10:00:24.000000000,2017-02-18 10:00:24.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-18 09:22:59.000000000', 'files': ['doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e9d309bbe9bdb9b83a023d4487a51f392adddce0', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttp://docs.openstack.org/developer/i18n/reviewing-translation-import.html\n\nChange-Id: Ice87086b32996c84750e493912e4ef2c46786607\n'}]",0,435677,e9d309bbe9bdb9b83a023d4487a51f392adddce0,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
http://docs.openstack.org/developer/i18n/reviewing-translation-import.html

Change-Id: Ice87086b32996c84750e493912e4ef2c46786607
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/77/435677/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/de/LC_MESSAGES/install-guide.po'],1,e9d309bbe9bdb9b83a023d4487a51f392adddce0,zanata/translations,"""POT-Creation-Date: 2017-02-16 10:53+0000\n""""PO-Revision-Date: 2017-02-17 11:00+0000\n""msgid ""Change the existing line from ``127.0.0.1``."" msgstr ""Ändern Sie das ``127.0.0.1`` in der vorhandenen Zeile."" msgid ""Change the existing line that had ``-l 127.0.0.1``."" msgstr ""Ändern Sie die bestehende Zeile, die ``-l 127.0.0.1`` enthielt."" msgid """" ""Edit the ``/etc/memcached.conf`` file and configure the service to use the "" ""management IP address of the controller node. This is to enable access by "" ""other nodes via the management network:"" msgstr """" ""Bearbeiten Sie die Datei ``/etc/memcached.conf`` und konfigurieren den "" ""Dienst so, dass die IP-Adresse des Managementnetzwerks des Controller-"" ""Knotens genutzt wird, um andere Knoten Zugriff über das Managementnetzwerk "" ""zu ermöglichen."" ""Edit the ``/etc/sysconfig/memcached`` file and configure the service to use "" ""the management IP address of the controller node. This is to enable access "" ""by other nodes via the management network:"" msgstr """" ""Bearbeiten Sie die Datei ``/etc/sysconfig/memcached`` und konfigurieren den "" ""Dienst so, dass die IP-Adresse des Managementnetzwerks des Controller-"" ""Knotens genutzt wird, um anderen Knoten den Zugriff über das "" ""Managementnetzwerk zu ermöglichen."" msgid """"","""POT-Creation-Date: 2017-02-15 14:35+0000\n""""PO-Revision-Date: 2017-02-13 03:12+0000\n""",28,2
openstack%2Fsenlin~stable%2Focata~I87311a316549279a77fd5a71dcfe0bb72722355f,openstack/senlin,stable/ocata,I87311a316549279a77fd5a71dcfe0bb72722355f,User reference documentation for health policy,MERGED,2017-02-18 05:29:07.000000000,2017-02-18 09:59:09.000000000,2017-02-18 09:59:09.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 05:29:07.000000000', 'files': ['doc/source/user/policy_types/health.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/83b046ad9b2aba05e8e8a8685b115273c891ddae', 'message': 'User reference documentation for health policy\n\nThis is a first draft for the health policy reference. More contents\nwill be added/modified as the development makes progress.\n\nChange-Id: I87311a316549279a77fd5a71dcfe0bb72722355f\n(cherry picked from commit 6f37c468285ee03014b9bafde9a2452a5831d8a5)\n'}]",0,435659,83b046ad9b2aba05e8e8a8685b115273c891ddae,6,2,1,8246,,,0,"User reference documentation for health policy

This is a first draft for the health policy reference. More contents
will be added/modified as the development makes progress.

Change-Id: I87311a316549279a77fd5a71dcfe0bb72722355f
(cherry picked from commit 6f37c468285ee03014b9bafde9a2452a5831d8a5)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/59/435659/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/health.rst'],1,83b046ad9b2aba05e8e8a8685b115273c891ddae,ref-health-policy,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _ref-health-policy: ============= Health Policy ============= The health policy is designed for Senlin to detect cluster node failures and to recover them in a way customizable by users. The health policy is not meant to be an universal solution that can solve all problems related to high-availability. However, the ultimate goal for the development team is to provide an auto-healing framework that is usable, flexible, extensible for most deployment scenarios. The policy type is currently applicable to clusters whose profile type is one of ``os.nova.server`` or ``os.heat.stack``. This could be extended in future. .. note:: The health policy is still under rapid development. More features are being designed, implemented and verified. Its support status is still ``EXPERIMENTAL``, which means there could be changes at the discretion of the development team before it is formally supported. Properties ~~~~~~~~~~ A typical spec for a health policy looks like the following example: .. code-block:: yaml type: senlin.policy.health version: 1.0 properties: detection: type: NODE_STATUS_POLLING options: interval: 60 recovery: actions: - name: REBOOT params: type: soft fencing: - compute There are two groups of properties (``detection`` and ``recovery``), each of which provides information related to the failure detection and the failure recovery aspect respectively. For failure detection, you can specify one of the following two values: - ``NODE_STATUS_POLLING``: Senlin engine (more specifically, the health manager service) is expected to poll each and every nodes periodically to find out if they are ""alive"" or not. - ``LIFECYCLE_EVENTS``: Many services can emit notification messages on the message queue when configured. Senlin engine is expected to listen to these events and react to them appropriately. Both detection types can carry an optional map of ``options``. When the detection type is set to ""``NODE_STATUS_POLLING``"", for example, you can specify a value for ``interval`` property to customize the frequency at which your cluster nodes are polled. As the policy type implementation stabilizes, more options may be added later. For failure recovery, there are currently two properties: ``actions`` and ``fencing``. The ``actions`` property takes a list of action names and an optional map of parameters specific to that action. For example, the ``REBOOT`` action can be accompanied with a ``type`` parameter that indicates if the intended reboot operation is a soft reboot or a hard reboot. .. note:: The plan for recovery actions is to support a list of actions which can be tried one by one by the Senlin engine. Currently, you can specify only *one* action due to implementation limitation. Another extension to the recovery action is to add triggers to user provided workflows. This is also under development. Validation ~~~~~~~~~~ Due to implementation limitation, currently you can only specify *one* action for the ``recovery.actions`` property. This constraint will be removed soon after the support to action list is completed. Fencing ~~~~~~~ Fencing may be an important step during a reliable node recovery process. Without fencing, we cannot ensure that the compute, network and/or storage resources are in a consistent, predictable status. However, fencing is very difficult because it always involves an out-of-band operation to the resource controller, for example, an IPMI command to power off a physical host sent to a specific IP address. Currently, the health policy only supports the fencing of virtual machines by forcibly delete it before taking measures to recover it. Snapshots ~~~~~~~~~ There have been some requirements to take snapshots of a node before recovery so that the recovered node(s) will resume from where they failed. This feature is also on the TODO list for the development team. ",,126,0
openstack%2Fheat~master~If68dc4840f99e852a5d2af53812661b3fc0aab55,openstack/heat,master,If68dc4840f99e852a5d2af53812661b3fc0aab55,Use keystone v3 and session for swiftclient,MERGED,2017-02-15 02:50:25.000000000,2017-02-18 09:41:32.000000000,2017-02-18 09:41:32.000000000,"[{'_account_id': 3}, {'_account_id': 7385}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12404}]","[{'number': 1, 'created': '2017-02-15 02:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c4679f48ada5c77626afa429042a66d688789602', 'message': 'Use keystone v3 and session for swiftclient\n\nAllow for using keystone v3 and session with swiftclient\nin integration tests.\n\nChange-Id: If68dc4840f99e852a5d2af53812661b3fc0aab55\n'}, {'number': 2, 'created': '2017-02-15 08:27:27.000000000', 'files': ['heat_integrationtests/common/clients.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/3188ea0f17da668afa1580def93ce9f17b690854', 'message': 'Use keystone v3 and session for swiftclient\n\nAllow for using keystone v3 and session with swiftclient\nin integration tests.\n\nThis also cleans up some unnecessary arguments passed to clients.\n\nChange-Id: If68dc4840f99e852a5d2af53812661b3fc0aab55\n'}]",4,434036,3188ea0f17da668afa1580def93ce9f17b690854,11,5,2,8833,,,0,"Use keystone v3 and session for swiftclient

Allow for using keystone v3 and session with swiftclient
in integration tests.

This also cleans up some unnecessary arguments passed to clients.

Change-Id: If68dc4840f99e852a5d2af53812661b3fc0aab55
",git fetch https://review.opendev.org/openstack/heat refs/changes/36/434036/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/common/clients.py'],1,c4679f48ada5c77626afa429042a66d688789602,test_cleanup," region_name=self.conf.region, service_type='network', region_name=self.conf.region, endpoint_type='publicURL') endpoint_type='publicURL', region_name=self.conf.region, 'session': self.identity_client.session, 'os_options': {'endpoint_type': 'publicURL', 'region_name': self.conf.region, 'service_type': 'object-store'},"," region = self.conf.region region_name=region, insecure=self.insecure, cacert=self.ca_file, endpoint_type='publicURL', insecure=self.insecure, ca_cert=self.ca_file) region = self.conf.region endpoint_type = 'publicURL' region_name=region, endpoint_type=endpoint_type, insecure=self.insecure, cacert=self.ca_file, 'tenant_name': self._tenant_name(), 'user': self._username(), 'key': self.conf.password, 'authurl': self.conf.auth_url, 'os_options': {'endpoint_type': 'publicURL'}, 'insecure': self.insecure, 'cacert': self.ca_file, 'insecure': self.insecure, 'cacert': self.ca_file,",10,23
openstack%2Fopenstack-ansible~master~Ie1435e6cc05eea840e121ce66935aed8ca879c7a,openstack/openstack-ansible,master,Ie1435e6cc05eea840e121ce66935aed8ca879c7a,Integration of dragonflow in integrated gate,MERGED,2016-10-28 15:50:32.000000000,2017-02-18 09:41:11.000000000,2017-02-17 20:22:10.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-10-28 15:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1e9af1a9b0f5fea1ce0bcaa84a493eef96b251d6', 'message': '[WIP] Integration of dragonflow inventory in integrated gate\n\nThis has to be done after the work done in neutron role.\n\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}, {'number': 2, 'created': '2017-01-26 11:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cf1e78388147b7448925ca3f9e92738a8e215b8d', 'message': 'Integration of dragonflow inventory in integrated gate\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}, {'number': 3, 'created': '2017-01-26 14:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c32ffad2b9f04bf847a5ccc6055efda2cf1cbd96', 'message': 'Integration of dragonflow in integrated gate\n\nInventory needs a change of env.d/nova and neutron, and will be\ndocumented in the neutron role.\n\nThis only makes possible to install the pip packages required by\ndragonflow. It should be enough to allow the installation of dragonflow.\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}, {'number': 4, 'created': '2017-02-13 08:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e8f2ffb85726b07fe1f2255f3c368fbd8559d82e', 'message': 'Integration of dragonflow in integrated gate\n\nInventory needs a change of env.d/nova and neutron, and will be\ndocumented in the neutron role.\n\nThis only makes possible to install the pip packages required by\ndragonflow. It should be enough to allow the installation of dragonflow.\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}, {'number': 5, 'created': '2017-02-16 20:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ee882e787d968885d0bd9fb74d599f0678acc686', 'message': 'Integration of dragonflow in integrated gate\n\nInventory needs a change of env.d/nova and neutron, and will be\ndocumented in the neutron role.\n\nThis only makes possible to install the pip packages required by\ndragonflow. It should be enough to allow the installation of dragonflow.\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}, {'number': 6, 'created': '2017-02-17 15:39:12.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f5d6475260150ed44a08f002c528170c82643973', 'message': 'Integration of dragonflow in integrated gate\n\nInventory needs a change of env.d/nova and neutron, and will be\ndocumented in the neutron role.\n\nThis only makes possible to install the pip packages required by\ndragonflow. It should be enough to allow the installation of dragonflow.\n\nDepends-On: Id5184845d18461c6c37a560cdc0404c8a487c020\nCo-Authored-By: Omer Anson <omer.anson@toganetworks.com>\nChange-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a\n'}]",0,391522,f5d6475260150ed44a08f002c528170c82643973,34,6,6,17068,,,0,"Integration of dragonflow in integrated gate

Inventory needs a change of env.d/nova and neutron, and will be
documented in the neutron role.

This only makes possible to install the pip packages required by
dragonflow. It should be enough to allow the installation of dragonflow.

Depends-On: Id5184845d18461c6c37a560cdc0404c8a487c020
Co-Authored-By: Omer Anson <omer.anson@toganetworks.com>
Change-Id: Ie1435e6cc05eea840e121ce66935aed8ca879c7a
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/22/391522/6 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/env.d/nova.yml'],1,1e9af1a9b0f5fea1ce0bcaa84a493eef96b251d6,dragonflow_initial_work, - neutron_dragonflow_agent,,1,0
openstack%2Fopenstack-ansible-os_trove~master~If853b0e1e45b7137572df8a1123273539343c83e,openstack/openstack-ansible-os_trove,master,If853b0e1e45b7137572df8a1123273539343c83e,Configure trove_conductor_workers in os_trove,MERGED,2017-02-17 07:24:11.000000000,2017-02-18 09:40:50.000000000,2017-02-17 20:52:25.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8662}, {'_account_id': 14806}, {'_account_id': 22111}, {'_account_id': 22981}]","[{'number': 1, 'created': '2017-02-17 07:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/5fd0831f03589ea4110969e541da7bb534cb7fb6', 'message': 'Configure trove_conductor_workers in os_trove\n\nConfigure trove_conductor_workers by calculating the default value.\nSimilar to other services worker threads, the default value for\ntrove_conductor_workers is half the number of vcpus on the machine.\n\nChange-Id: If853b0e1e45b7137572df8a1123273539343c83e\nCloses-Bug: #1664639\n'}, {'number': 2, 'created': '2017-02-17 08:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/d8948ad0ba5ee813b7c952f39606f83cc4392e40', 'message': 'Configure trove_conductor_workers in os_trove\n\nConfigure trove_conductor_workers by calculating the default value.\nSimilar to other services worker threads, the default value for\ntrove_conductor_workers is half the number of vcpus on the machine.\n\nAlso added capping of worker threads for trove.\n\nChange-Id: If853b0e1e45b7137572df8a1123273539343c83e\nCloses-Bug: #1664639\n'}, {'number': 3, 'created': '2017-02-17 09:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/e9a61585dbaf3a8e78ee2cd3f6b5dc0c5cc790a3', 'message': 'Configure trove_conductor_workers in os_trove\n\nConfigure trove_conductor_workers by calculating the default value.\nSimilar to other services worker threads, the default value for\ntrove_conductor_workers is half the number of vcpus on the machine.\n\nAlso added capping of worker threads for trove.\n\nChange-Id: If853b0e1e45b7137572df8a1123273539343c83e\nCloses-Bug: #1664639\n'}, {'number': 4, 'created': '2017-02-17 10:14:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/aa7a07322580123e24faf0c7601707b9afd66480', 'message': 'Configure trove_conductor_workers in os_trove\n\nConfigure trove_conductor_workers by calculating the default value.\nSimilar to other services worker threads, the default value for\ntrove_conductor_workers is half the number of vcpus on the machine.\n\nAlso added capping of worker threads for trove.\n\nChange-Id: If853b0e1e45b7137572df8a1123273539343c83e\nCloses-Bug: #1664639\n'}, {'number': 5, 'created': '2017-02-17 11:02:48.000000000', 'files': ['templates/trove.conf.j2', 'defaults/main.yml', 'templates/trove-conductor.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/fdd59ffe60672e7f4401f2b179d5fb152e0d33a3', 'message': 'Configure trove_conductor_workers in os_trove\n\nConfigure trove_conductor_workers by calculating the default value.\nSimilar to other services worker threads, the default value for\ntrove_conductor_workers is half the number of vcpus on the machine.\n\nAlso added capping of worker threads for trove.\n\nChange-Id: If853b0e1e45b7137572df8a1123273539343c83e\nCloses-Bug: #1664639\n'}]",22,435278,fdd59ffe60672e7f4401f2b179d5fb152e0d33a3,26,8,5,22111,,,0,"Configure trove_conductor_workers in os_trove

Configure trove_conductor_workers by calculating the default value.
Similar to other services worker threads, the default value for
trove_conductor_workers is half the number of vcpus on the machine.

Also added capping of worker threads for trove.

Change-Id: If853b0e1e45b7137572df8a1123273539343c83e
Closes-Bug: #1664639
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/78/435278/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/trove-conductor.conf.j2'],1,5fd0831f03589ea4110969e541da7bb534cb7fb6,ravi_trove_conductor_workers,{% set _conductor_threads = ansible_processor_vcpus|default(2) // 2 %} {% set conductor_threads = _conductor_threads if _conductor_threads > 0 else 1 %} trove_conductor_workers={{ trove_conductor_workers | default(conductor_threads) }},,4,0
openstack%2Fopenstack-ansible~master~Iebf59288a8abbf72a961832fed113bbd30cbe77c,openstack/openstack-ansible,master,Iebf59288a8abbf72a961832fed113bbd30cbe77c,Remove security role from user_variables.yml,MERGED,2017-02-15 13:34:35.000000000,2017-02-18 09:40:31.000000000,2017-02-17 22:57:56.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-15 13:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a2a733cb97ab45339ac0a86d8ea35f834016bdd2', 'message': 'Remove security role from user_variables.yml\n\nThis patch removes a confusing section of `user_variables.yml` that\nis no longer needed since the security role is applied by default.\n\nCloses-bug: 1664824\nChange-Id: Iebf59288a8abbf72a961832fed113bbd30cbe77c\n'}, {'number': 2, 'created': '2017-02-17 13:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3d18a0bd602bb6e5d3cd3a0c938a82495ff56b68', 'message': 'Remove security role from user_variables.yml\n\nThis patch removes a confusing section of `user_variables.yml` that\nis no longer needed since the security role is applied by default.\n\nCloses-bug: 1664824\nChange-Id: Iebf59288a8abbf72a961832fed113bbd30cbe77c\n'}, {'number': 3, 'created': '2017-02-17 15:39:54.000000000', 'files': ['etc/openstack_deploy/user_variables.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3ddf708eaf8f32d4c90f49e8a7595519308b200a', 'message': 'Remove security role from user_variables.yml\n\nThis patch removes a confusing section of `user_variables.yml` that\nis no longer needed since the security role is applied by default.\n\nCloses-bug: 1664824\nChange-Id: Iebf59288a8abbf72a961832fed113bbd30cbe77c\n'}]",0,434274,3ddf708eaf8f32d4c90f49e8a7595519308b200a,24,5,3,538,,,0,"Remove security role from user_variables.yml

This patch removes a confusing section of `user_variables.yml` that
is no longer needed since the security role is applied by default.

Closes-bug: 1664824
Change-Id: Iebf59288a8abbf72a961832fed113bbd30cbe77c
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/74/434274/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/openstack_deploy/user_variables.yml'],1,a2a733cb97ab45339ac0a86d8ea35f834016bdd2,bug/1664824,," ## Host security hardening # The openstack-ansible-security role provides security hardening for hosts # by applying security configurations from the STIG. Hardening is disabled by # default, but an option to opt-in is available by setting the following # variable to 'true'. # Docs: http://docs.openstack.org/developer/openstack-ansible-security/ # apply_security_hardening: true",0,8
openstack%2Fopenstack-ansible~master~I1763351a95bb3c30bcb1095fad0fedff72c1a751,openstack/openstack-ansible,master,I1763351a95bb3c30bcb1095fad0fedff72c1a751,Add CentOS support for AIO setup,MERGED,2016-12-06 20:11:27.000000000,2017-02-18 09:34:52.000000000,2017-02-17 21:41:23.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 22981}, {'_account_id': 23163}]","[{'number': 1, 'created': '2016-12-06 20:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2c5ca1c48f6b87ed4e755f25488049ea9f235d8b', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 2, 'created': '2016-12-06 20:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9d6a1d0aff1c009b9fd4c8aeb4924935effc25b8', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 3, 'created': '2016-12-15 16:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8de4926326d84d06c24afcde97ed3fac5ec10ff3', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 4, 'created': '2017-01-10 20:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5649e044ea1a3d00bc8c72d978c254d1fb04fe87', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 5, 'created': '2017-01-11 14:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c64147f2d1ec2bbaa4b96dd68e2a2119530f2768', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 6, 'created': '2017-01-24 19:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d2b60a8b2e30af2a23e082d53e4eee83bdf54c97', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 7, 'created': '2017-01-30 13:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/680ed6a647cabc31d29d426f7a4b8e57801b8f26', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 8, 'created': '2017-01-30 16:42:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d4eae7ac9321934a8b85eff2ecebd8ab93b74fba', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 9, 'created': '2017-01-30 16:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/90dcdca29f56448115a89202fc0a7de920e642e0', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 10, 'created': '2017-01-30 19:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/66c443abc61c1378d88939ee6d679dd82adb9b7a', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 11, 'created': '2017-01-30 20:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/89d18e9c585f241f633c38288a9a8c2ba7b7c090', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 12, 'created': '2017-01-30 20:38:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/de85f15daed4f27821d3f061ddc3895289fac00e', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 13, 'created': '2017-01-30 20:55:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a935b44a532d3c0e873406623f63d47560abb61f', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 14, 'created': '2017-01-31 16:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/48162cd01c336c777bf6e959452b49a0c672842f', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 15, 'created': '2017-01-31 19:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d06ca35f2cd97e146dd7ae1a08f3c618f4317b22', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 16, 'created': '2017-02-01 14:25:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/632f3f1f1c4f1ce593eebfccc1e0e8c5ee153964', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 17, 'created': '2017-02-01 14:48:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/559f32db6fcec116f7680b60b20204e68d5ebd5e', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 18, 'created': '2017-02-02 17:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d49b0059f0b9ca9d2807fce65189b4f535a15000', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 19, 'created': '2017-02-03 13:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/361f39706abd1b8f91d5af8a28630dc4be9be1f0', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 20, 'created': '2017-02-03 16:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9d98a5cc82f7ed5483557f7e2859adf5db2ccc4c', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 21, 'created': '2017-02-03 18:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e3ecf77b108b21a4fb12877c99e339218cce821a', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 22, 'created': '2017-02-03 18:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ef7912ea900e98773d939a13ef301ef5d716aa10', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 23, 'created': '2017-02-03 18:51:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3970cb8a8e3392bafbdf7ada653978fd54e9fe9b', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 24, 'created': '2017-02-03 20:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c9a9ec693fed0a161fe43e40fd81c39eda03067d', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 25, 'created': '2017-02-06 16:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0642b540a8944274dd5eb030b80720937cc8d03b', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 26, 'created': '2017-02-06 20:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a0edfcd9a297058c4dae2e27d0b0694ed38f12e5', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 27, 'created': '2017-02-07 13:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/71ca5f1257c0f5c0c560b398605f790611c91330', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 28, 'created': '2017-02-09 13:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d5aa3d3a5bf50f5cff88031d30e4a8c0701a8bf0', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 29, 'created': '2017-02-10 14:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bb62c1014444916314e6fec169c99e8429779afb', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 30, 'created': '2017-02-10 15:47:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ecf3f54db15c473ddb3ac65263f524bbab897193', 'message': '[WIP] Add CentOS support for AIO setup\n\nmissing\n- documentation\n- network bits\n- probably other stuff\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 31, 'created': '2017-02-10 20:29:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cd703c1ec7a7339e2e5b0343344e12b735f3c0c2', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 32, 'created': '2017-02-10 20:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a918bbb6630df7cf48ef45632064b7036b1ba30c', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 33, 'created': '2017-02-14 20:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d632b45777f26e6e0e969a5141a710e6f6715c16', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 34, 'created': '2017-02-15 13:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c01bdaa483a68ed21b7f7d08f8b3579b1112bdf0', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nDepends-On: I9cca5138934eee438906ac25d165d128c2411e31\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 35, 'created': '2017-02-16 09:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8692e4220b4772ffe635c08412a291d71981c517', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nDepends-On: I9cca5138934eee438906ac25d165d128c2411e31\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 36, 'created': '2017-02-16 09:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/31b68eb0d1c01dbcb0190a95687ed59e19494a29', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nDepends-On: I9cca5138934eee438906ac25d165d128c2411e31\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 37, 'created': '2017-02-16 09:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/76f7278b0f461f2d37645a0851fe296bbfbacb15', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nDepends-On: I9cca5138934eee438906ac25d165d128c2411e31\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 38, 'created': '2017-02-16 14:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a3955e42200662cc02bba053a53c2e0ce9524132', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 39, 'created': '2017-02-17 14:06:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9a27ac41685b47ad83bc0704afbc04c9a4b5ad2f', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}, {'number': 40, 'created': '2017-02-17 15:53:01.000000000', 'files': ['doc/source/developer-docs/quickstart-aio.rst', 'tests/roles/bootstrap-host/tasks/install-apt.yml', 'tests/roles/bootstrap-host/templates/redhat_interface_alias.cfg.j2', 'tests/roles/bootstrap-host/tasks/main.yml', 'tests/roles/bootstrap-host/tasks/prepare_networking.yml', 'tests/roles/bootstrap-host/defaults/main.yml', 'tests/bootstrap-aio.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_cinder.yml', 'deploy-guide/source/deploymenthost.rst', 'tests/roles/bootstrap-host/templates/redhat_interface_ifdown-post.cfg.j2', 'releasenotes/notes/Add-CentOS-support-9a63262163dfb678.yaml', 'tests/roles/bootstrap-host/templates/redhat_interface_ifup-post.cfg.j2', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swap.yml', 'deploy-guide/source/overview-requirements.rst', 'tests/roles/bootstrap-host/vars/redhat.yml', 'tests/roles/bootstrap-host/vars/ubuntu.yml', 'tests/roles/bootstrap-host/tasks/install_packages.yml', 'tests/roles/bootstrap-host/templates/redhat_interface_default.cfg.j2', 'deploy-guide/source/targethosts-prepare.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e44a7f1ac48d24614bf58ea6c4004ebb86f0d6ac', 'message': 'Add CentOS support for AIO setup\n\nThis patch add support for deploying on CentOS.\n\nChange-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751\n'}]",14,407690,e44a7f1ac48d24614bf58ea6c4004ebb86f0d6ac,121,7,40,13095,,,0,"Add CentOS support for AIO setup

This patch add support for deploying on CentOS.

Change-Id: I1763351a95bb3c30bcb1095fad0fedff72c1a751
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/90/407690/20 && git format-patch -1 --stdout FETCH_HEAD,"['my_patch.diff', 'tests/roles/bootstrap-host/tasks/install-apt.yml', 'tests/roles/bootstrap-host/tasks/check-requirements.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swap.yml', 'tests/roles/bootstrap-host/vars/redhat-7.yml', 'tests/roles/bootstrap-host/tasks/main.yml', 'tests/roles/bootstrap-host/tasks/prepare_networking.yml', 'tests/roles/bootstrap-host/vars/ubuntu.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_cinder.yml']",9,2c5ca1c48f6b87ed4e755f25488049ea9f235d8b,add-Centos-support," path: ""{{ rc_local }}"" dest: ""{{ rc_local }}""", path: /etc/rc.local dest: /etc/rc.local,271,25
openstack%2Fcinder~master~I145464d0d63cb5a00e0e905083c260fb6621dd89,openstack/cinder,master,I145464d0d63cb5a00e0e905083c260fb6621dd89,"Fix ""No documentation found in"" errors in docs",MERGED,2017-02-10 10:18:02.000000000,2017-02-18 09:10:36.000000000,2017-02-10 20:10:06.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11600}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 16422}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 18444}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21884}, {'_account_id': 21990}, {'_account_id': 22248}, {'_account_id': 23602}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-10 10:18:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80fde2c7cde6f8509a59d5a33f86af1b8275f4a8', 'message': ""Remove database_architecture.rst from docs\n\nThe only content that's rendered on this devref page is:\n\n Warning: No documentation found in\n          sqlalchemy = oslo_db.sqlalchemy.migration\n\nThis commit removes the page.\n\nChange-Id: I145464d0d63cb5a00e0e905083c260fb6621dd89\nCloses-Bug: 1663527\n""}, {'number': 2, 'created': '2017-02-10 11:58:54.000000000', 'files': ['doc/source/oslo-middleware.rst', 'cinder/scheduler/weights/capacity.py', 'doc/source/database_architecture.rst', 'cinder/scheduler/weights/volume_number.py', 'cinder/scheduler/weights/chance.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fbb7f6101e28bf1ab1be597ccc849b59b3f9ac57', 'message': 'Fix ""No documentation found in"" errors in docs\n\nThis commit removes errors like:\n\n Warning: No documentation found in\n          sqlalchemy = oslo_db.sqlalchemy.migration\n\nIt\'s done either by removing pages referring to oslo\'s completely or\nadding proper documentation to classes.\n\nChange-Id: I145464d0d63cb5a00e0e905083c260fb6621dd89\nCloses-Bug: 1663527\n'}]",0,432234,fbb7f6101e28bf1ab1be597ccc849b59b3f9ac57,67,28,2,11600,,,0,"Fix ""No documentation found in"" errors in docs

This commit removes errors like:

 Warning: No documentation found in
          sqlalchemy = oslo_db.sqlalchemy.migration

It's done either by removing pages referring to oslo's completely or
adding proper documentation to classes.

Change-Id: I145464d0d63cb5a00e0e905083c260fb6621dd89
Closes-Bug: 1663527
",git fetch https://review.opendev.org/openstack/cinder refs/changes/34/432234/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/database_architecture.rst'],1,80fde2c7cde6f8509a59d5a33f86af1b8275f4a8,bug/1663527,,============================== Cinder Database Architecture ============================== Cinder Database Backends ~~~~~~~~~~~~~~~~~~~~~~~~ .. list-plugins:: cinder.database.migration_backend :detailed: ,0,9
openstack%2Fdragonflow~master~Ib7ee3454342332e06eb5527c5d4cc806b4aecf4e,openstack/dragonflow,master,Ib7ee3454342332e06eb5527c5d4cc806b4aecf4e,Remove redundant methods in redis pubsub driver,MERGED,2017-02-16 10:15:08.000000000,2017-02-18 08:09:40.000000000,2017-02-18 08:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-16 10:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/10ba80df0576693747be345ffab305c4e35fd1a4', 'message': 'Remove redundant methods in redis pubsub driver\n\nChange-Id: Ib7ee3454342332e06eb5527c5d4cc806b4aecf4e\n'}, {'number': 2, 'created': '2017-02-16 12:16:04.000000000', 'files': ['dragonflow/db/pubsub_drivers/redis_db_pubsub_driver.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bb7797a7bcf2bebb336701746013e63ef1ef9c4c', 'message': 'Remove redundant methods in redis pubsub driver\n\nChange-Id: Ib7ee3454342332e06eb5527c5d4cc806b4aecf4e\n'}]",0,434797,bb7797a7bcf2bebb336701746013e63ef1ef9c4c,10,4,2,20229,,,0,"Remove redundant methods in redis pubsub driver

Change-Id: Ib7ee3454342332e06eb5527c5d4cc806b4aecf4e
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/97/434797/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/db/pubsub_drivers/redis_db_pubsub_driver.py'],1,10ba80df0576693747be345ffab305c4e35fd1a4,remove-dfdaemon,," def register_listen_address(self, uri): super(RedisSubscriberAgent, self).register_listen_address(uri) def unregister_listen_address(self, uri): super(RedisSubscriberAgent, self).unregister_listen_address(uri) ",0,6
openstack%2Fproject-config~master~Id2e9eef226ebbd4b576e0517c31eae72c3389dac,openstack/project-config,master,Id2e9eef226ebbd4b576e0517c31eae72c3389dac,tripleo/scenario004: add manila files,MERGED,2017-02-15 02:40:18.000000000,2017-02-18 06:59:17.000000000,2017-02-18 06:59:17.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 9003}, {'_account_id': 10873}]","[{'number': 1, 'created': '2017-02-15 02:40:18.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/918a2876062d77d0be1aaf03f5152694e60c0a62', 'message': 'tripleo/scenario004: add manila files\n\nTripleO Scenario004 now support Manila, so we increase testing coverage.\n\n1. Add manila files to run scenario004 when needed\n2. Run TripleO scenario004 in puppet-manila gate\n\nChange-Id: Id2e9eef226ebbd4b576e0517c31eae72c3389dac\nDepends-On: I70515c5b9ce2668a684649ecd40421b69078ee83\n'}]",0,434031,918a2876062d77d0be1aaf03f5152694e60c0a62,12,6,1,3153,,,0,"tripleo/scenario004: add manila files

TripleO Scenario004 now support Manila, so we increase testing coverage.

1. Add manila files to run scenario004 when needed
2. Run TripleO scenario004 in puppet-manila gate

Change-Id: Id2e9eef226ebbd4b576e0517c31eae72c3389dac
Depends-On: I70515c5b9ce2668a684649ecd40421b69078ee83
",git fetch https://review.opendev.org/openstack/project-config refs/changes/31/434031/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,918a2876062d77d0be1aaf03f5152694e60c0a62,manila/tripleo, - ^puppet/services/manila.*$ - ^manifests/profile/base/manila.*$ - name: tripleo-scenario-jobs-scenario004,,3,0
openstack%2Fpython-openstackclient~master~Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172,openstack/python-openstackclient,master,Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172,"Fix ""server create"" command failed when --nic auto or none",MERGED,2017-02-13 11:16:25.000000000,2017-02-18 06:41:14.000000000,2017-02-18 06:41:14.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}]","[{'number': 1, 'created': '2017-02-13 11:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/5ed8bf79f7f09367f9be955c50ac28d1c2b9e5a4', 'message': 'Fix ""server create"" command failed when --nic auto or none\n\n""auto"" and ""none"" options was added into --nic argument of server create\ncommand in patch https://review.openstack.org/#/c/412698/ , but that\ndon\'t work and raise internal error when execute command. The patch\nfix that issue and add unit and functional tests.\n\nChange-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172\nCo-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>\nCloses-Bug: #1663520\n'}, {'number': 2, 'created': '2017-02-14 06:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8cd54b288eb086e044f15d908e6ff6180a190cbe', 'message': 'Fix ""server create"" command failed when --nic auto or none\n\n""auto"" and ""none"" options was added into --nic argument of server create\ncommand in patch https://review.openstack.org/#/c/412698/ , but that\ndon\'t work and raise internal error when execute command. The patch\nfix that issue and add unit and functional tests.\n\nChange-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172\nCo-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>\nCloses-Bug: #1663520\n'}, {'number': 3, 'created': '2017-02-14 08:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/21fd06f687de41c961757a77168c1153da1201d1', 'message': 'Fix ""server create"" command failed when --nic auto or none\n\n""auto"" and ""none"" options was added into --nic argument of server create\ncommand in patch https://review.openstack.org/#/c/412698/ , but that\ndon\'t work and raise internal error when execute command. The patch\nfix that issue and add unit and functional tests.\n\nChange-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172\nCo-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>\nCloses-Bug: #1663520\n'}, {'number': 4, 'created': '2017-02-14 09:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/68c64843674c3130ba158996af74a8ee158b57a5', 'message': 'Fix ""server create"" command failed when --nic auto or none\n\n""auto"" and ""none"" options was added into --nic argument of server create\ncommand in patch https://review.openstack.org/#/c/412698/ , but that\ndon\'t work and raise internal error when execute command. The patch\nfix that issue and add unit and functional tests.\n\nChange-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172\nCo-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>\nCloses-Bug: #1663520\n'}, {'number': 5, 'created': '2017-02-15 06:26:26.000000000', 'files': ['releasenotes/notes/bug-1663520-d880bfa51ca7b798.yaml', 'doc/source/command-objects/server.rst', 'openstackclient/tests/functional/compute/v2/test_server.py', 'openstackclient/tests/unit/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c051c5f090fa6729a005c9d462afd8a75fc1b40f', 'message': 'Fix ""server create"" command failed when --nic auto or none\n\n""auto"" and ""none"" options was added into --nic argument of server create\ncommand in patch https://review.openstack.org/#/c/412698/ , but that\ndon\'t work and raise internal error when execute command. The patch\nfix that issue and add unit and functional tests.\n\nChange-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172\nCo-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>\nCloses-Bug: #1663520\n'}]",0,432993,c051c5f090fa6729a005c9d462afd8a75fc1b40f,22,3,5,8276,,,0,"Fix ""server create"" command failed when --nic auto or none

""auto"" and ""none"" options was added into --nic argument of server create
command in patch https://review.openstack.org/#/c/412698/ , but that
don't work and raise internal error when execute command. The patch
fix that issue and add unit and functional tests.

Change-Id: Ia718c3bac0a5172a0cdbe9f0d97972a9346c1172
Co-Authored-By: Kevin_Zheng <zhengzhenyu@huawei.com>
Closes-Bug: #1663520
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/93/432993/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1663520-d880bfa51ca7b798.yaml', 'doc/source/command-objects/server.rst', 'openstackclient/tests/functional/compute/v2/test_server.py', 'openstackclient/tests/unit/compute/v2/test_server.py', 'openstackclient/compute/v2/server.py']",5,5ed8bf79f7f09367f9be955c50ac28d1c2b9e5a4,bug/1663520," ""port-id=port-uuid,auto,none>"", ""allocate a network. Specifying a --nic of auto or none "" ""cannot be used with any other --nic value.""), auto_or_none = False for nic_str in parsed_args.nic: # Handle the special auto/none cases if nic_str in ('auto', 'none'): auto_or_none = True nics.append(nic_str) else: try: nic_info.update(dict(kv_str.split(""="", 1) for kv_str in nic_str.split("",""))) except ValueError: msg = _('Invalid --nic argument %s.') % nic_str raise exceptions.CommandError(msg) if nics: if auto_or_none: if len(nics) > 1: msg = _('Specifying a --nic of auto or none cannot ' 'be used with any other --nic value.') raise exceptions.CommandError(msg) nics = nics[0] else: # Default to empty list if nothing was specified, let nova side to # decide the default behavior. nics = [] "," ""port-id=port-uuid>"", ""allocate a network.""), if parsed_args.nic in ('auto', 'none'): nics = [parsed_args.nic] else: for nic_str in parsed_args.nic: nic_info.update(dict(kv_str.split(""="", 1) for kv_str in nic_str.split("","")))",272,12
openstack%2Fdragonflow~master~I6ffcb15067bf9802f899b4a02bf0158890b1cd16,openstack/dragonflow,master,I6ffcb15067bf9802f899b4a02bf0158890b1cd16,Add [H203] Use assertIs(Not)None to check for None,MERGED,2017-02-16 09:00:31.000000000,2017-02-18 06:26:06.000000000,2017-02-18 06:26:06.000000000,"[{'_account_id': 3}, {'_account_id': 6598}, {'_account_id': 7805}, {'_account_id': 11159}, {'_account_id': 20229}, {'_account_id': 23766}]","[{'number': 1, 'created': '2017-02-16 09:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e085a4daf048258a3975acfc888d17c3bcf1de67', 'message': 'Add [H203] Use assertIs(Not)None to check for None\n\nChange-Id: I6ffcb15067bf9802f899b4a02bf0158890b1cd16\n'}, {'number': 2, 'created': '2017-02-16 12:26:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/7ba1f53e7d0466d4ab04dc1463a828879c2c6284', 'message': 'Add [H203] Use assertIs(Not)None to check for None\n\nChange-Id: I6ffcb15067bf9802f899b4a02bf0158890b1cd16\n'}]",0,434751,7ba1f53e7d0466d4ab04dc1463a828879c2c6284,13,6,2,23766,,,0,"Add [H203] Use assertIs(Not)None to check for None

Change-Id: I6ffcb15067bf9802f899b4a02bf0158890b1cd16
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/51/434751/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e085a4daf048258a3975acfc888d17c3bcf1de67,add_h203,"# H203: Use assertIs(Not)None to check for None enable-extensions=H904,H203",enable-extensions=H904,2,1
openstack%2Fpython-openstackclient~master~I6200045c6228e245fc48a4d48d4b3796dede61b5,openstack/python-openstackclient,master,I6200045c6228e245fc48a4d48d4b3796dede61b5,Functional test for router,MERGED,2017-02-15 06:47:41.000000000,2017-02-18 06:25:16.000000000,2017-02-18 06:25:16.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 21514}]","[{'number': 1, 'created': '2017-02-15 06:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0a127b56690130aece5ac78fc819923ac84cc8ad', 'message': 'Functional test for router\n\nRefactor functional tests for testing more command options.\n\nChange-Id: I6200045c6228e245fc48a4d48d4b3796dede61b5\n'}, {'number': 2, 'created': '2017-02-15 10:45:22.000000000', 'files': ['openstackclient/tests/functional/network/v2/test_router.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/f96cff1a6dc40ea78a5d530b95626abf6f0e2467', 'message': 'Functional test for router\n\nRefactor functional tests for testing more command options.\n\nChange-Id: I6200045c6228e245fc48a4d48d4b3796dede61b5\n'}]",0,434099,f96cff1a6dc40ea78a5d530b95626abf6f0e2467,15,3,2,24080,,,0,"Functional test for router

Refactor functional tests for testing more command options.

Change-Id: I6200045c6228e245fc48a4d48d4b3796dede61b5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/99/434099/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/network/v2/test_router.py'],1,0a127b56690130aece5ac78fc819923ac84cc8ad,func-network-router,"import json def test_router_create_and_delete(self): """"""Test create options, delete"""""" name1 = uuid.uuid4().hex name2 = uuid.uuid4().hex cmd_output = json.loads(self.openstack( 'router create -f json ' + name1 )) self.assertEqual( name1, cmd_output[""name""], ) cmd_output = json.loads(self.openstack( 'router create -f json ' + name2 )) self.assertEqual( name2, cmd_output[""name""], ) del_output = self.openstack( 'router delete ' + name1 + ' ' + name2) self.assertOutput('', del_output) """"""Test create, list filter"""""" # Get project IDs cmd_output = json.loads(self.openstack('token issue -f json ')) auth_project_id = cmd_output['project_id'] cmd_output = json.loads(self.openstack('project list -f json ')) admin_project_id = None demo_project_id = None for p in cmd_output: if p['Name'] == 'admin': admin_project_id = p['ID'] if p['Name'] == 'demo': demo_project_id = p['ID'] # Verify assumptions: # * admin and demo projects are present # * demo and admin are distinct projects # * tests run as admin self.assertIsNotNone(admin_project_id) self.assertIsNotNone(demo_project_id) self.assertNotEqual(admin_project_id, demo_project_id) self.assertEqual(admin_project_id, auth_project_id) name1 = uuid.uuid4().hex name2 = uuid.uuid4().hex cmd_output = json.loads(self.openstack( 'router create -f json ' + '--disable ' + name1 )) self.assertEqual( name1, cmd_output[""name""], ) self.assertEqual( ""DOWN"", cmd_output[""admin_state_up""], ) self.assertEqual( admin_project_id, cmd_output[""project_id""], ) cmd_output = json.loads(self.openstack( 'router create -f json ' + '--project ' + demo_project_id + ' ' + name2 )) self.assertEqual( name2, cmd_output[""name""], ) self.assertEqual( ""UP"", cmd_output[""admin_state_up""], ) self.assertEqual( demo_project_id, cmd_output[""project_id""], ) # Test list --project cmd_output = json.loads(self.openstack( 'router list -f json ' + '--project ' + demo_project_id )) names = [x[""Name""] for x in cmd_output] self.assertNotIn(name1, names) self.assertIn(name2, names) # Test list --disable cmd_output = json.loads(self.openstack( 'router list -f json ' + '--disable ' )) names = [x[""Name""] for x in cmd_output] self.assertIn(name1, names) self.assertNotIn(name2, names) # Test list --name cmd_output = json.loads(self.openstack( 'router list -f json ' + '--name ' + name1 )) names = [x[""Name""] for x in cmd_output] self.assertIn(name1, names) self.assertNotIn(name2, names) # Test list --long cmd_output = json.loads(self.openstack( 'router list -f json ' + '--long ' )) names = [x[""Name""] for x in cmd_output] self.assertIn(name1, names) self.assertIn(name2, names) del_output = self.openstack( 'router delete ' + name1 + ' ' + name2) self.assertOutput('', del_output) def test_router_set_show_unset(self): """"""Tests create router, set, unset, show, delete"""""" name = uuid.uuid4().hex new_name = name + ""_"" cmd_output = json.loads(self.openstack( 'router create -f json ' + '--description aaaa ' + name )) self.assertEqual( name, cmd_output[""name""], ) self.assertEqual( 'aaaa', cmd_output[""description""], ) # Test set --disable cmd_output = self.openstack( 'router set ' + '--name ' + new_name + ' --description bbbb ' + '--disable ' + name ) self.assertOutput('', cmd_output) cmd_output = json.loads(self.openstack( 'router show -f json ' + new_name )) self.assertEqual( new_name, cmd_output[""name""], ) self.assertEqual( 'bbbb', cmd_output[""description""], ) self.assertEqual( 'DOWN', cmd_output[""admin_state_up""], ) # Test set --ha --distributed cmd_output = self.openstack( 'router set ' + '--distributed ' + '--external-gateway public ' + new_name ) self.assertOutput('', cmd_output) cmd_output = json.loads(self.openstack( 'router show -f json ' + new_name )) self.assertEqual( True, cmd_output[""distributed""], ) self.assertIsNotNone(cmd_output[""external_gateway_info""]) # Test unset cmd_output = self.openstack( 'router unset ' + '--external-gateway ' + new_name ) cmd_output = json.loads(self.openstack( 'router show -f json ' + new_name )) self.assertEqual( 'null', cmd_output[""external_gateway_info""], ) del_output = self.openstack( 'router delete ' + new_name) self.assertOutput('', del_output)"," NAME = uuid.uuid4().hex HEADERS = ['Name'] FIELDS = ['name'] @classmethod def setUpClass(cls): opts = cls.get_opts(cls.FIELDS) raw_output = cls.openstack('router create ' + cls.NAME + opts) expected = cls.NAME + '\n' cls.assertOutput(expected, raw_output) @classmethod def tearDownClass(cls): raw_output = cls.openstack('router delete ' + cls.NAME) cls.assertOutput('', raw_output) opts = self.get_opts(self.HEADERS) raw_output = self.openstack('router list' + opts) self.assertIn(self.NAME, raw_output) def test_router_set(self): self.openstack('router set --disable ' + self.NAME) opts = self.get_opts(['name', 'admin_state_up']) raw_output = self.openstack('router show ' + self.NAME + opts) self.assertEqual(""DOWN\n"" + self.NAME + ""\n"", raw_output) def test_router_show(self): opts = self.get_opts(self.FIELDS) raw_output = self.openstack('router show ' + self.NAME + opts) self.assertEqual(self.NAME + ""\n"", raw_output)",205,25
openstack%2Fpython-openstackclient~master~Ia39e6d20bf5c9d3096e46f3432804a240827548d,openstack/python-openstackclient,master,Ia39e6d20bf5c9d3096e46f3432804a240827548d,"Add ""volume host failover"" command",MERGED,2016-12-15 11:47:12.000000000,2017-02-18 06:25:10.000000000,2017-02-18 06:25:10.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 10058}, {'_account_id': 11904}, {'_account_id': 12112}, {'_account_id': 21514}, {'_account_id': 24081}]","[{'number': 1, 'created': '2016-12-15 11:47:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c5ad31c7b49cb42863516398d1fe1e427ce4473a', 'message': 'Add one option to ""volume host set"" command\n\nAdd ""--backend-id"" option to ""volume host set"" command to\nsupport failover the specified cinder-volume host\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\n'}, {'number': 2, 'created': '2016-12-18 16:35:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/78dc3df0bb4f81f3c78b83b8a3f18c1a46e84cda', 'message': 'Add one option to ""volume host set"" command\n\nAdd ""--backend-id"" option to ""volume host set"" command to\nsupport failover the specified cinder-volume host\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 3, 'created': '2016-12-19 03:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/515b40941a49f8873f18802b042b27f667a7782c', 'message': 'Add one option to ""volume host set"" command\n\nAdd ""--backend-id"" option to ""volume host set"" command to\nsupport failover the specified cinder-volume host\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 4, 'created': '2016-12-21 05:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/56a9c5031c412e2ae2b9237f9b92fcb1b5f102b2', 'message': 'Add one option to ""volume host set"" command\n\nAdd ""--failover"" option to ""volume host set"" command to\nsupport failover the specified cinder-volume host\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 5, 'created': '2017-01-11 21:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4ebba0426457becaf45ed8a226b0eae348ef02e1', 'message': 'Add one option to ""volume host set"" command\n\nAdd ""--failover"" option to ""volume host set"" command to\nsupport failover the specified cinder-volume host\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 6, 'created': '2017-01-16 08:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/75b40abe1e49f64784dda11d0348f792d68b5289', 'message': 'Add ""volume host failover"" command\n\nAdd ""volume host failover"" command in volume v2 (v2 only).\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 7, 'created': '2017-01-16 12:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1b0e91a1116432b83e5a481bc91ec25a868e5b27', 'message': 'Add ""volume host failover"" command\n\nAdd ""volume host failover"" command in volume v2 (v2 only).\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 8, 'created': '2017-01-17 10:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c936c7645bed31e36a85feecd2b47f486448277e', 'message': 'Add ""volume host failover"" command\n\nAdd ""volume host failover"" command in volume v2 (v2 only).\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}, {'number': 9, 'created': '2017-01-18 02:04:49.000000000', 'files': ['openstackclient/tests/unit/volume/v2/test_volume_host.py', 'doc/source/commands.rst', 'openstackclient/volume/v2/volume_host.py', 'doc/source/command-objects/volume-host.rst', 'releasenotes/notes/add-volume-host-failover-8fc77b24533b7fed.yaml', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/55195cec46fadd88f6151783b1e17557d5e94940', 'message': 'Add ""volume host failover"" command\n\nAdd ""volume host failover"" command in volume v2 (v2 only).\n\nChange-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d\nImplements: bp cinder-command-support\n'}]",16,411259,55195cec46fadd88f6151783b1e17557d5e94940,61,9,9,24081,,,0,"Add ""volume host failover"" command

Add ""volume host failover"" command in volume v2 (v2 only).

Change-Id: Ia39e6d20bf5c9d3096e46f3432804a240827548d
Implements: bp cinder-command-support
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/59/411259/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/unit/volume/v2/test_volume_host.py', 'openstackclient/volume/v2/volume_host.py', 'doc/source/command-objects/volume-host.rst']",3,c5ad31c7b49cb42863516398d1fe1e427ce4473a,bp/cinder-command-support, [--backend-id <backend-id>] Thaw and enable the specified volume host. Freeze and disable the specified volume host. .. option:: --backend-id ID of backend to failover to (Default=None) .. _volume_host_set-host-name:, Thaw and enable the specified volume host Freeze and disable the specified volume host .. _volume-host-set:,40,3
openstack%2Fsenlin~stable%2Focata~I803d034d9f820c92daa528870449205b2723d813,openstack/senlin,stable/ocata,I803d034d9f820c92daa528870449205b2723d813,Revise params check when cluster update,MERGED,2017-02-18 04:17:50.000000000,2017-02-18 06:12:35.000000000,2017-02-18 06:12:35.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 04:17:50.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/320e8d86a14e171839212bf40fa573b897d0f567', 'message': ""Revise params check when cluster update\n\nAdd check with timeout and name, don't need update\nif property value not changed.\n\nChange-Id: I803d034d9f820c92daa528870449205b2723d813\n(cherry picked from commit a258c49e5ff5d40ec1d06a16d04f142eedab9874)\n""}]",0,435655,320e8d86a14e171839212bf40fa573b897d0f567,6,2,1,8246,,,0,"Revise params check when cluster update

Add check with timeout and name, don't need update
if property value not changed.

Change-Id: I803d034d9f820c92daa528870449205b2723d813
(cherry picked from commit a258c49e5ff5d40ec1d06a16d04f142eedab9874)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/55/435655/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py']",2,320e8d86a14e171839212bf40fa573b897d0f567,revise/cluser_update," @mock.patch.object(am.Action, 'create') @mock.patch.object(co.Cluster, 'find') @mock.patch.object(dispatcher, 'start_action') def test_cluster_update_same_timeout(self, notify, mock_find, mock_action): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', timeout=10) x_cluster.to_dict.return_value = {'foo': 'bar'} x_cluster.timeout = 10 mock_find.return_value = x_cluster mock_action.return_value = 'ACTION_ID' req = orco.ClusterUpdateRequest(identity='FAKE_ID', name='NEW_NAME', timeout=10) # do it result = self.eng.cluster_update(self.ctx, req.obj_to_primitive()) self.assertEqual({'action': 'ACTION_ID', 'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_ID') mock_action.assert_called_once_with( self.ctx, '12345678AB', 'CLUSTER_UPDATE', name='cluster_update_12345678', status=am.Action.READY, cause=consts.CAUSE_RPC, inputs={ # Note timeout is not included in the inputs 'name': 'NEW_NAME', }, ) notify.assert_called_once_with() @mock.patch.object(am.Action, 'create') @mock.patch.object(co.Cluster, 'find') @mock.patch.object(dispatcher, 'start_action') def test_cluster_update_same_name(self, notify, mock_find, mock_action): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', name='OLD_NAME', timeout=10) x_cluster.name = 'OLD_NAME' x_cluster.to_dict.return_value = {'foo': 'bar'} mock_find.return_value = x_cluster mock_action.return_value = 'ACTION_ID' req = orco.ClusterUpdateRequest(identity='FAKE_ID', name='OLD_NAME', timeout=100) # do it result = self.eng.cluster_update(self.ctx, req.obj_to_primitive()) self.assertEqual({'action': 'ACTION_ID', 'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_ID') mock_action.assert_called_once_with( self.ctx, '12345678AB', 'CLUSTER_UPDATE', name='cluster_update_12345678', status=am.Action.READY, cause=consts.CAUSE_RPC, inputs={ # Note name is not included in the inputs 'timeout': 100, }, ) notify.assert_called_once_with() @mock.patch.object(co.Cluster, 'find') def test_cluster_update_all_property_same(self, mock_find): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', name='OLD_NAME', timeout=10) x_cluster.name = 'OLD_NAME' x_cluster.timeout = 10 mock_find.return_value = x_cluster # Notice that name and timeout are all not changed. req = orco.ClusterUpdateRequest(identity='CLUSTER', name='OLD_NAME', timeout=10) ex = self.assertRaises(rpc.ExpectedException, self.eng.cluster_update, self.ctx, req.obj_to_primitive()) self.assertEqual(exc.BadRequest, ex.exc_info[0]) self.assertEqual('', six.text_type(ex)) ",,85,2
openstack%2Fsenlin~stable%2Focata~Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977,openstack/senlin,stable/ocata,Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977,Listener endpoint for Heat stack events,MERGED,2017-02-18 03:19:23.000000000,2017-02-18 06:12:29.000000000,2017-02-18 06:12:29.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 03:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/38dfbc16d5fcb6717b8ce06651e54913fc7107f1', 'message': 'Listener endpoint for Heat stack events\n\nThis adds a event endpoint for listening to Heat stack related events.\n\nChange-Id: Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977\n(cherry picked from commit 7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04)\n'}, {'number': 2, 'created': '2017-02-18 04:16:02.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/972bcf8940dca399f359329a537394b09eba29d5', 'message': 'Listener endpoint for Heat stack events\n\nThis adds a event endpoint for listening to Heat stack related events.\n\nChange-Id: Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977\n(cherry picked from commit 7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04)\n'}]",0,435641,972bcf8940dca399f359329a537394b09eba29d5,8,2,2,8246,,,0,"Listener endpoint for Heat stack events

This adds a event endpoint for listening to Heat stack related events.

Change-Id: Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977
(cherry picked from commit 7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/41/435641/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py']",2,38dfbc16d5fcb6717b8ce06651e54913fc7107f1,heat-listener-endpoint,"@mock.patch('oslo_messaging.NotificationFilter') class TestHeatNotificationEndpoint(base.SenlinTestCase): @mock.patch('senlin.rpc.client.EngineClient') def test_init(self, mock_rpc, mock_filter): x_filter = mock_filter.return_value event_map = { 'orchestration.stack.delete.end': 'DELETE', } obj = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER') mock_filter.assert_called_once_with( publisher_id='^orchestration.*', event_type='^orchestration\.stack\..*', context={'project_id': '^PROJECT$'}) mock_rpc.assert_called_once_with() self.assertEqual(x_filter, obj.filter_rule) self.assertEqual(mock_rpc.return_value, obj.rpc) for e in event_map: self.assertIn(e, obj.STACK_FAILURE_EVENTS) self.assertEqual(event_map[e], obj.STACK_FAILURE_EVENTS[e]) self.assertEqual('PROJECT', obj.project_id) self.assertEqual('CLUSTER', obj.cluster_id) @mock.patch.object(context.RequestContext, 'from_dict') @mock.patch('senlin.rpc.client.EngineClient') def test_info(self, mock_rpc, mock_context, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = { 'tags': { 'cluster_id=CLUSTER_ID', 'cluster_node_id=FAKE_NODE', 'cluster_node_index=123', }, 'stack_identity': 'PHYSICAL_ID', 'user_identity': 'USER', 'state': 'DELETE_COMPLETE', } metadata = {'timestamp': 'TIMESTAMP'} call_ctx = mock.Mock() mock_context.return_value = call_ctx res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) x_rpc.call.assert_called_once_with(call_ctx, 'node_recover', mock.ANY) req = x_rpc.call.call_args[0][2] self.assertIsInstance(req, vorn.NodeRecoverRequest) self.assertEqual('FAKE_NODE', req.identity) expected_params = { 'event': 'DELETE', 'state': 'DELETE_COMPLETE', 'stack_id': 'PHYSICAL_ID', 'timestamp': 'TIMESTAMP', 'publisher': 'PUBLISHER', } self.assertEqual(expected_params, req.params) @mock.patch('senlin.rpc.client.EngineClient') def test_info_event_type_not_interested(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': {'cluster_id': 'CLUSTER_ID'}} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.create.start', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': None} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_empty_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': []} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_cluster_in_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['foo', 'bar']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_node_in_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['cluster_id=C1ID']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_cluster_id_not_match(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['cluster_id=FOOBAR', 'cluster_node_id=N2']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch.object(context.RequestContext, 'from_dict') @mock.patch('senlin.rpc.client.EngineClient') def test_info_default_values(self, mock_rpc, mock_context, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = { 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID' ], 'user_identity': 'USER', } metadata = {'timestamp': 'TIMESTAMP'} call_ctx = mock.Mock() mock_context.return_value = call_ctx res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) x_rpc.call.assert_called_once_with(call_ctx, 'node_recover', mock.ANY) req = x_rpc.call.call_args[0][2] self.assertIsInstance(req, vorn.NodeRecoverRequest) self.assertEqual('NODE_ID', req.identity) expected_params = { 'event': 'DELETE', 'state': 'Unknown', 'stack_id': 'Unknown', 'timestamp': 'TIMESTAMP', 'publisher': 'PUBLISHER', } self.assertEqual(expected_params, req.params) ",,234,0
openstack%2Fsenlin~stable%2Focata~Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9,openstack/senlin,stable/ocata,Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9,User reference doc for scaling policy,MERGED,2017-02-18 04:17:31.000000000,2017-02-18 06:12:24.000000000,2017-02-18 06:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 04:17:31.000000000', 'files': ['doc/source/user/policy_types/scaling.rst', 'senlin/policies/scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/713a33ebd68eb8bb96f2f958300b344db05a9370', 'message': 'User reference doc for scaling policy\n\nChange-Id: Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9\n(cherry picked from commit 431715ddda7fdd754a4c3da59d3920e758568164)\n'}]",0,435653,713a33ebd68eb8bb96f2f958300b344db05a9370,6,2,1,8246,,,0,"User reference doc for scaling policy

Change-Id: Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9
(cherry picked from commit 431715ddda7fdd754a4c3da59d3920e758568164)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/53/435653/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/policy_types/scaling.rst', 'senlin/policies/scaling_policy.py']",2,713a33ebd68eb8bb96f2f958300b344db05a9370,ref-scaling-policy, :param dict kwargs: Other optional parameters for policy object creation., :param \*\*kwargs: Other optional parameters for policy object creation.,143,3
openstack%2Fpuppet-vswitch~master~I2329aa122b9cacb3c7de18a21353f53ea1d988ed,openstack/puppet-vswitch,master,I2329aa122b9cacb3c7de18a21353f53ea1d988ed,Remove deprecated parameter 'core_list',MERGED,2017-02-15 09:04:55.000000000,2017-02-18 06:05:40.000000000,2017-02-18 06:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 18575}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-15 09:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/b1674764763e6a3da1c8cc14eba83980560aa10b', 'message': ""Remove deprecated parameter 'core_list'\n\nThe deprecated parameter 'core_list' shall be removed for Pike\n\nChange-Id: I2329aa122b9cacb3c7de18a21353f53ea1d988ed\nSigned-off-by: karthik s <ksundara@redhat.com>\n""}, {'number': 2, 'created': '2017-02-15 09:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/1923ef1d17c73e1873c8d161b5204b4ac9dc501b', 'message': ""Remove deprecated parameter 'core_list'\n\nThe deprecated parameter 'core_list' shall be removed for Pike\n\nChange-Id: I2329aa122b9cacb3c7de18a21353f53ea1d988ed\nSigned-off-by: karthik s <ksundara@redhat.com>\n""}, {'number': 3, 'created': '2017-02-15 09:37:17.000000000', 'files': ['spec/classes/vswitch_dpdk_spec.rb', 'manifests/dpdk.pp'], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/b4039a58d9bac5b94b061827327e30f1615e4778', 'message': ""Remove deprecated parameter 'core_list'\n\nThe deprecated parameter 'core_list' shall be removed for Pike\n\nCloses-Bug: #1664859\nChange-Id: I2329aa122b9cacb3c7de18a21353f53ea1d988ed\nSigned-off-by: karthik s <ksundara@redhat.com>\n""}]",0,434153,b4039a58d9bac5b94b061827327e30f1615e4778,16,4,3,18904,,,0,"Remove deprecated parameter 'core_list'

The deprecated parameter 'core_list' shall be removed for Pike

Closes-Bug: #1664859
Change-Id: I2329aa122b9cacb3c7de18a21353f53ea1d988ed
Signed-off-by: karthik s <ksundara@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-vswitch refs/changes/53/434153/3 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/vswitch_dpdk_spec.rb', 'manifests/dpdk.pp']",2,b1674764763e6a3da1c8cc14eba83980560aa10b,bug/1664859," if !$host_core_list { $options = ""DPDK_OPTIONS = \""-l ${host_core_list} -n ${memory_channels} ${socket_string} ${white_list}\""""","# DEPRECATED PARAMETERS # # [*core_list*] # (optional) Deprecated. # The list of cores to be used by the DPDK Poll Mode Driver # The core_list is a string with format as <c1>[-c2][,c3[-c4],...] where c1, c2, etc are core indexes between 0 and 128 # For example, to configure 3 cores the value should be ""0-2"" # Defaults to undef. # # DEPRECATED PARAMETERS $core_list = undef, if $host_core_list { $core_list_string = $host_core_list } elsif $core_list { warning('core_list is deprecated, will be used when host_core_list is not defined and will be removed in a future release.') $core_list_string = $core_list } else { $options = ""DPDK_OPTIONS = \""-l ${core_list_string} -n ${memory_channels} ${socket_string} ${white_list}\""""",7,52
openstack%2Fpuppet-ceph~master~Ie8666c0e3a68776fb6d2fbcba1f04846eaa1782b,openstack/puppet-ceph,master,Ie8666c0e3a68776fb6d2fbcba1f04846eaa1782b,Ensure osd.pp moves to activate only after finishing prepare,MERGED,2017-02-15 15:00:17.000000000,2017-02-18 06:05:32.000000000,2017-02-18 06:05:32.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-15 15:00:17.000000000', 'files': ['manifests/osd.pp'], 'web_link': 'https://opendev.org/openstack/puppet-ceph/commit/f749fa16ceaa50d1b119a7f6eea82891175372af', 'message': 'Ensure osd.pp moves to activate only after finishing prepare\n\nEnsures the order in which osd.pp executes the prepare and\nactivation is preserved for all disks so that none of the OSDs is\nactivated until all prepare (and udevadm settle) finished for all\ndisks.\n\nChange-Id: Ie8666c0e3a68776fb6d2fbcba1f04846eaa1782b\n'}]",0,434330,f749fa16ceaa50d1b119a7f6eea82891175372af,13,3,1,6796,,,0,"Ensure osd.pp moves to activate only after finishing prepare

Ensures the order in which osd.pp executes the prepare and
activation is preserved for all disks so that none of the OSDs is
activated until all prepare (and udevadm settle) finished for all
disks.

Change-Id: Ie8666c0e3a68776fb6d2fbcba1f04846eaa1782b
",git fetch https://review.opendev.org/openstack/puppet-ceph refs/changes/30/434330/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/osd.pp'],1,f749fa16ceaa50d1b119a7f6eea82891175372af,parallelism," # Ensure none is activated before prepare is finished for all Exec<| tag == 'prepare' |> -> Exec<| tag == 'activate' |> tag => 'prepare', tag => 'activate',",,5,0
openstack%2Fcinder~stable%2Focata~Ie9a7815df99869b62209d99bfdcf51b250a8dba4,openstack/cinder,stable/ocata,Ie9a7815df99869b62209d99bfdcf51b250a8dba4,Fix attachments after attached migration,MERGED,2017-02-16 17:41:40.000000000,2017-02-18 05:42:04.000000000,2017-02-16 21:04:06.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 15296}, {'_account_id': 18444}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 23613}, {'_account_id': 24578}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-16 17:41:40.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/unit/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0df4175ac17c1eb7c5946b1347764ca1308feaf3', 'message': 'Fix attachments after attached migration\n\nWhen migrating an attached volume, after the migration completion,\nthe volume gots stuck and can not be deleted or detached. This\nis happening due an error in the volume completion implementation.\nNow, before detaching the source volume, we first save the\nattachments and then re-connect then in the destination volume.\n\nCloses-bug: #1659914\nChange-Id: Ie9a7815df99869b62209d99bfdcf51b250a8dba4\n(cherry picked from commit a5ae53867bbe7f66bd640061a68a690c6d217177)\n'}]",0,435043,0df4175ac17c1eb7c5946b1347764ca1308feaf3,17,10,1,10058,,,0,"Fix attachments after attached migration

When migrating an attached volume, after the migration completion,
the volume gots stuck and can not be deleted or detached. This
is happening due an error in the volume completion implementation.
Now, before detaching the source volume, we first save the
attachments and then re-connect then in the destination volume.

Closes-bug: #1659914
Change-Id: Ie9a7815df99869b62209d99bfdcf51b250a8dba4
(cherry picked from commit a5ae53867bbe7f66bd640061a68a690c6d217177)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/43/435043/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/unit/test_volume.py']",2,0df4175ac17c1eb7c5946b1347764ca1308feaf3,(detached," attachment = None attachment = vol['volume_attachment'][0] attachment['id']) mock_attach_volume.assert_called_once_with( self.context, old_volume, attachment['instance_uuid'], attachment['attached_host'], attachment['mountpoint'], 'rw' )", attachment_id = None attachment_id = vol['volume_attachment'][0]['id'] attachment_id),20,7
openstack%2Fsenlin~master~Ie0d3383a201635648ac8d90a25a200c9bec1257b,openstack/senlin,master,Ie0d3383a201635648ac8d90a25a200c9bec1257b,Fix node get bug in docker profile,MERGED,2017-02-04 16:49:02.000000000,2017-02-18 05:30:07.000000000,2017-02-17 04:23:39.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-04 16:49:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/19a9627b8a052ff2f7702faa0d413e553656da87', 'message': 'Fix node get bug of docker profile\n\nThis patch fixes node get bug of docker profile.\n\nCloses-Bug: #1661862\n\nChange-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b\n'}, {'number': 2, 'created': '2017-02-04 16:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b0e84ee52b0f5f2d46fadfdbfdcef2dbd4af826b', 'message': 'Fix node get bug in docker profile\n\nThis patch fixes node get bug in docker profile.\n\nCloses-Bug: #1661862\n\nChange-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b\n'}, {'number': 3, 'created': '2017-02-04 16:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e8cad99ef849e7f6b4d272b789ccdefc5355c160', 'message': 'Fix node get bug in docker profile\n\nThis patch fixes node get bug in docker profile.\n\nCloses-Bug: #1661862\n\nChange-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b\n'}, {'number': 4, 'created': '2017-02-17 02:57:37.000000000', 'files': ['senlin/profiles/container/docker.py', 'senlin/tests/unit/profiles/test_container_docker.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3b42887a4d1e938b474cb96024e5427bee07c07a', 'message': 'Fix node get bug in docker profile\n\nThis patch fixes node get bug in docker profile.\n\nCo-Authored-By: Qiming Teng (tengqim@cn.ibm.com)\nCloses-Bug: #1661862\n\nChange-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b\n'}]",1,429285,3b42887a4d1e938b474cb96024e5427bee07c07a,13,3,4,22998,,,0,"Fix node get bug in docker profile

This patch fixes node get bug in docker profile.

Co-Authored-By: Qiming Teng (tengqim@cn.ibm.com)
Closes-Bug: #1661862

Change-Id: Ie0d3383a201635648ac8d90a25a200c9bec1257b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/85/429285/3 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/container/docker.py', 'senlin/tests/unit/profiles/test_container_docker.py']",2,19a9627b8a052ff2f7702faa0d413e553656da87,bug/1661862," def test__get_host_node_found_by_node(self, mock_load): mock_load.assert_called_once_with(ctx, node_id='host_node', project_safe=True) @mock.patch.object(dp.DockerProfile, '_get_random_node') def test__get_host_node_found_by_cluster(self, mock_get): node = mock.Mock() mock_get.return_value = node ctx = mock.Mock() profile = dp.DockerProfile('container', self.spec) res = profile._get_host(ctx, None, 'host_cluster') self.assertEqual(node, res) mock_get.assert_called_once_with(ctx, 'host_cluster') mock_cluster.assert_called_once_with(ctx, cluster_id='host_cluster', project_safe=True)"," def test__get_host_node_found(self, mock_load): mock_load.assert_called_once_with(ctx, node_id='host_node')",23,6
openstack%2Fsenlin~master~Iab6c93149c5c86dfe859caed3591bf7ec5592f85,openstack/senlin,master,Iab6c93149c5c86dfe859caed3591bf7ec5592f85,Add support to REBOOT as a recovery action,MERGED,2017-02-16 03:51:45.000000000,2017-02-18 05:29:32.000000000,2017-02-16 14:42:30.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 22998}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-16 03:51:45.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/common/consts.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/e029863372dcbae158b610152da090db1ddd2d4f', 'message': 'Add support to REBOOT as a recovery action\n\nThis adds REBOOT as a recovery action for health policy. The reboot\noperation has been added to the nova server profile type a while ago.\n\nChange-Id: Iab6c93149c5c86dfe859caed3591bf7ec5592f85\n'}]",0,434618,e029863372dcbae158b610152da090db1ddd2d4f,8,4,1,8246,,,0,"Add support to REBOOT as a recovery action

This adds REBOOT as a recovery action for health policy. The reboot
operation has been added to the nova server profile type a while ago.

Change-Id: Iab6c93149c5c86dfe859caed3591bf7ec5592f85
",git fetch https://review.opendev.org/openstack/senlin refs/changes/18/434618/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/common/consts.py']",3,e029863372dcbae158b610152da090db1ddd2d4f,health-policy-reboot,"DETECTION_TYPES = ( LIFECYCLE_EVENTS, NODE_STATUS_POLLING, # LB_STATUS_POLLING, 'LIFECYCLE_EVENTS', 'NODE_STATUS_POLLING', # 'LB_STATUS_POLLING',RECOVERY_ACTIONS = ( RECOVER_REBOOT, RECOVER_REBUILD, RECOVER_RECREATE, ) = ( 'REBOOT', 'REBUILD', 'RECREATE', )","DETECTION_TYPES = ( LIFECYCLE_EVENTS, NODE_STATUS_POLLING, # LB_STATUS_POLLING, ) = ( 'LIFECYCLE_EVENTS', 'NODE_STATUS_POLLING', # 'LB_STATUS_POLLING', ) RECOVER_OPERATIONS = ( RECOVER_RECREATE, RECOVER_REBUILD, 'RECREATE', 'REBUILD',",34,23
openstack%2Fsenlin~master~Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e,openstack/senlin,master,Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e,Validating adjustment properties for scaling policy,MERGED,2017-02-16 08:14:27.000000000,2017-02-18 05:29:18.000000000,2017-02-17 00:47:33.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 22998}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-16 08:14:27.000000000', 'files': ['senlin/policies/scaling_policy.py', 'senlin/tests/unit/policies/test_scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/373cf4cf8aa0c75501af1cb35556fa034a5fda02', 'message': ""Validating adjustment properties for scaling policy\n\nThis adds some logics to validate the property values specified for a\nscaling policy. When we migrate the policy schema to use, e.g. oslo\nversioned objects, we don't need to re-invent all these checks again and\nagain.\n\nChange-Id: Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e\n""}]",0,434718,373cf4cf8aa0c75501af1cb35556fa034a5fda02,8,5,1,8246,,,0,"Validating adjustment properties for scaling policy

This adds some logics to validate the property values specified for a
scaling policy. When we migrate the policy schema to use, e.g. oslo
versioned objects, we don't need to re-invent all these checks again and
again.

Change-Id: Ie1cd18bc5b857fcb06783f146a6eb5dc5c74230e
",git fetch https://review.opendev.org/openstack/senlin refs/changes/18/434718/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/scaling_policy.py', 'senlin/tests/unit/policies/test_scaling_policy.py']",2,373cf4cf8aa0c75501af1cb35556fa034a5fda02,validation-scaling-policy,"import sixfrom senlin.common import exception as exc def test_validate(self): self.spec['properties']['adjustment'] = {} policy = sp.ScalingPolicy('p1', self.spec) policy.validate(self.context) def test_validate_bad_number(self): self.spec['properties']['adjustment'] = {""number"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'number' for 'adjustment' must be > 0"", six.text_type(ex)) def test_validate_bad_min_step(self): self.spec['properties']['adjustment'] = {""min_step"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'min_step' for 'adjustment' must be >= 0"", six.text_type(ex)) def test_validate_bad_cooldown(self): self.spec['properties']['adjustment'] = {""cooldown"": -1} policy = sp.ScalingPolicy('p1', self.spec) ex = self.assertRaises(exc.InvalidSpec, policy.validate, self.context) self.assertEqual(""the 'cooldown' for 'adjustment' must be >= 0"", six.text_type(ex)) ",,52,0
openstack%2Fsenlin~master~I87311a316549279a77fd5a71dcfe0bb72722355f,openstack/senlin,master,I87311a316549279a77fd5a71dcfe0bb72722355f,User reference documentation for health policy,MERGED,2017-02-16 02:47:30.000000000,2017-02-18 05:29:07.000000000,2017-02-16 12:10:47.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 17645}]","[{'number': 1, 'created': '2017-02-16 02:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/08824682815240819f873f7a4f74786c2c0456a8', 'message': 'User reference documentation for health policy\n\nThis is a first draft for the health policy reference. More contents\nwill be added/modified as the development makes progress.\n\nChange-Id: I87311a316549279a77fd5a71dcfe0bb72722355f\n'}, {'number': 2, 'created': '2017-02-16 08:30:04.000000000', 'files': ['doc/source/user/policy_types/health.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6f37c468285ee03014b9bafde9a2452a5831d8a5', 'message': 'User reference documentation for health policy\n\nThis is a first draft for the health policy reference. More contents\nwill be added/modified as the development makes progress.\n\nChange-Id: I87311a316549279a77fd5a71dcfe0bb72722355f\n'}]",10,434588,6f37c468285ee03014b9bafde9a2452a5831d8a5,12,4,2,8246,,,0,"User reference documentation for health policy

This is a first draft for the health policy reference. More contents
will be added/modified as the development makes progress.

Change-Id: I87311a316549279a77fd5a71dcfe0bb72722355f
",git fetch https://review.opendev.org/openstack/senlin refs/changes/88/434588/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/health.rst'],1,08824682815240819f873f7a4f74786c2c0456a8,ref-health-policy,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _ref-health-policy: ============= Health Policy ============= The health policy is designed for Senlin to detect cluster node failures and to recover them in a way customizable by users. The health policy is not meant to be an universal solution that can solve all problems related to high-availability. However, the ultimate goal for the development team is to provide an auto-healing framework that is usable, flexible, extensible for most deployment scenarios. The policy type is currently applicable to clusters whose profile type is one of ``os.nova.server`` or ``os.heat.stack``. This could be extended in future. .. note:: The health policy is still under rapid development. More features are being designed, implemented and verified. Its support status is still ``EXPERIMENTAL``, which means there could be changes at the discretion of the development team before it is formally supported. Properties ~~~~~~~~~~ A typical spec for a health policy looks like the following example: .. code-block:: yaml type: senlin.policy.health version: 1.0 properties: detection: type: NODE_STATUS_POLLING options: interval: 60 recovery: actions: - name: REBOOT params: type: soft fencing: - compute There are two groups of properties (``detection`` and ``recovery``) each provides information related to the failure detection and the failure recovery aspect respectively. For failure detection, you can specify one of the following two values: - ``NODE_STATUS_POLLING``: Senlin engine (more specifically, the health manager service) is expected to poll each and every nodes periodically to find out if they are ""alive"" or not. - ``LIFECYCLE_EVENTS``: Many services can emit notification messages on the message queue when configured. Senlin engine is expected to listen to these events and react to them appropriately. Both detection types can carry an optional map of ``options``. When the detection type is set to ""``NODE_STATUS_POLLING``"", for example, you can specify a value for ``interval`` property to customize the frequency at which your cluster nodes are polled. As the policy type implementation stabilizes, more options may be added later. For failure recovery, there are currently two properties: ``actions`` and ``fencing``. The ``actions`` property takes a list of action names and an optional map of parameters specific to that action. For example, the ``REBOOT`` action can be accompanied with a ``type`` parameter that indicates if the intended reboot operation is a soft reboot or a hard reboot. .. note:: The plan for recovery actions is to support a list of actions which can be tried one by one by the Senlin engine. Currently, you can specifiy only *one* action due to implementation limitation. Another extension to the recovery action is to add triggers to user provided workflows. This is also under development. Validation ~~~~~~~~~~ Due to implementation limitations, currently you can only specify *one* action for the ``recovery.actions`` property. This constraint will be removed soon after the support to action list is completed. Fencing ~~~~~~~ Fencing may be an important step during a reliable node recovery process. Without fencing, we cannot ensure that the compute, network and/or storage resources are in a consistent, predictable status. However, fencing is very difficult because it always involes an out-of-band operation to the resource controller, for example, an IPMI command to power off a physical host sent to a specific IP address. Currently, the health policy only supports the fencing of virtual machines by forcibly delete it before taking measures to recover it. Snapshots ~~~~~~~~~ There have been some requirements to take snapshots of a node before recovery so that the recovered node(s) will resume from where they failed. This feature is also on the TODO list for the development team. ",,126,0
openstack%2Fpuppet-horizon~master~Idd4ac6a271b4c8d8e53ab27c68abd821a3aa0249,openstack/puppet-horizon,master,Idd4ac6a271b4c8d8e53ab27c68abd821a3aa0249,Avoid empty redirect rule in vhost config,MERGED,2017-02-16 15:31:14.000000000,2017-02-18 05:24:06.000000000,2017-02-18 05:24:06.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 23757}]","[{'number': 1, 'created': '2017-02-16 15:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/b51b8c8018a474c621bd5932c8449fa21887d23b', 'message': 'Avoid empty redirect rule in vhost config\n\nWhen root_url is empty, an incorrect rewrite rule will be\ncreated at vhosts config file causing httpd failure.\nIn order not to create any rule when root_url is empty,\nthe value should be ignored inside redirectmatch parameter\n\nChange-Id: Idd4ac6a271b4c8d8e53ab27c68abd821a3aa0249\nCloses-bug: #1665380\n'}, {'number': 2, 'created': '2017-02-17 10:23:30.000000000', 'files': ['manifests/wsgi/apache.pp', 'releasenotes/notes/empty-root-url-495e1f1f47372f47.yaml', 'spec/classes/horizon_wsgi_apache_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-horizon/commit/003d69f69cdebc5eadcac79890316dc82777e637', 'message': 'Avoid empty redirect rule in vhost config\n\nWhen root_url is empty, an incorrect rewrite rule will be\ncreated at vhosts config file causing httpd failure.\nIn order not to create any rule when root_url is empty,\nthe value should be ignored inside redirectmatch parameter\n\nChange-Id: Idd4ac6a271b4c8d8e53ab27c68abd821a3aa0249\nCloses-bug: #1665380\n'}]",1,434973,003d69f69cdebc5eadcac79890316dc82777e637,51,6,2,23757,,,0,"Avoid empty redirect rule in vhost config

When root_url is empty, an incorrect rewrite rule will be
created at vhosts config file causing httpd failure.
In order not to create any rule when root_url is empty,
the value should be ignored inside redirectmatch parameter

Change-Id: Idd4ac6a271b4c8d8e53ab27c68abd821a3aa0249
Closes-bug: #1665380
",git fetch https://review.opendev.org/openstack/puppet-horizon refs/changes/73/434973/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/wsgi/apache.pp'],1,b51b8c8018a474c621bd5932c8449fa21887d23b,bug/1665380," redirectmatch_regexp => $root_url ? { '' => undef, '/' => undef, default => $redirect_match }, redirectmatch_dest => $root_url ? { '' => undef, '/' => undef, default => $redirect_url }, redirectmatch_regexp => $root_url ? { '' => undef, '/' => undef, default => '^/$' }, redirectmatch_dest => $root_url ? { '' => undef, '/' => undef, default => $root_url },"," redirectmatch_regexp => $root_url ? { '/' => undef, default => $redirect_match }, redirectmatch_dest => $root_url ? { '/' => undef, default => $redirect_url }, redirectmatch_regexp => $root_url ? { '/' => undef, default => '^/$' }, redirectmatch_dest => $root_url ? { '/' => undef, default => $root_url },",4,4
openstack%2Fneutron~master~I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd,openstack/neutron,master,I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd,Pecan: Get loaded by paste deploy,MERGED,2016-09-02 03:41:18.000000000,2017-02-18 05:11:04.000000000,2017-02-18 05:11:04.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10385}, {'_account_id': 12906}, {'_account_id': 14208}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 20330}, {'_account_id': 22524}]","[{'number': 1, 'created': '2016-09-02 03:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/152a8095620cf09ac084e51573f578f92803075c', 'message': '[WIP] Support paste deploy for Pecan web framework\n\nThis patch support paste deployment option for web framework Pecan.\n1. It provides an option to let a operator deploy with paste\n2. Add wsgi factory class methods for root level controllers.\n3. As result, adjust version viewer controller to RootController \n\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n'}, {'number': 2, 'created': '2016-09-07 21:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fdc24a8e44285f3a61a20e5a10f14c1eda7bd342', 'message': '[WIP] Support paste deploy for Pecan web framework\n\nThis patch support paste deployment option for web framework Pecan.\n1. It provides an option to let a operator deploy with paste\n2. Add wsgi factory class methods for root level controllers.\n3. As result, adjust version viewer controller to RootController\n\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n'}, {'number': 3, 'created': '2016-09-09 16:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca7cf451a3a7117a436ec846ac6da7d068f9e0ee', 'message': 'Support paste deploy for Pecan web framework\n\nThis patch support paste deployment option for web framework Pecan.\n1. It provides an option to let a operator deploy with paste\n2. Add wsgi factory class methods for root level controllers.\n3. As result, adjust version viewer controller to RootController\n\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n'}, {'number': 4, 'created': '2017-01-16 23:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9648b60ca6af526fa5c78c6a3e364fb098e80f8b', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}, {'number': 5, 'created': '2017-01-17 21:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7713fcfaae6f59d9f56b375d1d39cd86a6bef180', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}, {'number': 6, 'created': '2017-01-18 00:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18a915ee897671fd94061954fc8d9567582e7f2f', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}, {'number': 7, 'created': '2017-01-18 16:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b34b44dc23be2cd5bdc43f23260b8203e9cfadc4', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}, {'number': 8, 'created': '2017-01-18 18:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f39630a6271725708e32b5aa46722c82eb343c3e', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}, {'number': 9, 'created': '2017-02-17 20:54:48.000000000', 'files': ['neutron/pecan_wsgi/controllers/root.py', 'neutron/cmd/eventlet/server/__init__.py', 'neutron/tests/functional/pecan_wsgi/test_controllers.py', 'neutron/api/versions.py', 'neutron/pecan_wsgi/controllers/extensions.py', 'neutron/pecan_wsgi/hooks/policy_enforcement.py', 'neutron/tests/unit/api/v2/test_router.py', 'neutron/tests/functional/pecan_wsgi/test_functional.py', 'neutron/pecan_wsgi/app.py', 'neutron/pecan_wsgi/hooks/context.py', 'neutron/tests/unit/api/test_versions.py', 'neutron/tests/etc/api-paste.ini', 'neutron/api/v2/router.py', 'neutron/server/wsgi_pecan.py', 'neutron/pecan_wsgi/startup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebc7e1fb2f264bc91c9ad0f43e7e0208eede7a25', 'message': ""Pecan: Get loaded by paste deploy\n\nThis sets up the factory methods needed to have paste deploy create the\npecan app and return it.  It also changes the legacy factory methods to\nconditionally use the pecan factory methods if the web_framework config\noption is set to 'pecan'.  This way, all deployments of neutron will not\nneed to change their api-paste.ini files to get pecan toggled on.  It\nshould just happen without notice once pecan becomes the default.\n\nAlso, by moving this to be loaded by paste deploy, there is a good chunk of\ncode that has been removed because it is no longer necessary.\n\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\nChange-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd\n""}]",3,364651,ebc7e1fb2f264bc91c9ad0f43e7e0208eede7a25,93,17,9,12906,,,0,"Pecan: Get loaded by paste deploy

This sets up the factory methods needed to have paste deploy create the
pecan app and return it.  It also changes the legacy factory methods to
conditionally use the pecan factory methods if the web_framework config
option is set to 'pecan'.  This way, all deployments of neutron will not
need to change their api-paste.ini files to get pecan toggled on.  It
should just happen without notice once pecan becomes the default.

Also, by moving this to be loaded by paste deploy, there is a good chunk of
code that has been removed because it is no longer necessary.

Co-Authored-By: Brandon Logan <brandon.logan@rackspace.com>
Change-Id: I8b1bbea8d90fdc62715cd8b6738ad955df53d7cd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/364651/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/api-pecan-paste.ini', 'neutron/pecan_wsgi/app.py', 'neutron/pecan_wsgi/controllers/root.py', 'neutron/conf/common.py']",4,152a8095620cf09ac084e51573f578f92803075c,bp/wsgi-pecan-switch," cfg.BoolOpt('pecan_paste_deploy', default=False, help=_(""If True, when web framework is pecan, will use paste "" ""deploy to launch the WSGI app "")),",,100,12
openstack%2Fpuppet-nova~stable%2Focata~I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83,openstack/puppet-nova,stable/ocata,I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83,Make placement's os_interface configurable,MERGED,2017-02-16 23:00:44.000000000,2017-02-18 05:00:05.000000000,2017-02-18 05:00:05.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2017-02-16 23:00:44.000000000', 'files': ['manifests/placement.pp', 'spec/classes/nova_placement_spec.rb', 'releasenotes/notes/Add-nova-placement-interface-config-option-cc6d444666f00111.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/739f84be18c2211d5a42452838ca72dc8ef76317', 'message': ""Make placement's os_interface configurable\n\nthis exposes the os_interface option for the placement API\nconfiguration, which enables us to set the interface (public, internal\nor admin) to use for the placement API endpoint. Before, it was\nhardcoded to public, due to the keystoneauth1 library's defaults.\nThe change was introduced by Ic996e596f8473c0b8626e8d0e92e1bf58044b4f8\n\nChange-Id: I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83\nRelated-Bug: #1663187\n(cherry picked from commit 84343cebe85f8c177ed9970e99422c25068ac67c)\n""}]",0,435143,739f84be18c2211d5a42452838ca72dc8ef76317,42,4,1,3153,,,0,"Make placement's os_interface configurable

this exposes the os_interface option for the placement API
configuration, which enables us to set the interface (public, internal
or admin) to use for the placement API endpoint. Before, it was
hardcoded to public, due to the keystoneauth1 library's defaults.
The change was introduced by Ic996e596f8473c0b8626e8d0e92e1bf58044b4f8

Change-Id: I1c7fd3a32d04e2fafb3820d1c1f221f45c613c83
Related-Bug: #1663187
(cherry picked from commit 84343cebe85f8c177ed9970e99422c25068ac67c)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/43/435143/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/placement.pp', 'spec/classes/nova_placement_spec.rb', 'releasenotes/notes/Add-nova-placement-interface-config-option-cc6d444666f00111.yaml']",3,739f84be18c2211d5a42452838ca72dc8ef76317,bug/1663187,--- features: - The os_interface option for the nova placement API is not configurable. This allows nodes communicating with the placement API (such as the compute nodes) to be able to choose which keystone endpoint's interface to use. ,,62,32
openstack%2Fsenlin~stable%2Focata~Ic87c527af7791abcd4c2b5084b253776a935b986,openstack/senlin,stable/ocata,Ic87c527af7791abcd4c2b5084b253776a935b986,User reference documentation for batch policy,MERGED,2017-02-18 04:17:39.000000000,2017-02-18 04:43:43.000000000,2017-02-18 04:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 04:17:39.000000000', 'files': ['doc/source/user/policy_types/batch.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2616899599ee43e58e59e8ac83376167845a1664', 'message': 'User reference documentation for batch policy\n\nChange-Id: Ic87c527af7791abcd4c2b5084b253776a935b986\n(cherry picked from commit cee97063bf3a126fe709097923ec435de3faaf25)\n'}]",0,435654,2616899599ee43e58e59e8ac83376167845a1664,6,2,1,8246,,,0,"User reference documentation for batch policy

Change-Id: Ic87c527af7791abcd4c2b5084b253776a935b986
(cherry picked from commit cee97063bf3a126fe709097923ec435de3faaf25)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/54/435654/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/batch.rst'],1,2616899599ee43e58e59e8ac83376167845a1664,ref-batch-policy,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _ref-batch-policy: ============ Batch Policy ============ The batch policy is designed to automatically group a large number of operations into smaller batches so that the service interruption can be better managed and there won't be flood of service requests sending to any other services that will form a DOS (denial-of-service) attack. Currently, this policy is applicable to clusters of all profile types and it is enforced when cluster is updated or deleted. The development team is still looking for an elegant solution that can regulate the resource creation requests. Properties ~~~~~~~~~~ Below is a typical spec for a batch policy: .. code-block:: yaml type: senlin.policy.batch version: 1.0 properties: min_in_service: 8 max_batch_size: 3 pause_time: 30 The ``min_in_service`` property specifies the minimum number of nodes to be kept in ACTIVE status. This is mainly for cluster update use cases. The other property ``max_batch_size`` specifies the number of nodes to be updated or deleted in each batch. This property is mainly used to ensure that batch requests are still within the processing capability of a backend service. Between each batch of service requests, you can specify an interval in the unit of seconds using the ``pause_time`` property. This can be used to ensure that updated nodes are fully active to provide services, for example. ",,54,0
openstack%2Fsenlin~stable%2Focata~I70ff9d7bf10869c725021e096733fecb46d181c6,openstack/senlin,stable/ocata,I70ff9d7bf10869c725021e096733fecb46d181c6,Revise action_delete_by_target api,MERGED,2017-02-18 03:20:20.000000000,2017-02-18 04:41:51.000000000,2017-02-18 04:41:51.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 03:20:20.000000000', 'files': ['senlin/objects/action.py', 'senlin/db/api.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/0336713421af06e9a0b9cdee83188f328475dc8f', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n(cherry picked from commit 95b685e85264219e9c81c94cafdb72269f291a8d)\n""}]",0,435643,0336713421af06e9a0b9cdee83188f328475dc8f,6,2,1,8246,,,0,"Revise action_delete_by_target api

This patch revises action_delete_by_target api.
It's a prepare for deleting action.
partial-blueprint: improve-action-event

Change-Id: I70ff9d7bf10869c725021e096733fecb46d181c6
(cherry picked from commit 95b685e85264219e9c81c94cafdb72269f291a8d)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/43/435643/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/objects/action.py', 'senlin/db/api.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/db/sqlalchemy/api.py']",4,0336713421af06e9a0b9cdee83188f328475dc8f,bp/improve-action-event,"def action_delete_by_target(context, target, action=None, action_excluded=None, status=None, project_safe=True): if action and action_excluded: msg = _(""action and action_excluded cannot be specified "" ""both."") LOG.warning(msg) return None with session_for_write() as session: q = session.query(models.Action).\ filter_by(target=target) if project_safe: q = q.filter_by(project=context.project) if action: q = q.filter(models.Action.action.in_(action)) if action_excluded: q = q.filter(~models.Action.action.in_(action_excluded)) if status: q = q.filter(models.Action.status.in_(status)) return q.delete(synchronize_session='fetch') ","def action_delete_by_target(context, target, exceptions=None): with session_for_write() as session: q = session.query(models.Action).\ filter(models.Action.target == target) if exceptions: q = q.filter(~models.Action.action.in_(exceptions)) return q.delete(synchronize_session='fetch') ",93,13
openstack%2Fsenlin~stable%2Focata~I4074f937e411f6a1299d23b1611ae58a74cd6bec,openstack/senlin,stable/ocata,I4074f937e411f6a1299d23b1611ae58a74cd6bec,Fix health registry claim bug,MERGED,2017-02-18 03:19:41.000000000,2017-02-18 04:41:46.000000000,2017-02-18 04:41:45.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 03:19:41.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4e2dfc3c566b4ec0859aceabd35b52eaf8c04cd8', 'message': 'Fix health registry claim bug\n\nThis patch fixes health registry claim bug\nwhich will cause health policy cannot work.\n\nChange-Id: I4074f937e411f6a1299d23b1611ae58a74cd6bec\nCloses-Bug: #1658661\n(cherry picked from commit bff4a7877d4dcfc7b7d4a012337a443b016d4ddc)\n'}]",0,435642,4e2dfc3c566b4ec0859aceabd35b52eaf8c04cd8,6,2,1,8246,,,0,"Fix health registry claim bug

This patch fixes health registry claim bug
which will cause health policy cannot work.

Change-Id: I4074f937e411f6a1299d23b1611ae58a74cd6bec
Closes-Bug: #1658661
(cherry picked from commit bff4a7877d4dcfc7b7d4a012337a443b016d4ddc)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/42/435642/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py']",2,4e2dfc3c566b4ec0859aceabd35b52eaf8c04cd8,bug/1658661," @mock.patch.object(hm.HealthManager, ""_load_runtime_registry"") def test__dummy_task(self, mock_load): self.hm._dummy_task() mock_load.assert_called_once_with() "," mock_load = self.patchobject(self.hm, '_load_runtime_registry') mock_load.assert_called_once_with()",6,4
openstack%2Fsenlin~stable%2Focata~I8da000c3451275ac5a300fe9071946dcbaaf2bd8,openstack/senlin,stable/ocata,I8da000c3451275ac5a300fe9071946dcbaaf2bd8,Fix update timeout field of cluster failed,MERGED,2017-02-18 03:20:54.000000000,2017-02-18 04:41:40.000000000,2017-02-18 04:41:40.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 03:20:54.000000000', 'files': ['senlin/objects/requests/clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/04fdf4224141da88459c72a7bf2e2535c9bd21f6', 'message': 'Fix update timeout field of cluster failed\n\nReplace timeout type and use NonNegativeIntegerField instead\n\nChange-Id: I8da000c3451275ac5a300fe9071946dcbaaf2bd8\n(cherry picked from commit efa9ff81553fed0210a70ec3cee39b9d8011cfda)\n'}]",0,435644,04fdf4224141da88459c72a7bf2e2535c9bd21f6,6,2,1,8246,,,0,"Fix update timeout field of cluster failed

Replace timeout type and use NonNegativeIntegerField instead

Change-Id: I8da000c3451275ac5a300fe9071946dcbaaf2bd8
(cherry picked from commit efa9ff81553fed0210a70ec3cee39b9d8011cfda)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/435644/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/objects/requests/clusters.py'],1,04fdf4224141da88459c72a7bf2e2535c9bd21f6,fix/cluster_update," 'timeout': fields.NonNegativeIntegerField(nullable=True),"," 'timeout': fields.IntegerField(nullable=True),",1,1
openstack%2Fsenlin~master~I803d034d9f820c92daa528870449205b2723d813,openstack/senlin,master,I803d034d9f820c92daa528870449205b2723d813,Revise params check when cluster update,MERGED,2017-02-16 01:52:25.000000000,2017-02-18 04:17:50.000000000,2017-02-16 09:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 17812}]","[{'number': 1, 'created': '2017-02-16 01:52:25.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a258c49e5ff5d40ec1d06a16d04f142eedab9874', 'message': ""Revise params check when cluster update\n\nAdd check with timeout and name, don't need update\nif property value not changed.\n\nChange-Id: I803d034d9f820c92daa528870449205b2723d813\n""}]",0,434576,a258c49e5ff5d40ec1d06a16d04f142eedab9874,9,4,1,15917,,,0,"Revise params check when cluster update

Add check with timeout and name, don't need update
if property value not changed.

Change-Id: I803d034d9f820c92daa528870449205b2723d813
",git fetch https://review.opendev.org/openstack/senlin refs/changes/76/434576/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py']",2,a258c49e5ff5d40ec1d06a16d04f142eedab9874,revise/cluser_update," @mock.patch.object(am.Action, 'create') @mock.patch.object(co.Cluster, 'find') @mock.patch.object(dispatcher, 'start_action') def test_cluster_update_same_timeout(self, notify, mock_find, mock_action): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', timeout=10) x_cluster.to_dict.return_value = {'foo': 'bar'} x_cluster.timeout = 10 mock_find.return_value = x_cluster mock_action.return_value = 'ACTION_ID' req = orco.ClusterUpdateRequest(identity='FAKE_ID', name='NEW_NAME', timeout=10) # do it result = self.eng.cluster_update(self.ctx, req.obj_to_primitive()) self.assertEqual({'action': 'ACTION_ID', 'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_ID') mock_action.assert_called_once_with( self.ctx, '12345678AB', 'CLUSTER_UPDATE', name='cluster_update_12345678', status=am.Action.READY, cause=consts.CAUSE_RPC, inputs={ # Note timeout is not included in the inputs 'name': 'NEW_NAME', }, ) notify.assert_called_once_with() @mock.patch.object(am.Action, 'create') @mock.patch.object(co.Cluster, 'find') @mock.patch.object(dispatcher, 'start_action') def test_cluster_update_same_name(self, notify, mock_find, mock_action): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', name='OLD_NAME', timeout=10) x_cluster.name = 'OLD_NAME' x_cluster.to_dict.return_value = {'foo': 'bar'} mock_find.return_value = x_cluster mock_action.return_value = 'ACTION_ID' req = orco.ClusterUpdateRequest(identity='FAKE_ID', name='OLD_NAME', timeout=100) # do it result = self.eng.cluster_update(self.ctx, req.obj_to_primitive()) self.assertEqual({'action': 'ACTION_ID', 'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_ID') mock_action.assert_called_once_with( self.ctx, '12345678AB', 'CLUSTER_UPDATE', name='cluster_update_12345678', status=am.Action.READY, cause=consts.CAUSE_RPC, inputs={ # Note name is not included in the inputs 'timeout': 100, }, ) notify.assert_called_once_with() @mock.patch.object(co.Cluster, 'find') def test_cluster_update_all_property_same(self, mock_find): x_cluster = mock.Mock(id='12345678AB', status='ACTIVE', name='OLD_NAME', timeout=10) x_cluster.name = 'OLD_NAME' x_cluster.timeout = 10 mock_find.return_value = x_cluster # Notice that name and timeout are all not changed. req = orco.ClusterUpdateRequest(identity='CLUSTER', name='OLD_NAME', timeout=10) ex = self.assertRaises(rpc.ExpectedException, self.eng.cluster_update, self.ctx, req.obj_to_primitive()) self.assertEqual(exc.BadRequest, ex.exc_info[0]) self.assertEqual('', six.text_type(ex)) ",,85,2
openstack%2Fsenlin~master~Ic87c527af7791abcd4c2b5084b253776a935b986,openstack/senlin,master,Ic87c527af7791abcd4c2b5084b253776a935b986,User reference documentation for batch policy,MERGED,2017-02-15 13:24:45.000000000,2017-02-18 04:17:39.000000000,2017-02-16 14:30:20.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 22998}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-15 13:24:45.000000000', 'files': ['doc/source/user/policy_types/batch.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/cee97063bf3a126fe709097923ec435de3faaf25', 'message': 'User reference documentation for batch policy\n\nChange-Id: Ic87c527af7791abcd4c2b5084b253776a935b986\n'}]",0,434267,cee97063bf3a126fe709097923ec435de3faaf25,8,4,1,8246,,,0,"User reference documentation for batch policy

Change-Id: Ic87c527af7791abcd4c2b5084b253776a935b986
",git fetch https://review.opendev.org/openstack/senlin refs/changes/67/434267/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/batch.rst'],1,cee97063bf3a126fe709097923ec435de3faaf25,ref-batch-policy,".. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. .. _ref-batch-policy: ============ Batch Policy ============ The batch policy is designed to automatically group a large number of operations into smaller batches so that the service interruption can be better managed and there won't be flood of service requests sending to any other services that will form a DOS (denial-of-service) attack. Currently, this policy is applicable to clusters of all profile types and it is enforced when cluster is updated or deleted. The development team is still looking for an elegant solution that can regulate the resource creation requests. Properties ~~~~~~~~~~ Below is a typical spec for a batch policy: .. code-block:: yaml type: senlin.policy.batch version: 1.0 properties: min_in_service: 8 max_batch_size: 3 pause_time: 30 The ``min_in_service`` property specifies the minimum number of nodes to be kept in ACTIVE status. This is mainly for cluster update use cases. The other property ``max_batch_size`` specifies the number of nodes to be updated or deleted in each batch. This property is mainly used to ensure that batch requests are still within the processing capability of a backend service. Between each batch of service requests, you can specify an interval in the unit of seconds using the ``pause_time`` property. This can be used to ensure that updated nodes are fully active to provide services, for example. ",,54,0
openstack%2Fsenlin~master~Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9,openstack/senlin,master,Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9,User reference doc for scaling policy,MERGED,2017-02-15 12:49:10.000000000,2017-02-18 04:17:31.000000000,2017-02-16 14:30:14.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 22998}, {'_account_id': 23401}]","[{'number': 1, 'created': '2017-02-15 12:49:10.000000000', 'files': ['doc/source/user/policy_types/scaling.rst', 'senlin/policies/scaling_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/431715ddda7fdd754a4c3da59d3920e758568164', 'message': 'User reference doc for scaling policy\n\nChange-Id: Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9\n'}]",0,434257,431715ddda7fdd754a4c3da59d3920e758568164,8,4,1,8246,,,0,"User reference doc for scaling policy

Change-Id: Ifcf6e5bc714e1c154194e9ec6dea7e84a79d13c9
",git fetch https://review.opendev.org/openstack/senlin refs/changes/57/434257/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/policy_types/scaling.rst', 'senlin/policies/scaling_policy.py']",2,431715ddda7fdd754a4c3da59d3920e758568164,ref-scaling-policy, :param dict kwargs: Other optional parameters for policy object creation., :param \*\*kwargs: Other optional parameters for policy object creation.,143,3
openstack%2Fcinder~stable%2Focata~Id9f39ddab3a3648b8721b711ecf78c18c8293451,openstack/cinder,stable/ocata,Id9f39ddab3a3648b8721b711ecf78c18c8293451,Fix volume retype with migration as non-admin,MERGED,2017-02-16 17:16:20.000000000,2017-02-18 04:11:54.000000000,2017-02-17 01:53:01.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 11904}, {'_account_id': 15296}, {'_account_id': 18444}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 23613}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-02-16 17:16:20.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/unit/volume/__init__.py', 'cinder/tests/unit/test_volume.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ac2d2f947f47c9894e4eae9d39408b6fb93e3197', 'message': 'Fix volume retype with migration as non-admin\n\nAs a non-admin user, when retyping a volume from type\nA -> B, where both types are in different backends,\nCinder will complete the operation but the volumes will\n not be migrated.\n\nThis happens because the retype operation relies in\ngetting the extra_specs information to the related type,\nbut extra_specs is only avaiable in admin context.\n\nCloses-bug: #1657806\nChange-Id: Id9f39ddab3a3648b8721b711ecf78c18c8293451\n(cherry picked from commit 7aecdf919c16a4e06389c1354a531d55057e2566)\n'}]",0,435032,ac2d2f947f47c9894e4eae9d39408b6fb93e3197,19,9,1,10058,,,0,"Fix volume retype with migration as non-admin

As a non-admin user, when retyping a volume from type
A -> B, where both types are in different backends,
Cinder will complete the operation but the volumes will
 not be migrated.

This happens because the retype operation relies in
getting the extra_specs information to the related type,
but extra_specs is only avaiable in admin context.

Closes-bug: #1657806
Change-Id: Id9f39ddab3a3648b8721b711ecf78c18c8293451
(cherry picked from commit 7aecdf919c16a4e06389c1354a531d55057e2566)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/32/435032/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/unit/volume/__init__.py', 'cinder/tests/unit/test_volume.py']",3,ac2d2f947f47c9894e4eae9d39408b6fb93e3197,(detached," snap.user_id = kwargs.get('user_id', fake.USER_ID) snap.project_id = kwargs.get('project_id', fake.PROJECT_ID) create_snapshot(volume.id, size=volume.size, user_id=self.user_context.user_id, project_id=self.user_context.project_id, ctxt=self.user_context) mock.patch.object(db.sqlalchemy.api, 'volume_get') as _vget,\ mock.patch.object(context.RequestContext, 'elevated') as _ctx: _vget.return_value = volume _ctx.return_value = self.context"," snap.user_id = fake.USER_ID snap.project_id = fake.PROJECT_ID create_snapshot(volume.id, size=volume.size) mock.patch.object(db.sqlalchemy.api, 'volume_get') as mock_get: mock_get.return_value = volume",24,13
openstack%2Ftripleo-ci~master~Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e,openstack/tripleo-ci,master,Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e,remove test-environments/multinode_major_upgrade.yaml,MERGED,2017-01-27 19:47:10.000000000,2017-02-18 04:03:41.000000000,2017-02-18 04:03:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8449}, {'_account_id': 10969}, {'_account_id': 16515}, {'_account_id': 20775}]","[{'number': 1, 'created': '2017-01-27 19:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0e992552ed61994884e822acff5500451d4646c0', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\nDepends-On: I931534e0ec33e131809186f74068eb479d38a0f9\n""}, {'number': 2, 'created': '2017-01-27 20:27:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6ca6cc94ccebc220b3e5b0711a7ae7757eaf98cd', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\nDepends-On: I931534e0ec33e131809186f74068eb479d38a0f9\n""}, {'number': 3, 'created': '2017-01-27 20:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ad566997c95b3129eb2696b34e7c48f07191c50a', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\nDepends-On: I931534e0ec33e131809186f74068eb479d38a0f9\n""}, {'number': 4, 'created': '2017-02-09 14:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7b0f2a20f56b27e3d40aa13eb677ea623448073e', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n""}, {'number': 5, 'created': '2017-02-10 15:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/535b4b4adba4bf26c4ccba47d8e59acae83b39ad', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n""}, {'number': 6, 'created': '2017-02-11 01:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d48c1574f979d25e216cbc69a3560d655e4af7ba', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n""}, {'number': 7, 'created': '2017-02-14 16:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c1e4f165ee1e2b451780655d880831be3d9c8f32', 'message': ""Remove test-environments/multinode_major_upgrade.yaml\n\nIt's not in THT.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n""}, {'number': 8, 'created': '2017-02-15 18:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f3e6b0e7d8a29d3e109d87c97839481a93799756', 'message': 'Remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nDepends-On: I78bd5c804284219a71b13dba21fd1188ca854fca\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 9, 'created': '2017-02-16 02:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f131e8b51e63d63076addf172d069203544ef7a4', 'message': 'Remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nDepends-On: I78bd5c804284219a71b13dba21fd1188ca854fca\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 10, 'created': '2017-02-16 20:58:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/dc5ab0025ddc45e887e13740f45a70c88f39a858', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nDepends-On: I78bd5c804284219a71b13dba21fd1188ca854fca\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 11, 'created': '2017-02-16 23:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6147d83823de175ca7af052b8220aefc55a8aefe', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nDepends-On: I78bd5c804284219a71b13dba21fd1188ca854fca\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 12, 'created': '2017-02-16 23:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/39addd4b223700ead8aff78b73b274b641f21637', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 13, 'created': '2017-02-17 09:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7659bf2506b988d86314c18f18a6b2c073d100d0', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 14, 'created': '2017-02-17 10:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/546dbed79e45d446d27d2b6b5a8921e8efc22618', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 15, 'created': '2017-02-17 11:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/102febc1c6a2a8d40d351dc5c5399931d9389136', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nDepends-On: Ie4c67ce232de8086ad1275d80432ef321cdbc573\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 16, 'created': '2017-02-17 23:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/388d0ebcc29c6e96d301d0928869272e512281db', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}, {'number': 17, 'created': '2017-02-17 23:29:50.000000000', 'files': ['test-environments/multinode_major_upgrade.yaml', 'scripts/common_functions.sh', 'scripts/deploy.sh', 'toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a52bbde43fc5b7d43a8c9e3785efc64b26530682', 'message': 'remove test-environments/multinode_major_upgrade.yaml\n\nThis is now in t-h-t so we should only use that version.\n\nNote this means we use the master version of the env for\ndefining the service list for the deployed (newton) overcloud.\n\nChange-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e\n'}]",10,426375,a52bbde43fc5b7d43a8c9e3785efc64b26530682,98,7,17,3153,,,0,"remove test-environments/multinode_major_upgrade.yaml

This is now in t-h-t so we should only use that version.

Note this means we use the master version of the env for
defining the service list for the deployed (newton) overcloud.

Change-Id: Ia7cc49daf8e9e26e3dee9db6f1bdb53b543b658e
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/75/426375/16 && git format-patch -1 --stdout FETCH_HEAD,"['test-environments/multinode_major_upgrade.yaml', 'toci_gate_test.sh']",2,0e992552ed61994884e822acff5500451d4646c0,upgrade_env_tht, UPGRADE_ENV=/usr/share/openstack-tripleo-heat-templates/ci/environments/multinode_major_upgrade.yaml, if [ -e /usr/share/openstack-tripleo-heat-templates/ci/environments/multinode_major_upgrade.yaml ]; then UPGRADE_ENV=/usr/share/openstack-tripleo-heat-templates/ci/environments/multinode_major_upgrade.yaml else # For backward compatibility until https://review.openstack.org/425690 is merged & packaged. UPGRADE_ENV=$TRIPLEO_ROOT/tripleo-ci/test-environments/multinode_major_upgrade.yaml fi,1,52
openstack%2Fsenlin~stable%2Focata~I32406c4afb6566f0001d479b9b6368c90367dcb6,openstack/senlin,stable/ocata,I32406c4afb6566f0001d479b9b6368c90367dcb6,Revise cluster action,MERGED,2017-02-18 02:48:19.000000000,2017-02-18 04:02:42.000000000,2017-02-18 04:02:42.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 02:48:19.000000000', 'files': ['senlin/api/openstack/v1/clusters.py', 'senlin/tests/unit/api/openstack/v1/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7667323c998a1853b87d7a654053d189d2d7a9a4', 'message': 'Revise cluster action\n\nThis patch revise api of cluster action, change all action\nmethod name to `_do_{{action}}`, if we want to add new actions\nin future, just need to realize _do_{{action}} method.\n\nChange-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6\n(cherry picked from commit e830b0d003bbd105f34c02757bd1e8256ad13436)\n'}]",0,435639,7667323c998a1853b87d7a654053d189d2d7a9a4,6,2,1,8246,,,0,"Revise cluster action

This patch revise api of cluster action, change all action
method name to `_do_{{action}}`, if we want to add new actions
in future, just need to realize _do_{{action}} method.

Change-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6
(cherry picked from commit e830b0d003bbd105f34c02757bd1e8256ad13436)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/39/435639/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/openstack/v1/clusters.py', 'senlin/tests/unit/api/openstack/v1/test_clusters.py']",2,7667323c998a1853b87d7a654053d189d2d7a9a4,revise/cluster_action," def test__do_add_nodes(self, mock_call, mock_parse, mock_enforce): data = dict(nodes=['NODE1']) resp = self.controller._do_add_nodes(req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_add_nodes_failed_request(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE2']) self.controller._do_add_nodes, req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) data = dict(nodes=['NODE3']) self.controller._do_add_nodes, req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_del_nodes(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE4'], destroy=False) resp = self.controller._do_del_nodes(req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_del_nodes_failed_request(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE5'], destroy=False) self.controller._do_del_nodes, req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_del_nodes_failed_engine(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE6'], destroy=False) self.controller._do_del_nodes, req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_replace_nodes(self, mock_call, mock_parse, _ignore): data = dict(nodes={'OLD': 'NEW'}) resp = self.controller._do_replace_nodes(req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_replace_nodes_none(self, mock_call, mock_parse, _ign): data = dict(nodes=None) self.controller._do_replace_nodes, req, cid, data) def test__do_replace_nodes_not_map(self, mock_call, mock_parse, _ign): data = dict(nodes=['abc', 'def']) self.controller._do_replace_nodes, req, cid, data) def test__do_replace_nodes_failed_request(self, mock_call, mock_parse, _ign): data = dict(nodes={'OLD': 'NEW'}) self.controller._do_replace_nodes, req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_replace_nodes_failed_engine(self, mock_call, mock_parse, _ign): data = dict(nodes={'OLD': 'NEW'}) self.controller._do_replace_nodes, req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def _test_do_resize_with_type(self, adj_type, mock_call, mock_parse): self._test_do_resize_with_type('EXACT_CAPACITY') self._test_do_resize_with_type('CHANGE_IN_CAPACITY') self._test_do_resize_with_type('CHANGE_IN_PERCENTAGE') data = dict(count=1) resp = self.controller._do_scale_out(req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=2) req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=3) req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=4) resp = self.controller._do_scale_in(req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=5) req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=6) req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} )"," def test__add_nodes(self, mock_call, mock_parse, mock_enforce): nodes = ['NODE1'] resp = self.controller._add_nodes(req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__add_nodes_failed_request(self, mock_call, mock_parse, _ignore): nodes = ['NODE2'] self.controller._add_nodes, req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) nodes = ['NODE3'] self.controller._add_nodes, req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__del_nodes(self, mock_call, mock_parse, _ignore): nodes = ['NODE4'] destroy = False resp = self.controller._del_nodes(req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__del_nodes_failed_request(self, mock_call, mock_parse, _ignore): nodes = ['NODE5'] destroy = False self.controller._del_nodes, req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__del_nodes_failed_engine(self, mock_call, mock_parse, _ignore): nodes = ['NODE6'] destroy = False self.controller._del_nodes, req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__replace_nodes(self, mock_call, mock_parse, _ignore): nodes = {'OLD': 'NEW'} resp = self.controller._replace_nodes(req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__replace_nodes_none(self, mock_call, mock_parse, _ign): self.controller._replace_nodes, req, cid, None) def test__replace_nodes_not_map(self, mock_call, mock_parse, _ign): nodes = ['abc', 'def'] self.controller._replace_nodes, req, cid, nodes) def test__replace_nodes_failed_request(self, mock_call, mock_parse, _ign): nodes = {'OLD': 'NEW'} self.controller._replace_nodes, req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__replace_nodes_failed_engine(self, mock_call, mock_parse, _ign): nodes = {'OLD': 'NEW'} self.controller._replace_nodes, req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def _test_resize_with_type(self, adj_type, mock_call, mock_parse): self._test_resize_with_type('EXACT_CAPACITY') self._test_resize_with_type('CHANGE_IN_CAPACITY') self._test_resize_with_type('CHANGE_IN_PERCENTAGE') count = 1 resp = self.controller._do_scale_out(req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 2 req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 3 req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 4 resp = self.controller._do_scale_in(req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count}) count = 5 req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count}) count = 6 req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count})",132,117
openstack%2Fdragonflow~master~Ibffeabe719c66ba8ac3a86473183528399bb91c2,openstack/dragonflow,master,Ibffeabe719c66ba8ac3a86473183528399bb91c2,Remove useless parameter,ABANDONED,2017-02-16 12:15:00.000000000,2017-02-18 03:56:46.000000000,,"[{'_account_id': 3}, {'_account_id': 11159}]","[{'number': 1, 'created': '2017-02-16 12:15:00.000000000', 'files': ['dragonflow/controller/dnat_app.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/30018f9bb81edfc1abd0cebff5689adc60457070', 'message': 'Remove useless parameter\n\nChange-Id: Ibffeabe719c66ba8ac3a86473183528399bb91c2\n'}]",0,434861,30018f9bb81edfc1abd0cebff5689adc60457070,4,2,1,22060,,,0,"Remove useless parameter

Change-Id: Ibffeabe719c66ba8ac3a86473183528399bb91c2
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/61/434861/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/dnat_app.py'],1,30018f9bb81edfc1abd0cebff5689adc60457070,, def switch_features_handler(self):," def switch_features_handler(self, ev):",1,1
openstack%2Fsenlin~stable%2Focata~Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4,openstack/senlin,stable/ocata,Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4,Use 'get_service_context' in health manager,MERGED,2017-02-18 02:47:13.000000000,2017-02-18 03:56:45.000000000,2017-02-18 03:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-18 02:47:13.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/engine/receivers/base.py', 'senlin/common/context.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/e81b5b418f84ed6622a0847cc1e1741476e0fcc7', 'message': ""Use 'get_service_context' in health manager\n\nUse the 'get_service_context' utility function instead of the\n'get_service_credentials' function in health manager.\n\nChange-Id: Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4\n(cherry picked from commit c9253b7cc5750f5de5a031e824b32383e232af42)\n""}]",0,435638,e81b5b418f84ed6622a0847cc1e1741476e0fcc7,6,2,1,8246,,,0,"Use 'get_service_context' in health manager

Use the 'get_service_context' utility function instead of the
'get_service_credentials' function in health manager.

Change-Id: Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4
(cherry picked from commit c9253b7cc5750f5de5a031e824b32383e232af42)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/38/435638/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py']",4,e81b5b418f84ed6622a0847cc1e1741476e0fcc7,get-svc-ctx, identity_service = driver_base.SenlinDriver().identity creds = identity_service.get_service_credentials(**kwargs) return RequestContext.from_dict(creds), return get_service_credentials(**kwargs),21,48
openstack%2Fpython-openstackclient~master~I3572635d5913d971a723a62d7790ffe0f20ec39a,openstack/python-openstackclient,master,I3572635d5913d971a723a62d7790ffe0f20ec39a,"Add ""encryption-*"" options in volume type commands",MERGED,2016-12-22 15:32:29.000000000,2017-02-18 03:36:06.000000000,2017-02-18 03:36:06.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 11904}, {'_account_id': 21514}]","[{'number': 1, 'created': '2016-12-22 15:32:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/7fb13edd232c1cc785b8a7166579a90023427427', 'message': 'WIP: Add options in ""volume type set"" command\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" command to implement the\ncinder commands ""cinder encryption_type_create"" and\n""cinder encryption_type_update"" in OSC\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 2, 'created': '2016-12-28 14:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a0f01c9f391acda8b4e310ed01d75e06ec0e6b12', 'message': 'Add options in ""volume type set"" command\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" command to implement the\ncinder commands ""cinder encryption_type_create"" and\n""cinder encryption_type_update"" in OSC\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 3, 'created': '2016-12-28 14:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1a3dc5e3006c808a76b63b86249f66711729a535', 'message': 'Add options in ""volume type set"" command\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" command to implement the\ncinder commands ""cinder encryption_type_create"" and\n""cinder encryption_type_update"" in OSC\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 4, 'created': '2016-12-30 02:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/03bea0e04ee4d0ac4d3ab220adae16ae597616e0', 'message': 'Add options in ""volume type set"" command\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" command to implement the\ncinder commands ""cinder encryption_type_create"" and\n""cinder encryption_type_update"" in OSC\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 5, 'created': '2017-01-04 16:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/772266699cbad349e098f02e2d262e213128952c', 'message': 'Add ""encryption-*"" options in ""volume type set/unset/create""\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"" command.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 6, 'created': '2017-01-05 01:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e53d205c0c67080857d687dac23ea5ab88913e37', 'message': 'Add ""encryption-*"" options in ""volume type set/unset/create""\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"" command.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 7, 'created': '2017-01-05 12:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6bbbc2a89bbb41963b1101a33c029104691b43db', 'message': 'Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 8, 'created': '2017-01-05 12:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0deb807391a727b9bb73ad1299a76382cca1e891', 'message': 'Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 9, 'created': '2017-01-09 13:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e8ecbfdd01619c3afe7a5016bd6d65612041f323', 'message': 'WIP: Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 10, 'created': '2017-01-10 15:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1e9a462546faca2de12fdbcccceed218fd041976', 'message': 'Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nPartial-Bug: #1651117\n'}, {'number': 11, 'created': '2017-01-11 13:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/362364aa6b2dfdac0cf90b22f54da60b0c4e844d', 'message': 'Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nCloses-Bug: #1651117\n'}, {'number': 12, 'created': '2017-01-14 13:57:28.000000000', 'files': ['openstackclient/tests/unit/volume/v1/fakes.py', 'openstackclient/tests/unit/volume/v2/test_type.py', 'doc/source/command-objects/volume-type.rst', 'openstackclient/tests/functional/volume/v2/test_volume_type.py', 'openstackclient/tests/unit/volume/v2/fakes.py', 'openstackclient/volume/v1/volume_type.py', 'openstackclient/volume/v2/volume_type.py', 'releasenotes/notes/bug-1651117-a1df37e7ea939ba4.yaml', 'openstackclient/tests/functional/volume/v1/test_volume_type.py', 'openstackclient/tests/unit/volume/v1/test_type.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b2fd8ba869cd4b8e927118f7712d0ed7fb60309f', 'message': 'Add ""encryption-*"" options in volume type commands\n\nAdd ""--encryption-provider"", ""--encryption-cipher"",\n""--encryption-key-size"" and ""--encryption-control-location""\noptions to ""volume type set"" and ""volume type create"" commands.\nAdd ""--encryption-type"" option to ""volume type unset"",\n""volume type list"" and ""volume type show"" commands.\n\nChange-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a\nImplements: bp cinder-command-support\nCloses-Bug: #1651117\n'}]",40,414197,b2fd8ba869cd4b8e927118f7712d0ed7fb60309f,57,8,12,21514,,,0,"Add ""encryption-*"" options in volume type commands

Add ""--encryption-provider"", ""--encryption-cipher"",
""--encryption-key-size"" and ""--encryption-control-location""
options to ""volume type set"" and ""volume type create"" commands.
Add ""--encryption-type"" option to ""volume type unset"",
""volume type list"" and ""volume type show"" commands.

Change-Id: I3572635d5913d971a723a62d7790ffe0f20ec39a
Implements: bp cinder-command-support
Closes-Bug: #1651117
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/97/414197/12 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/command-objects/volume-type.rst', 'openstackclient/volume/v1/volume_type.py', 'openstackclient/volume/v2/volume_type.py']",3,7fb13edd232c1cc785b8a7166579a90023427427,bp/cinder-command-support,"def _set_encryption_type(volume_client, volume_type, parsed_args): try: utils.find_resource( volume_client.volume_encryption_types, volume_type) except Exception: # create new encryption type LOG.warning(_(""No exiting encryption type found, creating "" ""new encryption type for this volume type ..."")) if not parsed_args.encryption_provider: msg = _(""'--encryption-provider' should be specified whlie "" ""creating new encryption type"") raise exceptions.CommandError(msg) else: control_location = parsed_args.encryption_control_location if not parsed_args.encryption_control_location: # set the default of control location while creating control_location = 'front-end' body = { 'provider': parsed_args.encryption_provider, 'cipher': parsed_args.encryption_cipher, 'key_size': parsed_args.encryption_key_size, 'control_location': control_location } volume_client.volume_encryption_types.create( volume_type, body) else: # update the existing encryption type body = { 'provider': parsed_args.encryption_provider, 'cipher': parsed_args.encryption_cipher, 'key_size': parsed_args.encryption_key_size, 'control_location': parsed_args.control_location } volume_client.volume_encryption_types.update(volume_type, body) parser.add_argument( '--encryption-provider', metavar='<provider>', help=_('Set the class that provides encryption support ' 'for this volume type (e.g ""LuksEncryptor"") ' '(admin only)'), ) parser.add_argument( '--encryption-cipher', metavar='<cipher>', help=_('Set the encryption algorithm or mode for this ' 'volume type (e.g ""aes-xts-plain64"") (admin only)'), ) parser.add_argument( '--encryption-key-size', metavar='<key-size>', type=int, help=_('Set the size of the encryption key of this ' 'volume type (e.g ""128"" or ""256"") (admin only)'), ) parser.add_argument( '--encryption-control-location', metavar='<control-location>', choices=['front-end', 'back-end'], help=_('Set the notional service where the encryption is ' 'performed (""front-end"" or ""back-end"") (admin only)'), ) if (parsed_args.encryption_provider or parsed_args.encryption_cipher or parsed_args.encryption_key_size or parsed_args.encryption_control_location): try: _set_encryption_type(volume_client, volume_type, parsed_args) except Exception as e: LOG.error(_(""Failed to set encryption information for this "" ""volume type: %s""), e) result += 1 ",,184,2
openstack%2Fdragonflow~master~Iaa3ea64eabf71681c9220c215fe655c055912e65,openstack/dragonflow,master,Iaa3ea64eabf71681c9220c215fe655c055912e65,Add _nested_txn property to DFOvsdbApi,MERGED,2017-02-16 18:05:33.000000000,2017-02-18 03:25:02.000000000,2017-02-17 02:58:24.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 11159}]","[{'number': 1, 'created': '2017-02-16 18:05:33.000000000', 'files': ['dragonflow/ovsdb/impl_idl.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/6cc1ced246c235ab98dea437aaf03094f025f314', 'message': ""Add _nested_txn property to DFOvsdbApi\n\nIn change I55dd417cae7ebbe0668ba5606949ce4ab045d251 , _nested_txn\nproperty was added to neutron.agent.ovsdb.api.API. DFOvsdbApi inherits\nfrom this class, but does not call the parent super, in order to\noverride the creation of the internal idl instance.\n\nThis means that the property is not created, but is later read in the\n'transaction' method in the parent class, which causes an error.\n\nThis change fixes this error.\n\nChange-Id: Iaa3ea64eabf71681c9220c215fe655c055912e65\n""}]",0,435055,6cc1ced246c235ab98dea437aaf03094f025f314,11,3,1,20229,,,0,"Add _nested_txn property to DFOvsdbApi

In change I55dd417cae7ebbe0668ba5606949ce4ab045d251 , _nested_txn
property was added to neutron.agent.ovsdb.api.API. DFOvsdbApi inherits
from this class, but does not call the parent super, in order to
override the creation of the internal idl instance.

This means that the property is not created, but is later read in the
'transaction' method in the parent class, which causes an error.

This change fixes this error.

Change-Id: Iaa3ea64eabf71681c9220c215fe655c055912e65
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/55/435055/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/ovsdb/impl_idl.py'],1,6cc1ced246c235ab98dea437aaf03094f025f314,nested_txn, self._nested_txn = None,,1,0
openstack%2Fsenlin~master~I8da000c3451275ac5a300fe9071946dcbaaf2bd8,openstack/senlin,master,I8da000c3451275ac5a300fe9071946dcbaaf2bd8,Fix update timeout field of cluster failed,MERGED,2017-02-15 11:39:30.000000000,2017-02-18 03:20:54.000000000,2017-02-16 03:37:32.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-15 11:39:30.000000000', 'files': ['senlin/objects/requests/clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/efa9ff81553fed0210a70ec3cee39b9d8011cfda', 'message': 'Fix update timeout field of cluster failed\n\nReplace timeout type and use NonNegativeIntegerField instead\n\nChange-Id: I8da000c3451275ac5a300fe9071946dcbaaf2bd8\n'}]",0,434235,efa9ff81553fed0210a70ec3cee39b9d8011cfda,9,3,1,15917,,,0,"Fix update timeout field of cluster failed

Replace timeout type and use NonNegativeIntegerField instead

Change-Id: I8da000c3451275ac5a300fe9071946dcbaaf2bd8
",git fetch https://review.opendev.org/openstack/senlin refs/changes/35/434235/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/objects/requests/clusters.py'],1,efa9ff81553fed0210a70ec3cee39b9d8011cfda,fix/cluster_update," 'timeout': fields.NonNegativeIntegerField(nullable=True),"," 'timeout': fields.IntegerField(nullable=True),",1,1
openstack%2Fsenlin~master~I70ff9d7bf10869c725021e096733fecb46d181c6,openstack/senlin,master,I70ff9d7bf10869c725021e096733fecb46d181c6,Revise action_delete_by_target api,MERGED,2017-01-18 01:43:12.000000000,2017-02-18 03:20:20.000000000,2017-02-15 14:54:50.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-01-18 01:43:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/27fab3d0f6c8a0a7f7c8aec48b2228405e3ae3be', 'message': 'Revise CLUSTER_CHECK design, avoid creating too many action records\n\nThis patch revise  CLUSTER_CHECK design, avoid creating too many\naction records.\n\nHave test this patch can work ok.\nThis patch has two problems need to be discussed:\n1)performance: I think Action.get_by_name is time-consuming\n, but maybe the same with Action.update we use in each cluster check.\n2)name is not a primary key.\n\nIf this design is ok, will add unit test.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 2, 'created': '2017-01-18 01:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d7210739aa0212ff82c6a4c7a16b6244ee923514', 'message': 'Revise CLUSTER_CHECK design, avoid creating too many action records\n\nThis patch revise  CLUSTER_CHECK design, avoid creating too many\naction records.\n\nHave test this patch can work ok.\nThis patch has two problems need to be discussed:\n1)performance: I think Action.get_by_name is time-consuming\n, but maybe the same with Action.update we use in each cluster check.\nSo maybe not a serious problem.\n2)name is not a primary key.\n\nIf this design is ok, will add unit test.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 3, 'created': '2017-01-18 02:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/575ccf1e6ea9b0204ace75a92af668efeeba4d67', 'message': 'Revise CLUSTER_CHECK design, avoid creating too many action records\n\nThis patch revises  CLUSTER_CHECK design, avoid creating too many\naction records.\n\nHave test this patch can work ok.\nThis patch has two problems need to be discussed:\n1)performance: I think Action.get_by_name is time-consuming\n, but maybe the same with Action.update we use in each cluster check.\nSo maybe not a serious problem.\n2)name is not a primary key.\n\nIf this design is ok, will add unit test.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 4, 'created': '2017-01-20 02:15:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/4bda19c2076dd8ba0adbd07a87aa6dbf03c8df28', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 5, 'created': '2017-02-05 14:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e5d0acfd0d485bce6d68385276c0c0d16173bf91', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 6, 'created': '2017-02-05 16:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/894cce4e8310d7bb740db831d8cef09d115fc0b0', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 7, 'created': '2017-02-06 15:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1429605fd3c0229828fccd4ad4b5090fc634867f', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 8, 'created': '2017-02-06 16:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/72c6232c9eeac446bb2f9c5176cda70c3996cebc', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 9, 'created': '2017-02-08 09:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3d3d277057bfea3a28f7482f3a9e1b6530b29855', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 10, 'created': '2017-02-08 11:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e116d177b6f20a31bd5c8347c3eafb1650dc16da', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 11, 'created': '2017-02-09 01:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a5d8937ac149cc4c889d9e7819792c3dbee38e04', 'message': 'Revise create action when do cluster check\n\nThis patch revises CLUSTER_CHECK design, avoid creating too many\naction records.\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 12, 'created': '2017-02-09 14:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d3af5355bc5ab93d56b9cceca477169b78b754ee', 'message': 'Revise cluster/node check action records design\n\nThis patch revises cluster/node check action records design, avoid\ncreating too many action records when do cluster/node checking.\n\nLink for bp:\nhttps://blueprints.launchpad.net/senlin/+spec/improve-action-event\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 13, 'created': '2017-02-09 14:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/cd68ee958a59e537d03b7b3cba1f347d0bde784a', 'message': 'Revise cluster/node check action records design\n\nThis patch revises cluster/node check action records design, the prurpose\nis to avoid creating too many action records when do cluster/node checking.\n\nLink for bp:\nhttps://blueprints.launchpad.net/senlin/+spec/improve-action-event\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n'}, {'number': 14, 'created': '2017-02-15 04:09:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/36568eb8b061de4478050063f9479a61f2fd8a89', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n""}, {'number': 15, 'created': '2017-02-15 04:12:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/25a6f37608b385ed7c9944a063d8f60d42c675d4', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n""}, {'number': 16, 'created': '2017-02-15 04:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d67ea126c40d06abc4ba6a4e12e1e01a19aad28a', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n""}, {'number': 17, 'created': '2017-02-15 08:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/7826c9f88da3844f08ea0fa01d67e82a3a6d51f7', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n""}, {'number': 18, 'created': '2017-02-15 08:23:28.000000000', 'files': ['senlin/objects/action.py', 'senlin/db/api.py', 'senlin/tests/unit/db/test_action_api.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/95b685e85264219e9c81c94cafdb72269f291a8d', 'message': ""Revise action_delete_by_target api\n\nThis patch revises action_delete_by_target api.\nIt's a prepare for deleting action.\npartial-blueprint: improve-action-event\n\nChange-Id: I70ff9d7bf10869c725021e096733fecb46d181c6\n""}]",42,421615,95b685e85264219e9c81c94cafdb72269f291a8d,60,4,18,22998,,,0,"Revise action_delete_by_target api

This patch revises action_delete_by_target api.
It's a prepare for deleting action.
partial-blueprint: improve-action-event

Change-Id: I70ff9d7bf10869c725021e096733fecb46d181c6
",git fetch https://review.opendev.org/openstack/senlin refs/changes/15/421615/4 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/engine/actions/cluster_action.py']",2,27fab3d0f6c8a0a7f7c8aec48b2228405e3ae3be,bp/improve-action-event," # we only create one check action for each node name = 'node_check_%s' % node_id[:8] old_action = ao.Action.get_by_name(self.context, name) if old_action is not None: action_id = old_action.to_dict()['id'] else: action_id = base.Action.create( self.context, node_id, consts.NODE_CHECK, name=name, cause=consts.CAUSE_DERIVED, ) "," action_id = base.Action.create( self.context, node_id, consts.NODE_CHECK, name='node_check_%s' % node_id[:8], cause=consts.CAUSE_DERIVED, )",23,7
openstack%2Fsenlin~master~I4074f937e411f6a1299d23b1611ae58a74cd6bec,openstack/senlin,master,I4074f937e411f6a1299d23b1611ae58a74cd6bec,Fix health registry claim bug,MERGED,2017-01-23 11:49:34.000000000,2017-02-18 03:19:41.000000000,2017-02-15 10:36:00.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-01-23 11:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a820735906ced98397bd7417ae16b4c03cf014ef', 'message': 'Fix health registry claim bug\n\nThis patch fixes health registry claim bug\nwhich will cause health policy cannot work.\n\nChange-Id: I4074f937e411f6a1299d23b1611ae58a74cd6bec\nCloses-Bug: #1658661\n'}, {'number': 2, 'created': '2017-02-15 08:16:49.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/bff4a7877d4dcfc7b7d4a012337a443b016d4ddc', 'message': 'Fix health registry claim bug\n\nThis patch fixes health registry claim bug\nwhich will cause health policy cannot work.\n\nChange-Id: I4074f937e411f6a1299d23b1611ae58a74cd6bec\nCloses-Bug: #1658661\n'}]",7,424073,bff4a7877d4dcfc7b7d4a012337a443b016d4ddc,22,4,2,22998,,,0,"Fix health registry claim bug

This patch fixes health registry claim bug
which will cause health policy cannot work.

Change-Id: I4074f937e411f6a1299d23b1611ae58a74cd6bec
Closes-Bug: #1658661
",git fetch https://review.opendev.org/openstack/senlin refs/changes/73/424073/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/db/test_registry_api.py', 'senlin/tests/unit/db/test_sqlalchemy_utils.py', 'senlin/db/sqlalchemy/utils.py', 'senlin/db/sqlalchemy/api.py']",5,a820735906ced98397bd7417ae16b4c03cf014ef,bug/1658661,"import eventlet cfg.CONF.import_opt(""periodic_interval"", ""senlin.common.config"") max_elapse = 2 * cfg.CONF.periodic_interval eventlet.sleep(max_elapse) svc_ids = [e.id for e in engines if not utils.is_service_dead(e, service_get(context, e.id))] ", svc_ids = [e.id for e in engines if not utils.is_service_dead(e)],31,21
openstack%2Fsenlin~master~Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977,openstack/senlin,master,Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977,Listener endpoint for Heat stack events,MERGED,2017-02-14 09:29:00.000000000,2017-02-18 03:19:23.000000000,2017-02-15 02:55:59.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-14 09:29:00.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04', 'message': 'Listener endpoint for Heat stack events\n\nThis adds a event endpoint for listening to Heat stack related events.\n\nChange-Id: Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977\n'}]",0,433529,7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04,7,2,1,8246,,,0,"Listener endpoint for Heat stack events

This adds a event endpoint for listening to Heat stack related events.

Change-Id: Ifa9e4aa3dc8ffc1422fc37eeab33bcfa3ff29977
",git fetch https://review.opendev.org/openstack/senlin refs/changes/29/433529/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py']",2,7ae52996b2e6f4e6373b71f8780c3b6e0c4c7e04,heat-listener-endpoint,"@mock.patch('oslo_messaging.NotificationFilter') class TestHeatNotificationEndpoint(base.SenlinTestCase): @mock.patch('senlin.rpc.client.EngineClient') def test_init(self, mock_rpc, mock_filter): x_filter = mock_filter.return_value event_map = { 'orchestration.stack.delete.end': 'DELETE', } obj = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER') mock_filter.assert_called_once_with( publisher_id='^orchestration.*', event_type='^orchestration\.stack\..*', context={'project_id': '^PROJECT$'}) mock_rpc.assert_called_once_with() self.assertEqual(x_filter, obj.filter_rule) self.assertEqual(mock_rpc.return_value, obj.rpc) for e in event_map: self.assertIn(e, obj.STACK_FAILURE_EVENTS) self.assertEqual(event_map[e], obj.STACK_FAILURE_EVENTS[e]) self.assertEqual('PROJECT', obj.project_id) self.assertEqual('CLUSTER', obj.cluster_id) @mock.patch.object(context.RequestContext, 'from_dict') @mock.patch('senlin.rpc.client.EngineClient') def test_info(self, mock_rpc, mock_context, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = { 'tags': { 'cluster_id=CLUSTER_ID', 'cluster_node_id=FAKE_NODE', 'cluster_node_index=123', }, 'stack_identity': 'PHYSICAL_ID', 'user_identity': 'USER', 'state': 'DELETE_COMPLETE', } metadata = {'timestamp': 'TIMESTAMP'} call_ctx = mock.Mock() mock_context.return_value = call_ctx res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) x_rpc.call.assert_called_once_with(call_ctx, 'node_recover', mock.ANY) req = x_rpc.call.call_args[0][2] self.assertIsInstance(req, vorn.NodeRecoverRequest) self.assertEqual('FAKE_NODE', req.identity) expected_params = { 'event': 'DELETE', 'state': 'DELETE_COMPLETE', 'stack_id': 'PHYSICAL_ID', 'timestamp': 'TIMESTAMP', 'publisher': 'PUBLISHER', } self.assertEqual(expected_params, req.params) @mock.patch('senlin.rpc.client.EngineClient') def test_info_event_type_not_interested(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': {'cluster_id': 'CLUSTER_ID'}} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.create.start', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': None} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_empty_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': []} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_cluster_in_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['foo', 'bar']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_no_node_in_tag(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['cluster_id=C1ID']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch('senlin.rpc.client.EngineClient') def test_info_cluster_id_not_match(self, mock_rpc, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = {'tags': ['cluster_id=FOOBAR', 'cluster_node_id=N2']} metadata = {'timestamp': 'TIMESTAMP'} res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) self.assertEqual(0, x_rpc.node_recover.call_count) @mock.patch.object(context.RequestContext, 'from_dict') @mock.patch('senlin.rpc.client.EngineClient') def test_info_default_values(self, mock_rpc, mock_context, mock_filter): x_rpc = mock_rpc.return_value endpoint = hm.HeatNotificationEndpoint('PROJECT', 'CLUSTER_ID') ctx = mock.Mock() payload = { 'tags': [ 'cluster_id=CLUSTER_ID', 'cluster_node_id=NODE_ID' ], 'user_identity': 'USER', } metadata = {'timestamp': 'TIMESTAMP'} call_ctx = mock.Mock() mock_context.return_value = call_ctx res = endpoint.info(ctx, 'PUBLISHER', 'orchestration.stack.delete.end', payload, metadata) self.assertIsNone(res) x_rpc.call.assert_called_once_with(call_ctx, 'node_recover', mock.ANY) req = x_rpc.call.call_args[0][2] self.assertIsInstance(req, vorn.NodeRecoverRequest) self.assertEqual('NODE_ID', req.identity) expected_params = { 'event': 'DELETE', 'state': 'Unknown', 'stack_id': 'Unknown', 'timestamp': 'TIMESTAMP', 'publisher': 'PUBLISHER', } self.assertEqual(expected_params, req.params) ",,234,0
openstack%2Finstack-undercloud~master~Id9f8c37d4df76b8b1899a73284c284b486e38c3c,openstack/instack-undercloud,master,Id9f8c37d4df76b8b1899a73284c284b486e38c3c,Handle service upgrades correctly when enable_telemetry=false,ABANDONED,2017-02-14 17:48:05.000000000,2017-02-18 03:11:23.000000000,,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6924}, {'_account_id': 7144}]","[{'number': 1, 'created': '2017-02-14 17:48:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b924f454aa6f58d31a9e332d51d93ef07aa83aae', 'message': 'Handle service upgrades correctly when enable_telemetry=false\n\nWhen enable_telemetry is false on upgrade, we need to ensure that\nthe services are disabled via puppet so they dont come back up on\nreboot. Currently if flag is false and we upgrade from true, the\nreboot brings the services back on even though telemetry services\nflag is disabled. We just set the service class enabled param to\nhiera value of enable_telemetry so the right state is set.\n\nCloses-bug: #1664654\n\nChange-Id: Id9f8c37d4df76b8b1899a73284c284b486e38c3c\n'}, {'number': 2, 'created': '2017-02-14 18:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/1beb59a1dd33204bb1ba84ff5c280c5b89777fdf', 'message': 'Handle service upgrades correctly when enable_telemetry=false\n\nWhen enable_telemetry is false on upgrade, we need to ensure that\nthe services are disabled via puppet so they dont come back up on\nreboot. Currently if flag is false and we upgrade from true, the\nreboot brings the services back on even though telemetry services\nflag is disabled. We just set the service class enabled param to\nhiera value of enable_telemetry so the right state is set.\n\nCloses-bug: #1664654\n\nChange-Id: Id9f8c37d4df76b8b1899a73284c284b486e38c3c\n'}, {'number': 3, 'created': '2017-02-15 06:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/b401b993df43f17e05f38220ab817143defb6570', 'message': 'Handle service upgrades correctly when enable_telemetry=false\n\nWhen enable_telemetry is false on upgrade, we need to ensure that\nthe services are disabled via puppet so they dont come back up on\nreboot. Currently if flag is false and we upgrade from true, the\nreboot brings the services back on even though telemetry services\nflag is disabled. We just set the service class enabled param to\nhiera value of enable_telemetry so the right state is set.\n\nCloses-bug: #1664654\n\nChange-Id: Id9f8c37d4df76b8b1899a73284c284b486e38c3c\n'}, {'number': 4, 'created': '2017-02-15 13:02:25.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp', 'elements/puppet-stack-config/puppet-stack-config.yaml.template'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/7884eba367751c622d54561db644bcefec6b85e2', 'message': 'Handle service upgrades correctly when enable_telemetry=false\n\nWhen enable_telemetry is false on upgrade, we need to ensure that\nthe services are disabled via puppet so they dont come back up on\nreboot. Currently if flag is false and we upgrade from true, the\nreboot brings the services back on even though telemetry services\nflag is disabled. We just set the service class enabled param to\nhiera value of enable_telemetry so the right state is set.\n\nCloses-bug: #1664654\n\nChange-Id: Id9f8c37d4df76b8b1899a73284c284b486e38c3c\n'}]",2,433824,7884eba367751c622d54561db644bcefec6b85e2,29,5,4,6924,,,0,"Handle service upgrades correctly when enable_telemetry=false

When enable_telemetry is false on upgrade, we need to ensure that
the services are disabled via puppet so they dont come back up on
reboot. Currently if flag is false and we upgrade from true, the
reboot brings the services back on even though telemetry services
flag is disabled. We just set the service class enabled param to
hiera value of enable_telemetry so the right state is set.

Closes-bug: #1664654

Change-Id: Id9f8c37d4df76b8b1899a73284c284b486e38c3c
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/24/433824/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/puppet-stack-config/puppet-stack-config.pp', 'elements/puppet-stack-config/puppet-stack-config.yaml.template']",2,b924f454aa6f58d31a9e332d51d93ef07aa83aae,bug/1664654,"ceilometer::api::enabled: ""%{hiera('enable_telemetry')}""ceilometer::collector::enabled: ""%{hiera('enable_telemetry')}""ceilometer::agent::central::enabled: ""%{hiera('enable_telemetry')}"" ceilometer::agent::notification::enabled: ""%{hiera('enable_telemetry')}""aodh::api::enabled: ""%{hiera('enable_telemetry')}""aodh::notifier::enabled: ""%{hiera('enable_telemetry')}"" aodh::listener::enabled: ""%{hiera('enable_telemetry')}"" aodh::evaluator::enabled: ""%{hiera('enable_telemetry')}""gnocchi::api::enabled: ""%{hiera('enable_telemetry')}""gnocchi::metricd::enabled: ""%{hiera('enable_telemetry')}""gnocchi::statsd::enabled: ""%{hiera('enable_telemetry')}""panko::api::enabled: ""%{hiera('enable_telemetry')}""",,35,1
openstack%2Fnova~stable%2Fnewton~I2285005098b7dab7753366f53667ff8d4532d668,openstack/nova,stable/newton,I2285005098b7dab7753366f53667ff8d4532d668,Skip soft-deleted records in 330_enforce_mitaka_online_migrations,MERGED,2017-02-17 22:48:59.000000000,2017-02-18 03:08:19.000000000,2017-02-18 03:08:19.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-17 22:48:59.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/642caf0c58ed0a0e0c06103d2e3ef001c1ae142f', 'message': ""Skip soft-deleted records in 330_enforce_mitaka_online_migrations\n\nThe 330_enforce_mitaka_online_migrations migration considers\nsoft-deleted records as unmigrated (the blocker migration uses the\nselect function from sqlalchemy), but the online migrations only\nmigrate non-deleted records (the migrations use the model_query\nfunction which defaults to read_deleted='no'). So even after running\nall of the online migrations, operators can get stuck until they can\nhard delete any soft-deleted compute_nodes, aggregates, and\npci_devices records they have.\n\n Conflicts:\n\tnova/tests/unit/db/test_sqlalchemy_migration.py\n\nNOTE(melwitt): The conflict is due to ocata unit tests that don't\nexist in newton.\n\nCloses-Bug: #1665719\n\nChange-Id: I2285005098b7dab7753366f53667ff8d4532d668\n(cherry picked from commit 6d64b7274410ae45b95bd7ac7f702c16daaa0fcd)\n""}]",0,435620,642caf0c58ed0a0e0c06103d2e3ef001c1ae142f,14,5,1,4690,,,0,"Skip soft-deleted records in 330_enforce_mitaka_online_migrations

The 330_enforce_mitaka_online_migrations migration considers
soft-deleted records as unmigrated (the blocker migration uses the
select function from sqlalchemy), but the online migrations only
migrate non-deleted records (the migrations use the model_query
function which defaults to read_deleted='no'). So even after running
all of the online migrations, operators can get stuck until they can
hard delete any soft-deleted compute_nodes, aggregates, and
pci_devices records they have.

 Conflicts:
	nova/tests/unit/db/test_sqlalchemy_migration.py

NOTE(melwitt): The conflict is due to ocata unit tests that don't
exist in newton.

Closes-Bug: #1665719

Change-Id: I2285005098b7dab7753366f53667ff8d4532d668
(cherry picked from commit 6d64b7274410ae45b95bd7ac7f702c16daaa0fcd)
",git fetch https://review.opendev.org/openstack/nova refs/changes/20/435620/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py']",2,642caf0c58ed0a0e0c06103d2e3ef001c1ae142f,bug/1665719," def test_deleted_not_migrated(self): cn_values = dict(vcpus=1, memory_mb=512, local_gb=10, vcpus_used=0, memory_mb_used=256, local_gb_used=5, hypervisor_type='HyperDanVM', hypervisor_version='34', cpu_info='foo') cn = db_api.compute_node_create(self.context, cn_values) agg_values = dict(name='foo') agg = db_api.aggregate_create(self.context, agg_values) pd = db_api.pci_device_update(self.context, 1, 'foo:bar', {'parent_addr': None, 'compute_node_id': 1, 'address': 'foo:bar', 'vendor_id': '123', 'product_id': '456', 'dev_type': 'foo', 'label': 'foobar', 'status': 'whatisthis?'}) db_api.compute_node_delete(self.context, cn['id']) db_api.aggregate_delete(self.context, agg['id']) db_api.pci_device_destroy(self.context, pd['compute_node_id'], pd['address']) # blocker should not block on soft-deleted records self.migration.upgrade(self.engine)",,32,5
openstack%2Fnova~master~I2285005098b7dab7753366f53667ff8d4532d668,openstack/nova,master,I2285005098b7dab7753366f53667ff8d4532d668,Skip soft-deleted records in 330_enforce_mitaka_online_migrations,MERGED,2017-02-17 17:31:24.000000000,2017-02-18 03:04:57.000000000,2017-02-18 03:04:56.000000000,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-17 17:31:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/09c5f6077b145c23481b46154289d858e89d0b4a', 'message': 'Skip soft-deleted records in 330_enforce_mitaka_online_migrations\n\nThe 330_enforce_mitaka_online_migrations migration considers\nsoft-deleted records as unmigrated, but the online migrations only\nmigrate non-deleted records. So even after running all of the online\nmigrations, operators can get stuck until they can hard delete any\nsoft-deleted compute_nodes, aggregates, and pci_devices records they\nhave.\n\nCloses-Bug: #1665719\n\nChange-Id: I2285005098b7dab7753366f53667ff8d4532d668\n'}, {'number': 2, 'created': '2017-02-17 22:09:45.000000000', 'files': ['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6d64b7274410ae45b95bd7ac7f702c16daaa0fcd', 'message': ""Skip soft-deleted records in 330_enforce_mitaka_online_migrations\n\nThe 330_enforce_mitaka_online_migrations migration considers\nsoft-deleted records as unmigrated (the blocker migration uses the\nselect function from sqlalchemy), but the online migrations only\nmigrate non-deleted records (the migrations use the model_query\nfunction which defaults to read_deleted='no'). So even after running\nall of the online migrations, operators can get stuck until they can\nhard delete any soft-deleted compute_nodes, aggregates, and\npci_devices records they have.\n\nCloses-Bug: #1665719\n\nChange-Id: I2285005098b7dab7753366f53667ff8d4532d668\n""}]",4,435546,6d64b7274410ae45b95bd7ac7f702c16daaa0fcd,34,13,2,4690,,,0,"Skip soft-deleted records in 330_enforce_mitaka_online_migrations

The 330_enforce_mitaka_online_migrations migration considers
soft-deleted records as unmigrated (the blocker migration uses the
select function from sqlalchemy), but the online migrations only
migrate non-deleted records (the migrations use the model_query
function which defaults to read_deleted='no'). So even after running
all of the online migrations, operators can get stuck until they can
hard delete any soft-deleted compute_nodes, aggregates, and
pci_devices records they have.

Closes-Bug: #1665719

Change-Id: I2285005098b7dab7753366f53667ff8d4532d668
",git fetch https://review.opendev.org/openstack/nova refs/changes/46/435546/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/db/sqlalchemy/migrate_repo/versions/330_enforce_mitaka_online_migrations.py', 'nova/tests/unit/db/test_sqlalchemy_migration.py']",2,09c5f6077b145c23481b46154289d858e89d0b4a,bug/1665719," def test_deleted_not_migrated(self): cn = objects.ComputeNode(context=self.context, vcpus=1, memory_mb=512, local_gb=10, vcpus_used=0, memory_mb_used=256, local_gb_used=5, hypervisor_type='HyperDanVM', hypervisor_version='34', cpu_info='foo') cn.create() agg = objects.Aggregate(context=self.context, name='foo') agg.create() db_api.pci_device_update(self.context, 1, 'foo:bar', {'parent_addr': None, 'compute_node_id': 1, 'address': 'foo:bar', 'vendor_id': '123', 'product_id': '456', 'dev_type': 'foo', 'label': 'foobar', 'status': 'whatisthis?'}) cn.destroy() agg.destroy() db_api.pci_device_destroy(self.context, 1, 'foo:bar') # blocker should not block on soft-deleted records self.migration.upgrade(self.engine) ",,33,5
openstack%2Fpython-neutronclient~stable%2Focata~Ib1ba356e994a98712e00a11ff045df67fbe4c7ea,openstack/python-neutronclient,stable/ocata,Ib1ba356e994a98712e00a11ff045df67fbe4c7ea,Add BGP VPN OSC commands,MERGED,2017-02-16 11:33:14.000000000,2017-02-18 02:48:41.000000000,2017-02-18 02:48:41.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 748}, {'_account_id': 7787}, {'_account_id': 9656}]","[{'number': 1, 'created': '2017-02-16 11:33:14.000000000', 'files': ['neutronclient/tests/unit/osc/v2/networking_bgpvpn/__init__.py', 'neutronclient/osc/v2/networking_bgpvpn/__init__.py', 'releasenotes/notes/support-networking-bgpvpn-cli-fdd0cc3a5b14983d.yaml', 'neutronclient/osc/v2/networking_bgpvpn/network_association.py', 'neutronclient/osc/v2/networking_bgpvpn/constants.py', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/fakes.py', 'neutronclient/v2_0/client.py', 'doc/source/usage/osc/v2/networking-bgpvpn.rst', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/test_bgpvpn.py', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/test_resource_association.py', 'setup.cfg', 'neutronclient/osc/v2/networking_bgpvpn/bgpvpn.py', 'neutronclient/osc/v2/networking_bgpvpn/resource_association.py', 'neutronclient/osc/v2/networking_bgpvpn/router_association.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/aa09d5b2608072310df001590d008f385bc73432', 'message': 'Add BGP VPN OSC commands\n\nChange-Id: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea\nCloses-Bug: #1650204\n(cherry picked from commit f2ace0415dd78d74b1f81c81134f7874d787fe5e)\n'}]",0,434838,aa09d5b2608072310df001590d008f385bc73432,15,5,1,12021,,,0,"Add BGP VPN OSC commands

Change-Id: Ib1ba356e994a98712e00a11ff045df67fbe4c7ea
Closes-Bug: #1650204
(cherry picked from commit f2ace0415dd78d74b1f81c81134f7874d787fe5e)
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/38/434838/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/osc/v2/networking_bgpvpn/__init__.py', 'neutronclient/osc/v2/networking_bgpvpn/__init__.py', 'releasenotes/notes/support-networking-bgpvpn-cli-fdd0cc3a5b14983d.yaml', 'neutronclient/osc/v2/networking_bgpvpn/network_association.py', 'neutronclient/osc/v2/networking_bgpvpn/constants.py', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/fakes.py', 'neutronclient/v2_0/client.py', 'doc/source/usage/osc/v2/networking-bgpvpn.rst', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/test_bgpvpn.py', 'neutronclient/tests/unit/osc/v2/networking_bgpvpn/test_resource_association.py', 'setup.cfg', 'neutronclient/osc/v2/networking_bgpvpn/bgpvpn.py', 'neutronclient/osc/v2/networking_bgpvpn/resource_association.py', 'neutronclient/osc/v2/networking_bgpvpn/router_association.py']",14,aa09d5b2608072310df001590d008f385bc73432,bug/1650204,"# Copyright (c) 2016 Juniper Routerworks Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # from neutronclient._i18n import _ from neutronclient.osc import utils as nc_osc_utils from neutronclient.osc.v2.networking_bgpvpn import constants from neutronclient.osc.v2.networking_bgpvpn.resource_association import\ CreateBgpvpnResAssoc from neutronclient.osc.v2.networking_bgpvpn.resource_association import\ DeleteBgpvpnResAssoc from neutronclient.osc.v2.networking_bgpvpn.resource_association import\ ListBgpvpnResAssoc from neutronclient.osc.v2.networking_bgpvpn.resource_association import\ ShowBgpvpnResAssoc class BgpvpnRouterAssoc(object): _assoc_res_name = constants.ROUTER_RESOURCE_NAME _resource = constants.ROUTER_ASSOC _resource_plural = constants.ROUTER_ASSOCS _attr_map = ( ('id', 'ID', nc_osc_utils.LIST_BOTH), ('tenant_id', 'Project ID', nc_osc_utils.LIST_LONG_ONLY), ('%s_id' % _assoc_res_name, '%s ID' % _assoc_res_name.capitalize(), nc_osc_utils.LIST_BOTH), ) _formatters = {} class CreateBgpvpnRouterAssoc(BgpvpnRouterAssoc, CreateBgpvpnResAssoc): _description = _(""Create a BGP VPN router association"") pass class DeleteBgpvpnRouterAssoc(BgpvpnRouterAssoc, DeleteBgpvpnResAssoc): _description = _(""Delete a BGP VPN router association(s) for a given BGP "" ""VPN"") pass class ListBgpvpnRouterAssoc(BgpvpnRouterAssoc, ListBgpvpnResAssoc): _description = _(""List BGP VPN router associations for a given BGP VPN"") pass class ShowBgpvpnRouterAssoc(BgpvpnRouterAssoc, ShowBgpvpnResAssoc): _description = _(""Show information of a given BGP VPN router association"") pass ",,2188,0
openstack%2Fsenlin~master~I32406c4afb6566f0001d479b9b6368c90367dcb6,openstack/senlin,master,I32406c4afb6566f0001d479b9b6368c90367dcb6,Revise cluster action,MERGED,2017-02-13 10:34:33.000000000,2017-02-18 02:48:19.000000000,2017-02-14 10:16:18.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 15917}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-13 10:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e484d66f3aef21998076f75b126b585103a56133', 'message': 'Revise cluster action\n\nThis patch revise api of cluster action, change all action\nmethod name to `_do_{{action}}`, if we want to add new actions\nin future, just need to realize _do_{{action}} method.\n\nChange-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6\n'}, {'number': 2, 'created': '2017-02-13 12:30:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5e98592dba7fb6bd71dbdba276f6f21116784a09', 'message': 'Revise cluster action\n\nThis patch revise api of cluster action, change all action\nmethod name to `_do_{{action}}`, if we want to add new actions\nin future, just need to realize _do_{{action}} method.\n\nChange-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6\n'}, {'number': 3, 'created': '2017-02-14 09:01:33.000000000', 'files': ['senlin/api/openstack/v1/clusters.py', 'senlin/tests/unit/api/openstack/v1/test_clusters.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/e830b0d003bbd105f34c02757bd1e8256ad13436', 'message': 'Revise cluster action\n\nThis patch revise api of cluster action, change all action\nmethod name to `_do_{{action}}`, if we want to add new actions\nin future, just need to realize _do_{{action}} method.\n\nChange-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6\n'}]",3,432972,e830b0d003bbd105f34c02757bd1e8256ad13436,18,4,3,15917,,,0,"Revise cluster action

This patch revise api of cluster action, change all action
method name to `_do_{{action}}`, if we want to add new actions
in future, just need to realize _do_{{action}} method.

Change-Id: I32406c4afb6566f0001d479b9b6368c90367dcb6
",git fetch https://review.opendev.org/openstack/senlin refs/changes/72/432972/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/openstack/v1/clusters.py', 'senlin/tests/unit/api/openstack/v1/test_clusters.py']",2,e484d66f3aef21998076f75b126b585103a56133,revise/cluster_action," def test__do_add_nodes(self, mock_call, mock_parse, mock_enforce): data = dict(nodes=['NODE1']) resp = self.controller._do_add_nodes(req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_add_nodes_failed_request(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE2']) self.controller._do_add_nodes, req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) data = dict(nodes=['NODE3']) self.controller._do_add_nodes, req, cid, data) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_del_nodes(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE4'], destroy=False) resp = self.controller._do_del_nodes(req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_del_nodes_failed_request(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE5'], destroy=False) self.controller._do_del_nodes, req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_del_nodes_failed_engine(self, mock_call, mock_parse, _ignore): data = dict(nodes=['NODE6'], destroy=False) self.controller._do_del_nodes, req, cid, data) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': data['nodes'], def test__do_replace_nodes(self, mock_call, mock_parse, _ignore): data = dict(nodes={'OLD': 'NEW'}) resp = self.controller._do_replace_nodes(req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_replace_nodes_none(self, mock_call, mock_parse, _ign): data = dict(nodes=None) self.controller._do_replace_nodes, req, cid, data) def test__do_replace_nodes_not_map(self, mock_call, mock_parse, _ign): data = dict(nodes=['abc', 'def']) self.controller._do_replace_nodes, req, cid, data) def test__do_replace_nodes_failed_request(self, mock_call, mock_parse, _ign): data = dict(nodes={'OLD': 'NEW'}) self.controller._do_replace_nodes, req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def test__do_replace_nodes_failed_engine(self, mock_call, mock_parse, _ign): data = dict(nodes={'OLD': 'NEW'}) self.controller._do_replace_nodes, req, cid, data) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': data['nodes']} ) def _test_do_resize_with_type(self, adj_type, mock_call, mock_parse): self._test_do_resize_with_type('EXACT_CAPACITY') self._test_do_resize_with_type('CHANGE_IN_CAPACITY') self._test_do_resize_with_type('CHANGE_IN_PERCENTAGE') data = dict(count=1) resp = self.controller._do_scale_out(req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=2) req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=3) req, cid, data) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=4) resp = self.controller._do_scale_in(req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=5) req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} ) data = dict(count=6) req, cid, data) 'ClusterScaleInRequest', req, {'identity': cid, 'count': data['count']} )"," def test__add_nodes(self, mock_call, mock_parse, mock_enforce): nodes = ['NODE1'] resp = self.controller._add_nodes(req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__add_nodes_failed_request(self, mock_call, mock_parse, _ignore): nodes = ['NODE2'] self.controller._add_nodes, req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) nodes = ['NODE3'] self.controller._add_nodes, req, cid, nodes) 'ClusterAddNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__del_nodes(self, mock_call, mock_parse, _ignore): nodes = ['NODE4'] destroy = False resp = self.controller._del_nodes(req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__del_nodes_failed_request(self, mock_call, mock_parse, _ignore): nodes = ['NODE5'] destroy = False self.controller._del_nodes, req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__del_nodes_failed_engine(self, mock_call, mock_parse, _ignore): nodes = ['NODE6'] destroy = False self.controller._del_nodes, req, cid, nodes, destroy) 'ClusterDelNodesRequest', req, {'identity': cid, 'nodes': nodes, def test__replace_nodes(self, mock_call, mock_parse, _ignore): nodes = {'OLD': 'NEW'} resp = self.controller._replace_nodes(req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__replace_nodes_none(self, mock_call, mock_parse, _ign): self.controller._replace_nodes, req, cid, None) def test__replace_nodes_not_map(self, mock_call, mock_parse, _ign): nodes = ['abc', 'def'] self.controller._replace_nodes, req, cid, nodes) def test__replace_nodes_failed_request(self, mock_call, mock_parse, _ign): nodes = {'OLD': 'NEW'} self.controller._replace_nodes, req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def test__replace_nodes_failed_engine(self, mock_call, mock_parse, _ign): nodes = {'OLD': 'NEW'} self.controller._replace_nodes, req, cid, nodes) 'ClusterReplaceNodesRequest', req, {'identity': cid, 'nodes': nodes}) def _test_resize_with_type(self, adj_type, mock_call, mock_parse): self._test_resize_with_type('EXACT_CAPACITY') self._test_resize_with_type('CHANGE_IN_CAPACITY') self._test_resize_with_type('CHANGE_IN_PERCENTAGE') count = 1 resp = self.controller._do_scale_out(req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 2 req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 3 req, cid, count) 'ClusterScaleOutRequest', req, {'identity': cid, 'count': count}) count = 4 resp = self.controller._do_scale_in(req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count}) count = 5 req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count}) count = 6 req, cid, count) 'ClusterScaleInRequest', req, {'identity': cid, 'count': count})",132,117
openstack%2Fsenlin~master~Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4,openstack/senlin,master,Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4,Use 'get_service_context' in health manager,MERGED,2017-02-14 05:14:05.000000000,2017-02-18 02:47:13.000000000,2017-02-14 10:16:12.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-14 05:14:05.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/engine/receivers/base.py', 'senlin/common/context.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/c9253b7cc5750f5de5a031e824b32383e232af42', 'message': ""Use 'get_service_context' in health manager\n\nUse the 'get_service_context' utility function instead of the\n'get_service_credentials' function in health manager.\n\nChange-Id: Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4\n""}]",0,433444,c9253b7cc5750f5de5a031e824b32383e232af42,8,3,1,8246,,,0,"Use 'get_service_context' in health manager

Use the 'get_service_context' utility function instead of the
'get_service_credentials' function in health manager.

Change-Id: Ice2d4f1d5b0ed7c71dbb8456da1782b67e41f1c4
",git fetch https://review.opendev.org/openstack/senlin refs/changes/44/433444/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py']",4,c9253b7cc5750f5de5a031e824b32383e232af42,get-svc-ctx, identity_service = driver_base.SenlinDriver().identity creds = identity_service.get_service_credentials(**kwargs) return RequestContext.from_dict(creds), return get_service_credentials(**kwargs),21,48
openstack%2Fpython-openstackclient~master~Ibb7fcbc5415f64e09b7df479f0afb9d3d44aeb86,openstack/python-openstackclient,master,Ibb7fcbc5415f64e09b7df479f0afb9d3d44aeb86,Gate broken test,ABANDONED,2017-02-16 11:18:49.000000000,2017-02-18 02:44:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 21514}]","[{'number': 1, 'created': '2017-02-16 11:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b07359227b27ce6a994ed3fc66d4905824df0144', 'message': ""Gate broken test\n\nGate was broken by uncertain error, I did not see\nthe error in my enviroment so I do not sure what cause\nthat, just remove the '--debug' option and see\nwhat happen\n\nChange-Id: Ibb7fcbc5415f64e09b7df479f0afb9d3d44aeb86\n""}, {'number': 2, 'created': '2017-02-16 15:38:01.000000000', 'files': ['openstackclient/tests/functional/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/951c24357c1816bc0b920b73463dc389bc16b8e3', 'message': ""Gate broken test\n\nGate was broken by uncertain error, I did not see\nthe error in my enviroment so I do not sure what cause\nthat, just remove the '--debug' option and see\nwhat happen\n\nChange-Id: Ibb7fcbc5415f64e09b7df479f0afb9d3d44aeb86\n""}]",0,434818,951c24357c1816bc0b920b73463dc389bc16b8e3,7,3,2,21514,,,0,"Gate broken test

Gate was broken by uncertain error, I did not see
the error in my enviroment so I do not sure what cause
that, just remove the '--debug' option and see
what happen

Change-Id: Ibb7fcbc5415f64e09b7df479f0afb9d3d44aeb86
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/18/434818/2 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/compute/v2/test_server.py'],1,b07359227b27ce6a994ed3fc66d4905824df0144,gate-broken, raw_output = self.openstack('server create --flavor ' +, raw_output = self.openstack('--debug server create --flavor ' +,1,1
openstack%2Foctavia~master~I88d1ff34e5dfd838b36e7e48154b719232f56df7,openstack/octavia,master,I88d1ff34e5dfd838b36e7e48154b719232f56df7,Amphora create will add a 'fake' heartbeat on creation,ABANDONED,2016-01-22 20:15:44.000000000,2017-02-18 02:40:01.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 6951}, {'_account_id': 8157}, {'_account_id': 10273}, {'_account_id': 10477}, {'_account_id': 10806}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 12040}, {'_account_id': 15226}, {'_account_id': 16923}]","[{'number': 1, 'created': '2016-01-22 20:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/533eb854b7a66fca1fb66339595ca8a7936a18ff', 'message': ""Amphora create will add a 'fake' heartbeat on creation.\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 2, 'created': '2016-01-25 16:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6e67f9b1491a05c8cedc297fa8049321faa5fcc1', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 3, 'created': '2016-02-03 15:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/958fdc3fd2673cd14e469f0c987401556cd4a0f0', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 4, 'created': '2016-02-04 15:29:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ba370be8343764798908e47da20598574ef28a5e', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 5, 'created': '2016-02-04 17:22:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ceb3151730c60c7441d5d4a5420bf460b433c549', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 6, 'created': '2016-02-04 20:36:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fbfc2c6bc93dec3d349fd17173a15e8deeca2687', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 7, 'created': '2016-02-04 23:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/37fe6ec33ab0500319d1b06b1e2b95929413a645', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations after a threshold defined\nin a config value has been reached.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 8, 'created': '2016-02-08 15:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e76e27f2d33e1abef254a3fd5c9a74021f4ecc75', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations after a threshold defined\nin a config value has been reached.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 9, 'created': '2016-02-08 16:37:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2dc23c5c53e9677449868744301175fcb51afbe5', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations after a threshold defined\nin a config value has been reached.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 10, 'created': '2016-07-28 21:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d6e9cc77aedcf9396acc94d89d46b5d27c41b5c3', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations after a threshold defined\nin a config value has been reached.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}, {'number': 11, 'created': '2016-07-29 16:19:52.000000000', 'files': ['octavia/common/config.py', 'octavia/controller/worker/flows/amphora_flows.py', 'octavia/common/constants.py', 'octavia/controller/worker/tasks/database_tasks.py', 'octavia/tests/unit/controller/worker/flows/test_amphora_flows.py', 'etc/octavia.conf'], 'web_link': 'https://opendev.org/openstack/octavia/commit/2a8c15f02a285d862df4b6db5a22927e9084c9fd', 'message': ""Amphora create will add a 'fake' heartbeat on creation\n\nPreviously if an amphora never made a heartbeat, it would never be failed-over.\nNow, a fake heartbeat will be inserted in the DB after the amphora is active,\nand should appropriately trigger failover operations after a threshold defined\nin a config value has been reached.\n\nChange-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7\nCloses-Bug: #1532506\n""}]",13,271512,2a8c15f02a285d862df4b6db5a22927e9084c9fd,72,12,11,10806,,,0,"Amphora create will add a 'fake' heartbeat on creation

Previously if an amphora never made a heartbeat, it would never be failed-over.
Now, a fake heartbeat will be inserted in the DB after the amphora is active,
and should appropriately trigger failover operations after a threshold defined
in a config value has been reached.

Change-Id: I88d1ff34e5dfd838b36e7e48154b719232f56df7
Closes-Bug: #1532506
",git fetch https://review.opendev.org/openstack/octavia refs/changes/12/271512/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/controller/worker/flows/amphora_flows.py', 'octavia/common/constants.py', 'octavia/controller/worker/tasks/database_tasks.py']",3,533eb854b7a66fca1fb66339595ca8a7936a18ff,bug/1532506,"import datetimeclass AddAmphoraHeartbeat(BaseDatabaseTask): def execute(self, amphora_id): """"""Add a fake heartbeat in the Amphora Health DB. :param amphora_id: The amphora id to mark busy """""" LOG.debug('Adding entry in amphora health db for amphora: %s', amphora_id) self.amp_health_repo.update(db_apis.get_session(), amphora_id=amphora_id, last_update=datetime.datetime.now()) ",,18,0
openstack%2Fnetworking-bagpipe~stable%2Focata~I7b5c3486b8a12f5fd2b11078e8e21743fb7f20eb,openstack/networking-bagpipe,stable/ocata,I7b5c3486b8a12f5fd2b11078e8e21743fb7f20eb,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-17 04:35:50.000000000,2017-02-18 02:18:55.000000000,2017-02-18 02:18:55.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-02-17 04:35:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/6b2fb516185c5b8bc06318dff51e959426c5a205', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I7b5c3486b8a12f5fd2b11078e8e21743fb7f20eb\n'}]",0,435233,6b2fb516185c5b8bc06318dff51e959426c5a205,9,3,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: I7b5c3486b8a12f5fd2b11078e8e21743fb7f20eb
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/33/435233/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6b2fb516185c5b8bc06318dff51e959426c5a205,create-ocata,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages},install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fnetworking-bagpipe~stable%2Focata~I6e04427c53816571d81c02f72eabf817056319ed,openstack/networking-bagpipe,stable/ocata,I6e04427c53816571d81c02f72eabf817056319ed,tox_install will follow stable/ocata,MERGED,2017-02-17 14:54:56.000000000,2017-02-18 02:18:50.000000000,2017-02-18 02:18:50.000000000,"[{'_account_id': 3}, {'_account_id': 748}]","[{'number': 1, 'created': '2017-02-17 14:54:56.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/630fe36dac1d4393a895f4fa0d5c936b29014477', 'message': 'tox_install will follow stable/ocata\n\nChange-Id: I6e04427c53816571d81c02f72eabf817056319ed\n'}]",0,435479,630fe36dac1d4393a895f4fa0d5c936b29014477,6,2,1,12021,,,0,"tox_install will follow stable/ocata

Change-Id: I6e04427c53816571d81c02f72eabf817056319ed
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/79/435479/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,630fe36dac1d4393a895f4fa0d5c936b29014477,,openstack_branch=stable/ocata,openstack_branch=master,1,1
openstack%2Fnetworking-bagpipe~stable%2Focata~Ia1cbffbc4f0e76cce3cf51fcc74bd2227333500d,openstack/networking-bagpipe,stable/ocata,Ia1cbffbc4f0e76cce3cf51fcc74bd2227333500d,Update .gitreview for stable/ocata,MERGED,2017-02-17 04:35:49.000000000,2017-02-18 02:12:17.000000000,2017-02-18 02:12:17.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-02-17 04:35:49.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/736c9785ded7a5571e519772ab1d62ccfb5b9da9', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: Ia1cbffbc4f0e76cce3cf51fcc74bd2227333500d\n'}]",0,435232,736c9785ded7a5571e519772ab1d62ccfb5b9da9,9,3,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: Ia1cbffbc4f0e76cce3cf51fcc74bd2227333500d
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/32/435232/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,736c9785ded7a5571e519772ab1d62ccfb5b9da9,create-ocata,defaultbranch=stable/ocata,,1,0
openstack%2Fneutron-lbaas~stable%2Focata~I8a045208f8550d96d15d364486202380ec2145ec,openstack/neutron-lbaas,stable/ocata,I8a045208f8550d96d15d364486202380ec2145ec,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-03 14:22:42.000000000,2017-02-18 02:04:47.000000000,2017-02-18 02:04:47.000000000,"[{'_account_id': 3}, {'_account_id': 748}]","[{'number': 1, 'created': '2017-02-03 14:22:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/c6011fb279e1c96a6b002423105cb3faced6b11a', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I8a045208f8550d96d15d364486202380ec2145ec\n'}]",0,428750,c6011fb279e1c96a6b002423105cb3faced6b11a,8,2,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: I8a045208f8550d96d15d364486202380ec2145ec
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/50/428750/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c6011fb279e1c96a6b002423105cb3faced6b11a,create-ocata, {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages}, {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Ftripleo-heat-templates~stable%2Focata~I38fc5772cdb4a7df7979beb2e7475c70f34076a7,openstack/tripleo-heat-templates,stable/ocata,I38fc5772cdb4a7df7979beb2e7475c70f34076a7,Apply post-upgrade step to not run puppet in post upgrade,MERGED,2017-02-17 01:30:23.000000000,2017-02-18 02:04:40.000000000,2017-02-18 02:04:40.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6924}, {'_account_id': 8449}, {'_account_id': 16515}]","[{'number': 1, 'created': '2017-02-17 01:30:23.000000000', 'files': ['overcloud-resource-registry-puppet.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a36cac39387fced4ae4a3a0cded097fcee95b035', 'message': ""Apply post-upgrade step to not run puppet in post upgrade\n\nIn the environment file:\nenvironments/major-upgrade-composable-steps.yaml\nwe don't want to run puppet in certains roles in post upgrade\nbecause we need to make some extra tasks on this nodes and\nrun puppet on converge step\n\nChange-Id: I38fc5772cdb4a7df7979beb2e7475c70f34076a7\n(cherry picked from commit b3b04eb0d22d776902462811d54bcd270e0fab73)\n""}]",0,435189,a36cac39387fced4ae4a3a0cded097fcee95b035,20,5,1,3153,,,0,"Apply post-upgrade step to not run puppet in post upgrade

In the environment file:
environments/major-upgrade-composable-steps.yaml
we don't want to run puppet in certains roles in post upgrade
because we need to make some extra tasks on this nodes and
run puppet on converge step

Change-Id: I38fc5772cdb4a7df7979beb2e7475c70f34076a7
(cherry picked from commit b3b04eb0d22d776902462811d54bcd270e0fab73)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/89/435189/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-resource-registry-puppet.j2.yaml'],1,a36cac39387fced4ae4a3a0cded097fcee95b035,fix-puppet-post-upgrade, OS::TripleO::PostUpgradeSteps: puppet/post-upgrade.yaml, OS::TripleO::PostUpgradeSteps: puppet/post.yaml,1,1
openstack%2Fneutron-vpnaas~stable%2Fnewton~I955546e4c63daacf0c8b4e979917eacb3a4e29d7,openstack/neutron-vpnaas,stable/newton,I955546e4c63daacf0c8b4e979917eacb3a4e29d7,devstack: Switch the default to strongswan,MERGED,2017-01-13 08:27:52.000000000,2017-02-18 01:50:54.000000000,2017-02-18 01:50:54.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 7787}]","[{'number': 1, 'created': '2017-01-13 08:27:52.000000000', 'files': ['devstack/settings'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/a94415316d61080fbb71ee5bf43736e10b3c9b50', 'message': 'devstack: Switch the default to strongswan\n\nCloses-Bug: #1649574\nChange-Id: I955546e4c63daacf0c8b4e979917eacb3a4e29d7\n(cherry picked from commit 55b0e6618f8a2221aa2ee36c45174d714f3718c6)\n'}]",0,419813,a94415316d61080fbb71ee5bf43736e10b3c9b50,7,3,1,6854,,,0,"devstack: Switch the default to strongswan

Closes-Bug: #1649574
Change-Id: I955546e4c63daacf0c8b4e979917eacb3a4e29d7
(cherry picked from commit 55b0e6618f8a2221aa2ee36c45174d714f3718c6)
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/13/419813/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,a94415316d61080fbb71ee5bf43736e10b3c9b50,bug/1649574,"NEUTRON_VPNAAS_SERVICE_PROVIDER=${NEUTRON_VPNAAS_SERVICE_PROVIDER:-""VPN:strongswan:neutron_vpnaas.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default""}IPSEC_PACKAGE=${IPSEC_PACKAGE:-""strongswan""} NEUTRON_VPNAAS_DEVICE_DRIVER=${NEUTRON_VPNAAS_DEVICE_DRIVER:-""neutron_vpnaas.services.vpn.device_drivers.strongswan_ipsec:StrongSwanDriver""}","NEUTRON_VPNAAS_SERVICE_PROVIDER=${NEUTRON_VPNAAS_SERVICE_PROVIDER:-""VPN:openswan:neutron_vpnaas.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default""}IPSEC_PACKAGE=${IPSEC_PACKAGE:-""openswan""} NEUTRON_VPNAAS_DEVICE_DRIVER=${NEUTRON_VPNAAS_DEVICE_DRIVER:-""neutron_vpnaas.services.vpn.device_drivers.ipsec.OpenSwanDriver""}",3,3
openstack%2Fkolla~master~I2ed9c7353040106650cbffb04eca8877fb7fc187,openstack/kolla,master,I2ed9c7353040106650cbffb04eca8877fb7fc187,build: sort list of built/failed images before printing,MERGED,2017-02-12 16:16:48.000000000,2017-02-18 01:46:09.000000000,2017-02-18 01:46:09.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}]","[{'number': 1, 'created': '2017-02-12 16:16:48.000000000', 'files': ['kolla/image/build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ffdfac2778436458319c264aa2a504f511164e11', 'message': ""build: sort list of built/failed images before printing\n\nI am building all images as test for my non-x86 support patch. Several\nimages fail for misc reasons. I am tired of having to copy/paste 'kolla'\noutput for manual sorting to find out which built, which failed.\n\nChange-Id: I2ed9c7353040106650cbffb04eca8877fb7fc187\n""}]",3,432774,ffdfac2778436458319c264aa2a504f511164e11,18,3,1,24072,,,0,"build: sort list of built/failed images before printing

I am building all images as test for my non-x86 support patch. Several
images fail for misc reasons. I am tired of having to copy/paste 'kolla'
output for manual sorting to find out which built, which failed.

Change-Id: I2ed9c7353040106650cbffb04eca8877fb7fc187
",git fetch https://review.opendev.org/openstack/kolla refs/changes/74/432774/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla/image/build.py'],1,ffdfac2778436458319c264aa2a504f511164e11,to-merge/sorted-images-list," for name in sorted(self.image_statuses_good.keys()): for name, status in sorted(self.image_statuses_bad.items()):"," for name in self.image_statuses_good.keys(): for name, status in self.image_statuses_bad.items():",2,2
openstack%2Fpuppet-nova~stable%2Fnewton~Iea0d874108b39609505e542eda29b9bb74ca2a35,openstack/puppet-nova,stable/newton,Iea0d874108b39609505e542eda29b9bb74ca2a35,Fix idempotency with empty available filters,MERGED,2017-02-17 22:18:55.000000000,2017-02-18 00:46:30.000000000,2017-02-18 00:43:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8971}]","[{'number': 1, 'created': '2017-02-17 22:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/16f0e576ad87f0221e850f56394d50d3d7f4bdb0', 'message': 'Fix idempotency with empty available filters\n\nIf an empty array is passed in for the available filters, the provider\nis improperly thinking a configuration value needs to be done. This\nchange checks for this case and sets it to $::os_service_default.\n\nChange-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35\nCloses-Bug: #1665443\nRelated-Bug: #1664650\n(cherry picked from commit 334eec2fd00a1ddd45296491bc115985ef1a3113)\n'}, {'number': 2, 'created': '2017-02-17 22:56:36.000000000', 'files': ['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/35d5c5a86d9d6719225f73a75449a8ff03fd007e', 'message': 'Fix idempotency with empty available filters\n\nIf an empty array is passed in for the available filters, the provider\nis improperly thinking a configuration value needs to be done. This\nchange checks for this case and sets it to $::os_service_default.\n\nChange-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35\nCloses-Bug: #1665443\nRelated-Bug: #1664650\n(cherry picked from commit 334eec2fd00a1ddd45296491bc115985ef1a3113)\n'}]",0,435617,35d5c5a86d9d6719225f73a75449a8ff03fd007e,11,3,2,14985,,,0,"Fix idempotency with empty available filters

If an empty array is passed in for the available filters, the provider
is improperly thinking a configuration value needs to be done. This
change checks for this case and sets it to $::os_service_default.

Change-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35
Closes-Bug: #1665443
Related-Bug: #1664650
(cherry picked from commit 334eec2fd00a1ddd45296491bc115985ef1a3113)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/17/435617/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb']",2,16f0e576ad87f0221e850f56394d50d3d7f4bdb0,bug/1665443," :scheduler_available_filters => [], it { is_expected.to contain_nova_config('DEFAULT/available_filters').with_value('<SERVICE DEFAULT>') }",,7,1
openstack%2Fpuppet-vswitch~stable%2Fnewton~I5f7448e3504c9190d7fe5f4a7958c604ef91a058,openstack/puppet-vswitch,stable/newton,I5f7448e3504c9190d7fe5f4a7958c604ef91a058,Add fail_mode parameter to OVS Ports,MERGED,2017-02-17 07:55:21.000000000,2017-02-18 00:42:59.000000000,2017-02-18 00:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-17 07:55:21.000000000', 'files': ['spec/unit/puppet/lib/type/vs_port_spec.rb', 'lib/puppet/provider/vs_port/ovs_redhat.rb', 'lib/puppet/type/vs_port.rb'], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/fc04875852029e70ebd335a1be14e010d59d3a1c', 'message': 'Add fail_mode parameter to OVS Ports\n\nAccording to info in https://bugs.launchpad.net/tripleo/+bug/1640812\nwhen setting a OVS bridge with physical interface we need to\ndefine fail_mode in OVS_EXTRA parameter of ifcfg to make\nsure it\'s set at the desired mode after reboot.\n\nThis patch adds new parameter fail_mode to vs_port (as ifcfg is created\nas part of vs_port, not vs_bridge) and defaults it to required value ""standalone"".\n\nSimilar patch was implemented to os-net-config in\nhttps://github.com/openstack/os-net-config/commit/e479535b508b4072f64300809b824dfecc3a9182\n\nChange-Id: I5f7448e3504c9190d7fe5f4a7958c604ef91a058\nCloses-Bug: #1656795\n(cherry picked from commit 026f64ade478a8f3e45a9af61a2239d9ff59acc9)\n'}]",0,435290,fc04875852029e70ebd335a1be14e010d59d3a1c,7,3,1,16312,,,0,"Add fail_mode parameter to OVS Ports

According to info in https://bugs.launchpad.net/tripleo/+bug/1640812
when setting a OVS bridge with physical interface we need to
define fail_mode in OVS_EXTRA parameter of ifcfg to make
sure it's set at the desired mode after reboot.

This patch adds new parameter fail_mode to vs_port (as ifcfg is created
as part of vs_port, not vs_bridge) and defaults it to required value ""standalone"".

Similar patch was implemented to os-net-config in
https://github.com/openstack/os-net-config/commit/e479535b508b4072f64300809b824dfecc3a9182

Change-Id: I5f7448e3504c9190d7fe5f4a7958c604ef91a058
Closes-Bug: #1656795
(cherry picked from commit 026f64ade478a8f3e45a9af61a2239d9ff59acc9)
",git fetch https://review.opendev.org/openstack/puppet-vswitch refs/changes/90/435290/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/puppet/lib/type/vs_port_spec.rb', 'lib/puppet/provider/vs_port/ovs_redhat.rb', 'lib/puppet/type/vs_port.rb']",3,fc04875852029e70ebd335a1be14e010d59d3a1c,bug/1656795," newparam(:fail_mode) do desc ""Set fail mode for this port. Possible values are 'standalone' or 'secure'. By default standalone is used."" defaultto ""standalone"" newvalues(:""standalone"", :""secure"") end ",,30,2
openstack%2Fkeystone~master~I72bc4289dcc80da3d29f7808c882e0d71ccc1dc8,openstack/keystone,master,I72bc4289dcc80da3d29f7808c882e0d71ccc1dc8,Remove logging import unused,MERGED,2017-02-16 03:24:30.000000000,2017-02-18 00:42:32.000000000,2017-02-18 00:42:32.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17639}, {'_account_id': 17643}, {'_account_id': 18338}]","[{'number': 1, 'created': '2017-02-16 03:24:30.000000000', 'files': ['keystone/resource/backends/base.py', 'keystone/assignment/backends/base.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/815bdfbbbfdbb23461228d2762071c9e1720a517', 'message': 'Remove logging import unused\n\nThis patch removes logging import unused in\nkeystone/assignment/backends/base.py\nkeystone/resource/backends/base.py\n\nChange-Id: I72bc4289dcc80da3d29f7808c882e0d71ccc1dc8\n'}]",0,434612,815bdfbbbfdbb23461228d2762071c9e1720a517,9,5,1,15905,,,0,"Remove logging import unused

This patch removes logging import unused in
keystone/assignment/backends/base.py
keystone/resource/backends/base.py

Change-Id: I72bc4289dcc80da3d29f7808c882e0d71ccc1dc8
",git fetch https://review.opendev.org/openstack/keystone refs/changes/12/434612/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/resource/backends/base.py', 'keystone/assignment/backends/base.py']",2,815bdfbbbfdbb23461228d2762071c9e1720a517,remove-logging-unused,,from oslo_log import logLOG = log.getLogger(__name__),0,4
openstack%2Fmagnum~master~I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa,openstack/magnum,master,I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa,Fix quota API get-all parameter type,MERGED,2017-02-16 19:07:30.000000000,2017-02-18 00:18:00.000000000,2017-02-18 00:18:00.000000000,"[{'_account_id': 3}, {'_account_id': 668}, {'_account_id': 13861}, {'_account_id': 21469}]","[{'number': 1, 'created': '2017-02-16 19:07:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/92c23026854b81bb83777685230bd2ed55c2a850', 'message': 'Fix quota API get-all parameter type\n\nChange-Id: I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa\nCloses-Bug: #1665109\n'}, {'number': 2, 'created': '2017-02-16 19:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2ccec6d57730005cc373b15ab997b3bc12691b87', 'message': 'Fix quota API get-all parameter type\n\nCurrently for admin user, quota get-all method returning\nall the quotas if all_tenants parameter is passed\nirrespective of whether the flag is set to True or False.\nThis change fixes the issue by setting the correct\nparameter type in quotas get-all method.\n\nChange-Id: I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa\nCloses-Bug: #1665109\n'}, {'number': 3, 'created': '2017-02-16 20:48:38.000000000', 'files': ['magnum/tests/unit/api/controllers/v1/test_quota.py', 'magnum/api/controllers/v1/quota.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/3a20d30696150e53997dbe3bbdb9cdb10d62ce00', 'message': 'Fix quota API get-all parameter type\n\nCurrently for admin user, quota get-all method returning\nall the quotas if all_tenants parameter is passed\nirrespective of whether the flag is set to True or False.\nThis change fixes the issue by setting the correct\nparameter type in quotas get-all method.\n\nChange-Id: I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa\nCloses-Bug: #1665109\n'}]",0,435068,3a20d30696150e53997dbe3bbdb9cdb10d62ce00,24,4,3,7230,,,0,"Fix quota API get-all parameter type

Currently for admin user, quota get-all method returning
all the quotas if all_tenants parameter is passed
irrespective of whether the flag is set to True or False.
This change fixes the issue by setting the correct
parameter type in quotas get-all method.

Change-Id: I6992c4b648bbbd01ce7d6ef4c53c031fa1f1c9aa
Closes-Bug: #1665109
",git fetch https://review.opendev.org/openstack/magnum refs/changes/68/435068/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/controllers/v1/test_quota.py', 'magnum/api/controllers/v1/quota.py']",2,92c23026854b81bb83777685230bd2ed55c2a850,bug/1665109,"from magnum.api.controllers.v1 import types @expose.expose(QuotaCollection, int, int, wtypes.text, wtypes.text, types.boolean)"," @expose.expose(QuotaCollection, int, int, wtypes.text, wtypes.text, bool)",17,1
openstack%2Freleases~master~I97e07359e2e0e4302bbc0d6f50340fb020135a52,openstack/releases,master,I97e07359e2e0e4302bbc0d6f50340fb020135a52,release congress rc2 for ocata,MERGED,2017-02-17 17:43:53.000000000,2017-02-18 00:16:27.000000000,2017-02-18 00:16:27.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 18591}]","[{'number': 1, 'created': '2017-02-17 17:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/25cb96ba476ccc7df7d81a8923afc19b548b5e3c', 'message': 'release congress rc2 for ocata\n\nChange-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52\n'}, {'number': 2, 'created': '2017-02-17 18:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/3bbc8fc4bf7fb38e0fc8ff54c278d3ed6b83bde5', 'message': 'release congress rc2 for ocata\n\nChange-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52\n'}, {'number': 3, 'created': '2017-02-17 19:01:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/aaa5b1ff5ba7598b2c12133daf558a1975ba1fc2', 'message': 'release congress rc2 for ocata\n\nChange-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52\n'}, {'number': 4, 'created': '2017-02-18 00:01:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/93a03ea631aba4390928e84f56ab0b5f8843d634', 'message': 'release congress rc2 for ocata\n\nChange-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52\n'}, {'number': 5, 'created': '2017-02-18 00:12:04.000000000', 'files': ['deliverables/ocata/congress.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/54b5285342568bd5831f4fa99be3af335cdf2774', 'message': 'release congress rc2 for ocata\n\nChange-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52\n'}]",0,435551,54b5285342568bd5831f4fa99be3af335cdf2774,29,4,5,18591,,,0,"release congress rc2 for ocata

Change-Id: I97e07359e2e0e4302bbc0d6f50340fb020135a52
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/435551/5 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/congress.yaml'],1,25cb96ba476ccc7df7d81a8923afc19b548b5e3c,435551, location: 5.0.0.0rc2 - version: 5.0.0.0rc2 projects: - repo: openstack/congress hash: 54926c44114800c0112099d57e04f209191737ba, location: 5.0.0.0rc1,5,1
openstack%2Ftripleo-heat-templates~stable%2Fmitaka~I5fd58d8c92bf09302f241a83fd44223fce59d248,openstack/tripleo-heat-templates,stable/mitaka,I5fd58d8c92bf09302f241a83fd44223fce59d248,Fix a typo in the nova db online data migrations during upgrade.,MERGED,2017-02-17 18:20:52.000000000,2017-02-18 00:13:21.000000000,2017-02-18 00:13:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 20172}]","[{'number': 1, 'created': '2017-02-17 18:20:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d0f6ec0290d48ebee6eb04bfa0030957fa995aee', 'message': 'Fix a typo in the nova db online data migrations during upgrade.\n\nThe last change in\nhttps://review.openstack.org/#/c/428093/19..21/extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp\nintroduced a small typo in the online_data_migrations command.  This fix\nit.\n\nRelated-Bug: #1661202\nChange-Id: I5fd58d8c92bf09302f241a83fd44223fce59d248\n'}, {'number': 2, 'created': '2017-02-17 18:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6f9eae91e9bb5ed8ecc95ca7a055634bf6e5747a', 'message': 'Fix a typo in the nova db online data migrations during upgrade.\n\nThe last change in\nhttps://review.openstack.org/#/c/428093/19..21/extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp\nintroduced a small typo in the online_data_migrations command.  This fix\nit.\n\nRelated-Bug: #1661202\nChange-Id: I5fd58d8c92bf09302f241a83fd44223fce59d248\n'}, {'number': 3, 'created': '2017-02-17 18:33:46.000000000', 'files': ['extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3d70fb6e0de054cf700799bd238164dc2ccb07ea', 'message': 'Fix a typo in the nova db online data migrations during upgrade.\n\nThe last change in\nhttps://review.openstack.org/#/c/428093/19..21/extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp\nintroduced a small typo in the online_data_migrations command.  This\nfixes it.\n\nRelated-Bug: #1661202\nChange-Id: I5fd58d8c92bf09302f241a83fd44223fce59d248\n'}]",0,435560,3d70fb6e0de054cf700799bd238164dc2ccb07ea,11,3,3,8297,,,0,"Fix a typo in the nova db online data migrations during upgrade.

The last change in
https://review.openstack.org/#/c/428093/19..21/extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp
introduced a small typo in the online_data_migrations command.  This
fixes it.

Related-Bug: #1661202
Change-Id: I5fd58d8c92bf09302f241a83fd44223fce59d248
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/435560/2 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp'],1,d0f6ec0290d48ebee6eb04bfa0030957fa995aee,bug/1661202," exec { 'nova-db-online-data-migrations': command => '/usr/bin/nova-manage db online_data_migrations',"," exec { 'nova-db-online-data-migration': command => '/usr/bin/nova-manage db online_data_migration',",2,2
openstack%2Fpuppet-nova~stable%2Focata~Iea0d874108b39609505e542eda29b9bb74ca2a35,openstack/puppet-nova,stable/ocata,Iea0d874108b39609505e542eda29b9bb74ca2a35,Fix idempotency with empty available filters,MERGED,2017-02-17 22:01:10.000000000,2017-02-18 00:13:16.000000000,2017-02-18 00:13:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-17 22:01:10.000000000', 'files': ['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8978f769a2cceadce847ef1ab430adccab273ada', 'message': 'Fix idempotency with empty available filters\n\nIf an empty array is passed in for the available filters, the provider\nis improperly thinking a configuration value needs to be done. This\nchange checks for this case and sets it to $::os_service_default.\n\nChange-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35\nCloses-Bug: #1665443\nRelated-Bug: #1664650\n(cherry picked from commit 334eec2fd00a1ddd45296491bc115985ef1a3113)\n'}]",0,435613,8978f769a2cceadce847ef1ab430adccab273ada,7,2,1,14985,,,0,"Fix idempotency with empty available filters

If an empty array is passed in for the available filters, the provider
is improperly thinking a configuration value needs to be done. This
change checks for this case and sets it to $::os_service_default.

Change-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35
Closes-Bug: #1665443
Related-Bug: #1664650
(cherry picked from commit 334eec2fd00a1ddd45296491bc115985ef1a3113)
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/13/435613/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb']",2,8978f769a2cceadce847ef1ab430adccab273ada,bug/1665443," :scheduler_available_filters => [], it { is_expected.to contain_nova_config('filter_scheduler/available_filters').with_value('<SERVICE DEFAULT>') }",,7,1
openstack%2Freleases~master~Ib65c70f2760b8fa3cd94ede3ee7b74f9eaecf1d5,openstack/releases,master,Ib65c70f2760b8fa3cd94ede3ee7b74f9eaecf1d5,update release notes links for ocata,MERGED,2017-02-16 19:17:25.000000000,2017-02-18 00:10:10.000000000,2017-02-18 00:10:10.000000000,"[{'_account_id': 3}, {'_account_id': 308}]","[{'number': 1, 'created': '2017-02-16 19:17:25.000000000', 'files': ['deliverables/ocata/barbican.yaml', 'deliverables/ocata/openstack-ansible.yaml', 'deliverables/ocata/python-zaqarclient.yaml', 'deliverables/ocata/puppet-ec2api.yaml', 'deliverables/ocata/senlin.yaml', 'deliverables/ocata/mistral.yaml', 'deliverables/ocata/osc-lib.yaml', 'deliverables/ocata/oslo.privsep.yaml', 'deliverables/ocata/python-tripleoclient.yaml', 'deliverables/ocata/oslo.db.yaml', 'deliverables/ocata/osprofiler.yaml', 'deliverables/ocata/puppet-horizon.yaml', 'deliverables/ocata/puppet-openstack_extras.yaml', 'deliverables/ocata/python-tackerclient.yaml', 'deliverables/ocata/debtcollector.yaml', 'deliverables/ocata/vitrage-dashboard.yaml', 'deliverables/ocata/oslo.reports.yaml', 'deliverables/ocata/bifrost.yaml', 'deliverables/ocata/oslo.cache.yaml', 'deliverables/ocata/oslo.i18n.yaml', 'deliverables/ocata/puppet-octavia.yaml', 'deliverables/ocata/solum.yaml', 'deliverables/ocata/puppet-panko.yaml', 'deliverables/ocata/python-vitrageclient.yaml', 'deliverables/ocata/oslo.context.yaml', 'deliverables/ocata/oslo.messaging.yaml', 'deliverables/ocata/puppet-ceilometer.yaml', 'deliverables/ocata/python-manilaclient.yaml', 'deliverables/ocata/python-senlinclient.yaml', 'deliverables/ocata/puppet-neutron.yaml', 'deliverables/ocata/keystoneauth.yaml', 'deliverables/ocata/zaqar.yaml', 'deliverables/ocata/taskflow.yaml', 'deliverables/ocata/trove-dashboard.yaml', 'deliverables/ocata/instack-undercloud.yaml', 'deliverables/ocata/oslo.config.yaml', 'deliverables/ocata/oslotest.yaml', 'deliverables/ocata/oslo.policy.yaml', 'deliverables/ocata/congress.yaml', 'deliverables/ocata/oslo.service.yaml', 'deliverables/ocata/puppet-nova.yaml', 'deliverables/ocata/octavia.yaml', 'deliverables/ocata/python-novaclient.yaml', 'deliverables/ocata/vitrage.yaml', 'deliverables/ocata/neutron.yaml', 'deliverables/ocata/python-neutronclient.yaml', 'deliverables/ocata/puppet-heat.yaml', 'deliverables/ocata/watcher.yaml', 'deliverables/ocata/manila.yaml', 'deliverables/ocata/python-cinderclient.yaml', 'deliverables/ocata/python-keystoneclient.yaml', 'deliverables/ocata/puppet-mistral.yaml', 'deliverables/ocata/python-ironicclient.yaml', 'deliverables/ocata/tripleo-image-elements.yaml', 'deliverables/ocata/puppet-murano.yaml', 'deliverables/ocata/murano.yaml', 'deliverables/ocata/tooz.yaml', 'deliverables/ocata/neutron-lbaas.yaml', 'deliverables/ocata/python-openstackclient.yaml', 'deliverables/ocata/oslo.serialization.yaml', 'deliverables/ocata/tripleo-heat-templates.yaml', 'deliverables/ocata/panko.yaml', 'deliverables/ocata/oslo.utils.yaml', 'deliverables/ocata/puppet-aodh.yaml', 'deliverables/ocata/tripleo-common.yaml', 'deliverables/ocata/tripleo-puppet-elements.yaml', 'deliverables/ocata/sahara.yaml', 'deliverables/ocata/puppet-keystone.yaml', 'deliverables/ocata/python-muranoclient.yaml', 'deliverables/ocata/puppet-manila.yaml', 'deliverables/ocata/oslo.rootwrap.yaml', 'deliverables/ocata/puppet-sahara.yaml', 'deliverables/ocata/puppet-tempest.yaml', 'deliverables/ocata/magnum-ui.yaml', 'deliverables/ocata/ironic-python-agent.yaml', 'deliverables/ocata/oslo.middleware.yaml', 'deliverables/ocata/futurist.yaml', 'deliverables/ocata/murano-agent.yaml', 'deliverables/ocata/python-ironic-inspector-client.yaml', 'deliverables/ocata/puppet-barbican.yaml', 'deliverables/ocata/puppet-magnum.yaml', 'deliverables/ocata/os-client-config.yaml', 'deliverables/ocata/python-glanceclient.yaml', 'deliverables/ocata/glance.yaml', 'deliverables/ocata/ironic-ui.yaml', 'deliverables/ocata/oslo.vmware.yaml', 'deliverables/ocata/ironic-inspector.yaml', 'deliverables/ocata/puppet-zaqar.yaml', 'deliverables/ocata/oslo.concurrency.yaml', 'deliverables/ocata/searchlight.yaml', 'deliverables/ocata/neutron-fwaas.yaml', 'deliverables/ocata/kolla-ansible.yaml', 'deliverables/ocata/puppet-congress.yaml', 'deliverables/ocata/puppet-swift.yaml', 'deliverables/ocata/python-saharaclient.yaml', 'deliverables/ocata/ceilometermiddleware.yaml', 'deliverables/ocata/horizon.yaml', 'deliverables/ocata/keystonemiddleware.yaml', 'deliverables/ocata/ceilometer.yaml', 'deliverables/ocata/puppet-trove.yaml', 'deliverables/ocata/heat.yaml', 'deliverables/ocata/zaqar-ui.yaml', 'deliverables/ocata/puppet-glance.yaml', 'deliverables/ocata/puppet-cinder.yaml', 'deliverables/ocata/puppet-tripleo.yaml', 'deliverables/ocata/puppet-ironic.yaml', 'deliverables/ocata/puppet-ovn.yaml', 'deliverables/ocata/automaton.yaml', 'deliverables/ocata/puppet-vswitch.yaml', 'deliverables/ocata/puppet-designate.yaml', 'deliverables/ocata/searchlight-ui.yaml', 'deliverables/ocata/cinder.yaml', 'deliverables/ocata/aodh.yaml', 'deliverables/ocata/oslosphinx.yaml', 'deliverables/ocata/puppet-oslo.yaml', 'deliverables/ocata/nova.yaml', 'deliverables/ocata/designate.yaml', 'deliverables/ocata/manila-ui.yaml', 'deliverables/ocata/tacker.yaml', 'deliverables/ocata/watcher-dashboard.yaml', 'deliverables/ocata/networking-ovn.yaml', 'deliverables/ocata/ironic.yaml', 'deliverables/ocata/oslo.versionedobjects.yaml', 'deliverables/ocata/puppet-gnocchi.yaml', 'deliverables/ocata/oslo.log.yaml', 'deliverables/ocata/neutron-lib.yaml', 'deliverables/ocata/tripleo-ui.yaml', 'deliverables/ocata/puppet-tacker.yaml', 'deliverables/ocata/puppet-watcher.yaml', 'deliverables/ocata/puppet-openstacklib.yaml', 'deliverables/ocata/murano-dashboard.yaml', 'deliverables/ocata/neutron-dynamic-routing.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/ba4cdcef57787dee33d7ecdffb5c7fa44627f31c', 'message': 'update release notes links for ocata\n\nUpdate the links for Ocata release notes to use HTTPS and to point to\nthe series-specific page.\n\nChange-Id: Ib65c70f2760b8fa3cd94ede3ee7b74f9eaecf1d5\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,435073,ba4cdcef57787dee33d7ecdffb5c7fa44627f31c,7,2,1,2472,,,0,"update release notes links for ocata

Update the links for Ocata release notes to use HTTPS and to point to
the series-specific page.

Change-Id: Ib65c70f2760b8fa3cd94ede3ee7b74f9eaecf1d5
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/73/435073/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/ocata/barbican.yaml', 'deliverables/ocata/openstack-ansible.yaml', 'deliverables/ocata/python-zaqarclient.yaml', 'deliverables/ocata/puppet-ec2api.yaml', 'deliverables/ocata/senlin.yaml', 'deliverables/ocata/mistral.yaml', 'deliverables/ocata/osc-lib.yaml', 'deliverables/ocata/oslo.privsep.yaml', 'deliverables/ocata/python-tripleoclient.yaml', 'deliverables/ocata/oslo.db.yaml', 'deliverables/ocata/osprofiler.yaml', 'deliverables/ocata/puppet-horizon.yaml', 'deliverables/ocata/puppet-openstack_extras.yaml', 'deliverables/ocata/python-tackerclient.yaml', 'deliverables/ocata/debtcollector.yaml', 'deliverables/ocata/vitrage-dashboard.yaml', 'deliverables/ocata/oslo.reports.yaml', 'deliverables/ocata/bifrost.yaml', 'deliverables/ocata/oslo.cache.yaml', 'deliverables/ocata/oslo.i18n.yaml', 'deliverables/ocata/puppet-octavia.yaml', 'deliverables/ocata/solum.yaml', 'deliverables/ocata/puppet-panko.yaml', 'deliverables/ocata/python-vitrageclient.yaml', 'deliverables/ocata/oslo.context.yaml', 'deliverables/ocata/oslo.messaging.yaml', 'deliverables/ocata/puppet-ceilometer.yaml', 'deliverables/ocata/python-manilaclient.yaml', 'deliverables/ocata/python-senlinclient.yaml', 'deliverables/ocata/puppet-neutron.yaml', 'deliverables/ocata/keystoneauth.yaml', 'deliverables/ocata/zaqar.yaml', 'deliverables/ocata/taskflow.yaml', 'deliverables/ocata/trove-dashboard.yaml', 'deliverables/ocata/instack-undercloud.yaml', 'deliverables/ocata/oslo.config.yaml', 'deliverables/ocata/oslotest.yaml', 'deliverables/ocata/oslo.policy.yaml', 'deliverables/ocata/congress.yaml', 'deliverables/ocata/oslo.service.yaml', 'deliverables/ocata/puppet-nova.yaml', 'deliverables/ocata/octavia.yaml', 'deliverables/ocata/python-novaclient.yaml', 'deliverables/ocata/vitrage.yaml', 'deliverables/ocata/neutron.yaml', 'deliverables/ocata/python-neutronclient.yaml', 'deliverables/ocata/puppet-heat.yaml', 'deliverables/ocata/watcher.yaml', 'deliverables/ocata/manila.yaml', 'deliverables/ocata/python-cinderclient.yaml', 'deliverables/ocata/python-keystoneclient.yaml', 'deliverables/ocata/puppet-mistral.yaml', 'deliverables/ocata/python-ironicclient.yaml', 'deliverables/ocata/tripleo-image-elements.yaml', 'deliverables/ocata/puppet-murano.yaml', 'deliverables/ocata/murano.yaml', 'deliverables/ocata/tooz.yaml', 'deliverables/ocata/neutron-lbaas.yaml', 'deliverables/ocata/python-openstackclient.yaml', 'deliverables/ocata/oslo.serialization.yaml', 'deliverables/ocata/tripleo-heat-templates.yaml', 'deliverables/ocata/panko.yaml', 'deliverables/ocata/oslo.utils.yaml', 'deliverables/ocata/puppet-aodh.yaml', 'deliverables/ocata/tripleo-common.yaml', 'deliverables/ocata/tripleo-puppet-elements.yaml', 'deliverables/ocata/sahara.yaml', 'deliverables/ocata/puppet-keystone.yaml', 'deliverables/ocata/python-muranoclient.yaml', 'deliverables/ocata/puppet-manila.yaml', 'deliverables/ocata/oslo.rootwrap.yaml', 'deliverables/ocata/puppet-sahara.yaml', 'deliverables/ocata/puppet-tempest.yaml', 'deliverables/ocata/magnum-ui.yaml', 'deliverables/ocata/ironic-python-agent.yaml', 'deliverables/ocata/oslo.middleware.yaml', 'deliverables/ocata/futurist.yaml', 'deliverables/ocata/murano-agent.yaml', 'deliverables/ocata/python-ironic-inspector-client.yaml', 'deliverables/ocata/puppet-barbican.yaml', 'deliverables/ocata/puppet-magnum.yaml', 'deliverables/ocata/os-client-config.yaml', 'deliverables/ocata/python-glanceclient.yaml', 'deliverables/ocata/glance.yaml', 'deliverables/ocata/ironic-ui.yaml', 'deliverables/ocata/oslo.vmware.yaml', 'deliverables/ocata/ironic-inspector.yaml', 'deliverables/ocata/puppet-zaqar.yaml', 'deliverables/ocata/oslo.concurrency.yaml', 'deliverables/ocata/searchlight.yaml', 'deliverables/ocata/neutron-fwaas.yaml', 'deliverables/ocata/kolla-ansible.yaml', 'deliverables/ocata/puppet-congress.yaml', 'deliverables/ocata/puppet-swift.yaml', 'deliverables/ocata/python-saharaclient.yaml', 'deliverables/ocata/ceilometermiddleware.yaml', 'deliverables/ocata/horizon.yaml', 'deliverables/ocata/keystonemiddleware.yaml', 'deliverables/ocata/ceilometer.yaml', 'deliverables/ocata/puppet-trove.yaml', 'deliverables/ocata/heat.yaml', 'deliverables/ocata/zaqar-ui.yaml', 'deliverables/ocata/puppet-glance.yaml', 'deliverables/ocata/puppet-cinder.yaml', 'deliverables/ocata/puppet-tripleo.yaml', 'deliverables/ocata/puppet-ironic.yaml', 'deliverables/ocata/puppet-ovn.yaml', 'deliverables/ocata/automaton.yaml', 'deliverables/ocata/puppet-vswitch.yaml', 'deliverables/ocata/puppet-designate.yaml', 'deliverables/ocata/searchlight-ui.yaml', 'deliverables/ocata/cinder.yaml', 'deliverables/ocata/aodh.yaml', 'deliverables/ocata/oslosphinx.yaml', 'deliverables/ocata/puppet-oslo.yaml', 'deliverables/ocata/nova.yaml', 'deliverables/ocata/designate.yaml', 'deliverables/ocata/manila-ui.yaml', 'deliverables/ocata/tacker.yaml', 'deliverables/ocata/watcher-dashboard.yaml', 'deliverables/ocata/networking-ovn.yaml', 'deliverables/ocata/ironic.yaml', 'deliverables/ocata/oslo.versionedobjects.yaml', 'deliverables/ocata/puppet-gnocchi.yaml', 'deliverables/ocata/oslo.log.yaml', 'deliverables/ocata/neutron-lib.yaml', 'deliverables/ocata/tripleo-ui.yaml', 'deliverables/ocata/puppet-tacker.yaml', 'deliverables/ocata/puppet-watcher.yaml', 'deliverables/ocata/puppet-openstacklib.yaml', 'deliverables/ocata/murano-dashboard.yaml', 'deliverables/ocata/neutron-dynamic-routing.yaml']",132,ba4cdcef57787dee33d7ecdffb5c7fa44627f31c,update-release-notes,release-notes: https://docs.openstack.org/releasenotes/neutron-dynamic-routing/ocata.html,release-notes: http://docs.openstack.org/releasenotes/neutron-dynamic-routing/ocata.html,132,124
openstack%2Fnetworking-sfc~master~I40eb54b2e0ca8cad63f8e219c87985af4ecab990,openstack/networking-sfc,master,I40eb54b2e0ca8cad63f8e219c87985af4ecab990,Optimize and clean-up sfc_driver.,MERGED,2017-02-17 09:49:48.000000000,2017-02-18 00:05:34.000000000,2017-02-18 00:05:34.000000000,"[{'_account_id': 3}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14037}, {'_account_id': 21798}]","[{'number': 1, 'created': '2017-02-17 09:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/c8b68015e775c1cde82a9382ca1445326b2d5ecd', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}, {'number': 2, 'created': '2017-02-17 10:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/24ee2572d7772f4a4374e6b38d7e8a9f60bdceb7', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}, {'number': 3, 'created': '2017-02-17 10:40:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/995053992da0cdea26677b6ffb0361af4ff75b13', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}, {'number': 4, 'created': '2017-02-17 10:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/ea5494f4eac43a896f6112375aacedbbc0405d29', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}, {'number': 5, 'created': '2017-02-17 19:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/693418151fb989ee1e37815f1a5019b10938f3ae', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}, {'number': 6, 'created': '2017-02-17 19:40:02.000000000', 'files': ['networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/tests/unit/services/sfc/agent/extensions/openvswitch/test_sfc_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/e9bfe8a5be86a6a5f578a6942268e3784740c317', 'message': 'Optimize and clean-up sfc_driver.\n\n - Add debug logging for update_flow_rules;\n - Use dictionary litrals instead of dict functions;\n - Fix typos, and reword messages;\n - Reform lines to increase readability;\n - Use the right way to merge dictionaries instead of hacking way.\n\n Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>\n\nChange-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990\n'}]",0,435334,e9bfe8a5be86a6a5f578a6942268e3784740c317,20,5,6,14037,,,0,"Optimize and clean-up sfc_driver.

 - Add debug logging for update_flow_rules;
 - Use dictionary litrals instead of dict functions;
 - Fix typos, and reword messages;
 - Reform lines to increase readability;
 - Use the right way to merge dictionaries instead of hacking way.

 Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>

Change-Id: I40eb54b2e0ca8cad63f8e219c87985af4ecab990
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/34/435334/3 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py'],1,c8b68015e775c1cde82a9382ca1445326b2d5ecd,optimize," LOG.debug('update_flow_rule, flowrule = %s', flowrule) flowrule_status_temp = {'id': flowrule['id'], 'status': constants.STATUS_ACTIVE} flowrule_status_temp = {'id': flowrule['id'], 'status': constants.STATUS_ERROR} LOG.debug(""delete_flow_rule, flowrule = %s"", flowrule) self._setup_local_switch_flows_on_int_br(flowrule, flowrule['del_fcs'], None, add_flow=False, match_inport=True) self.br_int.delete_flows(table=ACROSS_SUBNET_TABLE, dl_dst=item['mac_address']) flowrule_status_temp = {'id': flowrule['id'], 'status': constants.STATUS_ERROR} if (not flow_classifier['source_port_range_min'] and not flow_classifier['source_port_range_max']): if (not flow_classifier['destination_port_range_min'] and not flow_classifier['destination_port_range_max']): LOG.error(_LE(""Current portchain agent doesn't support IPv6"")) source_port_masks, destination_port_masks) LOG.error(_LE(""Current portchain agent only supports IPv4"")) flow_infos.append({'dl_type': dl_type, 'nw_src': nw_src, 'nw_dst': nw_dst, 'tp_src': '%s' % source_port, 'tp_dst': '%s' % destination_port}) else: flow_infos.append({'dl_type': dl_type, 'nw_proto': nw_proto, 'nw_src': nw_src, 'nw_dst': nw_dst, 'tp_src': '%s' % source_port, 'tp_dst': '%s' % destination_port}) self._get_flow_infos_from_flow_classifier(flow_classifier)) def _setup_local_switch_flows_on_int_br(self, flowrule, flow_classifier_list, actions, add_flow=True, match_inport=True): inport_match = {'in_port': egress_port.ofport} flow_classifier_list): match_info = dict(inport_match) match_info.update(flow_info) if add_flow: self.br_int.add_flow(table=ovs_consts.LOCAL_SWITCHING, priority=priority, actions=actions, **match_info) else: self.br_int.delete_flows(table=ovs_consts.LOCAL_SWITCHING, priority=priority, **match_info) if group_id and next_hops: bucket = ('bucket=weight=%d, mod_dl_dst:%s, resubmit(,%d)' % ( item['weight'], item['mac_address'], ACROSS_SUBNET_TABLE)) push_mpls = ('push_mpls:0x8847, ' 'set_mpls_label:%d, ' 'set_mpls_ttl:%d, ' 'mod_vlan_vid:%d,' % ( (flowrule['nsp'] << 8) | flowrule['nsi'], flowrule['nsi'], vlan)) subnet_actions = 'resubmit(,%d)' % INGRESS_TABLE subnet_actions = 'output:%s' % self.patch_tun_ofport type='select', buckets=buckets) type='select', buckets=buckets) enc_actions = ('group:%d' % group_id) match_inport=True) actions = ('strip_vlan, pop_mpls:0x0800, output:%s' % vif_port.ofport)"," flowrule_status_temp = {} flowrule_status_temp['id'] = flowrule['id'] flowrule_status_temp['status'] = constants.STATUS_ACTIVE flowrule_status_temp = {} flowrule_status_temp['id'] = flowrule['id'] flowrule_status_temp['status'] = constants.STATUS_ERROR LOG.debug(""delete_flow_rule, flowrule = %s"", flowrule) self._setup_local_switch_flows_on_int_br( flowrule, flowrule['del_fcs'], None, add_flow=False, match_inport=True ) self.br_int.delete_flows( table=ACROSS_SUBNET_TABLE, dl_dst=item['mac_address']) flowrule_status_temp = {} flowrule_status_temp['id'] = flowrule['id'] flowrule_status_temp['status'] = constants.STATUS_ERROR if ( not flow_classifier['source_port_range_min'] and not flow_classifier['source_port_range_max'] ): if ( not flow_classifier['destination_port_range_min'] and not flow_classifier['destination_port_range_max'] ): LOG.error(_LE(""Current portchain agent don't support Ipv6"")) source_port_masks, destination_port_masks ) LOG.error(_LE(""Current portchain agent don't support Ipv6"")) flow_infos.append(dict( dl_type=dl_type, nw_src=nw_src, nw_dst=nw_dst, tp_src='%s' % source_port, tp_dst='%s' % destination_port )) else: flow_infos.append(dict( dl_type=dl_type, nw_proto=nw_proto, nw_src=nw_src, nw_dst=nw_dst, tp_src='%s' % source_port, tp_dst='%s' % destination_port )) self._get_flow_infos_from_flow_classifier(flow_classifier) ) def _setup_local_switch_flows_on_int_br( self, flowrule, flow_classifier_list, actions, add_flow=True, match_inport=True ): inport_match = dict(in_port=egress_port.ofport) flow_classifier_list ): match_info = dict(inport_match, **flow_info) if add_flow: self.br_int.add_flow( table=ovs_consts.LOCAL_SWITCHING, priority=priority, actions=actions, **match_info ) else: self.br_int.delete_flows( table=ovs_consts.LOCAL_SWITCHING, priority=priority, **match_info ) if ( group_id and next_hops ): bucket = ( 'bucket=weight=%d, mod_dl_dst:%s,' 'resubmit(,%d)' % ( item['weight'], item['mac_address'], ACROSS_SUBNET_TABLE ) ) push_mpls = ( ""push_mpls:0x8847,"" ""set_mpls_label:%d,"" ""set_mpls_ttl:%d,"" ""mod_vlan_vid:%d,"" % ((flowrule['nsp'] << 8) | flowrule['nsi'], flowrule['nsi'], vlan)) subnet_actions = ( ""resubmit(,%d)"" % INGRESS_TABLE) subnet_actions = ""output:%s"" % self.patch_tun_ofport type='select', buckets=buckets) type='select', buckets=buckets) enc_actions = (""group:%d"" % group_id) match_inport=True ) actions = (""strip_vlan, pop_mpls:0x0800,"" ""output:%s"" % vif_port.ofport)",72,98
openstack%2Fpuppet-aodh~master~Iefe933f45353810200ec9c76ffc92f051db7a5e6,openstack/puppet-aodh,master,Iefe933f45353810200ec9c76ffc92f051db7a5e6,Install python-redis if coordination url uses it,MERGED,2017-02-14 22:15:09.000000000,2017-02-17 23:51:10.000000000,2017-02-16 01:16:24.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6924}, {'_account_id': 7144}, {'_account_id': 8971}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-14 22:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/838ecdd3eb41d35107957195ecfcd64d1b1fee9a', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n'}, {'number': 2, 'created': '2017-02-14 22:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/3c40ee70998c36cb752b8a4a1d33a64828194077', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n'}, {'number': 3, 'created': '2017-02-14 23:03:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/d387a4ff5728ed28fe60f02a184f16d37f95ee75', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n'}, {'number': 4, 'created': '2017-02-15 00:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/0336cd100876b0e9730b15a613b3f070a3ade4fd', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n'}, {'number': 5, 'created': '2017-02-15 13:23:38.000000000', 'files': ['manifests/params.pp', 'spec/classes/aodh_evaluator_spec.rb', 'manifests/evaluator.pp', 'releasenotes/notes/install-python-redis-d695b95171f6c392.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-aodh/commit/e50308cc6da360cbe1fdfdfa5ae4a3593a6949f7', 'message': 'Install python-redis if coordination url uses it\n\nIf tooz coordination is enabled and url is using redis\nlets ensure python-redis is installed.\n\nChange-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6\n'}]",4,433951,e50308cc6da360cbe1fdfdfa5ae4a3593a6949f7,39,9,5,6924,,,0,"Install python-redis if coordination url uses it

If tooz coordination is enabled and url is using redis
lets ensure python-redis is installed.

Change-Id: Iefe933f45353810200ec9c76ffc92f051db7a5e6
",git fetch https://review.opendev.org/openstack/puppet-aodh refs/changes/51/433951/5 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/params.pp', 'spec/classes/aodh_evaluator_spec.rb', 'manifests/evaluator.pp']",3,838ecdd3eb41d35107957195ecfcd64d1b1fee9a,install-redis," if ($coordination_url =~ /redis/ ) { ensure_packages('python-redis', { ensure => present, name => $::aodh::params::redis_package_name, tag => 'openstack', }) } ",,17,0
openstack%2Freleases~master~I4161bb048deba91ccf8170ea5f0b7208bd9a80a3,openstack/releases,master,I4161bb048deba91ccf8170ea5f0b7208bd9a80a3,reduce meaningless changes when updating release notes links,MERGED,2017-02-16 19:17:25.000000000,2017-02-17 23:49:01.000000000,2017-02-17 23:49:01.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}]","[{'number': 1, 'created': '2017-02-16 19:17:25.000000000', 'files': ['tools/add_release_note_links.sh'], 'web_link': 'https://opendev.org/openstack/releases/commit/4ee77e9dcdc44fd534166bf8b6f501c008b9f6bf', 'message': 'reduce meaningless changes when updating release notes links\n\nIf the existing link matches the expected link, leave it in place\nregardless of where it is in the file.\n\nIf the link needs to be updated, try to insert the link after the\n""team"" entry, assuming that will be closer to the top of the file\nthan ""releases"" and avoiding the need to figure out if ""branches"" comes\nbefore or after ""releases"".\n\nChange-Id: I4161bb048deba91ccf8170ea5f0b7208bd9a80a3\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,435072,4ee77e9dcdc44fd534166bf8b6f501c008b9f6bf,7,3,1,2472,,,0,"reduce meaningless changes when updating release notes links

If the existing link matches the expected link, leave it in place
regardless of where it is in the file.

If the link needs to be updated, try to insert the link after the
""team"" entry, assuming that will be closer to the top of the file
than ""releases"" and avoiding the need to figure out if ""branches"" comes
before or after ""releases"".

Change-Id: I4161bb048deba91ccf8170ea5f0b7208bd9a80a3
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/72/435072/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/add_release_note_links.sh'],1,4ee77e9dcdc44fd534166bf8b6f501c008b9f6bf,update-release-notes," new_value=""release-notes: $url"" if grep -q ""$new_value"" $filename; then echo "" OK"" else # Remove any existing links, since they might point to the # ""unreleased"" page. sed -i -e '/release-notes/d' $filename # Add the link pointing to the series-specific page. sed -i -e ""/team:.*/a \ $new_value"" $filename echo "" updated"" fi"," # Remove any existing links, since they might point to the # ""unreleased"" page. sed -i -e '/release-notes/d' $filename # Add the link pointing to the series-specific page. sed -i -e ""/releases:/i \ release-notes: $url"" $filename echo",12,7
openstack%2Freleases~master~I5479680a384666c9dee25fe10740426a420011f3,openstack/releases,master,I5479680a384666c9dee25fe10740426a420011f3,use https for release notes urls,MERGED,2017-02-16 19:17:25.000000000,2017-02-17 23:48:48.000000000,2017-02-17 23:48:48.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}]","[{'number': 1, 'created': '2017-02-16 19:17:25.000000000', 'files': ['tools/add_release_note_links.sh'], 'web_link': 'https://opendev.org/openstack/releases/commit/2c1d1be7e455f3906aea665acec40eb8067dc6cd', 'message': 'use https for release notes urls\n\nChange-Id: I5479680a384666c9dee25fe10740426a420011f3\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,435071,2c1d1be7e455f3906aea665acec40eb8067dc6cd,7,3,1,2472,,,0,"use https for release notes urls

Change-Id: I5479680a384666c9dee25fe10740426a420011f3
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/71/435071/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/add_release_note_links.sh'],1,2c1d1be7e455f3906aea665acec40eb8067dc6cd,update-release-notes," url=""https://docs.openstack.org/releasenotes/${deliverable}/${SERIES}.html"""," url=""http://docs.openstack.org/releasenotes/${deliverable}/${SERIES}.html""",1,1
openstack%2Fsushy~master~I246b2a9680cd8dfaa552466de16372b492d42ace,openstack/sushy,master,I246b2a9680cd8dfaa552466de16372b492d42ace,Add SSL support to the mockup servers,MERGED,2017-02-17 22:54:32.000000000,2017-02-17 23:24:04.000000000,2017-02-17 23:24:04.000000000,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-02-17 22:54:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/204b97592e2c09c509d8ca86426663f70d0500ba', 'message': 'Add SSL support to the mockup servers\n\nThis patch is adding SSL support to both of the mockup servers (static\nand libvirt). Both now accepts the parameters --ssl-certificate and\n--ssl-key.\n\nChange-Id: I246b2a9680cd8dfaa552466de16372b492d42ace\n'}, {'number': 2, 'created': '2017-02-17 23:17:47.000000000', 'files': ['doc/source/usage.rst', 'sushy/main.py', 'tools/mockup_server_libvirt/mockup_server_libvirt.py', 'sushy/connector.py', 'tools/mockup_server.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/5f125fdd639d868fb15da9023e496d9ffa8aa683', 'message': 'Add SSL support to the mockup servers\n\nThis patch is adding SSL support to both of the mockup servers (static\nand libvirt). Both now accepts the parameters --ssl-certificate and\n--ssl-key.\n\nChange-Id: I246b2a9680cd8dfaa552466de16372b492d42ace\n'}]",0,435621,5f125fdd639d868fb15da9023e496d9ffa8aa683,8,2,2,6773,,,0,"Add SSL support to the mockup servers

This patch is adding SSL support to both of the mockup servers (static
and libvirt). Both now accepts the parameters --ssl-certificate and
--ssl-key.

Change-Id: I246b2a9680cd8dfaa552466de16372b492d42ace
",git fetch https://review.opendev.org/openstack/sushy refs/changes/21/435621/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/usage.rst', 'tools/mockup_server_libvirt/mockup_server_libvirt.py', 'tools/mockup_server.py']",3,204b97592e2c09c509d8ca86426663f70d0500ba,mockups-ssl,"import ssl parser.add_argument('-c', '--ssl-certificate', type=str, help='SSL certificate to use for HTTPS') parser.add_argument('-k', '--ssl-key', type=str, help='SSL key to use for HTTPS') if args.ssl_certificate and args.ssl_key: httpd.socket = ssl.wrap_socket( httpd.socket, keyfile=args.ssl_key, certfile=args.ssl_certificate, server_side=True) ",,62,4
openstack%2Fnova-specs~master~I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a,openstack/nova-specs,master,I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a,Spec for libvirt driver extension for Veritas HyperScale,ABANDONED,2016-10-24 23:30:54.000000000,2017-02-17 23:17:25.000000000,,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 10135}, {'_account_id': 23610}]","[{'number': 1, 'created': '2016-10-24 23:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b85bd7dece2ac67d2c1e7bbc585370158ff1c18d', 'message': 'Spec for libvirt driver extension for Veritas HyperScale\n\nThis implementation will provide a libvirt driver extention for Veritas\nHyperScale\nImplements: blueprint nova-libvirt-driver-for-veritas-hyperscale\n\nChange-Id: I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a\n'}, {'number': 2, 'created': '2016-10-31 21:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/cee8f01dda0243fa01ef0bc8a4c405ef8f5bf5ff', 'message': 'Spec for libvirt driver extension for Veritas HyperScale\n\nThis implementation will provide a libvirt driver extention for Veritas\nHyperScale\nRemoved white spaces from end of line\nImplements: blueprint veritas-hyperscale-nova-libvirt-driver\n\nChange-Id: I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a\n'}, {'number': 3, 'created': '2016-10-31 22:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5581abda076cde8f95626c7945f3746fa34e8d09', 'message': ""Spec for libvirt driver extension for Veritas HyperScale\n\nThis implementation will provide a libvirt driver extention for Veritas\nHyperScale\nRemoved white spaces from end of line\n\nAdded section for 'Use Cases'\n\nImplements: blueprint veritas-hyperscale-nova-libvirt-driver\n\nChange-Id: I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a\n""}, {'number': 4, 'created': '2016-11-19 02:42:43.000000000', 'files': ['specs/ocata/approved/libvirt-driver-for-veritas-hyperscale.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b58f45d4a09d64485dbe00c0e1342806edc0d718', 'message': ""Spec for libvirt driver extension for Veritas HyperScale\n\nThis implementation will provide a libvirt driver extention for Veritas\nHyperScale\nRemoved white spaces from end of line\n\nAdded section for 'Use Cases'\n\nIncorporating review comment to allow use case based IO tapping\nmechanism.\n\nImplements: blueprint veritas-hyperscale-nova-libvirt-driver\n\nChange-Id: I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a\n""}]",9,390413,b58f45d4a09d64485dbe00c0e1342806edc0d718,19,4,4,19774,,,0,"Spec for libvirt driver extension for Veritas HyperScale

This implementation will provide a libvirt driver extention for Veritas
HyperScale
Removed white spaces from end of line

Added section for 'Use Cases'

Incorporating review comment to allow use case based IO tapping
mechanism.

Implements: blueprint veritas-hyperscale-nova-libvirt-driver

Change-Id: I7d4fec4f43c1d8bb83f1ec49e1f1741f40851e2a
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/13/390413/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ocata/approved/libvirt-driver-for-veritas-hyperscale.rst'],1,b85bd7dece2ac67d2c1e7bbc585370158ff1c18d,bp/veritas-hyperscale-nova-libvirt-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Libvirt driver for Veritas HyperScale ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/libvirt-driver-for-veritas-hyperscale This implementation will provide a libvirt driver extention for Veritas HyperScale which is a software-only storage provider which leverages commodity direct-attached storage in a shared-nothing environment to give high performance storage for OpenStack virtual machines. This implementation will allow OpenStack virtual machines to use Veritas HyperScale storage for boot/data volumes and allow for live migration and other VM functionality by simulating shared storage using shared-nothing DAS storage. Problem description =================== Veritas HyperScale is a high performance storage provider for OpenStack based virtual machines. This blueprint is being submitted to extend nova libvirt to support Veritas HyperScale. HyperScale will provide block storage to OpenStack VM to leverage commodity storage and get DAS performance combined with resiliency, quality of service and off-hosting services. To enable this in OpenStack, this driver extention is required. Proposed change =============== A libvirt driver for Veritas HyperScale will be added to the nova/virt/hyperscale directory. An entry will be added to the list of libvirt volume drivers in nova/virt/libvirt/driver.py. This will direct volumes of 'volume_driver' type 'hyperscale' to the correct driver. A new module for HyperScale volume functionality will be introduced. This module will contain all the code related to Veritas HyperScale volumes. Veritas HyperScale is software-only server SAN technology. It allows the use of commodity storage to offer high performance, resiliency, quality of service and off-hosting features. Veritas HyperScale software needs to be installed on OpenStack controller node, cinder volume node (used for off-host storage) and nova compute nodes. A specialized implementation of QEMU block driver also needs to be installed on compute nodes. This is being upstreamed to QEMU and being tracked here: https://bugzilla.redhat.com/show_bug.cgi?id=1341866 Once this is done, and this driver is installed, nova nodes can be provisioned to use Veritas HyperScale storage system and use them just like any other block storage. The Veritas QEMU driver will direct storage traffic over TCP/IP to the right server. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- End users will be able to create nova virtual machines that are backed by Veritas HyperScale storage. This change is accompanied by a cinder driver for Veritas HyperScale (a separate cinder blueprint). Performance Impact ------------------ The technology will leverage commodity direct-attached SSDs and HDDs to provide high IOPS storage and also allow for scaling by extending the compute plane. Storage/Network and service failures will be handled to provide resiliency with minimal performance impact. Other deployer impact --------------------- Veritas HyperScale software must be installed on OpenStack controller and computes before this functionality can be used. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: ketonne Work Items ---------- * Veritas HyperScale Libvirt driver in libvirt/hyperscale * An entry in the libvirt/driver.py file for Veritas Libvirt Volume driver for HyperScale in libvirt/hyperscale * a filter for Veritas HyperScale in nova/scheduler/hyperscale Dependencies ============ Cinder blueprint for Veritas HyperScale Testing ======= The cinder driver will be tested using the cinder acceptance tests. Those tests will cover this driver as well. A 3rd party CI testing system will be used and its results submitted. Documentation Impact ==================== This needs to be documented as a new feature. References ========== Veritas HyperScale: https://www.veritas.com/product/storage-management/hyperscale-for-openstack.html QEMU block driver for Veritas HyperScale: https://bugzilla.redhat.com/show_bug.cgi?id=1341866 ",,166,0
openstack%2Fopenstack-manuals~master~I3d1cc550bf1bd4873d2052f02569f3bdb0cd0562,openstack/openstack-manuals,master,I3d1cc550bf1bd4873d2052f02569f3bdb0cd0562,[admin-guide] Remove the obsolete flag,MERGED,2017-02-08 14:28:21.000000000,2017-02-17 23:16:53.000000000,2017-02-17 23:16:53.000000000,"[{'_account_id': 3}, {'_account_id': 8803}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 23205}]","[{'number': 1, 'created': '2017-02-08 14:28:21.000000000', 'files': ['doc/admin-guide/source/telemetry-alarms.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f81f9bbd65ce81cda34f30f6160bc0f66a4cb706', 'message': '[admin-guide] Remove the obsolete flag\n\nChange-Id: I3d1cc550bf1bd4873d2052f02569f3bdb0cd0562\nCloses-Bug: #1661696\nImplements: blueprint use-openstack-command\n'}]",6,430966,f81f9bbd65ce81cda34f30f6160bc0f66a4cb706,13,5,1,19779,,,0,"[admin-guide] Remove the obsolete flag

Change-Id: I3d1cc550bf1bd4873d2052f02569f3bdb0cd0562
Closes-Bug: #1661696
Implements: blueprint use-openstack-command
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/66/430966/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/admin-guide/source/telemetry-alarms.rst'],1,f81f9bbd65ce81cda34f30f6160bc0f66a4cb706,bug/1661696, $ openstack alarm state get ALARM_ID $ openstack alarm state set --state ok ALARM_ID, $ ceilometer alarm-state-get ALARM_ID $ ceilometer alarm-state-set --state ok -a ALARM_ID,2,2
openstack%2Fmanila~stable%2Focata~Ie24bc69402964af3d756c1548aed86cc53c272c4,openstack/manila,stable/ocata,Ie24bc69402964af3d756c1548aed86cc53c272c4,Update tempest pin to latest commit ref,MERGED,2017-02-14 13:43:35.000000000,2017-02-17 23:15:34.000000000,2017-02-17 02:41:50.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}, {'_account_id': 9003}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 22236}, {'_account_id': 24594}]","[{'number': 1, 'created': '2017-02-14 13:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/bb7976fc824a26de435293c932b45594411f8f80', 'message': 'Update tempest pin to latest commit ref\n\nAlso updated invocation of DynamicCredentialsProvider to supply\nnecessary parameters.\n\nChange-Id: Ie24bc69402964af3d756c1548aed86cc53c272c4\n'}, {'number': 2, 'created': '2017-02-14 18:38:41.000000000', 'files': ['manila_tempest_tests/tests/api/base.py', 'contrib/ci/common.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/5d5018d8e56d5089cc264c5fbcad78dde5190ebe', 'message': 'Update tempest pin to latest commit ref\n\nAlso updated invocation of DynamicCredentialsProvider to supply\nnecessary parameters.\n\nChange-Id: Ie24bc69402964af3d756c1548aed86cc53c272c4\n(cherry picked from commit 4cfdbea447ccf1ec07d8a7b2b1b180760f8d0c56)\n'}]",1,433651,5d5018d8e56d5089cc264c5fbcad78dde5190ebe,30,10,2,16643,,,0,"Update tempest pin to latest commit ref

Also updated invocation of DynamicCredentialsProvider to supply
necessary parameters.

Change-Id: Ie24bc69402964af3d756c1548aed86cc53c272c4
(cherry picked from commit 4cfdbea447ccf1ec07d8a7b2b1b180760f8d0c56)
",git fetch https://review.opendev.org/openstack/manila refs/changes/51/433651/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_tempest_tests/tests/api/base.py', 'contrib/ci/common.sh']",2,bb7976fc824a26de435293c932b45594411f8f80,tempest-pin-to-latest,"export MANILA_TEMPEST_COMMIT=""4ce3779"" # 10 Feb, 2017","export MANILA_TEMPEST_COMMIT=""c592707"" # 2 Sept, 2016 - tempest 12.2.0",23,13
openstack%2Fmanila-specs~master~If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf,openstack/manila-specs,master,If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf,Update Share Migration Ocata Improvements Spec,MERGED,2016-12-05 19:14:16.000000000,2017-02-17 23:08:59.000000000,2017-02-17 23:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 11047}, {'_account_id': 14567}, {'_account_id': 16643}]","[{'number': 1, 'created': '2016-12-05 19:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/bbde4927032c5b61dd7374fd8a0dd8b981e55f57', 'message': 'Update Share Migration Ocata Improvements Spec\n\nNew required changes have been discovered in coding\nphase. This change updates the spec accordingly.\n\nThis patchset is still pending decision of syntax of\npython-manilaclient migration-start command, so\nonce decided, it will be updated to include only\nthe decided command.\n\nChange-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf\nPartially-implements: blueprint ocata-migration-improvements\n'}, {'number': 2, 'created': '2016-12-19 17:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/536c21eb7c1953a170ffdc00ba7c7e439cbadbd2', 'message': 'Update Share Migration Ocata Improvements Spec\n\nNew required changes have been discovered in coding\nphase. This change updates the spec accordingly.\n\nChange-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf\nPartially-implements: blueprint ocata-migration-improvements\n'}, {'number': 3, 'created': '2017-02-06 11:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/e60d353ac1b0b0e92112664b3114315edb52bb6b', 'message': 'Update Share Migration Ocata Improvements Spec\n\nNew required changes have been discovered in coding\nphase. This change updates the spec accordingly.\n\nChange-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf\nPartially-implements: blueprint ocata-migration-improvements\n'}, {'number': 4, 'created': '2017-02-06 18:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/a1975738597ccb31539141493c9da1c8ec3492cd', 'message': 'Update Share Migration Ocata Improvements Spec\n\nNew required changes have been discovered in coding\nphase. This change updates the spec accordingly.\n\nChange-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf\nPartially-implements: blueprint ocata-migration-improvements\n'}, {'number': 5, 'created': '2017-02-08 11:35:02.000000000', 'files': ['specs/ocata/ocata-migration-improvements.rst'], 'web_link': 'https://opendev.org/openstack/manila-specs/commit/e718599a4379c9fe1dc42f8d6bb196c9a17f3b0d', 'message': 'Update Share Migration Ocata Improvements Spec\n\nNew required changes have been discovered in coding\nphase. This change updates the spec accordingly.\n\nChange-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf\nPartially-implements: blueprint ocata-migration-improvements\n'}]",10,407145,e718599a4379c9fe1dc42f8d6bb196c9a17f3b0d,26,5,5,14567,,,0,"Update Share Migration Ocata Improvements Spec

New required changes have been discovered in coding
phase. This change updates the spec accordingly.

Change-Id: If02180ec3b5ae05c9ff18c9f5a054c33f13edcdf
Partially-implements: blueprint ocata-migration-improvements
",git fetch https://review.opendev.org/openstack/manila-specs refs/changes/45/407145/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/ocata/ocata-migration-improvements.rst'],1,bbde4927032c5b61dd7374fd8a0dd8b981e55f57,bp/ocata-migration-improvements,"* The microversion will be bumped to include the changes proposed. Support to previous microversion of migration-start will be dropped as we will only support the one with mandatory parameters. -- To be decided -- 1) All parameters fixed positional <preserve-metadata> <preserve-snapshots> --force-host-assisted-migration 2) All parameters with optional syntax, any order manila migration-start <share> <host> --nondisruptive --writable --preserve-metadata --preserve-snapshots --force-host-assisted-migration --new-share-network --new-share-type manila migration-start share_1 ubuntu@generic1#GENERIC1 --writable True --nondisruptive False --preserve-metadata True --preserve-snapshots False 3) key=value style, comma separated, any order manila migration-start <share> <host> <writable=True|False, preserve-metadata=True|False,preserve-snapshots=True|False, nondisruptive=True|False> --force-host-assisted-migration --new-share-network --new-share-type manila migration-start share_1 ubuntu@generic1#GENERIC1 writable=True, preserve-metadata=True,preserve-snapshots=True,nondisruptive=True 4) key=value style, space separated, any order manila migration-start <share> <host> <writable=True|False preserve-metadata=True|False preserve-snapshots=True|False nondisruptive=True|False> --force-host-assisted-migration --new-share-network --new-share-type manila migration-start share_1 ubuntu@generic1#GENERIC1 writable=True preserve_metadata=True preserve_snapshots=True nondisruptive=True All existing migration driver interfaces will be updated to include snapshot-related parameters. See the new updated interfaces below:: def migration_start( self, context, source_share, destination_share, source_snapshots, snapshot_mappings, share_server=None, destination_share_server=None): """"""Starts migration of a given share to another host. .. note:: Is called in source share's backend to start migration. Driver should implement this method if willing to perform migration in a driver-assisted way, useful for when source share's backend driver is compatible with destination backend driver. This method should start the migration procedure in the backend and end. Following steps should be done in 'migration_continue'. :param context: The 'context.RequestContext' object for the request. :param source_share: Reference to the original share model. :param destination_share: Reference to the share model to be used by migrated share. :param source_snapshots: List of snapshots owned by the source share. :param snapshot_mappings: Mapping of source snapshot IDs to destination snapshot models. :param share_server: Share server model or None. :param destination_share_server: Destination Share server model or None. """""" raise NotImplementedError() def migration_continue( self, context, source_share, destination_share, source_snapshots, snapshot_mappings, share_server=None, destination_share_server=None): """"""Continues migration of a given share to another host. .. note:: Is called in source share's backend to continue migration. Driver should implement this method to continue monitor the migration progress in storage and perform following steps until 1st phase is completed. :param context: The 'context.RequestContext' object for the request. :param source_share: Reference to the original share model. :param destination_share: Reference to the share model to be used by migrated share. :param source_snapshots: List of snapshots owned by the source share. :param snapshot_mappings: Mapping of source snapshot IDs to destination snapshot models. :param share_server: Share server model or None. :param destination_share_server: Destination Share server model or None. :return: Boolean value to indicate if 1st phase is finished. """""" raise NotImplementedError() def migration_complete( self, context, source_share, destination_share, source_snapshots, snapshot_mappings, share_server=None, destination_share_server=None): """"""Completes migration of a given share to another host. .. note:: Is called in source share's backend to complete migration. If driver is implementing 2-phase migration, this method should perform the disruptive tasks related to the 2nd phase of migration, thus completing it. Driver should also delete all original share data from source backend. :param context: The 'context.RequestContext' object for the request. :param source_share: Reference to the original share model. :param destination_share: Reference to the share model to be used by migrated share. :param source_snapshots: List of snapshots owned by the source share. :param snapshot_mappings: Mapping of source snapshot IDs to destination snapshot models. :param share_server: Share server model or None. :param destination_share_server: Destination Share server model or None. :return: A dictionary containing a list of export locations and a list of model updates for each snapshot indexed by their IDs. Example:: { 'export_locations': [ { 'path': '1.2.3.4:/foo', 'metadata': {}, 'is_admin_only': False }, { 'path': '5.6.7.8:/foo', 'metadata': {}, 'is_admin_only': True }, ], 'snapshot_updates': { 'bc4e3b28-0832-4168-b688-67fdc3e9d408': { 'provider_location': '/snapshots/foo/bar_1' }, '2e62b7ea-4e30-445f-bc05-fd523ca62941': { 'provider_location': '/snapshots/foo/bar_2' }, }, } """""" raise NotImplementedError() def migration_cancel( self, context, source_share, destination_share, source_snapshots, snapshot_mappings, share_server=None, destination_share_server=None): """"""Cancels migration of a given share to another host. .. note:: Is called in source share's backend to cancel migration. If possible, driver can implement a way to cancel an in-progress migration. :param context: The 'context.RequestContext' object for the request. :param source_share: Reference to the original share model. :param destination_share: Reference to the share model to be used by migrated share. :param source_snapshots: List of snapshots owned by the source share. :param snapshot_mappings: Mapping of source snapshot IDs to destination snapshot models. :param share_server: Share server model or None. :param destination_share_server: Destination Share server model or None. """""" raise NotImplementedError() def migration_get_progress( self, context, source_share, destination_share, source_snapshots, snapshot_mappings, share_server=None, destination_share_server=None): """"""Obtains progress of migration of a given share to another host. .. note:: Is called in source share's backend to obtain migration progress. If possible, driver can implement a way to return migration progress information. :param context: The 'context.RequestContext' object for the request. :param source_share: Reference to the original share model. :param destination_share: Reference to the share model to be used by migrated share. :param source_snapshots: List of snapshots owned by the source share. :param snapshot_mappings: Mapping of source snapshot IDs to destination snapshot models. :param share_server: Share server model or None. :param destination_share_server: Destination Share server model or None. :return: A dictionary with at least 'total_progress' field containing the percentage value. """""" raise NotImplementedError() As can be noted above, the migration_complete driver interfaces had its return value changed to return a dictionary structure containing the export locations and a dictionary of snapshot updates, containing model updates for each snapshot, in order to update the provider location in manila's database. When starting a driver-assisted migration, it will be checked if drivers can support ""preserve_snapshots"" regardless of the API option specified, due to the fact that the migrating share may have existing snapshots. In case the driver does not support ""preserve_snapshots"", an error message will be raised, stating that driver-assisted migration cannot proceed while the share has snapshots. If the driver does support ""preserve_snapshots"", it will be checked if all existing snapshots have 'available' status. If so, destination snapshot instances respective to each source snapshot instance will be created in the database. Finally, a list of source snapshot instances and a mapping dictionary, that comprises of destination snapshot instances indexed by source snapshot instance IDs, will be passed to drivers in the update driver interface. This mapping and list of snapshots will be easily retrieved from the database at later stages such as when invoking migration_continue and migration_complete. As for host-assisted migration, the validation of existing snapshots that once was in the API layer, has been moved to before starting a host-assisted migration, as it will prevent the host-assisted migration from running. ","* The microversion will be bumped to include the changes proposed. <preserve_metadata> <preserve_snapshots> --force-host-assisted-migrationPlease note that during code implementation we may decide to change the syntax shown in the example above with regards to the mandatory driver-assisted parameters, in order to drive a better user experience with the CLI.",234,5
openstack%2Fgnocchi~stable%2F3.1~I1c99878eef37fa59d7a806d0e8c838fd85214d3f,openstack/gnocchi,stable/3.1,I1c99878eef37fa59d7a806d0e8c838fd85214d3f,s3: use a different bucket prefix for each test,MERGED,2017-02-17 21:28:13.000000000,2017-02-17 22:58:57.000000000,2017-02-17 22:58:57.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-02-17 21:28:13.000000000', 'files': ['gnocchi/tests/base.py', 'gnocchi/tests/test_storage.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0fad6445d4cb5341f3c3530d1334f1e869894a25', 'message': 's3: use a different bucket prefix for each test\n\nThat allows to run more tests!\n\nChange-Id: I1c99878eef37fa59d7a806d0e8c838fd85214d3f\n(cherry picked from commit 17ed44ba4541defb4b580fbf261f97169ede0773)\n'}]",0,435606,0fad6445d4cb5341f3c3530d1334f1e869894a25,6,2,1,1669,,,0,"s3: use a different bucket prefix for each test

That allows to run more tests!

Change-Id: I1c99878eef37fa59d7a806d0e8c838fd85214d3f
(cherry picked from commit 17ed44ba4541defb4b580fbf261f97169ede0773)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/06/435606/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/base.py', 'gnocchi/tests/test_storage.py']",2,0fad6445d4cb5341f3c3530d1334f1e869894a25,jd/fix-s3,," if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."")",5,16
openstack%2Fgnocchi~stable%2F3.1~I088d9f7b5079523f0ec5eb1a1282f0c145131f9e,openstack/gnocchi,stable/3.1,I088d9f7b5079523f0ec5eb1a1282f0c145131f9e,s3: set maximum length for s3_bucket_prefix option,MERGED,2017-02-17 21:28:21.000000000,2017-02-17 22:56:55.000000000,2017-02-17 22:56:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-02-17 21:28:21.000000000', 'files': ['requirements.txt', 'gnocchi/storage/s3.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/689f2b3932e61c7e4053d6da8edffd71104465e2', 'message': 's3: set maximum length for s3_bucket_prefix option\n\nChange-Id: I088d9f7b5079523f0ec5eb1a1282f0c145131f9e\n(cherry picked from commit 1dc358235670794119d7bf9362012445e152ce66)\n'}]",0,435607,689f2b3932e61c7e4053d6da8edffd71104465e2,6,2,1,1669,,,0,"s3: set maximum length for s3_bucket_prefix option

Change-Id: I088d9f7b5079523f0ec5eb1a1282f0c145131f9e
(cherry picked from commit 1dc358235670794119d7bf9362012445e152ce66)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/07/435607/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'gnocchi/storage/s3.py']",2,689f2b3932e61c7e4053d6da8edffd71104465e2,jd/fix-s3," # Max bucket length is 63 and we use ""-"" as separator # 63 - 1 - len(uuid) = 26 max_length=26,",,4,1
openstack%2Fcharm-ceilometer~master~I5064ce130da1ec302245aaff5dbe93d9dab63b38,openstack/charm-ceilometer,master,I5064ce130da1ec302245aaff5dbe93d9dab63b38,Stop checking for ceilometer-agent-central service,MERGED,2017-02-17 17:13:47.000000000,2017-02-17 22:55:56.000000000,2017-02-17 22:55:56.000000000,"[{'_account_id': 3}, {'_account_id': 11805}, {'_account_id': 12549}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-17 17:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/721aba6a6ed78aad5aab6e260709135e0e2bccb5', 'message': 'Stop checking for ceilometer-agent-central service\n\nSince Liberty ceilometer-agent-central has been replaced with\nceilometer-polling. There is some confusion there as the package\nis still named ceilometer-agent-central.\n\nFor OpenStack releases >= Liberty stop checking for the\nceilometer-agent-central service to be running.\n\nTODO for post release: remove the OCF management of the service(s).\n\nChange-Id: I5064ce130da1ec302245aaff5dbe93d9dab63b38\nPartial-bug: #1664898\n'}, {'number': 2, 'created': '2017-02-17 17:27:34.000000000', 'files': ['lib/ceilometer_utils.py', 'hooks/ceilometer_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-ceilometer/commit/5951cbb7636dc1195c1c2e415c7647922336f2c5', 'message': 'Stop checking for ceilometer-agent-central service\n\nSince Liberty ceilometer-agent-central has been replaced with\nceilometer-polling. There is some confusion there as the package\nis still named ceilometer-agent-central.\n\nFor OpenStack releases >= Liberty stop checking for the\nceilometer-agent-central service to be running.\n\nTODO for post release: remove the OCF management of the service(s).\n\nChange-Id: I5064ce130da1ec302245aaff5dbe93d9dab63b38\nPartial-bug: #1664898\n'}]",1,435540,5951cbb7636dc1195c1c2e415c7647922336f2c5,12,5,2,20805,,,0,"Stop checking for ceilometer-agent-central service

Since Liberty ceilometer-agent-central has been replaced with
ceilometer-polling. There is some confusion there as the package
is still named ceilometer-agent-central.

For OpenStack releases >= Liberty stop checking for the
ceilometer-agent-central service to be running.

TODO for post release: remove the OCF management of the service(s).

Change-Id: I5064ce130da1ec302245aaff5dbe93d9dab63b38
Partial-bug: #1664898
",git fetch https://review.opendev.org/openstack/charm-ceilometer refs/changes/40/435540/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ceilometer_utils.py', 'hooks/ceilometer_hooks.py']",2,721aba6a6ed78aad5aab6e260709135e0e2bccb5,bug/1664898, # TODO Move away from using the OCF resource for openstack service # management.,,10,1
openstack%2Fpython-openstackclient~master~I8f3318f55ed79d617c3594142f0c086e2bd1a7b1,openstack/python-openstackclient,master,I8f3318f55ed79d617c3594142f0c086e2bd1a7b1,Fix image selection in server function tests,MERGED,2017-02-17 18:15:46.000000000,2017-02-17 22:52:35.000000000,2017-02-17 22:52:35.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 6482}, {'_account_id': 18332}]","[{'number': 1, 'created': '2017-02-17 18:15:46.000000000', 'files': ['openstackclient/tests/functional/compute/v2/test_server.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/ef1a86a802149e0a62c68fb93edf66b802bc72d1', 'message': 'Fix image selection in server function tests\n\nThe image selection has been affected by Cirros image changes in DevStack,\nmake the logic moe robust and convert it to JSON.  The conversion for the\nremainder of the file will follow.\n\nChange-Id: I8f3318f55ed79d617c3594142f0c086e2bd1a7b1\n'}]",0,435559,ef1a86a802149e0a62c68fb93edf66b802bc72d1,11,4,1,970,,,0,"Fix image selection in server function tests

The image selection has been affected by Cirros image changes in DevStack,
make the logic moe robust and convert it to JSON.  The conversion for the
remainder of the file will follow.

Change-Id: I8f3318f55ed79d617c3594142f0c086e2bd1a7b1
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/59/435559/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/functional/compute/v2/test_server.py'],1,ef1a86a802149e0a62c68fb93edf66b802bc72d1,fix-cirros-image-get," # NOTE(rtheis): Get first Cirros image since functional tests may # create other images. Image may be named '-uec' or # '-disk'. cmd_output = json.loads(cls.openstack( ""image list -f json "" )) for image in cmd_output: if (image['Name'].startswith('cirros-') and (image['Name'].endswith('-uec') or image['Name'].endswith('-disk'))): server_image = image['Name']", # NOTE(rtheis): Get cirros image since functional tests may # create other images. images = cls.openstack('image list -c Name -f value').split('\n') for image in images: if image.startswith('cirros-') and image.endswith('-uec'): server_image = image,11,6
openstack%2Fnetworking-generic-switch~master~Iffe28120ca74fc1d66108115d57513962714f25b,openstack/networking-generic-switch,master,Iffe28120ca74fc1d66108115d57513962714f25b,Use flake8-import-order,MERGED,2017-02-17 19:14:22.000000000,2017-02-17 22:52:28.000000000,2017-02-17 22:52:28.000000000,"[{'_account_id': 3}, {'_account_id': 14525}]","[{'number': 1, 'created': '2017-02-17 19:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/5b976076d78797d6ab3695845494a5ec44ed8d45', 'message': ""Use flake8-import-order\n\nUse the flake8 plugin flake8-import-order to check import ordering. It\ncan do it automatically and don't need reviewers to check it.\n\nChange-Id: Iffe28120ca74fc1d66108115d57513962714f25b\n""}, {'number': 2, 'created': '2017-02-17 19:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/4b5e5318c32e0d94fe40d9b788fa3adca6d1445c', 'message': ""Use flake8-import-order\n\nUse the flake8 plugin flake8-import-order to check import ordering. It\ncan do it automatically and don't need reviewers to check it.\n\nChange-Id: Iffe28120ca74fc1d66108115d57513962714f25b\n""}, {'number': 3, 'created': '2017-02-17 20:48:08.000000000', 'files': ['test-requirements.txt', 'networking_generic_switch/devices/netmiko_devices/__init__.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-generic-switch/commit/8e231e73605670f9937a0e0ebd45e8931517df29', 'message': ""Use flake8-import-order\n\nUse the flake8 plugin flake8-import-order to check import ordering. It\ncan do it automatically and don't need reviewers to check it.\n\nChange-Id: Iffe28120ca74fc1d66108115d57513962714f25b\n""}]",0,435571,8e231e73605670f9937a0e0ebd45e8931517df29,9,2,3,14525,,,0,"Use flake8-import-order

Use the flake8 plugin flake8-import-order to check import ordering. It
can do it automatically and don't need reviewers to check it.

Change-Id: Iffe28120ca74fc1d66108115d57513962714f25b
",git fetch https://review.opendev.org/openstack/networking-generic-switch refs/changes/71/435571/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,5b976076d78797d6ab3695845494a5ec44ed8d45,,import-order-style = pep8,,2,0
openstack%2Fgnocchi~stable%2F3.1~Ie5e4760c630d9906b57eda48dbd42165108c96e7,openstack/gnocchi,stable/3.1,Ie5e4760c630d9906b57eda48dbd42165108c96e7,s3: fix minimum botocore version,MERGED,2017-02-17 21:27:46.000000000,2017-02-17 22:35:04.000000000,2017-02-17 22:35:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}]","[{'number': 1, 'created': '2017-02-17 21:27:46.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1dd962bbd5cc4238471378d69a3b525ef23a3279', 'message': 's3: fix minimum botocore version\n\nBotocore is mainly used as a dependency of boto3, but Gnocchi actually requires\nversion 1.5 minimum to have list_objects_v2 available.\n\nChange-Id: Ie5e4760c630d9906b57eda48dbd42165108c96e7\n(cherry picked from commit 6f09a699535a1b53b021a8d8f70ca55bfe5222de)\n'}]",0,435604,1dd962bbd5cc4238471378d69a3b525ef23a3279,6,2,1,1669,,,0,"s3: fix minimum botocore version

Botocore is mainly used as a dependency of boto3, but Gnocchi actually requires
version 1.5 minimum to have list_objects_v2 available.

Change-Id: Ie5e4760c630d9906b57eda48dbd42165108c96e7
(cherry picked from commit 6f09a699535a1b53b021a8d8f70ca55bfe5222de)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/04/435604/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,1dd962bbd5cc4238471378d69a3b525ef23a3279,jd/fix-s3, botocore>=1.5,,1,0
openstack%2Fceilometer~stable%2Focata~I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac,openstack/ceilometer,stable/ocata,I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac,set OS_AUTH_TYPE in gate,MERGED,2017-02-17 20:09:58.000000000,2017-02-17 22:28:26.000000000,2017-02-17 22:28:26.000000000,"[{'_account_id': 3}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-17 20:09:58.000000000', 'files': ['ceilometer/tests/integration/hooks/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b3c404a7c5c38f6d7a0999693fc38eef2f8840d6', 'message': ""set OS_AUTH_TYPE in gate\n\nwe use keystone in integration gate but never set OS_AUTH_TYPE.\ngnocchi will not default to keystone if OS_AUTH_TYPE isn't set.\n\nChange-Id: I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac\n(cherry picked from commit 83412c80cc94da3afa7a0368a27ffce49cf1ac15)\n""}]",0,435582,b3c404a7c5c38f6d7a0999693fc38eef2f8840d6,6,2,1,6537,,,0,"set OS_AUTH_TYPE in gate

we use keystone in integration gate but never set OS_AUTH_TYPE.
gnocchi will not default to keystone if OS_AUTH_TYPE isn't set.

Change-Id: I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac
(cherry picked from commit 83412c80cc94da3afa7a0368a27ffce49cf1ac15)
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/82/435582/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/integration/hooks/post_test_hook.sh'],1,b3c404a7c5c38f6d7a0999693fc38eef2f8840d6,test,export OS_AUTH_TYPE=password,,1,0
openstack%2Fopenstack-ansible~master~I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b,openstack/openstack-ansible,master,I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b,Cinder use correct glance API when RBD enabled,MERGED,2017-02-17 01:22:55.000000000,2017-02-17 22:14:44.000000000,2017-02-17 21:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-17 01:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/63ca5d4ce6afd349345b197ff3d19cf6a5ea93e5', 'message': 'Cinder use correct glance API when RBD enabled\n\nThe syntax of the jinja block was broken and outputted a line break\nalways, like this:\nok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {\n    ""msg"": ""True\\n""\n}\n\nSo the resulting evaluation was always false, and glance API v1 was\nused by cinder-volume, breaking the ceph CoW functionality.\n\nThis fixes the variable to eval properly as a boolean and make\nCinder use the correct glance API version.\n\nChange-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b\n'}, {'number': 2, 'created': '2017-02-17 13:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e8727bd33bd8ca98f6fdf3cc8f3a93b85689b6c1', 'message': 'Cinder use correct glance API when RBD enabled\n\nThe syntax of the jinja block was broken and outputted a line break\nalways, like this:\nok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {\n    ""msg"": ""True\\n""\n}\n\nSo the resulting evaluation was always false, and glance API v1 was\nused by cinder-volume, breaking the ceph CoW functionality.\n\nThis fixes the variable to eval properly as a boolean and make\nCinder use the correct glance API version.\n\nChange-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b\n'}, {'number': 3, 'created': '2017-02-17 15:39:26.000000000', 'files': ['playbooks/inventory/group_vars/all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6bc3bf911cff85afd08e37c19faeafaaca8e1494', 'message': 'Cinder use correct glance API when RBD enabled\n\nThe syntax of the jinja block was broken and outputted a line break\nalways, like this:\nok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {\n    ""msg"": ""True\\n""\n}\n\nSo the resulting evaluation was always false, and glance API v1 was\nused by cinder-volume, breaking the ceph CoW functionality.\n\nThis fixes the variable to eval properly as a boolean and make\nCinder use the correct glance API version.\n\nChange-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b\n'}]",0,435184,6bc3bf911cff85afd08e37c19faeafaaca8e1494,18,4,3,17799,,,0,"Cinder use correct glance API when RBD enabled

The syntax of the jinja block was broken and outputted a line break
always, like this:
ok: [lsn-d6329_cinder_volumes_container-9a2bbc7d] => {
    ""msg"": ""True\n""
}

So the resulting evaluation was always false, and glance API v1 was
used by cinder-volume, breaking the ceph CoW functionality.

This fixes the variable to eval properly as a boolean and make
Cinder use the correct glance API version.

Change-Id: I9c1f31bba80bf2591710fd4d59f320ffadaf1c8b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/84/435184/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/inventory/group_vars/all.yml'],1,63ca5d4ce6afd349345b197ff3d19cf6a5ea93e5,cinder-rbd-fix,cinder_backends_rbd_inuse: >-,cinder_backends_rbd_inuse: >,1,1
openstack%2Frequirements~master~I048487967c00c01047d8da21479ac930253876a8,openstack/requirements,master,I048487967c00c01047d8da21479ac930253876a8,[WIP] Testing python-magnumclient 2.5.0,ABANDONED,2017-02-17 16:45:56.000000000,2017-02-17 22:04:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-02-17 16:45:56.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/78c473ceb1359c7367a83642c4f09cf1a711a6c2', 'message': '[WIP] Testing python-magnumclient 2.5.0\n\nChange-Id: I048487967c00c01047d8da21479ac930253876a8\n'}]",0,435523,78c473ceb1359c7367a83642c4f09cf1a711a6c2,6,3,1,5638,,,0,"[WIP] Testing python-magnumclient 2.5.0

Change-Id: I048487967c00c01047d8da21479ac930253876a8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/23/435523/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,78c473ceb1359c7367a83642c4f09cf1a711a6c2,test-magnum-client-2.5.0,python-magnumclient===2.5.0,python-magnumclient===2.4.0,1,1
openstack%2Fpuppet-nova~master~Iea0d874108b39609505e542eda29b9bb74ca2a35,openstack/puppet-nova,master,Iea0d874108b39609505e542eda29b9bb74ca2a35,Fix idempotency with empty available filters,MERGED,2017-02-16 20:19:24.000000000,2017-02-17 22:01:10.000000000,2017-02-17 22:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 15519}, {'_account_id': 18795}]","[{'number': 1, 'created': '2017-02-16 20:19:24.000000000', 'files': ['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/334eec2fd00a1ddd45296491bc115985ef1a3113', 'message': 'Fix idempotency with empty available filters\n\nIf an empty array is passed in for the available filters, the provider\nis improperly thinking a configuration value needs to be done. This\nchange checks for this case and sets it to $::os_service_default.\n\nChange-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35\nCloses-Bug: #1665443\nRelated-Bug: #1664650\n'}]",0,435099,334eec2fd00a1ddd45296491bc115985ef1a3113,28,4,1,14985,,,0,"Fix idempotency with empty available filters

If an empty array is passed in for the available filters, the provider
is improperly thinking a configuration value needs to be done. This
change checks for this case and sets it to $::os_service_default.

Change-Id: Iea0d874108b39609505e542eda29b9bb74ca2a35
Closes-Bug: #1665443
Related-Bug: #1664650
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/99/435099/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/scheduler/filter.pp', 'spec/classes/nova_scheduler_filter_spec.rb']",2,334eec2fd00a1ddd45296491bc115985ef1a3113,bug/1665443," :scheduler_available_filters => [], it { is_expected.to contain_nova_config('filter_scheduler/available_filters').with_value('<SERVICE DEFAULT>') }",,7,1
openstack%2Fpython-zunclient~master~Iebc28e9781357c11a664c6b0d203a4c20a63a6ca,openstack/python-zunclient,master,Iebc28e9781357c11a664c6b0d203a4c20a63a6ca,Add OSC commands functional test,MERGED,2017-02-02 17:56:36.000000000,2017-02-17 22:00:14.000000000,2017-02-17 22:00:14.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 11536}, {'_account_id': 12175}, {'_account_id': 21785}]","[{'number': 1, 'created': '2017-02-02 17:56:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/c5480b02d350e80af99cbdbad0095d5d48eed2eb', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 2, 'created': '2017-02-03 04:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/c4c6040850c2e4c76142e6bee3f829f4fbda43bf', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 3, 'created': '2017-02-03 05:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/102d2074ec786247f3bc9c16d1da2167afe1a940', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 4, 'created': '2017-02-03 05:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/2714b8910bd07808dabe2631f2fee127d78b897a', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 5, 'created': '2017-02-03 07:50:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/199f9b46f5c780bb777bd3616eae3752336ba0ee', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 6, 'created': '2017-02-03 09:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/3a0dbdd22c66c33020a199c95fcbd1f777168f80', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 7, 'created': '2017-02-03 15:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/80111fe33e4cac621fa2002abd577dd113be6c8e', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 8, 'created': '2017-02-05 08:02:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/fb6ebcc2d678f5d5b16d8a24eed2771e7c226318', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 9, 'created': '2017-02-05 10:50:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/38fb65221a62ee9935528deebb8a98bbf784dc46', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 10, 'created': '2017-02-06 08:13:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/1f098ab581182bd7815b5917ee6d468b69278ab3', 'message': '[WIP]Add OSC commands functional test\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 11, 'created': '2017-02-06 09:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/a29370cc84ce78bde20715f472dbd124ed644310', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 12, 'created': '2017-02-06 09:37:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/e15b9b9d9486d19739d9edb73f19d8057ae31bc8', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 13, 'created': '2017-02-13 09:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/778729ea66722fbd1d3ed77ca739c91406bd1be0', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 14, 'created': '2017-02-13 10:23:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/17c208fbe4de247ec493c78c7ca8da976d15c94e', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 15, 'created': '2017-02-14 10:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/9c056cb84987f611e4c8c581bbc629023d5cd9c7', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}, {'number': 16, 'created': '2017-02-16 09:54:02.000000000', 'files': ['zunclient/tests/functional/osc/__init__.py', 'requirements.txt', 'zunclient/tests/functional/base.py', 'zunclient/tests/functional/osc/v1/test_container.py', '.gitignore', 'test-requirements.txt', 'zunclient/tests/functional/hooks/post_test_hook.sh', 'zunclient/tests/functional/osc/v1/__init__.py', 'tools/run_functional.sh', 'tox.ini', 'zunclient/tests/functional/osc/v1/base.py'], 'web_link': 'https://opendev.org/openstack/python-zunclient/commit/6b5ef0dab21661b27c323851af3bb6cdb011c0aa', 'message': 'Add OSC commands functional test\n\nThis patch adds the basic files and only one test now.\nConsecutive patches will add more test cases.\n\nChange-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca\n'}]",18,428300,6b5ef0dab21661b27c323851af3bb6cdb011c0aa,51,5,16,21785,,,0,"Add OSC commands functional test

This patch adds the basic files and only one test now.
Consecutive patches will add more test cases.

Change-Id: Iebc28e9781357c11a664c6b0d203a4c20a63a6ca
",git fetch https://review.opendev.org/openstack/python-zunclient refs/changes/00/428300/16 && git format-patch -1 --stdout FETCH_HEAD,"['zunclient/tests/functional/osc/__init__.py', 'zunclient/tests/functional/base.py', 'zunclient/tests/functional/osc/v1/test_container.py', 'test-requirements.txt', 'tox.ini', 'zunclient/tests/functional/osc/v1/__init__.py', 'zunclient/tests/functional/osc/v1/base.py']",7,c5480b02d350e80af99cbdbad0095d5d48eed2eb,osc_test,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json from tempest.lib.common.utils import data_utils from tempest.lib import exceptions from zunclient.tests.functional import base class TestCase(base.FunctionalTestBase): def openstack(self, *args, **kwargs): return self._zun_osc(*args, **kwargs) def get_opts(self, fields=None, output_format='json'): """"""Get options for OSC output fields format. :param List fields: List of fields to get :param String output_format: Select output format :return: String of formatted options """""" if not fields: return ' -f {0}'.format(output_format) return ' -f {0} {1}'.format(output_format, ' '.join(['-c ' + it for it in fields])) def container_list(self, fields=None, params=''): """"""List Container. :param List fields: List of fields to show :param String params: Additional kwargs :return: list of JSON node objects """""" opts = self.get_opts(fields=fields) output = self.openstack('containers list {0} {1}' .format(opts, params)) return json.loads(output) ",,291,0
openstack%2Ftripleo-heat-templates~stable%2Focata~I07bfeee7b7d9a9b8c2c20e5d5c9ed735d0bfc842,openstack/tripleo-heat-templates,stable/ocata,I07bfeee7b7d9a9b8c2c20e5d5c9ed735d0bfc842,Apply puppet in non-controller script in step.,MERGED,2017-02-17 08:59:14.000000000,2017-02-17 21:53:27.000000000,2017-02-17 21:53:27.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8297}, {'_account_id': 8449}]","[{'number': 1, 'created': '2017-02-17 08:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/18be75a2e24d2f7492991b12ab852236d39809ef', 'message': 'Apply puppet in non-controller script in step.\n\nWe want to apply a puppet manifest for the non-controller role, but we\nneed to apply it in stages.  By loading the proper hieradata we get the\nneeded step configuration.\n\nChange-Id: I07bfeee7b7d9a9b8c2c20e5d5c9ed735d0bfc842\nCloses-Bug: #1664304\n'}, {'number': 2, 'created': '2017-02-17 09:39:31.000000000', 'files': ['extraconfig/tasks/run_puppet.sh', 'extraconfig/tasks/tripleo_upgrade_node.sh', 'puppet/major_upgrade_steps.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3440d9d8caa26f0360be9d9d6110ff46e6e8ddb6', 'message': 'Apply puppet in non-controller script in step.\n\nWe want to apply a puppet manifest for the non-controller role, but we\nneed to apply it in stages.  By loading the proper hieradata we get the\nneeded step configuration.\n\nChange-Id: I07bfeee7b7d9a9b8c2c20e5d5c9ed735d0bfc842\nCloses-Bug: #1664304\n(cherry picked from commit 237cd2004a2c0869d60d0e11e9dccd59e809ff90)\n'}]",1,435315,3440d9d8caa26f0360be9d9d6110ff46e6e8ddb6,15,6,2,8449,,,0,"Apply puppet in non-controller script in step.

We want to apply a puppet manifest for the non-controller role, but we
need to apply it in stages.  By loading the proper hieradata we get the
needed step configuration.

Change-Id: I07bfeee7b7d9a9b8c2c20e5d5c9ed735d0bfc842
Closes-Bug: #1664304
(cherry picked from commit 237cd2004a2c0869d60d0e11e9dccd59e809ff90)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/435315/2 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/tasks/run_puppet.sh', 'extraconfig/tasks/tripleo_upgrade_node.sh', 'puppet/major_upgrade_steps.j2.yaml']",3,18be75a2e24d2f7492991b12ab852236d39809ef,bug/1664304, - get_file: ../extraconfig/tasks/run_puppet.sh,,36,3
openstack%2Fkeystone~master~I3832d9ffd5bcac8f4a137a22adfd8a6687c137b3,openstack/keystone,master,I3832d9ffd5bcac8f4a137a22adfd8a6687c137b3,Move default user policies in code,ABANDONED,2017-02-17 21:26:13.000000000,2017-02-17 21:50:20.000000000,,[{'_account_id': 5046}],"[{'number': 1, 'created': '2017-02-17 21:26:13.000000000', 'files': ['keystone/policies/__init__.py', 'keystone/policies/users.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/keystone/commit/4ecf97c0d9a8baffbcecdc9e2b5a814cf06a11cd', 'message': 'Move default user policies in code\n\npartially-implements bp policy-in-code\n\nChange-Id: I3832d9ffd5bcac8f4a137a22adfd8a6687c137b3\n'}]",0,435603,4ecf97c0d9a8baffbcecdc9e2b5a814cf06a11cd,3,1,1,5046,,,0,"Move default user policies in code

partially-implements bp policy-in-code

Change-Id: I3832d9ffd5bcac8f4a137a22adfd8a6687c137b3
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/435603/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/policies/__init__.py', 'keystone/policies/users.py', 'etc/policy.json']",3,4ecf97c0d9a8baffbcecdc9e2b5a814cf06a11cd,bp/policy-in-code,," ""identity:get_user"": ""rule:admin_or_owner"", ""identity:list_users"": ""rule:admin_required"", ""identity:create_user"": ""rule:admin_required"", ""identity:update_user"": ""rule:admin_required"", ""identity:delete_user"": ""rule:admin_required"", ""identity:change_password"": ""rule:admin_or_owner"", ",52,8
openstack%2Fkeystone~master~I7d72e470d4b607dc593710fe8f46d58325b7dc1a,openstack/keystone,master,I7d72e470d4b607dc593710fe8f46d58325b7dc1a,Create a policies module,ABANDONED,2017-02-17 21:26:13.000000000,2017-02-17 21:50:13.000000000,,[{'_account_id': 5046}],"[{'number': 1, 'created': '2017-02-17 21:26:13.000000000', 'files': ['keystone/policies/__init__.py', 'keystone/policy/backends/rules.py', 'keystone/policies/base.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/keystone/commit/86eb133d7d784c65e620a581889ef2c07b8662c8', 'message': 'Create a policies module\n\nThis commit follows a lot of the patterns established by nova for\npulling default policy rules into code. Here we are specifically:\n\n  - Creating a new module called `policies` to hold in-code defaults\n  - Ensuring we use pass our list of policies to our policy ENFORCER\n    before use\n  - Add a base module for common policy rules that will be used\n    throughout other policy checks\n\nSubsequent patches will start migrating defaults from our policy into\ncode. Note that each subsequent patch will remove checks from the\npolicy file we maintain.\n\npartially-implements bp policy-in-code\n\nChange-Id: I7d72e470d4b607dc593710fe8f46d58325b7dc1a\n'}]",0,435602,86eb133d7d784c65e620a581889ef2c07b8662c8,3,1,1,5046,,,0,"Create a policies module

This commit follows a lot of the patterns established by nova for
pulling default policy rules into code. Here we are specifically:

  - Creating a new module called `policies` to hold in-code defaults
  - Ensuring we use pass our list of policies to our policy ENFORCER
    before use
  - Add a base module for common policy rules that will be used
    throughout other policy checks

Subsequent patches will start migrating defaults from our policy into
code. Note that each subsequent patch will remove checks from the
policy file we maintain.

partially-implements bp policy-in-code

Change-Id: I7d72e470d4b607dc593710fe8f46d58325b7dc1a
",git fetch https://review.opendev.org/openstack/keystone refs/changes/02/435602/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/policies/__init__.py', 'keystone/policy/backends/rules.py', 'etc/policy.json', 'keystone/policies/base.py']",4,86eb133d7d784c65e620a581889ef2c07b8662c8,bp/policy-in-code,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_policy import policy IDENTITY_API = 'identity:%s' RULE_ADMIN_REQUIRED = 'rule:admin_required' RULE_ADMIN_OR_OWNER = 'rule:admin_or_owner' rules = [ policy.RuleDefault( name='admin_required', check_str='role:admin or is_admin:1' ), policy.RuleDefault( name='service_role', check_str='role:service' ), policy.RuleDefault( name='service_or_admin', check_str='rule:admin_required or rule:service_role' ), policy.RuleDefault( name='owner', check_str='user_id:%(user_id)s' ), policy.RuleDefault( name='admin_or_owner', check_str='rule:admin_required or rule:owner' ), policy.RuleDefault( name='token_subject', check_str='user_id:%(target.token.user_id)s' ), policy.RuleDefault( name='admin_or_token_subject', check_str='rule:admin_required or rule:token_subject' ), policy.RuleDefault( name='service_admin_or_token_subject', check_str='rule:service_or_admin or rule:token_subject' ), policy.RuleDefault( name='default', check_str='rule:admin_required' ) ] def list_rules(): return rules ",,90,11
openstack%2Fpuppet-openstack-integration~master~Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9,openstack/puppet-openstack-integration,master,Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9,add vitrage,MERGED,2017-02-06 13:39:28.000000000,2017-02-17 21:45:07.000000000,2017-02-17 21:45:07.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 15519}, {'_account_id': 19134}]","[{'number': 1, 'created': '2017-02-06 13:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/2cd589afaaa9264def384910553d9be13a260ae6', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 2, 'created': '2017-02-06 13:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/6745cef97acd1b07ef177de9d4ad8a152bb09cb0', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 3, 'created': '2017-02-06 14:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/0b2f83cf4f160d6c8930e009221a4a6b46fc3dd4', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 4, 'created': '2017-02-06 15:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/b29a38e596699538b9e280fde62bbabf69191f5a', 'message': 'add vitrage\n\nDepends-On: I74e5b427c6813ee55a69b3092e9627b58bda5945\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 5, 'created': '2017-02-08 07:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/3ca6e26e18d9e1a5bf942cb32a44fbb2f26525a5', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 6, 'created': '2017-02-08 09:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c4f771129dabce7cbcbf86fd5ea0fb18d8df5956', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 7, 'created': '2017-02-08 09:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/64ffd5967b3913f134b1728f0f74ed24534aa3b2', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 8, 'created': '2017-02-08 17:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/05f8116222ca607bea78a21dad9fd8d3336be72f', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 9, 'created': '2017-02-08 17:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/cbb842150b0e68532e173b514cbb1d98ff0cd2f5', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 10, 'created': '2017-02-09 07:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/49c2eafcfe2dc948539be24054a1bac6112b8e19', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 11, 'created': '2017-02-09 09:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/a4b58cbb0b48a306ffd505ba804d2b6aea4ecdf9', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 12, 'created': '2017-02-09 09:29:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/cf9b0584755d3b62bdcd72f3af0208e16283c216', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 13, 'created': '2017-02-09 09:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/c0a0fc37b0d4dba1f1b7197d7b65b8a95f6db12e', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 14, 'created': '2017-02-09 09:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/50e5028ee4574434bc33c50b316088178b354ace', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 15, 'created': '2017-02-09 10:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/44349b56e019911ad765fc2389dc20d94c1c9552', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 16, 'created': '2017-02-09 11:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/7ac453a7ed37b2d7579ba9c64dba880434180385', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 17, 'created': '2017-02-09 11:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/44556f69ec82e27eb5b5d6ec21312f46e9856168', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 18, 'created': '2017-02-09 12:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/179b69127fa6cffd3abcd4116f7a2dfa0b387caa', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 19, 'created': '2017-02-09 15:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/4d0a45a64fb8e74a28ad37fec1b1be2232d42b0d', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 20, 'created': '2017-02-13 14:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/376c7a840f789951917cf795835ec8a9322276d7', 'message': 'add vitrage\n\nDepends-On: I4743bfe1fa0e6ab1763985239b2de273e4aeb4c0\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 21, 'created': '2017-02-14 08:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/2db80122f22824bfc0cf49b58e7840fa82f5cc16', 'message': 'add vitrage\n\nDepends-On: I4743bfe1fa0e6ab1763985239b2de273e4aeb4c0\nDepends-On: I73f8ccf2e190de17e0d53b809f7f9783c470452d\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}, {'number': 22, 'created': '2017-02-14 14:55:46.000000000', 'files': ['run_tests.sh', 'openstack_modules.txt', 'Puppetfile', 'fixtures/scenario001.pp', 'manifests/tempest.pp', 'manifests/vitrage.pp', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/94fad23968c3c16a60d17110454e5d14a0e19459', 'message': 'add vitrage\n\nChange-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9\n'}]",9,429705,94fad23968c3c16a60d17110454e5d14a0e19459,59,5,22,19134,,,0,"add vitrage

Change-Id: Ibdb1e687ec348fa4147a9ca970b4f0f1c355ade9
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/05/429705/6 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_modules.txt', 'fixtures/scenario001.pp', 'manifests/tempest.pp', 'manifests/vitrage.pp', 'README.md']",5,2cd589afaaa9264def384910553d9be13a260ae6,eyalb/vitrage,| vitrage | | X | | | |,,80,0
openstack%2Ftempest~master~I9c9e25255e9d84639122156a618f266b91818743,openstack/tempest,master,I9c9e25255e9d84639122156a618f266b91818743,Change instance variable to local variable in scenario/image/volume,MERGED,2017-02-17 01:46:59.000000000,2017-02-17 21:31:08.000000000,2017-02-17 21:31:08.000000000,"[{'_account_id': 3}, {'_account_id': 6167}, {'_account_id': 7350}]","[{'number': 1, 'created': '2017-02-17 01:46:59.000000000', 'files': ['tempest/scenario/test_aggregates_basic_ops.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/api/image/v1/test_images.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/7a8f29dffea6c203e3c31f28fc06161a5de3d4f1', 'message': 'Change instance variable to local variable in scenario/image/volume\n\nThere are still some unnecessary instance variables, and this is to\nchange them to local variables.\n\nChange-Id: I9c9e25255e9d84639122156a618f266b91818743\n'}]",0,435194,7a8f29dffea6c203e3c31f28fc06161a5de3d4f1,12,3,1,20190,,,0,"Change instance variable to local variable in scenario/image/volume

There are still some unnecessary instance variables, and this is to
change them to local variables.

Change-Id: I9c9e25255e9d84639122156a618f266b91818743
",git fetch https://review.opendev.org/openstack/tempest refs/changes/94/435194/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_aggregates_basic_ops.py', 'tempest/api/volume/test_volumes_extend.py', 'tempest/scenario/test_network_basic_ops.py', 'tempest/api/image/v1/test_images.py']",4,7a8f29dffea6c203e3c31f28fc06161a5de3d4f1,instance_var_scenario," container_format_alt) = CONF.image.container_formats[:2] if container_format_alt in a_formats: cls.disk_format_alt = container_format_alt img2 = cls._create_remote_image('two', container_format_alt, img5 = cls._create_standard_image('1', container_format_alt, img6 = cls._create_standard_image('2', container_format_alt,"," cls.container_format_alt) = CONF.image.container_formats[:2] if cls.container_format_alt in a_formats: cls.disk_format_alt = cls.container_format_alt img2 = cls._create_remote_image('two', cls.container_format_alt, img5 = cls._create_standard_image('1', cls.container_format_alt, img6 = cls._create_standard_image('2', cls.container_format_alt,",17,18
openstack%2Ftripleo-quickstart-extras~master~I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7,openstack/tripleo-quickstart-extras,master,I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7,Add scenario support to overcloud-deploy and config for 001,MERGED,2017-01-24 20:03:56.000000000,2017-02-17 21:29:32.000000000,2017-02-17 21:29:32.000000000,"[{'_account_id': 3}, {'_account_id': 6721}, {'_account_id': 8652}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 18846}, {'_account_id': 24752}]","[{'number': 1, 'created': '2017-01-24 20:03:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e66bf8b20728bc4b23a97f480a9665d405a773ea', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 2, 'created': '2017-01-24 21:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8c053bd28c46432b71e47d67d35716e9e516bfce', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 3, 'created': '2017-01-25 23:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/838832f252f226807e0f8db0474be353ab6f14f6', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 4, 'created': '2017-01-27 14:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d51ff39d1b021d605644875defcbbf0b992d860e', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 5, 'created': '2017-01-27 17:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/98145dc1da8ac51e47c5d99fe64ea003d5c9224e', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 6, 'created': '2017-01-27 19:13:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5cd66d1f4e8a8a0961c4276f09ffb0523a9a93a9', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 7, 'created': '2017-01-27 20:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/624ec54304e486ba7b90bb3275a7da1e0af11b3f', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 8, 'created': '2017-01-27 20:05:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8f9d972f8efc24763d606a8e926d86bed09ca68c', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 9, 'created': '2017-01-27 21:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c07858990b9c561c1ee775ea0949e443123d9571', 'message': '[WIP] composable scenario tests\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 10, 'created': '2017-01-31 17:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7ea341d1082da28b963c36536c2fc1b7f869a285', 'message': 'composable scenario001\n\nThis implements scenario0001\nhttps://github.com/openstack/tripleo-heat-templates/blob/master/ci/environments/scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 11, 'created': '2017-02-01 02:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c3342d9874f681c4da5a6b00fc9393019f773b9e', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 12, 'created': '2017-02-08 13:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f924a4fdc74ec7bfbb17815f8dca59af6c2fd142', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 13, 'created': '2017-02-08 19:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2a40c6a78d1b5ac9438ede54314af3ab063248dd', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 14, 'created': '2017-02-08 21:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/50ea7845cb0c1fc3230d0926fff499ccbb0e8afc', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 15, 'created': '2017-02-09 00:54:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/1810b6ed57070d5dacfc5625d94106a3fbd57a49', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 16, 'created': '2017-02-09 05:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/36d6df8268b5bde828f8afced822162cf2924237', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 17, 'created': '2017-02-09 06:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/45171c08c127647662e07a73826fe5f9249c3410', 'message': 'composable scenario001-multinode.yaml\n\nThis implements scenario001-multinode.yaml\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 18, 'created': '2017-02-09 22:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/eb43913549500c01c4ccdf0578e08e3a9e1b2282', 'message': 'Add scenario support to overcloud-deploy and config for 001\n\nThis change implements optional scenario support in the\novercloud-deploy role and adds a single scenario:\nscenario001-multinode. Other scenarios will follow in\nsubsequent reviews.\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}, {'number': 19, 'created': '2017-02-09 22:05:16.000000000', 'files': ['config/general_config/scenario001-multinode.yml', 'roles/overcloud-deploy/tasks/pre-deploy.yml', 'roles/overcloud-deploy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/b0cf63a79a8ae6179524df445f1bf66e2615625a', 'message': 'Add scenario support to overcloud-deploy and config for 001\n\nThis change implements optional scenario support in the\novercloud-deploy role and adds a single scenario:\nscenario001-multinode. Other scenarios will follow in\nsubsequent reviews.\n\nChange-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7\n'}]",4,424827,b0cf63a79a8ae6179524df445f1bf66e2615625a,99,9,19,9592,,,0,"Add scenario support to overcloud-deploy and config for 001

This change implements optional scenario support in the
overcloud-deploy role and adds a single scenario:
scenario001-multinode. Other scenarios will follow in
subsequent reviews.

Change-Id: I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/27/424827/12 && git format-patch -1 --stdout FETCH_HEAD,"['config/general_config/scenario0001.yml', 'roles/overcloud-prep-config/tasks/main.yml']",2,e66bf8b20728bc4b23a97f480a9665d405a773ea,I51df15a5534f4b9cb9e3d4a6c18ed3a5ae0d91d7,"- when: deploy_composable_scenario is defined and deploy_composable_scenario|bool block: - name: get the scenario template from tripleo-ci shell: | wget ""{{ scenario_template_source }}/{{ composable_scenario }}"" ",,71,0
openstack%2Fgnocchi~master~I088d9f7b5079523f0ec5eb1a1282f0c145131f9e,openstack/gnocchi,master,I088d9f7b5079523f0ec5eb1a1282f0c145131f9e,s3: set maximum length for s3_bucket_prefix option,MERGED,2017-02-07 17:25:11.000000000,2017-02-17 21:28:21.000000000,2017-02-16 14:22:52.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-07 17:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/ab84c6a9359a7a0843933b42da32d1e47ab5e660', 'message': 's3: set maximum length for s3_bucket_prefix option\n\nChange-Id: I088d9f7b5079523f0ec5eb1a1282f0c145131f9e\n'}, {'number': 2, 'created': '2017-02-16 07:56:49.000000000', 'files': ['requirements.txt', 'gnocchi/storage/s3.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/1dc358235670794119d7bf9362012445e152ce66', 'message': 's3: set maximum length for s3_bucket_prefix option\n\nChange-Id: I088d9f7b5079523f0ec5eb1a1282f0c145131f9e\n'}]",0,430377,1dc358235670794119d7bf9362012445e152ce66,13,3,2,1669,,,0,"s3: set maximum length for s3_bucket_prefix option

Change-Id: I088d9f7b5079523f0ec5eb1a1282f0c145131f9e
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/77/430377/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/s3.py'],1,ab84c6a9359a7a0843933b42da32d1e47ab5e660,jd/fix-s3," # Max bucket length is 63 and we use ""-"" as separator # 63 - 1 - len(uuid) = 26 max_length=26,",,3,0
openstack%2Fgnocchi~master~I1c99878eef37fa59d7a806d0e8c838fd85214d3f,openstack/gnocchi,master,I1c99878eef37fa59d7a806d0e8c838fd85214d3f,s3: use a different bucket prefix for each test,MERGED,2017-02-07 17:25:11.000000000,2017-02-17 21:28:13.000000000,2017-02-16 00:17:23.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-07 17:25:11.000000000', 'files': ['gnocchi/tests/base.py', 'gnocchi/tests/test_storage.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/17ed44ba4541defb4b580fbf261f97169ede0773', 'message': 's3: use a different bucket prefix for each test\n\nThat allows to run more tests!\n\nChange-Id: I1c99878eef37fa59d7a806d0e8c838fd85214d3f\n'}]",0,430376,17ed44ba4541defb4b580fbf261f97169ede0773,8,3,1,1669,,,0,"s3: use a different bucket prefix for each test

That allows to run more tests!

Change-Id: I1c99878eef37fa59d7a806d0e8c838fd85214d3f
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/76/430376/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/base.py', 'gnocchi/tests/test_storage.py']",2,17ed44ba4541defb4b580fbf261f97169ede0773,jd/fix-s3,," if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."") if self.conf.storage.driver == ""s3"": self.skipTest( ""This test does not work with S3 as backend as the S3 driver "" ""has no fake client, and tests run in parallel."")",5,16
openstack%2Fgnocchi~master~Idbd0de3452828d0b19946c09b31c27656a1d959b,openstack/gnocchi,master,Idbd0de3452828d0b19946c09b31c27656a1d959b,s3: fix new metric listing,MERGED,2017-02-07 14:59:39.000000000,2017-02-17 21:27:56.000000000,2017-02-16 00:13:52.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-07 14:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d08c2b9cf70dd0b8528de7fdd9cbc742bc652d73', 'message': ""s3: fix new metric listing\n\nIt's impossible to index a set\n\nChange-Id: Idbd0de3452828d0b19946c09b31c27656a1d959b\n""}, {'number': 2, 'created': '2017-02-07 17:25:11.000000000', 'files': ['gnocchi/storage/incoming/s3.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e8139066612e2958e29c75befcbdf2583ca273cb', 'message': ""s3: fix new metric listing\n\nIt's impossible to index a set\n\nChange-Id: Idbd0de3452828d0b19946c09b31c27656a1d959b\n""}]",0,430285,e8139066612e2958e29c75befcbdf2583ca273cb,11,3,2,1669,,,0,"s3: fix new metric listing

It's impossible to index a set

Change-Id: Idbd0de3452828d0b19946c09b31c27656a1d959b
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/85/430285/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/incoming/s3.py'],1,d08c2b9cf70dd0b8528de7fdd9cbc742bc652d73,jd/fix-s3, return sorted(list(metrics))[size * part:], return metrics[size * part:],1,1
openstack%2Fgnocchi~master~Ie5e4760c630d9906b57eda48dbd42165108c96e7,openstack/gnocchi,master,Ie5e4760c630d9906b57eda48dbd42165108c96e7,s3: fix minimum botocore version,MERGED,2017-02-07 14:59:39.000000000,2017-02-17 21:27:46.000000000,2017-02-16 00:12:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2017-02-07 14:59:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/30e7cc8181028d2b837026e148f4ad23da9b6fd8', 'message': 's3: fix minimum botocore version\n\nBotocore is mainly used as a dependency of boto3, but Gnocchi actually requires\nversion 1.5 minimum to have list_objects_v2 available.\n\nChange-Id: Ie5e4760c630d9906b57eda48dbd42165108c96e7\n'}, {'number': 2, 'created': '2017-02-07 17:25:11.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6f09a699535a1b53b021a8d8f70ca55bfe5222de', 'message': 's3: fix minimum botocore version\n\nBotocore is mainly used as a dependency of boto3, but Gnocchi actually requires\nversion 1.5 minimum to have list_objects_v2 available.\n\nChange-Id: Ie5e4760c630d9906b57eda48dbd42165108c96e7\n'}]",0,430286,6f09a699535a1b53b021a8d8f70ca55bfe5222de,11,4,2,1669,,,0,"s3: fix minimum botocore version

Botocore is mainly used as a dependency of boto3, but Gnocchi actually requires
version 1.5 minimum to have list_objects_v2 available.

Change-Id: Ie5e4760c630d9906b57eda48dbd42165108c96e7
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/86/430286/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,30e7cc8181028d2b837026e148f4ad23da9b6fd8,jd/fix-s3, botocore>=1.5,,1,0
openstack%2Fgnocchi~stable%2F3.0~I938c7263824bae0a01634fa48fa784a91ae49499,openstack/gnocchi,stable/3.0,I938c7263824bae0a01634fa48fa784a91ae49499,indexer: fix resource type update,MERGED,2017-02-09 13:53:18.000000000,2017-02-17 21:22:47.000000000,2017-02-17 21:22:47.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2017-02-09 13:53:18.000000000', 'files': ['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e34779ad1978a66513dd60242f5dd38dc157dde5', 'message': 'indexer: fix resource type update\n\nCurrently when we update a resource type the history table is broken\nbecause a column is missing.\n\nThis change fixes that.\n\nCloses-bug: #1649261\nChange-Id: I938c7263824bae0a01634fa48fa784a91ae49499\n(cherry picked from commit 178a34916231d0bde14a914d216ec7fb0b25c818)\n'}]",0,431546,e34779ad1978a66513dd60242f5dd38dc157dde5,6,3,1,6537,,,0,"indexer: fix resource type update

Currently when we update a resource type the history table is broken
because a column is missing.

This change fixes that.

Closes-bug: #1649261
Change-Id: I938c7263824bae0a01634fa48fa784a91ae49499
(cherry picked from commit 178a34916231d0bde14a914d216ec7fb0b25c818)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/46/431546/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_indexer.py', 'gnocchi/indexer/sqlalchemy.py']",2,e34779ad1978a66513dd60242f5dd38dc157dde5,sileht/measures-driver," add_attributes = add_attributes or [] del_attributes = del_attributes or [] for table in [rt.tablename, '%s_history' % rt.tablename]: with op.batch_alter_table(table) as batch_op: for attr in del_attributes: batch_op.drop_column(attr) for attr in add_attributes: # TODO(sileht): When attr.required is True, we # have to pass a default. rest layer current # protect us, requied = True is not yet allowed batch_op.add_column(sqlalchemy.Column( attr.name, attr.satype, nullable=not attr.required))"," with op.batch_alter_table(rt.tablename) as batch_op: for attr in del_attributes: batch_op.drop_column(attr) for attr in add_attributes: # TODO(sileht): When attr.required is True, we have # to pass a default. rest layer current protect us, # requied = True is not yet allowed batch_op.add_column(sqlalchemy.Column( attr.name, attr.satype, nullable=not attr.required))",37,10
openstack%2Fgnocchi~stable%2F3.1~I84a78139ca6e5e049f70fd9c84033e60bc13e035,openstack/gnocchi,stable/3.1,I84a78139ca6e5e049f70fd9c84033e60bc13e035,fix bad slash migration,MERGED,2017-02-14 01:51:34.000000000,2017-02-17 21:22:41.000000000,2017-02-17 21:22:41.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2017-02-14 01:51:34.000000000', 'files': ['gnocchi/indexer/alembic/versions/397987e38570_no_more_slash_and_reencode.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/840888be19b4c674550a98f6ca3e141c40861ac7', 'message': ""fix bad slash migration\n\nwe're incorrectly looking at the column when debating whether to\nreencode a resource.\n\nCloses-Bug: #1662990\nChange-Id: I84a78139ca6e5e049f70fd9c84033e60bc13e035\n(cherry picked from commit f186f89a4b0c5b4e06c1bc07983e93f1f8ce5f15)\n""}]",0,433388,840888be19b4c674550a98f6ca3e141c40861ac7,7,3,1,6537,,,0,"fix bad slash migration

we're incorrectly looking at the column when debating whether to
reencode a resource.

Closes-Bug: #1662990
Change-Id: I84a78139ca6e5e049f70fd9c84033e60bc13e035
(cherry picked from commit f186f89a4b0c5b4e06c1bc07983e93f1f8ce5f15)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/88/433388/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/alembic/versions/397987e38570_no_more_slash_and_reencode.py'],1,840888be19b4c674550a98f6ca3e141c40861ac7,bug/1662990, if resource.original_resource_id is None: orig_as_uuid = uuid.UUID(str(resource.original_resource_id)) if orig_as_uuid == resource.id:, if resource_table.c.original_resource_id is None: orig_as_uuid = uuid.UUID( str(resource_table.c.original_resource_id)) if orig_as_uuid == resource_table.c.id:,3,4
openstack%2Fapp-catalog~master~I22ab0323458c22bdc6a79a5164bac42ccd0f4978,openstack/app-catalog,master,I22ab0323458c22bdc6a79a5164bac42ccd0f4978,Add EnterpriseDB application and Centos 7 image for ppc64le,MERGED,2017-02-17 10:42:33.000000000,2017-02-17 21:21:44.000000000,2017-02-17 21:21:44.000000000,"[{'_account_id': 3}, {'_account_id': 5545}, {'_account_id': 9788}]","[{'number': 1, 'created': '2017-02-17 10:42:33.000000000', 'files': ['openstack_catalog/web/static/assets.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/56fc380d8e92ad556ce87341748e9694665c0e7b', 'message': 'Add EnterpriseDB application and Centos 7 image for ppc64le\n\nEnterpriseDB application for ppc64le\npackage-name: io.murano.databases.EDBPPC64LE.zip\npackage-hash: dfacb76b893228a568058eb7da195a76\npackage-url: https://drive.google.com/file/d/0B0deXevtrE_aV0w0cmFNREotblU/view?usp=sharing\n\nCentos 7 ppc64le image with pre-installed murano-agent\nimage-name: centos-7-ppc64le-m-agent.qcow2\nimage-hash: af16644e47de1793a4d3e2f68913a648\nimage-url: https://drive.google.com/file/d/0Bxft_1Z5VLHwNFhmOTB6aEg5d2M/view?usp=sharing\n\nChange-Id: I22ab0323458c22bdc6a79a5164bac42ccd0f4978\n'}]",0,435358,56fc380d8e92ad556ce87341748e9694665c0e7b,7,3,1,10374,,,0,"Add EnterpriseDB application and Centos 7 image for ppc64le

EnterpriseDB application for ppc64le
package-name: io.murano.databases.EDBPPC64LE.zip
package-hash: dfacb76b893228a568058eb7da195a76
package-url: https://drive.google.com/file/d/0B0deXevtrE_aV0w0cmFNREotblU/view?usp=sharing

Centos 7 ppc64le image with pre-installed murano-agent
image-name: centos-7-ppc64le-m-agent.qcow2
image-hash: af16644e47de1793a4d3e2f68913a648
image-url: https://drive.google.com/file/d/0Bxft_1Z5VLHwNFhmOTB6aEg5d2M/view?usp=sharing

Change-Id: I22ab0323458c22bdc6a79a5164bac42ccd0f4978
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/58/435358/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/assets.yaml'],1,56fc380d8e92ad556ce87341748e9694665c0e7b,ppc64le-edb," description: Ubuntu 16.04 ppc64le with murano-agent pre-installed name: Centos 7 ppc64le (pre-installed murano-agent) provided_by: name: Andrii Bubyr href: mailto:abubyr@mirantis.com company: Mirantis, Inc. description: Centos 7 ppc64le with murano-agent pre-installed service: type: glance disk_format: qcow2 container_format: bare license: Multi-licensed OpenSource hash: af16644e47de1793a4d3e2f68913a648 attributes: url: http://storage.apps.openstack.org/images/centos-7-ppc64le-m-agent.qcow2 - name: EDB Postgres Advanced Server ppc64le tags: ['app'] provided_by: name: Alexander Bochkarev href: ""mailto:abochkarev@mirantis.com"" company: Mirantis, Inc. description: > EDB Postgres Advanced Server is EDB’s enhanced Postgres database designed to meet the needs of the digital enterprise. EDB Advanced Server incorporates all of PostgreSQL’s features with additional enterprise-class functionality for enhanced performance and security requirements for enterprise workloads. service: type: murano format: package package_name: io.murano.databases.EDBPPC64LE release: - Mitaka license: Multi-licensed OpenSource depends: - name: Centos 7 ppc64le (pre-installed murano-agent) hash: dfacb76b893228a568058eb7da195a76 attributes: ""Package URL"": ""http://storage.apps.openstack.org/apps/io.murano.databases.EDBPPC64LE.zip"" -", description: > Ubuntu 16.04 ppc64le with murano-agent pre-installed used by Murano applications that does not rely on pre-installed software in the image and instead provision applications using murano-agent.,41,5
openstack%2Fzun~master~I342f4f86337cdc08668cf089e6a6ed90e12b00ff,openstack/zun,master,I342f4f86337cdc08668cf089e6a6ed90e12b00ff,changed the spelling,MERGED,2017-02-17 09:36:17.000000000,2017-02-17 21:17:51.000000000,2017-02-17 21:17:51.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 15917}, {'_account_id': 16277}, {'_account_id': 17645}, {'_account_id': 17845}, {'_account_id': 24924}]","[{'number': 1, 'created': '2017-02-17 09:36:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zun/commit/d76258316b0c269ac7a080a2b6288068a172aa6f', 'message': 'changed the spelling\n\nChange-Id: I342f4f86337cdc08668cf089e6a6ed90e12b00ff\n'}, {'number': 2, 'created': '2017-02-17 10:11:55.000000000', 'files': ['zun/tests/tempest/README.rst', 'specs/cinder-integration.rst', 'specs/container-sandbox.rst'], 'web_link': 'https://opendev.org/openstack/zun/commit/24a5dd928248bcaeeb2fd2652dceed5998a193bd', 'message': 'changed the spelling\n\nChange-Id: I342f4f86337cdc08668cf089e6a6ed90e12b00ff\n'}]",1,435329,24a5dd928248bcaeeb2fd2652dceed5998a193bd,13,7,2,24925,,,0,"changed the spelling

Change-Id: I342f4f86337cdc08668cf089e6a6ed90e12b00ff
",git fetch https://review.opendev.org/openstack/zun refs/changes/29/435329/2 && git format-patch -1 --stdout FETCH_HEAD,['zun/tests/tempest/README.rst'],1,d76258316b0c269ac7a080a2b6288068a172aa6f,spelling,Zun Tempest testing setup,Zun Tempest testing sutup,1,1
openstack%2Fgnocchi~stable%2F3.1~Id516c5b1d091ca01688d6ad8cf1076a998d15333,openstack/gnocchi,stable/3.1,Id516c5b1d091ca01688d6ad8cf1076a998d15333,ensure original_resource_id is not none,MERGED,2017-02-14 04:03:11.000000000,2017-02-17 21:15:26.000000000,2017-02-17 21:15:26.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2017-02-14 04:03:11.000000000', 'files': ['gnocchi/indexer/alembic/versions/1e1a63d3d186_original_resource_id_not_null.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/04ef146e1961448a1f0ad13075f6bc7fb0e19477', 'message': ""ensure original_resource_id is not none\n\nstatsd resource doesn't have an original_resource_id so we need to\nset it by copying over id during upgrade\n\nChange-Id: Id516c5b1d091ca01688d6ad8cf1076a998d15333\nCloses-Bug: #1662849\n(cherry picked from commit 9b53bce0c5fb86fc8db3055d861d7b1f2715a00c)\n""}]",0,433431,04ef146e1961448a1f0ad13075f6bc7fb0e19477,7,3,1,6537,,,0,"ensure original_resource_id is not none

statsd resource doesn't have an original_resource_id so we need to
set it by copying over id during upgrade

Change-Id: Id516c5b1d091ca01688d6ad8cf1076a998d15333
Closes-Bug: #1662849
(cherry picked from commit 9b53bce0c5fb86fc8db3055d861d7b1f2715a00c)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/31/433431/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/alembic/versions/1e1a63d3d186_original_resource_id_not_null.py'],1,04ef146e1961448a1f0ad13075f6bc7fb0e19477,bug/1662849,"from sqlalchemy import func import sqlalchemy_utilsdef clean_substr(col, start, length): return func.lower(func.substr(func.hex(col), start, length)) def upgrade(): bind = op.get_bind() for table_name in ('resource', 'resource_history'): table = sa.Table(table_name, sa.MetaData(), sa.Column('id', sqlalchemy_utils.types.uuid.UUIDType(), nullable=False), sa.Column('original_resource_id', sa.String(255))) # NOTE(gordc): mysql stores id as binary so we need to rebuild back to # string uuid. if bind and bind.engine.name == ""mysql"": vals = {'original_resource_id': clean_substr(table.c.id, 1, 8) + '-' + clean_substr(table.c.id, 9, 4) + '-' + clean_substr(table.c.id, 13, 4) + '-' + clean_substr(table.c.id, 17, 4) + '-' + clean_substr(table.c.id, 21, 12)} else: vals = {'original_resource_id': table.c.id} op.execute(table.update().where( table.c.original_resource_id.is_(None)).values(vals))","def upgrade(): for table_name in ('resource', 'resource_history'):",27,0
openstack%2Fkeystone~master~I35d890011107fe1414032ddc4b357066e0092ecd,openstack/keystone,master,I35d890011107fe1414032ddc4b357066e0092ecd,Fix example response formatting,MERGED,2017-02-17 16:30:49.000000000,2017-02-17 21:00:46.000000000,2017-02-17 21:00:46.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 7665}, {'_account_id': 7725}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-02-17 16:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/85648be403f17ac73c72d4d828b71e115f2c6a7e', 'message': 'Fix example response formatting\n\nSeveral example responses are not formatted\nmaking them hard to read.\n\nThis patch formats them.\n\nChange-Id: I35d890011107fe1414032ddc4b357066e0092ecd\nCloses-Bug: #1665706\n'}, {'number': 2, 'created': '2017-02-17 17:06:27.000000000', 'files': ['doc/source/devref/api_curl_examples.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f51b7ca7d175d9b1ff1063591c2b90a4d020511f', 'message': 'Fix example response formatting\n\nSeveral example responses are not formatted\nmaking them hard to read.\n\nThis patch formats them.\n\nChange-Id: I35d890011107fe1414032ddc4b357066e0092ecd\nCloses-Bug: #1665706\n'}]",8,435518,f51b7ca7d175d9b1ff1063591c2b90a4d020511f,13,5,2,7665,,,0,"Fix example response formatting

Several example responses are not formatted
making them hard to read.

This patch formats them.

Change-Id: I35d890011107fe1414032ddc4b357066e0092ecd
Closes-Bug: #1665706
",git fetch https://review.opendev.org/openstack/keystone refs/changes/18/435518/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/api_curl_examples.rst'],1,85648be403f17ac73c72d4d828b71e115f2c6a7e,bug/1665706,"Example response (formatted): .. code-block:: javascript { ""token"": { ""methods"": [""password""], ""roles"": [{ ""id"": ""9fe2ff9ee4384b1894a90878d3e92bab"", ""name"": ""_member_"" }, { ""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin"" }], ""expires_at"": ""2014-06-10T2:55:16.806001Z"", ""project"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""8538a3f13f9541b28c2620eb19065e45"", ""name"": ""admin"" }, ""catalog"": [{ ""endpoints"": [{ ""url"": ""http://localhost:3537/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""8707e3735d4415c97ae231b4841eb1c"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5"" }], ""type"": ""identity"", ""id"": ""bd73972c0e14fb69bae8ff76e112a90"", ""name"": ""keystone"" }], ""extras"": {}, ""user"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin"" }, ""audit_ids"": [""yRt0UrxJSs6-WYJgwEMMmg""], ""issued_at"": ""201406-10T20:55:16.806027Z"" } }Example response (formatted): .. code-block:: javascript { ""token"": { ""audit_ids"": [""ECwrVNWbSCqmEgPnu0YCRw""], ""methods"": [""password""], ""roles"": [{ ""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin"" }], ""expires_at"": ""2014-06-10T21:40:14.360795Z"", ""project"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""3d4c2c82bd5948f0bcab0cf3a7c9b48c"", ""name"": ""demo"" }, ""catalog"": [{ ""endpoints"": [{ ""url"": ""http://localhost:35357/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""87057e3735d4415c97ae231b4841eb1c"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5"" }], ""type"": ""identity"", ""id"": ""bd7397d2c0e14fb69bae8ff76e112a90"", ""name"": ""keystone"" }], ""extras"": {}, ""user"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin"" }, ""issued_at"": ""2014-06-10T20:40:14.360822Z"" } }Example response (formatted): .. code-block:: javascript { ""token"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""methods"": [""password""], ""roles"": [{ ""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin"" }], ""expires_at"": ""2014-06-10T21:52:58.852167Z"", ""catalog"": [{ ""endpoints"": [{ ""url"": ""http://localhost:35357/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""87057e3735d4415c97ae231b4841eb1c"" }, { ""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5"" }], ""type"": ""identity"", ""id"": ""bd7397d2c0e14fb69bae8ff76e112a90"", ""name"": ""keystone"" }], ""extras"": {}, ""user"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin"" }, ""audit_ids"": [""Xpa6Uyn-T9S6mTREudUH3w""], ""issued_at"": ""2014-06-10T20:52:58.852194Z"" } }Example response (formatted): .. code-block:: javascript { ""token"": { ""methods"": [""token"", ""password""], ""expires_at"": ""2015-05-28T07:43:44.808209Z"", ""extras"": {}, ""user"": { ""domain"": { ""id"": ""default"", ""name"": ""Default"" }, ""id"": ""753867c25c3340ffad1abc22d488c31a"", ""name"": ""admin"" }, ""audit_ids"": [""ZE0OPSuzTmCXHo0eIOYltw"", ""xxIQCkHOQOywL0oY6CTppQ"" ], ""issued_at"": ""2015-05-28T07:19:23.763532Z"" } }","Example response:: {""token"": {""methods"": [""password""], ""roles"": [{""id"": ""9fe2ff9ee4384b1894a90878d3e92bab"", ""name"": ""_member_""}, {""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin""}], ""expires_at"": ""2014-06-10T2:55:16.806001Z"", ""project"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""8538a3f13f9541b28c2620eb19065e45"", ""name"": ""admin""}, ""catalog"": [{""endpoints"": [{""url"": ""http://localhost:3537/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""8707e3735d4415c97ae231b4841eb1c""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5""}], ""type"": ""identity"", ""id"": ""bd73972c0e14fb69bae8ff76e112a90"", ""name"": ""keystone""}], ""extras"": {}, ""user"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin""}, ""audit_ids"": [""yRt0UrxJSs6-WYJgwEMMmg""], ""issued_at"": ""201406-10T20:55:16.806027Z""}}Example response:: {""token"": {""audit_ids"": [""ECwrVNWbSCqmEgPnu0YCRw""], ""methods"": [""password""], ""roles"": [{""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin""}], ""expires_at"": ""2014-06-10T21:40:14.360795Z"", ""project"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""3d4c2c82bd5948f0bcab0cf3a7c9b48c"", ""name"": ""demo""}, ""catalog"": [{""endpoints"": [{""url"": ""http://localhost:35357/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""87057e3735d4415c97ae231b4841eb1c""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5""}], ""type"": ""identity"", ""id"": ""bd7397d2c0e14fb69bae8ff76e112a90"", ""name"": ""keystone""}], ""extras"": {}, ""user"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin""}, ""issued_at"": ""2014-06-10T20:40:14.360822Z""}}Example response:: {""token"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""methods"": [""password""], ""roles"": [{""id"": ""c703057be878458588961ce9a0ce686b"", ""name"": ""admin""}], ""expires_at"": ""2014-06-10T21:52:58.852167Z"", ""catalog"": [{""endpoints"": [{""url"": ""http://localhost:35357/v2.0"", ""region"": ""RegionOne"", ""interface"": ""admin"", ""id"": ""29beb2f1567642eb810b042b6719ea88""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""internal"", ""id"": ""87057e3735d4415c97ae231b4841eb1c""}, {""url"": ""http://localhost:5000/v2.0"", ""region"": ""RegionOne"", ""interface"": ""public"", ""id"": ""ef303187fc8d41668f25199c298396a5""}], ""type"": ""identity"", ""id"": ""bd7397d2c0e14fb69bae8ff76e112a90"", ""name"": ""keystone""}], ""extras"": {}, ""user"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""3ec3164f750146be97f21559ee4d9c51"", ""name"": ""admin""}, ""audit_ids"": [""Xpa6Uyn-T9S6mTREudUH3w""], ""issued_at"": ""2014-06-10T20:52:58.852194Z""}}Example response:: {""token"": {""methods"": [""token"", ""password""], ""expires_at"": ""2015-05-28T07:43:44.808209Z"", ""extras"": {}, ""user"": {""domain"": {""id"": ""default"", ""name"": ""Default""}, ""id"": ""753867c25c3340ffad1abc22d488c31a"", ""name"": ""admin""}, ""audit_ids"": [""ZE0OPSuzTmCXHo0eIOYltw"", ""xxIQCkHOQOywL0oY6CTppQ""], ""issued_at"": ""2015-05-28T07:19:23.763532Z""}}",180,53
openstack%2Fdevstack~master~Ibb0dcb8bae2e9223db302d7b19e8fbee4ebbf0e3,openstack/devstack,master,Ibb0dcb8bae2e9223db302d7b19e8fbee4ebbf0e3,only set nova catalog if it's not the default,MERGED,2017-02-17 16:52:12.000000000,2017-02-17 20:59:26.000000000,2017-02-17 20:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 10118}, {'_account_id': 11904}]","[{'number': 1, 'created': '2017-02-17 16:52:12.000000000', 'files': ['lib/cinder'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0b259c3abdafa99e7194e62c9a47483ddcf6b65a', 'message': ""only set nova catalog if it's not the default\n\nThis ensures we only set the nova catalog when it's not the default,\ninstead of also putting defaults in devstack.\n\nChange-Id: Ibb0dcb8bae2e9223db302d7b19e8fbee4ebbf0e3\n""}]",0,435528,0b259c3abdafa99e7194e62c9a47483ddcf6b65a,11,5,1,2750,,,0,"only set nova catalog if it's not the default

This ensures we only set the nova catalog when it's not the default,
instead of also putting defaults in devstack.

Change-Id: Ibb0dcb8bae2e9223db302d7b19e8fbee4ebbf0e3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/28/435528/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder'],1,0b259c3abdafa99e7194e62c9a47483ddcf6b65a,cinder," # Change the default nova_catalog_info and nova_catalog_admin_info values in # cinder so that the service name cinder is searching for matches that set for # nova in keystone. if [[ -n ""$CINDER_NOVA_CATALOG_INFO"" ]]; then iniset $CINDER_CONF DEFAULT nova_catalog_info $CINDER_NOVA_CATALOG_INFO fi if [[ -n ""$CINDER_NOVA_CATALOG_ADMIN_INFO"" ]]; then iniset $CINDER_CONF DEFAULT nova_catalog_admin_info $CINDER_NOVA_CATALOG_ADMIN_INFO fi",# Change the default nova_catalog_info and nova_catalog_admin_info values in # cinder so that the service name cinder is searching for matches that set for # nova in keystone. CINDER_NOVA_CATALOG_INFO=${CINDER_NOVA_CATALOG_INFO:-compute:nova:publicURL} CINDER_NOVA_CATALOG_ADMIN_INFO=${CINDER_NOVA_CATALOG_ADMIN_INFO:-compute:nova:adminURL} iniset $CINDER_CONF DEFAULT nova_catalog_info $CINDER_NOVA_CATALOG_INFO iniset $CINDER_CONF DEFAULT nova_catalog_admin_info $CINDER_NOVA_CATALOG_ADMIN_INFO,9,8
openstack%2Fopenstack-ansible-security~stable%2Focata~I544cb4bffe7e41d0614ebea6a47c91e617647866,openstack/openstack-ansible-security,stable/ocata,I544cb4bffe7e41d0614ebea6a47c91e617647866,"Only enable ssh, not start",MERGED,2017-02-17 18:07:31.000000000,2017-02-17 20:43:57.000000000,2017-02-17 20:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 15993}]","[{'number': 1, 'created': '2017-02-17 18:07:31.000000000', 'files': ['tasks/rhel7stig/sshd.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/dcad9391b925e74ce2b9bad0a9b56dd62f220ddb', 'message': ""Only enable ssh, not start\n\nThere is an unusual issue occurring when the ssh daemon is asked to\nstart when it is already running. This patch ensures that the ssh\ndaemon is running but it doesn't try to start it. The handler will\ntake care of restarting sshd later on in the role.\n\nChange-Id: I544cb4bffe7e41d0614ebea6a47c91e617647866\n(cherry picked from commit 2e5fe3b038f46002ef38c0b21f1a49baac20bc6e)\n""}]",0,435557,dcad9391b925e74ce2b9bad0a9b56dd62f220ddb,7,3,1,538,,,0,"Only enable ssh, not start

There is an unusual issue occurring when the ssh daemon is asked to
start when it is already running. This patch ensures that the ssh
daemon is running but it doesn't try to start it. The handler will
take care of restarting sshd later on in the role.

Change-Id: I544cb4bffe7e41d0614ebea6a47c91e617647866
(cherry picked from commit 2e5fe3b038f46002ef38c0b21f1a49baac20bc6e)
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/57/435557/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/sshd.yml'],1,dcad9391b925e74ce2b9bad0a9b56dd62f220ddb,sshd-fix-start,- name: Ensure sshd is enabled at boot time,- name: Ensure sshd is running and enabled state: started,1,2
openstack%2Ftripleo-puppet-elements~master~Iba36f0a7d0225843e1997a8a5a330ad49f5a9e21,openstack/tripleo-puppet-elements,master,Iba36f0a7d0225843e1997a8a5a330ad49f5a9e21,Fail fast and warn if old hiera data is detected,ABANDONED,2017-01-26 22:25:05.000000000,2017-02-17 20:40:42.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 18851}]","[{'number': 1, 'created': '2017-01-26 22:25:05.000000000', 'files': ['elements/hiera/10-hiera-disable'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/36388653a715f0a391fe20dee768b6615b7c3684', 'message': ""Fail fast and warn if old hiera data is detected\n\nThis patch updates 10-hiera-disable so that we\nfail faster and log a warning message if the\nold Hiera datafiles format is detected. Since\nwe aren't having a deprecation period for this\nhook change and the old/new hooks can't live\nside by side this warning may help identify\nany out of tree changes using the old formats.\n\nChange-Id: Iba36f0a7d0225843e1997a8a5a330ad49f5a9e21\n""}]",3,425955,36388653a715f0a391fe20dee768b6615b7c3684,11,6,1,360,,,0,"Fail fast and warn if old hiera data is detected

This patch updates 10-hiera-disable so that we
fail faster and log a warning message if the
old Hiera datafiles format is detected. Since
we aren't having a deprecation period for this
hook change and the old/new hooks can't live
side by side this warning may help identify
any out of tree changes using the old formats.

Change-Id: Iba36f0a7d0225843e1997a8a5a330ad49f5a9e21
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/55/425955/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/hiera/10-hiera-disable'],1,36388653a715f0a391fe20dee768b6615b7c3684,hiera_warn," HIERA_DATAFILES=$(os-apply-config --key hiera.datafiles --type raw --key-default '') if [ -n ""$HIERA_DATAFILES"" ]; then echo ""Please update your TripleO services and extradata interfaces to"" echo ""use the new 'hiera' hook instead of the o-a-c element."" exit 1 fi ",,8,0
openstack%2Fcinder~master~I5f641334bd994d028a286c13476b93b3bd8a14b0,openstack/cinder,master,I5f641334bd994d028a286c13476b93b3bd8a14b0,Dell SC: Return all paths,ABANDONED,2016-09-02 20:27:17.000000000,2017-02-17 20:36:29.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10379}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12112}, {'_account_id': 12176}, {'_account_id': 12369}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14208}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15011}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16212}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18444}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}, {'_account_id': 19933}, {'_account_id': 21193}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22450}, {'_account_id': 22510}]","[{'number': 1, 'created': '2016-09-02 20:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/54db5bb9b6b5c868c9a73a11fb63a2325c3b3f26', 'message': ""WIP: Dell SC: Return all paths\n\nDidn't. Does. Don't think this is a great idea.\n\nChange-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0\n""}, {'number': 2, 'created': '2016-09-08 22:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1fd228bcad4883bf686e42ac4821c91c557bbc28', 'message': ""Dell SC: Return all paths\n\nThe Dell driver didn't return all the non active paths. This\ncould lead to a server showing partial connectivity. This is\nmore of a display problem than anything.\n\nThis patch returns all ports.\n\nChange-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0\n""}, {'number': 3, 'created': '2016-09-09 15:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2ba6ae56d3b3e6bb48d444c1eb28b1d7de5ef938', 'message': ""Dell SC: Return all paths\n\nThe Dell driver didn't return all the non active paths. This\ncould lead to a server showing partial connectivity. This is\nmore of a display problem than anything.\n\nThis patch returns all ports.\n\nCloses-Bug: #1621907\nChange-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0\n""}, {'number': 4, 'created': '2016-09-09 19:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/2fa03e88d60bed50e7bd457a3bb24434146d6ad1', 'message': ""Dell SC: Return all paths\n\nThe Dell driver didn't return all the non active paths. This\ncould lead to a server showing partial connectivity. This is\nmore of a display problem than anything.\n\nThis patch returns all ports.\n\nCloses-Bug: #1621907\nChange-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0\n""}, {'number': 5, 'created': '2016-09-19 21:02:19.000000000', 'files': ['cinder/volume/drivers/dell/dell_storagecenter_api.py', 'cinder/tests/unit/volume/drivers/dell/test_dellscapi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2309bc098a56164cc655b9b88ffc6495f7a9086e', 'message': ""Dell SC: Return all paths\n\nThe Dell driver didn't return all the non active paths. This\ncould lead to a server showing partial connectivity. This is\nmore of a display problem than anything.\n\nThis patch returns all ports.\n\nCloses-Bug: #1621907\nChange-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0\n""}]",5,365129,2309bc098a56164cc655b9b88ffc6495f7a9086e,145,60,5,12112,,,0,"Dell SC: Return all paths

The Dell driver didn't return all the non active paths. This
could lead to a server showing partial connectivity. This is
more of a display problem than anything.

This patch returns all ports.

Closes-Bug: #1621907
Change-Id: I5f641334bd994d028a286c13476b93b3bd8a14b0
",git fetch https://review.opendev.org/openstack/cinder refs/changes/29/365129/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/dell/dell_storagecenter_api.py'],1,54db5bb9b6b5c868c9a73a11fb63a2325c3b3f26,," def _is_active(self, activectrlid, currentctrl): currentctrlid = self._get_id(currentctrl) return (activectrlid == currentctrlid) def _get_virtual_ports(self, dom): vports = None r = self.client.get('StorageCenter/ScFaultDomain/%s/VirtualPortList' % dom['instanceId']) if self._check_result(r): vports = self._get_json(r) return vports vports = self._get_virtual_ports(dom) if vports: for vport in vports: isactive = self._is_active( actvctrl, vport['controller']) iqn = vport['iscsiName'] process(lun, iqn, ipaddress, portnumber, status, isactive) currentctrl = mapping['controller'] status, self._is_active(actvctrl, currentctrl))"," # Check if our controller ID matches our active controller ID. isactive = True if (self._get_controller_id(mapping) == actvctrl) else False process(lun, iqn, ipaddress, portnumber, status, isactive) status, isactive) def find_replication_dest(self, instance_id, destssn): pass ",23,9
openstack%2Freleases~master~If19b4b33eadcc593ed6753917d23508d49055464,openstack/releases,master,If19b4b33eadcc593ed6753917d23508d49055464,Create magnum stable/ocata branch,MERGED,2017-02-17 17:42:51.000000000,2017-02-17 20:31:39.000000000,2017-02-17 20:31:39.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-17 17:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/9e57842a8973c4c3c9afe97d9ee4075e4e133c34', 'message': 'Release magnum 4.1.0\n\nChange-Id: If19b4b33eadcc593ed6753917d23508d49055464\n'}, {'number': 2, 'created': '2017-02-17 20:24:15.000000000', 'files': ['deliverables/ocata/magnum.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/7a1fcc8d612df0a879beac62ad3d771c47e19e4a', 'message': 'Create magnum stable/ocata branch\n\nChange-Id: If19b4b33eadcc593ed6753917d23508d49055464\n'}]",0,435549,7a1fcc8d612df0a879beac62ad3d771c47e19e4a,8,2,2,20498,,,0,"Create magnum stable/ocata branch

Change-Id: If19b4b33eadcc593ed6753917d23508d49055464
",git fetch https://review.opendev.org/openstack/releases refs/changes/49/435549/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/magnum.yaml'],1,9e57842a8973c4c3c9afe97d9ee4075e4e133c34,,branches: - name: stable/ocata location: 4.1.0,,3,0
openstack%2Frequirements~master~I16544372f7efff28933da728d11f85dc5e5f9aea,openstack/requirements,master,I16544372f7efff28933da728d11f85dc5e5f9aea,Narrow down the results/matches,MERGED,2017-02-15 02:20:30.000000000,2017-02-17 20:30:00.000000000,2017-02-17 20:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 13404}, {'_account_id': 14288}]","[{'number': 1, 'created': '2017-02-15 02:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/cab79376bd1646262b555e33214ea10008a836f4', 'message': 'Narrow down the results/matches\n\nIf you run grep-all.sh requests, you get all the item that match that\nprefix.  It is a little messy.  Make the match patten more specific so\nyou only get the library you pass on the command line.\n\nChange-Id: I16544372f7efff28933da728d11f85dc5e5f9aea\n'}, {'number': 2, 'created': '2017-02-16 21:26:33.000000000', 'files': ['tools/grep-all.sh'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b4e3ac5714d27967d24daffe2c9ca7b757573883', 'message': 'Narrow down the results/matches\n\nIf you run grep-all.sh requests, you get all the item that match that\nprefix.  It is a little messy.  Make the match patten more specific so\nyou only get the library you pass on the command line.\n\nChange-Id: I16544372f7efff28933da728d11f85dc5e5f9aea\n'}]",2,434024,b4e3ac5714d27967d24daffe2c9ca7b757573883,18,5,2,12898,,,0,"Narrow down the results/matches

If you run grep-all.sh requests, you get all the item that match that
prefix.  It is a little messy.  Make the match patten more specific so
you only get the library you pass on the command line.

Change-Id: I16544372f7efff28933da728d11f85dc5e5f9aea
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/434024/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/grep-all.sh'],1,cab79376bd1646262b555e33214ea10008a836f4,feature/enhance-grep-all," git grep -Eiw ""^${1}[=><!]"" ${2} -- ""${3}"" | cut -d: -f4-"," git grep -Ei ""^${1}"" ${2} -- ""${3}"" | cut -d: -f4-",1,1
openstack%2Fcharm-nova-cloud-controller~master~I32df10286f34801acafc59017710c2fcbe58b29e,openstack/charm-nova-cloud-controller,master,I32df10286f34801acafc59017710c2fcbe58b29e,Move add_hosts_to_cell earlier in compute_changed,MERGED,2017-02-17 19:05:40.000000000,2017-02-17 20:25:11.000000000,2017-02-17 20:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 20648}, {'_account_id': 20805}]","[{'number': 1, 'created': '2017-02-17 19:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/6bc65ef9ad04063d60d58a8fdae4064a0ab07390', 'message': 'Move add_hosts_to_cell earlier in compute_changed\n\nThe cloud-compute-relation-changed hook returns early in some\ncases, such as when migration-auth-type is not set. Move the\nadd_hosts_to_cell call earlier in the hook so that it always\nhas a chance to be called when a compute host is added. This\nalso fixes the broken indentation.\n\nChange-Id: I32df10286f34801acafc59017710c2fcbe58b29e\n'}, {'number': 2, 'created': '2017-02-17 19:11:43.000000000', 'files': ['unit_tests/test_nova_cc_hooks.py', 'hooks/nova_cc_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/e8539fe8fd3d9d40fcc90a8ec99486f90783bf58', 'message': 'Move add_hosts_to_cell earlier in compute_changed\n\nThe cloud-compute-relation-changed hook returns early in some\ncases, such as when migration-auth-type is not set. Move the\nadd_hosts_to_cell call earlier in the hook so that it always\nhas a chance to be called when a compute host is added. This\nalso fixes the broken indentation.\n\nChange-Id: I32df10286f34801acafc59017710c2fcbe58b29e\n'}]",0,435568,e8539fe8fd3d9d40fcc90a8ec99486f90783bf58,10,3,2,11805,,,0,"Move add_hosts_to_cell earlier in compute_changed

The cloud-compute-relation-changed hook returns early in some
cases, such as when migration-auth-type is not set. Move the
add_hosts_to_cell call earlier in the hook so that it always
has a chance to be called when a compute host is added. This
also fixes the broken indentation.

Change-Id: I32df10286f34801acafc59017710c2fcbe58b29e
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/68/435568/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/nova_cc_hooks.py'],1,6bc65ef9ad04063d60d58a8fdae4064a0ab07390,, if is_db_initialised(): add_hosts_to_cell() , if is_db_initialised(): add_hosts_to_cell() ,4,3
openstack%2Ftripleo-quickstart~master~Ib0e5b361e144e676f9e836e6c24bba216ea7f1d8,openstack/tripleo-quickstart,master,Ib0e5b361e144e676f9e836e6c24bba216ea7f1d8,"Replace ""ara generate"" by ""ara generate html""",MERGED,2017-02-13 17:30:03.000000000,2017-02-17 20:23:04.000000000,2017-02-17 20:23:04.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 10022}, {'_account_id': 12715}]","[{'number': 1, 'created': '2017-02-13 17:30:03.000000000', 'files': ['ci-scripts/collect-logs.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/2d8b1631db098849bb7352c468d7c2d2d1544f62', 'message': 'Replace ""ara generate"" by ""ara generate html""\n\nThe newest version of ARA, 0.11, deprecated ""ara generate"" in favor\nof ""ara generate html"". ""ara generate"" will be removed sometime in\nthe future so let\'s adjust it right away.\n\nChange-Id: Ib0e5b361e144e676f9e836e6c24bba216ea7f1d8\n'}]",0,433208,2d8b1631db098849bb7352c468d7c2d2d1544f62,15,4,1,9061,,,0,"Replace ""ara generate"" by ""ara generate html""

The newest version of ARA, 0.11, deprecated ""ara generate"" in favor
of ""ara generate html"". ""ara generate"" will be removed sometime in
the future so let's adjust it right away.

Change-Id: Ib0e5b361e144e676f9e836e6c24bba216ea7f1d8
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/08/433208/1 && git format-patch -1 --stdout FETCH_HEAD,['ci-scripts/collect-logs.sh'],1,2d8b1631db098849bb7352c468d7c2d2d1544f62,ara-generate-deprecation,$WORKSPACE/bin/ara generate html $WORKSPACE/ara,$WORKSPACE/bin/ara generate $WORKSPACE/ara,1,1
openstack%2Fopenstack-ansible~master~I0eca3c973da29c39645937a7da9a82337d9071e8,openstack/openstack-ansible,master,I0eca3c973da29c39645937a7da9a82337d9071e8,Set upgrade test to test ocata->master,MERGED,2017-02-13 11:59:01.000000000,2017-02-17 20:22:25.000000000,2017-02-17 20:22:25.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 4656}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 13095}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-13 11:59:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ad3379b9cfab9582fc7381c160ec6469dce2f7c1', 'message': 'Set upgrade test to test ocata->master\n\nChange-Id: I0eca3c973da29c39645937a7da9a82337d9071e8\n'}, {'number': 2, 'created': '2017-02-14 19:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/756354e1320064187ad984bbc73d4a0fb312194c', 'message': 'Set upgrade test to test ocata->master\n\nChange-Id: I0eca3c973da29c39645937a7da9a82337d9071e8\n'}, {'number': 3, 'created': '2017-02-15 08:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5cd8a41e95e1dc4c9918b06b655069435d1c0d7a', 'message': 'Set upgrade test to test ocata->master\n\nChange-Id: I0eca3c973da29c39645937a7da9a82337d9071e8\n'}, {'number': 4, 'created': '2017-02-17 13:53:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/087a67774e5f6e776c0aa983d2e3f2939bcc1682', 'message': 'Set upgrade test to test ocata->master\n\nChange-Id: I0eca3c973da29c39645937a7da9a82337d9071e8\n'}, {'number': 5, 'created': '2017-02-17 15:39:20.000000000', 'files': ['scripts/gate-check-commit.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9ea99be45ea4ca5f3e48b90d56c247422fc94615', 'message': 'Set upgrade test to test ocata->master\n\nChange-Id: I0eca3c973da29c39645937a7da9a82337d9071e8\n'}]",0,433024,9ea99be45ea4ca5f3e48b90d56c247422fc94615,33,7,5,6816,,,0,"Set upgrade test to test ocata->master

Change-Id: I0eca3c973da29c39645937a7da9a82337d9071e8
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/24/433024/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/gate-check-commit.sh'],1,ad3379b9cfab9582fc7381c160ec6469dce2f7c1,,"export UPGRADE_BASEBRANCH=${2:-""ocata""}","export UPGRADE_BASEBRANCH=${2:-""newton""}",1,1
openstack%2Fopenstacksdk~master~Iccb423aad801115d593a6ad5ead408f48054c5d4,openstack/openstacksdk,master,Iccb423aad801115d593a6ad5ead408f48054c5d4,Privatize session instance on Proxy subclasses,MERGED,2017-02-15 18:28:59.000000000,2017-02-17 20:15:25.000000000,2017-02-16 02:58:12.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-15 18:28:59.000000000', 'files': ['openstack/proxy2.py', 'openstack/message/v2/_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/cluster/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/message/v1/_proxy.py', 'openstack/proxy.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/compute/v2/_proxy.py', 'openstack/object_store/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/87c253c03f4c931e01d2c26e531902e4f8f89401', 'message': ""Privatize session instance on Proxy subclasses\n\nEach Proxy subclass has a session, but it's currently a public name, and\nas such is accessible. Making it accessible is sort of a low risk thing,\nbut isn't really necessary—if someone needs a session instance they will\nperhaps be creating their own which they pass into a Connection, or they\nwould be more likely to get the session off of a Connection instance\n(which is fine being public there, I think).\n\nThis came up in the proxy doc work I'm doing, where every proxy has a\nwarning for not documenting the `session` name. At the proxy level it\nreally should just be a private name and a part of the implementation.\n\nThis change basically does a s/self.session/self._session/\n\nChange-Id: Iccb423aad801115d593a6ad5ead408f48054c5d4\n""}]",0,434457,87c253c03f4c931e01d2c26e531902e4f8f89401,9,3,1,8257,,,0,"Privatize session instance on Proxy subclasses

Each Proxy subclass has a session, but it's currently a public name, and
as such is accessible. Making it accessible is sort of a low risk thing,
but isn't really necessary—if someone needs a session instance they will
perhaps be creating their own which they pass into a Connection, or they
would be more likely to get the session off of a Connection instance
(which is fine being public there, I think).

This came up in the proxy doc work I'm doing, where every proxy has a
warning for not documenting the `session` name. At the proxy level it
really should just be a private name and a part of the implementation.

This change basically does a s/self.session/self._session/

Change-Id: Iccb423aad801115d593a6ad5ead408f48054c5d4
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/57/434457/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/proxy2.py', 'openstack/message/v2/_proxy.py', 'openstack/tests/unit/orchestration/v1/test_proxy.py', 'openstack/cluster/v1/_proxy.py', 'openstack/image/v2/_proxy.py', 'openstack/network/v2/_proxy.py', 'openstack/message/v1/_proxy.py', 'openstack/proxy.py', 'openstack/orchestration/v1/_proxy.py', 'openstack/compute/v2/_proxy.py', 'openstack/object_store/v1/_proxy.py']",11,87c253c03f4c931e01d2c26e531902e4f8f89401,privatize_proxy_session," account.set_metadata(self._session, metadata) account.delete_metadata(self._session, keys) return _container.Container.list(self._session, **query) res.set_metadata(self._session, metadata) res.delete_metadata(self._session, keys) objs = _obj.Object.list(self._session, res.set_metadata(self._session, metadata) res.delete_metadata(self._session, keys)"," account.set_metadata(self.session, metadata) account.delete_metadata(self.session, keys) return _container.Container.list(self.session, **query) res.set_metadata(self.session, metadata) res.delete_metadata(self.session, keys) objs = _obj.Object.list(self.session, res.set_metadata(self.session, metadata) res.delete_metadata(self.session, keys)",112,111
openstack%2Fdiskimage-builder~master~I9e7261c4124b71eeb6bddd9e21747b61bbdc16fa,openstack/diskimage-builder,master,I9e7261c4124b71eeb6bddd9e21747b61bbdc16fa,Fix requirements update,MERGED,2017-02-12 15:59:29.000000000,2017-02-17 20:14:06.000000000,2017-02-17 20:14:06.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 21741}]","[{'number': 1, 'created': '2017-02-12 15:59:29.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/b833960c69645ccbb9c57af99704da6df1676fd2', 'message': 'Fix requirements update\n\nSphinx 1.5 fails with current pbr (needs new pbr release, see change\nI52d45fa0a0d42de690d3a492068f7bb03483a224.\n\nFor now, set warnerrors to False to be able to use this.\n\nAlso, remove duplicate requirements line.\n\nAlso, update to new sphinx version to show that this works.\n\nThis is in reaction to the failure in\nIa184446fe34c49a48ca079c828157ea34e662d4b.\n\nChange-Id: I9e7261c4124b71eeb6bddd9e21747b61bbdc16fa\n'}]",0,432771,b833960c69645ccbb9c57af99704da6df1676fd2,10,3,1,6547,,,0,"Fix requirements update

Sphinx 1.5 fails with current pbr (needs new pbr release, see change
I52d45fa0a0d42de690d3a492068f7bb03483a224.

For now, set warnerrors to False to be able to use this.

Also, remove duplicate requirements line.

Also, update to new sphinx version to show that this works.

This is in reaction to the failure in
Ia184446fe34c49a48ca079c828157ea34e662d4b.

Change-Id: I9e7261c4124b71eeb6bddd9e21747b61bbdc16fa
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/71/432771/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt', 'setup.cfg']",3,b833960c69645ccbb9c57af99704da6df1676fd2,warnerrors,# TODO(jaegerandi): Set to True once pbr 1.11.0 is out. warnerrors = False,warnerrors = True,3,3
openstack%2Fceilometer~master~I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac,openstack/ceilometer,master,I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac,set OS_AUTH_TYPE in gate,MERGED,2017-02-16 15:30:18.000000000,2017-02-17 20:09:58.000000000,2017-02-17 02:50:13.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 8290}, {'_account_id': 22752}]","[{'number': 1, 'created': '2017-02-16 15:30:18.000000000', 'files': ['ceilometer/tests/integration/hooks/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/83412c80cc94da3afa7a0368a27ffce49cf1ac15', 'message': ""set OS_AUTH_TYPE in gate\n\nwe use keystone in integration gate but never set OS_AUTH_TYPE.\ngnocchi will not default to keystone if OS_AUTH_TYPE isn't set.\n\nChange-Id: I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac\n""}]",0,434972,83412c80cc94da3afa7a0368a27ffce49cf1ac15,12,4,1,6537,,,0,"set OS_AUTH_TYPE in gate

we use keystone in integration gate but never set OS_AUTH_TYPE.
gnocchi will not default to keystone if OS_AUTH_TYPE isn't set.

Change-Id: I5e006c1b47a68bbe6c2e966faf8c740c23dde1ac
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/72/434972/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/integration/hooks/post_test_hook.sh'],1,83412c80cc94da3afa7a0368a27ffce49cf1ac15,test,export OS_AUTH_TYPE=password,,1,0
openstack%2Fkeystone~master~Ic4fff30c306561b71288712480f073aba1fccbde,openstack/keystone,master,Ic4fff30c306561b71288712480f073aba1fccbde,Fix multiple uuid warnings with pycadf,MERGED,2017-01-27 21:57:36.000000000,2017-02-17 20:03:39.000000000,2017-02-17 20:03:39.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 20466}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-01-27 21:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f843ab591159878e1c46659336b04a45be122b39', 'message': ""WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes the default test fixtures DOMAIN_ID to a valid uuid\nand the ROLES ids to valid uuids.\n\n(WIP NOTE) - Need to fix/handle multiple tests expecting a role id\nof 'admin' that are currently failing.\n\nCo-Authored-By: Kristi Nikolla <knikolla@bu.edu>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 2, 'created': '2017-01-27 22:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5e34b7b0b480859911157f7f2c566168cd10a52', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes the default test fixtures DOMAIN_ID to a valid uuid\nand the ROLES ids to valid uuids. Also changed ROLE_ASSIGNMENT\nto expect the now declared ADMIN_ROLE_ID.\n\nCo-Authored-By: Kristi Nikolla <knikolla@bu.edu>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 3, 'created': '2017-01-30 04:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ba116cb661039b9f126029a94628486c8959dbff', 'message': 'WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn(\'Invalid uuid. To ensure interoperability, identifiers\'\n\nThis changes the default_domain_id to a valid uuid of:\n\n""00000000000000000000000000000000"".\n\nAlso changes the default test fixtures DOMAIN_ID to a valid uuid\nand the ROLES ids to valid uuids. Also changed ROLE_ASSIGNMENT\nto expect the now declared ADMIN_ROLE_ID.\n\nCo-Authored-By: Kristi Nikolla <knikolla@bu.edu>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n'}, {'number': 4, 'created': '2017-01-31 23:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1f008baaf3b18ec6d1b2b7c2143409d8e6119139', 'message': 'WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn(\'Invalid uuid. To ensure interoperability, identifiers\'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their \'id\' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures\' \'name\' value, rather\nthan \'id\'.\n\nThis also changes the default_domain_id in the test config to a valid\nuuid of: ""00000000000000000000000000000000"".\n\nCo-Authored-By: Kristi Nikolla <knikolla@bu.edu>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n'}, {'number': 5, 'created': '2017-02-01 18:03:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fa0dbf0bf0b70c57abc9321f104bb5b0d3b55613', 'message': 'WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn(\'Invalid uuid. To ensure interoperability, identifiers\'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their \'id\' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures\' \'name\' value, rather\nthan \'id\'.\n\nThis also changes the default_domain_id in the test config to a valid\nuuid of: ""00000000000000000000000000000001"".\n\nCo-Authored-By: Kristi Nikolla <knikolla@bu.edu>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n'}, {'number': 6, 'created': '2017-02-02 03:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/59db112060f3efce011bc962d506a78ce1364506', 'message': 'WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn(\'Invalid uuid. To ensure interoperability, identifiers\'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their \'id\' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures\' \'name\' value, rather\nthan \'id\'. Replaced many instances of hard-coded id\'s to use\nrandom uuids instead.\n\nThis also changes the default_domain_id in the test config to a valid\nuuid of: ""00000000000000000000000000000001"".\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n'}, {'number': 7, 'created': '2017-02-02 20:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/bbfe33a2fd12ffc7dd09725b2c5669372ec302d2', 'message': ""WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 8, 'created': '2017-02-03 16:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/76ceb4d817481ac27162c605e1954b5dbdb90f75', 'message': ""WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 9, 'created': '2017-02-03 17:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5e3eac31e9d6b4fe3df54fdd4f7424eece519868', 'message': ""WIP Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 10, 'created': '2017-02-03 21:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0df96ab296aba1233d6839fa5ad3c24365e7af8e', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\n""}, {'number': 11, 'created': '2017-02-06 23:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d1ab8d0456dbc82cc51b15734fa2929f8c9fbe0c', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\nDepends-On: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 12, 'created': '2017-02-08 01:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d1e6ed66271374b2257cdd2880e3e85a6a881cf', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\nDepends-On: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 13, 'created': '2017-02-08 01:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3476c0d19c6ff12e6548024e8a3839a714f48bcc', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids or default_fixture ids.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\nDepends-On: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 14, 'created': '2017-02-09 03:17:27.000000000', 'files': ['keystone/tests/unit/catalog/test_backends.py', 'keystone/tests/unit/assignment/test_backends.py', 'keystone/tests/unit/core.py', 'keystone/tests/unit/filtering.py', 'keystone/tests/unit/test_backend_ldap.py', 'keystone/tests/unit/assignment/test_core.py', 'keystone/tests/unit/default_fixtures.py', 'keystone/tests/unit/identity/test_backends.py', 'keystone/tests/unit/test_catalog.py', 'keystone/tests/unit/test_v3_catalog.py', 'keystone/tests/unit/test_auth.py', 'keystone/tests/unit/rest.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2be615ea9303109f11033e293c229df586e3b1e1', 'message': ""Fix multiple uuid warnings with pycadf\n\nThere are multiple pycadf warnings about invalid uuids when\nrunning keystone tests:\n\nTo ensure interoperability, identifiersshould be a valid uuid.\n  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'\n\nThis changes multiple fixtures within default_fixtures to use valid\nuuids for their 'id' values. Also changed load_fixtures to build\nthe fixtures based on the default_fixtures' 'name' value, rather\nthan 'id'. Replaced many instances of invalid hard-coded ids to use\nrandom uuids, default_fixture ids, or 'default'.\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nChange-Id: Ic4fff30c306561b71288712480f073aba1fccbde\nCloses-Bug: #1659053\nDepends-On: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}]",33,426411,2be615ea9303109f11033e293c229df586e3b1e1,62,5,14,21420,,,0,"Fix multiple uuid warnings with pycadf

There are multiple pycadf warnings about invalid uuids when
running keystone tests:

To ensure interoperability, identifiersshould be a valid uuid.
  warnings.warn('Invalid uuid. To ensure interoperability, identifiers'

This changes multiple fixtures within default_fixtures to use valid
uuids for their 'id' values. Also changed load_fixtures to build
the fixtures based on the default_fixtures' 'name' value, rather
than 'id'. Replaced many instances of invalid hard-coded ids to use
random uuids, default_fixture ids, or 'default'.

Co-Authored-By: Tin Lam <tinlam@gmail.com>

Change-Id: Ic4fff30c306561b71288712480f073aba1fccbde
Closes-Bug: #1659053
Depends-On: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4
",git fetch https://review.opendev.org/openstack/keystone refs/changes/11/426411/6 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/default_fixtures.py'],1,f843ab591159878e1c46659336b04a45be122b39,bug/1659053,"DEFAULT_DOMAIN_ID = uuid.uuid4().hex ROLE_ID = uuid.uuid4().hex ADMIN_ROLE_ID = '1234567890abcdef1234567890abcdef' 'id': ADMIN_ROLE_ID, 'id': ROLE_ID, 'id': ROLE_ID, 'id': ROLE_ID, 'id': ROLE_ID, 'id': ROLE_ID,","DEFAULT_DOMAIN_ID = 'default' 'id': 'admin', 'id': 'member', 'id': 'other', 'id': 'browser', 'id': 'writer', 'id': 'service',",9,7
openstack%2Fceilometer~stable%2Fmitaka~I2013e3992a961b6763f8c26807f00054b71d2291,openstack/ceilometer,stable/mitaka,I2013e3992a961b6763f8c26807f00054b71d2291,Updated from global requirements,ABANDONED,2016-06-10 23:12:37.000000000,2017-02-17 20:03:14.000000000,,"[{'_account_id': 3}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 22165}, {'_account_id': 22752}, {'_account_id': 22779}]","[{'number': 1, 'created': '2016-06-10 23:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/18ce99c61fc2c356d126e93cc7341d41a6ecf22f', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 2, 'created': '2016-07-08 12:35:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/12e4985f1461afc7352167edb436650b91bc42ab', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 3, 'created': '2016-07-14 09:17:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/410b187d5d5beb581acc914613cc2dcb5b6e78f2', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 4, 'created': '2016-07-20 18:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/24db9abe6b94973e81269b8dc27d69bf7109dd55', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 5, 'created': '2016-08-17 14:15:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7298b629eac27d1f421f32f0a67e57cf2c11b4b2', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 6, 'created': '2016-09-06 09:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/71d9debc1e41ceaf86835e04c392c0841d3bceba', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 7, 'created': '2017-01-23 22:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e37a0ca113eae969201a581f37caf096553f207', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 8, 'created': '2017-02-14 09:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6043628dffc54227e0d6f1b787c54360018487df', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}, {'number': 9, 'created': '2017-02-17 17:55:59.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5509f9e1d498ba0bb3080a88dbbc7a9c771b7b67', 'message': 'Updated from global requirements\n\nChange-Id: I2013e3992a961b6763f8c26807f00054b71d2291\n'}]",0,328529,5509f9e1d498ba0bb3080a88dbbc7a9c771b7b67,30,7,9,11131,,,0,"Updated from global requirements

Change-Id: I2013e3992a961b6763f8c26807f00054b71d2291
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/29/328529/8 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,18ce99c61fc2c356d126e93cc7341d41a6ecf22f,openstack/requirements,oslo.concurrency>=3.7.1 # Apache-2.0,oslo.concurrency>=3.5.0 # Apache-2.0,1,1
openstack%2Fopenstacksdk~master~If2d0e0a402bf4fc530187ec07dfd3f69057104bf,openstack/openstacksdk,master,If2d0e0a402bf4fc530187ec07dfd3f69057104bf,Fix function test for compute images,MERGED,2017-02-17 14:48:53.000000000,2017-02-17 19:47:12.000000000,2017-02-17 19:47:12.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2017-02-17 14:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8834134a3ceffe455946ad020a52de2cedd8603a', 'message': 'Fix function test for compute images\n\nThe functional test for compute image metadata did not\nexpect to get anything back for some reason.\n\nPartial-bug: #1665495\n\nChange-Id: If2d0e0a402bf4fc530187ec07dfd3f69057104bf\n'}, {'number': 2, 'created': '2017-02-17 15:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f1e88f45ea4ca79862c27b067c091dc074ca9a34', 'message': 'Fix function test for compute images\n\nThe functional test for compute image metadata did not\nexpect to get anything back for some reason.\n\nPartial-bug: #1665495\n\nChange-Id: If2d0e0a402bf4fc530187ec07dfd3f69057104bf\n'}, {'number': 3, 'created': '2017-02-17 16:03:14.000000000', 'files': ['openstack/tests/functional/compute/v2/test_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/78d1a2400d0cf923cfa737cff59d6c9951dbe314', 'message': 'Fix function test for compute images\n\nThe functional test for compute image metadata did not\nexpect to get anything back for some reason.\n\nPartial-bug: #1665495\n\nChange-Id: If2d0e0a402bf4fc530187ec07dfd3f69057104bf\n'}]",0,435478,78d1a2400d0cf923cfa737cff59d6c9951dbe314,13,3,3,8736,,,0,"Fix function test for compute images

The functional test for compute image metadata did not
expect to get anything back for some reason.

Partial-bug: #1665495

Change-Id: If2d0e0a402bf4fc530187ec07dfd3f69057104bf
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/78/435478/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/compute/v2/test_image.py'],1,8834134a3ceffe455946ad020a52de2cedd8603a,bug/1665495," self.assertIn('k1', image.metadata) self.assertEqual('', image.metadata['k1'])", self.assertFalse(image.metadata),2,1
openstack%2Fnova~master~Id98c42f935c65a97dc40aa38c78cae0779ed563f,openstack/nova,master,Id98c42f935c65a97dc40aa38c78cae0779ed563f,Allow pattern-based substitutions in CellMapping URLs,ABANDONED,2017-02-06 22:43:42.000000000,2017-02-17 19:47:08.000000000,,"[{'_account_id': 3}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2017-02-06 22:43:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3ee92869f50db61db5042201497a3216e58f4f91', 'message': 'Allow pattern-based substitutions in CellMapping URLs\n\nCertain HA setups may require additional parameters in things like\nthe database_connection URL that need to be different for each host.\nNow that we\'re storing cell database connections in the database itself,\neach host will see the same value for the connection, instead of a\nlocally-override-able value in their config files. This is the case\nin TripleO with HA, where one of the controllers will be the VIP\nholder for the database interface at any one point. The controller\nthat is the current VIP holder will be connecting to that address\nand Linux\'s weak host model short-circuits the routing logic to\nignore any preferential source adddress that is set on the appropriate\nroute. Thus, there is a need to provide ""?bind_address=$addr"" in the\nsqlalchemy connection URL. See the below-referenced bugs for\nmore information.\n\nThis sets up a system for being able to substitute replacement values\nin the transport_url and database_connection fields of CellMapping\nas they are loaded out of the database. Currently the only such\nsubstitution is for CONF.my_ip, which will solve the immediate\nbind address need.\n\nChange-Id: Id98c42f935c65a97dc40aa38c78cae0779ed563f\nRelated-Bug: #1662344\nRelated-Bug: #1643487\n'}, {'number': 2, 'created': '2017-02-06 22:58:02.000000000', 'files': ['nova/objects/cell_mapping.py', 'nova/tests/unit/objects/test_cell_mapping.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f36580bb936b66ee175b74abe3ae0f01aa16aaae', 'message': 'Allow pattern-based substitutions in CellMapping URLs\n\nCertain HA setups may require additional parameters in things like\nthe database_connection URL that need to be different for each host.\nNow that we\'re storing cell database connections in the database itself,\neach host will see the same value for the connection, instead of a\nlocally-override-able value in their config files. This is the case\nin TripleO with HA, where one of the controllers will be the VIP\nholder for the database interface at any one point. The controller\nthat is the current VIP holder will be connecting to that address\nand Linux\'s weak host model short-circuits the routing logic to\nignore any preferential source adddress that is set on the appropriate\nroute. Thus, there is a need to provide ""?bind_address=$addr"" in the\nsqlalchemy connection URL. See the below-referenced bugs for\nmore information.\n\nThis sets up a system for being able to substitute replacement values\nin the transport_url and database_connection fields of CellMapping\nas they are loaded out of the database. Currently the only such\nsubstitution is for CONF.my_ip, which will solve the immediate\nbind address need.\n\nChange-Id: Id98c42f935c65a97dc40aa38c78cae0779ed563f\nRelated-Bug: #1662344\nRelated-Bug: #1643487\n'}]",2,429910,f36580bb936b66ee175b74abe3ae0f01aa16aaae,20,12,2,4393,,,0,"Allow pattern-based substitutions in CellMapping URLs

Certain HA setups may require additional parameters in things like
the database_connection URL that need to be different for each host.
Now that we're storing cell database connections in the database itself,
each host will see the same value for the connection, instead of a
locally-override-able value in their config files. This is the case
in TripleO with HA, where one of the controllers will be the VIP
holder for the database interface at any one point. The controller
that is the current VIP holder will be connecting to that address
and Linux's weak host model short-circuits the routing logic to
ignore any preferential source adddress that is set on the appropriate
route. Thus, there is a need to provide ""?bind_address=$addr"" in the
sqlalchemy connection URL. See the below-referenced bugs for
more information.

This sets up a system for being able to substitute replacement values
in the transport_url and database_connection fields of CellMapping
as they are loaded out of the database. Currently the only such
substitution is for CONF.my_ip, which will solve the immediate
bind address need.

Change-Id: Id98c42f935c65a97dc40aa38c78cae0779ed563f
Related-Bug: #1662344
Related-Bug: #1643487
",git fetch https://review.opendev.org/openstack/nova refs/changes/10/429910/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/cell_mapping.py', 'nova/tests/unit/objects/test_cell_mapping.py']",2,3ee92869f50db61db5042201497a3216e58f4f91,bug/1662344," def test_pattern_load(self): self.flags(my_ip='1.2.3.4') db_mapping = get_db_mapping(database_connection='foo://%(my_ip)s/bar', transport_url='fake://foo/%(my_ip)s') obj = objects.CellMapping._from_db_object(self.context, objects.CellMapping(), db_mapping) self.assertEqual('foo://1.2.3.4/bar', obj.database_connection) self.assertEqual('fake://foo/1.2.3.4', obj.transport_url) def test_pattern_load_no_pattern(self): self.flags(my_ip='1.2.3.4') db_mapping = get_db_mapping(database_connection='foo://bar', transport_url='fake://foo/') obj = objects.CellMapping._from_db_object(self.context, objects.CellMapping(), db_mapping) self.assertEqual('foo://bar', obj.database_connection) self.assertEqual('fake://foo/', obj.transport_url) def test_pattern_fail_load(self): self.flags(my_ip='1.2.3.4') db_mapping = get_db_mapping(database_connection='foo://%(dne)s/bar', transport_url='fake://foo/%(dne)s') obj = objects.CellMapping._from_db_object(self.context, objects.CellMapping(), db_mapping) self.assertEqual('foo://%(dne)s/bar', obj.database_connection) self.assertEqual('fake://foo/%(dne)s', obj.transport_url) ",,63,1
openstack%2Ftripleo-common~master~Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e,openstack/tripleo-common,master,Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e,Open log in utf-8 to prevent UnicodeEncodeError,MERGED,2017-02-15 21:11:57.000000000,2017-02-17 19:22:34.000000000,2017-02-17 19:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-15 21:11:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/851da3aba83cb888456477fb140092555fa27493', 'message': 'Encode log line to prevent UnicodeEncodeError\n\nSince we are decoding the log line before trying to write it out to file\na file, we need to encode it to so it does not throw an error about\nunicode characters when trying to write out to the log file. This change\nencodes the log line when writing it out to the log file to prevent\nascii/utf-8 issues.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n'}, {'number': 2, 'created': '2017-02-15 23:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0412b0f19ff0e74998a635a331eae910b1c8dccf', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n'}, {'number': 3, 'created': '2017-02-16 00:47:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/44890030953a807e762cf68317c97b19053c0602', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n'}, {'number': 4, 'created': '2017-02-16 15:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0d82f2211e4691107515bcd47287475c455017c6', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n'}, {'number': 5, 'created': '2017-02-16 17:16:25.000000000', 'files': ['tripleo_common/tests/image/test_image_builder.py', 'tripleo_common/image/image_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/9d2a6dae35de3987aded8d4611040d7130d6dc91', 'message': 'Open log in utf-8 to prevent UnicodeEncodeError\n\nIn python2 opens files as ascii by default, we were getting errors when\ntrying to write out unicode to log files. This change pulls in the\ncodecs module for python2 to support writing unicode out to files. In\npython3, all strings are unicode so there is no issues when writing them\nout to a file.\n\nChange-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e\nCloses-Bug: #1665114\n'}]",2,434520,9d2a6dae35de3987aded8d4611040d7130d6dc91,23,4,5,14985,,,0,"Open log in utf-8 to prevent UnicodeEncodeError

In python2 opens files as ascii by default, we were getting errors when
trying to write out unicode to log files. This change pulls in the
codecs module for python2 to support writing unicode out to files. In
python3, all strings are unicode so there is no issues when writing them
out to a file.

Change-Id: Id740253a0e6143cfcdd4f7fe2b5460d9f64fa01e
Closes-Bug: #1665114
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/20/434520/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_builder.py'],1,851da3aba83cb888456477fb140092555fa27493,bug/1665114, f.write(line.encode('utf-8')), f.write(line),1,1
openstack%2Ftripleo-ci~master~Ibe5427c8a8ad7c8e9235e0393fe0b6f35b197595,openstack/tripleo-ci,master,Ibe5427c8a8ad7c8e9235e0393fe0b6f35b197595,Stop mirroring centos images,MERGED,2017-02-07 17:17:20.000000000,2017-02-17 19:15:42.000000000,2017-02-17 19:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 3153}, {'_account_id': 10969}]","[{'number': 1, 'created': '2017-02-07 17:17:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6d2562a7683a19f5c38bcc1b25028b9b83fe8a59', 'message': ""Stop mirroring centos images\n\nWe aren't using the centos images on the mirror server anyway, and\nthey eat up a significant amount of disk space.\n\nChange-Id: Ibe5427c8a8ad7c8e9235e0393fe0b6f35b197595\n""}, {'number': 2, 'created': '2017-02-13 22:02:24.000000000', 'files': ['scripts/mirror-server/mirror-server.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bfa1c5be54a588440cf425a30ab67b1eb458e73e', 'message': ""Stop mirroring centos images\n\nWe aren't using the centos images on the mirror server anyway, and\nthey eat up a significant amount of disk space.\n\nChange-Id: Ibe5427c8a8ad7c8e9235e0393fe0b6f35b197595\n""}]",0,430372,bfa1c5be54a588440cf425a30ab67b1eb458e73e,14,4,2,6928,,,0,"Stop mirroring centos images

We aren't using the centos images on the mirror server anyway, and
they eat up a significant amount of disk space.

Change-Id: Ibe5427c8a8ad7c8e9235e0393fe0b6f35b197595
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/72/430372/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/mirror-server/mirror-server.pp'],1,6d2562a7683a19f5c38bcc1b25028b9b83fe8a59,stop-mirror-images,,"cron {""centos-cloud-images"": command => ""cd /var/www/html && timeout 30m wget -m --no-parent --accept-regex qcow2.xz --progress=dot http://cloud.centos.org/centos/7/images/"", minute => ""11"" } ",0,6
openstack%2Ftripleo-ci~master~I94bd0c203e3d6dbfab5c24fffde56b9cf34af7e1,openstack/tripleo-ci,master,I94bd0c203e3d6dbfab5c24fffde56b9cf34af7e1,Remove openstack-heat-templates from bootstrap elements path,MERGED,2017-02-16 20:24:12.000000000,2017-02-17 19:15:11.000000000,2017-02-17 19:15:11.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2017-02-16 20:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1f28e1c78cbd98cf366698c915d8ea1e2e933caf', 'message': 'Remove openstack-heat-templates from bootstrap elements path\n\nWe no longer use anything from openstack-heat-templates, so having\nthis included is just preventing us from dropping the dependency.\n\nChange-Id: I94bd0c203e3d6dbfab5c24fffde56b9cf34af7e1\n'}, {'number': 2, 'created': '2017-02-16 21:30:57.000000000', 'files': ['scripts/bootstrap-overcloud-full.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/46a7ed16bffefcf37dd4b9db60925f3409d1355c', 'message': 'Remove openstack-heat-templates from bootstrap elements path\n\nWe no longer use anything from openstack-heat-templates so having\nthis included is just preventing us from dropping the dependency.\n\nChange-Id: I94bd0c203e3d6dbfab5c24fffde56b9cf34af7e1\n'}]",0,435102,46a7ed16bffefcf37dd4b9db60925f3409d1355c,18,4,2,6928,,,0,"Remove openstack-heat-templates from bootstrap elements path

We no longer use anything from openstack-heat-templates so having
this included is just preventing us from dropping the dependency.

Change-Id: I94bd0c203e3d6dbfab5c24fffde56b9cf34af7e1
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/02/435102/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/bootstrap-overcloud-full.sh'],1,1f28e1c78cbd98cf366698c915d8ea1e2e933caf,no-heat-templates,"export ELEMENTS_PATH=""${COMMON_ELEMENTS_PATH}:/usr/share/instack-undercloud:/usr/share/tripleo-image-elements:/usr/share/tripleo-puppet-elements""","export ELEMENTS_PATH=""${COMMON_ELEMENTS_PATH}:/usr/share/instack-undercloud:/usr/share/tripleo-image-elements:/usr/share/tripleo-puppet-elements:/usr/share/openstack-heat-templates/software-config/elements""",1,1
openstack%2Ftripleo-ui~stable%2Focata~Ic19a3f5fcb0f7d99a5f95a3d877df47abf9dfebe,openstack/tripleo-ui,stable/ocata,Ic19a3f5fcb0f7d99a5f95a3d877df47abf9dfebe,Add i18n to nodes page and buttons,MERGED,2017-02-17 11:15:41.000000000,2017-02-17 19:15:06.000000000,2017-02-17 19:15:06.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 20970}]","[{'number': 1, 'created': '2017-02-17 11:15:41.000000000', 'files': ['src/js/components/nodes/RegisteredNodesTabPane.js', 'src/js/components/nodes/Nodes.js'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/42e715e4be4a4d21024def865bec4dcf5ec74ca2', 'message': 'Add i18n to nodes page and buttons\n\nChange-Id: Ic19a3f5fcb0f7d99a5f95a3d877df47abf9dfebe\nPartial-Bug: #1662964\n(cherry picked from commit b20142046ae54d92e684b0a2eb5dad784032f7e0)\n'}]",0,435381,42e715e4be4a4d21024def865bec4dcf5ec74ca2,7,3,1,4978,,,0,"Add i18n to nodes page and buttons

Change-Id: Ic19a3f5fcb0f7d99a5f95a3d877df47abf9dfebe
Partial-Bug: #1662964
(cherry picked from commit b20142046ae54d92e684b0a2eb5dad784032f7e0)
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/81/435381/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/js/components/nodes/RegisteredNodesTabPane.js', 'src/js/components/nodes/Nodes.js']",2,42e715e4be4a4d21024def865bec4dcf5ec74ca2,bug/1662964,"import { defineMessages, FormattedMessage } from 'react-intl';const messages = defineMessages({ refreshResults: { id: 'Nodes.refreshResults', defaultMessage: 'Refresh Results' }, registerNodes: { id: 'Nodes.registerNodes', defaultMessage: 'Register Nodes' }, nodes: { id: 'Nodes.nodes', defaultMessage: 'Nodes' }, registeredTab: { id: 'Nodes.registeredTab', defaultMessage: 'Registered' }, deployedTab: { id: 'Nodes.deployedTab', defaultMessage: 'Deployed' }, maintenanceTab: { id: 'Nodes.maintenanceTab', defaultMessage: 'Maintenance' } }); <span className=""pficon pficon-refresh""></span> <FormattedMessage {...messages.refreshResults}/> <span className=""fa fa-plus""/> <FormattedMessage {...messages.registerNodes}/> <h1><FormattedMessage {...messages.nodes}/></h1> <FormattedMessage {...messages.registeredTab}/> <span className=""badge"">{this.props.nodes.get('registered').size}</span> <FormattedMessage {...messages.deployedTab}/> <span className=""badge"">{this.props.nodes.get('deployed').size}</span> <FormattedMessage {...messages.maintenanceTab}/> <span className=""badge"">{this.props.nodes.get('maintenance').size}</span>"," <span className=""pficon pficon-refresh""></span> Refresh Results <span className=""fa fa-plus""/> Register Nodes <h1>Nodes</h1> Registered<span className=""badge"">{this.props.nodes.get('registered').size}</span> Deployed<span className=""badge"">{this.props.nodes.get('deployed').size}</span> Maintenance<span className=""badge"">{this.props.nodes.get('maintenance').size}</span>",77,13
openstack%2Ftripleo-ui~stable%2Focata~I702b73ffd42bcc73c0378cf444c075bfdf01ebe3,openstack/tripleo-ui,stable/ocata,I702b73ffd42bcc73c0378cf444c075bfdf01ebe3,Include j2 files in plan creation,MERGED,2017-02-17 11:16:05.000000000,2017-02-17 19:15:00.000000000,2017-02-17 19:15:00.000000000,"[{'_account_id': 3}, {'_account_id': 7509}, {'_account_id': 10112}, {'_account_id': 20970}]","[{'number': 1, 'created': '2017-02-17 11:16:05.000000000', 'files': ['src/js/components/plan/PlanFileInput.js', 'releasenotes/notes/include-j2-bedc0ee22603acb0.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ui/commit/3f231b41cdf528de35aceef31a95d4136c8fca94', 'message': 'Include j2 files in plan creation\n\nCloses-Bug: #1664892\nChange-Id: I702b73ffd42bcc73c0378cf444c075bfdf01ebe3\n(cherry picked from commit f9ee9d1d2ead2f746742720c25efbcf3d0ca9732)\n'}]",0,435382,3f231b41cdf528de35aceef31a95d4136c8fca94,8,4,1,4978,,,0,"Include j2 files in plan creation

Closes-Bug: #1664892
Change-Id: I702b73ffd42bcc73c0378cf444c075bfdf01ebe3
(cherry picked from commit f9ee9d1d2ead2f746742720c25efbcf3d0ca9732)
",git fetch https://review.opendev.org/openstack/tripleo-ui refs/changes/82/435382/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/js/components/plan/PlanFileInput.js', 'releasenotes/notes/include-j2-bedc0ee22603acb0.yaml']",2,3f231b41cdf528de35aceef31a95d4136c8fca94,bug/1664892,fixes: - | Fixes `bug 1664892 <https://launchpad.net/bugs/1664892>`__ Jinja2 partials are included in plan creation ,,5,1
openstack%2Ftripleo-heat-templates~stable%2Focata~I70515c5b9ce2668a684649ecd40421b69078ee83,openstack/tripleo-heat-templates,stable/ocata,I70515c5b9ce2668a684649ecd40421b69078ee83,Deploy Manila with CephMDS in scenario004,MERGED,2017-02-17 12:10:52.000000000,2017-02-17 19:14:47.000000000,2017-02-17 19:14:47.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 9003}]","[{'number': 1, 'created': '2017-02-17 12:10:52.000000000', 'files': ['ci/environments/scenario004-multinode.yaml', 'README.rst', 'ci/pingtests/scenario004-multinode.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/695efa6bd055162f3a6e805caef44e7522ab0cb0', 'message': 'Deploy Manila with CephMDS in scenario004\n\nAdds the Manila and CephMDS services into scenario004 and a few\nresources in the pingtest to test the Manila deployment.\n\nAlso adds Pacemaker to scenario004 which is needed for ManilaShare.\n\nCo-Authored-By: jprovazn@redhat.com\nChange-Id: I70515c5b9ce2668a684649ecd40421b69078ee83\nRelated-Bug: #1644784\n(cherry picked from commit db58ec86c748a99efb427a8b37ee4a514f7acdaf)\n'}]",0,435408,695efa6bd055162f3a6e805caef44e7522ab0cb0,9,4,1,3153,,,0,"Deploy Manila with CephMDS in scenario004

Adds the Manila and CephMDS services into scenario004 and a few
resources in the pingtest to test the Manila deployment.

Also adds Pacemaker to scenario004 which is needed for ManilaShare.

Co-Authored-By: jprovazn@redhat.com
Change-Id: I70515c5b9ce2668a684649ecd40421b69078ee83
Related-Bug: #1644784
(cherry picked from commit db58ec86c748a99efb427a8b37ee4a514f7acdaf)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/08/435408/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/scenario004-multinode.yaml', 'README.rst', 'ci/pingtests/scenario004-multinode.yaml']",3,695efa6bd055162f3a6e805caef44e7522ab0cb0,bug/1644784, manila_share_type: type: OS::Manila::ShareType properties: name: default driver_handles_share_servers: false manila_share: type: OS::Manila::Share properties: share_protocol: CEPHFS size: 1 ,,43,8
openstack%2Ftripleo-heat-templates~stable%2Focata~I758179182265da5160c06bb95f4c6258dc0edcd6,openstack/tripleo-heat-templates,stable/ocata,I758179182265da5160c06bb95f4c6258dc0edcd6,Automatically backup and restore Swift rings from the undercloud,MERGED,2017-02-17 01:30:55.000000000,2017-02-17 19:13:52.000000000,2017-02-17 19:13:52.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6924}]","[{'number': 1, 'created': '2017-02-17 01:30:55.000000000', 'files': ['extraconfig/tasks/swift-ring-deploy.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'extraconfig/tasks/swift-ring-update.yaml', 'puppet/puppet-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a334a1545db4f5411037ce8a2e397c7ac86daf32', 'message': 'Automatically backup and restore Swift rings from the undercloud\n\nSwift rings created or updated on the overcloud nodes will now be\nstored on the undercloud at the end of the deployment.  An\nadditional consistency check is executed before storing them,\nensuring all rings within the cluster are identical.\n\nThese rings will be retrieved (before Puppet runs) by every node\nwhen an UPDATE is executed, and by doing this will be in a\nconsistent state across the cluster.\n\nThis makes it possible to add, remove or replace nodes in an\nexisting cluster without manual operator interaction.\n\nCloses-Bug: 1609421\nDepends-On: Ic3da38cffdd993c768bdb137c17d625dff1aa372\nChange-Id: I758179182265da5160c06bb95f4c6258dc0edcd6\n(cherry picked from commit b323f8a16035549d84cdec4718380bde3d23d6c3)\n'}]",5,435191,a334a1545db4f5411037ce8a2e397c7ac86daf32,12,4,1,3153,,,0,"Automatically backup and restore Swift rings from the undercloud

Swift rings created or updated on the overcloud nodes will now be
stored on the undercloud at the end of the deployment.  An
additional consistency check is executed before storing them,
ensuring all rings within the cluster are identical.

These rings will be retrieved (before Puppet runs) by every node
when an UPDATE is executed, and by doing this will be in a
consistent state across the cluster.

This makes it possible to add, remove or replace nodes in an
existing cluster without manual operator interaction.

Closes-Bug: 1609421
Depends-On: Ic3da38cffdd993c768bdb137c17d625dff1aa372
Change-Id: I758179182265da5160c06bb95f4c6258dc0edcd6
(cherry picked from commit b323f8a16035549d84cdec4718380bde3d23d6c3)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/91/435191/1 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/tasks/swift-ring-deploy.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'extraconfig/tasks/swift-ring-update.yaml', 'puppet/puppet-steps.j2']",4,a334a1545db4f5411037ce8a2e397c7ac86daf32,bug/1609421," {% if role.name in ['Controller', 'ObjectStorage'] %} {{role.name}}SwiftRingDeploy: type: OS::TripleO::Tasks::SwiftRingDeploy properties: servers: {get_param: [servers, {{role.name}}]} {% endif %} {% if role.name in ['Controller', 'ObjectStorage'] %} {{role.name}}SwiftRingUpdate: type: OS::TripleO::Tasks::SwiftRingUpdate depends_on: {% for dep in roles %} - {{dep.name}}Deployment_Step5 {% endfor %} properties: servers: {get_param: [servers, {{role.name}}]} {% endif %}",,94,0
openstack%2Ftripleo-common~stable%2Fnewton~Ic3da38cffdd993c768bdb137c17d625dff1aa372,openstack/tripleo-common,stable/newton,Ic3da38cffdd993c768bdb137c17d625dff1aa372,Use Mistral to create Swift temporary URLs,MERGED,2017-02-17 07:47:01.000000000,2017-02-17 19:13:34.000000000,2017-02-17 19:13:34.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6968}, {'_account_id': 9712}]","[{'number': 1, 'created': '2017-02-17 07:47:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b25825bab61c3413bdfd2db48848aa056ecdf9d7', 'message': ""Use Mistral to create Swift temporary URLs\n\nThis patch consists of two parts.\n\nA new Mistral action has been added to create signed temporary URLs.\nThe method to generate temporary URLs isnt' exposed by\npython-swiftclient, therefore adding that method using it's own action.\nIt also sets the required metadata with a random key if not yet\nexisting.\n\nThe deployment workbook has been updated to create two temporary URLs\n(one PUT, one GET) that can be used during the deployment for up- and\ndownloading Swift rings to the undercloud node.\n\nRelated-Bug: 1609421\nChange-Id: Ic3da38cffdd993c768bdb137c17d625dff1aa372\n(cherry picked from commit 067049594a9e2a770c7851feb134fdcbcce8e6ce)\n""}, {'number': 2, 'created': '2017-02-17 10:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c0d18bf51c214ea43742d72d96528712d5474236', 'message': ""Use Mistral to create Swift temporary URLs\n\nThis patch consists of two parts.\n\nA new Mistral action has been added to create signed temporary URLs.\nThe method to generate temporary URLs isnt' exposed by\npython-swiftclient, therefore adding that method using it's own action.\nIt also sets the required metadata with a random key if not yet\nexisting.\n\nThe deployment workbook has been updated to create two temporary URLs\n(one PUT, one GET) that can be used during the deployment for up- and\ndownloading Swift rings to the undercloud node.\n\nRelated-Bug: 1609421\nChange-Id: Ic3da38cffdd993c768bdb137c17d625dff1aa372\n(cherry picked from commit 067049594a9e2a770c7851feb134fdcbcce8e6ce)\n""}, {'number': 3, 'created': '2017-02-17 11:18:51.000000000', 'files': ['workbooks/deployment.yaml', 'tripleo_common/tests/actions/test_swifthelper.py', 'tripleo_common/actions/swifthelper.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c79248d50d0c18f947a5fa9ebc452ebf9b49260e', 'message': ""Use Mistral to create Swift temporary URLs\n\nThis patch consists of two parts.\n\nA new Mistral action has been added to create signed temporary URLs.\nThe method to generate temporary URLs isnt' exposed by\npython-swiftclient, therefore adding that method using it's own action.\nIt also sets the required metadata with a random key if not yet\nexisting.\n\nThe deployment workbook has been updated to create two temporary URLs\n(one PUT, one GET) that can be used during the deployment for up- and\ndownloading Swift rings to the undercloud node.\n\nRelated-Bug: 1609421\nChange-Id: Ic3da38cffdd993c768bdb137c17d625dff1aa372\n(cherry picked from commit 067049594a9e2a770c7851feb134fdcbcce8e6ce)\n""}]",2,435284,c79248d50d0c18f947a5fa9ebc452ebf9b49260e,15,5,3,6968,,,0,"Use Mistral to create Swift temporary URLs

This patch consists of two parts.

A new Mistral action has been added to create signed temporary URLs.
The method to generate temporary URLs isnt' exposed by
python-swiftclient, therefore adding that method using it's own action.
It also sets the required metadata with a random key if not yet
existing.

The deployment workbook has been updated to create two temporary URLs
(one PUT, one GET) that can be used during the deployment for up- and
downloading Swift rings to the undercloud node.

Related-Bug: 1609421
Change-Id: Ic3da38cffdd993c768bdb137c17d625dff1aa372
(cherry picked from commit 067049594a9e2a770c7851feb134fdcbcce8e6ce)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/84/435284/2 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/deployment.yaml', 'tripleo_common/tests/actions/test_swifthelper.py', 'tripleo_common/actions/swifthelper.py', 'releasenotes/notes/mistral-swift-tempurl-action-ce4946a0b76db53c.yaml', 'setup.cfg']",5,b25825bab61c3413bdfd2db48848aa056ecdf9d7,bug/1609421, tripleo.swift.tempurl = tripleo_common.actions.swifthelper:SwiftTempUrlAction,,155,1
openstack%2Fnetworking-bagpipe~master~I7cbfc4ea4481a285889824a4d0c25e2be0915db0,openstack/networking-bagpipe,master,I7cbfc4ea4481a285889824a4d0c25e2be0915db0,Update reno for stable/ocata,MERGED,2017-02-17 04:35:50.000000000,2017-02-17 19:06:12.000000000,2017-02-17 19:06:12.000000000,"[{'_account_id': 3}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-02-17 04:35:50.000000000', 'files': ['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/119ac8ce5960f0700586bb0e8f52f55eca174f8a', 'message': 'Update reno for stable/ocata\n\nChange-Id: I7cbfc4ea4481a285889824a4d0c25e2be0915db0\n'}]",0,435234,119ac8ce5960f0700586bb0e8f52f55eca174f8a,9,2,1,22816,,,0,"Update reno for stable/ocata

Change-Id: I7cbfc4ea4481a285889824a4d0c25e2be0915db0
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/34/435234/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/ocata.rst', 'releasenotes/source/index.rst']",2,119ac8ce5960f0700586bb0e8f52f55eca174f8a,reno-ocata, ocata,,7,0
openstack%2Foctavia~master~Id44dbb133f21d77f6596c34b7db60ee5b079ae52,openstack/octavia,master,Id44dbb133f21d77f6596c34b7db60ee5b079ae52,Remove unused logging import,MERGED,2017-02-17 06:41:15.000000000,2017-02-17 18:55:20.000000000,2017-02-17 18:50:23.000000000,"[{'_account_id': 3}, {'_account_id': 11628}, {'_account_id': 14591}, {'_account_id': 16923}]","[{'number': 1, 'created': '2017-02-17 06:41:15.000000000', 'files': ['octavia/tests/tempest/v1/scenario/test_load_balancer_tree_minimal.py', 'octavia/controller/worker/tasks/lifecycle_tasks.py', 'octavia/api/v1/controllers/quotas.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/92af1dfb2891fbcd2ec8b3195b487dda73c092bf', 'message': 'Remove unused logging import\n\nChange-Id: Id44dbb133f21d77f6596c34b7db60ee5b079ae52\n'}]",0,435272,92af1dfb2891fbcd2ec8b3195b487dda73c092bf,9,4,1,19935,,,0,"Remove unused logging import

Change-Id: Id44dbb133f21d77f6596c34b7db60ee5b079ae52
",git fetch https://review.opendev.org/openstack/octavia refs/changes/72/435272/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/tests/tempest/v1/scenario/test_load_balancer_tree_minimal.py', 'octavia/controller/worker/tasks/lifecycle_tasks.py', 'octavia/api/v1/controllers/quotas.py']",3,92af1dfb2891fbcd2ec8b3195b487dda73c092bf,,,import logging LOG = logging.getLogger(__name__),0,10
openstack%2Fcongress~stable%2Focata~I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f,openstack/congress,stable/ocata,I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f,Exclude atomic rule from dependency graph,MERGED,2017-02-17 08:10:34.000000000,2017-02-17 18:44:18.000000000,2017-02-17 18:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 18591}]","[{'number': 1, 'created': '2017-02-17 08:10:34.000000000', 'files': ['congress/tests/policy_engines/test_agnostic.py', 'congress/datalog/compile.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/d635bad1ae10d84e8542916d18af573d4b1d1280', 'message': 'Exclude atomic rule from dependency graph\n\nDependency graph used by agnostic excludes positive literals\nof type compile.Literal. But when a policy is deleted, the facts\nin the policy are deleted as atomic rules of type compile.Rule. As\na result, some nodes in the dependency graph are prematurely deleted\nbecause the deleting of facts (type compile.Rule) via policy delete\ndecreased ref counters that had not been correspondingly increased\nby the adding of those same facts (type compile.Literal). When a\ndependency graph is thus corrupted, congress gives Internal Server\nError on all future attempts to add/delete/sync rules.\n\nThis patch fixes the problem by having agnostic treat an atomic rule\n(type compile.Rule) the same way it treats an atom\n(type compile.Literal) in the dependency graph -- ignore both.\n\nCloses-Bug: 1662809\n\nChange-Id: I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f\n'}]",0,435296,d635bad1ae10d84e8542916d18af573d4b1d1280,9,3,1,18591,,,0,"Exclude atomic rule from dependency graph

Dependency graph used by agnostic excludes positive literals
of type compile.Literal. But when a policy is deleted, the facts
in the policy are deleted as atomic rules of type compile.Rule. As
a result, some nodes in the dependency graph are prematurely deleted
because the deleting of facts (type compile.Rule) via policy delete
decreased ref counters that had not been correspondingly increased
by the adding of those same facts (type compile.Literal). When a
dependency graph is thus corrupted, congress gives Internal Server
Error on all future attempts to add/delete/sync rules.

This patch fixes the problem by having agnostic treat an atomic rule
(type compile.Rule) the same way it treats an atom
(type compile.Literal) in the dependency graph -- ignore both.

Closes-Bug: 1662809

Change-Id: I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f
",git fetch https://review.opendev.org/openstack/congress refs/changes/96/435296/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy_engines/test_agnostic.py', 'congress/datalog/compile.py']",2,d635bad1ae10d84e8542916d18af573d4b1d1280,bug/1662809, if is_atom_like(formula):def is_atom_rule(x): return is_regular_rule(x) and len(x.body) == 0 and is_literal(x.heads[0]) def is_literal_rule(x): return is_regular_rule(x) and len(x.body) == 0 and is_literal(x.heads[0]) def is_atom_like(x): return is_atom(x) or is_atom_rule(x) def is_literal_like(x): return is_literal(x) or is_literal_rule(x) , if is_atom(formula):,37,1
openstack%2Fheat~stable%2Fmitaka~I90979e9fe889deb1ef322ab0af31b9e079b77747,openstack/heat,stable/mitaka,I90979e9fe889deb1ef322ab0af31b9e079b77747,Use region_name when creating keystone client,MERGED,2017-02-07 05:00:20.000000000,2017-02-17 18:41:48.000000000,2017-02-17 18:41:48.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 6577}, {'_account_id': 8289}]","[{'number': 1, 'created': '2017-02-07 05:00:20.000000000', 'files': ['heat/tests/clients/test_heat_client.py', 'heat/common/heat_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/674b36f2356103805fe2120e03d92e925918b747', 'message': 'Use region_name when creating keystone client\n\nWhen creating trust and stack domain user/project, we\ncreate a keystone client without the region_name. This\nmay not work in a multi-region environment.\n\nChange-Id: I90979e9fe889deb1ef322ab0af31b9e079b77747\nCloses-Bug: #1661594\n(cherry picked from commit a21a29c8479e18e13df4be350743b169c311eb67)\n'}]",0,430061,674b36f2356103805fe2120e03d92e925918b747,14,4,1,8833,,,0,"Use region_name when creating keystone client

When creating trust and stack domain user/project, we
create a keystone client without the region_name. This
may not work in a multi-region environment.

Change-Id: I90979e9fe889deb1ef322ab0af31b9e079b77747
Closes-Bug: #1661594
(cherry picked from commit a21a29c8479e18e13df4be350743b169c311eb67)
",git fetch https://review.opendev.org/openstack/heat refs/changes/61/430061/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/clients/test_heat_client.py', 'heat/common/heat_keystoneclient.py']",2,674b36f2356103805fe2120e03d92e925918b747,bug/1661594," def region_name(self): return self.context.region_name or cfg.CONF.region_name_for_services @property auth=self.domain_admin_auth, region_name=self.region_name) auth=self.context.auth_plugin, region_name=self.region_name)", auth=self.domain_admin_auth) auth=self.context.auth_plugin),14,5
openstack%2Fproject-config~master~I73683e071c579772b2c734891bee9bceb36e68fc,openstack/project-config,master,I73683e071c579772b2c734891bee9bceb36e68fc,Remove liberty branch conditions from some projects,MERGED,2017-02-17 08:16:05.000000000,2017-02-17 18:28:49.000000000,2017-02-17 18:28:49.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-17 08:16:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d2f0b844ab0ba68edf0fc0b9b08625c724420bd4', 'message': 'Remove liberty branch conditions from some projects\n\noslo.messaging and openstack-ansible do not have a stable/liberty or a\nliberty branch anymore, these are EOLed.\n\nRemove liberty from the branch conditions.\n\nChange-Id: I73683e071c579772b2c734891bee9bceb36e68fc\n'}, {'number': 2, 'created': '2017-02-17 18:05:25.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b5046bf385fca204278a8dba89ceb9d427b865be', 'message': 'Remove liberty branch conditions from some projects\n\noslo.messaging and openstack-ansible do not have a stable/liberty or a\nliberty branch anymore, these are EOLed.\n\nRemove liberty from the branch conditions.\n\nChange-Id: I73683e071c579772b2c734891bee9bceb36e68fc\n'}]",0,435299,b5046bf385fca204278a8dba89ceb9d427b865be,14,4,2,6547,,,0,"Remove liberty branch conditions from some projects

oslo.messaging and openstack-ansible do not have a stable/liberty or a
liberty branch anymore, these are EOLed.

Remove liberty from the branch conditions.

Change-Id: I73683e071c579772b2c734891bee9bceb36e68fc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/99/435299/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,d2f0b844ab0ba68edf0fc0b9b08625c724420bd4,liberty-eol, branch: ^stable/(mitaka|newton)$ branch: ^(?!stable/(mitaka|newton)).*$ branch: ^(?!stable/(mitaka|newton)).*$ branch: ^(?!stable/(mitaka|newton)).*$ branch: ^(?!stable/(mitaka|newton)).*$ branch: ^(?!stable/(mitaka|newton)).*$ branch: ^(?!stable/(mitaka|newton)).*$, branch: ^stable/(liberty|mitaka|newton)$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$ branch: ^(?!(liberty|stable/(mitaka|newton))).*$,7,7
openstack%2Fopenstack-ansible-tests~stable%2Focata~Id66582a8c684ab9473623debc2fd72801197d6f5,openstack/openstack-ansible-tests,stable/ocata,Id66582a8c684ab9473623debc2fd72801197d6f5,Reduce MariaDB buffer size to 256M for tests,MERGED,2017-02-17 16:42:55.000000000,2017-02-17 18:19:51.000000000,2017-02-17 18:19:51.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-17 16:42:55.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/b90fbae837680d7a3b53d29eec662b8c126cef7d', 'message': ""Reduce MariaDB buffer size to 256M for tests\n\nThis helps reduce the frequency of out-of-memory errors\nwhen executing tests. We don't need a large buffer, we\njust want things to work.\n\nChange-Id: Id66582a8c684ab9473623debc2fd72801197d6f5\n(cherry picked from commit e3d2caabe5b113c84445a3e36cd6bc5379c5fd61)\n""}]",0,435522,b90fbae837680d7a3b53d29eec662b8c126cef7d,7,3,1,6816,,,0,"Reduce MariaDB buffer size to 256M for tests

This helps reduce the frequency of out-of-memory errors
when executing tests. We don't need a large buffer, we
just want things to work.

Change-Id: Id66582a8c684ab9473623debc2fd72801197d6f5
(cherry picked from commit e3d2caabe5b113c84445a3e36cd6bc5379c5fd61)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/22/435522/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,b90fbae837680d7a3b53d29eec662b8c126cef7d,,galera_innodb_buffer_pool_size: 256M,galera_innodb_buffer_pool_size: 512M,1,1
openstack%2Fopenstack-manuals~master~I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d,openstack/openstack-manuals,master,I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d,[obs-install] Add note for overried configuration,MERGED,2017-02-17 17:07:09.000000000,2017-02-17 18:10:50.000000000,2017-02-17 18:10:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 8803}, {'_account_id': 10607}, {'_account_id': 19298}]","[{'number': 1, 'created': '2017-02-17 17:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6dc14647382d0d146c05787e6088de576a032397', 'message': '[obs-install] Add note for overried configuration\n\nSUSE is shipping OpenStack packages with default upstream configuration\nfiles and uses override files in `../$SERVICE.conf.d/` to configure a\nservice. This change adds a note to the identity installation\ninstructions.\n\nChange-Id: I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d\n'}, {'number': 2, 'created': '2017-02-17 17:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca048688564144348b9eca65739064a3b60a9379', 'message': '[obs-install] Add note for overried configuration\n\nSUSE is shipping OpenStack packages with default upstream configuration\nfiles and uses override files in `../$SERVICE.conf.d/` to configure a\nservice. This change adds a note to the identity installation\ninstructions.\n\nChange-Id: I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d\n'}, {'number': 3, 'created': '2017-02-17 17:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0c20f1dbc8af19eb28bba8687a58a862e452e6ea', 'message': '[obs-install] Add note for overried configuration\n\nSUSE is shipping OpenStack packages with default upstream configuration\nfiles and uses override files in `../$SERVICE.conf.d/` to configure a\nservice. This change adds notes to the installation instructions to\npoint this out.\n\nChange-Id: I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d\n'}, {'number': 4, 'created': '2017-02-17 17:24:19.000000000', 'files': ['doc/install-guide/source/keystone-install.rst', 'doc/install-guide/source/glance-install.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/87358707422f428f65e8fb9e5048fd560b0fe2a5', 'message': '[obs-install] Add note for overried configuration\n\nSUSE is shipping OpenStack packages with default upstream configuration\nfiles and uses override files in `../$SERVICE.conf.d/` to configure a\nservice. This change adds notes to the installation instructions to\npoint this out.\n\nChange-Id: I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d\n'}]",7,435536,87358707422f428f65e8fb9e5048fd560b0fe2a5,16,5,4,19298,,,0,"[obs-install] Add note for overried configuration

SUSE is shipping OpenStack packages with default upstream configuration
files and uses override files in `../$SERVICE.conf.d/` to configure a
service. This change adds notes to the installation instructions to
point this out.

Change-Id: I2da33760e5a29dbb565e5ee7dd020d9c86b78e0d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/36/435536/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/keystone-install.rst'],1,6dc14647382d0d146c05787e6088de576a032397,obs_keystone_install,".. only:: obs .. note:: Starting with the Newton release, SUSE OpenStack packages are shipping with the upstream default configuration file, e.g. ``/etc/keystone/keystone.conf`` with customizations in ``/etc/keystone/keystone.conf.d/010-keystone.conf``. While the following instructions modify the default configuration file, adding a new file in ``/etc/keystone/keystone.conf.d`` will achieve the same result. .. endonly ",,14,0
openstack%2Fproject-config~master~I921f2e5903ea6d308ca51ffb1ff3c74cab5a5ba1,openstack/project-config,master,I921f2e5903ea6d308ca51ffb1ff3c74cab5a5ba1,WIP: Remove now unused db-jobs,ABANDONED,2017-02-10 19:21:52.000000000,2017-02-17 18:10:27.000000000,,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2017-02-10 19:21:52.000000000', 'files': ['jenkins/jobs/python-jobs.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/663c0ab81071a444bca2f55609de2963ce7ffcde', 'message': 'WIP: Remove now unused db-jobs\n\nNo project uses the db jobs anymore, remove the templates and\njob-groups.\n\nWIP since some of these are still in use. Just pushed to not forget this\nfinal step.\n\nChange-Id: I921f2e5903ea6d308ca51ffb1ff3c74cab5a5ba1\n'}]",0,432430,663c0ab81071a444bca2f55609de2963ce7ffcde,5,2,1,6547,,,0,"WIP: Remove now unused db-jobs

No project uses the db jobs anymore, remove the templates and
job-groups.

WIP since some of these are still in use. Just pushed to not forget this
final step.

Change-Id: I921f2e5903ea6d308ca51ffb1ff3c74cab5a5ba1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/30/432430/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/python-jobs.yaml', 'zuul/layout.yaml']",2,663c0ab81071a444bca2f55609de2963ce7ffcde,test-setup,," # Invokes the same targets as python-jobs with one change: # python27-db is used instead of python27. The job # python27-db sets up databases. - name: python-db-jobs check: - 'gate-{name}-docs-ubuntu-trusty' - 'gate-{name}-pep8-ubuntu-trusty' - 'gate-{name}-python27-db-ubuntu-trusty' - 'gate-{name}-docs-ubuntu-xenial' - 'gate-{name}-pep8-ubuntu-xenial' - 'gate-{name}-python27-db-ubuntu-xenial' gate: - 'gate-{name}-docs-ubuntu-trusty' - 'gate-{name}-pep8-ubuntu-trusty' - 'gate-{name}-python27-db-ubuntu-trusty' - 'gate-{name}-docs-ubuntu-xenial' - 'gate-{name}-pep8-ubuntu-xenial' - 'gate-{name}-python27-db-ubuntu-xenial' post: - '{name}-branch-tarball' # Invokes the same targets as python34-jobs, but sets up databases. - name: python34-db-jobs check: - 'gate-{name}-python34-db' gate: - 'gate-{name}-python34-db' - name: python35-jobs-nv check: - 'gate-{name}-python35-nv' # Invokes the same targets as python35-jobs-nv, but sets up databases. - name: python35-db-jobs-nv check: - 'gate-{name}-python35-db-nv' # Invokes the same targets as python35-jobs, but sets up databases. - name: python35-db-jobs check: - 'gate-{name}-python35-db' gate: - 'gate-{name}-python35-db' - name: periodic-db-mitaka periodic-stable: - 'periodic-{name}-docs-mitaka' - 'periodic-{name}-python27-db-mitaka' - name: periodic-db-newton periodic-stable: - 'periodic-{name}-docs-newton' - 'periodic-{name}-python27-db-newton' - name: periodic-db-ocata periodic-stable: - 'periodic-{name}-docs-ocata' - 'periodic-{name}-python27-db-ocata' ",0,282
openstack%2Fopenstack-ansible-security~master~I544cb4bffe7e41d0614ebea6a47c91e617647866,openstack/openstack-ansible-security,master,I544cb4bffe7e41d0614ebea6a47c91e617647866,"Only enable ssh, not start",MERGED,2017-02-17 15:50:47.000000000,2017-02-17 18:07:31.000000000,2017-02-17 16:55:57.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 13095}]","[{'number': 1, 'created': '2017-02-17 15:50:47.000000000', 'files': ['tasks/rhel7stig/sshd.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-security/commit/2e5fe3b038f46002ef38c0b21f1a49baac20bc6e', 'message': ""Only enable ssh, not start\n\nThere is an unusual issue occurring when the ssh daemon is asked to\nstart when it is already running. This patch ensures that the ssh\ndaemon is running but it doesn't try to start it. The handler will\ntake care of restarting sshd later on in the role.\n\nChange-Id: I544cb4bffe7e41d0614ebea6a47c91e617647866\n""}]",0,435501,2e5fe3b038f46002ef38c0b21f1a49baac20bc6e,10,3,1,538,,,0,"Only enable ssh, not start

There is an unusual issue occurring when the ssh daemon is asked to
start when it is already running. This patch ensures that the ssh
daemon is running but it doesn't try to start it. The handler will
take care of restarting sshd later on in the role.

Change-Id: I544cb4bffe7e41d0614ebea6a47c91e617647866
",git fetch https://review.opendev.org/openstack/openstack-ansible-security refs/changes/01/435501/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/rhel7stig/sshd.yml'],1,2e5fe3b038f46002ef38c0b21f1a49baac20bc6e,sshd-fix-start,- name: Ensure sshd is enabled at boot time,- name: Ensure sshd is running and enabled state: started,1,2
openstack%2Fpycadf~master~I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4,openstack/pycadf,master,I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4,Make `is_valid` more flexible with uuid validation,MERGED,2017-02-03 02:25:51.000000000,2017-02-17 18:06:41.000000000,2017-02-17 18:06:41.000000000,"[{'_account_id': 3}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 20466}, {'_account_id': 21420}]","[{'number': 1, 'created': '2017-02-03 02:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/3c5cdd08da496eb9cfc883dd066acc241eff9076', 'message': ""Allow multiple joined uuids to be considered valid\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo IDs together. This causes issues with pycadf validation and\ncaused the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 2, 'created': '2017-02-03 02:28:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/ef858713dbd51adb23d0cf0d63491ec4692220c4', 'message': ""Allow multiple joined uuids to be considered valid\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo IDs together. This causes issues with pycadf validation and\ncaused the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Added offending value to printed warning\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 3, 'created': '2017-02-03 16:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/e58a95fc1d107c17035022fad532290effb8ac29', 'message': ""Make `is_valid` more flexible with uuid validation\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo valid uuids together. This causes issues with pycadf validation\nand causes the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Added offending value to printed warning\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words and extra characters that\ncan be present in a valid uuid according to [2]\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n[2] https://docs.python.org/2/library/uuid.html\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 4, 'created': '2017-02-03 18:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/7a94da19821ae82caf6c881da4000d5f16308ffc', 'message': ""Make `is_valid` more flexible with uuid validation\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo valid uuids together. This causes issues with pycadf validation\nand causes the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Added offending value to printed warning\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words and extra characters that\ncan be present in a valid uuid according to [2]\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n[2] https://docs.python.org/2/library/uuid.html\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 5, 'created': '2017-02-06 19:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/02155e1055ece69ca09f66fa54d4e9f7ffe34f02', 'message': ""Make `is_valid` more flexible with uuid validation\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo valid uuids together. This causes issues with pycadf validation\nand causes the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Added offending value to printed warning\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words and extra characters that\ncan be present in a valid uuid according to [2]\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n[2] https://docs.python.org/2/library/uuid.html\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}, {'number': 6, 'created': '2017-02-06 23:01:17.000000000', 'files': ['pycadf/identifier.py', 'pycadf/tests/test_cadf_spec.py'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/a4a8f46248ab1d1a68d422276df21f75b24be84c', 'message': ""Make `is_valid` more flexible with uuid validation\n\nIn keystone, multiple domain ids are handled by concatenating\ntwo valid uuids together. This causes issues with pycadf validation\nand causes the following warning to be thrown:\n\nwarnings.warn('Invalid uuid. To ensure interoperability, identifiers '\n'should be a valid uuid.')\n\nThis appears throughout the testing logs while running keystone tests\nand there is a current attempt to remove most/all invalid uuids to\neliminate this warning [0]. However due to the multiple domain id\nissue, this cannot be solved in keystone alone.\n\nThe idea to allow multiple uuids that were joined together was\nmentioned before in a previous attempt to solve this issue [1].\n\nThis change:\n- Allows 2 or more concatenated uuids to be considered valid without\nemitting a warning\n- Cleaned up the list of words that are exceptions for validation\n- Added 'default' to list of valid words in exception list\n- Added offending value to printed warning\n- Broke up test_identifiers for better clarity about which tests\nwere valid. This also solves the issue of `warning_mock.called` always\nbeing `True` once an invalid uuid of type string was checked within\ntest_identifier\n- Added test for valid exception words and extra characters that\ncan be present in a valid uuid according to [2]\n\n[0] https://bugs.launchpad.net/keystone/+bug/1659053\n[1] https://bugs.launchpad.net/keystone/+bug/1521844\n[2] https://docs.python.org/2/library/uuid.html\n\nCo-Authored-By: Tin Lam <tinlam@gmail.com>\n\nPartial-Bug: #1659053\nChange-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4\n""}]",12,428543,a4a8f46248ab1d1a68d422276df21f75b24be84c,30,6,6,21420,,,0,"Make `is_valid` more flexible with uuid validation

In keystone, multiple domain ids are handled by concatenating
two valid uuids together. This causes issues with pycadf validation
and causes the following warning to be thrown:

warnings.warn('Invalid uuid. To ensure interoperability, identifiers '
'should be a valid uuid.')

This appears throughout the testing logs while running keystone tests
and there is a current attempt to remove most/all invalid uuids to
eliminate this warning [0]. However due to the multiple domain id
issue, this cannot be solved in keystone alone.

The idea to allow multiple uuids that were joined together was
mentioned before in a previous attempt to solve this issue [1].

This change:
- Allows 2 or more concatenated uuids to be considered valid without
emitting a warning
- Cleaned up the list of words that are exceptions for validation
- Added 'default' to list of valid words in exception list
- Added offending value to printed warning
- Broke up test_identifiers for better clarity about which tests
were valid. This also solves the issue of `warning_mock.called` always
being `True` once an invalid uuid of type string was checked within
test_identifier
- Added test for valid exception words and extra characters that
can be present in a valid uuid according to [2]

[0] https://bugs.launchpad.net/keystone/+bug/1659053
[1] https://bugs.launchpad.net/keystone/+bug/1521844
[2] https://docs.python.org/2/library/uuid.html

Co-Authored-By: Tin Lam <tinlam@gmail.com>

Partial-Bug: #1659053
Change-Id: I58bba04c21c2d24fd37850c9ecc6fac99deb3fc4
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/43/428543/6 && git format-patch -1 --stdout FETCH_HEAD,"['pycadf/identifier.py', 'pycadf/tests/test_cadf_spec.py']",2,3c5cdd08da496eb9cfc883dd066acc241eff9076,bug/1659053," def test_identifier_generated_uuid(self, warning_mock): @mock.patch('pycadf.identifier.warnings.warn') def test_identifier_empty_string_is_invalid(self, warning_mock): # empty string self.assertFalse(identifier.is_valid('')) self.assertFalse(warning_mock.called) @mock.patch('pycadf.identifier.warnings.warn') def test_identifier_any_string_is_invalid(self, warning_mock): @mock.patch('pycadf.identifier.warnings.warn') def test_identifier_joined_uuids_are_valid(self, warning_mock): # multiple uuids joined together long_128_uuid = ('3adce28e67e44544a5a9d5f1ab54f578a86d310aac3a465e9d' 'd2693a78b45c0e42dce28e67e44544a5a9d5f1ab54f578a86d' '310aac3a465e9dd2693a78b45c0e') self.assertTrue(identifier.is_valid(long_128_uuid)) self.assertFalse(warning_mock.called) @mock.patch('pycadf.identifier.warnings.warn') def test_identifier_long_nonjoined_uuid_is_invalid(self, warning_mock): # long uuid not of size % 32 char_42_id = '3adce28e67e44544a5a9d5f1ab54f578a86d310aac' self.assertTrue(identifier.is_valid(char_42_id)) self.assertTrue(warning_mock.called) @mock.patch('pycadf.identifier.warnings.warn') def test_identifier_specific_exceptions_are_valid(self, warning_mock): # uuid exceptions for value in identifier.VALID_EXCEPTIONS: self.assertTrue(identifier.is_valid(value)) self.assertFalse(warning_mock.called) "," def test_identifier(self, warning_mock): # empty string self.assertFalse(identifier.is_valid(''))",55,7
openstack%2Fopenstack-ansible-tests~stable%2Focata~Ie0fde213b5850a0c011c09ae2e568208471b15a5,openstack/openstack-ansible-tests,stable/ocata,Ie0fde213b5850a0c011c09ae2e568208471b15a5,"Revert ""Revert swift git install branch to master""",MERGED,2017-02-17 16:14:03.000000000,2017-02-17 18:04:17.000000000,2017-02-17 18:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}]","[{'number': 1, 'created': '2017-02-17 16:14:03.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/b7a242c9026bd4da97e3ff6c54446e91e8206306', 'message': 'Revert ""Revert swift git install branch to master""\n\nThis reverts commit bd7e9e2c251f6b719f816665b42d34141742652b.\n\nChange-Id: Ie0fde213b5850a0c011c09ae2e568208471b15a5\n'}]",0,435513,b7a242c9026bd4da97e3ff6c54446e91e8206306,6,3,1,6816,,,0,"Revert ""Revert swift git install branch to master""

This reverts commit bd7e9e2c251f6b719f816665b42d34141742652b.

Change-Id: Ie0fde213b5850a0c011c09ae2e568208471b15a5
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/13/435513/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,b7a242c9026bd4da97e3ff6c54446e91e8206306,create-ocata,swift_git_install_branch: stable/ocata,swift_git_install_branch: master,1,1
openstack%2Fkolla~master~I5e0cfe138198b37328c7a7f56413f48999118cfa,openstack/kolla,master,I5e0cfe138198b37328c7a7f56413f48999118cfa,Re-enable grafana gpgcheck,MERGED,2017-02-15 08:15:19.000000000,2017-02-17 18:02:03.000000000,2017-02-17 18:02:03.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 16620}]","[{'number': 1, 'created': '2017-02-15 08:15:19.000000000', 'files': ['docker/base/grafana.repo'], 'web_link': 'https://opendev.org/openstack/kolla/commit/257b14395cbee80ca04db4d930544750e55889d8', 'message': 'Re-enable grafana gpgcheck\n\ngrafana package is signed now.\n\nChange-Id: I5e0cfe138198b37328c7a7f56413f48999118cfa\nCloses-Bug: #1664272\n'}]",0,434129,257b14395cbee80ca04db4d930544750e55889d8,9,3,1,7488,,,0,"Re-enable grafana gpgcheck

grafana package is signed now.

Change-Id: I5e0cfe138198b37328c7a7f56413f48999118cfa
Closes-Bug: #1664272
",git fetch https://review.opendev.org/openstack/kolla refs/changes/29/434129/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/grafana.repo'],1,257b14395cbee80ca04db4d930544750e55889d8,bug/1664272,gpgcheck=1,"# TODO(jeffrey4l), enable gpg check when grafana gpgkey is OK. gpgcheck=0",1,2
openstack%2Fopenstack-ansible-lxc_hosts~stable%2Focata~Id2137fcff787fdbe043cb158b44aee63176a813b,openstack/openstack-ansible-lxc_hosts,stable/ocata,Id2137fcff787fdbe043cb158b44aee63176a813b,CentOS Remove old code for lxc-source-install,MERGED,2017-02-17 17:29:19.000000000,2017-02-17 18:01:12.000000000,2017-02-17 18:01:12.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 13095}]","[{'number': 1, 'created': '2017-02-17 17:29:19.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/4de0af71c22ae05eabd2437cfb83d8ee348bac02', 'message': 'CentOS Remove old code for lxc-source-install\n\nChange-Id: Id2137fcff787fdbe043cb158b44aee63176a813b\n(cherry picked from commit d289677aee6441078f7a4008d4baeb3f73124849)\n'}]",0,435544,4de0af71c22ae05eabd2437cfb83d8ee348bac02,7,3,1,6816,,,0,"CentOS Remove old code for lxc-source-install

Change-Id: Id2137fcff787fdbe043cb158b44aee63176a813b
(cherry picked from commit d289677aee6441078f7a4008d4baeb3f73124849)
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/44/435544/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,4de0af71c22ae05eabd2437cfb83d8ee348bac02,clean-up-old-lxc-install,,"lxc_download_url: ""https://linuxcontainers.org/downloads/lxc/lxc-2.0.6.tar.gz"" lxc_sha256sum: ""7c292cd0055dac1a0e6fbb6a7740fd12b6ffb204603c198faf37c11c9d6dcd7a""lxc_hosts_pip_install_options: > --global-option=build_ext --global-option=""-L/opt/lxc_embedded/x86_64-linux-gnu/"" --global-option=""-I/opt/lxc_embedded/include/"" ",0,7
openstack%2Fkolla-kubernetes~master~I7d6cbc3c5e9888f79a9ba96e630efc7a3b2e4bda,openstack/kolla-kubernetes,master,I7d6cbc3c5e9888f79a9ba96e630efc7a3b2e4bda,Stagger mariadb / rabbitmq start to avoid cross storage locks,MERGED,2017-02-16 23:41:12.000000000,2017-02-17 18:00:51.000000000,2017-02-17 18:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 17666}, {'_account_id': 19384}, {'_account_id': 24992}]","[{'number': 1, 'created': '2017-02-16 23:41:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/e094ee127d6d1b0a4b614b2532de988e9512fc80', 'message': 'Stagger mariadb / rabbitmq start to avoid cross storage locks\n\nWhen starting mariadb and rabbitmq at the same time using ceph\nstorage it looked like there was a race condition that could\ncause the bring up of these services to hang.  After making\nthe change to bring up mariadb / memcache, wait, and then\nstart up rabbitmq this issue seems to be gone after extensive\ntesting.\n\nChange-Id: I7d6cbc3c5e9888f79a9ba96e630efc7a3b2e4bda\n'}, {'number': 2, 'created': '2017-02-16 23:41:57.000000000', 'files': ['tests/bin/ceph_workflow_service.sh'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/8f474db65e8f07a226b2c3e9e8940648a5266f67', 'message': 'Stagger mariadb / rabbitmq start to avoid cross storage locks\n\nWhen starting mariadb and rabbitmq at the same time using ceph\nstorage it looked like there was a race condition that could\ncause the bring up of these services to hang.  After making\nthe change to bring up mariadb / memcache, wait, and then\nstart up rabbitmq this issue seems to be gone after extensive\ntesting.\n\nChange-Id: I7d6cbc3c5e9888f79a9ba96e630efc7a3b2e4bda\n'}]",0,435151,8f474db65e8f07a226b2c3e9e8940648a5266f67,17,5,2,16520,,,0,"Stagger mariadb / rabbitmq start to avoid cross storage locks

When starting mariadb and rabbitmq at the same time using ceph
storage it looked like there was a race condition that could
cause the bring up of these services to hang.  After making
the change to bring up mariadb / memcache, wait, and then
start up rabbitmq this issue seems to be gone after extensive
testing.

Change-Id: I7d6cbc3c5e9888f79a9ba96e630efc7a3b2e4bda
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/51/435151/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/bin/ceph_workflow_service.sh'],1,e094ee127d6d1b0a4b614b2532de988e9512fc80,fix_ceph_access_issue,"wait_for_pods kolla mariadb,memcached running,succeeded wait_for_pods kolla rabbitmq running,succeededexit 0 ","wait_for_pods kolla mariadb,memcached,rabbitmq running,succeeded",5,1
openstack%2Fopenstack-ansible-os_monasca~stable%2Focata~Ia7dfb8f87bd65ccc20564b31bad991b4136a9815,openstack/openstack-ansible-os_monasca,stable/ocata,Ia7dfb8f87bd65ccc20564b31bad991b4136a9815,Update repo for stable/ocata,MERGED,2017-02-08 11:03:10.000000000,2017-02-17 17:59:48.000000000,2017-02-17 17:59:48.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 14805}, {'_account_id': 16168}]","[{'number': 1, 'created': '2017-02-08 11:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca/commit/545babc743658f2f26b3b13bc6837465707716a7', 'message': 'Update repo for stable/ocata\n\nThere are no new tags for the 3rd party repositories, so for now we will\nhave to use master branch. This should be fixed once we can get tags\nor branches created for these repositories.\n\nChange-Id: Ia7dfb8f87bd65ccc20564b31bad991b4136a9815\n'}, {'number': 2, 'created': '2017-02-16 17:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca/commit/bce32a3294438886710e633e2bde7a731e9d2ce5', 'message': 'Update repo for stable/ocata\n\nThere are no new tags for the 3rd party repositories, so for now we will\nhave to use master branch. This should be fixed once we can get tags\nor branches created for these repositories.\n\nChange-Id: Ia7dfb8f87bd65ccc20564b31bad991b4136a9815\n'}, {'number': 3, 'created': '2017-02-17 16:45:26.000000000', 'files': ['tests/ansible-role-requirements.yml', 'defaults/main.yml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca/commit/a50afe40b85ae5d491bbcaa84fcdd78692d81f35', 'message': 'Update repo for stable/ocata\n\nThere are no new tags for the 3rd party repositories, so for now we will\nhave to use master branch. This should be fixed once we can get tags\nor branches created for these repositories.\n\nAdditionally, the mirror that is used by default in the upstream\nansible-kafka role is not currently working, we can overwrite this with\na var in the meta/main.yml file.\n\nChange-Id: Ia7dfb8f87bd65ccc20564b31bad991b4136a9815\n'}]",0,430767,a50afe40b85ae5d491bbcaa84fcdd78692d81f35,27,7,3,2799,,,0,"Update repo for stable/ocata

There are no new tags for the 3rd party repositories, so for now we will
have to use master branch. This should be fixed once we can get tags
or branches created for these repositories.

Additionally, the mirror that is used by default in the upstream
ansible-kafka role is not currently working, we can overwrite this with
a var in the meta/main.yml file.

Change-Id: Ia7dfb8f87bd65ccc20564b31bad991b4136a9815
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_monasca refs/changes/67/430767/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', 'tox.ini', 'defaults/main.yml']",3,545babc743658f2f26b3b13bc6837465707716a7,create-ocata,monasca_api_git_install_branch: stable/ocatamonasca_log_api_git_install_branch: stable/ocatamonasca_ceilometer_git_install_branch: stable/ocatamonasca_common_git_install_branch: stable/ocatamonasca_thresh_git_install_branch: stable/ocatamonasca_transform_git_install_branch: stable/ocatamonasca_notification_git_install_branch: stable/ocatamonasca_persister_git_install_branch: stable/ocatamonasca_python_client_git_install_branch: stable/ocata,monasca_api_git_install_branch: mastermonasca_log_api_git_install_branch: mastermonasca_ceilometer_git_install_branch: mastermonasca_common_git_install_branch: mastermonasca_thresh_git_install_branch: mastermonasca_transform_git_install_branch: mastermonasca_notification_git_install_branch: mastermonasca_persister_git_install_branch: mastermonasca_python_client_git_install_branch: master,26,26
openstack%2Frequirements~stable%2Fmitaka~I34ae312f6e92787c9724f14d5b37e7965ff0d5eb,openstack/requirements,stable/mitaka,I34ae312f6e92787c9724f14d5b37e7965ff0d5eb,Add mitaka tripleo-common to requirements,MERGED,2017-01-17 21:50:34.000000000,2017-02-17 17:55:02.000000000,2017-02-17 17:55:02.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4978}, {'_account_id': 5638}, {'_account_id': 7065}, {'_account_id': 9317}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 13404}]","[{'number': 1, 'created': '2017-01-17 21:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/01df1ced70a401fa2efcb8f15b900491b173c773', 'message': ""Add mitaka tripleo-common to requirements\n\nTripleO did some bad things in mitaka with the requirements files.\nThe unit tests in some TripleO projects are now broken because they\nare uncapped, but we can't start using upper-constraints because\nthe aforementioned bad things include direct dependencies on a git\nrepo instead of a released package.  To fix this, I've pushed\nI1c219a3547ca48e5c4a649441632eabc326081f9 but it fails the\nrequirements job because tripleo-common was not even in g-r in the\nmitaka release.\n\nAccording to [1], tripleo-common was 2.1.0 for mitaka, so for the\nsake of global-requirements we would want to use releases between\n2.0.0 and 3.0.0.\n\n1: https://github.com/openstack/releases/blob/master/deliverables/mitaka/tripleo-common.yaml\n\nChange-Id: I34ae312f6e92787c9724f14d5b37e7965ff0d5eb\nRelated-Bug: 1656871\n""}, {'number': 2, 'created': '2017-01-19 11:04:18.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ba5d397da32088fec161c611a463018332f70e2e', 'message': ""Add mitaka tripleo-common to requirements\n\nTripleO did some bad things in mitaka with the requirements files.\nThe unit tests in some TripleO projects are now broken because they\nare uncapped, but we can't start using upper-constraints because\nthe aforementioned bad things include direct dependencies on a git\nrepo instead of a released package.  To fix this, I've pushed\nI1c219a3547ca48e5c4a649441632eabc326081f9 but it fails the\nrequirements job because tripleo-common was not even in g-r in the\nmitaka release.\n\nAccording to [1], tripleo-common was 2.1.0 for mitaka, so for the\nsake of global-requirements we would want to use releases between\n2.0.0 and 3.0.0.\n\n1: https://github.com/openstack/releases/blob/master/deliverables/mitaka/tripleo-common.yaml\n\nChange-Id: I34ae312f6e92787c9724f14d5b37e7965ff0d5eb\nRelated-Bug: 1656871\n""}]",0,421543,ba5d397da32088fec161c611a463018332f70e2e,21,9,2,6928,,,0,"Add mitaka tripleo-common to requirements

TripleO did some bad things in mitaka with the requirements files.
The unit tests in some TripleO projects are now broken because they
are uncapped, but we can't start using upper-constraints because
the aforementioned bad things include direct dependencies on a git
repo instead of a released package.  To fix this, I've pushed
I1c219a3547ca48e5c4a649441632eabc326081f9 but it fails the
requirements job because tripleo-common was not even in g-r in the
mitaka release.

According to [1], tripleo-common was 2.1.0 for mitaka, so for the
sake of global-requirements we would want to use releases between
2.0.0 and 3.0.0.

1: https://github.com/openstack/releases/blob/master/deliverables/mitaka/tripleo-common.yaml

Change-Id: I34ae312f6e92787c9724f14d5b37e7965ff0d5eb
Related-Bug: 1656871
",git fetch https://review.opendev.org/openstack/requirements refs/changes/43/421543/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,01df1ced70a401fa2efcb8f15b900491b173c773,bug/1656871,"tripleo-common>=2.0.0,<3.0.0 # Apache-2.0",,1,0
openstack%2Fnetworking-odl~master~Ie495f09617324e6221512e449c678d6a1e2f5149,openstack/networking-odl,master,Ie495f09617324e6221512e449c678d6a1e2f5149,Enable placement-api for compute node to fix multinode tempest failure,MERGED,2017-02-17 03:37:10.000000000,2017-02-17 17:53:28.000000000,2017-02-17 17:53:27.000000000,"[{'_account_id': 3}, {'_account_id': 333}]","[{'number': 1, 'created': '2017-02-17 03:37:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/8a6f4f2b050a6b42ea4ac7c241ed0336269725ad', 'message': 'DO NOT REVIEW/MERGE: Enable placement for compute node\n\nChange-Id: Ie495f09617324e6221512e449c678d6a1e2f5149\n'}, {'number': 2, 'created': '2017-02-17 05:52:57.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/735c96860584139dec07a663c8490da8990da929', 'message': 'Enable placement-api for compute node to fix multinode tempest failure\n\nChange-Id: Ie495f09617324e6221512e449c678d6a1e2f5149\nRelated-Bug: #1633242\n'}]",0,435210,735c96860584139dec07a663c8490da8990da929,10,2,2,15070,,,0,"Enable placement-api for compute node to fix multinode tempest failure

Change-Id: Ie495f09617324e6221512e449c678d6a1e2f5149
Related-Bug: #1633242
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/10/435210/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,8a6f4f2b050a6b42ea4ac7c241ed0336269725ad,," export DEVSTACK_SUBNODE_CONFIG+=$'\n'""ENABLED_SERVICES=n-cpu,dstat,c-vol,c-bak,q-odl,placement-api"""," export DEVSTACK_SUBNODE_CONFIG+=$'\n'""ENABLED_SERVICES=n-cpu,dstat,c-vol,c-bak,q-odl""",1,1
openstack%2Ftripleo-heat-templates~stable%2Focata~Icf91dd91c0ab04e7919172fcfd130183bfd427b4,openstack/tripleo-heat-templates,stable/ocata,Icf91dd91c0ab04e7919172fcfd130183bfd427b4,Add explicit swift check to tripleo_upgrade_node.sh,MERGED,2017-02-17 09:58:54.000000000,2017-02-17 17:49:10.000000000,2017-02-17 17:49:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8449}]","[{'number': 1, 'created': '2017-02-17 09:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eeb036fd92a7378c2e125342cb034a2e9d51a4c0', 'message': 'Add explicit swift check to tripleo_upgrade_node.sh\n\nAnd change the conditional to use hiera instead.\n\nChange-Id: Icf91dd91c0ab04e7919172fcfd130183bfd427b4\n'}, {'number': 2, 'created': '2017-02-17 12:11:58.000000000', 'files': ['extraconfig/tasks/tripleo_upgrade_node.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e160cd2b53270fb3ec2099b2a5731de38e042f47', 'message': 'Add explicit swift check to tripleo_upgrade_node.sh\n\nAnd change the conditional to use hiera instead.\n\nChange-Id: Icf91dd91c0ab04e7919172fcfd130183bfd427b4\n(cherry picked from commit d8e75b220efec3b17a76bed6898327784fb4e6cc)\n'}]",1,435338,e160cd2b53270fb3ec2099b2a5731de38e042f47,10,3,2,8449,,,0,"Add explicit swift check to tripleo_upgrade_node.sh

And change the conditional to use hiera instead.

Change-Id: Icf91dd91c0ab04e7919172fcfd130183bfd427b4
(cherry picked from commit d8e75b220efec3b17a76bed6898327784fb4e6cc)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/38/435338/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/tripleo_upgrade_node.sh'],1,eeb036fd92a7378c2e125342cb034a2e9d51a4c0,fixup_tripleo_upgradesh,"if hiera -c /etc/puppet/hiera.yaml service_names | grep nova_compute ; thenSWIFT_STORAGE="""" if hiera -c /etc/puppet/hiera.yaml service_names | grep swift_storage ; then SWIFT_STORAGE=""true"" fiif [[ -n \$SWIFT_STORAGE ]]; then systemctl_swift stop fiif [[ -n \$SWIFT_STORAGE ]]; then systemctl_swift start fi",if systemctl show 'openstack-nova-compute' --property ActiveState | grep '\bactive\b'; thensystemctl_swift stopsystemctl_swift start ,11,4
openstack%2Ftripleo-heat-templates~stable%2Fnewton~Ie4c67ce232de8086ad1275d80432ef321cdbc573,openstack/tripleo-heat-templates,stable/newton,Ie4c67ce232de8086ad1275d80432ef321cdbc573,backport multinode_major_upgrade.yaml environment,MERGED,2017-02-17 11:53:51.000000000,2017-02-17 17:48:21.000000000,2017-02-17 17:48:21.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-17 11:53:51.000000000', 'files': ['ci/environments/multinode-core.yaml', 'ci/environments/multinode.yaml', 'ci/environments/multinode_major_upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d8b82b0e3f9c989abf6fa12197e4d71012de16d5', 'message': 'backport multinode_major_upgrade.yaml environment\n\nThis is a squashed commit containing the following changes:\nI3e3aa5d4fa7e03d1f4483bf42fcff17386b58709\nI931534e0ec33e131809186f74068eb479d38a0f9\nI41692d2ddb9fbd2002fd7910933ab4edff74f33e\nI512ad89d9ac82ae62f9cbe7d0029fb1ac7445cc9\nI78bd5c804284219a71b13dba21fd1188ca854fca\n\nThis aligns the stable/newton branch with the current file contents\non master/ocata\n\nChange-Id: Ie4c67ce232de8086ad1275d80432ef321cdbc573\n'}]",0,435402,d8b82b0e3f9c989abf6fa12197e4d71012de16d5,8,2,1,4328,,,0,"backport multinode_major_upgrade.yaml environment

This is a squashed commit containing the following changes:
I3e3aa5d4fa7e03d1f4483bf42fcff17386b58709
I931534e0ec33e131809186f74068eb479d38a0f9
I41692d2ddb9fbd2002fd7910933ab4edff74f33e
I512ad89d9ac82ae62f9cbe7d0029fb1ac7445cc9
I78bd5c804284219a71b13dba21fd1188ca854fca

This aligns the stable/newton branch with the current file contents
on master/ocata

Change-Id: Ie4c67ce232de8086ad1275d80432ef321cdbc573
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/02/435402/1 && git format-patch -1 --stdout FETCH_HEAD,"['ci/environments/multinode-core.yaml', 'ci/environments/multinode.yaml', 'ci/environments/multinode_major_upgrade.yaml']",3,d8b82b0e3f9c989abf6fa12197e4d71012de16d5,upgrade_ci_nova_newton,resource_registry: OS::TripleO::Controller::Net::SoftwareConfig: ../common/net-config-multinode.yaml OS::TripleO::Compute::Net::SoftwareConfig: ../common/net-config-multinode.yaml parameter_defaults: ControllerServices: - OS::TripleO::Services::CACerts - OS::TripleO::Services::Kernel - OS::TripleO::Services::Keystone - OS::TripleO::Services::GlanceApi - OS::TripleO::Services::GlanceRegistry - OS::TripleO::Services::NeutronDhcpAgent - OS::TripleO::Services::NeutronL3Agent - OS::TripleO::Services::NeutronMetadataAgent - OS::TripleO::Services::NeutronServer - OS::TripleO::Services::NeutronCorePlugin - OS::TripleO::Services::NeutronOvsAgent - OS::TripleO::Services::CinderApi - OS::TripleO::Services::CinderScheduler - OS::TripleO::Services::CinderVolume - OS::TripleO::Services::HeatApi - OS::TripleO::Services::HeatApiCfn - OS::TripleO::Services::HeatApiCloudwatch - OS::TripleO::Services::HeatEngine - OS::TripleO::Services::SwiftProxy - OS::TripleO::Services::SwiftStorage - OS::TripleO::Services::SwiftRingBuilder - OS::TripleO::Services::SaharaApi - OS::TripleO::Services::SaharaEngine - OS::TripleO::Services::MySQL - OS::TripleO::Services::RabbitMQ - OS::TripleO::Services::HAproxy - OS::TripleO::Services::Keepalived - OS::TripleO::Services::Memcached - OS::TripleO::Services::Ntp - OS::TripleO::Services::Timezone - OS::TripleO::Services::TripleoPackages - OS::TripleO::Services::TripleoFirewall ControllerExtraConfig: nova::compute::libvirt::services::libvirt_virt_type: qemu nova::compute::libvirt::libvirt_virt_type: qemu # Required for Centos 7.3 and Qemu 2.6.0 nova::compute::libvirt::libvirt_cpu_mode: 'none' heat::rpc_response_timeout: 600 SwiftCeilometerPipelineEnabled: False Debug: True ,,84,0
openstack%2Finstack-undercloud~stable%2Focata~I444baf37c7f880fadd08766c47c7d0f6173e312f,openstack/instack-undercloud,stable/ocata,I444baf37c7f880fadd08766c47c7d0f6173e312f,Update .gitreview for stable/ocata,MERGED,2017-02-16 12:59:03.000000000,2017-02-17 17:48:10.000000000,2017-02-17 17:48:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-16 12:59:03.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/4d5eee64578ba1a5f30a52472cc9a377e8833cea', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: I444baf37c7f880fadd08766c47c7d0f6173e312f\n'}]",0,434871,4d5eee64578ba1a5f30a52472cc9a377e8833cea,15,2,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: I444baf37c7f880fadd08766c47c7d0f6173e312f
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/71/434871/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,4d5eee64578ba1a5f30a52472cc9a377e8833cea,create-ocata,defaultbranch=stable/ocata,defaultbranch=master,1,1
openstack%2Fproject-config~master~Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8,openstack/project-config,master,Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8,OSA: Close trusty job leaks for Ocata onwards,MERGED,2017-02-09 12:47:20.000000000,2017-02-17 17:46:33.000000000,2017-02-17 17:46:33.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-09 12:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5797e078b8e10e4604fd9334ea9689ac4f44e0c8', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 2, 'created': '2017-02-09 12:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0009ad838d4eaa2fac4c02e97d5a42adada1c67c', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 3, 'created': '2017-02-17 08:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0b2fa531a94b56d06780ab6156f75a45e8f91ee9', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak, it simplifies the conditions and\nmakes clearer what is run where.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 4, 'created': '2017-02-17 08:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5da90fae30a20f970317dd95c0688fe5fbc40cc6', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak, it simplifies the conditions and\nmakes clearer what is run where.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 5, 'created': '2017-02-17 09:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9bc3c320e3acd47a514190716e3c4a2f2fe064a5', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak, it simplifies the conditions and\nmakes clearer what is run where.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-docs-ubuntu-trusty\ngate-openstack-ansible-os_keystone-linters-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 6, 'created': '2017-02-17 10:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3165e31141bb2a8a3e54d9832c4d3d91248ba205', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak, it simplifies the conditions and\nmakes clearer what is run where.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-docs-ubuntu-trusty\ngate-openstack-ansible-os_keystone-linters-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\n\nFor Mitaka, these should not run:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_neutron-ansible-calico-ubuntu-trusty-nv\ngate-openstack-ansible-os_neutron-ansible-dragonflow-ubuntu-trusty-nv\ngate-openstack-ansible-os_neutron-ansible-func_ovs-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}, {'number': 7, 'created': '2017-02-17 10:35:54.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/84bb932fad4b8a5c86443f33bfc8ad517cea1ea9', 'message': 'OSA: Close trusty job leaks for Ocata onwards\n\nIn https://review.openstack.org/429649 we managed to\nfix our Mitaka job execution, but now have a leak of\nsome trusty jobs into our Ocata & Master branches.\n\nThis will hopefully plug that leak, it simplifies the conditions and\nmakes clearer what is run where.\n\nJobs that should NOT run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty\n\nJobs that should run for Ocata onwards:\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv\ngate-openstack-ansible-os_nova-docs-ubuntu-xenial\ngate-openstack-ansible-os_nova-linters-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial\n\nFor Mitaka, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-docs-ubuntu-trusty\ngate-openstack-ansible-os_keystone-linters-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\n\nFor Mitaka, these should not run:\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_neutron-ansible-calico-ubuntu-trusty-nv\ngate-openstack-ansible-os_neutron-ansible-dragonflow-ubuntu-trusty-nv\ngate-openstack-ansible-os_neutron-ansible-func_ovs-ubuntu-trusty\n\nFor Newton, these should run:\ngate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial\ngate-openstack-ansible-rabbitmq_server-ansible-func-centos-7\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty\ngate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-docs-ubuntu-xenial\ngate-openstack-ansible-os_keystone-linters-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-func-centos-7\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty\ngate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial\n\nChange-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8\n'}]",14,431501,84bb932fad4b8a5c86443f33bfc8ad517cea1ea9,32,5,7,6816,,,0,"OSA: Close trusty job leaks for Ocata onwards

In https://review.openstack.org/429649 we managed to
fix our Mitaka job execution, but now have a leak of
some trusty jobs into our Ocata & Master branches.

This will hopefully plug that leak, it simplifies the conditions and
makes clearer what is run where.

Jobs that should NOT run for Ocata onwards:
gate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty
gate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-trusty

Jobs that should run for Ocata onwards:
gate-openstack-ansible-os_keystone-ansible-func-centos-7
gate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial
gate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7
gate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenia
gate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7
gate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial
gate-openstack-ansible-os_keystone-ansible-upgrade-ubuntu-xenial-nv
gate-openstack-ansible-os_nova-docs-ubuntu-xenial
gate-openstack-ansible-os_nova-linters-ubuntu-xenial
gate-openstack-ansible-os_nova-ansible-func-ubuntu-xenial
gate-openstack-ansible-os_nova-ansible-func_lxd-ubuntu-xenial

For Mitaka, these should run:
gate-openstack-ansible-rabbitmq_server-docs-ubuntu-trusty
gate-openstack-ansible-rabbitmq_server-linters-ubuntu-trusty
gate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty
gate-openstack-ansible-os_keystone-docs-ubuntu-trusty
gate-openstack-ansible-os_keystone-linters-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty

For Mitaka, these should not run:
gate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty
gate-openstack-ansible-os_neutron-ansible-calico-ubuntu-trusty-nv
gate-openstack-ansible-os_neutron-ansible-dragonflow-ubuntu-trusty-nv
gate-openstack-ansible-os_neutron-ansible-func_ovs-ubuntu-trusty

For Newton, these should run:
gate-openstack-ansible-rabbitmq_server-docs-ubuntu-xenial
gate-openstack-ansible-rabbitmq_server-linters-ubuntu-xenial
gate-openstack-ansible-rabbitmq_server-ansible-func-centos-7
gate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-trusty
gate-openstack-ansible-rabbitmq_server-ansible-func-ubuntu-xenial
gate-openstack-ansible-os_keystone-docs-ubuntu-xenial
gate-openstack-ansible-os_keystone-linters-ubuntu-xenial
gate-openstack-ansible-os_keystone-ansible-func-centos-7
gate-openstack-ansible-os_keystone-ansible-func-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-func-ubuntu-xenial
gate-openstack-ansible-os_keystone-ansible-uw_apache-centos-7
gate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-uw_apache-ubuntu-xenial
gate-openstack-ansible-os_keystone-ansible-uw_nginx-centos-7
gate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-trusty
gate-openstack-ansible-os_keystone-ansible-uw_nginx-ubuntu-xenial

Change-Id: Iff2791a9ad1fbe99d8cce51fb5d37187d9fcd1e8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/431501/5 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,5797e078b8e10e4604fd9334ea9689ac4f44e0c8,openstack-ansible, # Skip jobs on ubuntu-trusty from Ocata onwards - name: ^gate-openstack-ansible-.*-ubuntu-trusty$ branch: ^(?!(stable/ocata|master).*$ ,,4,0
openstack%2Ftripleo-ci~master~Ifcdb048a1081b16a8a33816be98ddbbe07c27856,openstack/tripleo-ci,master,Ifcdb048a1081b16a8a33816be98ddbbe07c27856,Add converge update to major upgrade test,MERGED,2017-02-15 12:29:48.000000000,2017-02-17 17:44:59.000000000,2017-02-17 17:44:59.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 8449}, {'_account_id': 16515}]","[{'number': 1, 'created': '2017-02-15 12:29:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/59c9d99d46db284a9668d1bc9f29aed82ab64fd6', 'message': 'Add converge update to major upgrade test\n\nDiscussion on IRC has made clear that for real deployments we can\'t\navoid the converge step, because we do still need a way to pin/unpin\nthe RPC (even when using ""auto"" as the version), and also potentially\nsome other nova specific steps will be required during the converge.\n\nSo align the CI test with how real deployments will be upgraded, even\nthough this will make the job take a little longer, otherwise the test\nisn\'t representative of the expected upgrade workflow.\n\nChange-Id: Ifcdb048a1081b16a8a33816be98ddbbe07c27856\n'}, {'number': 2, 'created': '2017-02-15 16:39:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/49bd1c8130f8cb5be0ad5474edc8dedf08fec2e2', 'message': 'Add converge update to major upgrade test\n\nDiscussion on IRC has made clear that for real deployments we can\'t\navoid the converge step, because we do still need a way to pin/unpin\nthe RPC (even when using ""auto"" as the version), and also potentially\nsome other nova specific steps will be required during the converge.\n\nSo align the CI test with how real deployments will be upgraded, even\nthough this will make the job take a little longer, otherwise the test\nisn\'t representative of the expected upgrade workflow.\n\nChange-Id: Ifcdb048a1081b16a8a33816be98ddbbe07c27856\n'}, {'number': 3, 'created': '2017-02-15 19:09:49.000000000', 'files': ['scripts/tripleo.sh', 'scripts/deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e36bfbd0a4a0851016d402cc2b616abc09f8289b', 'message': 'Add converge update to major upgrade test\n\nDiscussion on IRC has made clear that for real deployments we can\'t\navoid the converge step, because we do still need a way to pin/unpin\nthe RPC (even when using ""auto"" as the version), and also potentially\nsome other nova specific steps will be required during the converge.\n\nSo align the CI test with how real deployments will be upgraded, even\nthough this will make the job take a little longer, otherwise the test\nisn\'t representative of the expected upgrade workflow.\n\nDepends-On: If5016b910931364a621b280465420d0bf2617895\nChange-Id: Ifcdb048a1081b16a8a33816be98ddbbe07c27856\n'}]",0,434250,e36bfbd0a4a0851016d402cc2b616abc09f8289b,26,5,3,4328,,,0,"Add converge update to major upgrade test

Discussion on IRC has made clear that for real deployments we can't
avoid the converge step, because we do still need a way to pin/unpin
the RPC (even when using ""auto"" as the version), and also potentially
some other nova specific steps will be required during the converge.

So align the CI test with how real deployments will be upgraded, even
though this will make the job take a little longer, otherwise the test
isn't representative of the expected upgrade workflow.

Depends-On: If5016b910931364a621b280465420d0bf2617895
Change-Id: Ifcdb048a1081b16a8a33816be98ddbbe07c27856
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/50/434250/3 && git format-patch -1 --stdout FETCH_HEAD,"['scripts/tripleo.sh', 'scripts/deploy.sh']",2,59c9d99d46db284a9668d1bc9f29aed82ab64fd6,upgrade_add_converge," # must survive the upgrade. The upgrade is performed in two steps, even though this # is an all-in-one test, as this is close to how a real deployment with computes would # be upgraded. $TRIPLEO_ROOT/tripleo-ci/scripts/tripleo.sh --overcloud-sanity --skip-sanitytest-create --skip-sanitytest-cleanup $TRIPLEO_ROOT/tripleo-ci/scripts/tripleo.sh --overcloud-upgrade-converge", # must survive the upgrade.,35,3
openstack%2Fdesignate-tempest-plugin~master~Ia75006f709b2f3c35cdbbd6a4ff8b590ec36ba67,openstack/designate-tempest-plugin,master,Ia75006f709b2f3c35cdbbd6a4ff8b590ec36ba67,Remove tempest tests for APIv1 as smoke tests,MERGED,2017-02-16 09:21:01.000000000,2017-02-17 17:42:59.000000000,2017-02-17 17:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2017-02-16 09:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/d670bbb1cc290d6b7d8b255df21b34d9ebb3f9c8', 'message': ""Remove tempest tests for APIv1 as smoke tests\n\nDesignate API v1 is now disabled by default [1], so i think\nthe tests for this API version shouldn't be considered\nas smoke tests\n\n[1] https://review.openstack.org/#/c/434347/\n\nChange-Id: Ia75006f709b2f3c35cdbbd6a4ff8b590ec36ba67\n""}, {'number': 2, 'created': '2017-02-16 10:15:52.000000000', 'files': ['designate_tempest_plugin/tests/api/v1/test_records.py', 'designate_tempest_plugin/tests/api/v1/test_domains.py'], 'web_link': 'https://opendev.org/openstack/designate-tempest-plugin/commit/f90cfcf912586b833fde0f80dbb622b0dab3f3a2', 'message': ""Remove tempest tests for APIv1 as smoke tests\n\nDesignate API v1 is now disabled by default [1], so i think\nthe tests for this API version shouldn't be considered\nas smoke tests\n\n[1] https://review.openstack.org/#/c/434347/\n\nChange-Id: Ia75006f709b2f3c35cdbbd6a4ff8b590ec36ba67\n""}]",0,434761,f90cfcf912586b833fde0f80dbb622b0dab3f3a2,13,3,2,16312,,,0,"Remove tempest tests for APIv1 as smoke tests

Designate API v1 is now disabled by default [1], so i think
the tests for this API version shouldn't be considered
as smoke tests

[1] https://review.openstack.org/#/c/434347/

Change-Id: Ia75006f709b2f3c35cdbbd6a4ff8b590ec36ba67
",git fetch https://review.opendev.org/openstack/designate-tempest-plugin refs/changes/61/434761/1 && git format-patch -1 --stdout FETCH_HEAD,"['designate_tempest_plugin/tests/api/v1/test_records.py', 'designate_tempest_plugin/tests/api/v1/test_domains.py']",2,d670bbb1cc290d6b7d8b255df21b34d9ebb3f9c8,remove-smoke-v1,, @test.attr(type='smoke'),0,2
openstack%2Fproject-config~master~I9b4f22737e53470e7d1108d94c79f8176feeeeb0,openstack/project-config,master,I9b4f22737e53470e7d1108d94c79f8176feeeeb0,"Revert ""Revert ""Revert ""Temporarily disable osic-cloud1""""""",MERGED,2017-02-17 07:27:01.000000000,2017-02-17 17:33:15.000000000,2017-02-17 17:33:15.000000000,"[{'_account_id': 3}, {'_account_id': 4162}, {'_account_id': 5263}]","[{'number': 1, 'created': '2017-02-17 07:27:01.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/963fb25c30cc8882138a889dcc0256682baf9e0d', 'message': 'Revert ""Revert ""Revert ""Temporarily disable osic-cloud1""""""\n\nLet\'s try again enabling OSIC.\n\nThis reverts commit e7e4e5ec74118c984fa7d2af8f56770d9390c305.\n\nChange-Id: I9b4f22737e53470e7d1108d94c79f8176feeeeb0\n'}]",0,435279,963fb25c30cc8882138a889dcc0256682baf9e0d,7,3,1,6547,,,0,"Revert ""Revert ""Revert ""Temporarily disable osic-cloud1""""""

Let's try again enabling OSIC.

This reverts commit e7e4e5ec74118c984fa7d2af8f56770d9390c305.

Change-Id: I9b4f22737e53470e7d1108d94c79f8176feeeeb0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/435279/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,963fb25c30cc8882138a889dcc0256682baf9e0d,, max-servers: 256 max-servers: 256 max-servers: 512, max-servers: 0 max-servers: 0 max-servers: 0,3,3
openstack%2Fopenstack-ansible-lxc_hosts~master~Id2137fcff787fdbe043cb158b44aee63176a813b,openstack/openstack-ansible-lxc_hosts,master,Id2137fcff787fdbe043cb158b44aee63176a813b,CentOS Remove old code for lxc-source-install,MERGED,2017-02-17 16:36:01.000000000,2017-02-17 17:29:19.000000000,2017-02-17 17:28:15.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-17 16:36:01.000000000', 'files': ['vars/redhat-7.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/d289677aee6441078f7a4008d4baeb3f73124849', 'message': 'CentOS Remove old code for lxc-source-install\n\nChange-Id: Id2137fcff787fdbe043cb158b44aee63176a813b\n'}]",0,435519,d289677aee6441078f7a4008d4baeb3f73124849,8,3,1,13095,,,0,"CentOS Remove old code for lxc-source-install

Change-Id: Id2137fcff787fdbe043cb158b44aee63176a813b
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/19/435519/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/redhat-7.yml'],1,d289677aee6441078f7a4008d4baeb3f73124849,clean-up-old-lxc-install,,"lxc_download_url: ""https://linuxcontainers.org/downloads/lxc/lxc-2.0.6.tar.gz"" lxc_sha256sum: ""7c292cd0055dac1a0e6fbb6a7740fd12b6ffb204603c198faf37c11c9d6dcd7a""lxc_hosts_pip_install_options: > --global-option=build_ext --global-option=""-L/opt/lxc_embedded/x86_64-linux-gnu/"" --global-option=""-I/opt/lxc_embedded/include/"" ",0,7
openstack%2Fnetworking-sfc~master~Ib84f4dcc47bc6bd0ba4b138708c9f31e06a04c69,openstack/networking-sfc,master,Ib84f4dcc47bc6bd0ba4b138708c9f31e06a04c69,Pass update_flowrule_status in driver.py,MERGED,2017-02-08 23:05:22.000000000,2017-02-17 17:20:03.000000000,2017-02-17 17:20:03.000000000,"[{'_account_id': 3}, {'_account_id': 9396}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14037}, {'_account_id': 21798}, {'_account_id': 23310}]","[{'number': 1, 'created': '2017-02-08 23:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/c1286edf413da8ba5b38029509ce43811dc6a3c6', 'message': ""Pass update_flowrule_status in driver.py\n\n    Pass update_flowrule_status function in drivers/ovs/driver.py\n\n    * drivers/ovs/db.py will be removed in the future with 4 ovs tables,\n      update_path_node function referred in this function and\n      update_flowrule_status function itself will be no longer used.\n    * On the other hand, this function currently raised:\n        * RuntimeError: reentrant call\n        * DBError: reentrant call\n        * DBConnectionError: (pymysql.err.OperationalError)\n              (2014, 'Command Out of Sync'))\n\n    Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>\n    Co-Authored-By: Cathy Zhang <Cathy.H.Zhang@huawei.com>\n\nChange-Id: Ib84f4dcc47bc6bd0ba4b138708c9f31e06a04c69\n""}, {'number': 2, 'created': '2017-02-16 23:46:37.000000000', 'files': ['networking_sfc/services/sfc/drivers/ovs/driver.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/2222e802b29301e882259a7f28c9d952da1e6610', 'message': ""Pass update_flowrule_status in driver.py\n\n    Pass update_flowrule_status function in drivers/ovs/driver.py\n\n    * drivers/ovs/db.py will be removed in the future with 4 ovs tables,\n      update_path_node function referred in this function and\n      update_flowrule_status function itself will be no longer used.\n    * On the other hand, this function currently raised:\n        * RuntimeError: reentrant call\n        * DBError: reentrant call\n        * DBConnectionError: (pymysql.err.OperationalError)\n              (2014, 'Command Out of Sync'))\n\n    Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>\n\nPartial-Bug: #1665406\nChange-Id: Ib84f4dcc47bc6bd0ba4b138708c9f31e06a04c69\n""}]",2,431218,2222e802b29301e882259a7f28c9d952da1e6610,18,7,2,23142,,,0,"Pass update_flowrule_status in driver.py

    Pass update_flowrule_status function in drivers/ovs/driver.py

    * drivers/ovs/db.py will be removed in the future with 4 ovs tables,
      update_path_node function referred in this function and
      update_flowrule_status function itself will be no longer used.
    * On the other hand, this function currently raised:
        * RuntimeError: reentrant call
        * DBError: reentrant call
        * DBConnectionError: (pymysql.err.OperationalError)
              (2014, 'Command Out of Sync'))

    Co-Authored-By: Louis Fourie <louis.fourie@huawei.com>

Partial-Bug: #1665406
Change-Id: Ib84f4dcc47bc6bd0ba4b138708c9f31e06a04c69
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/18/431218/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_sfc/services/sfc/drivers/ovs/driver.py'],1,c1286edf413da8ba5b38029509ce43811dc6a3c6,pass_status," pass # try: # flowrule_status = dict(status=status) # self.update_path_node(id, flowrule_status) # except Exception as e: # LOG.exception(e) # LOG.error(_LE(""update_flowrule_status failed""))"," try: flowrule_status = dict(status=status) self.update_path_node(id, flowrule_status) except Exception as e: LOG.exception(e) LOG.error(_LE(""update_flowrule_status failed""))",7,6
openstack%2Fproject-config~master~Ic6d0b6d82e10d68d9310218762f83bc44514e88d,openstack/project-config,master,Ic6d0b6d82e10d68d9310218762f83bc44514e88d,Remove now unused db jobs,MERGED,2017-02-17 06:07:42.000000000,2017-02-17 17:19:30.000000000,2017-02-17 17:19:30.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}]","[{'number': 1, 'created': '2017-02-17 06:07:42.000000000', 'files': ['jenkins/jobs/python-bitrot-jobs.yaml', 'jenkins/jobs/python-jobs.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4922d50e15aab92ff6e42693a980436e346f63d7', 'message': 'Remove now unused db jobs\n\nThese db jobs are not needed anymore, remove them.\n\nFurther jobs will be removed once the last repo has been updated for\ntest-setup.\n\nChange-Id: Ic6d0b6d82e10d68d9310218762f83bc44514e88d\n'}]",0,435260,4922d50e15aab92ff6e42693a980436e346f63d7,7,3,1,6547,,,0,"Remove now unused db jobs

These db jobs are not needed anymore, remove them.

Further jobs will be removed once the last repo has been updated for
test-setup.

Change-Id: Ic6d0b6d82e10d68d9310218762f83bc44514e88d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/435260/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/python-bitrot-jobs.yaml', 'jenkins/jobs/python-jobs.yaml', 'zuul/layout.yaml']",3,4922d50e15aab92ff6e42693a980436e346f63d7,first-db-cleanup,," # Invokes the same targets as python34-jobs, but sets up databases. - name: python34-db-jobs check: - 'gate-{name}-python34-db' gate: - 'gate-{name}-python34-db' - name: periodic-db-ocata periodic-stable: - 'periodic-{name}-docs-ocata' - 'periodic-{name}-python27-db-ocata' ",0,52
openstack%2Fopenstack-ansible-tests~master~I91cef51968f1f7273edf07aca8173ece1a622c69,openstack/openstack-ansible-tests,master,I91cef51968f1f7273edf07aca8173ece1a622c69,Octavia test addition,ABANDONED,2017-02-15 17:06:00.000000000,2017-02-17 17:17:28.000000000,,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12807}]","[{'number': 1, 'created': '2017-02-15 17:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/6af326b1ea376d7096e5a570e93c91481f7d54f2', 'message': 'Octavia test addition\n\nThis adds an Octavia install to the tests\n\nChange-Id: I91cef51968f1f7273edf07aca8173ece1a622c69\n'}, {'number': 2, 'created': '2017-02-15 17:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/7c264f4365238f9137a971e5ad3cd357297435f7', 'message': 'Octavia test addition\n\nThis adds an Octavia install to the tests\n\nDepends-On: Idb419a4ca5daa311d39c90eda5f83412ccf576ad\n\nChange-Id: I91cef51968f1f7273edf07aca8173ece1a622c69\n'}, {'number': 3, 'created': '2017-02-15 19:55:35.000000000', 'files': ['test-vars.yml', 'test-install-octavia.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/31545768888115b513a9b0c58d1769129fcd15e8', 'message': 'Octavia test addition\n\nThis adds an Octavia install to the tests\n\nDepends-On: Idb419a4ca5daa311d39c90eda5f83412ccf576ad\n\nChange-Id: I91cef51968f1f7273edf07aca8173ece1a622c69\n'}]",3,434398,31545768888115b513a9b0c58d1769129fcd15e8,9,3,3,10850,,,0,"Octavia test addition

This adds an Octavia install to the tests

Depends-On: Idb419a4ca5daa311d39c90eda5f83412ccf576ad

Change-Id: I91cef51968f1f7273edf07aca8173ece1a622c69
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/98/434398/1 && git format-patch -1 --stdout FETCH_HEAD,['test-install-octavia.yml'],1,6af326b1ea376d7096e5a570e93c91481f7d54f2,octavia,"--- # Copyright 2016, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Playbook for installing Octavia hosts: octavia_all remote_user: root gather_facts: true pre_tasks: - include: ensure-rabbitmq.yml vhost_name: ""{{ octavia_rabbitmq_vhost }}"" user_name: ""{{ octavia_rabbitmq_userid }}"" user_password: ""{{ octavia_rabbitmq_password }}"" - include: create-grant-db.yml db_name: ""{{ octavia_galera_database }}"" db_password: ""{{ octavia_container_mysql_password }}"" roles: - role: ""{{ octavia_rolename | default('os_octavia') }}"" vars_files: - test-vars.yml ",,31,0
openstack%2Fopenstack-ansible-os_nova~stable%2Focata~If9b638d2ebbae0a9397ece993a9d1b5e09e46b2c,openstack/openstack-ansible-os_nova,stable/ocata,If9b638d2ebbae0a9397ece993a9d1b5e09e46b2c,Move nova-lxd to stable/ocata branch,MERGED,2017-02-17 15:32:07.000000000,2017-02-17 17:17:03.000000000,2017-02-17 17:17:03.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 14805}, {'_account_id': 17643}]","[{'number': 1, 'created': '2017-02-17 15:32:07.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/1d1923b3d56dd269f246d0ed6c382d0febedc259', 'message': 'Move nova-lxd to stable/ocata branch\n\nNow that nova-lxd has created a stable/ocata branch we should use that\nand remove the TODO item.\n\nChange-Id: If9b638d2ebbae0a9397ece993a9d1b5e09e46b2c\n'}]",0,435490,1d1923b3d56dd269f246d0ed6c382d0febedc259,8,4,1,2799,,,0,"Move nova-lxd to stable/ocata branch

Now that nova-lxd has created a stable/ocata branch we should use that
and remove the TODO item.

Change-Id: If9b638d2ebbae0a9397ece993a9d1b5e09e46b2c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/90/435490/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,1d1923b3d56dd269f246d0ed6c382d0febedc259,,nova_lxd_git_install_branch: stable/ocata,# TODO (andymccr): Update branch for lxd once it is creatednova_lxd_git_install_branch: master,1,2
openstack%2Fhorizon~master~I4c15b83b8e864ffc4a4c8fe9f2c34ad35ef0db79,openstack/horizon,master,I4c15b83b8e864ffc4a4c8fe9f2c34ad35ef0db79,Fix tooltip positioning.,ABANDONED,2016-10-31 21:32:50.000000000,2017-02-17 17:14:36.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9155}, {'_account_id': 14151}]","[{'number': 1, 'created': '2016-10-31 21:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/378283dde5647f8be51f1a6572500e140c14ca31', 'message': 'Fix tooltip positioning.\n\nUse fixed positioning for tooltips to avoid truncation due to overflow.\n\nChange-Id: I4c15b83b8e864ffc4a4c8fe9f2c34ad35ef0db79\nCloses-bug: #1626310\n'}, {'number': 2, 'created': '2016-11-17 22:22:22.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/_debt.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/44d5ccd9d9b2e274680e8bc53415099ec9dff5e6', 'message': 'Fix tooltip positioning.\n\nUse fixed positioning for tooltips to avoid truncation due to overflow.\n\nChange-Id: I4c15b83b8e864ffc4a4c8fe9f2c34ad35ef0db79\nCloses-bug: #1626310\n'}]",0,391978,44d5ccd9d9b2e274680e8bc53415099ec9dff5e6,7,4,2,13474,,,0,"Fix tooltip positioning.

Use fixed positioning for tooltips to avoid truncation due to overflow.

Change-Id: I4c15b83b8e864ffc4a4c8fe9f2c34ad35ef0db79
Closes-bug: #1626310
",git fetch https://review.opendev.org/openstack/horizon refs/changes/78/391978/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/dashboard/scss/_debt.scss'],1,378283dde5647f8be51f1a6572500e140c14ca31,bug/1626310, position: fixed;} ,},2,1
openstack%2Fhorizon~master~Ie07f4ebd17daf31ba95bdac365efd85437b58d34,openstack/horizon,master,Ie07f4ebd17daf31ba95bdac365efd85437b58d34,Show all projects a user is associated with.,ABANDONED,2016-11-01 16:25:34.000000000,2017-02-17 17:14:34.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9155}, {'_account_id': 14151}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-11-01 16:25:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a96c05e782dad2fe21ff98e02ff54722ac7db06d', 'message': 'Show all projects a user is associated with.\n\nShows a comma-separated list of all projects that a user is associated\nwith in the details overview page.\n\nChange-Id: Ie07f4ebd17daf31ba95bdac365efd85437b58d34\nCloses-bug: #1194109\n'}, {'number': 2, 'created': '2016-11-17 23:02:30.000000000', 'files': ['openstack_dashboard/dashboards/identity/users/tests.py', 'openstack_dashboard/dashboards/identity/users/views.py', 'openstack_dashboard/dashboards/identity/users/templates/users/_detail_overview.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/407242578d91df77b3c6a569232ded718570aab5', 'message': 'Show all projects a user is associated with.\n\nShows a comma-separated list of all projects that a user is associated\nwith in the details overview page.\n\nChange-Id: Ie07f4ebd17daf31ba95bdac365efd85437b58d34\nCloses-bug: #1194109\n'}]",2,392226,407242578d91df77b3c6a569232ded718570aab5,9,5,2,13474,,,0,"Show all projects a user is associated with.

Shows a comma-separated list of all projects that a user is associated
with in the details overview page.

Change-Id: Ie07f4ebd17daf31ba95bdac365efd85437b58d34
Closes-bug: #1194109
",git fetch https://review.opendev.org/openstack/horizon refs/changes/26/392226/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/users/tests.py', 'openstack_dashboard/dashboards/identity/users/views.py', 'openstack_dashboard/dashboards/identity/users/templates/users/_detail_overview.html']",3,a96c05e782dad2fe21ff98e02ff54722ac7db06d,bug/1194109," {% if tenants %} <dt>{% trans ""Projects"" %}</dt> <dd>{{ tenants|join:"", "" }}</dd> {% endif %}",,16,1
openstack%2Fhorizon~master~Iad0d8f9dbbc041ce782808c1dbeec50bf3cdfe68,openstack/horizon,master,Iad0d8f9dbbc041ce782808c1dbeec50bf3cdfe68,horizon branch changes,ABANDONED,2016-11-18 07:52:54.000000000,2017-02-17 17:14:33.000000000,,"[{'_account_id': 3}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-11-18 07:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/08c1940ba6dfa6dd53b4d871a0d4e3a0b466da11', 'message': 'horizon branch changes\n\nChange-Id: Iad0d8f9dbbc041ce782808c1dbeec50bf3cdfe68\n'}, {'number': 2, 'created': '2016-11-18 09:52:11.000000000', 'files': ['openstack_dashboard/templates/base.html', 'openstack_dashboard/dashboards/project/networks/views.py', 'horizon/static/horizon/js/horizon.modals.js', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/050081508093a55b6cb9f36bd8a65bf6041ede47', 'message': 'horizon branch changes\n\nChange-Id: Iad0d8f9dbbc041ce782808c1dbeec50bf3cdfe68\n'}]",3,399419,050081508093a55b6cb9f36bd8a65bf6041ede47,9,4,2,24130,,,0,"horizon branch changes

Change-Id: Iad0d8f9dbbc041ce782808c1dbeec50bf3cdfe68
",git fetch https://review.opendev.org/openstack/horizon refs/changes/19/399419/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/templates/base.html', 'openstack_dashboard/dashboards/project/networks/views.py', 'horizon/static/horizon/js/horizon.modals.js', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.controller.js']",6,08c1940ba6dfa6dd53b4d871a0d4e3a0b466da11,refs/meta/config,console.log($scope.model.networks);,,7,4
openstack%2Fhorizon~master~Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46,openstack/horizon,master,Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46,WIP: Enable Angular Flavors Panel,ABANDONED,2016-07-19 20:37:31.000000000,2017-02-17 17:14:31.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9622}, {'_account_id': 14151}]","[{'number': 1, 'created': '2016-07-19 20:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ab404afcee76ae4d4e9e7a8c82dcc18cc8ee9ee8', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 2, 'created': '2016-07-19 21:36:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e3c2cfd394ac075fe2f07d39bc7759b5a2bae13', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 3, 'created': '2016-07-21 15:12:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e3da11ea80c03750cb1adbf493c3cb9fced65980', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 4, 'created': '2016-07-29 13:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6070f02b942dab2427e1c086bacdd647cc4747d5', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 5, 'created': '2016-08-02 17:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/856fb611a79950b09734183b8051898100ee0ac9', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 6, 'created': '2016-08-02 18:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a8045862f56d7d8aae0023bd4b59a55de0a0c0ad', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 7, 'created': '2016-08-02 19:17:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/fdc029a8733a5729c89d5ca391b02816a20d6c3e', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 8, 'created': '2016-08-02 19:20:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/63026c8dbfe94d019a41651bf9d0687032bae6cc', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 9, 'created': '2016-08-03 14:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/28c7166511bfc97a235b6356ff8c85ff51d5b684', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 10, 'created': '2016-08-08 13:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3236178a97e96b31176833799921714ce62596e2', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 11, 'created': '2016-08-08 14:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b39e6087076cce801faf4bcbac5366a1a7dfbec2', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 12, 'created': '2016-08-15 14:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/80b0548d3d7faf20b05fa5c7b48fe544af03bd9e', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 13, 'created': '2016-08-15 14:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/429590302a39d00a342333b401b9d44fd558e7a6', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 14, 'created': '2016-08-15 15:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/475081d2115747781f31a3b47b9fcf768d88f110', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 15, 'created': '2016-08-15 19:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ee86246e98cdb7336f3bd4dbbcb0cbc4677353dd', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 16, 'created': '2016-08-17 20:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/47fc2fc7faaaa4f52abe123159277d83c12ceb41', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 17, 'created': '2016-08-25 21:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c0e6a2edc620e6aa1cf6f12c3df2f3b154248ec1', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 18, 'created': '2016-10-10 19:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/829dc4f32a2cd1dde3eea138d1805b0a6245e2b4', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}, {'number': 19, 'created': '2016-10-12 00:07:57.000000000', 'files': ['doc/source/topics/settings.rst', 'openstack_dashboard/test/integration_tests/horizon.conf', 'openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/fd06ceac4cd4da521513e90a4829c51555deec75', 'message': 'WIP: Enable Angular Flavors Panel\n\nThis patch enables the Angular Flavors panel and deprecates the Django-based\nFlavors panel.\n\nChange-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46\nPartially-Implements: blueprint ng-flavors\n'}]",0,344456,fd06ceac4cd4da521513e90a4829c51555deec75,39,4,19,14124,,,0,"WIP: Enable Angular Flavors Panel

This patch enables the Angular Flavors panel and deprecates the Django-based
Flavors panel.

Change-Id: Iaa7c37fd072304d0cf0c11d1873da3d3a7acfc46
Partially-Implements: blueprint ng-flavors
",git fetch https://review.opendev.org/openstack/horizon refs/changes/56/344456/5 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/enabled/_2080_admin_flavors_panel.py'],1,ab404afcee76ae4d4e9e7a8c82dcc18cc8ee9ee8,angular-features-setting, 'flavors_panel': 'angular', 'flavors_panel': 'legacy',1,1
openstack%2Fhorizon~master~I03444e355ecc7bd914d2fbe787b9d77d3fe636e6,openstack/horizon,master,I03444e355ecc7bd914d2fbe787b9d77d3fe636e6,Correct Horizon's default device naming on instance spawn.,ABANDONED,2016-11-22 02:13:04.000000000,2017-02-17 17:14:30.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 22827}]","[{'number': 1, 'created': '2016-11-22 02:13:04.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e528346068f61f2cd99c784ae864f9e511782e73', 'message': ""Correct Horizon's default device naming on instance spawn.\n\nHorizon (by default) will provide the default (primary) device name with\nvda when spawning instances.\nThis behaviour is not ideal as the hypervisor or image properties should\ndictate what the primary device\nname is.\n\nFix was provided by user eblock in\nhttps://bugs.launchpad.net/nova/+bug/1560965/comments/6\n\nChange-Id: I03444e355ecc7bd914d2fbe787b9d77d3fe636e6\nCloses-Bug: 1560965\n""}]",0,400463,e528346068f61f2cd99c784ae864f9e511782e73,5,3,1,22827,,,0,"Correct Horizon's default device naming on instance spawn.

Horizon (by default) will provide the default (primary) device name with
vda when spawning instances.
This behaviour is not ideal as the hypervisor or image properties should
dictate what the primary device
name is.

Fix was provided by user eblock in
https://bugs.launchpad.net/nova/+bug/1560965/comments/6

Change-Id: I03444e355ecc7bd914d2fbe787b9d77d3fe636e6
Closes-Bug: 1560965
",git fetch https://review.opendev.org/openstack/horizon refs/changes/63/400463/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/launch-instance-model.service.js'],1,e528346068f61f2cd99c784ae864f9e511782e73,bug/1560965," vol_device_name: 'NOTSET', if (finalSpec.vol_device_name=='NOTSET') { finalSpec.block_device_mapping_v2.push( { // 'device_name': deviceName, 'source_type': SOURCE_TYPE_IMAGE, 'destination_type': SOURCE_TYPE_VOLUME, 'delete_on_termination': finalSpec.vol_delete_on_instance_delete, 'uuid': finalSpec.source_id, 'boot_index': '0', 'volume_size': finalSpec.vol_size } ); } else { finalSpec.block_device_mapping_v2.push( 'source_type': SOURCE_TYPE_IMAGE, 'destination_type': SOURCE_TYPE_VOLUME, ); }"," vol_device_name: 'vda', finalSpec.block_device_mapping_v2.push( 'source_type': bootSourceTypes.IMAGE, 'destination_type': bootSourceTypes.VOLUME, );",20,5
openstack%2Fhorizon~master~I29adfde5d00bec1aa8b19e180faab794f828ddb9,openstack/horizon,master,I29adfde5d00bec1aa8b19e180faab794f828ddb9,Use timedelta.total_seconds instead of calculating,ABANDONED,2015-12-16 09:36:32.000000000,2017-02-17 17:14:29.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12281}, {'_account_id': 14151}, {'_account_id': 15424}, {'_account_id': 17172}, {'_account_id': 17645}]","[{'number': 1, 'created': '2015-12-16 09:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5b94c37548e89de8d659a8bdaa07d94474b97aa5', 'message': 'timedelta.total_seconds() instead of calculating\n\nSince we dropped Python 2.6, so we can use datetime.timedelta.total_seconds()\ninstead of calculating it manually.\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 2, 'created': '2016-01-08 03:53:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af7185985166f344f1ab2a1f407e9a2bea6a4edc', 'message': 'timedelta.total_seconds() instead of calculating\n\nSince we dropped Python 2.6, so we can use datetime.timedelta.total_seconds()\ninstead of calculating timedelta manually.\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 3, 'created': '2016-01-11 06:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d04c698636ca2d1eb1e18ae498635aef1af87cfa', 'message': 'Use timedelta.total_seconds instead of calculating\n\nSince we dropped Python 2.6, so we can use\ndatetime.timedelta.total_seconds() instead of\ncalculating timedelta manually.\n\nThis commit let\'s replace expressions like\n""delta.days * 24 * 3600 + delta.seconds""\nwith ""delta.total_seconds()"".\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 4, 'created': '2016-01-25 06:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7ac67693d20202abc0edeb6cd33763fb449fe8ae', 'message': 'Use timedelta.total_seconds instead of calculating\n\nSince we dropped Python 2.6, so we can use\ndatetime.timedelta.total_seconds() instead of\ncalculating timedelta manually.\n\nThis commit let\'s replace expressions like\n""delta.days * 24 * 3600 + delta.seconds""\nwith ""delta.total_seconds()"".\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 5, 'created': '2016-02-08 09:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13f0b8ac3bfa1bd2c32d2d371121a948f7974e5f', 'message': 'Use timedelta.total_seconds instead of calculating\n\nSince we dropped Python 2.6, so we can use\ndatetime.timedelta.total_seconds() instead of\ncalculating timedelta manually.\n\nThis commit let\'s replace expressions like\n""delta.days * 24 * 3600 + delta.seconds""\nwith ""delta.total_seconds()"".\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 6, 'created': '2016-03-09 07:39:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c5e4b289a7aa5e4bc450097c24b86d728da57ea7', 'message': 'Use timedelta.total_seconds instead of calculating\n\nSince we dropped Python 2.6, so we can use\ndatetime.timedelta.total_seconds() instead of\ncalculating timedelta manually.\n\nThis commit let\'s replace expressions like\n""delta.days * 24 * 3600 + delta.seconds""\nwith ""delta.total_seconds()"".\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}, {'number': 7, 'created': '2016-09-16 06:09:39.000000000', 'files': ['openstack_dashboard/utils/metering.py', 'horizon/utils/filters.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/594a09a5924fd254b1e2f8b1715e11fb3d75866e', 'message': 'Use timedelta.total_seconds instead of calculating\n\nSince we dropped Python 2.6, so we can use\ndatetime.timedelta.total_seconds() instead of\ncalculating timedelta manually.\n\nThis commit let\'s replace expressions like\n""delta.days * 24 * 3600 + delta.seconds""\nwith ""delta.total_seconds()"".\n\nChange-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9\n'}]",3,258375,594a09a5924fd254b1e2f8b1715e11fb3d75866e,43,10,7,15424,,,0,"Use timedelta.total_seconds instead of calculating

Since we dropped Python 2.6, so we can use
datetime.timedelta.total_seconds() instead of
calculating timedelta manually.

This commit let's replace expressions like
""delta.days * 24 * 3600 + delta.seconds""
with ""delta.total_seconds()"".

Change-Id: I29adfde5d00bec1aa8b19e180faab794f828ddb9
",git fetch https://review.opendev.org/openstack/horizon refs/changes/75/258375/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/utils/filters.py'],1,5b94c37548e89de8d659a8bdaa07d94474b97aa5,timedelta-total_seconds," (delta.total_seconds(), timesince(dt)))"," # timedelta.total_seconds() not supported on python < 2.7 seconds = delta.seconds + (delta.days * 24 * 3600) (seconds, timesince(dt)))",1,3
openstack%2Fhorizon~master~I01f6abfa2cd65cf3538f810daed9e29dabab44c2,openstack/horizon,master,I01f6abfa2cd65cf3538f810daed9e29dabab44c2,Help tooltips added for dashboard names in the left navigation bar Closes-Bug: #1381641 Change-Id: I01f6abfa2cd65cf3538f810daed9e29dabab44c2,ABANDONED,2016-07-31 20:52:34.000000000,2017-02-17 17:14:27.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9048}, {'_account_id': 14151}, {'_account_id': 22599}]","[{'number': 1, 'created': '2016-07-31 20:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/050a7379ecc667e18e870078292cb10a7758a7ac', 'message': 'First commit-tooltips working\n\nChange-Id: I01f6abfa2cd65cf3538f810daed9e29dabab44c2\n'}, {'number': 2, 'created': '2016-08-01 17:07:46.000000000', 'files': ['horizon/templates/horizon/_sidebar.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/9c0842d537de1590b336a08caffd05c4f52f02f0', 'message': 'Help tooltips added for dashboard names in the left navigation bar\nCloses-Bug: #1381641\nChange-Id: I01f6abfa2cd65cf3538f810daed9e29dabab44c2\n'}]",0,349291,9c0842d537de1590b336a08caffd05c4f52f02f0,12,5,2,22599,,,0,"Help tooltips added for dashboard names in the left navigation bar
Closes-Bug: #1381641
Change-Id: I01f6abfa2cd65cf3538f810daed9e29dabab44c2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/91/349291/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/templates/horizon/_sidebar.html'],1,050a7379ecc667e18e870078292cb10a7758a7ac,branch1,"<style> .collapsed { position: relative; display: inline-block; border-bottom: 1px dotted black; } .collapsed .tooltiptext { visibility: hidden; width: 120px; background-color: black; color: #fff; text-align: center; border-radius: 6px; padding: 5px 0; position: absolute; z-index: 1; top: -5px; left: 110%; opacity: 0.8; } .collapsed .tooltiptext::after { content: """"; position: absolute; top: 50%; right: 100%; margin-top: -5px; border-width: 5px; border-style: solid; border-color: transparent black transparent transparent; } .collapsed:hover .tooltiptext { visibility: visible; } </style> <script> p = 1; a = 0; i = 0; d = 0; function setTooltip(e) { if (e.id == ""id-Project"" && p) { return; } else if (e.id == ""id-Admin"" && a) { return; } else if (e.id == ""id-Identity"" && i) { return; } else if (e.id == ""id-Developer"" && d) { return; } var allNodes = e.childNodes; if (e.id == ""id-Project"" && !p) { allNodes[1].innerHTML = ""This is Project.""; } else if (e.id == ""id-Admin"" && !a) { allNodes[1].innerHTML = ""This is Admin.""; } else if (e.id == ""id-Identity"" && !i) { allNodes[1].innerHTML = ""This is Identity.""; } else if (e.id == ""id-Developer"" && !d) { allNodes[1].innerHTML = ""This is Developer.""; } } function removeTooltip(e) { var allNodes = e.childNodes; allNodes[1].innerHTML = """"; if (e.id == ""id-Project"") { if (a == 1) { a = 0; } if (i == 1) { i = 0; } if (d == 1) { d = 0; } p = !p; } else if (e.id == ""id-Admin"") { if (p == 1) { p = 0; } if (i == 1) { i = 0; } if (d == 1) { d = 0; } a = !a; } else if (e.id == ""id-Identity"") { if (a == 1) { a = 0; } if (p == 1) { p = 0; } if (d == 1) { d = 0; } i = !i; } else if (e.id == ""id-Developer"") { if (a == 1) { a = 0; } if (i == 1) { i = 0; } if (p == 1) { p = 0; } d = !d; } } </script> data-placement=""right"" id=""id-{{ dashboard.name }}"" onClick=""removeTooltip(this)"" onmousemove=""setTooltip(this)"" <span class=""tooltiptext""></span>",,128,0
openstack%2Fhorizon~master~Iec5daf1969e63b3512544a798e54b04bd4bc3bd7,openstack/horizon,master,Iec5daf1969e63b3512544a798e54b04bd4bc3bd7,Rename jenkins to zuul,ABANDONED,2016-06-17 07:49:37.000000000,2017-02-17 17:14:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-06-17 07:49:37.000000000', 'files': ['run_tests.sh', 'doc/source/contributing.rst', 'doc/source/topics/testing.rst', 'tools/abandon_old_reviews.sh', 'doc/source/testing.rst', 'doc/source/topics/angularjs.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/37fcda22807658e288bc862f7611226e4443e77d', 'message': 'Rename jenkins to zuul\n\nName ""Jenkins"" or username ""jenkins"" from Gerrit\nshould be updated to use the full name ""Zuul"" or\nusername ""zuul"" as Jenkins is retired and Zuul is\non stage.\n\nChange-Id: Iec5daf1969e63b3512544a798e54b04bd4bc3bd7\n'}]",0,330935,37fcda22807658e288bc862f7611226e4443e77d,6,3,1,19902,,,0,"Rename jenkins to zuul

Name ""Jenkins"" or username ""jenkins"" from Gerrit
should be updated to use the full name ""Zuul"" or
username ""zuul"" as Jenkins is retired and Zuul is
on stage.

Change-Id: Iec5daf1969e63b3512544a798e54b04bd4bc3bd7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/330935/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'doc/source/contributing.rst', 'doc/source/topics/testing.rst', 'tools/abandon_old_reviews.sh', 'doc/source/testing.rst', 'doc/source/topics/angularjs.rst']",6,37fcda22807658e288bc862f7611226e4443e77d,jenkins_rename,is part of the automated tests run by Zuul. You can run ESLint from the,is part of the automated tests run by Jenkins. You can run ESLint from the,11,12
openstack%2Fhorizon~master~Ic81d47898d3b8f541cd27d2bb786979365d9d4ea,openstack/horizon,master,Ic81d47898d3b8f541cd27d2bb786979365d9d4ea,Prevent Neutron API wrapper overwriting data,ABANDONED,2016-11-29 13:04:16.000000000,2017-02-17 17:14:23.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}]","[{'number': 1, 'created': '2016-11-29 13:04:16.000000000', 'files': ['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/admin/networks/ports/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d739319257a36fa992c0699e2a78f5634a420836', 'message': ""Prevent Neutron API wrapper overwriting data\n\nThe Neutron API wrapper layer attempts to overwrite the network's\nsubnets given certain conditions. Naturally this changes the returned\ndata, meaning any call to network_get has no idea whether it is getting\na list of Subnet IDs (unicode strings) or of Subnet objects.\n\nThis patch cleans up the overwrite so that it adds the data to a new\nkey, so that any views can easily check whether they have more detailed\ninformation available before defaulting to the list of Subnet IDs\n\nChange-Id: Ic81d47898d3b8f541cd27d2bb786979365d9d4ea\nCloses-Bug: 1645708\n""}]",0,404202,d739319257a36fa992c0699e2a78f5634a420836,4,2,1,12826,,,0,"Prevent Neutron API wrapper overwriting data

The Neutron API wrapper layer attempts to overwrite the network's
subnets given certain conditions. Naturally this changes the returned
data, meaning any call to network_get has no idea whether it is getting
a list of Subnet IDs (unicode strings) or of Subnet objects.

This patch cleans up the overwrite so that it adds the data to a new
key, so that any views can easily check whether they have more detailed
information available before defaulting to the list of Subnet IDs

Change-Id: Ic81d47898d3b8f541cd27d2bb786979365d9d4ea
Closes-Bug: 1645708
",git fetch https://review.opendev.org/openstack/horizon refs/changes/02/404202/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/api/neutron.py', 'openstack_dashboard/dashboards/admin/networks/ports/forms.py']",3,d739319257a36fa992c0699e2a78f5634a420836,bug/1645708," # If we have detailed subnet info, then display it, else fall back # to just subnet IDs. if 'expanded_subnets' in network: return [(subnet.id, '%s %s' % (subnet.name_or_id, subnet.cidr)) for subnet in network.expanded_subnets] else: return [(subnet, subnet) for subnet in network.subnets]"," return [(subnet.id, '%s %s' % (subnet.name_or_id, subnet.cidr)) for subnet in network.subnets]",10,5
openstack%2Fhorizon~master~Ide93dced9fdd11ed20cdc0713c6a150aeebaa236,openstack/horizon,master,Ide93dced9fdd11ed20cdc0713c6a150aeebaa236,Refactor the code to delete some redundant code,ABANDONED,2016-09-19 08:46:29.000000000,2017-02-17 17:14:22.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 9155}, {'_account_id': 14151}, {'_account_id': 20506}, {'_account_id': 20509}, {'_account_id': 22587}, {'_account_id': 23165}]","[{'number': 1, 'created': '2016-09-19 08:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/240e3582d7a3c06cb983e624422c45d9e7cb6b49', 'message': 'Refactor the code to make the code more concise\n\nChange-Id: Ide93dced9fdd11ed20cdc0713c6a150aeebaa236\n'}, {'number': 2, 'created': '2016-09-19 08:49:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7a3dc4a2c1080e1f5c866a578747f59317d2bc90', 'message': 'Refactor the code to make the code more concise\n\nChange-Id: Ide93dced9fdd11ed20cdc0713c6a150aeebaa236\n'}, {'number': 3, 'created': '2016-09-22 01:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/72994c8abd03c3233fa7cf888c89d650c119ca82', 'message': 'Refactor the code to reduce some redundant code\n\nChange-Id: Ide93dced9fdd11ed20cdc0713c6a150aeebaa236\n'}, {'number': 4, 'created': '2016-09-22 13:49:31.000000000', 'files': ['openstack_dashboard/dashboards/project/images/urls.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/410b5094f36d56a0b5314ac0610d3e73f4245225', 'message': ""Refactor the code to delete some redundant code\n\nThe 'image_urls' and 'snapshot_urls' in 'images/urls.py' are repeated,\nthis patch refactor the code to remove some redundant code.\n\nCloses-Bug: #1626566\nChange-Id: Ide93dced9fdd11ed20cdc0713c6a150aeebaa236\n""}]",1,372312,410b5094f36d56a0b5314ac0610d3e73f4245225,23,10,4,14151,,,0,"Refactor the code to delete some redundant code

The 'image_urls' and 'snapshot_urls' in 'images/urls.py' are repeated,
this patch refactor the code to remove some redundant code.

Closes-Bug: #1626566
Change-Id: Ide93dced9fdd11ed20cdc0713c6a150aeebaa236
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/372312/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/images/urls.py'],1,240e3582d7a3c06cb983e624422c45d9e7cb6b49,,"urlpatterns = [ url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')), ] urlpatterns += ["," urlpatterns = [ url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')), url(r'', include(image_urls, namespace='images')), url(r'', include(snapshot_urls, namespace='snapshots')),",6,5
openstack%2Fhorizon~master~I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2,openstack/horizon,master,I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2,Policy should support AND and OR checks for panels,ABANDONED,2015-04-21 16:44:56.000000000,2017-02-17 17:14:21.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 8040}, {'_account_id': 13372}, {'_account_id': 15637}, {'_account_id': 17172}]","[{'number': 1, 'created': '2015-04-21 16:44:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b669ae7e74143d0b077ee194af93eda254f7c6bf', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}, {'number': 2, 'created': '2016-03-08 14:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2be42f943b4101222762f21dc4f965f0e5ea73f1', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nCo-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}, {'number': 3, 'created': '2016-03-08 15:45:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/559a0bfc671769f62ecfbfd35de8883058cd683b', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nCo-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}, {'number': 4, 'created': '2016-03-08 20:26:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b342584e5918ef6c33870dca2849c21be40077e5', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nCo-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}, {'number': 5, 'created': '2016-03-09 08:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/84c7a6f2dd7986045f41d6eb7a02ab80c976c2b3', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nCo-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}, {'number': 6, 'created': '2016-03-13 06:19:33.000000000', 'files': ['horizon/base.py', 'horizon/test/tests/base.py', 'openstack_dashboard/test/tests/policy.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/53a1e3c0955115b3637ce79b8fbd883a344f70aa', 'message': 'Policy should support AND and OR checks for panels\n\nAllowing for more complex combinations of policy checks.\nWill check for logical OR of all top level permissions.\nWill use logical AND for all first level tuples (check\nthat use has all the  permissions in the tuple list)\n\nExamples:\nT = Policy Rule Tuple.\n\nChecks for ALL required permissions\n([T1, T2, T3],) => T1 AND T2 AND T3\n\nChecks for T1 OR (T2 AND T3)\n(T1, [T2, T3],) => T1 OR (T2 AND T3)\n\nAdded 3 policy test cases for Panels which tests AND, OR and a mix\nof AND OR logics. The test cases are :\nP  = Policy rule for Panel\nP1 = True\nP2 = False\nP3 = True\nP4 = False\n\n(P1, P2,) expands to P1 OR P2 results as True.\n\n([P1, P2],) expands to P1 AND P2 results as False.\n\n(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.\n\nCloses-Bug: #1426415\nCo-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>\nChange-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2\n'}]",3,175982,53a1e3c0955115b3637ce79b8fbd883a344f70aa,24,7,6,15103,,,0,"Policy should support AND and OR checks for panels

Allowing for more complex combinations of policy checks.
Will check for logical OR of all top level permissions.
Will use logical AND for all first level tuples (check
that use has all the  permissions in the tuple list)

Examples:
T = Policy Rule Tuple.

Checks for ALL required permissions
([T1, T2, T3],) => T1 AND T2 AND T3

Checks for T1 OR (T2 AND T3)
(T1, [T2, T3],) => T1 OR (T2 AND T3)

Added 3 policy test cases for Panels which tests AND, OR and a mix
of AND OR logics. The test cases are :
P  = Policy rule for Panel
P1 = True
P2 = False
P3 = True
P4 = False

(P1, P2,) expands to P1 OR P2 results as True.

([P1, P2],) expands to P1 AND P2 results as False.

(P1, [P3, P4],)expands to P1 OR (P3 AND P4) results True.

Closes-Bug: #1426415
Co-Authored-By: Dmitry Ratushnyy <d.ratushnyy@gmail.com>
Change-Id: I5f7d4808c73eea98b13bc0662fe4aa649e27e6c2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/175982/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/base.py', 'horizon/test/tests/base.py']",2,b669ae7e74143d0b077ee194af93eda254f7c6bf,bug_1426415,"from django.test.utils import override_settingsclass PolicyOrAccessPanel(horizon.Panel): name = ""Policy Panel OR"" slug = ""policy_panel_or"" policy_rules = ((""identity"", ""identity:list_projects""), (""identity"", ""identity:list_user_projects""),) class PolicyAndAccessPanel(horizon.Panel): name = ""Policy Panel AND"" slug = ""policy_panel_and"" policy_rules = ([(""identity"", ""identity:list_projects""), (""identity"", ""identity:list_user_projects"")],) class PolicyMixedAccessPanel(horizon.Panel): name = ""Policy Panel MIXED"" slug = ""policy_panel_mixed"" policy_rules = (('identity', 'identity:list_projects'), [('telemetry', 'telemetry:compute_statistics'), ('telemetry', 'telemetry:get_meter')],) def policy_check(rule, request): if not cmp(rule, ((""identity"", ""identity:list_projects""),)): return True elif not cmp(rule, ((""identity"", ""identity:list_user_projects""),)): return False elif not cmp(rule, (('telemetry', 'telemetry:compute_statistics'),)): return True elif not cmp(rule, (('telemetry', 'telemetry:get_meter'),)): return False else: return False class OrPolicyHorizonTests(test.TestCase): def setUp(self): super(OrPolicyHorizonTests, self).setUp() # Adjust our horizon config and register our custom dashboards/panels. self.old_default_dash = settings.HORIZON_CONFIG['default_dashboard'] settings.HORIZON_CONFIG['default_dashboard'] = 'cats' self.old_dashboards = settings.HORIZON_CONFIG['dashboards'] settings.HORIZON_CONFIG['dashboards'] = ('cats', 'dogs') base.Horizon.register(Cats) Cats.register(PolicyOrAccessPanel) Cats.default_panel = 'policy_panel_or' # Trigger discovery, registration, and URLconf generation if it # hasn't happened yet. base.Horizon._urls() # Store our original dashboards self._discovered_dashboards = base.Horizon._registry.keys() # Gather up and store our original panels for each dashboard self._discovered_panels = {} for dash in self._discovered_dashboards: panels = base.Horizon._registry[dash]._registry.keys() self._discovered_panels[dash] = panels def tearDown(self): super(OrPolicyHorizonTests, self).tearDown() # Restore our settings settings.HORIZON_CONFIG['default_dashboard'] = self.old_default_dash settings.HORIZON_CONFIG['dashboards'] = self.old_dashboards # Destroy our singleton and re-create it. base.HorizonSite._instance = None del base.Horizon base.Horizon = base.HorizonSite() # Reload the convenience references to Horizon stored in __init__ reload(import_module(""horizon"")) # Reset Cats and Dogs default_panel to default values Cats.default_panel = 'kittens' # Re-register our original dashboards and panels. # This is necessary because autodiscovery only works on the first # import, and calling reload introduces innumerable additional # problems. Manual re-registration is the only good way for testing. self._discovered_dashboards.remove(Cats) for dash in self._discovered_dashboards: base.Horizon.register(dash) for panel in self._discovered_panels[dash]: dash.register(panel) @override_settings(POLICY_CHECK_FUNCTION=policy_check) def test_policy_check(self): context = {'request': self.request} cats = horizon.get_dashboard(""cats"") panel = cats.get_panel(""policy_panel_or"") self.assertTrue(panel.can_access(context)) class AndPolicyHorizonTests(test.TestCase): def setUp(self): super(AndPolicyHorizonTests, self).setUp() # Adjust our horizon config and register our custom dashboards/panels. self.old_default_dash = settings.HORIZON_CONFIG['default_dashboard'] settings.HORIZON_CONFIG['default_dashboard'] = 'cats' self.old_dashboards = settings.HORIZON_CONFIG['dashboards'] settings.HORIZON_CONFIG['dashboards'] = ('cats', 'dogs') base.Horizon.register(Cats) Cats.register(PolicyAndAccessPanel) Cats.default_panel = 'policy_panel_and' # Trigger discovery, registration, and URLconf generation if it # hasn't happened yet. base.Horizon._urls() # Store our original dashboards self._discovered_dashboards = base.Horizon._registry.keys() # Gather up and store our original panels for each dashboard self._discovered_panels = {} for dash in self._discovered_dashboards: panels = base.Horizon._registry[dash]._registry.keys() self._discovered_panels[dash] = panels def tearDown(self): super(AndPolicyHorizonTests, self).tearDown() # Restore our settings settings.HORIZON_CONFIG['default_dashboard'] = self.old_default_dash settings.HORIZON_CONFIG['dashboards'] = self.old_dashboards # Destroy our singleton and re-create it. base.HorizonSite._instance = None del base.Horizon base.Horizon = base.HorizonSite() # Reload the convenience references to Horizon stored in __init__ reload(import_module(""horizon"")) # Reset Cats and Dogs default_panel to default values Cats.default_panel = 'kittens' # Re-register our original dashboards and panels. # This is necessary because autodiscovery only works on the first # import, and calling reload introduces innumerable additional # problems. Manual re-registration is the only good way for testing. self._discovered_dashboards.remove(Cats) for dash in self._discovered_dashboards: base.Horizon.register(dash) for panel in self._discovered_panels[dash]: dash.register(panel) @override_settings(POLICY_CHECK_FUNCTION=policy_check) def test_policy_check(self): context = {'request': self.request} cats = horizon.get_dashboard(""cats"") panel = cats.get_panel(""policy_panel_and"") self.assertFalse(panel.can_access(context)) class MixedPolicyHorizonTests(test.TestCase): def setUp(self): super(MixedPolicyHorizonTests, self).setUp() # Adjust our horizon config and register our custom dashboards/panels. self.old_default_dash = settings.HORIZON_CONFIG['default_dashboard'] settings.HORIZON_CONFIG['default_dashboard'] = 'cats' self.old_dashboards = settings.HORIZON_CONFIG['dashboards'] settings.HORIZON_CONFIG['dashboards'] = ('cats', 'dogs') base.Horizon.register(Cats) Cats.register(PolicyMixedAccessPanel) Cats.default_panel = 'policy_panel_mixed' # Trigger discovery, registration, and URLconf generation if it # hasn't happened yet. base.Horizon._urls() # Store our original dashboards self._discovered_dashboards = base.Horizon._registry.keys() # Gather up and store our original panels for each dashboard self._discovered_panels = {} for dash in self._discovered_dashboards: panels = base.Horizon._registry[dash]._registry.keys() self._discovered_panels[dash] = panels def tearDown(self): super(MixedPolicyHorizonTests, self).tearDown() # Restore our settings settings.HORIZON_CONFIG['default_dashboard'] = self.old_default_dash settings.HORIZON_CONFIG['dashboards'] = self.old_dashboards # Destroy our singleton and re-create it. base.HorizonSite._instance = None del base.Horizon base.Horizon = base.HorizonSite() # Reload the convenience references to Horizon stored in __init__ reload(import_module(""horizon"")) # Reset Cats and Dogs default_panel to default values Cats.default_panel = 'kittens' # Re-register our original dashboards and panels. # This is necessary because autodiscovery only works on the first # import, and calling reload introduces innumerable additional # problems. Manual re-registration is the only good way for testing. self._discovered_dashboards.remove(Cats) for dash in self._discovered_dashboards: base.Horizon.register(dash) for panel in self._discovered_panels[dash]: dash.register(panel) @override_settings(POLICY_CHECK_FUNCTION=policy_check) def test_policy_check(self): context = {'request': self.request} cats = horizon.get_dashboard(""cats"") panel = cats.get_panel(""policy_panel_mixed"") self.assertTrue(panel.can_access(context))",,235,9
openstack%2Fhorizon~master~I6b11321bfe561556cb777083530b22f93e93a3a1,openstack/horizon,master,I6b11321bfe561556cb777083530b22f93e93a3a1,Subnet Network Address is missing asterisk.,ABANDONED,2016-09-13 14:13:29.000000000,2017-02-17 17:14:19.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9178}, {'_account_id': 9622}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-09-13 14:13:29.000000000', 'files': ['openstack_dashboard/dashboards/project/networks/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c7547f89b55c22d6aeaaacb5a0aa719f67e6df35', 'message': 'Subnet Network Address is missing asterisk.\n\nAdded asterisk to Network Address field.\n\nChange-Id: I6b11321bfe561556cb777083530b22f93e93a3a1\nCloses-Bug: #1420370\n'}]",0,369477,c7547f89b55c22d6aeaaacb5a0aa719f67e6df35,8,5,1,22593,,,0,"Subnet Network Address is missing asterisk.

Added asterisk to Network Address field.

Change-Id: I6b11321bfe561556cb777083530b22f93e93a3a1
Closes-Bug: #1420370
",git fetch https://review.opendev.org/openstack/horizon refs/changes/77/369477/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/networks/workflows.py'],1,c7547f89b55c22d6aeaaacb5a0aa719f67e6df35,,," required=False,",0,1
openstack%2Fhorizon~master~Ifd804845496cfc68c0d7fea023612023a1f21f2b,openstack/horizon,master,Ifd804845496cfc68c0d7fea023612023a1f21f2b,WIP - Add cinder group types to Admin volume panel,ABANDONED,2016-12-14 01:28:10.000000000,2017-02-17 17:14:18.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 11941}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-12-14 01:28:10.000000000', 'files': ['openstack_dashboard/dashboards/project/volumes/cg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_edit.html', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/tables.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/forms.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/_create_group_type.html', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/create_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/group_types_tables.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/index.html', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/edit.html', 'openstack_dashboard/dashboards/project/volumes/cgroups/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_index.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/tests.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/create.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/urls.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/views.py', 'openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/_update_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/update_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/forms.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_create.html', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/views.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/urls.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b7685db7e316c88a3421eadbd04f8efd3b945df0', 'message': 'WIP - Add cinder group types to Admin volume panel\n\nAs of Cinder API 3.11, generic volume groups will replace the\nexisting consistency volume groups. Users will still be able\nto set their generic groups to behave like consistency groups\n(for the purpose of snapshots and backups), but generic\ngroups will also allow more flexibility to simple provide\ngroupings to better manage and isolate volumes that share\ncharacteristics.\n\nVolume group types is the first patch of this feature.\nSubsequent patches will address groups and group\nsnapshots.\n\nTo use the new Cinder API to access generic groups,\nmicroversions must be specified in the API requests.\n\nPartially-Implements: blueprint cinder-generic-volume-groups\nPartially-Implements: blueprint microversion-support\nChange-Id: Ifd804845496cfc68c0d7fea023612023a1f21f2b\n'}]",0,410490,b7685db7e316c88a3421eadbd04f8efd3b945df0,6,4,1,11941,,,0,"WIP - Add cinder group types to Admin volume panel

As of Cinder API 3.11, generic volume groups will replace the
existing consistency volume groups. Users will still be able
to set their generic groups to behave like consistency groups
(for the purpose of snapshots and backups), but generic
groups will also allow more flexibility to simple provide
groupings to better manage and isolate volumes that share
characteristics.

Volume group types is the first patch of this feature.
Subsequent patches will address groups and group
snapshots.

To use the new Cinder API to access generic groups,
microversions must be specified in the API requests.

Partially-Implements: blueprint cinder-generic-volume-groups
Partially-Implements: blueprint microversion-support
Change-Id: Ifd804845496cfc68c0d7fea023612023a1f21f2b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/90/410490/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/volumes/cg_snapshots/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_edit.html', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/tables.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/forms.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/_create_group_type.html', 'openstack_dashboard/dashboards/project/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/__init__.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/create_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/group_types_tables.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/index.html', 'openstack_dashboard/dashboards/admin/volumes/urls.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/edit.html', 'openstack_dashboard/dashboards/project/volumes/cgroups/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_index.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/tests.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/tables.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/create.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/urls.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/views.py', 'openstack_dashboard/dashboards/admin/volumes/tabs.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/_update_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/update_group_type.html', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/forms.py', 'openstack_dashboard/dashboards/admin/volumes/templates/volumes/group_types/specs/_create.html', 'openstack_dashboard/api/base.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/views.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/urls.py', 'openstack_dashboard/dashboards/admin/volumes/group_types/specs/tests.py']",30,b7685db7e316c88a3421eadbd04f8efd3b945df0,add-cinder-group-types,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from django.core.urlresolvers import reverse from django import http from mox3.mox import IsA # noqa from openstack_dashboard import api from openstack_dashboard.test import helpers as test class VolTypeExtrasTests(test.BaseAdminViewTests): @test.create_stubs({api.cinder: ('volume_type_extra_get', 'volume_type_get'), }) def test_list_extras_when_none_exists(self): vol_type = self.cinder_volume_types.first() extras = [api.cinder.VolTypeExtraSpec(vol_type.id, 'k1', 'v1')] api.cinder.volume_type_get(IsA(http.HttpRequest), vol_type.id).AndReturn(vol_type) api.cinder.volume_type_extra_get(IsA(http.HttpRequest), vol_type.id).AndReturn(extras) self.mox.ReplayAll() url = reverse('horizon:admin:volumes:volume_types:extras:index', args=[vol_type.id]) resp = self.client.get(url) self.assertEqual(resp.status_code, 200) self.assertTemplateUsed(resp, ""admin/volumes/volume_types/extras/index.html"") @test.create_stubs({api.cinder: ('volume_type_extra_get', 'volume_type_get'), }) def test_extras_view_with_exception(self): vol_type = self.cinder_volume_types.first() api.cinder.volume_type_get(IsA(http.HttpRequest), vol_type.id).AndReturn(vol_type) api.cinder.volume_type_extra_get(IsA(http.HttpRequest), vol_type.id) \ .AndRaise(self.exceptions.cinder) self.mox.ReplayAll() url = reverse('horizon:admin:volumes:volume_types:extras:index', args=[vol_type.id]) resp = self.client.get(url) self.assertEqual(len(resp.context['extras_table'].data), 0) self.assertMessageCount(resp, error=1) @test.create_stubs({api.cinder: ('volume_type_extra_set', ), }) def test_extra_create_post(self): vol_type = self.cinder_volume_types.first() create_url = reverse( 'horizon:admin:volumes:volume_types:extras:create', args=[vol_type.id]) index_url = reverse( 'horizon:admin:volumes:volume_types:extras:index', args=[vol_type.id]) data = {'key': u'k1', 'value': u'v1'} api.cinder.volume_type_extra_set(IsA(http.HttpRequest), vol_type.id, {data['key']: data['value']}) self.mox.ReplayAll() resp = self.client.post(create_url, data) self.assertNoFormErrors(resp) self.assertMessageCount(success=1) self.assertRedirectsNoFollow(resp, index_url) @test.create_stubs({api.cinder: ('volume_type_get', ), }) def test_extra_create_get(self): vol_type = self.cinder_volume_types.first() create_url = reverse( 'horizon:admin:volumes:volume_types:extras:create', args=[vol_type.id]) api.cinder.volume_type_get(IsA(http.HttpRequest), vol_type.id).AndReturn(vol_type) self.mox.ReplayAll() resp = self.client.get(create_url) self.assertEqual(resp.status_code, 200) self.assertTemplateUsed( resp, 'admin/volumes/volume_types/extras/create.html') @test.create_stubs({api.cinder: ('volume_type_extra_get', 'volume_type_extra_set',), }) def test_extra_edit(self): vol_type = self.cinder_volume_types.first() key = 'foo' edit_url = reverse('horizon:admin:volumes:volume_types:extras:edit', args=[vol_type.id, key]) index_url = reverse('horizon:admin:volumes:volume_types:extras:index', args=[vol_type.id]) data = {'value': u'v1'} extras = {key: data['value']} api.cinder.volume_type_extra_get(IsA(http.HttpRequest), vol_type.id, raw=True).AndReturn(extras) api.cinder.volume_type_extra_set(IsA(http.HttpRequest), vol_type.id, extras) self.mox.ReplayAll() resp = self.client.post(edit_url, data) self.assertNoFormErrors(resp) self.assertMessageCount(success=1) self.assertRedirectsNoFollow(resp, index_url) @test.create_stubs({api.cinder: ('volume_type_extra_get', 'volume_type_extra_delete'), }) def test_extra_delete(self): vol_type = self.cinder_volume_types.first() extras = [api.cinder.VolTypeExtraSpec(vol_type.id, 'k1', 'v1')] formData = {'action': 'extras__delete__k1'} index_url = reverse('horizon:admin:volumes:volume_types:extras:index', args=[vol_type.id]) api.cinder.volume_type_extra_get(IsA(http.HttpRequest), vol_type.id).AndReturn(extras) api.cinder.volume_type_extra_delete(IsA(http.HttpRequest), vol_type.id, 'k1').AndReturn(vol_type) self.mox.ReplayAll() res = self.client.post(index_url, formData) self.assertNoFormErrors(res) self.assertRedirectsNoFollow(res, index_url) ",,1484,17
openstack%2Fhorizon~master~I1cf1732b8a734a4d5f154f5c2ab61231c60354b1,openstack/horizon,master,I1cf1732b8a734a4d5f154f5c2ab61231c60354b1,WIP Change User Settings Panel to Angular,ABANDONED,2016-08-27 00:06:47.000000000,2017-02-17 17:14:17.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9155}, {'_account_id': 9622}, {'_account_id': 23037}]","[{'number': 1, 'created': '2016-08-27 00:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/43c5aa5a03574bd63650765ef1d6a774144a8848', 'message': 'WIP Change User Settings Panel to Angular\n\nUse schema-form to generate the settings form.\n\nChange-Id: I1cf1732b8a734a4d5f154f5c2ab61231c60354b1\n'}, {'number': 2, 'created': '2016-08-27 00:15:24.000000000', 'files': ['openstack_dashboard/dashboards/settings/nguser/panel.py', 'openstack_dashboard/enabled/_5000_settings.py', 'openstack_dashboard/dashboards/settings/nguser/__init__.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/panel.html', 'openstack_dashboard/enabled/_5021_ng_user_settings_panel.py', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/user.module.js', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/settings.module.spec.js', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/settings.module.js', 'openstack_dashboard/dashboards/settings/nguser/views.py', 'openstack_dashboard/dashboards/settings/nguser/urls.py', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/user.controller.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5b9d4f08f3141cde0f65b4b0a49da3823fee0d70', 'message': 'WIP Change User Settings Panel to Angular\n\nUse schema-form to generate the settings form.\n\nChange-Id: I1cf1732b8a734a4d5f154f5c2ab61231c60354b1\n'}]",1,361529,5b9d4f08f3141cde0f65b4b0a49da3823fee0d70,9,5,2,9622,,,0,"WIP Change User Settings Panel to Angular

Use schema-form to generate the settings form.

Change-Id: I1cf1732b8a734a4d5f154f5c2ab61231c60354b1
",git fetch https://review.opendev.org/openstack/horizon refs/changes/29/361529/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/settings/nguser/panel.py', 'openstack_dashboard/enabled/_5000_settings.py', 'openstack_dashboard/dashboards/settings/nguser/__init__.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/panel.html', 'openstack_dashboard/enabled/_5021_ng_user_settings_panel.py', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/user.module.js', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/settings.module.spec.js', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/settings.module.js', 'openstack_dashboard/dashboards/settings/nguser/views.py', 'openstack_dashboard/dashboards/settings/nguser/urls.py', 'openstack_dashboard/dashboards/settings/static/dashboard/settings/user/user.controller.js']",12,43c5aa5a03574bd63650765ef1d6a774144a8848,ngsettings,"(function () { 'use strict'; angular .module('horizon.dashboard.settings.user') .controller('horizon.dashboard.settings.UserController', UserController); UserController.$inject = [ 'horizon.app.core.openstack-service-api.settings' ]; function UserController(settingsService) { var ctrl = this; ctrl.model = { page_size: horizon.cookies.get('horizon_pagesize'), instance_log_length: horizon.cookies.get('instance_log_length') }; ctrl.submitForm = submitForm; ctrl.schema = { type: 'object', properties: { language: { type: 'string' }, page_size: { type: 'string' }, instance_log_length: { type: 'string' } }, required: ['language', 'page_size', 'instance_log_length'] }; ctrl.form = [ { key: 'language', title: gettext('Language'), type: 'select' }, { key: 'page_size', title: gettext('Items Per Page'), description: gettext('Number of items to show per page ' + '(applies to the pages that have API supported pagination, Max Value: 1000)') }, { key: 'instance_log_length', title: gettext('Log Lines Per Instance'), description: gettext('Number of log lines to be shown per instance') }, { type: ""submit"", title: ""Save"" } ]; // get initial data if (angular.isUndefined(ctrl.model.page_size)) { settingsService.getSetting('API_RESULT_PAGE_SIZE').then( function(data) { ctrl.model.page_size = data ? data : '20'; }); } if (angular.isUndefined(ctrl.model.instance_log_length)) { settingsService.getSetting('INSTANCE_LOG_LENGTH').then( function(data) { ctrl.model.instance_log_length = data ? data : '35'; }); } settingsService.getSetting('LANGUAGES').then(setLanguages); settingsService.getSetting('LANGUAGE_COOKIE_NAME').then( function (cookieName) { var code = horizon.cookies.get(cookieName); if (angular.isUndefined(code)) { settingsService.getSetting('LANGUAGE_CODE').then(setLanguage); } else { setLanguage(code); } }); function setLanguages(data) { var obj = []; data.forEach(function(data) { obj.push({ value: data[0], name: data[1]}); }); ctrl.form[0].titleMap = obj; } function setLanguage(data) { ctrl.model.language = data; } function submitForm(form, model) { console.log(model); // TODO: Check that model has changed before updating horizon.cookies.put('horizon_pagesize', ctrl.model.page_size); horizon.cookies.put('instance_log_length', ctrl.model.instance_log_length); settingsService.getSetting('LANGUAGE_COOKIE_NAME').then( function (cookieName) { horizon.cookies.put(cookieName, ctrl.model.language); }); } } })(); ",,317,1
openstack%2Fhorizon~master~I2758e4ffd6c832a0d7d811db3a104f2fd03d9e09,openstack/horizon,master,I2758e4ffd6c832a0d7d811db3a104f2fd03d9e09,Add appropriate policy rules to admin networks panel,ABANDONED,2016-10-07 21:01:51.000000000,2017-02-17 17:14:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 12826}, {'_account_id': 14151}, {'_account_id': 23165}, {'_account_id': 23185}]","[{'number': 1, 'created': '2016-10-07 21:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3dcf6f5dca6fe33e858c70da4bfe154cfda56738', 'message': 'Add appropriate policy rules to admin networks panel\n\nCurrently many panels are missing their appropriate policy rules.\n\nThis patch adds policy rules to the admin networks panel.\n\nChange-Id: I2758e4ffd6c832a0d7d811db3a104f2fd03d9e09\nPartial-bug:#1534495\n'}, {'number': 2, 'created': '2016-10-26 18:34:23.000000000', 'files': ['openstack_dashboard/dashboards/admin/networks/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/29216ff1d7af1e8c8a035a4872563ae54a1d8a4f', 'message': 'Add appropriate policy rules to admin networks panel\n\nCurrently many panels are missing their appropriate policy rules.\n\nThis patch adds policy rules to the admin networks panel.\n\nChange-Id: I2758e4ffd6c832a0d7d811db3a104f2fd03d9e09\nPartial-bug:#1534495\n'}]",9,383937,29216ff1d7af1e8c8a035a4872563ae54a1d8a4f,14,7,2,23165,,,0,"Add appropriate policy rules to admin networks panel

Currently many panels are missing their appropriate policy rules.

This patch adds policy rules to the admin networks panel.

Change-Id: I2758e4ffd6c832a0d7d811db3a104f2fd03d9e09
Partial-bug:#1534495
",git fetch https://review.opendev.org/openstack/horizon refs/changes/37/383937/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/admin/networks/panel.py'],1,3dcf6f5dca6fe33e858c70da4bfe154cfda56738,networkspanel," policy_rules = ((""compute"", ""network:get_all""), (""compute"", ""network:create""))",,2,0
openstack%2Fhorizon~master~If19fa192d8957058b6a78dc350f95668900528d5,openstack/horizon,master,If19fa192d8957058b6a78dc350f95668900528d5,Prompt user to confirm deletes on network topology,ABANDONED,2016-10-06 22:38:31.000000000,2017-02-17 17:14:14.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 9155}, {'_account_id': 17172}, {'_account_id': 22587}]","[{'number': 1, 'created': '2016-10-06 22:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af0c626729923976b0305a9d68dbe3768b936b8a', 'message': 'Prompt user to confirm deletes on network topology\n\nAdds modal confirmations for deleting resources on network topology\ngraph.\n\nChange-Id: If19fa192d8957058b6a78dc350f95668900528d5\nFixes-bug: #1631162\n'}, {'number': 2, 'created': '2016-10-07 20:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/df9343c6bcead0ebbd182635728efb31e4b10031', 'message': 'Prompt user to confirm deletes on network topology\n\nAdds modal confirmations for deleting resources on network topology\ngraph.\n\nChange-Id: If19fa192d8957058b6a78dc350f95668900528d5\nFixes-bug: #1631162\n'}, {'number': 3, 'created': '2016-12-17 01:13:25.000000000', 'files': ['horizon/static/horizon/js/horizon.networktopology.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a13cff6b7353ae783744fba1aa98b4177d86e7f1', 'message': 'Prompt user to confirm deletes on network topology\n\nAdds modal confirmations for deleting resources on network topology\ngraph.\n\nChange-Id: If19fa192d8957058b6a78dc350f95668900528d5\nFixes-bug: #1631162\n'}]",0,383500,a13cff6b7353ae783744fba1aa98b4177d86e7f1,11,5,3,13474,,,0,"Prompt user to confirm deletes on network topology

Adds modal confirmations for deleting resources on network topology
graph.

Change-Id: If19fa192d8957058b6a78dc350f95668900528d5
Fixes-bug: #1631162
",git fetch https://review.opendev.org/openstack/horizon refs/changes/00/383500/3 && git format-patch -1 --stdout FETCH_HEAD,['horizon/static/horizon/js/horizon.networktopology.js'],1,af0c626729923976b0305a9d68dbe3768b936b8a,bug/1631162," confirm:function(action, name_string, func) { var $action = $(action), $modal_parent = $(action).closest("".modal""), name_array = [], action_string, title, body, modal, form; if($action.hasClass(""disabled"")) { return; } action_string = $action.text(); name_string = interpolate(gettext(""You have selected %s. ""), [name_string]); title = interpolate(gettext(""Confirm %s""), [action_string]); body = name_string + gettext(""Please confirm your selection.""); modal = horizon.modals.create(title, body, action_string); modal.modal(); if($modal_parent.length) { var child_backdrop = modal.next("".modal-backdrop""); // re-arrange z-index for these stacking modal child_backdrop.css(""z-index"", $modal_parent.css(""z-index"")+10); modal.css(""z-index"", child_backdrop.css(""z-index"")+10); } modal.find("".btn-primary"").click(function () { $action.prop(""disabled"", true); d3.select(""#id_"" + $action.data(""device-id"")).classed(""loading"",true); func(); modal.modal(""hide""); return false; }); return modal; }, var _this = angular.element(this), balloon = _this.parents('.topologyBalloon'), name_string = htmlData.name, delete_func = self.delete_device.bind(self, _this.data('type'),_this.data('device-id')); self.confirm(_this, name_string, delete_func); self.delete_balloon(); var _this = angular.element(this), table_row = _this.parents('tr'), name_string = table_row.find('th span').attr('title') || '', delete_func = self.delete_port.bind(self, _this.data('router-id'),_this.data('port-id'),_this.data('network-id')); self.confirm(_this, name_string, delete_func);"," var _this = angular.element(this); _this.prop('disabled', true); d3.select('#id_' + _this.data('device-id')).classed('loading',true); self.delete_device(_this.data('type'),_this.data('device-id')); var _this = angular.element(this); self.delete_port(_this.data('router-id'),_this.data('port-id'),_this.data('network-id'));",46,6
openstack%2Fhorizon~master~I96bf361dde273a35bd6f4878a691c676c2439f73,openstack/horizon,master,I96bf361dde273a35bd6f4878a691c676c2439f73,Ability to manage implied roles,ABANDONED,2016-07-22 09:57:27.000000000,2017-02-17 17:14:11.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7179}, {'_account_id': 14151}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-07-22 09:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/53a70dfa5608b89c953bc16a2f4904e4003085dc', 'message': '[WIP]Ability to create implied role\n\nKeystone implemented this feature in Mitaka\n - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html\n - https://blueprints.launchpad.net/keystone/+spec/implied-roles\n\n//TOOD\n - create detail page for role\n\nChange-Id: I96bf361dde273a35bd6f4878a691c676c2439f73\n'}, {'number': 2, 'created': '2016-07-26 05:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8053c799eeb75644f97f21bcfb092719dcb1ab50', 'message': 'Ability to manage implied roles\n\nKeystone implemented this feature in Mitaka\n - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html\nThis patch will support it.\n\nChange-Id: I96bf361dde273a35bd6f4878a691c676c2439f73\nCloses-Bug: #1606430\n'}, {'number': 3, 'created': '2016-07-29 07:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7677991e83f7800103fe8575a51a57ad2826d44c', 'message': 'Ability to manage implied roles\n\nKeystone implemented this feature in Mitaka\n - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html\nThis patch will support it.\n\nImplementation for angular is after being the patch below merged.\nhttps://review.openstack.org/#/c/222825/\n\nChange-Id: I96bf361dde273a35bd6f4878a691c676c2439f73\nCloses-Bug: #1606430\n'}, {'number': 4, 'created': '2016-08-05 09:58:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/457598ceb447ab8a39f081659aa5292834e0c37a', 'message': 'Ability to manage implied roles\n\nKeystone implemented this feature in Mitaka\n - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html\nThis patch will support it.\n\nImplementation for angular can proceed after this patch merges:\nhttps://review.openstack.org/#/c/222825/\n\nChange-Id: I96bf361dde273a35bd6f4878a691c676c2439f73\nCloses-Bug: #1606430\n'}, {'number': 5, 'created': '2016-08-24 01:54:20.000000000', 'files': ['releasenotes/notes/bug-1606430-e67212f21f89a68b.yaml', 'openstack_dashboard/dashboards/identity/roles/urls.py', 'openstack_dashboard/dashboards/identity/roles/templates/roles/_detail_overview.html', 'openstack_dashboard/dashboards/identity/roles/tables.py', 'openstack_dashboard/dashboards/identity/roles/tests.py', 'openstack_dashboard/dashboards/identity/roles/templates/roles/detail.html', 'horizon/utils/filters.py', 'openstack_dashboard/dashboards/identity/roles/views.py', 'openstack_dashboard/dashboards/identity/roles/forms.py', 'openstack_dashboard/api/keystone.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5353f0cd24c9f4bcbef5b412ae7a75f6a047691e', 'message': 'Ability to manage implied roles\n\nKeystone implemented this feature in Mitaka\n - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html\nThis patch will support it.\n\nImplementation for angular can proceed after this patch merges:\nhttps://review.openstack.org/#/c/222825/\n\nChange-Id: I96bf361dde273a35bd6f4878a691c676c2439f73\nCloses-Bug: #1606430\n'}]",6,345955,5353f0cd24c9f4bcbef5b412ae7a75f6a047691e,25,5,5,17172,,,0,"Ability to manage implied roles

Keystone implemented this feature in Mitaka
 - http://specs.openstack.org/openstack/keystone-specs/specs/backlog/implied-roles.html
This patch will support it.

Implementation for angular can proceed after this patch merges:
https://review.openstack.org/#/c/222825/

Change-Id: I96bf361dde273a35bd6f4878a691c676c2439f73
Closes-Bug: #1606430
",git fetch https://review.opendev.org/openstack/horizon refs/changes/55/345955/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/roles/tests.py', 'openstack_dashboard/dashboards/identity/roles/forms.py', 'openstack_dashboard/api/keystone.py']",3,53a70dfa5608b89c953bc16a2f4904e4003085dc,bug/1606430," def implied_create(request, prior_role, implied_role, **kwargs): manager = keystoneclient(request, admin=True).roles return manager.create_implied(prior_role, implied_role, **kwargs) def implied_get(request, prior_role, implied_role, **kwargs): manager = keystoneclient(request, admin=True).roles return manager.get_implied(prior_role, implied_role, **kwargs) def implied_delete(request, prior_role, implied_role, **kwargs): manager = keystoneclient(request, admin=True).roles return manager.delete_implied(prior_role, implied_role, **kwargs) def implied_check(request, prior_role, implied_role, **kwargs): manager = keystoneclient(request, admin=True).roles return manager.check_implied(prior_role, implied_role, **kwargs) def list_role_inferences(request, **kwargs): manager = keystoneclient(request, admin=True).roles return manager.list_role_inferences(**kwargs)",,88,3
openstack%2Fhorizon~master~I19c97195ce8954c33d85cf96a729269e9a9f537b,openstack/horizon,master,I19c97195ce8954c33d85cf96a729269e9a9f537b,retrieve password when the key is protected,ABANDONED,2016-10-11 14:45:43.000000000,2017-02-17 17:14:10.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 20509}, {'_account_id': 21987}]","[{'number': 1, 'created': '2016-10-11 14:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0b84316035d87cb27541075c2a8bfbfcc7c94377', 'message': 'retrieve password when the key is protected\nwhen the private key is crypted with a\npassphrase, horizon is unable to decrypt\nit.\nA new input has been added to the form\nand with the jsrsasign lib, the private\nkey is decrypted before the password\nCloses-Bug: #1632353\n\nChange-Id: I19c97195ce8954c33d85cf96a729269e9a9f537b\n'}, {'number': 2, 'created': '2016-10-12 12:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/03a10de6262fc662244116a59656e8c5022c6d78', 'message': 'retrieve password when the key is protected\nwhen the private key is crypted with a\npassphrase, horizon is unable to decrypt\nit.\nA new input has been added to the form\nand with the jsrsasign lib, the private\nkey is decrypted before the password\nCloses-Bug: #1632353\n\nChange-Id: I19c97195ce8954c33d85cf96a729269e9a9f537b\n'}, {'number': 3, 'created': '2017-01-12 10:29:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6eb3fafaa4e2ec3e6038d1e950e714df14fb138c', 'message': 'retrieve password when the key is protected\nwhen the private key is crypted with a\npassphrase, horizon is unable to decrypt\nit.\nA new input has been added to the form\nand with the jsrsasign lib, the private\nkey is decrypted before the password\nCloses-Bug: #1632353\n\nChange-Id: I19c97195ce8954c33d85cf96a729269e9a9f537b\n'}, {'number': 4, 'created': '2017-01-12 10:29:44.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/templates/instances/_decryptpassword.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/instances/instances.module.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/instances/retrieve-password.controller.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/project.module.js', 'openstack_dashboard/static/js/horizon.instances.js', 'openstack_dashboard/templates/horizon/_scripts.html', 'openstack_dashboard/dashboards/project/instances/forms.py', 'horizon/static/horizon/lib/jsrsasign/jsrsasign.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/96934b1311fe13c0234cf5553fcbb64a65d9a79c', 'message': 'retrieve password when the key is protected\n\nwhen the private key is crypted with a\npassphrase, horizon is unable to decrypt\nit.\nA new input has been added to the form\nand with the jsrsasign lib, the private\nkey is decrypted before the password\nCloses-Bug: #1632353\n\nChange-Id: I19c97195ce8954c33d85cf96a729269e9a9f537b\n'}]",5,385042,96934b1311fe13c0234cf5553fcbb64a65d9a79c,11,4,4,23045,,,0,"retrieve password when the key is protected

when the private key is crypted with a
passphrase, horizon is unable to decrypt
it.
A new input has been added to the form
and with the jsrsasign lib, the private
key is decrypted before the password
Closes-Bug: #1632353

Change-Id: I19c97195ce8954c33d85cf96a729269e9a9f537b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/385042/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/instances/templates/instances/_decryptpassword.html', 'openstack_dashboard/dashboards/project/static/dashboard/project/instances/instances.module.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/instances/retrieve-password.controller.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/project.module.js', 'openstack_dashboard/templates/horizon/_scripts.html', 'openstack_dashboard/dashboards/project/instances/forms.py', 'horizon/static/horizon/js/horizon.instances.js', 'horizon/static/horizon/lib/jsrsasign/jsrsasign.js']",8,0b84316035d87cb27541075c2a8bfbfcc7c94377,(detached," /* * jsrsasign 4.2.2 (c) 2010-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ /* yahoo-min.js Copyright (c) 2011, Yahoo! Inc. All rights reserved. Code licensed under the BSD License: http://developer.yahoo.com/yui/license.html version: 2.9.0 */ if(typeof YAHOO==""undefined""||!YAHOO){var YAHOO={};}YAHOO.namespace=function(){var b=arguments,g=null,e,c,f;for(e=0;e<b.length;e=e+1){f=(""""+b[e]).split(""."");g=YAHOO;for(c=(f[0]==""YAHOO"")?1:0;c<f.length;c=c+1){g[f[c]]=g[f[c]]||{};g=g[f[c]];}}return g;};YAHOO.log=function(d,a,c){var b=YAHOO.widget.Logger;if(b&&b.log){return b.log(d,a,c);}else{return false;}};YAHOO.register=function(a,f,e){var k=YAHOO.env.modules,c,j,h,g,d;if(!k[a]){k[a]={versions:[],builds:[]};}c=k[a];j=e.version;h=e.build;g=YAHOO.env.listeners;c.name=a;c.version=j;c.build=h;c.versions.push(j);c.builds.push(h);c.mainClass=f;for(d=0;d<g.length;d=d+1){g[d](c);}if(f){f.VERSION=j;f.BUILD=h;}else{YAHOO.log(""mainClass is undefined for module ""+a,""warn"");}};YAHOO.env=YAHOO.env||{modules:[],listeners:[]};YAHOO.env.getVersion=function(a){return YAHOO.env.modules[a]||null;};YAHOO.env.parseUA=function(d){var e=function(i){var j=0;return parseFloat(i.replace(/\./g,function(){return(j++==1)?"""":""."";}));},h=navigator,g={ie:0,opera:0,gecko:0,webkit:0,chrome:0,mobile:null,air:0,ipad:0,iphone:0,ipod:0,ios:null,android:0,webos:0,caja:h&&h.cajaVersion,secure:false,os:null},c=d||(navigator&&navigator.userAgent),f=window&&window.location,b=f&&f.href,a;g.secure=b&&(b.toLowerCase().indexOf(""https"")===0);if(c){if((/windows|win32/i).test(c)){g.os=""windows"";}else{if((/macintosh/i).test(c)){g.os=""macintosh"";}else{if((/rhino/i).test(c)){g.os=""rhino"";}}}if((/KHTML/).test(c)){g.webkit=1;}a=c.match(/AppleWebKit\/([^\s]*)/);if(a&&a[1]){g.webkit=e(a[1]);if(/ Mobile\//.test(c)){g.mobile=""Apple"";a=c.match(/OS ([^\s]*)/);if(a&&a[1]){a=e(a[1].replace(""_"","".""));}g.ios=a;g.ipad=g.ipod=g.iphone=0;a=c.match(/iPad|iPod|iPhone/);if(a&&a[0]){g[a[0].toLowerCase()]=g.ios;}}else{a=c.match(/NokiaN[^\/]*|Android \d\.\d|webOS\/\d\.\d/);if(a){g.mobile=a[0];}if(/webOS/.test(c)){g.mobile=""WebOS"";a=c.match(/webOS\/([^\s]*);/);if(a&&a[1]){g.webos=e(a[1]);}}if(/ Android/.test(c)){g.mobile=""Android"";a=c.match(/Android ([^\s]*);/);if(a&&a[1]){g.android=e(a[1]);}}}a=c.match(/Chrome\/([^\s]*)/);if(a&&a[1]){g.chrome=e(a[1]);}else{a=c.match(/AdobeAIR\/([^\s]*)/);if(a){g.air=a[0];}}}if(!g.webkit){a=c.match(/Opera[\s\/]([^\s]*)/);if(a&&a[1]){g.opera=e(a[1]);a=c.match(/Version\/([^\s]*)/);if(a&&a[1]){g.opera=e(a[1]);}a=c.match(/Opera Mini[^;]*/);if(a){g.mobile=a[0];}}else{a=c.match(/MSIE\s([^;]*)/);if(a&&a[1]){g.ie=e(a[1]);}else{a=c.match(/Gecko\/([^\s]*)/);if(a){g.gecko=1;a=c.match(/rv:([^\s\)]*)/);if(a&&a[1]){g.gecko=e(a[1]);}}}}}}return g;};YAHOO.env.ua=YAHOO.env.parseUA();(function(){YAHOO.namespace(""util"",""widget"",""example"");if(""undefined""!==typeof YAHOO_config){var b=YAHOO_config.listener,a=YAHOO.env.listeners,d=true,c;if(b){for(c=0;c<a.length;c++){if(a[c]==b){d=false;break;}}if(d){a.push(b);}}}})();YAHOO.lang=YAHOO.lang||{};(function(){var f=YAHOO.lang,a=Object.prototype,c=""[object Array]"",h=""[object Function]"",i=""[object Object]"",b=[],g={""&"":""&amp;"",""<"":""&lt;"","">"":""&gt;"",'""':""&quot;"",""'"":""&#x27;"",""/"":""&#x2F;"",""`"":""&#x60;""},d=[""toString"",""valueOf""],e={isArray:function(j){return a.toString.apply(j)===c;},isBoolean:function(j){return typeof j===""boolean"";},isFunction:function(j){return(typeof j===""function"")||a.toString.apply(j)===h;},isNull:function(j){return j===null;},isNumber:function(j){return typeof j===""number""&&isFinite(j);},isObject:function(j){return(j&&(typeof j===""object""||f.isFunction(j)))||false;},isString:function(j){return typeof j===""string"";},isUndefined:function(j){return typeof j===""undefined"";},_IEEnumFix:(YAHOO.env.ua.ie)?function(l,k){var j,n,m;for(j=0;j<d.length;j=j+1){n=d[j];m=k[n];if(f.isFunction(m)&&m!=a[n]){l[n]=m;}}}:function(){},escapeHTML:function(j){return j.replace(/[&<>""'\/`]/g,function(k){return g[k];});},extend:function(m,n,l){if(!n||!m){throw new Error(""extend failed, please check that ""+""all dependencies are included."");}var k=function(){},j;k.prototype=n.prototype;m.prototype=new k();m.prototype.constructor=m;m.superclass=n.prototype;if(n.prototype.constructor==a.constructor){n.prototype.constructor=n;}if(l){for(j in l){if(f.hasOwnProperty(l,j)){m.prototype[j]=l[j];}}f._IEEnumFix(m.prototype,l);}},augmentObject:function(n,m){if(!m||!n){throw new Error(""Absorb failed, verify dependencies."");}var j=arguments,l,o,k=j[2];if(k&&k!==true){for(l=2;l<j.length;l=l+1){n[j[l]]=m[j[l]];}}else{for(o in m){if(k||!(o in n)){n[o]=m[o];}}f._IEEnumFix(n,m);}return n;},augmentProto:function(m,l){if(!l||!m){throw new Error(""Augment failed, verify dependencies."");}var j=[m.prototype,l.prototype],k;for(k=2;k<arguments.length;k=k+1){j.push(arguments[k]);}f.augmentObject.apply(this,j);return m;},dump:function(j,p){var l,n,r=[],t=""{...}"",k=""f(){...}"",q="", "",m="" => "";if(!f.isObject(j)){return j+"""";}else{if(j instanceof Date||(""nodeType"" in j&&""tagName"" in j)){return j;}else{if(f.isFunction(j)){return k;}}}p=(f.isNumber(p))?p:3;if(f.isArray(j)){r.push(""["");for(l=0,n=j.length;l<n;l=l+1){if(f.isObject(j[l])){r.push((p>0)?f.dump(j[l],p-1):t);}else{r.push(j[l]);}r.push(q);}if(r.length>1){r.pop();}r.push(""]"");}else{r.push(""{"");for(l in j){if(f.hasOwnProperty(j,l)){r.push(l+m);if(f.isObject(j[l])){r.push((p>0)?f.dump(j[l],p-1):t);}else{r.push(j[l]);}r.push(q);}}if(r.length>1){r.pop();}r.push(""}"");}return r.join("""");},substitute:function(x,y,E,l){var D,C,B,G,t,u,F=[],p,z=x.length,A=""dump"",r="" "",q=""{"",m=""}"",n,w;for(;;){D=x.lastIndexOf(q,z);if(D<0){break;}C=x.indexOf(m,D);if(D+1>C){break;}p=x.substring(D+1,C);G=p;u=null;B=G.indexOf(r);if(B>-1){u=G.substring(B+1);G=G.substring(0,B);}t=y[G];if(E){t=E(G,t,u);}if(f.isObject(t)){if(f.isArray(t)){t=f.dump(t,parseInt(u,10));}else{u=u||"""";n=u.indexOf(A);if(n>-1){u=u.substring(4);}w=t.toString();if(w===i||n>-1){t=f.dump(t,parseInt(u,10));}else{t=w;}}}else{if(!f.isString(t)&&!f.isNumber(t)){t=""~-""+F.length+""-~"";F[F.length]=p;}}x=x.substring(0,D)+t+x.substring(C+1);if(l===false){z=D-1;}}for(D=F.length-1;D>=0;D=D-1){x=x.replace(new RegExp(""~-""+D+""-~""),""{""+F[D]+""}"",""g"");}return x;},trim:function(j){try{return j.replace(/^\s+|\s+$/g,"""");}catch(k){return j; }},merge:function(){var n={},k=arguments,j=k.length,m;for(m=0;m<j;m=m+1){f.augmentObject(n,k[m],true);}return n;},later:function(t,k,u,n,p){t=t||0;k=k||{};var l=u,s=n,q,j;if(f.isString(u)){l=k[u];}if(!l){throw new TypeError(""method undefined"");}if(!f.isUndefined(n)&&!f.isArray(s)){s=[n];}q=function(){l.apply(k,s||b);};j=(p)?setInterval(q,t):setTimeout(q,t);return{interval:p,cancel:function(){if(this.interval){clearInterval(j);}else{clearTimeout(j);}}};},isValue:function(j){return(f.isObject(j)||f.isString(j)||f.isNumber(j)||f.isBoolean(j));}};f.hasOwnProperty=(a.hasOwnProperty)?function(j,k){return j&&j.hasOwnProperty&&j.hasOwnProperty(k);}:function(j,k){return !f.isUndefined(j[k])&&j.constructor.prototype[k]!==j[k];};e.augmentObject(f,e,true);YAHOO.util.Lang=f;f.augment=f.augmentProto;YAHOO.augment=f.augmentProto;YAHOO.extend=f.extend;})();YAHOO.register(""yahoo"",YAHOO,{version:""2.9.0"",build:""2800""}); /*! CryptoJS v3.1.2 core-fix.js * code.google.com/p/crypto-js * (c) 2009-2013 by Jeff Mott. All rights reserved. * code.google.com/p/crypto-js/wiki/License * THIS IS FIX of 'core.js' to fix Hmac issue. * https://code.google.com/p/crypto-js/issues/detail?id=84 * https://crypto-js.googlecode.com/svn-history/r667/branches/3.x/src/core.js */ var CryptoJS=CryptoJS||(function(e,g){var a={};var b=a.lib={};var j=b.Base=(function(){function n(){}return{extend:function(p){n.prototype=this;var o=new n();if(p){o.mixIn(p)}if(!o.hasOwnProperty(""init"")){o.init=function(){o.$super.init.apply(this,arguments)}}o.init.prototype=o;o.$super=this;return o},create:function(){var o=this.extend();o.init.apply(o,arguments);return o},init:function(){},mixIn:function(p){for(var o in p){if(p.hasOwnProperty(o)){this[o]=p[o]}}if(p.hasOwnProperty(""toString"")){this.toString=p.toString}},clone:function(){return this.init.prototype.extend(this)}}}());var l=b.WordArray=j.extend({init:function(o,n){o=this.words=o||[];if(n!=g){this.sigBytes=n}else{this.sigBytes=o.length*4}},toString:function(n){return(n||h).stringify(this)},concat:function(t){var q=this.words;var p=t.words;var n=this.sigBytes;var s=t.sigBytes;this.clamp();if(n%4){for(var r=0;r<s;r++){var o=(p[r>>>2]>>>(24-(r%4)*8))&255;q[(n+r)>>>2]|=o<<(24-((n+r)%4)*8)}}else{for(var r=0;r<s;r+=4){q[(n+r)>>>2]=p[r>>>2]}}this.sigBytes+=s;return this},clamp:function(){var o=this.words;var n=this.sigBytes;o[n>>>2]&=4294967295<<(32-(n%4)*8);o.length=e.ceil(n/4)},clone:function(){var n=j.clone.call(this);n.words=this.words.slice(0);return n},random:function(p){var o=[];for(var n=0;n<p;n+=4){o.push((e.random()*4294967296)|0)}return new l.init(o,p)}});var m=a.enc={};var h=m.Hex={stringify:function(p){var r=p.words;var o=p.sigBytes;var q=[];for(var n=0;n<o;n++){var s=(r[n>>>2]>>>(24-(n%4)*8))&255;q.push((s>>>4).toString(16));q.push((s&15).toString(16))}return q.join("""")},parse:function(p){var n=p.length;var q=[];for(var o=0;o<n;o+=2){q[o>>>3]|=parseInt(p.substr(o,2),16)<<(24-(o%8)*4)}return new l.init(q,n/2)}};var d=m.Latin1={stringify:function(q){var r=q.words;var p=q.sigBytes;var n=[];for(var o=0;o<p;o++){var s=(r[o>>>2]>>>(24-(o%4)*8))&255;n.push(String.fromCharCode(s))}return n.join("""")},parse:function(p){var n=p.length;var q=[];for(var o=0;o<n;o++){q[o>>>2]|=(p.charCodeAt(o)&255)<<(24-(o%4)*8)}return new l.init(q,n)}};var c=m.Utf8={stringify:function(n){try{return decodeURIComponent(escape(d.stringify(n)))}catch(o){throw new Error(""Malformed UTF-8 data"")}},parse:function(n){return d.parse(unescape(encodeURIComponent(n)))}};var i=b.BufferedBlockAlgorithm=j.extend({reset:function(){this._data=new l.init();this._nDataBytes=0},_append:function(n){if(typeof n==""string""){n=c.parse(n)}this._data.concat(n);this._nDataBytes+=n.sigBytes},_process:function(w){var q=this._data;var x=q.words;var n=q.sigBytes;var t=this.blockSize;var v=t*4;var u=n/v;if(w){u=e.ceil(u)}else{u=e.max((u|0)-this._minBufferSize,0)}var s=u*t;var r=e.min(s*4,n);if(s){for(var p=0;p<s;p+=t){this._doProcessBlock(x,p)}var o=x.splice(0,s);q.sigBytes-=r}return new l.init(o,r)},clone:function(){var n=j.clone.call(this);n._data=this._data.clone();return n},_minBufferSize:0});var f=b.Hasher=i.extend({cfg:j.extend(),init:function(n){this.cfg=this.cfg.extend(n);this.reset()},reset:function(){i.reset.call(this);this._doReset()},update:function(n){this._append(n);this._process();return this},finalize:function(n){if(n){this._append(n)}var o=this._doFinalize();return o},blockSize:512/32,_createHelper:function(n){return function(p,o){return new n.init(o).finalize(p)}},_createHmacHelper:function(n){return function(p,o){return new k.HMAC.init(n,o).finalize(p)}}});var k=a.algo={};return a}(Math));/* CryptoJS v3.1.2 x64-core-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(g){var a=CryptoJS,f=a.lib,e=f.Base,h=f.WordArray,a=a.x64={};a.Word=e.extend({init:function(b,c){this.high=b;this.low=c}});a.WordArray=e.extend({init:function(b,c){b=this.words=b||[];this.sigBytes=c!=g?c:8*b.length},toX32:function(){for(var b=this.words,c=b.length,a=[],d=0;d<c;d++){var e=b[d];a.push(e.high);a.push(e.low)}return h.create(a,this.sigBytes)},clone:function(){for(var b=e.clone.call(this),c=b.words=this.words.slice(0),a=c.length,d=0;d<a;d++)c[d]=c[d].clone();return b}})})(); /* CryptoJS v3.1.2 hmac-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var c=CryptoJS,k=c.enc.Utf8;c.algo.HMAC=c.lib.Base.extend({init:function(a,b){a=this._hasher=new a.init;""string""==typeof b&&(b=k.parse(b));var c=a.blockSize,e=4*c;b.sigBytes>e&&(b=a.finalize(b));b.clamp();for(var f=this._oKey=b.clone(),g=this._iKey=b.clone(),h=f.words,j=g.words,d=0;d<c;d++)h[d]^=1549556828,j[d]^=909522486;f.sigBytes=g.sigBytes=e;this.reset()},reset:function(){var a=this._hasher;a.reset();a.update(this._iKey)},update:function(a){this._hasher.update(a);return this},finalize:function(a){var b= this._hasher;a=b.finalize(a);b.reset();return b.finalize(this._oKey.clone().concat(a))}})})(); /* CryptoJS v3.1.2 sha256-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(k){for(var g=CryptoJS,h=g.lib,v=h.WordArray,j=h.Hasher,h=g.algo,s=[],t=[],u=function(q){return 4294967296*(q-(q|0))|0},l=2,b=0;64>b;){var d;a:{d=l;for(var w=k.sqrt(d),r=2;r<=w;r++)if(!(d%r)){d=!1;break a}d=!0}d&&(8>b&&(s[b]=u(k.pow(l,0.5))),t[b]=u(k.pow(l,1/3)),b++);l++}var n=[],h=h.SHA256=j.extend({_doReset:function(){this._hash=new v.init(s.slice(0))},_doProcessBlock:function(q,h){for(var a=this._hash.words,c=a[0],d=a[1],b=a[2],k=a[3],f=a[4],g=a[5],j=a[6],l=a[7],e=0;64>e;e++){if(16>e)n[e]= q[h+e]|0;else{var m=n[e-15],p=n[e-2];n[e]=((m<<25|m>>>7)^(m<<14|m>>>18)^m>>>3)+n[e-7]+((p<<15|p>>>17)^(p<<13|p>>>19)^p>>>10)+n[e-16]}m=l+((f<<26|f>>>6)^(f<<21|f>>>11)^(f<<7|f>>>25))+(f&g^~f&j)+t[e]+n[e];p=((c<<30|c>>>2)^(c<<19|c>>>13)^(c<<10|c>>>22))+(c&d^c&b^d&b);l=j;j=g;g=f;f=k+m|0;k=b;b=d;d=c;c=m+p|0}a[0]=a[0]+c|0;a[1]=a[1]+d|0;a[2]=a[2]+b|0;a[3]=a[3]+k|0;a[4]=a[4]+f|0;a[5]=a[5]+g|0;a[6]=a[6]+j|0;a[7]=a[7]+l|0},_doFinalize:function(){var d=this._data,b=d.words,a=8*this._nDataBytes,c=8*d.sigBytes; b[c>>>5]|=128<<24-c%32;b[(c+64>>>9<<4)+14]=k.floor(a/4294967296);b[(c+64>>>9<<4)+15]=a;d.sigBytes=4*b.length;this._process();return this._hash},clone:function(){var b=j.clone.call(this);b._hash=this._hash.clone();return b}});g.SHA256=j._createHelper(h);g.HmacSHA256=j._createHmacHelper(h)})(Math); /* CryptoJS v3.1.2 sha224-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var b=CryptoJS,d=b.lib.WordArray,a=b.algo,c=a.SHA256,a=a.SHA224=c.extend({_doReset:function(){this._hash=new d.init([3238371032,914150663,812702999,4144912697,4290775857,1750603025,1694076839,3204075428])},_doFinalize:function(){var a=c._doFinalize.call(this);a.sigBytes-=4;return a}});b.SHA224=c._createHelper(a);b.HmacSHA224=c._createHmacHelper(a)})(); /* CryptoJS v3.1.2 sha512-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){function a(){return d.create.apply(d,arguments)}for(var n=CryptoJS,r=n.lib.Hasher,e=n.x64,d=e.Word,T=e.WordArray,e=n.algo,ea=[a(1116352408,3609767458),a(1899447441,602891725),a(3049323471,3964484399),a(3921009573,2173295548),a(961987163,4081628472),a(1508970993,3053834265),a(2453635748,2937671579),a(2870763221,3664609560),a(3624381080,2734883394),a(310598401,1164996542),a(607225278,1323610764),a(1426881987,3590304994),a(1925078388,4068182383),a(2162078206,991336113),a(2614888103,633803317), a(3248222580,3479774868),a(3835390401,2666613458),a(4022224774,944711139),a(264347078,2341262773),a(604807628,2007800933),a(770255983,1495990901),a(1249150122,1856431235),a(1555081692,3175218132),a(1996064986,2198950837),a(2554220882,3999719339),a(2821834349,766784016),a(2952996808,2566594879),a(3210313671,3203337956),a(3336571891,1034457026),a(3584528711,2466948901),a(113926993,3758326383),a(338241895,168717936),a(666307205,1188179964),a(773529912,1546045734),a(1294757372,1522805485),a(1396182291, 2643833823),a(1695183700,2343527390),a(1986661051,1014477480),a(2177026350,1206759142),a(2456956037,344077627),a(2730485921,1290863460),a(2820302411,3158454273),a(3259730800,3505952657),a(3345764771,106217008),a(3516065817,3606008344),a(3600352804,1432725776),a(4094571909,1467031594),a(275423344,851169720),a(430227734,3100823752),a(506948616,1363258195),a(659060556,3750685593),a(883997877,3785050280),a(958139571,3318307427),a(1322822218,3812723403),a(1537002063,2003034995),a(1747873779,3602036899), a(1955562222,1575990012),a(2024104815,1125592928),a(2227730452,2716904306),a(2361852424,442776044),a(2428436474,593698344),a(2756734187,3733110249),a(3204031479,2999351573),a(3329325298,3815920427),a(3391569614,3928383900),a(3515267271,566280711),a(3940187606,3454069534),a(4118630271,4000239992),a(116418474,1914138554),a(174292421,2731055270),a(289380356,3203993006),a(460393269,320620315),a(685471733,587496836),a(852142971,1086792851),a(1017036298,365543100),a(1126000580,2618297676),a(1288033470, 3409855158),a(1501505948,4234509866),a(1607167915,987167468),a(1816402316,1246189591)],v=[],w=0;80>w;w++)v[w]=a();e=e.SHA512=r.extend({_doReset:function(){this._hash=new T.init([new d.init(1779033703,4089235720),new d.init(3144134277,2227873595),new d.init(1013904242,4271175723),new d.init(2773480762,1595750129),new d.init(1359893119,2917565137),new d.init(2600822924,725511199),new d.init(528734635,4215389547),new d.init(1541459225,327033209)])},_doProcessBlock:function(a,d){for(var f=this._hash.words, F=f[0],e=f[1],n=f[2],r=f[3],G=f[4],H=f[5],I=f[6],f=f[7],w=F.high,J=F.low,X=e.high,K=e.low,Y=n.high,L=n.low,Z=r.high,M=r.low,$=G.high,N=G.low,aa=H.high,O=H.low,ba=I.high,P=I.low,ca=f.high,Q=f.low,k=w,g=J,z=X,x=K,A=Y,y=L,U=Z,B=M,l=$,h=N,R=aa,C=O,S=ba,D=P,V=ca,E=Q,m=0;80>m;m++){var s=v[m];if(16>m)var j=s.high=a[d+2*m]|0,b=s.low=a[d+2*m+1]|0;else{var j=v[m-15],b=j.high,p=j.low,j=(b>>>1|p<<31)^(b>>>8|p<<24)^b>>>7,p=(p>>>1|b<<31)^(p>>>8|b<<24)^(p>>>7|b<<25),u=v[m-2],b=u.high,c=u.low,u=(b>>>19|c<<13)^(b<< 3|c>>>29)^b>>>6,c=(c>>>19|b<<13)^(c<<3|b>>>29)^(c>>>6|b<<26),b=v[m-7],W=b.high,t=v[m-16],q=t.high,t=t.low,b=p+b.low,j=j+W+(b>>>0<p>>>0?1:0),b=b+c,j=j+u+(b>>>0<c>>>0?1:0),b=b+t,j=j+q+(b>>>0<t>>>0?1:0);s.high=j;s.low=b}var W=l&R^~l&S,t=h&C^~h&D,s=k&z^k&A^z&A,T=g&x^g&y^x&y,p=(k>>>28|g<<4)^(k<<30|g>>>2)^(k<<25|g>>>7),u=(g>>>28|k<<4)^(g<<30|k>>>2)^(g<<25|k>>>7),c=ea[m],fa=c.high,da=c.low,c=E+((h>>>14|l<<18)^(h>>>18|l<<14)^(h<<23|l>>>9)),q=V+((l>>>14|h<<18)^(l>>>18|h<<14)^(l<<23|h>>>9))+(c>>>0<E>>>0?1: 0),c=c+t,q=q+W+(c>>>0<t>>>0?1:0),c=c+da,q=q+fa+(c>>>0<da>>>0?1:0),c=c+b,q=q+j+(c>>>0<b>>>0?1:0),b=u+T,s=p+s+(b>>>0<u>>>0?1:0),V=S,E=D,S=R,D=C,R=l,C=h,h=B+c|0,l=U+q+(h>>>0<B>>>0?1:0)|0,U=A,B=y,A=z,y=x,z=k,x=g,g=c+b|0,k=q+s+(g>>>0<c>>>0?1:0)|0}J=F.low=J+g;F.high=w+k+(J>>>0<g>>>0?1:0);K=e.low=K+x;e.high=X+z+(K>>>0<x>>>0?1:0);L=n.low=L+y;n.high=Y+A+(L>>>0<y>>>0?1:0);M=r.low=M+B;r.high=Z+U+(M>>>0<B>>>0?1:0);N=G.low=N+h;G.high=$+l+(N>>>0<h>>>0?1:0);O=H.low=O+C;H.high=aa+R+(O>>>0<C>>>0?1:0);P=I.low=P+D; I.high=ba+S+(P>>>0<D>>>0?1:0);Q=f.low=Q+E;f.high=ca+V+(Q>>>0<E>>>0?1:0)},_doFinalize:function(){var a=this._data,d=a.words,f=8*this._nDataBytes,e=8*a.sigBytes;d[e>>>5]|=128<<24-e%32;d[(e+128>>>10<<5)+30]=Math.floor(f/4294967296);d[(e+128>>>10<<5)+31]=f;a.sigBytes=4*d.length;this._process();return this._hash.toX32()},clone:function(){var a=r.clone.call(this);a._hash=this._hash.clone();return a},blockSize:32});n.SHA512=r._createHelper(e);n.HmacSHA512=r._createHmacHelper(e)})(); /* CryptoJS v3.1.2 sha384-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var c=CryptoJS,a=c.x64,b=a.Word,e=a.WordArray,a=c.algo,d=a.SHA512,a=a.SHA384=d.extend({_doReset:function(){this._hash=new e.init([new b.init(3418070365,3238371032),new b.init(1654270250,914150663),new b.init(2438529370,812702999),new b.init(355462360,4144912697),new b.init(1731405415,4290775857),new b.init(2394180231,1750603025),new b.init(3675008525,1694076839),new b.init(1203062813,3204075428)])},_doFinalize:function(){var a=d._doFinalize.call(this);a.sigBytes-=16;return a}});c.SHA384= d._createHelper(a);c.HmacSHA384=d._createHmacHelper(a)})(); /* CryptoJS v3.1.2 md5-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(E){function h(a,f,g,j,p,h,k){a=a+(f&g|~f&j)+p+k;return(a<<h|a>>>32-h)+f}function k(a,f,g,j,p,h,k){a=a+(f&j|g&~j)+p+k;return(a<<h|a>>>32-h)+f}function l(a,f,g,j,h,k,l){a=a+(f^g^j)+h+l;return(a<<k|a>>>32-k)+f}function n(a,f,g,j,h,k,l){a=a+(g^(f|~j))+h+l;return(a<<k|a>>>32-k)+f}for(var r=CryptoJS,q=r.lib,F=q.WordArray,s=q.Hasher,q=r.algo,a=[],t=0;64>t;t++)a[t]=4294967296*E.abs(E.sin(t+1))|0;q=q.MD5=s.extend({_doReset:function(){this._hash=new F.init([1732584193,4023233417,2562383102,271733878])}, _doProcessBlock:function(m,f){for(var g=0;16>g;g++){var j=f+g,p=m[j];m[j]=(p<<8|p>>>24)&16711935|(p<<24|p>>>8)&4278255360}var g=this._hash.words,j=m[f+0],p=m[f+1],q=m[f+2],r=m[f+3],s=m[f+4],t=m[f+5],u=m[f+6],v=m[f+7],w=m[f+8],x=m[f+9],y=m[f+10],z=m[f+11],A=m[f+12],B=m[f+13],C=m[f+14],D=m[f+15],b=g[0],c=g[1],d=g[2],e=g[3],b=h(b,c,d,e,j,7,a[0]),e=h(e,b,c,d,p,12,a[1]),d=h(d,e,b,c,q,17,a[2]),c=h(c,d,e,b,r,22,a[3]),b=h(b,c,d,e,s,7,a[4]),e=h(e,b,c,d,t,12,a[5]),d=h(d,e,b,c,u,17,a[6]),c=h(c,d,e,b,v,22,a[7]), b=h(b,c,d,e,w,7,a[8]),e=h(e,b,c,d,x,12,a[9]),d=h(d,e,b,c,y,17,a[10]),c=h(c,d,e,b,z,22,a[11]),b=h(b,c,d,e,A,7,a[12]),e=h(e,b,c,d,B,12,a[13]),d=h(d,e,b,c,C,17,a[14]),c=h(c,d,e,b,D,22,a[15]),b=k(b,c,d,e,p,5,a[16]),e=k(e,b,c,d,u,9,a[17]),d=k(d,e,b,c,z,14,a[18]),c=k(c,d,e,b,j,20,a[19]),b=k(b,c,d,e,t,5,a[20]),e=k(e,b,c,d,y,9,a[21]),d=k(d,e,b,c,D,14,a[22]),c=k(c,d,e,b,s,20,a[23]),b=k(b,c,d,e,x,5,a[24]),e=k(e,b,c,d,C,9,a[25]),d=k(d,e,b,c,r,14,a[26]),c=k(c,d,e,b,w,20,a[27]),b=k(b,c,d,e,B,5,a[28]),e=k(e,b, c,d,q,9,a[29]),d=k(d,e,b,c,v,14,a[30]),c=k(c,d,e,b,A,20,a[31]),b=l(b,c,d,e,t,4,a[32]),e=l(e,b,c,d,w,11,a[33]),d=l(d,e,b,c,z,16,a[34]),c=l(c,d,e,b,C,23,a[35]),b=l(b,c,d,e,p,4,a[36]),e=l(e,b,c,d,s,11,a[37]),d=l(d,e,b,c,v,16,a[38]),c=l(c,d,e,b,y,23,a[39]),b=l(b,c,d,e,B,4,a[40]),e=l(e,b,c,d,j,11,a[41]),d=l(d,e,b,c,r,16,a[42]),c=l(c,d,e,b,u,23,a[43]),b=l(b,c,d,e,x,4,a[44]),e=l(e,b,c,d,A,11,a[45]),d=l(d,e,b,c,D,16,a[46]),c=l(c,d,e,b,q,23,a[47]),b=n(b,c,d,e,j,6,a[48]),e=n(e,b,c,d,v,10,a[49]),d=n(d,e,b,c, C,15,a[50]),c=n(c,d,e,b,t,21,a[51]),b=n(b,c,d,e,A,6,a[52]),e=n(e,b,c,d,r,10,a[53]),d=n(d,e,b,c,y,15,a[54]),c=n(c,d,e,b,p,21,a[55]),b=n(b,c,d,e,w,6,a[56]),e=n(e,b,c,d,D,10,a[57]),d=n(d,e,b,c,u,15,a[58]),c=n(c,d,e,b,B,21,a[59]),b=n(b,c,d,e,s,6,a[60]),e=n(e,b,c,d,z,10,a[61]),d=n(d,e,b,c,q,15,a[62]),c=n(c,d,e,b,x,21,a[63]);g[0]=g[0]+b|0;g[1]=g[1]+c|0;g[2]=g[2]+d|0;g[3]=g[3]+e|0},_doFinalize:function(){var a=this._data,f=a.words,g=8*this._nDataBytes,j=8*a.sigBytes;f[j>>>5]|=128<<24-j%32;var h=E.floor(g/ 4294967296);f[(j+64>>>9<<4)+15]=(h<<8|h>>>24)&16711935|(h<<24|h>>>8)&4278255360;f[(j+64>>>9<<4)+14]=(g<<8|g>>>24)&16711935|(g<<24|g>>>8)&4278255360;a.sigBytes=4*(f.length+1);this._process();a=this._hash;f=a.words;for(g=0;4>g;g++)j=f[g],f[g]=(j<<8|j>>>24)&16711935|(j<<24|j>>>8)&4278255360;return a},clone:function(){var a=s.clone.call(this);a._hash=this._hash.clone();return a}});r.MD5=s._createHelper(q);r.HmacMD5=s._createHmacHelper(q)})(Math); /* CryptoJS v3.1.2 enc-base64-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var h=CryptoJS,j=h.lib.WordArray;h.enc.Base64={stringify:function(b){var e=b.words,f=b.sigBytes,c=this._map;b.clamp();b=[];for(var a=0;a<f;a+=3)for(var d=(e[a>>>2]>>>24-8*(a%4)&255)<<16|(e[a+1>>>2]>>>24-8*((a+1)%4)&255)<<8|e[a+2>>>2]>>>24-8*((a+2)%4)&255,g=0;4>g&&a+0.75*g<f;g++)b.push(c.charAt(d>>>6*(3-g)&63));if(e=c.charAt(64))for(;b.length%4;)b.push(e);return b.join("""")},parse:function(b){var e=b.length,f=this._map,c=f.charAt(64);c&&(c=b.indexOf(c),-1!=c&&(e=c));for(var c=[],a=0,d=0;d< e;d++)if(d%4){var g=f.indexOf(b.charAt(d-1))<<2*(d%4),h=f.indexOf(b.charAt(d))>>>6-2*(d%4);c[a>>>2]|=(g|h)<<24-8*(a%4);a++}return j.create(c,a)},_map:""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=""}})(); /* CryptoJS v3.1.2 cipher-core-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ CryptoJS.lib.Cipher||function(u){var g=CryptoJS,f=g.lib,k=f.Base,l=f.WordArray,q=f.BufferedBlockAlgorithm,r=g.enc.Base64,v=g.algo.EvpKDF,n=f.Cipher=q.extend({cfg:k.extend(),createEncryptor:function(a,b){return this.create(this._ENC_XFORM_MODE,a,b)},createDecryptor:function(a,b){return this.create(this._DEC_XFORM_MODE,a,b)},init:function(a,b,c){this.cfg=this.cfg.extend(c);this._xformMode=a;this._key=b;this.reset()},reset:function(){q.reset.call(this);this._doReset()},process:function(a){this._append(a); return this._process()},finalize:function(a){a&&this._append(a);return this._doFinalize()},keySize:4,ivSize:4,_ENC_XFORM_MODE:1,_DEC_XFORM_MODE:2,_createHelper:function(a){return{encrypt:function(b,c,d){return(""string""==typeof c?s:j).encrypt(a,b,c,d)},decrypt:function(b,c,d){return(""string""==typeof c?s:j).decrypt(a,b,c,d)}}}});f.StreamCipher=n.extend({_doFinalize:function(){return this._process(!0)},blockSize:1});var m=g.mode={},t=function(a,b,c){var d=this._iv;d?this._iv=u:d=this._prevBlock;for(var e= 0;e<c;e++)a[b+e]^=d[e]},h=(f.BlockCipherMode=k.extend({createEncryptor:function(a,b){return this.Encryptor.create(a,b)},createDecryptor:function(a,b){return this.Decryptor.create(a,b)},init:function(a,b){this._cipher=a;this._iv=b}})).extend();h.Encryptor=h.extend({processBlock:function(a,b){var c=this._cipher,d=c.blockSize;t.call(this,a,b,d);c.encryptBlock(a,b);this._prevBlock=a.slice(b,b+d)}});h.Decryptor=h.extend({processBlock:function(a,b){var c=this._cipher,d=c.blockSize,e=a.slice(b,b+d);c.decryptBlock(a, b);t.call(this,a,b,d);this._prevBlock=e}});m=m.CBC=h;h=(g.pad={}).Pkcs7={pad:function(a,b){for(var c=4*b,c=c-a.sigBytes%c,d=c<<24|c<<16|c<<8|c,e=[],f=0;f<c;f+=4)e.push(d);c=l.create(e,c);a.concat(c)},unpad:function(a){a.sigBytes-=a.words[a.sigBytes-1>>>2]&255}};f.BlockCipher=n.extend({cfg:n.cfg.extend({mode:m,padding:h}),reset:function(){n.reset.call(this);var a=this.cfg,b=a.iv,a=a.mode;if(this._xformMode==this._ENC_XFORM_MODE)var c=a.createEncryptor;else c=a.createDecryptor,this._minBufferSize=1; this._mode=c.call(a,this,b&&b.words)},_doProcessBlock:function(a,b){this._mode.processBlock(a,b)},_doFinalize:function(){var a=this.cfg.padding;if(this._xformMode==this._ENC_XFORM_MODE){a.pad(this._data,this.blockSize);var b=this._process(!0)}else b=this._process(!0),a.unpad(b);return b},blockSize:4});var p=f.CipherParams=k.extend({init:function(a){this.mixIn(a)},toString:function(a){return(a||this.formatter).stringify(this)}}),m=(g.format={}).OpenSSL={stringify:function(a){var b=a.ciphertext;a=a.salt; return(a?l.create([1398893684,1701076831]).concat(a).concat(b):b).toString(r)},parse:function(a){a=r.parse(a);var b=a.words;if(1398893684==b[0]&&1701076831==b[1]){var c=l.create(b.slice(2,4));b.splice(0,4);a.sigBytes-=16}return p.create({ciphertext:a,salt:c})}},j=f.SerializableCipher=k.extend({cfg:k.extend({format:m}),encrypt:function(a,b,c,d){d=this.cfg.extend(d);var e=a.createEncryptor(c,d);b=e.finalize(b);e=e.cfg;return p.create({ciphertext:b,key:c,iv:e.iv,algorithm:a,mode:e.mode,padding:e.padding, blockSize:a.blockSize,formatter:d.format})},decrypt:function(a,b,c,d){d=this.cfg.extend(d);b=this._parse(b,d.format);return a.createDecryptor(c,d).finalize(b.ciphertext)},_parse:function(a,b){return""string""==typeof a?b.parse(a,this):a}}),g=(g.kdf={}).OpenSSL={execute:function(a,b,c,d){d||(d=l.random(8));a=v.create({keySize:b+c}).compute(a,d);c=l.create(a.words.slice(b),4*c);a.sigBytes=4*b;return p.create({key:a,iv:c,salt:d})}},s=f.PasswordBasedCipher=j.extend({cfg:j.cfg.extend({kdf:g}),encrypt:function(a, b,c,d){d=this.cfg.extend(d);c=d.kdf.execute(c,a.keySize,a.ivSize);d.iv=c.iv;a=j.encrypt.call(this,a,b,c.key,d);a.mixIn(c);return a},decrypt:function(a,b,c,d){d=this.cfg.extend(d);b=this._parse(b,d.format);c=d.kdf.execute(c,a.keySize,a.ivSize,b.salt);d.iv=c.iv;return j.decrypt.call(this,a,b,c.key,d)}})}(); /* CryptoJS v3.1.2 aes-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){for(var q=CryptoJS,x=q.lib.BlockCipher,r=q.algo,j=[],y=[],z=[],A=[],B=[],C=[],s=[],u=[],v=[],w=[],g=[],k=0;256>k;k++)g[k]=128>k?k<<1:k<<1^283;for(var n=0,l=0,k=0;256>k;k++){var f=l^l<<1^l<<2^l<<3^l<<4,f=f>>>8^f&255^99;j[n]=f;y[f]=n;var t=g[n],D=g[t],E=g[D],b=257*g[f]^16843008*f;z[n]=b<<24|b>>>8;A[n]=b<<16|b>>>16;B[n]=b<<8|b>>>24;C[n]=b;b=16843009*E^65537*D^257*t^16843008*n;s[f]=b<<24|b>>>8;u[f]=b<<16|b>>>16;v[f]=b<<8|b>>>24;w[f]=b;n?(n=t^g[g[g[E^t]]],l^=g[g[l]]):n=l=1}var F=[0,1,2,4,8, 16,32,64,128,27,54],r=r.AES=x.extend({_doReset:function(){for(var c=this._key,e=c.words,a=c.sigBytes/4,c=4*((this._nRounds=a+6)+1),b=this._keySchedule=[],h=0;h<c;h++)if(h<a)b[h]=e[h];else{var d=b[h-1];h%a?6<a&&4==h%a&&(d=j[d>>>24]<<24|j[d>>>16&255]<<16|j[d>>>8&255]<<8|j[d&255]):(d=d<<8|d>>>24,d=j[d>>>24]<<24|j[d>>>16&255]<<16|j[d>>>8&255]<<8|j[d&255],d^=F[h/a|0]<<24);b[h]=b[h-a]^d}e=this._invKeySchedule=[];for(a=0;a<c;a++)h=c-a,d=a%4?b[h]:b[h-4],e[a]=4>a||4>=h?d:s[j[d>>>24]]^u[j[d>>>16&255]]^v[j[d>>> 8&255]]^w[j[d&255]]},encryptBlock:function(c,e){this._doCryptBlock(c,e,this._keySchedule,z,A,B,C,j)},decryptBlock:function(c,e){var a=c[e+1];c[e+1]=c[e+3];c[e+3]=a;this._doCryptBlock(c,e,this._invKeySchedule,s,u,v,w,y);a=c[e+1];c[e+1]=c[e+3];c[e+3]=a},_doCryptBlock:function(c,e,a,b,h,d,j,m){for(var n=this._nRounds,f=c[e]^a[0],g=c[e+1]^a[1],k=c[e+2]^a[2],p=c[e+3]^a[3],l=4,t=1;t<n;t++)var q=b[f>>>24]^h[g>>>16&255]^d[k>>>8&255]^j[p&255]^a[l++],r=b[g>>>24]^h[k>>>16&255]^d[p>>>8&255]^j[f&255]^a[l++],s= b[k>>>24]^h[p>>>16&255]^d[f>>>8&255]^j[g&255]^a[l++],p=b[p>>>24]^h[f>>>16&255]^d[g>>>8&255]^j[k&255]^a[l++],f=q,g=r,k=s;q=(m[f>>>24]<<24|m[g>>>16&255]<<16|m[k>>>8&255]<<8|m[p&255])^a[l++];r=(m[g>>>24]<<24|m[k>>>16&255]<<16|m[p>>>8&255]<<8|m[f&255])^a[l++];s=(m[k>>>24]<<24|m[p>>>16&255]<<16|m[f>>>8&255]<<8|m[g&255])^a[l++];p=(m[p>>>24]<<24|m[f>>>16&255]<<16|m[g>>>8&255]<<8|m[k&255])^a[l++];c[e]=q;c[e+1]=r;c[e+2]=s;c[e+3]=p},keySize:8});q.AES=x._createHelper(r)})(); /* CryptoJS v3.1.2 tripledes-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){function j(b,c){var a=(this._lBlock>>>b^this._rBlock)&c;this._rBlock^=a;this._lBlock^=a<<b}function l(b,c){var a=(this._rBlock>>>b^this._lBlock)&c;this._lBlock^=a;this._rBlock^=a<<b}var h=CryptoJS,e=h.lib,n=e.WordArray,e=e.BlockCipher,g=h.algo,q=[57,49,41,33,25,17,9,1,58,50,42,34,26,18,10,2,59,51,43,35,27,19,11,3,60,52,44,36,63,55,47,39,31,23,15,7,62,54,46,38,30,22,14,6,61,53,45,37,29,21,13,5,28,20,12,4],p=[14,17,11,24,1,5,3,28,15,6,21,10,23,19,12,4,26,8,16,7,27,20,13,2,41,52,31,37,47, 55,30,40,51,45,33,48,44,49,39,56,34,53,46,42,50,36,29,32],r=[1,2,4,6,8,10,12,14,15,17,19,21,23,25,27,28],s=[{""0"":8421888,268435456:32768,536870912:8421378,805306368:2,1073741824:512,1342177280:8421890,1610612736:8389122,1879048192:8388608,2147483648:514,2415919104:8389120,2684354560:33280,2952790016:8421376,3221225472:32770,3489660928:8388610,3758096384:0,4026531840:33282,134217728:0,402653184:8421890,671088640:33282,939524096:32768,1207959552:8421888,1476395008:512,1744830464:8421378,2013265920:2, 2281701376:8389120,2550136832:33280,2818572288:8421376,3087007744:8389122,3355443200:8388610,3623878656:32770,3892314112:514,4160749568:8388608,1:32768,268435457:2,536870913:8421888,805306369:8388608,1073741825:8421378,1342177281:33280,1610612737:512,1879048193:8389122,2147483649:8421890,2415919105:8421376,2684354561:8388610,2952790017:33282,3221225473:514,3489660929:8389120,3758096385:32770,4026531841:0,134217729:8421890,402653185:8421376,671088641:8388608,939524097:512,1207959553:32768,1476395009:8388610, 1744830465:2,2013265921:33282,2281701377:32770,2550136833:8389122,2818572289:514,3087007745:8421888,3355443201:8389120,3623878657:0,3892314113:33280,4160749569:8421378},{""0"":1074282512,16777216:16384,33554432:524288,50331648:1074266128,67108864:1073741840,83886080:1074282496,100663296:1073758208,117440512:16,134217728:540672,150994944:1073758224,167772160:1073741824,184549376:540688,201326592:524304,218103808:0,234881024:16400,251658240:1074266112,8388608:1073758208,25165824:540688,41943040:16,58720256:1073758224, 75497472:1074282512,92274688:1073741824,109051904:524288,125829120:1074266128,142606336:524304,159383552:0,176160768:16384,192937984:1074266112,209715200:1073741840,226492416:540672,243269632:1074282496,260046848:16400,268435456:0,285212672:1074266128,301989888:1073758224,318767104:1074282496,335544320:1074266112,352321536:16,369098752:540688,385875968:16384,402653184:16400,419430400:524288,436207616:524304,452984832:1073741840,469762048:540672,486539264:1073758208,503316480:1073741824,520093696:1074282512, 276824064:540688,293601280:524288,310378496:1074266112,327155712:16384,343932928:1073758208,360710144:1074282512,377487360:16,394264576:1073741824,411041792:1074282496,427819008:1073741840,444596224:1073758224,461373440:524304,478150656:0,494927872:16400,511705088:1074266128,528482304:540672},{""0"":260,1048576:0,2097152:67109120,3145728:65796,4194304:65540,5242880:67108868,6291456:67174660,7340032:67174400,8388608:67108864,9437184:67174656,10485760:65792,11534336:67174404,12582912:67109124,13631488:65536, 14680064:4,15728640:256,524288:67174656,1572864:67174404,2621440:0,3670016:67109120,4718592:67108868,5767168:65536,6815744:65540,7864320:260,8912896:4,9961472:256,11010048:67174400,12058624:65796,13107200:65792,14155776:67109124,15204352:67174660,16252928:67108864,16777216:67174656,17825792:65540,18874368:65536,19922944:67109120,20971520:256,22020096:67174660,23068672:67108868,24117248:0,25165824:67109124,26214400:67108864,27262976:4,28311552:65792,29360128:67174400,30408704:260,31457280:65796,32505856:67174404, 17301504:67108864,18350080:260,19398656:67174656,20447232:0,21495808:65540,22544384:67109120,23592960:256,24641536:67174404,25690112:65536,26738688:67174660,27787264:65796,28835840:67108868,29884416:67109124,30932992:67174400,31981568:4,33030144:65792},{""0"":2151682048,65536:2147487808,131072:4198464,196608:2151677952,262144:0,327680:4198400,393216:2147483712,458752:4194368,524288:2147483648,589824:4194304,655360:64,720896:2147487744,786432:2151678016,851968:4160,917504:4096,983040:2151682112,32768:2147487808, 98304:64,163840:2151678016,229376:2147487744,294912:4198400,360448:2151682112,425984:0,491520:2151677952,557056:4096,622592:2151682048,688128:4194304,753664:4160,819200:2147483648,884736:4194368,950272:4198464,1015808:2147483712,1048576:4194368,1114112:4198400,1179648:2147483712,1245184:0,1310720:4160,1376256:2151678016,1441792:2151682048,1507328:2147487808,1572864:2151682112,1638400:2147483648,1703936:2151677952,1769472:4198464,1835008:2147487744,1900544:4194304,1966080:64,2031616:4096,1081344:2151677952, 1146880:2151682112,1212416:0,1277952:4198400,1343488:4194368,1409024:2147483648,1474560:2147487808,1540096:64,1605632:2147483712,1671168:4096,1736704:2147487744,1802240:2151678016,1867776:4160,1933312:2151682048,1998848:4194304,2064384:4198464},{""0"":128,4096:17039360,8192:262144,12288:536870912,16384:537133184,20480:16777344,24576:553648256,28672:262272,32768:16777216,36864:537133056,40960:536871040,45056:553910400,49152:553910272,53248:0,57344:17039488,61440:553648128,2048:17039488,6144:553648256, 10240:128,14336:17039360,18432:262144,22528:537133184,26624:553910272,30720:536870912,34816:537133056,38912:0,43008:553910400,47104:16777344,51200:536871040,55296:553648128,59392:16777216,63488:262272,65536:262144,69632:128,73728:536870912,77824:553648256,81920:16777344,86016:553910272,90112:537133184,94208:16777216,98304:553910400,102400:553648128,106496:17039360,110592:537133056,114688:262272,118784:536871040,122880:0,126976:17039488,67584:553648256,71680:16777216,75776:17039360,79872:537133184, 83968:536870912,88064:17039488,92160:128,96256:553910272,100352:262272,104448:553910400,108544:0,112640:553648128,116736:16777344,120832:262144,124928:537133056,129024:536871040},{""0"":268435464,256:8192,512:270532608,768:270540808,1024:268443648,1280:2097152,1536:2097160,1792:268435456,2048:0,2304:268443656,2560:2105344,2816:8,3072:270532616,3328:2105352,3584:8200,3840:270540800,128:270532608,384:270540808,640:8,896:2097152,1152:2105352,1408:268435464,1664:268443648,1920:8200,2176:2097160,2432:8192, 2688:268443656,2944:270532616,3200:0,3456:270540800,3712:2105344,3968:268435456,4096:268443648,4352:270532616,4608:270540808,4864:8200,5120:2097152,5376:268435456,5632:268435464,5888:2105344,6144:2105352,6400:0,6656:8,6912:270532608,7168:8192,7424:268443656,7680:270540800,7936:2097160,4224:8,4480:2105344,4736:2097152,4992:268435464,5248:268443648,5504:8200,5760:270540808,6016:270532608,6272:270540800,6528:270532616,6784:8192,7040:2105352,7296:2097160,7552:0,7808:268435456,8064:268443656},{""0"":1048576, 16:33555457,32:1024,48:1049601,64:34604033,80:0,96:1,112:34603009,128:33555456,144:1048577,160:33554433,176:34604032,192:34603008,208:1025,224:1049600,240:33554432,8:34603009,24:0,40:33555457,56:34604032,72:1048576,88:33554433,104:33554432,120:1025,136:1049601,152:33555456,168:34603008,184:1048577,200:1024,216:34604033,232:1,248:1049600,256:33554432,272:1048576,288:33555457,304:34603009,320:1048577,336:33555456,352:34604032,368:1049601,384:1025,400:34604033,416:1049600,432:1,448:0,464:34603008,480:33554433, 496:1024,264:1049600,280:33555457,296:34603009,312:1,328:33554432,344:1048576,360:1025,376:34604032,392:33554433,408:34603008,424:0,440:34604033,456:1049601,472:1024,488:33555456,504:1048577},{""0"":134219808,1:131072,2:134217728,3:32,4:131104,5:134350880,6:134350848,7:2048,8:134348800,9:134219776,10:133120,11:134348832,12:2080,13:0,14:134217760,15:133152,2147483648:2048,2147483649:134350880,2147483650:134219808,2147483651:134217728,2147483652:134348800,2147483653:133120,2147483654:133152,2147483655:32, 2147483656:134217760,2147483657:2080,2147483658:131104,2147483659:134350848,2147483660:0,2147483661:134348832,2147483662:134219776,2147483663:131072,16:133152,17:134350848,18:32,19:2048,20:134219776,21:134217760,22:134348832,23:131072,24:0,25:131104,26:134348800,27:134219808,28:134350880,29:133120,30:2080,31:134217728,2147483664:131072,2147483665:2048,2147483666:134348832,2147483667:133152,2147483668:32,2147483669:134348800,2147483670:134217728,2147483671:134219808,2147483672:134350880,2147483673:134217760, 2147483674:134219776,2147483675:0,2147483676:133120,2147483677:2080,2147483678:131104,2147483679:134350848}],t=[4160749569,528482304,33030144,2064384,129024,8064,504,2147483679],m=g.DES=e.extend({_doReset:function(){for(var b=this._key.words,c=[],a=0;56>a;a++){var f=q[a]-1;c[a]=b[f>>>5]>>>31-f%32&1}b=this._subKeys=[];for(f=0;16>f;f++){for(var d=b[f]=[],e=r[f],a=0;24>a;a++)d[a/6|0]|=c[(p[a]-1+e)%28]<<31-a%6,d[4+(a/6|0)]|=c[28+(p[a+24]-1+e)%28]<<31-a%6;d[0]=d[0]<<1|d[0]>>>31;for(a=1;7>a;a++)d[a]>>>= 4*(a-1)+3;d[7]=d[7]<<5|d[7]>>>27}c=this._invSubKeys=[];for(a=0;16>a;a++)c[a]=b[15-a]},encryptBlock:function(b,c){this._doCryptBlock(b,c,this._subKeys)},decryptBlock:function(b,c){this._doCryptBlock(b,c,this._invSubKeys)},_doCryptBlock:function(b,c,a){this._lBlock=b[c];this._rBlock=b[c+1];j.call(this,4,252645135);j.call(this,16,65535);l.call(this,2,858993459);l.call(this,8,16711935);j.call(this,1,1431655765);for(var f=0;16>f;f++){for(var d=a[f],e=this._lBlock,h=this._rBlock,g=0,k=0;8>k;k++)g|=s[k][((h^ d[k])&t[k])>>>0];this._lBlock=h;this._rBlock=e^g}a=this._lBlock;this._lBlock=this._rBlock;this._rBlock=a;j.call(this,1,1431655765);l.call(this,8,16711935);l.call(this,2,858993459);j.call(this,16,65535);j.call(this,4,252645135);b[c]=this._lBlock;b[c+1]=this._rBlock},keySize:2,ivSize:2,blockSize:2});h.DES=e._createHelper(m);g=g.TripleDES=e.extend({_doReset:function(){var b=this._key.words;this._des1=m.createEncryptor(n.create(b.slice(0,2)));this._des2=m.createEncryptor(n.create(b.slice(2,4)));this._des3= m.createEncryptor(n.create(b.slice(4,6)))},encryptBlock:function(b,c){this._des1.encryptBlock(b,c);this._des2.decryptBlock(b,c);this._des3.encryptBlock(b,c)},decryptBlock:function(b,c){this._des3.decryptBlock(b,c);this._des2.encryptBlock(b,c);this._des1.decryptBlock(b,c)},keySize:6,ivSize:2,blockSize:2});h.TripleDES=e._createHelper(g)})(); /* CryptoJS v3.1.2 sha1-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var k=CryptoJS,b=k.lib,m=b.WordArray,l=b.Hasher,d=[],b=k.algo.SHA1=l.extend({_doReset:function(){this._hash=new m.init([1732584193,4023233417,2562383102,271733878,3285377520])},_doProcessBlock:function(n,p){for(var a=this._hash.words,e=a[0],f=a[1],h=a[2],j=a[3],b=a[4],c=0;80>c;c++){if(16>c)d[c]=n[p+c]|0;else{var g=d[c-3]^d[c-8]^d[c-14]^d[c-16];d[c]=g<<1|g>>>31}g=(e<<5|e>>>27)+b+d[c];g=20>c?g+((f&h|~f&j)+1518500249):40>c?g+((f^h^j)+1859775393):60>c?g+((f&h|f&j|h&j)-1894007588):g+((f^h^ j)-899497514);b=j;j=h;h=f<<30|f>>>2;f=e;e=g}a[0]=a[0]+e|0;a[1]=a[1]+f|0;a[2]=a[2]+h|0;a[3]=a[3]+j|0;a[4]=a[4]+b|0},_doFinalize:function(){var b=this._data,d=b.words,a=8*this._nDataBytes,e=8*b.sigBytes;d[e>>>5]|=128<<24-e%32;d[(e+64>>>9<<4)+14]=Math.floor(a/4294967296);d[(e+64>>>9<<4)+15]=a;b.sigBytes=4*d.length;this._process();return this._hash},clone:function(){var b=l.clone.call(this);b._hash=this._hash.clone();return b}});k.SHA1=l._createHelper(b);k.HmacSHA1=l._createHmacHelper(b)})(); /* CryptoJS v3.1.2 ripemd160-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ /* (c) 2012 by Cedric Mesnil. All rights reserved. Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: - Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. - Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. */ (function(){var q=CryptoJS,d=q.lib,n=d.WordArray,p=d.Hasher,d=q.algo,x=n.create([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,7,4,13,1,10,6,15,3,12,0,9,5,2,14,11,8,3,10,14,4,9,15,8,1,2,7,0,6,13,11,5,12,1,9,11,10,0,8,12,4,13,3,7,15,14,5,6,2,4,0,5,9,7,12,2,10,14,1,3,8,11,6,15,13]),y=n.create([5,14,7,0,9,2,11,4,13,6,15,8,1,10,3,12,6,11,3,7,0,13,5,10,14,15,8,12,4,9,1,2,15,5,1,3,7,14,6,9,11,8,12,2,10,0,4,13,8,6,4,1,3,11,15,0,5,12,2,13,9,7,10,14,12,15,10,4,1,5,8,7,6,2,13,14,0,3,9,11]),z=n.create([11,14,15,12, 5,8,7,9,11,13,14,15,6,7,9,8,7,6,8,13,11,9,7,15,7,12,15,9,11,7,13,12,11,13,6,7,14,9,13,15,14,8,13,6,5,12,7,5,11,12,14,15,14,15,9,8,9,14,5,6,8,6,5,12,9,15,5,11,6,8,13,12,5,12,13,14,11,8,5,6]),A=n.create([8,9,9,11,13,15,15,5,7,7,8,11,14,14,12,6,9,13,15,7,12,8,9,11,7,7,12,7,6,15,13,11,9,7,15,11,8,6,6,14,12,13,5,14,13,13,7,5,15,5,8,11,14,14,6,14,6,9,12,9,12,5,15,8,8,5,12,9,12,5,14,6,8,13,6,5,15,13,11,11]),B=n.create([0,1518500249,1859775393,2400959708,2840853838]),C=n.create([1352829926,1548603684,1836072691, 2053994217,0]),d=d.RIPEMD160=p.extend({_doReset:function(){this._hash=n.create([1732584193,4023233417,2562383102,271733878,3285377520])},_doProcessBlock:function(e,v){for(var b=0;16>b;b++){var c=v+b,f=e[c];e[c]=(f<<8|f>>>24)&16711935|(f<<24|f>>>8)&4278255360}var c=this._hash.words,f=B.words,d=C.words,n=x.words,q=y.words,p=z.words,w=A.words,t,g,h,j,r,u,k,l,m,s;u=t=c[0];k=g=c[1];l=h=c[2];m=j=c[3];s=r=c[4];for(var a,b=0;80>b;b+=1)a=t+e[v+n[b]]|0,a=16>b?a+((g^h^j)+f[0]):32>b?a+((g&h|~g&j)+f[1]):48>b? a+(((g|~h)^j)+f[2]):64>b?a+((g&j|h&~j)+f[3]):a+((g^(h|~j))+f[4]),a|=0,a=a<<p[b]|a>>>32-p[b],a=a+r|0,t=r,r=j,j=h<<10|h>>>22,h=g,g=a,a=u+e[v+q[b]]|0,a=16>b?a+((k^(l|~m))+d[0]):32>b?a+((k&m|l&~m)+d[1]):48>b?a+(((k|~l)^m)+d[2]):64>b?a+((k&l|~k&m)+d[3]):a+((k^l^m)+d[4]),a|=0,a=a<<w[b]|a>>>32-w[b],a=a+s|0,u=s,s=m,m=l<<10|l>>>22,l=k,k=a;a=c[1]+h+m|0;c[1]=c[2]+j+s|0;c[2]=c[3]+r+u|0;c[3]=c[4]+t+k|0;c[4]=c[0]+g+l|0;c[0]=a},_doFinalize:function(){var e=this._data,d=e.words,b=8*this._nDataBytes,c=8*e.sigBytes; d[c>>>5]|=128<<24-c%32;d[(c+64>>>9<<4)+14]=(b<<8|b>>>24)&16711935|(b<<24|b>>>8)&4278255360;e.sigBytes=4*(d.length+1);this._process();e=this._hash;d=e.words;for(b=0;5>b;b++)c=d[b],d[b]=(c<<8|c>>>24)&16711935|(c<<24|c>>>8)&4278255360;return e},clone:function(){var d=p.clone.call(this);d._hash=this._hash.clone();return d}});q.RIPEMD160=p._createHelper(d);q.HmacRIPEMD160=p._createHmacHelper(d)})(Math); /* CryptoJS v3.1.2 pbkdf2-min.js code.google.com/p/crypto-js (c) 2009-2013 by Jeff Mott. All rights reserved. code.google.com/p/crypto-js/wiki/License */ (function(){var b=CryptoJS,a=b.lib,d=a.Base,m=a.WordArray,a=b.algo,q=a.HMAC,l=a.PBKDF2=d.extend({cfg:d.extend({keySize:4,hasher:a.SHA1,iterations:1}),init:function(a){this.cfg=this.cfg.extend(a)},compute:function(a,b){for(var c=this.cfg,f=q.create(c.hasher,a),g=m.create(),d=m.create([1]),l=g.words,r=d.words,n=c.keySize,c=c.iterations;l.length<n;){var h=f.update(b).finalize(d);f.reset();for(var j=h.words,s=j.length,k=h,p=1;p<c;p++){k=f.finalize(k);f.reset();for(var t=k.words,e=0;e<s;e++)j[e]^=t[e]}g.concat(h); r[0]++}g.sigBytes=4*n;return g}});b.PBKDF2=function(a,b,c){return l.create(c).compute(a,b)}})(); /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ var b64map=""ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/"";var b64pad=""="";function hex2b64(d){var b;var e;var a="""";for(b=0;b+3<=d.length;b+=3){e=parseInt(d.substring(b,b+3),16);a+=b64map.charAt(e>>6)+b64map.charAt(e&63)}if(b+1==d.length){e=parseInt(d.substring(b,b+1),16);a+=b64map.charAt(e<<2)}else{if(b+2==d.length){e=parseInt(d.substring(b,b+2),16);a+=b64map.charAt(e>>2)+b64map.charAt((e&3)<<4)}}if(b64pad){while((a.length&3)>0){a+=b64pad}}return a}function b64tohex(f){var d="""";var e;var b=0;var c;var a;for(e=0;e<f.length;++e){if(f.charAt(e)==b64pad){break}a=b64map.indexOf(f.charAt(e));if(a<0){continue}if(b==0){d+=int2char(a>>2);c=a&3;b=1}else{if(b==1){d+=int2char((c<<2)|(a>>4));c=a&15;b=2}else{if(b==2){d+=int2char(c);d+=int2char(a>>2);c=a&3;b=3}else{d+=int2char((c<<2)|(a>>4));d+=int2char(a&15);b=0}}}}if(b==1){d+=int2char(c<<2)}return d}function b64toBA(e){var d=b64tohex(e);var c;var b=new Array();for(c=0;2*c<d.length;++c){b[c]=parseInt(d.substring(2*c,2*c+2),16)}return b}; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ var dbits;var canary=244837814094590;var j_lm=((canary&16777215)==15715070);function BigInteger(e,d,f){if(e!=null){if(""number""==typeof e){this.fromNumber(e,d,f)}else{if(d==null&&""string""!=typeof e){this.fromString(e,256)}else{this.fromString(e,d)}}}}function nbi(){return new BigInteger(null)}function am1(f,a,b,e,h,g){while(--g>=0){var d=a*this[f++]+b[e]+h;h=Math.floor(d/67108864);b[e++]=d&67108863}return h}function am2(f,q,r,e,o,a){var k=q&32767,p=q>>15;while(--a>=0){var d=this[f]&32767;var g=this[f++]>>15;var b=p*d+g*k;d=k*d+((b&32767)<<15)+r[e]+(o&1073741823);o=(d>>>30)+(b>>>15)+p*g+(o>>>30);r[e++]=d&1073741823}return o}function am3(f,q,r,e,o,a){var k=q&16383,p=q>>14;while(--a>=0){var d=this[f]&16383;var g=this[f++]>>14;var b=p*d+g*k;d=k*d+((b&16383)<<14)+r[e]+o;o=(d>>28)+(b>>14)+p*g;r[e++]=d&268435455}return o}if(j_lm&&(navigator.appName==""Microsoft Internet Explorer"")){BigInteger.prototype.am=am2;dbits=30}else{if(j_lm&&(navigator.appName!=""Netscape"")){BigInteger.prototype.am=am1;dbits=26}else{BigInteger.prototype.am=am3;dbits=28}}BigInteger.prototype.DB=dbits;BigInteger.prototype.DM=((1<<dbits)-1);BigInteger.prototype.DV=(1<<dbits);var BI_FP=52;BigInteger.prototype.FV=Math.pow(2,BI_FP);BigInteger.prototype.F1=BI_FP-dbits;BigInteger.prototype.F2=2*dbits-BI_FP;var BI_RM=""0123456789abcdefghijklmnopqrstuvwxyz"";var BI_RC=new Array();var rr,vv;rr=""0"".charCodeAt(0);for(vv=0;vv<=9;++vv){BI_RC[rr++]=vv}rr=""a"".charCodeAt(0);for(vv=10;vv<36;++vv){BI_RC[rr++]=vv}rr=""A"".charCodeAt(0);for(vv=10;vv<36;++vv){BI_RC[rr++]=vv}function int2char(a){return BI_RM.charAt(a)}function intAt(b,a){var d=BI_RC[b.charCodeAt(a)];return(d==null)?-1:d}function bnpCopyTo(b){for(var a=this.t-1;a>=0;--a){b[a]=this[a]}b.t=this.t;b.s=this.s}function bnpFromInt(a){this.t=1;this.s=(a<0)?-1:0;if(a>0){this[0]=a}else{if(a<-1){this[0]=a+this.DV}else{this.t=0}}}function nbv(a){var b=nbi();b.fromInt(a);return b}function bnpFromString(h,c){var e;if(c==16){e=4}else{if(c==8){e=3}else{if(c==256){e=8}else{if(c==2){e=1}else{if(c==32){e=5}else{if(c==4){e=2}else{this.fromRadix(h,c);return}}}}}}this.t=0;this.s=0;var g=h.length,d=false,f=0;while(--g>=0){var a=(e==8)?h[g]&255:intAt(h,g);if(a<0){if(h.charAt(g)==""-""){d=true}continue}d=false;if(f==0){this[this.t++]=a}else{if(f+e>this.DB){this[this.t-1]|=(a&((1<<(this.DB-f))-1))<<f;this[this.t++]=(a>>(this.DB-f))}else{this[this.t-1]|=a<<f}}f+=e;if(f>=this.DB){f-=this.DB}}if(e==8&&(h[0]&128)!=0){this.s=-1;if(f>0){this[this.t-1]|=((1<<(this.DB-f))-1)<<f}}this.clamp();if(d){BigInteger.ZERO.subTo(this,this)}}function bnpClamp(){var a=this.s&this.DM;while(this.t>0&&this[this.t-1]==a){--this.t}}function bnToString(c){if(this.s<0){return""-""+this.negate().toString(c)}var e;if(c==16){e=4}else{if(c==8){e=3}else{if(c==2){e=1}else{if(c==32){e=5}else{if(c==4){e=2}else{return this.toRadix(c)}}}}}var g=(1<<e)-1,l,a=false,h="""",f=this.t;var j=this.DB-(f*this.DB)%e;if(f-->0){if(j<this.DB&&(l=this[f]>>j)>0){a=true;h=int2char(l)}while(f>=0){if(j<e){l=(this[f]&((1<<j)-1))<<(e-j);l|=this[--f]>>(j+=this.DB-e)}else{l=(this[f]>>(j-=e))&g;if(j<=0){j+=this.DB;--f}}if(l>0){a=true}if(a){h+=int2char(l)}}}return a?h:""0""}function bnNegate(){var a=nbi();BigInteger.ZERO.subTo(this,a);return a}function bnAbs(){return(this.s<0)?this.negate():this}function bnCompareTo(b){var d=this.s-b.s;if(d!=0){return d}var c=this.t;d=c-b.t;if(d!=0){return(this.s<0)?-d:d}while(--c>=0){if((d=this[c]-b[c])!=0){return d}}return 0}function nbits(a){var c=1,b;if((b=a>>>16)!=0){a=b;c+=16}if((b=a>>8)!=0){a=b;c+=8}if((b=a>>4)!=0){a=b;c+=4}if((b=a>>2)!=0){a=b;c+=2}if((b=a>>1)!=0){a=b;c+=1}return c}function bnBitLength(){if(this.t<=0){return 0}return this.DB*(this.t-1)+nbits(this[this.t-1]^(this.s&this.DM))}function bnpDLShiftTo(c,b){var a;for(a=this.t-1;a>=0;--a){b[a+c]=this[a]}for(a=c-1;a>=0;--a){b[a]=0}b.t=this.t+c;b.s=this.s}function bnpDRShiftTo(c,b){for(var a=c;a<this.t;++a){b[a-c]=this[a]}b.t=Math.max(this.t-c,0);b.s=this.s}function bnpLShiftTo(j,e){var b=j%this.DB;var a=this.DB-b;var g=(1<<a)-1;var f=Math.floor(j/this.DB),h=(this.s<<b)&this.DM,d;for(d=this.t-1;d>=0;--d){e[d+f+1]=(this[d]>>a)|h;h=(this[d]&g)<<b}for(d=f-1;d>=0;--d){e[d]=0}e[f]=h;e.t=this.t+f+1;e.s=this.s;e.clamp()}function bnpRShiftTo(g,d){d.s=this.s;var e=Math.floor(g/this.DB);if(e>=this.t){d.t=0;return}var b=g%this.DB;var a=this.DB-b;var f=(1<<b)-1;d[0]=this[e]>>b;for(var c=e+1;c<this.t;++c){d[c-e-1]|=(this[c]&f)<<a;d[c-e]=this[c]>>b}if(b>0){d[this.t-e-1]|=(this.s&f)<<a}d.t=this.t-e;d.clamp()}function bnpSubTo(d,f){var e=0,g=0,b=Math.min(d.t,this.t);while(e<b){g+=this[e]-d[e];f[e++]=g&this.DM;g>>=this.DB}if(d.t<this.t){g-=d.s;while(e<this.t){g+=this[e];f[e++]=g&this.DM;g>>=this.DB}g+=this.s}else{g+=this.s;while(e<d.t){g-=d[e];f[e++]=g&this.DM;g>>=this.DB}g-=d.s}f.s=(g<0)?-1:0;if(g<-1){f[e++]=this.DV+g}else{if(g>0){f[e++]=g}}f.t=e;f.clamp()}function bnpMultiplyTo(c,e){var b=this.abs(),f=c.abs();var d=b.t;e.t=d+f.t;while(--d>=0){e[d]=0}for(d=0;d<f.t;++d){e[d+b.t]=b.am(0,f[d],e,d,0,b.t)}e.s=0;e.clamp();if(this.s!=c.s){BigInteger.ZERO.subTo(e,e)}}function bnpSquareTo(d){var a=this.abs();var b=d.t=2*a.t;while(--b>=0){d[b]=0}for(b=0;b<a.t-1;++b){var e=a.am(b,a[b],d,2*b,0,1);if((d[b+a.t]+=a.am(b+1,2*a[b],d,2*b+1,e,a.t-b-1))>=a.DV){d[b+a.t]-=a.DV;d[b+a.t+1]=1}}if(d.t>0){d[d.t-1]+=a.am(b,a[b],d,2*b,0,1)}d.s=0;d.clamp()}function bnpDivRemTo(n,h,g){var w=n.abs();if(w.t<=0){return}var k=this.abs();if(k.t<w.t){if(h!=null){h.fromInt(0)}if(g!=null){this.copyTo(g)}return}if(g==null){g=nbi()}var d=nbi(),a=this.s,l=n.s;var v=this.DB-nbits(w[w.t-1]);if(v>0){w.lShiftTo(v,d);k.lShiftTo(v,g)}else{w.copyTo(d);k.copyTo(g)}var p=d.t;var b=d[p-1];if(b==0){return}var o=b*(1<<this.F1)+((p>1)?d[p-2]>>this.F2:0);var A=this.FV/o,z=(1<<this.F1)/o,x=1<<this.F2;var u=g.t,s=u-p,f=(h==null)?nbi():h;d.dlShiftTo(s,f);if(g.compareTo(f)>=0){g[g.t++]=1;g.subTo(f,g)}BigInteger.ONE.dlShiftTo(p,f);f.subTo(d,d);while(d.t<p){d[d.t++]=0}while(--s>=0){var c=(g[--u]==b)?this.DM:Math.floor(g[u]*A+(g[u-1]+x)*z);if((g[u]+=d.am(0,c,g,s,0,p))<c){d.dlShiftTo(s,f);g.subTo(f,g);while(g[u]<--c){g.subTo(f,g)}}}if(h!=null){g.drShiftTo(p,h);if(a!=l){BigInteger.ZERO.subTo(h,h)}}g.t=p;g.clamp();if(v>0){g.rShiftTo(v,g)}if(a<0){BigInteger.ZERO.subTo(g,g)}}function bnMod(b){var c=nbi();this.abs().divRemTo(b,null,c);if(this.s<0&&c.compareTo(BigInteger.ZERO)>0){b.subTo(c,c)}return c}function Classic(a){this.m=a}function cConvert(a){if(a.s<0||a.compareTo(this.m)>=0){return a.mod(this.m)}else{return a}}function cRevert(a){return a}function cReduce(a){a.divRemTo(this.m,null,a)}function cMulTo(a,c,b){a.multiplyTo(c,b);this.reduce(b)}function cSqrTo(a,b){a.squareTo(b);this.reduce(b)}Classic.prototype.convert=cConvert;Classic.prototype.revert=cRevert;Classic.prototype.reduce=cReduce;Classic.prototype.mulTo=cMulTo;Classic.prototype.sqrTo=cSqrTo;function bnpInvDigit(){if(this.t<1){return 0}var a=this[0];if((a&1)==0){return 0}var b=a&3;b=(b*(2-(a&15)*b))&15;b=(b*(2-(a&255)*b))&255;b=(b*(2-(((a&65535)*b)&65535)))&65535;b=(b*(2-a*b%this.DV))%this.DV;return(b>0)?this.DV-b:-b}function Montgomery(a){this.m=a;this.mp=a.invDigit();this.mpl=this.mp&32767;this.mph=this.mp>>15;this.um=(1<<(a.DB-15))-1;this.mt2=2*a.t}function montConvert(a){var b=nbi();a.abs().dlShiftTo(this.m.t,b);b.divRemTo(this.m,null,b);if(a.s<0&&b.compareTo(BigInteger.ZERO)>0){this.m.subTo(b,b)}return b}function montRevert(a){var b=nbi();a.copyTo(b);this.reduce(b);return b}function montReduce(a){while(a.t<=this.mt2){a[a.t++]=0}for(var c=0;c<this.m.t;++c){var b=a[c]&32767;var d=(b*this.mpl+(((b*this.mph+(a[c]>>15)*this.mpl)&this.um)<<15))&a.DM;b=c+this.m.t;a[b]+=this.m.am(0,d,a,c,0,this.m.t);while(a[b]>=a.DV){a[b]-=a.DV;a[++b]++}}a.clamp();a.drShiftTo(this.m.t,a);if(a.compareTo(this.m)>=0){a.subTo(this.m,a)}}function montSqrTo(a,b){a.squareTo(b);this.reduce(b)}function montMulTo(a,c,b){a.multiplyTo(c,b);this.reduce(b)}Montgomery.prototype.convert=montConvert;Montgomery.prototype.revert=montRevert;Montgomery.prototype.reduce=montReduce;Montgomery.prototype.mulTo=montMulTo;Montgomery.prototype.sqrTo=montSqrTo;function bnpIsEven(){return((this.t>0)?(this[0]&1):this.s)==0}function bnpExp(h,j){if(h>4294967295||h<1){return BigInteger.ONE}var f=nbi(),a=nbi(),d=j.convert(this),c=nbits(h)-1;d.copyTo(f);while(--c>=0){j.sqrTo(f,a);if((h&(1<<c))>0){j.mulTo(a,d,f)}else{var b=f;f=a;a=b}}return j.revert(f)}function bnModPowInt(b,a){var c;if(b<256||a.isEven()){c=new Classic(a)}else{c=new Montgomery(a)}return this.exp(b,c)}BigInteger.prototype.copyTo=bnpCopyTo;BigInteger.prototype.fromInt=bnpFromInt;BigInteger.prototype.fromString=bnpFromString;BigInteger.prototype.clamp=bnpClamp;BigInteger.prototype.dlShiftTo=bnpDLShiftTo;BigInteger.prototype.drShiftTo=bnpDRShiftTo;BigInteger.prototype.lShiftTo=bnpLShiftTo;BigInteger.prototype.rShiftTo=bnpRShiftTo;BigInteger.prototype.subTo=bnpSubTo;BigInteger.prototype.multiplyTo=bnpMultiplyTo;BigInteger.prototype.squareTo=bnpSquareTo;BigInteger.prototype.divRemTo=bnpDivRemTo;BigInteger.prototype.invDigit=bnpInvDigit;BigInteger.prototype.isEven=bnpIsEven;BigInteger.prototype.exp=bnpExp;BigInteger.prototype.toString=bnToString;BigInteger.prototype.negate=bnNegate;BigInteger.prototype.abs=bnAbs;BigInteger.prototype.compareTo=bnCompareTo;BigInteger.prototype.bitLength=bnBitLength;BigInteger.prototype.mod=bnMod;BigInteger.prototype.modPowInt=bnModPowInt;BigInteger.ZERO=nbv(0);BigInteger.ONE=nbv(1); /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ function bnClone(){var a=nbi();this.copyTo(a);return a}function bnIntValue(){if(this.s<0){if(this.t==1){return this[0]-this.DV}else{if(this.t==0){return -1}}}else{if(this.t==1){return this[0]}else{if(this.t==0){return 0}}}return((this[1]&((1<<(32-this.DB))-1))<<this.DB)|this[0]}function bnByteValue(){return(this.t==0)?this.s:(this[0]<<24)>>24}function bnShortValue(){return(this.t==0)?this.s:(this[0]<<16)>>16}function bnpChunkSize(a){return Math.floor(Math.LN2*this.DB/Math.log(a))}function bnSigNum(){if(this.s<0){return -1}else{if(this.t<=0||(this.t==1&&this[0]<=0)){return 0}else{return 1}}}function bnpToRadix(c){if(c==null){c=10}if(this.signum()==0||c<2||c>36){return""0""}var f=this.chunkSize(c);var e=Math.pow(c,f);var i=nbv(e),j=nbi(),h=nbi(),g="""";this.divRemTo(i,j,h);while(j.signum()>0){g=(e+h.intValue()).toString(c).substr(1)+g;j.divRemTo(i,j,h)}return h.intValue().toString(c)+g}function bnpFromRadix(m,h){this.fromInt(0);if(h==null){h=10}var f=this.chunkSize(h);var g=Math.pow(h,f),e=false,a=0,l=0;for(var c=0;c<m.length;++c){var k=intAt(m,c);if(k<0){if(m.charAt(c)==""-""&&this.signum()==0){e=true}continue}l=h*l+k;if(++a>=f){this.dMultiply(g);this.dAddOffset(l,0);a=0;l=0}}if(a>0){this.dMultiply(Math.pow(h,a));this.dAddOffset(l,0)}if(e){BigInteger.ZERO.subTo(this,this)}}function bnpFromNumber(f,e,h){if(""number""==typeof e){if(f<2){this.fromInt(1)}else{this.fromNumber(f,h);if(!this.testBit(f-1)){this.bitwiseTo(BigInteger.ONE.shiftLeft(f-1),op_or,this)}if(this.isEven()){this.dAddOffset(1,0)}while(!this.isProbablePrime(e)){this.dAddOffset(2,0);if(this.bitLength()>f){this.subTo(BigInteger.ONE.shiftLeft(f-1),this)}}}}else{var d=new Array(),g=f&7;d.length=(f>>3)+1;e.nextBytes(d);if(g>0){d[0]&=((1<<g)-1)}else{d[0]=0}this.fromString(d,256)}}function bnToByteArray(){var b=this.t,c=new Array();c[0]=this.s;var e=this.DB-(b*this.DB)%8,f,a=0;if(b-->0){if(e<this.DB&&(f=this[b]>>e)!=(this.s&this.DM)>>e){c[a++]=f|(this.s<<(this.DB-e))}while(b>=0){if(e<8){f=(this[b]&((1<<e)-1))<<(8-e);f|=this[--b]>>(e+=this.DB-8)}else{f=(this[b]>>(e-=8))&255;if(e<=0){e+=this.DB;--b}}if((f&128)!=0){f|=-256}if(a==0&&(this.s&128)!=(f&128)){++a}if(a>0||f!=this.s){c[a++]=f}}}return c}function bnEquals(b){return(this.compareTo(b)==0)}function bnMin(b){return(this.compareTo(b)<0)?this:b}function bnMax(b){return(this.compareTo(b)>0)?this:b}function bnpBitwiseTo(c,h,e){var d,g,b=Math.min(c.t,this.t);for(d=0;d<b;++d){e[d]=h(this[d],c[d])}if(c.t<this.t){g=c.s&this.DM;for(d=b;d<this.t;++d){e[d]=h(this[d],g)}e.t=this.t}else{g=this.s&this.DM;for(d=b;d<c.t;++d){e[d]=h(g,c[d])}e.t=c.t}e.s=h(this.s,c.s);e.clamp()}function op_and(a,b){return a&b}function bnAnd(b){var c=nbi();this.bitwiseTo(b,op_and,c);return c}function op_or(a,b){return a|b}function bnOr(b){var c=nbi();this.bitwiseTo(b,op_or,c);return c}function op_xor(a,b){return a^b}function bnXor(b){var c=nbi();this.bitwiseTo(b,op_xor,c);return c}function op_andnot(a,b){return a&~b}function bnAndNot(b){var c=nbi();this.bitwiseTo(b,op_andnot,c);return c}function bnNot(){var b=nbi();for(var a=0;a<this.t;++a){b[a]=this.DM&~this[a]}b.t=this.t;b.s=~this.s;return b}function bnShiftLeft(b){var a=nbi();if(b<0){this.rShiftTo(-b,a)}else{this.lShiftTo(b,a)}return a}function bnShiftRight(b){var a=nbi();if(b<0){this.lShiftTo(-b,a)}else{this.rShiftTo(b,a)}return a}function lbit(a){if(a==0){return -1}var b=0;if((a&65535)==0){a>>=16;b+=16}if((a&255)==0){a>>=8;b+=8}if((a&15)==0){a>>=4;b+=4}if((a&3)==0){a>>=2;b+=2}if((a&1)==0){++b}return b}function bnGetLowestSetBit(){for(var a=0;a<this.t;++a){if(this[a]!=0){return a*this.DB+lbit(this[a])}}if(this.s<0){return this.t*this.DB}return -1}function cbit(a){var b=0;while(a!=0){a&=a-1;++b}return b}function bnBitCount(){var c=0,a=this.s&this.DM;for(var b=0;b<this.t;++b){c+=cbit(this[b]^a)}return c}function bnTestBit(b){var a=Math.floor(b/this.DB);if(a>=this.t){return(this.s!=0)}return((this[a]&(1<<(b%this.DB)))!=0)}function bnpChangeBit(c,b){var a=BigInteger.ONE.shiftLeft(c);this.bitwiseTo(a,b,a);return a}function bnSetBit(a){return this.changeBit(a,op_or)}function bnClearBit(a){return this.changeBit(a,op_andnot)}function bnFlipBit(a){return this.changeBit(a,op_xor)}function bnpAddTo(d,f){var e=0,g=0,b=Math.min(d.t,this.t);while(e<b){g+=this[e]+d[e];f[e++]=g&this.DM;g>>=this.DB}if(d.t<this.t){g+=d.s;while(e<this.t){g+=this[e];f[e++]=g&this.DM;g>>=this.DB}g+=this.s}else{g+=this.s;while(e<d.t){g+=d[e];f[e++]=g&this.DM;g>>=this.DB}g+=d.s}f.s=(g<0)?-1:0;if(g>0){f[e++]=g}else{if(g<-1){f[e++]=this.DV+g}}f.t=e;f.clamp()}function bnAdd(b){var c=nbi();this.addTo(b,c);return c}function bnSubtract(b){var c=nbi();this.subTo(b,c);return c}function bnMultiply(b){var c=nbi();this.multiplyTo(b,c);return c}function bnSquare(){var a=nbi();this.squareTo(a);return a}function bnDivide(b){var c=nbi();this.divRemTo(b,c,null);return c}function bnRemainder(b){var c=nbi();this.divRemTo(b,null,c);return c}function bnDivideAndRemainder(b){var d=nbi(),c=nbi();this.divRemTo(b,d,c);return new Array(d,c)}function bnpDMultiply(a){this[this.t]=this.am(0,a-1,this,0,0,this.t);++this.t;this.clamp()}function bnpDAddOffset(b,a){if(b==0){return}while(this.t<=a){this[this.t++]=0}this[a]+=b;while(this[a]>=this.DV){this[a]-=this.DV;if(++a>=this.t){this[this.t++]=0}++this[a]}}function NullExp(){}function nNop(a){return a}function nMulTo(a,c,b){a.multiplyTo(c,b)}function nSqrTo(a,b){a.squareTo(b)}NullExp.prototype.convert=nNop;NullExp.prototype.revert=nNop;NullExp.prototype.mulTo=nMulTo;NullExp.prototype.sqrTo=nSqrTo;function bnPow(a){return this.exp(a,new NullExp())}function bnpMultiplyLowerTo(b,f,e){var d=Math.min(this.t+b.t,f);e.s=0;e.t=d;while(d>0){e[--d]=0}var c;for(c=e.t-this.t;d<c;++d){e[d+this.t]=this.am(0,b[d],e,d,0,this.t)}for(c=Math.min(b.t,f);d<c;++d){this.am(0,b[d],e,d,0,f-d)}e.clamp()}function bnpMultiplyUpperTo(b,e,d){--e;var c=d.t=this.t+b.t-e;d.s=0;while(--c>=0){d[c]=0}for(c=Math.max(e-this.t,0);c<b.t;++c){d[this.t+c-e]=this.am(e-c,b[c],d,0,0,this.t+c-e)}d.clamp();d.drShiftTo(1,d)}function Barrett(a){this.r2=nbi();this.q3=nbi();BigInteger.ONE.dlShiftTo(2*a.t,this.r2);this.mu=this.r2.divide(a);this.m=a}function barrettConvert(a){if(a.s<0||a.t>2*this.m.t){return a.mod(this.m)}else{if(a.compareTo(this.m)<0){return a}else{var b=nbi();a.copyTo(b);this.reduce(b);return b}}}function barrettRevert(a){return a}function barrettReduce(a){a.drShiftTo(this.m.t-1,this.r2);if(a.t>this.m.t+1){a.t=this.m.t+1;a.clamp()}this.mu.multiplyUpperTo(this.r2,this.m.t+1,this.q3);this.m.multiplyLowerTo(this.q3,this.m.t+1,this.r2);while(a.compareTo(this.r2)<0){a.dAddOffset(1,this.m.t+1)}a.subTo(this.r2,a);while(a.compareTo(this.m)>=0){a.subTo(this.m,a)}}function barrettSqrTo(a,b){a.squareTo(b);this.reduce(b)}function barrettMulTo(a,c,b){a.multiplyTo(c,b);this.reduce(b)}Barrett.prototype.convert=barrettConvert;Barrett.prototype.revert=barrettRevert;Barrett.prototype.reduce=barrettReduce;Barrett.prototype.mulTo=barrettMulTo;Barrett.prototype.sqrTo=barrettSqrTo;function bnModPow(q,f){var o=q.bitLength(),h,b=nbv(1),v;if(o<=0){return b}else{if(o<18){h=1}else{if(o<48){h=3}else{if(o<144){h=4}else{if(o<768){h=5}else{h=6}}}}}if(o<8){v=new Classic(f)}else{if(f.isEven()){v=new Barrett(f)}else{v=new Montgomery(f)}}var p=new Array(),d=3,s=h-1,a=(1<<h)-1;p[1]=v.convert(this);if(h>1){var A=nbi();v.sqrTo(p[1],A);while(d<=a){p[d]=nbi();v.mulTo(A,p[d-2],p[d]);d+=2}}var l=q.t-1,x,u=true,c=nbi(),y;o=nbits(q[l])-1;while(l>=0){if(o>=s){x=(q[l]>>(o-s))&a}else{x=(q[l]&((1<<(o+1))-1))<<(s-o);if(l>0){x|=q[l-1]>>(this.DB+o-s)}}d=h;while((x&1)==0){x>>=1;--d}if((o-=d)<0){o+=this.DB;--l}if(u){p[x].copyTo(b);u=false}else{while(d>1){v.sqrTo(b,c);v.sqrTo(c,b);d-=2}if(d>0){v.sqrTo(b,c)}else{y=b;b=c;c=y}v.mulTo(c,p[x],b)}while(l>=0&&(q[l]&(1<<o))==0){v.sqrTo(b,c);y=b;b=c;c=y;if(--o<0){o=this.DB-1;--l}}}return v.revert(b)}function bnGCD(c){var b=(this.s<0)?this.negate():this.clone();var h=(c.s<0)?c.negate():c.clone();if(b.compareTo(h)<0){var e=b;b=h;h=e}var d=b.getLowestSetBit(),f=h.getLowestSetBit();if(f<0){return b}if(d<f){f=d}if(f>0){b.rShiftTo(f,b);h.rShiftTo(f,h)}while(b.signum()>0){if((d=b.getLowestSetBit())>0){b.rShiftTo(d,b)}if((d=h.getLowestSetBit())>0){h.rShiftTo(d,h)}if(b.compareTo(h)>=0){b.subTo(h,b);b.rShiftTo(1,b)}else{h.subTo(b,h);h.rShiftTo(1,h)}}if(f>0){h.lShiftTo(f,h)}return h}function bnpModInt(e){if(e<=0){return 0}var c=this.DV%e,b=(this.s<0)?e-1:0;if(this.t>0){if(c==0){b=this[0]%e}else{for(var a=this.t-1;a>=0;--a){b=(c*b+this[a])%e}}}return b}function bnModInverse(f){var j=f.isEven();if((this.isEven()&&j)||f.signum()==0){return BigInteger.ZERO}var i=f.clone(),h=this.clone();var g=nbv(1),e=nbv(0),l=nbv(0),k=nbv(1);while(i.signum()!=0){while(i.isEven()){i.rShiftTo(1,i);if(j){if(!g.isEven()||!e.isEven()){g.addTo(this,g);e.subTo(f,e)}g.rShiftTo(1,g)}else{if(!e.isEven()){e.subTo(f,e)}}e.rShiftTo(1,e)}while(h.isEven()){h.rShiftTo(1,h);if(j){if(!l.isEven()||!k.isEven()){l.addTo(this,l);k.subTo(f,k)}l.rShiftTo(1,l)}else{if(!k.isEven()){k.subTo(f,k)}}k.rShiftTo(1,k)}if(i.compareTo(h)>=0){i.subTo(h,i);if(j){g.subTo(l,g)}e.subTo(k,e)}else{h.subTo(i,h);if(j){l.subTo(g,l)}k.subTo(e,k)}}if(h.compareTo(BigInteger.ONE)!=0){return BigInteger.ZERO}if(k.compareTo(f)>=0){return k.subtract(f)}if(k.signum()<0){k.addTo(f,k)}else{return k}if(k.signum()<0){return k.add(f)}else{return k}}var lowprimes=[2,3,5,7,11,13,17,19,23,29,31,37,41,43,47,53,59,61,67,71,73,79,83,89,97,101,103,107,109,113,127,131,137,139,149,151,157,163,167,173,179,181,191,193,197,199,211,223,227,229,233,239,241,251,257,263,269,271,277,281,283,293,307,311,313,317,331,337,347,349,353,359,367,373,379,383,389,397,401,409,419,421,431,433,439,443,449,457,461,463,467,479,487,491,499,503,509,521,523,541,547,557,563,569,571,577,587,593,599,601,607,613,617,619,631,641,643,647,653,659,661,673,677,683,691,701,709,719,727,733,739,743,751,757,761,769,773,787,797,809,811,821,823,827,829,839,853,857,859,863,877,881,883,887,907,911,919,929,937,941,947,953,967,971,977,983,991,997];var lplim=(1<<26)/lowprimes[lowprimes.length-1];function bnIsProbablePrime(e){var d,b=this.abs();if(b.t==1&&b[0]<=lowprimes[lowprimes.length-1]){for(d=0;d<lowprimes.length;++d){if(b[0]==lowprimes[d]){return true}}return false}if(b.isEven()){return false}d=1;while(d<lowprimes.length){var a=lowprimes[d],c=d+1;while(c<lowprimes.length&&a<lplim){a*=lowprimes[c++]}a=b.modInt(a);while(d<c){if(a%lowprimes[d++]==0){return false}}}return b.millerRabin(e)}function bnpMillerRabin(f){var g=this.subtract(BigInteger.ONE);var c=g.getLowestSetBit();if(c<=0){return false}var h=g.shiftRight(c);f=(f+1)>>1;if(f>lowprimes.length){f=lowprimes.length}var b=nbi();for(var e=0;e<f;++e){b.fromInt(lowprimes[Math.floor(Math.random()*lowprimes.length)]);var l=b.modPow(h,this);if(l.compareTo(BigInteger.ONE)!=0&&l.compareTo(g)!=0){var d=1;while(d++<c&&l.compareTo(g)!=0){l=l.modPowInt(2,this);if(l.compareTo(BigInteger.ONE)==0){return false}}if(l.compareTo(g)!=0){return false}}}return true}BigInteger.prototype.chunkSize=bnpChunkSize;BigInteger.prototype.toRadix=bnpToRadix;BigInteger.prototype.fromRadix=bnpFromRadix;BigInteger.prototype.fromNumber=bnpFromNumber;BigInteger.prototype.bitwiseTo=bnpBitwiseTo;BigInteger.prototype.changeBit=bnpChangeBit;BigInteger.prototype.addTo=bnpAddTo;BigInteger.prototype.dMultiply=bnpDMultiply;BigInteger.prototype.dAddOffset=bnpDAddOffset;BigInteger.prototype.multiplyLowerTo=bnpMultiplyLowerTo;BigInteger.prototype.multiplyUpperTo=bnpMultiplyUpperTo;BigInteger.prototype.modInt=bnpModInt;BigInteger.prototype.millerRabin=bnpMillerRabin;BigInteger.prototype.clone=bnClone;BigInteger.prototype.intValue=bnIntValue;BigInteger.prototype.byteValue=bnByteValue;BigInteger.prototype.shortValue=bnShortValue;BigInteger.prototype.signum=bnSigNum;BigInteger.prototype.toByteArray=bnToByteArray;BigInteger.prototype.equals=bnEquals;BigInteger.prototype.min=bnMin;BigInteger.prototype.max=bnMax;BigInteger.prototype.and=bnAnd;BigInteger.prototype.or=bnOr;BigInteger.prototype.xor=bnXor;BigInteger.prototype.andNot=bnAndNot;BigInteger.prototype.not=bnNot;BigInteger.prototype.shiftLeft=bnShiftLeft;BigInteger.prototype.shiftRight=bnShiftRight;BigInteger.prototype.getLowestSetBit=bnGetLowestSetBit;BigInteger.prototype.bitCount=bnBitCount;BigInteger.prototype.testBit=bnTestBit;BigInteger.prototype.setBit=bnSetBit;BigInteger.prototype.clearBit=bnClearBit;BigInteger.prototype.flipBit=bnFlipBit;BigInteger.prototype.add=bnAdd;BigInteger.prototype.subtract=bnSubtract;BigInteger.prototype.multiply=bnMultiply;BigInteger.prototype.divide=bnDivide;BigInteger.prototype.remainder=bnRemainder;BigInteger.prototype.divideAndRemainder=bnDivideAndRemainder;BigInteger.prototype.modPow=bnModPow;BigInteger.prototype.modInverse=bnModInverse;BigInteger.prototype.pow=bnPow;BigInteger.prototype.gcd=bnGCD;BigInteger.prototype.isProbablePrime=bnIsProbablePrime;BigInteger.prototype.square=bnSquare; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ function Arcfour(){this.i=0;this.j=0;this.S=new Array()}function ARC4init(d){var c,a,b;for(c=0;c<256;++c){this.S[c]=c}a=0;for(c=0;c<256;++c){a=(a+this.S[c]+d[c%d.length])&255;b=this.S[c];this.S[c]=this.S[a];this.S[a]=b}this.i=0;this.j=0}function ARC4next(){var a;this.i=(this.i+1)&255;this.j=(this.j+this.S[this.i])&255;a=this.S[this.i];this.S[this.i]=this.S[this.j];this.S[this.j]=a;return this.S[(a+this.S[this.i])&255]}Arcfour.prototype.init=ARC4init;Arcfour.prototype.next=ARC4next;function prng_newstate(){return new Arcfour()}var rng_psize=256; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ var rng_state;var rng_pool;var rng_pptr;function rng_seed_int(a){rng_pool[rng_pptr++]^=a&255;rng_pool[rng_pptr++]^=(a>>8)&255;rng_pool[rng_pptr++]^=(a>>16)&255;rng_pool[rng_pptr++]^=(a>>24)&255;if(rng_pptr>=rng_psize){rng_pptr-=rng_psize}}function rng_seed_time(){rng_seed_int(new Date().getTime())}if(rng_pool==null){rng_pool=new Array();rng_pptr=0;var t;if(navigator.appName==""Netscape""&&navigator.appVersion<""5""&&window.crypto){var z=window.crypto.random(32);for(t=0;t<z.length;++t){rng_pool[rng_pptr++]=z.charCodeAt(t)&255}}while(rng_pptr<rng_psize){t=Math.floor(65536*Math.random());rng_pool[rng_pptr++]=t>>>8;rng_pool[rng_pptr++]=t&255}rng_pptr=0;rng_seed_time()}function rng_get_byte(){if(rng_state==null){rng_seed_time();rng_state=prng_newstate();rng_state.init(rng_pool);for(rng_pptr=0;rng_pptr<rng_pool.length;++rng_pptr){rng_pool[rng_pptr]=0}rng_pptr=0}return rng_state.next()}function rng_get_bytes(b){var a;for(a=0;a<b.length;++a){b[a]=rng_get_byte()}}function SecureRandom(){}SecureRandom.prototype.nextBytes=rng_get_bytes; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ function parseBigInt(b,a){return new BigInteger(b,a)}function linebrk(c,d){var a="""";var b=0;while(b+d<c.length){a+=c.substring(b,b+d)+""\n"";b+=d}return a+c.substring(b,c.length)}function byte2Hex(a){if(a<16){return""0""+a.toString(16)}else{return a.toString(16)}}function pkcs1pad2(e,h){if(h<e.length+11){alert(""Message too long for RSA"");return null}var g=new Array();var d=e.length-1;while(d>=0&&h>0){var f=e.charCodeAt(d--);if(f<128){g[--h]=f}else{if((f>127)&&(f<2048)){g[--h]=(f&63)|128;g[--h]=(f>>6)|192}else{g[--h]=(f&63)|128;g[--h]=((f>>6)&63)|128;g[--h]=(f>>12)|224}}}g[--h]=0;var b=new SecureRandom();var a=new Array();while(h>2){a[0]=0;while(a[0]==0){b.nextBytes(a)}g[--h]=a[0]}g[--h]=2;g[--h]=0;return new BigInteger(g)}function oaep_mgf1_arr(c,a,e){var b="""",d=0;while(b.length<a){b+=e(String.fromCharCode.apply(String,c.concat([(d&4278190080)>>24,(d&16711680)>>16,(d&65280)>>8,d&255])));d+=1}return b}var SHA1_SIZE=20;function oaep_pad(l,a,c){if(l.length+2*SHA1_SIZE+2>a){throw""Message too long for RSA""}var h="""",d;for(d=0;d<a-l.length-2*SHA1_SIZE-2;d+=1){h+=""\x00""}var e=rstr_sha1("""")+h+""\x01""+l;var f=new Array(SHA1_SIZE);new SecureRandom().nextBytes(f);var g=oaep_mgf1_arr(f,e.length,c||rstr_sha1);var k=[];for(d=0;d<e.length;d+=1){k[d]=e.charCodeAt(d)^g.charCodeAt(d)}var j=oaep_mgf1_arr(k,f.length,rstr_sha1);var b=[0];for(d=0;d<f.length;d+=1){b[d+1]=f[d]^j.charCodeAt(d)}return new BigInteger(b.concat(k))}function RSAKey(){this.n=null;this.e=0;this.d=null;this.p=null;this.q=null;this.dmp1=null;this.dmq1=null;this.coeff=null}function RSASetPublic(b,a){this.isPublic=true;if(typeof b!==""string""){this.n=b;this.e=a}else{if(b!=null&&a!=null&&b.length>0&&a.length>0){this.n=parseBigInt(b,16);this.e=parseInt(a,16)}else{alert(""Invalid RSA public key"")}}}function RSADoPublic(a){return a.modPowInt(this.e,this.n)}function RSAEncrypt(d){var a=pkcs1pad2(d,(this.n.bitLength()+7)>>3);if(a==null){return null}var e=this.doPublic(a);if(e==null){return null}var b=e.toString(16);if((b.length&1)==0){return b}else{return""0""+b}}function RSAEncryptOAEP(e,d){var a=oaep_pad(e,(this.n.bitLength()+7)>>3,d);if(a==null){return null}var f=this.doPublic(a);if(f==null){return null}var b=f.toString(16);if((b.length&1)==0){return b}else{return""0""+b}}RSAKey.prototype.doPublic=RSADoPublic;RSAKey.prototype.setPublic=RSASetPublic;RSAKey.prototype.encrypt=RSAEncrypt;RSAKey.prototype.encryptOAEP=RSAEncryptOAEP;RSAKey.prototype.type=""RSA""; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ function pkcs1unpad2(g,j){var a=g.toByteArray();var f=0;while(f<a.length&&a[f]==0){++f}if(a.length-f!=j-1||a[f]!=2){return null}++f;while(a[f]!=0){if(++f>=a.length){return null}}var e="""";while(++f<a.length){var h=a[f]&255;if(h<128){e+=String.fromCharCode(h)}else{if((h>191)&&(h<224)){e+=String.fromCharCode(((h&31)<<6)|(a[f+1]&63));++f}else{e+=String.fromCharCode(((h&15)<<12)|((a[f+1]&63)<<6)|(a[f+2]&63));f+=2}}}return e}function oaep_mgf1_str(c,a,e){var b="""",d=0;while(b.length<a){b+=e(c+String.fromCharCode.apply(String,[(d&4278190080)>>24,(d&16711680)>>16,(d&65280)>>8,d&255]));d+=1}return b}var SHA1_SIZE=20;function oaep_unpad(l,b,e){l=l.toByteArray();var f;for(f=0;f<l.length;f+=1){l[f]&=255}while(l.length<b){l.unshift(0)}l=String.fromCharCode.apply(String,l);if(l.length<2*SHA1_SIZE+2){throw""Cipher too short""}var c=l.substr(1,SHA1_SIZE);var o=l.substr(SHA1_SIZE+1);var m=oaep_mgf1_str(o,SHA1_SIZE,e||rstr_sha1);var h=[],f;for(f=0;f<c.length;f+=1){h[f]=c.charCodeAt(f)^m.charCodeAt(f)}var j=oaep_mgf1_str(String.fromCharCode.apply(String,h),l.length-SHA1_SIZE,rstr_sha1);var g=[];for(f=0;f<o.length;f+=1){g[f]=o.charCodeAt(f)^j.charCodeAt(f)}g=String.fromCharCode.apply(String,g);if(g.substr(0,SHA1_SIZE)!==rstr_sha1("""")){throw""Hash mismatch""}g=g.substr(SHA1_SIZE);var a=g.indexOf(""\x01"");var k=(a!=-1)?g.substr(0,a).lastIndexOf(""\x00""):-1;if(k+1!=a){throw""Malformed data""}return g.substr(a+1)}function RSASetPrivate(c,a,b){this.isPrivate=true;if(typeof c!==""string""){this.n=c;this.e=a;this.d=b}else{if(c!=null&&a!=null&&c.length>0&&a.length>0){this.n=parseBigInt(c,16);this.e=parseInt(a,16);this.d=parseBigInt(b,16)}else{alert(""Invalid RSA private key"")}}}function RSASetPrivateEx(g,d,e,c,b,a,h,f){this.isPrivate=true;if(g==null){throw""RSASetPrivateEx N == null""}if(d==null){throw""RSASetPrivateEx E == null""}if(g.length==0){throw""RSASetPrivateEx N.length == 0""}if(d.length==0){throw""RSASetPrivateEx E.length == 0""}if(g!=null&&d!=null&&g.length>0&&d.length>0){this.n=parseBigInt(g,16);this.e=parseInt(d,16);this.d=parseBigInt(e,16);this.p=parseBigInt(c,16);this.q=parseBigInt(b,16);this.dmp1=parseBigInt(a,16);this.dmq1=parseBigInt(h,16);this.coeff=parseBigInt(f,16)}else{alert(""Invalid RSA private key in RSASetPrivateEx"")}}function RSAGenerate(b,i){var a=new SecureRandom();var f=b>>1;this.e=parseInt(i,16);var c=new BigInteger(i,16);for(;;){for(;;){this.p=new BigInteger(b-f,1,a);if(this.p.subtract(BigInteger.ONE).gcd(c).compareTo(BigInteger.ONE)==0&&this.p.isProbablePrime(10)){break}}for(;;){this.q=new BigInteger(f,1,a);if(this.q.subtract(BigInteger.ONE).gcd(c).compareTo(BigInteger.ONE)==0&&this.q.isProbablePrime(10)){break}}if(this.p.compareTo(this.q)<=0){var h=this.p;this.p=this.q;this.q=h}var g=this.p.subtract(BigInteger.ONE);var d=this.q.subtract(BigInteger.ONE);var e=g.multiply(d);if(e.gcd(c).compareTo(BigInteger.ONE)==0){this.n=this.p.multiply(this.q);this.d=c.modInverse(e);this.dmp1=this.d.mod(g);this.dmq1=this.d.mod(d);this.coeff=this.q.modInverse(this.p);break}}}function RSADoPrivate(a){if(this.p==null||this.q==null){return a.modPow(this.d,this.n)}var c=a.mod(this.p).modPow(this.dmp1,this.p);var b=a.mod(this.q).modPow(this.dmq1,this.q);while(c.compareTo(b)<0){c=c.add(this.p)}return c.subtract(b).multiply(this.coeff).mod(this.p).multiply(this.q).add(b)}function RSADecrypt(b){var d=parseBigInt(b,16);var a=this.doPrivate(d);if(a==null){return null}return pkcs1unpad2(a,(this.n.bitLength()+7)>>3)}function RSADecryptOAEP(d,b){var e=parseBigInt(d,16);var a=this.doPrivate(e);if(a==null){return null}return oaep_unpad(a,(this.n.bitLength()+7)>>3,b)}RSAKey.prototype.doPrivate=RSADoPrivate;RSAKey.prototype.setPrivate=RSASetPrivate;RSAKey.prototype.setPrivateEx=RSASetPrivateEx;RSAKey.prototype.generate=RSAGenerate;RSAKey.prototype.decrypt=RSADecrypt;RSAKey.prototype.decryptOAEP=RSADecryptOAEP; /*! (c) Tom Wu | http://www-cs-students.stanford.edu/~tjw/jsbn/ */ function ECFieldElementFp(b,a){this.x=a;this.q=b}function feFpEquals(a){if(a==this){return true}return(this.q.equals(a.q)&&this.x.equals(a.x))}function feFpToBigInteger(){return this.x}function feFpNegate(){return new ECFieldElementFp(this.q,this.x.negate().mod(this.q))}function feFpAdd(a){return new ECFieldElementFp(this.q,this.x.add(a.toBigInteger()).mod(this.q))}function feFpSubtract(a){return new ECFieldElementFp(this.q,this.x.subtract(a.toBigInteger()).mod(this.q))}function feFpMultiply(a){return new ECFieldElementFp(this.q,this.x.multiply(a.toBigInteger()).mod(this.q))}function feFpSquare(){return new ECFieldElementFp(this.q,this.x.square().mod(this.q))}function feFpDivide(a){return new ECFieldElementFp(this.q,this.x.multiply(a.toBigInteger().modInverse(this.q)).mod(this.q))}ECFieldElementFp.prototype.equals=feFpEquals;ECFieldElementFp.prototype.toBigInteger=feFpToBigInteger;ECFieldElementFp.prototype.negate=feFpNegate;ECFieldElementFp.prototype.add=feFpAdd;ECFieldElementFp.prototype.subtract=feFpSubtract;ECFieldElementFp.prototype.multiply=feFpMultiply;ECFieldElementFp.prototype.square=feFpSquare;ECFieldElementFp.prototype.divide=feFpDivide;function ECPointFp(c,a,d,b){this.curve=c;this.x=a;this.y=d;if(b==null){this.z=BigInteger.ONE}else{this.z=b}this.zinv=null}function pointFpGetX(){if(this.zinv==null){this.zinv=this.z.modInverse(this.curve.q)}return this.curve.fromBigInteger(this.x.toBigInteger().multiply(this.zinv).mod(this.curve.q))}function pointFpGetY(){if(this.zinv==null){this.zinv=this.z.modInverse(this.curve.q)}return this.curve.fromBigInteger(this.y.toBigInteger().multiply(this.zinv).mod(this.curve.q))}function pointFpEquals(a){if(a==this){return true}if(this.isInfinity()){return a.isInfinity()}if(a.isInfinity()){return this.isInfinity()}var c,b;c=a.y.toBigInteger().multiply(this.z).subtract(this.y.toBigInteger().multiply(a.z)).mod(this.curve.q);if(!c.equals(BigInteger.ZERO)){return false}b=a.x.toBigInteger().multiply(this.z).subtract(this.x.toBigInteger().multiply(a.z)).mod(this.curve.q);return b.equals(BigInteger.ZERO)}function pointFpIsInfinity(){if((this.x==null)&&(this.y==null)){return true}return this.z.equals(BigInteger.ZERO)&&!this.y.toBigInteger().equals(BigInteger.ZERO)}function pointFpNegate(){return new ECPointFp(this.curve,this.x,this.y.negate(),this.z)}function pointFpAdd(l){if(this.isInfinity()){return l}if(l.isInfinity()){return this}var p=l.y.toBigInteger().multiply(this.z).subtract(this.y.toBigInteger().multiply(l.z)).mod(this.curve.q);var o=l.x.toBigInteger().multiply(this.z).subtract(this.x.toBigInteger().multiply(l.z)).mod(this.curve.q);if(BigInteger.ZERO.equals(o)){if(BigInteger.ZERO.equals(p)){return this.twice()}return this.curve.getInfinity()}var j=new BigInteger(""3"");var e=this.x.toBigInteger();var n=this.y.toBigInteger();var c=l.x.toBigInteger();var k=l.y.toBigInteger();var m=o.square();var i=m.multiply(o);var d=e.multiply(m);var g=p.square().multiply(this.z);var a=g.subtract(d.shiftLeft(1)).multiply(l.z).subtract(i).multiply(o).mod(this.curve.q);var h=d.multiply(j).multiply(p).subtract(n.multiply(i)).subtract(g.multiply(p)).multiply(l.z).add(p.multiply(i)).mod(this.curve.q);var f=i.multiply(this.z).multiply(l.z).mod(this.curve.q);return new ECPointFp(this.curve,this.curve.fromBigInteger(a),this.curve.fromBigInteger(h),f)}function pointFpTwice(){if(this.isInfinity()){return this}if(this.y.toBigInteger().signum()==0){return this.curve.getInfinity()}var g=new BigInteger(""3"");var c=this.x.toBigInteger();var h=this.y.toBigInteger();var e=h.multiply(this.z);var j=e.multiply(h).mod(this.curve.q);var i=this.curve.a.toBigInteger();var k=c.square().multiply(g);if(!BigInteger.ZERO.equals(i)){k=k.add(this.z.square().multiply(i))}k=k.mod(this.curve.q);var b=k.square().subtract(c.shiftLeft(3).multiply(j)).shiftLeft(1).multiply(e).mod(this.curve.q);var f=k.multiply(g).multiply(c).subtract(j.shiftLeft(1)).shiftLeft(2).multiply(j).subtract(k.square().multiply(k)).mod(this.curve.q);var d=e.square().multiply(e).shiftLeft(3).mod(this.curve.q);return new ECPointFp(this.curve,this.curve.fromBigInteger(b),this.curve.fromBigInteger(f),d)}function pointFpMultiply(b){if(this.isInfinity()){return this}if(b.signum()==0){return this.curve.getInfinity()}var g=b;var f=g.multiply(new BigInteger(""3""));var l=this.negate();var d=this;var c;for(c=f.bitLength()-2;c>0;--c){d=d.twice();var a=f.testBit(c);var j=g.testBit(c);if(a!=j){d=d.add(a?this:l)}}return d}function pointFpMultiplyTwo(c,a,b){var d;if(c.bitLength()>b.bitLength()){d=c.bitLength()-1}else{d=b.bitLength()-1}var f=this.curve.getInfinity();var e=this.add(a);while(d>=0){f=f.twice();if(c.testBit(d)){if(b.testBit(d)){f=f.add(e)}else{f=f.add(this)}}else{if(b.testBit(d)){f=f.add(a)}}--d}return f}ECPointFp.prototype.getX=pointFpGetX;ECPointFp.prototype.getY=pointFpGetY;ECPointFp.prototype.equals=pointFpEquals;ECPointFp.prototype.isInfinity=pointFpIsInfinity;ECPointFp.prototype.negate=pointFpNegate;ECPointFp.prototype.add=pointFpAdd;ECPointFp.prototype.twice=pointFpTwice;ECPointFp.prototype.multiply=pointFpMultiply;ECPointFp.prototype.multiplyTwo=pointFpMultiplyTwo;function ECCurveFp(e,d,c){this.q=e;this.a=this.fromBigInteger(d);this.b=this.fromBigInteger(c);this.infinity=new ECPointFp(this,null,null)}function curveFpGetQ(){return this.q}function curveFpGetA(){return this.a}function curveFpGetB(){return this.b}function curveFpEquals(a){if(a==this){return true}return(this.q.equals(a.q)&&this.a.equals(a.a)&&this.b.equals(a.b))}function curveFpGetInfinity(){return this.infinity}function curveFpFromBigInteger(a){return new ECFieldElementFp(this.q,a)}function curveFpDecodePointHex(d){switch(parseInt(d.substr(0,2),16)){case 0:return this.infinity;case 2:case 3:return null;case 4:case 6:case 7:var a=(d.length-2)/2;var c=d.substr(2,a);var b=d.substr(a+2,a);return new ECPointFp(this,this.fromBigInteger(new BigInteger(c,16)),this.fromBigInteger(new BigInteger(b,16)));default:return null}}ECCurveFp.prototype.getQ=curveFpGetQ;ECCurveFp.prototype.getA=curveFpGetA;ECCurveFp.prototype.getB=curveFpGetB;ECCurveFp.prototype.equals=curveFpEquals;ECCurveFp.prototype.getInfinity=curveFpGetInfinity;ECCurveFp.prototype.fromBigInteger=curveFpFromBigInteger;ECCurveFp.prototype.decodePointHex=curveFpDecodePointHex; /*! (c) Stefan Thomas | https://github.com/bitcoinjs/bitcoinjs-lib */ ECFieldElementFp.prototype.getByteLength=function(){return Math.floor((this.toBigInteger().bitLength()+7)/8)};ECPointFp.prototype.getEncoded=function(c){var d=function(h,f){var g=h.toByteArrayUnsigned();if(f<g.length){g=g.slice(g.length-f)}else{while(f>g.length){g.unshift(0)}}return g};var a=this.getX().toBigInteger();var e=this.getY().toBigInteger();var b=d(a,32);if(c){if(e.isEven()){b.unshift(2)}else{b.unshift(3)}}else{b.unshift(4);b=b.concat(d(e,32))}return b};ECPointFp.decodeFrom=function(g,c){var f=c[0];var e=c.length-1;var d=c.slice(1,1+e/2);var b=c.slice(1+e/2,1+e);d.unshift(0);b.unshift(0);var a=new BigInteger(d);var h=new BigInteger(b);return new ECPointFp(g,g.fromBigInteger(a),g.fromBigInteger(h))};ECPointFp.decodeFromHex=function(g,c){var f=c.substr(0,2);var e=c.length-2;var d=c.substr(2,e/2);var b=c.substr(2+e/2,e/2);var a=new BigInteger(d,16);var h=new BigInteger(b,16);return new ECPointFp(g,g.fromBigInteger(a),g.fromBigInteger(h))};ECPointFp.prototype.add2D=function(c){if(this.isInfinity()){return c}if(c.isInfinity()){return this}if(this.x.equals(c.x)){if(this.y.equals(c.y)){return this.twice()}return this.curve.getInfinity()}var g=c.x.subtract(this.x);var e=c.y.subtract(this.y);var a=e.divide(g);var d=a.square().subtract(this.x).subtract(c.x);var f=a.multiply(this.x.subtract(d)).subtract(this.y);return new ECPointFp(this.curve,d,f)};ECPointFp.prototype.twice2D=function(){if(this.isInfinity()){return this}if(this.y.toBigInteger().signum()==0){return this.curve.getInfinity()}var b=this.curve.fromBigInteger(BigInteger.valueOf(2));var e=this.curve.fromBigInteger(BigInteger.valueOf(3));var a=this.x.square().multiply(e).add(this.curve.a).divide(this.y.multiply(b));var c=a.square().subtract(this.x.multiply(b));var d=a.multiply(this.x.subtract(c)).subtract(this.y);return new ECPointFp(this.curve,c,d)};ECPointFp.prototype.multiply2D=function(b){if(this.isInfinity()){return this}if(b.signum()==0){return this.curve.getInfinity()}var g=b;var f=g.multiply(new BigInteger(""3""));var l=this.negate();var d=this;var c;for(c=f.bitLength()-2;c>0;--c){d=d.twice();var a=f.testBit(c);var j=g.testBit(c);if(a!=j){d=d.add2D(a?this:l)}}return d};ECPointFp.prototype.isOnCurve=function(){var d=this.getX().toBigInteger();var i=this.getY().toBigInteger();var f=this.curve.getA().toBigInteger();var c=this.curve.getB().toBigInteger();var h=this.curve.getQ();var e=i.multiply(i).mod(h);var g=d.multiply(d).multiply(d).add(f.multiply(d)).add(c).mod(h);return e.equals(g)};ECPointFp.prototype.toString=function(){return""(""+this.getX().toBigInteger().toString()+"",""+this.getY().toBigInteger().toString()+"")""};ECPointFp.prototype.validate=function(){var c=this.curve.getQ();if(this.isInfinity()){throw new Error(""Point is at infinity."")}var a=this.getX().toBigInteger();var b=this.getY().toBigInteger();if(a.compareTo(BigInteger.ONE)<0||a.compareTo(c.subtract(BigInteger.ONE))>0){throw new Error(""x coordinate out of bounds"")}if(b.compareTo(BigInteger.ONE)<0||b.compareTo(c.subtract(BigInteger.ONE))>0){throw new Error(""y coordinate out of bounds"")}if(!this.isOnCurve()){throw new Error(""Point is not on the curve."")}if(this.multiply(c).isInfinity()){throw new Error(""Point is not a scalar multiple of G."")}return true}; /*! asn1-1.0.6.js (c) 2013 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.asn1==""undefined""||!KJUR.asn1){KJUR.asn1={}}KJUR.asn1.ASN1Util=new function(){this.integerToByteHex=function(a){var b=a.toString(16);if((b.length%2)==1){b=""0""+b}return b};this.bigIntToMinTwosComplementsHex=function(j){var f=j.toString(16);if(f.substr(0,1)!=""-""){if(f.length%2==1){f=""0""+f}else{if(!f.match(/^[0-7]/)){f=""00""+f}}}else{var a=f.substr(1);var e=a.length;if(e%2==1){e+=1}else{if(!f.match(/^[0-7]/)){e+=2}}var g="""";for(var d=0;d<e;d++){g+=""f""}var c=new BigInteger(g,16);var b=c.xor(j).add(BigInteger.ONE);f=b.toString(16).replace(/^-/,"""")}return f};this.getPEMStringFromHex=function(a,b){var c=KJUR.asn1;var f=CryptoJS.enc.Hex.parse(a);var d=CryptoJS.enc.Base64.stringify(f);var e=d.replace(/(.{64})/g,""$1\r\n"");e=e.replace(/\r\n$/,"""");return""-----BEGIN ""+b+""-----\r\n""+e+""\r\n-----END ""+b+""-----\r\n""};this.newObject=function(b){var g=KJUR.asn1;var k=Object.keys(b);if(k.length!=1){throw""key of param shall be only one.""}var j=k[0];if("":bool:int:bitstr:octstr:null:oid:utf8str:numstr:prnstr:telstr:ia5str:utctime:gentime:seq:set:tag:"".indexOf("":""+j+"":"")==-1){throw""undefined key: ""+j}if(j==""bool""){return new g.DERBoolean(b[j])}if(j==""int""){return new g.DERInteger(b[j])}if(j==""bitstr""){return new g.DERBitString(b[j])}if(j==""octstr""){return new g.DEROctetString(b[j])}if(j==""null""){return new g.DERNull(b[j])}if(j==""oid""){return new g.DERObjectIdentifier(b[j])}if(j==""utf8str""){return new g.DERUTF8String(b[j])}if(j==""numstr""){return new g.DERNumericString(b[j])}if(j==""prnstr""){return new g.DERPrintableString(b[j])}if(j==""telstr""){return new g.DERTeletexString(b[j])}if(j==""ia5str""){return new g.DERIA5String(b[j])}if(j==""utctime""){return new g.DERUTCTime(b[j])}if(j==""gentime""){return new g.DERGeneralizedTime(b[j])}if(j==""seq""){var m=b[j];var h=[];for(var e=0;e<m.length;e++){var l=g.ASN1Util.newObject(m[e]);h.push(l)}return new g.DERSequence({array:h})}if(j==""set""){var m=b[j];var h=[];for(var e=0;e<m.length;e++){var l=g.ASN1Util.newObject(m[e]);h.push(l)}return new g.DERSet({array:h})}if(j==""tag""){var c=b[j];if(Object.prototype.toString.call(c)===""[object Array]""&&c.length==3){var d=g.ASN1Util.newObject(c[2]);return new g.DERTaggedObject({tag:c[0],explicit:c[1],obj:d})}else{var f={};if(c.explicit!==undefined){f.explicit=c.explicit}if(c.tag!==undefined){f.tag=c.tag}if(c.obj===undefined){throw""obj shall be specified for 'tag'.""}f.obj=g.ASN1Util.newObject(c.obj);return new g.DERTaggedObject(f)}}};this.jsonToASN1HEX=function(b){var a=this.newObject(b);return a.getEncodedHex()}};KJUR.asn1.ASN1Object=function(){var c=true;var b=null;var d=""00"";var e=""00"";var a="""";this.getLengthHexFromValue=function(){if(typeof this.hV==""undefined""||this.hV==null){throw""this.hV is null or undefined.""}if(this.hV.length%2==1){throw""value hex must be even length: n=""+a.length+"",v=""+this.hV}var i=this.hV.length/2;var h=i.toString(16);if(h.length%2==1){h=""0""+h}if(i<128){return h}else{var g=h.length/2;if(g>15){throw""ASN.1 length too long to represent by 8x: n = ""+i.toString(16)}var f=128+g;return f.toString(16)+h}};this.getEncodedHex=function(){if(this.hTLV==null||this.isModified){this.hV=this.getFreshValueHex();this.hL=this.getLengthHexFromValue();this.hTLV=this.hT+this.hL+this.hV;this.isModified=false}return this.hTLV};this.getValueHex=function(){this.getEncodedHex();return this.hV};this.getFreshValueHex=function(){return""""}};KJUR.asn1.DERAbstractString=function(c){KJUR.asn1.DERAbstractString.superclass.constructor.call(this);var b=null;var a=null;this.getString=function(){return this.s};this.setString=function(d){this.hTLV=null;this.isModified=true;this.s=d;this.hV=stohex(this.s)};this.setStringHex=function(d){this.hTLV=null;this.isModified=true;this.s=null;this.hV=d};this.getFreshValueHex=function(){return this.hV};if(typeof c!=""undefined""){if(typeof c==""string""){this.setString(c)}else{if(typeof c.str!=""undefined""){this.setString(c.str)}else{if(typeof c.hex!=""undefined""){this.setStringHex(c.hex)}}}}};YAHOO.lang.extend(KJUR.asn1.DERAbstractString,KJUR.asn1.ASN1Object);KJUR.asn1.DERAbstractTime=function(c){KJUR.asn1.DERAbstractTime.superclass.constructor.call(this);var b=null;var a=null;this.localDateToUTC=function(f){utc=f.getTime()+(f.getTimezoneOffset()*60000);var e=new Date(utc);return e};this.formatDate=function(m,o,e){var g=this.zeroPadding;var n=this.localDateToUTC(m);var p=String(n.getFullYear());if(o==""utc""){p=p.substr(2,2)}var l=g(String(n.getMonth()+1),2);var q=g(String(n.getDate()),2);var h=g(String(n.getHours()),2);var i=g(String(n.getMinutes()),2);var j=g(String(n.getSeconds()),2);var r=p+l+q+h+i+j;if(e===true){var f=n.getMilliseconds();if(f!=0){var k=g(String(f),3);k=k.replace(/[0]+$/,"""");r=r+"".""+k}}return r+""Z""};this.zeroPadding=function(e,d){if(e.length>=d){return e}return new Array(d-e.length+1).join(""0"")+e};this.getString=function(){return this.s};this.setString=function(d){this.hTLV=null;this.isModified=true;this.s=d;this.hV=stohex(d)};this.setByDateValue=function(h,j,e,d,f,g){var i=new Date(Date.UTC(h,j-1,e,d,f,g,0));this.setByDate(i)};this.getFreshValueHex=function(){return this.hV}};YAHOO.lang.extend(KJUR.asn1.DERAbstractTime,KJUR.asn1.ASN1Object);KJUR.asn1.DERAbstractStructured=function(b){KJUR.asn1.DERAbstractString.superclass.constructor.call(this);var a=null;this.setByASN1ObjectArray=function(c){this.hTLV=null;this.isModified=true;this.asn1Array=c};this.appendASN1Object=function(c){this.hTLV=null;this.isModified=true;this.asn1Array.push(c)};this.asn1Array=new Array();if(typeof b!=""undefined""){if(typeof b.array!=""undefined""){this.asn1Array=b.array}}};YAHOO.lang.extend(KJUR.asn1.DERAbstractStructured,KJUR.asn1.ASN1Object);KJUR.asn1.DERBoolean=function(){KJUR.asn1.DERBoolean.superclass.constructor.call(this);this.hT=""01"";this.hTLV=""0101ff""};YAHOO.lang.extend(KJUR.asn1.DERBoolean,KJUR.asn1.ASN1Object);KJUR.asn1.DERInteger=function(a){KJUR.asn1.DERInteger.superclass.constructor.call(this);this.hT=""02"";this.setByBigInteger=function(b){this.hTLV=null;this.isModified=true;this.hV=KJUR.asn1.ASN1Util.bigIntToMinTwosComplementsHex(b)};this.setByInteger=function(c){var b=new BigInteger(String(c),10);this.setByBigInteger(b)};this.setValueHex=function(b){this.hV=b};this.getFreshValueHex=function(){return this.hV};if(typeof a!=""undefined""){if(typeof a.bigint!=""undefined""){this.setByBigInteger(a.bigint)}else{if(typeof a[""int""]!=""undefined""){this.setByInteger(a[""int""])}else{if(typeof a==""number""){this.setByInteger(a)}else{if(typeof a.hex!=""undefined""){this.setValueHex(a.hex)}}}}}};YAHOO.lang.extend(KJUR.asn1.DERInteger,KJUR.asn1.ASN1Object);KJUR.asn1.DERBitString=function(a){KJUR.asn1.DERBitString.superclass.constructor.call(this);this.hT=""03"";this.setHexValueIncludingUnusedBits=function(b){this.hTLV=null;this.isModified=true;this.hV=b};this.setUnusedBitsAndHexValue=function(b,d){if(b<0||7<b){throw""unused bits shall be from 0 to 7: u = ""+b}var c=""0""+b;this.hTLV=null;this.isModified=true;this.hV=c+d};this.setByBinaryString=function(e){e=e.replace(/0+$/,"""");var f=8-e.length%8;if(f==8){f=0}for(var g=0;g<=f;g++){e+=""0""}var j="""";for(var g=0;g<e.length-1;g+=8){var d=e.substr(g,8);var c=parseInt(d,2).toString(16);if(c.length==1){c=""0""+c}j+=c}this.hTLV=null;this.isModified=true;this.hV=""0""+f+j};this.setByBooleanArray=function(d){var c="""";for(var b=0;b<d.length;b++){if(d[b]==true){c+=""1""}else{c+=""0""}}this.setByBinaryString(c)};this.newFalseArray=function(d){var b=new Array(d);for(var c=0;c<d;c++){b[c]=false}return b};this.getFreshValueHex=function(){return this.hV};if(typeof a!=""undefined""){if(typeof a==""string""&&a.toLowerCase().match(/^[0-9a-f]+$/)){this.setHexValueIncludingUnusedBits(a)}else{if(typeof a.hex!=""undefined""){this.setHexValueIncludingUnusedBits(a.hex)}else{if(typeof a.bin!=""undefined""){this.setByBinaryString(a.bin)}else{if(typeof a.array!=""undefined""){this.setByBooleanArray(a.array)}}}}}};YAHOO.lang.extend(KJUR.asn1.DERBitString,KJUR.asn1.ASN1Object);KJUR.asn1.DEROctetString=function(a){KJUR.asn1.DEROctetString.superclass.constructor.call(this,a);this.hT=""04""};YAHOO.lang.extend(KJUR.asn1.DEROctetString,KJUR.asn1.DERAbstractString);KJUR.asn1.DERNull=function(){KJUR.asn1.DERNull.superclass.constructor.call(this);this.hT=""05"";this.hTLV=""0500""};YAHOO.lang.extend(KJUR.asn1.DERNull,KJUR.asn1.ASN1Object);KJUR.asn1.DERObjectIdentifier=function(c){var b=function(d){var e=d.toString(16);if(e.length==1){e=""0""+e}return e};var a=function(k){var j="""";var e=new BigInteger(k,10);var d=e.toString(2);var f=7-d.length%7;if(f==7){f=0}var m="""";for(var g=0;g<f;g++){m+=""0""}d=m+d;for(var g=0;g<d.length-1;g+=7){var l=d.substr(g,7);if(g!=d.length-7){l=""1""+l}j+=b(parseInt(l,2))}return j};KJUR.asn1.DERObjectIdentifier.superclass.constructor.call(this);this.hT=""06"";this.setValueHex=function(d){this.hTLV=null;this.isModified=true;this.s=null;this.hV=d};this.setValueOidString=function(f){if(!f.match(/^[0-9.]+$/)){throw""malformed oid string: ""+f}var g="""";var d=f.split(""."");var j=parseInt(d[0])*40+parseInt(d[1]);g+=b(j);d.splice(0,2);for(var e=0;e<d.length;e++){g+=a(d[e])}this.hTLV=null;this.isModified=true;this.s=null;this.hV=g};this.setValueName=function(e){if(typeof KJUR.asn1.x509.OID.name2oidList[e]!=""undefined""){var d=KJUR.asn1.x509.OID.name2oidList[e];this.setValueOidString(d)}else{throw""DERObjectIdentifier oidName undefined: ""+e}};this.getFreshValueHex=function(){return this.hV};if(typeof c!=""undefined""){if(typeof c==""string""&&c.match(/^[0-2].[0-9.]+$/)){this.setValueOidString(c)}else{if(KJUR.asn1.x509.OID.name2oidList[c]!==undefined){this.setValueOidString(KJUR.asn1.x509.OID.name2oidList[c])}else{if(typeof c.oid!=""undefined""){this.setValueOidString(c.oid)}else{if(typeof c.hex!=""undefined""){this.setValueHex(c.hex)}else{if(typeof c.name!=""undefined""){this.setValueName(c.name)}}}}}}};YAHOO.lang.extend(KJUR.asn1.DERObjectIdentifier,KJUR.asn1.ASN1Object);KJUR.asn1.DERUTF8String=function(a){KJUR.asn1.DERUTF8String.superclass.constructor.call(this,a);this.hT=""0c""};YAHOO.lang.extend(KJUR.asn1.DERUTF8String,KJUR.asn1.DERAbstractString);KJUR.asn1.DERNumericString=function(a){KJUR.asn1.DERNumericString.superclass.constructor.call(this,a);this.hT=""12""};YAHOO.lang.extend(KJUR.asn1.DERNumericString,KJUR.asn1.DERAbstractString);KJUR.asn1.DERPrintableString=function(a){KJUR.asn1.DERPrintableString.superclass.constructor.call(this,a);this.hT=""13""};YAHOO.lang.extend(KJUR.asn1.DERPrintableString,KJUR.asn1.DERAbstractString);KJUR.asn1.DERTeletexString=function(a){KJUR.asn1.DERTeletexString.superclass.constructor.call(this,a);this.hT=""14""};YAHOO.lang.extend(KJUR.asn1.DERTeletexString,KJUR.asn1.DERAbstractString);KJUR.asn1.DERIA5String=function(a){KJUR.asn1.DERIA5String.superclass.constructor.call(this,a);this.hT=""16""};YAHOO.lang.extend(KJUR.asn1.DERIA5String,KJUR.asn1.DERAbstractString);KJUR.asn1.DERUTCTime=function(a){KJUR.asn1.DERUTCTime.superclass.constructor.call(this,a);this.hT=""17"";this.setByDate=function(b){this.hTLV=null;this.isModified=true;this.date=b;this.s=this.formatDate(this.date,""utc"");this.hV=stohex(this.s)};this.getFreshValueHex=function(){if(typeof this.date==""undefined""&&typeof this.s==""undefined""){this.date=new Date();this.s=this.formatDate(this.date,""utc"");this.hV=stohex(this.s)}return this.hV};if(typeof a!=""undefined""){if(typeof a.str!=""undefined""){this.setString(a.str)}else{if(typeof a==""string""&&a.match(/^[0-9]{12}Z$/)){this.setString(a)}else{if(typeof a.hex!=""undefined""){this.setStringHex(a.hex)}else{if(typeof a.date!=""undefined""){this.setByDate(a.date)}}}}}};YAHOO.lang.extend(KJUR.asn1.DERUTCTime,KJUR.asn1.DERAbstractTime);KJUR.asn1.DERGeneralizedTime=function(a){KJUR.asn1.DERGeneralizedTime.superclass.constructor.call(this,a);this.hT=""18"";this.withMillis=false;this.setByDate=function(b){this.hTLV=null;this.isModified=true;this.date=b;this.s=this.formatDate(this.date,""gen"",this.withMillis);this.hV=stohex(this.s)};this.getFreshValueHex=function(){if(typeof this.date==""undefined""&&typeof this.s==""undefined""){this.date=new Date();this.s=this.formatDate(this.date,""gen"",this.withMillis);this.hV=stohex(this.s)}return this.hV};if(typeof a!=""undefined""){if(typeof a.str!=""undefined""){this.setString(a.str)}else{if(typeof a==""string""&&a.match(/^[0-9]{14}Z$/)){this.setString(a)}else{if(typeof a.hex!=""undefined""){this.setStringHex(a.hex)}else{if(typeof a.date!=""undefined""){this.setByDate(a.date)}else{if(a.millis===true){this.withMillis=true}}}}}}};YAHOO.lang.extend(KJUR.asn1.DERGeneralizedTime,KJUR.asn1.DERAbstractTime);KJUR.asn1.DERSequence=function(a){KJUR.asn1.DERSequence.superclass.constructor.call(this,a);this.hT=""30"";this.getFreshValueHex=function(){var c="""";for(var b=0;b<this.asn1Array.length;b++){var d=this.asn1Array[b];c+=d.getEncodedHex()}this.hV=c;return this.hV}};YAHOO.lang.extend(KJUR.asn1.DERSequence,KJUR.asn1.DERAbstractStructured);KJUR.asn1.DERSet=function(a){KJUR.asn1.DERSet.superclass.constructor.call(this,a);this.hT=""31"";this.sortFlag=true;this.getFreshValueHex=function(){var b=new Array();for(var c=0;c<this.asn1Array.length;c++){var d=this.asn1Array[c];b.push(d.getEncodedHex())}if(this.sortFlag==true){b.sort()}this.hV=b.join("""");return this.hV};if(typeof a!=""undefined""){if(typeof a.sortflag!=""undefined""&&a.sortflag==false){this.sortFlag=false}}};YAHOO.lang.extend(KJUR.asn1.DERSet,KJUR.asn1.DERAbstractStructured);KJUR.asn1.DERTaggedObject=function(a){KJUR.asn1.DERTaggedObject.superclass.constructor.call(this);this.hT=""a0"";this.hV="""";this.isExplicit=true;this.asn1Object=null;this.setASN1Object=function(b,c,d){this.hT=c;this.isExplicit=b;this.asn1Object=d;if(this.isExplicit){this.hV=this.asn1Object.getEncodedHex();this.hTLV=null;this.isModified=true}else{this.hV=null;this.hTLV=d.getEncodedHex();this.hTLV=this.hTLV.replace(/^../,c);this.isModified=false}};this.getFreshValueHex=function(){return this.hV};if(typeof a!=""undefined""){if(typeof a.tag!=""undefined""){this.hT=a.tag}if(typeof a.explicit!=""undefined""){this.isExplicit=a.explicit}if(typeof a.obj!=""undefined""){this.asn1Object=a.obj;this.setASN1Object(this.isExplicit,this.hT,this.asn1Object)}}};YAHOO.lang.extend(KJUR.asn1.DERTaggedObject,KJUR.asn1.ASN1Object); /*! asn1hex-1.1.5.js (c) 2012-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ var ASN1HEX=new function(){this.getByteLengthOfL_AtObj=function(b,c){if(b.substring(c+2,c+3)!=""8""){return 1}var a=parseInt(b.substring(c+3,c+4));if(a==0){return -1}if(0<a&&a<10){return a+1}return -2};this.getHexOfL_AtObj=function(b,c){var a=this.getByteLengthOfL_AtObj(b,c);if(a<1){return""""}return b.substring(c+2,c+2+a*2)};this.getIntOfL_AtObj=function(c,d){var b=this.getHexOfL_AtObj(c,d);if(b==""""){return -1}var a;if(parseInt(b.substring(0,1))<8){a=new BigInteger(b,16)}else{a=new BigInteger(b.substring(2),16)}return a.intValue()};this.getStartPosOfV_AtObj=function(b,c){var a=this.getByteLengthOfL_AtObj(b,c);if(a<0){return a}return c+(a+1)*2};this.getHexOfV_AtObj=function(c,d){var b=this.getStartPosOfV_AtObj(c,d);var a=this.getIntOfL_AtObj(c,d);return c.substring(b,b+a*2)};this.getHexOfTLV_AtObj=function(c,e){var b=c.substr(e,2);var d=this.getHexOfL_AtObj(c,e);var a=this.getHexOfV_AtObj(c,e);return b+d+a};this.getPosOfNextSibling_AtObj=function(c,d){var b=this.getStartPosOfV_AtObj(c,d);var a=this.getIntOfL_AtObj(c,d);return b+a*2};this.getPosArrayOfChildren_AtObj=function(f,j){var c=new Array();var i=this.getStartPosOfV_AtObj(f,j);c.push(i);var b=this.getIntOfL_AtObj(f,j);var g=i;var d=0;while(1){var e=this.getPosOfNextSibling_AtObj(f,g);if(e==null||(e-i>=(b*2))){break}if(d>=200){break}c.push(e);g=e;d++}return c};this.getNthChildIndex_AtObj=function(d,b,e){var c=this.getPosArrayOfChildren_AtObj(d,b);return c[e]};this.getDecendantIndexByNthList=function(e,d,c){if(c.length==0){return d}var f=c.shift();var b=this.getPosArrayOfChildren_AtObj(e,d);return this.getDecendantIndexByNthList(e,b[f],c)};this.getDecendantHexTLVByNthList=function(d,c,b){var a=this.getDecendantIndexByNthList(d,c,b);return this.getHexOfTLV_AtObj(d,a)};this.getDecendantHexVByNthList=function(d,c,b){var a=this.getDecendantIndexByNthList(d,c,b);return this.getHexOfV_AtObj(d,a)}};ASN1HEX.getVbyList=function(d,c,b,e){var a=this.getDecendantIndexByNthList(d,c,b);if(a===undefined){throw""can't find nthList object""}if(e!==undefined){if(d.substr(a,2)!=e){throw""checking tag doesn't match: ""+d.substr(a,2)+""!=""+e}}return this.getHexOfV_AtObj(d,a)};ASN1HEX.hextooidstr=function(e){var h=function(b,a){if(b.length>=a){return b}return new Array(a-b.length+1).join(""0"")+b};var l=[];var o=e.substr(0,2);var f=parseInt(o,16);l[0]=new String(Math.floor(f/40));l[1]=new String(f%40);var m=e.substr(2);var k=[];for(var g=0;g<m.length/2;g++){k.push(parseInt(m.substr(g*2,2),16))}var j=[];var d="""";for(var g=0;g<k.length;g++){if(k[g]&128){d=d+h((k[g]&127).toString(2),7)}else{d=d+h((k[g]&127).toString(2),7);j.push(new String(parseInt(d,2)));d=""""}}var n=l.join(""."");if(j.length>0){n=n+"".""+j.join(""."")}return n}; /*! asn1x509-1.0.9.js (c) 2013-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.asn1==""undefined""||!KJUR.asn1){KJUR.asn1={}}if(typeof KJUR.asn1.x509==""undefined""||!KJUR.asn1.x509){KJUR.asn1.x509={}}KJUR.asn1.x509.Certificate=function(g){KJUR.asn1.x509.Certificate.superclass.constructor.call(this);var b=null;var d=null;var f=null;var c=null;var a=null;var e=null;this.setRsaPrvKeyByPEMandPass=function(i,k){var h=PKCS5PKEY.getDecryptedKeyHex(i,k);var j=new RSAKey();j.readPrivateKeyFromASN1HexString(h);this.prvKey=j};this.sign=function(){this.asn1SignatureAlg=this.asn1TBSCert.asn1SignatureAlg;sig=new KJUR.crypto.Signature({alg:""SHA1withRSA""});sig.init(this.prvKey);sig.updateHex(this.asn1TBSCert.getEncodedHex());this.hexSig=sig.sign();this.asn1Sig=new KJUR.asn1.DERBitString({hex:""00""+this.hexSig});var h=new KJUR.asn1.DERSequence({array:[this.asn1TBSCert,this.asn1SignatureAlg,this.asn1Sig]});this.hTLV=h.getEncodedHex();this.isModified=false};this.setSignatureHex=function(h){this.asn1SignatureAlg=this.asn1TBSCert.asn1SignatureAlg;this.hexSig=h;this.asn1Sig=new KJUR.asn1.DERBitString({hex:""00""+this.hexSig});var i=new KJUR.asn1.DERSequence({array:[this.asn1TBSCert,this.asn1SignatureAlg,this.asn1Sig]});this.hTLV=i.getEncodedHex();this.isModified=false};this.getEncodedHex=function(){if(this.isModified==false&&this.hTLV!=null){return this.hTLV}throw""not signed yet""};this.getPEMString=function(){var j=this.getEncodedHex();var h=CryptoJS.enc.Hex.parse(j);var i=CryptoJS.enc.Base64.stringify(h);var k=i.replace(/(.{64})/g,""$1\r\n"");return""-----BEGIN CERTIFICATE-----\r\n""+k+""\r\n-----END CERTIFICATE-----\r\n""};if(typeof g!=""undefined""){if(typeof g.tbscertobj!=""undefined""){this.asn1TBSCert=g.tbscertobj}if(typeof g.prvkeyobj!=""undefined""){this.prvKey=g.prvkeyobj}else{if(typeof g.rsaprvkey!=""undefined""){this.prvKey=g.rsaprvkey}else{if((typeof g.rsaprvpem!=""undefined"")&&(typeof g.rsaprvpas!=""undefined"")){this.setRsaPrvKeyByPEMandPass(g.rsaprvpem,g.rsaprvpas)}}}}};YAHOO.lang.extend(KJUR.asn1.x509.Certificate,KJUR.asn1.ASN1Object);KJUR.asn1.x509.TBSCertificate=function(a){KJUR.asn1.x509.TBSCertificate.superclass.constructor.call(this);this._initialize=function(){this.asn1Array=new Array();this.asn1Version=new KJUR.asn1.DERTaggedObject({obj:new KJUR.asn1.DERInteger({""int"":2})});this.asn1SerialNumber=null;this.asn1SignatureAlg=null;this.asn1Issuer=null;this.asn1NotBefore=null;this.asn1NotAfter=null;this.asn1Subject=null;this.asn1SubjPKey=null;this.extensionsArray=new Array()};this.setSerialNumberByParam=function(b){this.asn1SerialNumber=new KJUR.asn1.DERInteger(b)};this.setSignatureAlgByParam=function(b){this.asn1SignatureAlg=new KJUR.asn1.x509.AlgorithmIdentifier(b)};this.setIssuerByParam=function(b){this.asn1Issuer=new KJUR.asn1.x509.X500Name(b)};this.setNotBeforeByParam=function(b){this.asn1NotBefore=new KJUR.asn1.x509.Time(b)};this.setNotAfterByParam=function(b){this.asn1NotAfter=new KJUR.asn1.x509.Time(b)};this.setSubjectByParam=function(b){this.asn1Subject=new KJUR.asn1.x509.X500Name(b)};this.setSubjectPublicKeyByParam=function(b){this.asn1SubjPKey=new KJUR.asn1.x509.SubjectPublicKeyInfo(b)};this.setSubjectPublicKeyByGetKey=function(c){var b=KEYUTIL.getKey(c);this.asn1SubjPKey=new KJUR.asn1.x509.SubjectPublicKeyInfo(b)};this.appendExtension=function(b){this.extensionsArray.push(b)};this.appendExtensionByName=function(d,b){if(d.toLowerCase()==""basicconstraints""){var c=new KJUR.asn1.x509.BasicConstraints(b);this.appendExtension(c)}else{if(d.toLowerCase()==""keyusage""){var c=new KJUR.asn1.x509.KeyUsage(b);this.appendExtension(c)}else{if(d.toLowerCase()==""crldistributionpoints""){var c=new KJUR.asn1.x509.CRLDistributionPoints(b);this.appendExtension(c)}else{if(d.toLowerCase()==""extkeyusage""){var c=new KJUR.asn1.x509.ExtKeyUsage(b);this.appendExtension(c)}else{if(d.toLowerCase()==""authoritykeyidentifier""){var c=new KJUR.asn1.x509.AuthorityKeyIdentifier(b);this.appendExtension(c)}else{throw""unsupported extension name: ""+d}}}}}};this.getEncodedHex=function(){if(this.asn1NotBefore==null||this.asn1NotAfter==null){throw""notBefore and/or notAfter not set""}var c=new KJUR.asn1.DERSequence({array:[this.asn1NotBefore,this.asn1NotAfter]});this.asn1Array=new Array();this.asn1Array.push(this.asn1Version);this.asn1Array.push(this.asn1SerialNumber);this.asn1Array.push(this.asn1SignatureAlg);this.asn1Array.push(this.asn1Issuer);this.asn1Array.push(c);this.asn1Array.push(this.asn1Subject);this.asn1Array.push(this.asn1SubjPKey);if(this.extensionsArray.length>0){var d=new KJUR.asn1.DERSequence({array:this.extensionsArray});var b=new KJUR.asn1.DERTaggedObject({explicit:true,tag:""a3"",obj:d});this.asn1Array.push(b)}var e=new KJUR.asn1.DERSequence({array:this.asn1Array});this.hTLV=e.getEncodedHex();this.isModified=false;return this.hTLV};this._initialize()};YAHOO.lang.extend(KJUR.asn1.x509.TBSCertificate,KJUR.asn1.ASN1Object);KJUR.asn1.x509.Extension=function(b){KJUR.asn1.x509.Extension.superclass.constructor.call(this);var a=null;this.getEncodedHex=function(){var f=new KJUR.asn1.DERObjectIdentifier({oid:this.oid});var e=new KJUR.asn1.DEROctetString({hex:this.getExtnValueHex()});var d=new Array();d.push(f);if(this.critical){d.push(new KJUR.asn1.DERBoolean())}d.push(e);var c=new KJUR.asn1.DERSequence({array:d});return c.getEncodedHex()};this.critical=false;if(typeof b!=""undefined""){if(typeof b.critical!=""undefined""){this.critical=b.critical}}};YAHOO.lang.extend(KJUR.asn1.x509.Extension,KJUR.asn1.ASN1Object);KJUR.asn1.x509.KeyUsage=function(a){KJUR.asn1.x509.KeyUsage.superclass.constructor.call(this,a);this.getExtnValueHex=function(){return this.asn1ExtnValue.getEncodedHex()};this.oid=""2.5.29.15"";if(typeof a!=""undefined""){if(typeof a.bin!=""undefined""){this.asn1ExtnValue=new KJUR.asn1.DERBitString(a)}}};YAHOO.lang.extend(KJUR.asn1.x509.KeyUsage,KJUR.asn1.x509.Extension);KJUR.asn1.x509.BasicConstraints=function(c){KJUR.asn1.x509.BasicConstraints.superclass.constructor.call(this,c);var a=false;var b=-1;this.getExtnValueHex=function(){var e=new Array();if(this.cA){e.push(new KJUR.asn1.DERBoolean())}if(this.pathLen>-1){e.push(new KJUR.asn1.DERInteger({""int"":this.pathLen}))}var d=new KJUR.asn1.DERSequence({array:e});this.asn1ExtnValue=d;return this.asn1ExtnValue.getEncodedHex()};this.oid=""2.5.29.19"";this.cA=false;this.pathLen=-1;if(typeof c!=""undefined""){if(typeof c.cA!=""undefined""){this.cA=c.cA}if(typeof c.pathLen!=""undefined""){this.pathLen=c.pathLen}}};YAHOO.lang.extend(KJUR.asn1.x509.BasicConstraints,KJUR.asn1.x509.Extension);KJUR.asn1.x509.CRLDistributionPoints=function(a){KJUR.asn1.x509.CRLDistributionPoints.superclass.constructor.call(this,a);this.getExtnValueHex=function(){return this.asn1ExtnValue.getEncodedHex()};this.setByDPArray=function(b){this.asn1ExtnValue=new KJUR.asn1.DERSequence({array:b})};this.setByOneURI=function(e){var b=new KJUR.asn1.x509.GeneralNames([{uri:e}]);var d=new KJUR.asn1.x509.DistributionPointName(b);var c=new KJUR.asn1.x509.DistributionPoint({dpobj:d});this.setByDPArray([c])};this.oid=""2.5.29.31"";if(typeof a!=""undefined""){if(typeof a.array!=""undefined""){this.setByDPArray(a.array)}else{if(typeof a.uri!=""undefined""){this.setByOneURI(a.uri)}}}};YAHOO.lang.extend(KJUR.asn1.x509.CRLDistributionPoints,KJUR.asn1.x509.Extension);KJUR.asn1.x509.ExtKeyUsage=function(a){KJUR.asn1.x509.ExtKeyUsage.superclass.constructor.call(this,a);this.setPurposeArray=function(b){this.asn1ExtnValue=new KJUR.asn1.DERSequence();for(var c=0;c<b.length;c++){var d=new KJUR.asn1.DERObjectIdentifier(b[c]);this.asn1ExtnValue.appendASN1Object(d)}};this.getExtnValueHex=function(){return this.asn1ExtnValue.getEncodedHex()};this.oid=""2.5.29.37"";if(typeof a!=""undefined""){if(typeof a.array!=""undefined""){this.setPurposeArray(a.array)}}};YAHOO.lang.extend(KJUR.asn1.x509.ExtKeyUsage,KJUR.asn1.x509.Extension);KJUR.asn1.x509.AuthorityKeyIdentifier=function(a){KJUR.asn1.x509.AuthorityKeyIdentifier.superclass.constructor.call(this,a);this.asn1KID=null;this.asn1CertIssuer=null;this.asn1CertSN=null;this.getExtnValueHex=function(){var c=new Array();if(this.asn1KID){c.push(new KJUR.asn1.DERTaggedObject({explicit:false,tag:""80"",obj:this.asn1KID}))}if(this.asn1CertIssuer){c.push(new KJUR.asn1.DERTaggedObject({explicit:false,tag:""a1"",obj:this.asn1CertIssuer}))}if(this.asn1CertSN){c.push(new KJUR.asn1.DERTaggedObject({explicit:false,tag:""82"",obj:this.asn1CertSN}))}var b=new KJUR.asn1.DERSequence({array:c});this.asn1ExtnValue=b;return this.asn1ExtnValue.getEncodedHex()};this.setKIDByParam=function(b){this.asn1KID=new KJUR.asn1.DEROctetString(b)};this.setCertIssuerByParam=function(b){this.asn1CertIssuer=new KJUR.asn1.x509.X500Name(b)};this.setCertSNByParam=function(b){this.asn1CertSN=new KJUR.asn1.DERInteger(b)};this.oid=""2.5.29.35"";if(typeof a!=""undefined""){if(typeof a.kid!=""undefined""){this.setKIDByParam(a.kid)}if(typeof a.issuer!=""undefined""){this.setCertIssuerByParam(a.issuer)}if(typeof a.sn!=""undefined""){this.setCertSNByParam(a.sn)}}};YAHOO.lang.extend(KJUR.asn1.x509.AuthorityKeyIdentifier,KJUR.asn1.x509.Extension);KJUR.asn1.x509.CRL=function(f){KJUR.asn1.x509.CRL.superclass.constructor.call(this);var a=null;var c=null;var e=null;var b=null;var d=null;this.setRsaPrvKeyByPEMandPass=function(h,j){var g=PKCS5PKEY.getDecryptedKeyHex(h,j);var i=new RSAKey();i.readPrivateKeyFromASN1HexString(g);this.rsaPrvKey=i};this.sign=function(){this.asn1SignatureAlg=this.asn1TBSCertList.asn1SignatureAlg;sig=new KJUR.crypto.Signature({alg:""SHA1withRSA"",prov:""cryptojs/jsrsa""});sig.initSign(this.rsaPrvKey);sig.updateHex(this.asn1TBSCertList.getEncodedHex());this.hexSig=sig.sign();this.asn1Sig=new KJUR.asn1.DERBitString({hex:""00""+this.hexSig});var g=new KJUR.asn1.DERSequence({array:[this.asn1TBSCertList,this.asn1SignatureAlg,this.asn1Sig]});this.hTLV=g.getEncodedHex();this.isModified=false};this.getEncodedHex=function(){if(this.isModified==false&&this.hTLV!=null){return this.hTLV}throw""not signed yet""};this.getPEMString=function(){var i=this.getEncodedHex();var g=CryptoJS.enc.Hex.parse(i);var h=CryptoJS.enc.Base64.stringify(g);var j=h.replace(/(.{64})/g,""$1\r\n"");return""-----BEGIN X509 CRL-----\r\n""+j+""\r\n-----END X509 CRL-----\r\n""};if(typeof f!=""undefined""){if(typeof f.tbsobj!=""undefined""){this.asn1TBSCertList=f.tbsobj}if(typeof f.rsaprvkey!=""undefined""){this.rsaPrvKey=f.rsaprvkey}if((typeof f.rsaprvpem!=""undefined"")&&(typeof f.rsaprvpas!=""undefined"")){this.setRsaPrvKeyByPEMandPass(f.rsaprvpem,f.rsaprvpas)}}};YAHOO.lang.extend(KJUR.asn1.x509.CRL,KJUR.asn1.ASN1Object);KJUR.asn1.x509.TBSCertList=function(b){KJUR.asn1.x509.TBSCertList.superclass.constructor.call(this);var a=null;this.setSignatureAlgByParam=function(c){this.asn1SignatureAlg=new KJUR.asn1.x509.AlgorithmIdentifier(c)};this.setIssuerByParam=function(c){this.asn1Issuer=new KJUR.asn1.x509.X500Name(c)};this.setThisUpdateByParam=function(c){this.asn1ThisUpdate=new KJUR.asn1.x509.Time(c)};this.setNextUpdateByParam=function(c){this.asn1NextUpdate=new KJUR.asn1.x509.Time(c)};this.addRevokedCert=function(c,d){var f={};if(c!=undefined&&c!=null){f.sn=c}if(d!=undefined&&d!=null){f.time=d}var e=new KJUR.asn1.x509.CRLEntry(f);this.aRevokedCert.push(e)};this.getEncodedHex=function(){this.asn1Array=new Array();if(this.asn1Version!=null){this.asn1Array.push(this.asn1Version)}this.asn1Array.push(this.asn1SignatureAlg);this.asn1Array.push(this.asn1Issuer);this.asn1Array.push(this.asn1ThisUpdate);if(this.asn1NextUpdate!=null){this.asn1Array.push(this.asn1NextUpdate)}if(this.aRevokedCert.length>0){var c=new KJUR.asn1.DERSequence({array:this.aRevokedCert});this.asn1Array.push(c)}var d=new KJUR.asn1.DERSequence({array:this.asn1Array});this.hTLV=d.getEncodedHex();this.isModified=false;return this.hTLV};this._initialize=function(){this.asn1Version=null;this.asn1SignatureAlg=null;this.asn1Issuer=null;this.asn1ThisUpdate=null;this.asn1NextUpdate=null;this.aRevokedCert=new Array()};this._initialize()};YAHOO.lang.extend(KJUR.asn1.x509.TBSCertList,KJUR.asn1.ASN1Object);KJUR.asn1.x509.CRLEntry=function(c){KJUR.asn1.x509.CRLEntry.superclass.constructor.call(this);var b=null;var a=null;this.setCertSerial=function(d){this.sn=new KJUR.asn1.DERInteger(d)};this.setRevocationDate=function(d){this.time=new KJUR.asn1.x509.Time(d)};this.getEncodedHex=function(){var d=new KJUR.asn1.DERSequence({array:[this.sn,this.time]});this.TLV=d.getEncodedHex();return this.TLV};if(typeof c!=""undefined""){if(typeof c.time!=""undefined""){this.setRevocationDate(c.time)}if(typeof c.sn!=""undefined""){this.setCertSerial(c.sn)}}};YAHOO.lang.extend(KJUR.asn1.x509.CRLEntry,KJUR.asn1.ASN1Object);KJUR.asn1.x509.X500Name=function(b){KJUR.asn1.x509.X500Name.superclass.constructor.call(this);this.asn1Array=new Array();this.setByString=function(c){var d=c.split(""/"");d.shift();for(var e=0;e<d.length;e++){this.asn1Array.push(new KJUR.asn1.x509.RDN({str:d[e]}))}};this.getEncodedHex=function(){if(typeof this.hTLV==""string""){return this.hTLV}var c=new KJUR.asn1.DERSequence({array:this.asn1Array});this.hTLV=c.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(typeof b.str!=""undefined""){this.setByString(b.str)}if(typeof b.certissuer!=""undefined""){var a=new X509();a.hex=X509.pemToHex(b.certissuer);this.hTLV=a.getIssuerHex()}if(typeof b.certsubject!=""undefined""){var a=new X509();a.hex=X509.pemToHex(b.certsubject);this.hTLV=a.getSubjectHex()}}};YAHOO.lang.extend(KJUR.asn1.x509.X500Name,KJUR.asn1.ASN1Object);KJUR.asn1.x509.RDN=function(a){KJUR.asn1.x509.RDN.superclass.constructor.call(this);this.asn1Array=new Array();this.addByString=function(b){this.asn1Array.push(new KJUR.asn1.x509.AttributeTypeAndValue({str:b}))};this.getEncodedHex=function(){var b=new KJUR.asn1.DERSet({array:this.asn1Array});this.TLV=b.getEncodedHex();return this.TLV};if(typeof a!=""undefined""){if(typeof a.str!=""undefined""){this.addByString(a.str)}}};YAHOO.lang.extend(KJUR.asn1.x509.RDN,KJUR.asn1.ASN1Object);KJUR.asn1.x509.AttributeTypeAndValue=function(b){KJUR.asn1.x509.AttributeTypeAndValue.superclass.constructor.call(this);var d=null;var c=null;var a=""utf8"";this.setByString=function(e){if(e.match(/^([^=]+)=(.+)$/)){this.setByAttrTypeAndValueStr(RegExp.$1,RegExp.$2)}else{throw""malformed attrTypeAndValueStr: ""+e}};this.setByAttrTypeAndValueStr=function(g,f){this.typeObj=KJUR.asn1.x509.OID.atype2obj(g);var e=a;if(g==""C""){e=""prn""}this.valueObj=this.getValueObj(e,f)};this.getValueObj=function(f,e){if(f==""utf8""){return new KJUR.asn1.DERUTF8String({str:e})}if(f==""prn""){return new KJUR.asn1.DERPrintableString({str:e})}if(f==""tel""){return new KJUR.asn1.DERTeletexString({str:e})}if(f==""ia5""){return new KJUR.asn1.DERIA5String({str:e})}throw""unsupported directory string type: type=""+f+"" value=""+e};this.getEncodedHex=function(){var e=new KJUR.asn1.DERSequence({array:[this.typeObj,this.valueObj]});this.TLV=e.getEncodedHex();return this.TLV};if(typeof b!=""undefined""){if(typeof b.str!=""undefined""){this.setByString(b.str)}}};YAHOO.lang.extend(KJUR.asn1.x509.AttributeTypeAndValue,KJUR.asn1.ASN1Object);KJUR.asn1.x509.SubjectPublicKeyInfo=function(d){KJUR.asn1.x509.SubjectPublicKeyInfo.superclass.constructor.call(this);var b=null;var c=null;var a=null;this.setRSAKey=function(e){if(!RSAKey.prototype.isPrototypeOf(e)){throw""argument is not RSAKey instance""}this.rsaKey=e;var g=new KJUR.asn1.DERInteger({bigint:e.n});var f=new KJUR.asn1.DERInteger({""int"":e.e});var i=new KJUR.asn1.DERSequence({array:[g,f]});var h=i.getEncodedHex();this.asn1AlgId=new KJUR.asn1.x509.AlgorithmIdentifier({name:""rsaEncryption""});this.asn1SubjPKey=new KJUR.asn1.DERBitString({hex:""00""+h})};this.setRSAPEM=function(g){if(g.match(/-----BEGIN PUBLIC KEY-----/)){var n=g;n=n.replace(/^-----[^-]+-----/,"""");n=n.replace(/-----[^-]+-----\s*$/,"""");var m=n.replace(/\s+/g,"""");var f=CryptoJS.enc.Base64.parse(m);var i=CryptoJS.enc.Hex.stringify(f);var k=_rsapem_getHexValueArrayOfChildrenFromHex(i);var h=k[1];var l=h.substr(2);var e=_rsapem_getHexValueArrayOfChildrenFromHex(l);var j=new RSAKey();j.setPublic(e[0],e[1]);this.setRSAKey(j)}else{throw""key not supported""}};this.getASN1Object=function(){if(this.asn1AlgId==null||this.asn1SubjPKey==null){throw""algId and/or subjPubKey not set""}var e=new KJUR.asn1.DERSequence({array:[this.asn1AlgId,this.asn1SubjPKey]});return e};this.getEncodedHex=function(){var e=this.getASN1Object();this.hTLV=e.getEncodedHex();return this.hTLV};this._setRSAKey=function(e){var g=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":{bigint:e.n}},{""int"":{""int"":e.e}}]});var f=g.getEncodedHex();this.asn1AlgId=new KJUR.asn1.x509.AlgorithmIdentifier({name:""rsaEncryption""});this.asn1SubjPKey=new KJUR.asn1.DERBitString({hex:""00""+f})};this._setEC=function(e){var f=new KJUR.asn1.DERObjectIdentifier({name:e.curveName});this.asn1AlgId=new KJUR.asn1.x509.AlgorithmIdentifier({name:""ecPublicKey"",asn1params:f});this.asn1SubjPKey=new KJUR.asn1.DERBitString({hex:""00""+e.pubKeyHex})};this._setDSA=function(e){var f=new KJUR.asn1.ASN1Util.newObject({seq:[{""int"":{bigint:e.p}},{""int"":{bigint:e.q}},{""int"":{bigint:e.g}}]});this.asn1AlgId=new KJUR.asn1.x509.AlgorithmIdentifier({name:""dsa"",asn1params:f});var g=new KJUR.asn1.DERInteger({bigint:e.y});this.asn1SubjPKey=new KJUR.asn1.DERBitString({hex:""00""+g.getEncodedHex()})};if(typeof d!=""undefined""){if(typeof RSAKey!=""undefined""&&d instanceof RSAKey){this._setRSAKey(d)}else{if(typeof KJUR.crypto.ECDSA!=""undefined""&&d instanceof KJUR.crypto.ECDSA){this._setEC(d)}else{if(typeof KJUR.crypto.DSA!=""undefined""&&d instanceof KJUR.crypto.DSA){this._setDSA(d)}else{if(typeof d.rsakey!=""undefined""){this.setRSAKey(d.rsakey)}else{if(typeof d.rsapem!=""undefined""){this.setRSAPEM(d.rsapem)}}}}}}};YAHOO.lang.extend(KJUR.asn1.x509.SubjectPublicKeyInfo,KJUR.asn1.ASN1Object);KJUR.asn1.x509.Time=function(c){KJUR.asn1.x509.Time.superclass.constructor.call(this);var b=null;var a=null;this.setTimeParams=function(d){this.timeParams=d};this.getEncodedHex=function(){var d=null;if(this.timeParams!=null){if(this.type==""utc""){d=new KJUR.asn1.DERUTCTime(this.timeParams)}else{d=new KJUR.asn1.DERGeneralizedTime(this.timeParams)}}else{if(this.type==""utc""){d=new KJUR.asn1.DERUTCTime()}else{d=new KJUR.asn1.DERGeneralizedTime()}}this.TLV=d.getEncodedHex();return this.TLV};this.type=""utc"";if(typeof c!=""undefined""){if(typeof c.type!=""undefined""){this.type=c.type}else{if(typeof c.str!=""undefined""){if(c.str.match(/^[0-9]{12}Z$/)){this.type=""utc""}if(c.str.match(/^[0-9]{14}Z$/)){this.type=""gen""}}}this.timeParams=c}};YAHOO.lang.extend(KJUR.asn1.x509.Time,KJUR.asn1.ASN1Object);KJUR.asn1.x509.AlgorithmIdentifier=function(e){KJUR.asn1.x509.AlgorithmIdentifier.superclass.constructor.call(this);var a=null;var d=null;var b=null;var c=false;this.getEncodedHex=function(){if(this.nameAlg==null&&this.asn1Alg==null){throw""algorithm not specified""}if(this.nameAlg!=null&&this.asn1Alg==null){this.asn1Alg=KJUR.asn1.x509.OID.name2obj(this.nameAlg)}var f=[this.asn1Alg];if(!this.paramEmpty){f.push(this.asn1Params)}var g=new KJUR.asn1.DERSequence({array:f});this.hTLV=g.getEncodedHex();return this.hTLV};if(typeof e!=""undefined""){if(typeof e.name!=""undefined""){this.nameAlg=e.name}if(typeof e.asn1params!=""undefined""){this.asn1Params=e.asn1params}if(typeof e.paramempty!=""undefined""){this.paramEmpty=e.paramempty}}if(this.asn1Params==null){this.asn1Params=new KJUR.asn1.DERNull()}};YAHOO.lang.extend(KJUR.asn1.x509.AlgorithmIdentifier,KJUR.asn1.ASN1Object);KJUR.asn1.x509.GeneralName=function(d){KJUR.asn1.x509.GeneralName.superclass.constructor.call(this);var c=null;var b=null;var a={rfc822:""81"",dns:""82"",uri:""86""};this.setByParam=function(g){var f=null;var e=null;if(typeof g.rfc822!=""undefined""){this.type=""rfc822"";e=new KJUR.asn1.DERIA5String({str:g[this.type]})}if(typeof g.dns!=""undefined""){this.type=""dns"";e=new KJUR.asn1.DERIA5String({str:g[this.type]})}if(typeof g.uri!=""undefined""){this.type=""uri"";e=new KJUR.asn1.DERIA5String({str:g[this.type]})}if(this.type==null){throw""unsupported type in params=""+g}this.asn1Obj=new KJUR.asn1.DERTaggedObject({explicit:false,tag:a[this.type],obj:e})};this.getEncodedHex=function(){return this.asn1Obj.getEncodedHex()};if(typeof d!=""undefined""){this.setByParam(d)}};YAHOO.lang.extend(KJUR.asn1.x509.GeneralName,KJUR.asn1.ASN1Object);KJUR.asn1.x509.GeneralNames=function(b){KJUR.asn1.x509.GeneralNames.superclass.constructor.call(this);var a=null;this.setByParamArray=function(e){for(var c=0;c<e.length;c++){var d=new KJUR.asn1.x509.GeneralName(e[c]);this.asn1Array.push(d)}};this.getEncodedHex=function(){var c=new KJUR.asn1.DERSequence({array:this.asn1Array});return c.getEncodedHex()};this.asn1Array=new Array();if(typeof b!=""undefined""){this.setByParamArray(b)}};YAHOO.lang.extend(KJUR.asn1.x509.GeneralNames,KJUR.asn1.ASN1Object);KJUR.asn1.x509.DistributionPointName=function(b){KJUR.asn1.x509.DistributionPointName.superclass.constructor.call(this);var e=null;var c=null;var a=null;var d=null;this.getEncodedHex=function(){if(this.type!=""full""){throw""currently type shall be 'full': ""+this.type}this.asn1Obj=new KJUR.asn1.DERTaggedObject({explicit:false,tag:this.tag,obj:this.asn1V});this.hTLV=this.asn1Obj.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(KJUR.asn1.x509.GeneralNames.prototype.isPrototypeOf(b)){this.type=""full"";this.tag=""a0"";this.asn1V=b}else{throw""This class supports GeneralNames only as argument""}}};YAHOO.lang.extend(KJUR.asn1.x509.DistributionPointName,KJUR.asn1.ASN1Object);KJUR.asn1.x509.DistributionPoint=function(b){KJUR.asn1.x509.DistributionPoint.superclass.constructor.call(this);var a=null;this.getEncodedHex=function(){var c=new KJUR.asn1.DERSequence();if(this.asn1DP!=null){var d=new KJUR.asn1.DERTaggedObject({explicit:true,tag:""a0"",obj:this.asn1DP});c.appendASN1Object(d)}this.hTLV=c.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(typeof b.dpobj!=""undefined""){this.asn1DP=b.dpobj}}};YAHOO.lang.extend(KJUR.asn1.x509.DistributionPoint,KJUR.asn1.ASN1Object);KJUR.asn1.x509.OID=new function(a){this.atype2oidList={C:""2.5.4.6"",O:""2.5.4.10"",OU:""2.5.4.11"",ST:""2.5.4.8"",L:""2.5.4.7"",CN:""2.5.4.3"",DN:""2.5.4.49"",DC:""0.9.2342.19200300.100.1.25"",};this.name2oidList={sha1:""1.3.14.3.2.26"",sha256:""2.16.840.1.101.3.4.2.1"",sha384:""2.16.840.1.101.3.4.2.2"",sha512:""2.16.840.1.101.3.4.2.3"",sha224:""2.16.840.1.101.3.4.2.4"",md5:""1.2.840.113549.2.5"",md2:""1.3.14.7.2.2.1"",ripemd160:""1.3.36.3.2.1"",MD2withRSA:""1.2.840.113549.1.1.2"",MD4withRSA:""1.2.840.113549.1.1.3"",MD5withRSA:""1.2.840.113549.1.1.4"",SHA1withRSA:""1.2.840.113549.1.1.5"",SHA224withRSA:""1.2.840.113549.1.1.14"",SHA256withRSA:""1.2.840.113549.1.1.11"",SHA384withRSA:""1.2.840.113549.1.1.12"",SHA512withRSA:""1.2.840.113549.1.1.13"",SHA1withECDSA:""1.2.840.10045.4.1"",SHA224withECDSA:""1.2.840.10045.4.3.1"",SHA256withECDSA:""1.2.840.10045.4.3.2"",SHA384withECDSA:""1.2.840.10045.4.3.3"",SHA512withECDSA:""1.2.840.10045.4.3.4"",dsa:""1.2.840.10040.4.1"",SHA1withDSA:""1.2.840.10040.4.3"",SHA224withDSA:""2.16.840.1.101.3.4.3.1"",SHA256withDSA:""2.16.840.1.101.3.4.3.2"",rsaEncryption:""1.2.840.113549.1.1.1"",subjectKeyIdentifier:""2.5.29.14"",countryName:""2.5.4.6"",organization:""2.5.4.10"",organizationalUnit:""2.5.4.11"",stateOrProvinceName:""2.5.4.8"",locality:""2.5.4.7"",commonName:""2.5.4.3"",keyUsage:""2.5.29.15"",basicConstraints:""2.5.29.19"",cRLDistributionPoints:""2.5.29.31"",certificatePolicies:""2.5.29.32"",authorityKeyIdentifier:""2.5.29.35"",extKeyUsage:""2.5.29.37"",anyExtendedKeyUsage:""2.5.29.37.0"",serverAuth:""1.3.6.1.5.5.7.3.1"",clientAuth:""1.3.6.1.5.5.7.3.2"",codeSigning:""1.3.6.1.5.5.7.3.3"",emailProtection:""1.3.6.1.5.5.7.3.4"",timeStamping:""1.3.6.1.5.5.7.3.8"",ocspSigning:""1.3.6.1.5.5.7.3.9"",ecPublicKey:""1.2.840.10045.2.1"",secp256r1:""1.2.840.10045.3.1.7"",secp256k1:""1.3.132.0.10"",secp384r1:""1.3.132.0.34"",pkcs5PBES2:""1.2.840.113549.1.5.13"",pkcs5PBKDF2:""1.2.840.113549.1.5.12"",""des-EDE3-CBC"":""1.2.840.113549.3.7"",data:""1.2.840.113549.1.7.1"",""signed-data"":""1.2.840.113549.1.7.2"",""enveloped-data"":""1.2.840.113549.1.7.3"",""digested-data"":""1.2.840.113549.1.7.5"",""encrypted-data"":""1.2.840.113549.1.7.6"",""authenticated-data"":""1.2.840.113549.1.9.16.1.2"",tstinfo:""1.2.840.113549.1.9.16.1.4"",};this.objCache={};this.name2obj=function(b){if(typeof this.objCache[b]!=""undefined""){return this.objCache[b]}if(typeof this.name2oidList[b]==""undefined""){throw""Name of ObjectIdentifier not defined: ""+b}var c=this.name2oidList[b];var d=new KJUR.asn1.DERObjectIdentifier({oid:c});this.objCache[b]=d;return d};this.atype2obj=function(b){if(typeof this.objCache[b]!=""undefined""){return this.objCache[b]}if(typeof this.atype2oidList[b]==""undefined""){throw""AttributeType name undefined: ""+b}var c=this.atype2oidList[b];var d=new KJUR.asn1.DERObjectIdentifier({oid:c});this.objCache[b]=d;return d}};KJUR.asn1.x509.OID.oid2name=function(b){var c=KJUR.asn1.x509.OID.name2oidList;for(var a in c){if(c[a]==b){return a}}return""""};KJUR.asn1.x509.X509Util=new function(){this.getPKCS8PubKeyPEMfromRSAKey=function(i){var h=null;var f=KJUR.asn1.ASN1Util.bigIntToMinTwosComplementsHex(i.n);var j=KJUR.asn1.ASN1Util.integerToByteHex(i.e);var a=new KJUR.asn1.DERInteger({hex:f});var g=new KJUR.asn1.DERInteger({hex:j});var l=new KJUR.asn1.DERSequence({array:[a,g]});var c=l.getEncodedHex();var d=new KJUR.asn1.x509.AlgorithmIdentifier({name:""rsaEncryption""});var b=new KJUR.asn1.DERBitString({hex:""00""+c});var k=new KJUR.asn1.DERSequence({array:[d,b]});var e=k.getEncodedHex();var h=KJUR.asn1.ASN1Util.getPEMStringFromHex(e,""PUBLIC KEY"");return h}};KJUR.asn1.x509.X509Util.newCertPEM=function(f){var c=KJUR.asn1.x509;var e=new c.TBSCertificate();if(f.serial!==undefined){e.setSerialNumberByParam(f.serial)}else{throw""serial number undefined.""}if(typeof f.sigalg.name==""string""){e.setSignatureAlgByParam(f.sigalg)}else{throw""unproper signature algorithm name""}if(f.issuer!==undefined){e.setIssuerByParam(f.issuer)}else{throw""issuer name undefined.""}if(f.notbefore!==undefined){e.setNotBeforeByParam(f.notbefore)}else{throw""notbefore undefined.""}if(f.notafter!==undefined){e.setNotAfterByParam(f.notafter)}else{throw""notafter undefined.""}if(f.subject!==undefined){e.setSubjectByParam(f.subject)}else{throw""subject name undefined.""}if(f.sbjpubkey!==undefined){e.setSubjectPublicKeyByGetKey(f.sbjpubkey)}else{throw""subject public key undefined.""}if(f.ext!==undefined&&f.ext.length!==undefined){for(var b=0;b<f.ext.length;b++){for(key in f.ext[b]){e.appendExtensionByName(key,f.ext[b][key])}}}if(f.cakey===undefined&&f.sighex===undefined){throw""param cakey and sighex undefined.""}var d=null;var a=null;if(f.cakey){d=KEYUTIL.getKey.apply(null,f.cakey);a=new c.Certificate({tbscertobj:e,prvkeyobj:d});a.sign()}if(f.sighex){a=new c.Certificate({tbscertobj:e});a.setSignatureHex(f.sighex)}return a.getPEMString()}; /*! asn1cms-1.0.2.js (c) 2013-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.asn1==""undefined""||!KJUR.asn1){KJUR.asn1={}}if(typeof KJUR.asn1.cms==""undefined""||!KJUR.asn1.cms){KJUR.asn1.cms={}}KJUR.asn1.cms.Attribute=function(b){KJUR.asn1.cms.Attribute.superclass.constructor.call(this);var a=[];this.getEncodedHex=function(){var f,e,c;f=new KJUR.asn1.DERObjectIdentifier({oid:this.attrTypeOid});e=new KJUR.asn1.DERSet({array:this.valueList});try{e.getEncodedHex()}catch(d){throw""fail valueSet.getEncodedHex in Attribute(1)/""+d}c=new KJUR.asn1.DERSequence({array:[f,e]});try{this.hTLV=c.getEncodedHex()}catch(d){throw""failed seq.getEncodedHex in Attribute(2)/""+d}return this.hTLV}};YAHOO.lang.extend(KJUR.asn1.cms.Attribute,KJUR.asn1.ASN1Object);KJUR.asn1.cms.ContentType=function(b){KJUR.asn1.cms.ContentType.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.3"";var a=null;if(typeof b!=""undefined""){var a=new KJUR.asn1.DERObjectIdentifier(b);this.valueList=[a]}};YAHOO.lang.extend(KJUR.asn1.cms.ContentType,KJUR.asn1.cms.Attribute);KJUR.asn1.cms.MessageDigest=function(e){KJUR.asn1.cms.MessageDigest.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.4"";if(typeof e!=""undefined""){if(e.eciObj instanceof KJUR.asn1.cms.EncapsulatedContentInfo&&typeof e.hashAlg==""string""){var b=e.eciObj.eContentValueHex;var a=e.hashAlg;var c=KJUR.crypto.Util.hashHex(b,a);var d=new KJUR.asn1.DEROctetString({hex:c});d.getEncodedHex();this.valueList=[d]}else{var d=new KJUR.asn1.DEROctetString(e);d.getEncodedHex();this.valueList=[d]}}};YAHOO.lang.extend(KJUR.asn1.cms.MessageDigest,KJUR.asn1.cms.Attribute);KJUR.asn1.cms.SigningTime=function(c){KJUR.asn1.cms.SigningTime.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.5"";if(typeof c!=""undefined""){var a=new KJUR.asn1.x509.Time(c);try{a.getEncodedHex()}catch(b){throw""SigningTime.getEncodedHex() failed/""+b}this.valueList=[a]}};YAHOO.lang.extend(KJUR.asn1.cms.SigningTime,KJUR.asn1.cms.Attribute);KJUR.asn1.cms.SigningCertificate=function(d){KJUR.asn1.cms.SigningCertificate.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.16.2.12"";var a=KJUR.asn1;var c=KJUR.asn1.cms;var b=KJUR.crypto;this.setCerts=function(l){var j=[];for(var h=0;h<l.length;h++){var f=KEYUTIL.getHexFromPEM(l[h]);var e=b.Util.hashHex(f,""sha1"");var m=new a.DEROctetString({hex:e});m.getEncodedHex();var k=new c.IssuerAndSerialNumber({cert:l[h]});k.getEncodedHex();var n=new a.DERSequence({array:[m,k]});n.getEncodedHex();j.push(n)}var g=new a.DERSequence({array:j});g.getEncodedHex();this.valueList=[g]};if(typeof d!=""undefined""){if(typeof d.array==""object""){this.setCerts(d.array)}}};YAHOO.lang.extend(KJUR.asn1.cms.SigningCertificate,KJUR.asn1.cms.Attribute);KJUR.asn1.cms.SigningCertificateV2=function(e){KJUR.asn1.cms.SigningCertificateV2.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.16.2.47"";var b=KJUR.asn1;var f=KJUR.asn1.x509;var d=KJUR.asn1.cms;var c=KJUR.crypto;this.setCerts=function(p,h){var n=[];for(var l=0;l<p.length;l++){var j=KEYUTIL.getHexFromPEM(p[l]);var r=[];if(h!=""sha256""){r.push(new f.AlgorithmIdentifier({name:h}))}var g=c.Util.hashHex(j,h);var q=new b.DEROctetString({hex:g});q.getEncodedHex();r.push(q);var m=new d.IssuerAndSerialNumber({cert:p[l]});m.getEncodedHex();r.push(m);var o=new b.DERSequence({array:r});o.getEncodedHex();n.push(o)}var k=new b.DERSequence({array:n});k.getEncodedHex();this.valueList=[k]};if(typeof e!=""undefined""){if(typeof e.array==""object""){var a=""sha256"";if(typeof e.hashAlg==""string""){a=e.hashAlg}this.setCerts(e.array,a)}}};YAHOO.lang.extend(KJUR.asn1.cms.SigningCertificateV2,KJUR.asn1.cms.Attribute);KJUR.asn1.cms.IssuerAndSerialNumber=function(c){KJUR.asn1.cms.IssuerAndSerialNumber.superclass.constructor.call(this);var e=null;var b=null;var a=KJUR.asn1;var d=a.x509;this.setByCertPEM=function(i){var g=KEYUTIL.getHexFromPEM(i);var f=new X509();f.hex=g;var j=f.getIssuerHex();this.dIssuer=new d.X500Name();this.dIssuer.hTLV=j;var h=f.getSerialNumberHex();this.dSerial=new a.DERInteger({hex:h})};this.getEncodedHex=function(){var f=new KJUR.asn1.DERSequence({array:[this.dIssuer,this.dSerial]});this.hTLV=f.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(typeof c==""string""&&c.indexOf(""-----BEGIN "")!=-1){this.setByCertPEM(c)}if(c.issuer&&c.serial){if(c.issuer instanceof KJUR.asn1.x509.X500Name){this.dIssuer=c.issuer}else{this.dIssuer=new KJUR.asn1.x509.X500Name(c.issuer)}if(c.serial instanceof KJUR.asn1.DERInteger){this.dSerial=c.serial}else{this.dSerial=new KJUR.asn1.DERInteger(c.serial)}}if(typeof c.cert==""string""){this.setByCertPEM(c.cert)}}};YAHOO.lang.extend(KJUR.asn1.cms.IssuerAndSerialNumber,KJUR.asn1.ASN1Object);KJUR.asn1.cms.AttributeList=function(a){KJUR.asn1.cms.AttributeList.superclass.constructor.call(this);this.list=new Array();this.sortFlag=true;this.add=function(b){if(b instanceof KJUR.asn1.cms.Attribute){this.list.push(b)}};this.length=function(){return this.list.length};this.clear=function(){this.list=new Array();this.hTLV=null;this.hV=null};this.getEncodedHex=function(){if(typeof this.hTLV==""string""){return this.hTLV}var b=new KJUR.asn1.DERSet({array:this.list,sortflag:this.sortFlag});this.hTLV=b.getEncodedHex();return this.hTLV};if(typeof a!=""undefined""){if(typeof a.sortflag!=""undefined""&&a.sortflag==false){this.sortFlag=false}}};YAHOO.lang.extend(KJUR.asn1.cms.AttributeList,KJUR.asn1.ASN1Object);KJUR.asn1.cms.SignerInfo=function(c){KJUR.asn1.cms.SignerInfo.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.cms;var d=KJUR.asn1.x509;this.dCMSVersion=new a.DERInteger({""int"":1});this.dSignerIdentifier=null;this.dDigestAlgorithm=null;this.dSignedAttrs=new b.AttributeList();this.dSigAlg=null;this.dSig=null;this.dUnsignedAttrs=new b.AttributeList();this.setSignerIdentifier=function(f){if(typeof f==""string""&&f.indexOf(""CERTIFICATE"")!=-1&&f.indexOf(""BEGIN"")!=-1&&f.indexOf(""END"")!=-1){var e=f;this.dSignerIdentifier=new b.IssuerAndSerialNumber({cert:f})}};this.setForContentAndHash=function(e){if(typeof e!=""undefined""){if(e.eciObj instanceof KJUR.asn1.cms.EncapsulatedContentInfo){this.dSignedAttrs.add(new b.ContentType({oid:""1.2.840.113549.1.7.1""}));this.dSignedAttrs.add(new b.MessageDigest({eciObj:e.eciObj,hashAlg:e.hashAlg}))}if(typeof e.sdObj!=""undefined""&&e.sdObj instanceof KJUR.asn1.cms.SignedData){if(e.sdObj.digestAlgNameList.join("":"").indexOf(e.hashAlg)==-1){e.sdObj.digestAlgNameList.push(e.hashAlg)}}if(typeof e.hashAlg==""string""){this.dDigestAlgorithm=new d.AlgorithmIdentifier({name:e.hashAlg})}}};this.sign=function(j,f){this.dSigAlg=new d.AlgorithmIdentifier({name:f});var g=this.dSignedAttrs.getEncodedHex();var e=KEYUTIL.getKey(j);var i=new KJUR.crypto.Signature({alg:f});i.init(e);i.updateHex(g);var h=i.sign();this.dSig=new a.DEROctetString({hex:h})};this.addUnsigned=function(e){this.hTLV=null;this.dUnsignedAttrs.hTLV=null;this.dUnsignedAttrs.add(e)};this.getEncodedHex=function(){if(this.dSignedAttrs instanceof KJUR.asn1.cms.AttributeList&&this.dSignedAttrs.length()==0){throw""SignedAttrs length = 0 (empty)""}var e=new a.DERTaggedObject({obj:this.dSignedAttrs,tag:""a0"",explicit:false});var h=null;if(this.dUnsignedAttrs.length()>0){h=new a.DERTaggedObject({obj:this.dUnsignedAttrs,tag:""a1"",explicit:false})}var g=[this.dCMSVersion,this.dSignerIdentifier,this.dDigestAlgorithm,e,this.dSigAlg,this.dSig,];if(h!=null){g.push(h)}var f=new a.DERSequence({array:g});this.hTLV=f.getEncodedHex();return this.hTLV}};YAHOO.lang.extend(KJUR.asn1.cms.SignerInfo,KJUR.asn1.ASN1Object);KJUR.asn1.cms.EncapsulatedContentInfo=function(c){KJUR.asn1.cms.EncapsulatedContentInfo.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.cms;var d=KJUR.asn1.x509;this.dEContentType=new a.DERObjectIdentifier({name:""data""});this.dEContent=null;this.isDetached=false;this.eContentValueHex=null;this.setContentType=function(e){if(e.match(/^[0-2][.][0-9.]+$/)){this.dEContentType=new a.DERObjectIdentifier({oid:e})}else{this.dEContentType=new a.DERObjectIdentifier({name:e})}};this.setContentValue=function(e){if(typeof e!=""undefined""){if(typeof e.hex==""string""){this.eContentValueHex=e.hex}else{if(typeof e.str==""string""){this.eContentValueHex=utf8tohex(e.str)}}}};this.setContentValueHex=function(e){this.eContentValueHex=e};this.setContentValueStr=function(e){this.eContentValueHex=utf8tohex(e)};this.getEncodedHex=function(){if(typeof this.eContentValueHex!=""string""){throw""eContentValue not yet set""}var g=new a.DEROctetString({hex:this.eContentValueHex});this.dEContent=new a.DERTaggedObject({obj:g,tag:""a0"",explicit:true});var e=[this.dEContentType];if(!this.isDetached){e.push(this.dEContent)}var f=new a.DERSequence({array:e});this.hTLV=f.getEncodedHex();return this.hTLV}};YAHOO.lang.extend(KJUR.asn1.cms.EncapsulatedContentInfo,KJUR.asn1.ASN1Object);KJUR.asn1.cms.ContentInfo=function(c){KJUR.asn1.cms.ContentInfo.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.cms;var d=KJUR.asn1.x509;this.dContentType=null;this.dContent=null;this.setContentType=function(e){if(typeof e==""string""){this.dContentType=d.OID.name2obj(e)}};this.getEncodedHex=function(){var f=new a.DERTaggedObject({obj:this.dContent,tag:""a0"",explicit:true});var e=new a.DERSequence({array:[this.dContentType,f]});this.hTLV=e.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(c.type){this.setContentType(c.type)}if(c.obj&&c.obj instanceof a.ASN1Object){this.dContent=c.obj}}};YAHOO.lang.extend(KJUR.asn1.cms.ContentInfo,KJUR.asn1.ASN1Object);KJUR.asn1.cms.SignedData=function(c){KJUR.asn1.cms.SignedData.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.cms;var d=KJUR.asn1.x509;this.dCMSVersion=new a.DERInteger({""int"":1});this.dDigestAlgs=null;this.digestAlgNameList=[];this.dEncapContentInfo=new b.EncapsulatedContentInfo();this.dCerts=null;this.certificateList=[];this.crlList=[];this.signerInfoList=[new b.SignerInfo()];this.addCertificatesByPEM=function(e){var f=KEYUTIL.getHexFromPEM(e);var g=new a.ASN1Object();g.hTLV=f;this.certificateList.push(g)};this.getEncodedHex=function(){if(typeof this.hTLV==""string""){return this.hTLV}if(this.dDigestAlgs==null){var k=[];for(var j=0;j<this.digestAlgNameList.length;j++){var h=this.digestAlgNameList[j];var m=new d.AlgorithmIdentifier({name:h});k.push(m)}this.dDigestAlgs=new a.DERSet({array:k})}var e=[this.dCMSVersion,this.dDigestAlgs,this.dEncapContentInfo];if(this.dCerts==null){if(this.certificateList.length>0){var l=new a.DERSet({array:this.certificateList});this.dCerts=new a.DERTaggedObject({obj:l,tag:""a0"",explicit:false})}}if(this.dCerts!=null){e.push(this.dCerts)}var g=new a.DERSet({array:this.signerInfoList});e.push(g);var f=new a.DERSequence({array:e});this.hTLV=f.getEncodedHex();return this.hTLV};this.getContentInfo=function(){this.getEncodedHex();var e=new b.ContentInfo({type:""signed-data"",obj:this});return e};this.getContentInfoEncodedHex=function(){var e=this.getContentInfo();var f=e.getEncodedHex();return f};this.getPEM=function(){var e=this.getContentInfoEncodedHex();var f=a.ASN1Util.getPEMStringFromHex(e,""CMS"");return f}};YAHOO.lang.extend(KJUR.asn1.cms.SignedData,KJUR.asn1.ASN1Object);KJUR.asn1.cms.CMSUtil=new function(){};KJUR.asn1.cms.CMSUtil.newSignedData=function(a){var h=KJUR.asn1.cms;var g=KJUR.asn1.cades;var f=new h.SignedData();f.dEncapContentInfo.setContentValue(a.content);if(typeof a.certs==""object""){for(var b=0;b<a.certs.length;b++){f.addCertificatesByPEM(a.certs[b])}}f.signerInfoList=[];for(var b=0;b<a.signerInfos.length;b++){var d=a.signerInfos[b];var c=new h.SignerInfo();c.setSignerIdentifier(d.signerCert);c.setForContentAndHash({sdObj:f,eciObj:f.dEncapContentInfo,hashAlg:d.hashAlg});for(attrName in d.sAttr){var j=d.sAttr[attrName];if(attrName==""SigningTime""){var e=new h.SigningTime(j);c.dSignedAttrs.add(e)}if(attrName==""SigningCertificate""){var e=new h.SigningCertificate(j);c.dSignedAttrs.add(e)}if(attrName==""SigningCertificateV2""){var e=new h.SigningCertificateV2(j);c.dSignedAttrs.add(e)}if(attrName==""SignaturePolicyIdentifier""){var e=new g.SignaturePolicyIdentifier(j);c.dSignedAttrs.add(e)}}c.sign(d.signerPrvKey,d.sigAlg);f.signerInfoList.push(c)}return f}; /*! asn1tsp-1.0.1.js (c) 2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.asn1==""undefined""||!KJUR.asn1){KJUR.asn1={}}if(typeof KJUR.asn1.tsp==""undefined""||!KJUR.asn1.tsp){KJUR.asn1.tsp={}}KJUR.asn1.tsp.Accuracy=function(b){KJUR.asn1.tsp.Accuracy.superclass.constructor.call(this);var a=KJUR.asn1;this.seconds=null;this.millis=null;this.micros=null;this.getEncodedHex=function(){var e=null;var g=null;var i=null;var c=[];if(this.seconds!=null){e=new a.DERInteger({""int"":this.seconds});c.push(e)}if(this.millis!=null){var h=new a.DERInteger({""int"":this.millis});g=new a.DERTaggedObject({obj:h,tag:""80"",explicit:false});c.push(g)}if(this.micros!=null){var f=new a.DERInteger({""int"":this.micros});i=new a.DERTaggedObject({obj:f,tag:""81"",explicit:false});c.push(i)}var d=new a.DERSequence({array:c});this.hTLV=d.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(typeof b.seconds==""number""){this.seconds=b.seconds}if(typeof b.millis==""number""){this.millis=b.millis}if(typeof b.micros==""number""){this.micros=b.micros}}};YAHOO.lang.extend(KJUR.asn1.tsp.Accuracy,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.MessageImprint=function(b){KJUR.asn1.tsp.MessageImprint.superclass.constructor.call(this);var a=KJUR.asn1;var c=KJUR.asn1.x509;this.dHashAlg=null;this.dHashValue=null;this.getEncodedHex=function(){if(typeof this.hTLV==""string""){return this.hTLV}var d=new a.DERSequence({array:[this.dHashAlg,this.dHashValue]});return d.getEncodedHex()};if(typeof b!=""undefined""){if(typeof b.hashAlg==""string""){this.dHashAlg=new c.AlgorithmIdentifier({name:b.hashAlg})}if(typeof b.hashValue==""string""){this.dHashValue=new a.DEROctetString({hex:b.hashValue})}}};YAHOO.lang.extend(KJUR.asn1.tsp.MessageImprint,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.TimeStampReq=function(c){KJUR.asn1.tsp.TimeStampReq.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.tsp;this.dVersion=new a.DERInteger({""int"":1});this.dMessageImprint=null;this.dPolicy=null;this.dNonce=null;this.certReq=true;this.setMessageImprint=function(d){if(d instanceof KJUR.asn1.tsp.MessageImprint){this.dMessageImprint=d;return}if(typeof d==""object""){this.dMessageImprint=new b.MessageImprint(d)}};this.getEncodedHex=function(){if(this.dMessageImprint==null){throw""messageImprint shall be specified""}var d=[this.dVersion,this.dMessageImprint];if(this.dPolicy!=null){d.push(this.dPolicy)}if(this.dNonce!=null){d.push(this.dNonce)}if(this.certReq){d.push(new a.DERBoolean())}var e=new a.DERSequence({array:d});this.hTLV=e.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(typeof c.mi==""object""){this.setMessageImprint(c.mi)}if(typeof c.policy==""object""){this.dPolicy=new a.DERObjectIdentifier(c.policy)}if(typeof c.nonce==""object""){this.dNonce=new a.DERInteger(c.nonce)}if(typeof c.certreq==""boolean""){this.certReq=c.certreq}}};YAHOO.lang.extend(KJUR.asn1.tsp.TimeStampReq,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.TSTInfo=function(c){KJUR.asn1.tsp.TSTInfo.superclass.constructor.call(this);var a=KJUR.asn1;var d=KJUR.asn1.x509;var b=KJUR.asn1.tsp;this.dVersion=new a.DERInteger({""int"":1});this.dPolicy=null;this.dMessageImprint=null;this.dSerialNumber=null;this.dGenTime=null;this.dAccuracy=null;this.dOrdering=null;this.dNonce=null;this.dTsa=null;this.getEncodedHex=function(){var e=[this.dVersion];if(this.dPolicy==null){throw""policy shall be specified.""}e.push(this.dPolicy);if(this.dMessageImprint==null){throw""messageImprint shall be specified.""}e.push(this.dMessageImprint);if(this.dSerialNumber==null){throw""serialNumber shall be specified.""}e.push(this.dSerialNumber);if(this.dGenTime==null){throw""genTime shall be specified.""}e.push(this.dGenTime);if(this.dAccuracy!=null){e.push(this.dAccuracy)}if(this.dOrdering!=null){e.push(this.dOrdering)}if(this.dNonce!=null){e.push(this.dNonce)}if(this.dTsa!=null){e.push(this.dTsa)}var f=new a.DERSequence({array:e});this.hTLV=f.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(typeof c.policy==""string""){if(!c.policy.match(/^[0-9.]+$/)){throw""policy shall be oid like 0.1.4.134""}this.dPolicy=new a.DERObjectIdentifier({oid:c.policy})}if(typeof c.messageImprint!=""undefined""){this.dMessageImprint=new b.MessageImprint(c.messageImprint)}if(typeof c.serialNumber!=""undefined""){this.dSerialNumber=new a.DERInteger(c.serialNumber)}if(typeof c.genTime!=""undefined""){this.dGenTime=new a.DERGeneralizedTime(c.genTime)}if(typeof c.accuracy!=""undefind""){this.dAccuracy=new b.Accuracy(c.accuracy)}if(typeof c.ordering!=""undefined""&&c.ordering==true){this.dOrdering=new a.DERBoolean()}if(typeof c.nonce!=""undefined""){this.dNonce=new a.DERInteger(c.nonce)}if(typeof c.tsa!=""undefined""){this.dTsa=new d.X500Name(c.tsa)}}};YAHOO.lang.extend(KJUR.asn1.tsp.TSTInfo,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.TimeStampResp=function(c){KJUR.asn1.tsp.TimeStampResp.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.tsp;this.dStatus=null;this.dTST=null;this.getEncodedHex=function(){if(this.dStatus==null){throw""status shall be specified""}var d=[this.dStatus];if(this.dTST!=null){d.push(this.dTST)}var e=new a.DERSequence({array:d});this.hTLV=e.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(typeof c.status==""object""){this.dStatus=new b.PKIStatusInfo(c.status)}if(typeof c.tst!=""undefined""&&c.tst instanceof KJUR.asn1.ASN1Object){this.dTST=c.tst.getContentInfo()}}};YAHOO.lang.extend(KJUR.asn1.tsp.TimeStampResp,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.PKIStatusInfo=function(c){KJUR.asn1.tsp.PKIStatusInfo.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.tsp;this.dStatus=null;this.dStatusString=null;this.dFailureInfo=null;this.getEncodedHex=function(){if(this.dStatus==null){throw""status shall be specified""}var d=[this.dStatus];if(this.dStatusString!=null){d.push(this.dStatusString)}if(this.dFailureInfo!=null){d.push(this.dFailureInfo)}var e=new a.DERSequence({array:d});this.hTLV=e.getEncodedHex();return this.hTLV};if(typeof c!=""undefined""){if(typeof c.status==""object""){this.dStatus=new b.PKIStatus(c.status)}if(typeof c.statstr==""object""){this.dStatusString=new b.PKIFreeText({array:c.statstr})}if(typeof c.failinfo==""object""){this.dFailureInfo=new b.PKIFailureInfo(c.failinfo)}}};YAHOO.lang.extend(KJUR.asn1.tsp.PKIStatusInfo,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.PKIStatus=function(e){KJUR.asn1.tsp.PKIStatus.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.tsp;var d=null;this.getEncodedHex=function(){this.hTLV=this.dStatus.getEncodedHex();return this.hTLV};if(typeof e!=""undefined""){if(typeof e.name!=""undefined""){var c=b.PKIStatus.valueList;if(typeof c[e.name]==""undefined""){throw""name undefined: ""+e.name}this.dStatus=new a.DERInteger({""int"":c[e.name]})}else{this.dStatus=new a.DERInteger(e)}}};YAHOO.lang.extend(KJUR.asn1.tsp.PKIStatus,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.PKIStatus.valueList={granted:0,grantedWithMods:1,rejection:2,waiting:3,revocationWarning:4,revocationNotification:5};KJUR.asn1.tsp.PKIFreeText=function(b){KJUR.asn1.tsp.PKIFreeText.superclass.constructor.call(this);var a=KJUR.asn1;this.textList=[];this.getEncodedHex=function(){var c=[];for(var e=0;e<this.textList.length;e++){c.push(new a.DERUTF8String({str:this.textList[e]}))}var d=new a.DERSequence({array:c});this.hTLV=d.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(typeof b.array==""object""){this.textList=b.array}}};YAHOO.lang.extend(KJUR.asn1.tsp.PKIFreeText,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.PKIFailureInfo=function(d){KJUR.asn1.tsp.PKIFailureInfo.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.tsp;this.value=null;this.getEncodedHex=function(){if(this.value==null){throw""value shall be specified""}var e=new Number(this.value).toString(2);var f=new a.DERBitString();f.setByBinaryString(e);this.hTLV=f.getEncodedHex();return this.hTLV};if(typeof d!=""undefined""){if(typeof d.name==""string""){var c=b.PKIFailureInfo.valueList;if(typeof c[d.name]==""undefined""){throw""name undefined: ""+d.name}this.value=c[d.name]}else{if(typeof d[""int""]==""number""){this.value=d[""int""]}}}};YAHOO.lang.extend(KJUR.asn1.tsp.PKIFailureInfo,KJUR.asn1.ASN1Object);KJUR.asn1.tsp.PKIFailureInfo.valueList={badAlg:0,badRequest:2,badDataFormat:5,timeNotAvailable:14,unacceptedPolicy:15,unacceptedExtension:16,addInfoNotAvailable:17,systemFailure:25};KJUR.asn1.tsp.AbstractTSAAdapter=function(a){this.getTSTHex=function(c,b){throw""not implemented yet""}};KJUR.asn1.tsp.SimpleTSAAdapter=function(a){KJUR.asn1.tsp.SimpleTSAAdapter.superclass.constructor.call(this);this.params=null;this.serial=0;this.getTSTHex=function(c,b){var e=KJUR.crypto.Util.hashHex(c,b);this.params.tstInfo.messageImprint={hashAlg:b,hashValue:e};this.params.tstInfo.serialNumber={""int"":this.serial++};var d=Math.floor(Math.random()*1000000000);this.params.tstInfo.nonce={""int"":d};var f=KJUR.asn1.tsp.TSPUtil.newTimeStampToken(this.params);return f.getContentInfoEncodedHex()};if(typeof a!=""undefined""){this.params=a}};YAHOO.lang.extend(KJUR.asn1.tsp.SimpleTSAAdapter,KJUR.asn1.tsp.AbstractTSAAdapter);KJUR.asn1.tsp.FixedTSAAdapter=function(a){KJUR.asn1.tsp.FixedTSAAdapter.superclass.constructor.call(this);this.params=null;this.getTSTHex=function(c,b){var d=KJUR.crypto.Util.hashHex(c,b);this.params.tstInfo.messageImprint={hashAlg:b,hashValue:d};var e=KJUR.asn1.tsp.TSPUtil.newTimeStampToken(this.params);return e.getContentInfoEncodedHex()};if(typeof a!=""undefined""){this.params=a}};YAHOO.lang.extend(KJUR.asn1.tsp.FixedTSAAdapter,KJUR.asn1.tsp.AbstractTSAAdapter);KJUR.asn1.tsp.TSPUtil=new function(){};KJUR.asn1.tsp.TSPUtil.newTimeStampToken=function(b){var j=KJUR.asn1.cms;var a=KJUR.asn1.tsp;var g=new j.SignedData();var e=new a.TSTInfo(b.tstInfo);var f=e.getEncodedHex();g.dEncapContentInfo.setContentValue({hex:f});g.dEncapContentInfo.setContentType(""tstinfo"");if(typeof b.certs==""object""){for(var c=0;c<b.certs.length;c++){g.addCertificatesByPEM(b.certs[c])}}var d=g.signerInfoList[0];d.setSignerIdentifier(b.signerCert);d.setForContentAndHash({sdObj:g,eciObj:g.dEncapContentInfo,hashAlg:b.hashAlg});var h=new j.SigningCertificate({array:[b.signerCert]});d.dSignedAttrs.add(h);d.sign(b.signerPrvKey,b.sigAlg);return g};KJUR.asn1.tsp.TSPUtil.parseTimeStampReq=function(d){var f={};f.certreq=false;var h=ASN1HEX.getPosArrayOfChildren_AtObj(d,0);if(h.length<2){throw""TimeStampReq must have at least 2 items""}var c=ASN1HEX.getHexOfTLV_AtObj(d,h[1]);f.mi=KJUR.asn1.tsp.TSPUtil.parseMessageImprint(c);for(var e=2;e<h.length;e++){var b=h[e];var a=d.substr(b,2);if(a==""06""){var g=ASN1HEX.getHexOfV_AtObj(d,b);f.policy=ASN1HEX.hextooidstr(g)}if(a==""02""){f.nonce=ASN1HEX.getHexOfV_AtObj(d,b)}if(a==""01""){f.certreq=true}}return f};KJUR.asn1.tsp.TSPUtil.parseMessageImprint=function(c){var h={};if(c.substr(0,2)!=""30""){throw""head of messageImprint hex shall be '30'""}var a=ASN1HEX.getPosArrayOfChildren_AtObj(c,0);var i=ASN1HEX.getDecendantIndexByNthList(c,0,[0,0]);var d=ASN1HEX.getHexOfV_AtObj(c,i);var e=ASN1HEX.hextooidstr(d);var g=KJUR.asn1.x509.OID.oid2name(e);if(g==""""){throw""hashAlg name undefined: ""+e}var b=g;var f=ASN1HEX.getDecendantIndexByNthList(c,0,[1]);h.hashAlg=b;h.hashValue=ASN1HEX.getHexOfV_AtObj(c,f);return h}; /*! asn1cades-1.0.0.js (c) 2013-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.asn1==""undefined""||!KJUR.asn1){KJUR.asn1={}}if(typeof KJUR.asn1.cades==""undefined""||!KJUR.asn1.cades){KJUR.asn1.cades={}}KJUR.asn1.cades.SignaturePolicyIdentifier=function(e){KJUR.asn1.cades.SignaturePolicyIdentifier.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.16.2.15"";var b=KJUR.asn1;var d=KJUR.asn1.cades;if(typeof e!=""undefined""){if(typeof e.oid==""string""&&typeof e.hash==""object""){var f=new b.DERObjectIdentifier({oid:e.oid});var a=new d.OtherHashAlgAndValue(e.hash);var c=new b.DERSequence({array:[f,a]});this.valueList=[c]}}};YAHOO.lang.extend(KJUR.asn1.cades.SignaturePolicyIdentifier,KJUR.asn1.cms.Attribute);KJUR.asn1.cades.OtherHashAlgAndValue=function(b){KJUR.asn1.cades.OtherHashAlgAndValue.superclass.constructor.call(this);var a=KJUR.asn1;var c=KJUR.asn1.x509;this.dAlg=null;this.dHash=null;this.getEncodedHex=function(){var d=new a.DERSequence({array:[this.dAlg,this.dHash]});this.hTLV=d.getEncodedHex();return this.hTLV};if(typeof b!=""undefined""){if(typeof b.alg==""string""&&typeof b.hash==""string""){this.dAlg=new c.AlgorithmIdentifier({name:b.alg});this.dHash=new a.DEROctetString({hex:b.hash})}}};YAHOO.lang.extend(KJUR.asn1.cades.OtherHashAlgAndValue,KJUR.asn1.ASN1Object);KJUR.asn1.cades.SignatureTimeStamp=function(c){KJUR.asn1.cades.SignatureTimeStamp.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.16.2.14"";this.tstHex=null;var a=KJUR.asn1;if(typeof c!=""undefined""){if(typeof c.res!=""undefined""){if(typeof c.res==""string""&&c.res.match(/^[0-9A-Fa-f]+$/)){}else{if(c.res instanceof KJUR.asn1.ASN1Object){}else{throw""res param shall be ASN1Object or hex string""}}}if(typeof c.tst!=""undefined""){if(typeof c.tst==""string""&&c.tst.match(/^[0-9A-Fa-f]+$/)){var b=new a.ASN1Object();this.tstHex=c.tst;b.hTLV=this.tstHex;b.getEncodedHex();this.valueList=[b]}else{if(c.tst instanceof KJUR.asn1.ASN1Object){}else{throw""tst param shall be ASN1Object or hex string""}}}}};YAHOO.lang.extend(KJUR.asn1.cades.SignatureTimeStamp,KJUR.asn1.cms.Attribute);KJUR.asn1.cades.CompleteCertificateRefs=function(c){KJUR.asn1.cades.CompleteCertificateRefs.superclass.constructor.call(this);this.attrTypeOid=""1.2.840.113549.1.9.16.2.21"";var a=KJUR.asn1;var b=KJUR.asn1.cades;this.setByArray=function(d){this.valueList=[];for(var e=0;e<d.length;e++){var f=new b.OtherCertID(d[e]);this.valueList.push(f)}};if(typeof c!=""undefined""){if(typeof c==""object""&&typeof c.length==""number""){this.setByArray(c)}}};YAHOO.lang.extend(KJUR.asn1.cades.CompleteCertificateRefs,KJUR.asn1.cms.Attribute);KJUR.asn1.cades.OtherCertID=function(d){KJUR.asn1.cades.OtherCertID.superclass.constructor.call(this);var a=KJUR.asn1;var c=KJUR.asn1.cms;var b=KJUR.asn1.cades;this.hasIssuerSerial=true;this.dOtherCertHash=null;this.dIssuerSerial=null;this.setByCertPEM=function(e){this.dOtherCertHash=new b.OtherHash(e);if(this.hasIssuerSerial){this.dIssuerSerial=new c.IssuerAndSerialNumber(e)}};this.getEncodedHex=function(){if(this.hTLV!=null){return this.hTLV}if(this.dOtherCertHash==null){throw""otherCertHash not set""}var e=[this.dOtherCertHash];if(this.dIssuerSerial!=null){e.push(this.dIssuerSerial)}var f=new a.DERSequence({array:e});this.hTLV=f.getEncodedHex();return this.hTLV};if(typeof d!=""undefined""){if(typeof d==""string""&&d.indexOf(""-----BEGIN "")!=-1){this.setByCertPEM(d)}if(typeof d==""object""){if(d.hasis===false){this.hasIssuerSerial=false}if(typeof d.cert==""string""){this.setByCertPEM(d.cert)}}}};YAHOO.lang.extend(KJUR.asn1.cades.OtherCertID,KJUR.asn1.ASN1Object);KJUR.asn1.cades.OtherHash=function(c){KJUR.asn1.cades.OtherHash.superclass.constructor.call(this);var a=KJUR.asn1;var b=KJUR.asn1.cades;this.alg=""sha256"";this.dOtherHash=null;this.setByCertPEM=function(d){if(d.indexOf(""-----BEGIN "")==-1){throw""certPEM not to seem PEM format""}var e=X509.pemToHex(d);var f=KJUR.crypto.Util.hashHex(e,this.alg);this.dOtherHash=new b.OtherHashAlgAndValue({alg:this.alg,hash:f})};this.getEncodedHex=function(){if(this.dOtherHash==null){throw""OtherHash not set""}return this.dOtherHash.getEncodedHex()};if(typeof c!=""undefined""){if(typeof c==""string""){if(c.indexOf(""-----BEGIN "")!=-1){this.setByCertPEM(c)}else{if(c.match(/^[0-9A-Fa-f]+$/)){this.dOtherHash=new a.DEROctetString({hex:c})}else{throw""unsupported string value for params""}}}else{if(typeof c==""object""){if(typeof c.cert==""string""){if(typeof c.alg==""string""){this.alg=c.alg}this.setByCertPEM(c.cert)}else{this.dOtherHash=new b.OtherHashAlgAndValue(c)}}}}};YAHOO.lang.extend(KJUR.asn1.cades.OtherHash,KJUR.asn1.ASN1Object);KJUR.asn1.cades.CAdESUtil=new function(){};KJUR.asn1.cades.CAdESUtil.addSigTS=function(c,b,a){};KJUR.asn1.cades.CAdESUtil.parseSignedDataForAddingUnsigned=function(d){var q=KJUR.asn1;var p=KJUR.asn1.cms;var c=KJUR.asn1.cades.CAdESUtil;var a={};if(ASN1HEX.getDecendantHexTLVByNthList(d,0,[0])!=""06092a864886f70d010702""){throw""hex is not CMS SignedData""}var s=ASN1HEX.getDecendantIndexByNthList(d,0,[1,0]);var b=ASN1HEX.getPosArrayOfChildren_AtObj(d,s);if(b.length<4){throw""num of SignedData elem shall be 4 at least""}var f=b.shift();a.version=ASN1HEX.getHexOfTLV_AtObj(d,f);var l=b.shift();a.algs=ASN1HEX.getHexOfTLV_AtObj(d,l);var m=b.shift();a.encapcontent=ASN1HEX.getHexOfTLV_AtObj(d,m);a.certs=null;a.revs=null;a.si=[];var n=b.shift();if(d.substr(n,2)==""a0""){a.certs=ASN1HEX.getHexOfTLV_AtObj(d,n);n=b.shift()}if(d.substr(n,2)==""a1""){a.revs=ASN1HEX.getHexOfTLV_AtObj(d,n);n=b.shift()}var k=n;if(d.substr(k,2)!=""31""){throw""Can't find signerInfos""}var j=ASN1HEX.getPosArrayOfChildren_AtObj(d,k);for(var h=0;h<j.length;h++){var o=j[h];var e=c.parseSignerInfoForAddingUnsigned(d,o,h);a.si[h]=e}var g=null;a.obj=new p.SignedData();g=new q.ASN1Object();g.hTLV=a.version;a.obj.dCMSVersion=g;g=new q.ASN1Object();g.hTLV=a.algs;a.obj.dDigestAlgs=g;g=new q.ASN1Object();g.hTLV=a.encapcontent;a.obj.dEncapContentInfo=g;g=new q.ASN1Object();g.hTLV=a.certs;a.obj.dCerts=g;a.obj.signerInfoList=[];for(var h=0;h<a.si.length;h++){a.obj.signerInfoList.push(a.si[h].obj)}return a};KJUR.asn1.cades.CAdESUtil.parseSignerInfoForAddingUnsigned=function(d,k,a){var m=KJUR.asn1;var l=KJUR.asn1.cms;var b={};var e=ASN1HEX.getPosArrayOfChildren_AtObj(d,k);if(e.length!=6){throw""not supported items for SignerInfo (!=6)""}var f=e.shift();b.version=ASN1HEX.getHexOfTLV_AtObj(d,f);var n=e.shift();b.si=ASN1HEX.getHexOfTLV_AtObj(d,n);var h=e.shift();b.digalg=ASN1HEX.getHexOfTLV_AtObj(d,h);var c=e.shift();b.sattrs=ASN1HEX.getHexOfTLV_AtObj(d,c);var i=e.shift();b.sigalg=ASN1HEX.getHexOfTLV_AtObj(d,i);var j=e.shift();b.sig=ASN1HEX.getHexOfTLV_AtObj(d,j);b.sigval=ASN1HEX.getHexOfV_AtObj(d,j);var g=null;b.obj=new l.SignerInfo();g=new m.ASN1Object();g.hTLV=b.version;b.obj.dCMSVersion=g;g=new m.ASN1Object();g.hTLV=b.si;b.obj.dSignerIdentifier=g;g=new m.ASN1Object();g.hTLV=b.digalg;b.obj.dDigestAlgorithm=g;g=new m.ASN1Object();g.hTLV=b.sattrs;b.obj.dSignedAttrs=g;g=new m.ASN1Object();g.hTLV=b.sigalg;b.obj.dSigAlg=g;g=new m.ASN1Object();g.hTLV=b.sig;b.obj.dSig=g;b.obj.dUnsignedAttrs=new l.AttributeList();return b}; /*! base64x-1.1.3 (c) 2012-2014 Kenji Urushima | kjur.github.com/jsjws/license */ function Base64x(){}function stoBA(d){var b=new Array();for(var c=0;c<d.length;c++){b[c]=d.charCodeAt(c)}return b}function BAtos(b){var d="""";for(var c=0;c<b.length;c++){d=d+String.fromCharCode(b[c])}return d}function BAtohex(b){var e="""";for(var d=0;d<b.length;d++){var c=b[d].toString(16);if(c.length==1){c=""0""+c}e=e+c}return e}function stohex(a){return BAtohex(stoBA(a))}function stob64(a){return hex2b64(stohex(a))}function stob64u(a){return b64tob64u(hex2b64(stohex(a)))}function b64utos(a){return BAtos(b64toBA(b64utob64(a)))}function b64tob64u(a){a=a.replace(/\=/g,"""");a=a.replace(/\+/g,""-"");a=a.replace(/\//g,""_"");return a}function b64utob64(a){if(a.length%4==2){a=a+""==""}else{if(a.length%4==3){a=a+""=""}}a=a.replace(/-/g,""+"");a=a.replace(/_/g,""/"");return a}function hextob64u(a){return b64tob64u(hex2b64(a))}function b64utohex(a){return b64tohex(b64utob64(a))}var utf8tob64u,b64utoutf8;if(typeof Buffer===""function""){utf8tob64u=function(a){return b64tob64u(new Buffer(a,""utf8"").toString(""base64""))};b64utoutf8=function(a){return new Buffer(b64utob64(a),""base64"").toString(""utf8"")}}else{utf8tob64u=function(a){return hextob64u(uricmptohex(encodeURIComponentAll(a)))};b64utoutf8=function(a){return decodeURIComponent(hextouricmp(b64utohex(a)))}}function utf8tob64(a){return hex2b64(uricmptohex(encodeURIComponentAll(a)))}function b64toutf8(a){return decodeURIComponent(hextouricmp(b64tohex(a)))}function utf8tohex(a){return uricmptohex(encodeURIComponentAll(a))}function hextoutf8(a){return decodeURIComponent(hextouricmp(a))}function hextorstr(c){var b="""";for(var a=0;a<c.length-1;a+=2){b+=String.fromCharCode(parseInt(c.substr(a,2),16))}return b}function rstrtohex(c){var a="""";for(var b=0;b<c.length;b++){a+=(""0""+c.charCodeAt(b).toString(16)).slice(-2)}return a}function hextob64(a){return hex2b64(a)}function hextob64nl(b){var a=hextob64(b);var c=a.replace(/(.{64})/g,""$1\r\n"");c=c.replace(/\r\n$/,"""");return c}function b64nltohex(b){var a=b.replace(/[^0-9A-Za-z\/+=]*/g,"""");var c=b64tohex(a);return c}function uricmptohex(a){return a.replace(/%/g,"""")}function hextouricmp(a){return a.replace(/(..)/g,""%$1"")}function encodeURIComponentAll(a){var d=encodeURIComponent(a);var b="""";for(var c=0;c<d.length;c++){if(d[c]==""%""){b=b+d.substr(c,3);c=c+2}else{b=b+""%""+stohex(d[c])}}return b}function newline_toUnix(a){a=a.replace(/\r\n/mg,""\n"");return a}function newline_toDos(a){a=a.replace(/\r\n/mg,""\n"");a=a.replace(/\n/mg,""\r\n"");return a}; /*! crypto-1.1.5.js (c) 2013 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.crypto==""undefined""||!KJUR.crypto){KJUR.crypto={}}KJUR.crypto.Util=new function(){this.DIGESTINFOHEAD={sha1:""3021300906052b0e03021a05000414"",sha224:""302d300d06096086480165030402040500041c"",sha256:""3031300d060960864801650304020105000420"",sha384:""3041300d060960864801650304020205000430"",sha512:""3051300d060960864801650304020305000440"",md2:""3020300c06082a864886f70d020205000410"",md5:""3020300c06082a864886f70d020505000410"",ripemd160:""3021300906052b2403020105000414"",};this.DEFAULTPROVIDER={md5:""cryptojs"",sha1:""cryptojs"",sha224:""cryptojs"",sha256:""cryptojs"",sha384:""cryptojs"",sha512:""cryptojs"",ripemd160:""cryptojs"",hmacmd5:""cryptojs"",hmacsha1:""cryptojs"",hmacsha224:""cryptojs"",hmacsha256:""cryptojs"",hmacsha384:""cryptojs"",hmacsha512:""cryptojs"",hmacripemd160:""cryptojs"",MD5withRSA:""cryptojs/jsrsa"",SHA1withRSA:""cryptojs/jsrsa"",SHA224withRSA:""cryptojs/jsrsa"",SHA256withRSA:""cryptojs/jsrsa"",SHA384withRSA:""cryptojs/jsrsa"",SHA512withRSA:""cryptojs/jsrsa"",RIPEMD160withRSA:""cryptojs/jsrsa"",MD5withECDSA:""cryptojs/jsrsa"",SHA1withECDSA:""cryptojs/jsrsa"",SHA224withECDSA:""cryptojs/jsrsa"",SHA256withECDSA:""cryptojs/jsrsa"",SHA384withECDSA:""cryptojs/jsrsa"",SHA512withECDSA:""cryptojs/jsrsa"",RIPEMD160withECDSA:""cryptojs/jsrsa"",SHA1withDSA:""cryptojs/jsrsa"",SHA224withDSA:""cryptojs/jsrsa"",SHA256withDSA:""cryptojs/jsrsa"",MD5withRSAandMGF1:""cryptojs/jsrsa"",SHA1withRSAandMGF1:""cryptojs/jsrsa"",SHA224withRSAandMGF1:""cryptojs/jsrsa"",SHA256withRSAandMGF1:""cryptojs/jsrsa"",SHA384withRSAandMGF1:""cryptojs/jsrsa"",SHA512withRSAandMGF1:""cryptojs/jsrsa"",RIPEMD160withRSAandMGF1:""cryptojs/jsrsa"",};this.CRYPTOJSMESSAGEDIGESTNAME={md5:""CryptoJS.algo.MD5"",sha1:""CryptoJS.algo.SHA1"",sha224:""CryptoJS.algo.SHA224"",sha256:""CryptoJS.algo.SHA256"",sha384:""CryptoJS.algo.SHA384"",sha512:""CryptoJS.algo.SHA512"",ripemd160:""CryptoJS.algo.RIPEMD160""};this.getDigestInfoHex=function(a,b){if(typeof this.DIGESTINFOHEAD[b]==""undefined""){throw""alg not supported in Util.DIGESTINFOHEAD: ""+b}return this.DIGESTINFOHEAD[b]+a};this.getPaddedDigestInfoHex=function(h,a,j){var c=this.getDigestInfoHex(h,a);var d=j/4;if(c.length+22>d){throw""key is too short for SigAlg: keylen=""+j+"",""+a}var b=""0001"";var k=""00""+c;var g="""";var l=d-b.length-k.length;for(var f=0;f<l;f+=2){g+=""ff""}var e=b+g+k;return e};this.hashString=function(a,c){var b=new KJUR.crypto.MessageDigest({alg:c});return b.digestString(a)};this.hashHex=function(b,c){var a=new KJUR.crypto.MessageDigest({alg:c});return a.digestHex(b)};this.sha1=function(a){var b=new KJUR.crypto.MessageDigest({alg:""sha1"",prov:""cryptojs""});return b.digestString(a)};this.sha256=function(a){var b=new KJUR.crypto.MessageDigest({alg:""sha256"",prov:""cryptojs""});return b.digestString(a)};this.sha256Hex=function(a){var b=new KJUR.crypto.MessageDigest({alg:""sha256"",prov:""cryptojs""});return b.digestHex(a)};this.sha512=function(a){var b=new KJUR.crypto.MessageDigest({alg:""sha512"",prov:""cryptojs""});return b.digestString(a)};this.sha512Hex=function(a){var b=new KJUR.crypto.MessageDigest({alg:""sha512"",prov:""cryptojs""});return b.digestHex(a)};this.md5=function(a){var b=new KJUR.crypto.MessageDigest({alg:""md5"",prov:""cryptojs""});return b.digestString(a)};this.ripemd160=function(a){var b=new KJUR.crypto.MessageDigest({alg:""ripemd160"",prov:""cryptojs""});return b.digestString(a)};this.getCryptoJSMDByName=function(a){}};KJUR.crypto.MessageDigest=function(params){var md=null;var algName=null;var provName=null;this.setAlgAndProvider=function(alg,prov){if(alg!=null&&prov===undefined){prov=KJUR.crypto.Util.DEFAULTPROVIDER[alg]}if("":md5:sha1:sha224:sha256:sha384:sha512:ripemd160:"".indexOf(alg)!=-1&&prov==""cryptojs""){try{this.md=eval(KJUR.crypto.Util.CRYPTOJSMESSAGEDIGESTNAME[alg]).create()}catch(ex){throw""setAlgAndProvider hash alg set fail alg=""+alg+""/""+ex}this.updateString=function(str){this.md.update(str)};this.updateHex=function(hex){var wHex=CryptoJS.enc.Hex.parse(hex);this.md.update(wHex)};this.digest=function(){var hash=this.md.finalize();return hash.toString(CryptoJS.enc.Hex)};this.digestString=function(str){this.updateString(str);return this.digest()};this.digestHex=function(hex){this.updateHex(hex);return this.digest()}}if("":sha256:"".indexOf(alg)!=-1&&prov==""sjcl""){try{this.md=new sjcl.hash.sha256()}catch(ex){throw""setAlgAndProvider hash alg set fail alg=""+alg+""/""+ex}this.updateString=function(str){this.md.update(str)};this.updateHex=function(hex){var baHex=sjcl.codec.hex.toBits(hex);this.md.update(baHex)};this.digest=function(){var hash=this.md.finalize();return sjcl.codec.hex.fromBits(hash)};this.digestString=function(str){this.updateString(str);return this.digest()};this.digestHex=function(hex){this.updateHex(hex);return this.digest()}}};this.updateString=function(str){throw""updateString(str) not supported for this alg/prov: ""+this.algName+""/""+this.provName};this.updateHex=function(hex){throw""updateHex(hex) not supported for this alg/prov: ""+this.algName+""/""+this.provName};this.digest=function(){throw""digest() not supported for this alg/prov: ""+this.algName+""/""+this.provName};this.digestString=function(str){throw""digestString(str) not supported for this alg/prov: ""+this.algName+""/""+this.provName};this.digestHex=function(hex){throw""digestHex(hex) not supported for this alg/prov: ""+this.algName+""/""+this.provName};if(params!==undefined){if(params.alg!==undefined){this.algName=params.alg;if(params.prov===undefined){this.provName=KJUR.crypto.Util.DEFAULTPROVIDER[this.algName]}this.setAlgAndProvider(this.algName,this.provName)}}};KJUR.crypto.Mac=function(params){var mac=null;var pass=null;var algName=null;var provName=null;var algProv=null;this.setAlgAndProvider=function(alg,prov){if(alg==null){alg=""hmacsha1""}alg=alg.toLowerCase();if(alg.substr(0,4)!=""hmac""){throw""setAlgAndProvider unsupported HMAC alg: ""+alg}if(prov===undefined){prov=KJUR.crypto.Util.DEFAULTPROVIDER[alg]}this.algProv=alg+""/""+prov;var hashAlg=alg.substr(4);if("":md5:sha1:sha224:sha256:sha384:sha512:ripemd160:"".indexOf(hashAlg)!=-1&&prov==""cryptojs""){try{var mdObj=eval(KJUR.crypto.Util.CRYPTOJSMESSAGEDIGESTNAME[hashAlg]);this.mac=CryptoJS.algo.HMAC.create(mdObj,this.pass)}catch(ex){throw""setAlgAndProvider hash alg set fail hashAlg=""+hashAlg+""/""+ex}this.updateString=function(str){this.mac.update(str)};this.updateHex=function(hex){var wHex=CryptoJS.enc.Hex.parse(hex);this.mac.update(wHex)};this.doFinal=function(){var hash=this.mac.finalize();return hash.toString(CryptoJS.enc.Hex)};this.doFinalString=function(str){this.updateString(str);return this.doFinal()};this.doFinalHex=function(hex){this.updateHex(hex);return this.doFinal()}}};this.updateString=function(str){throw""updateString(str) not supported for this alg/prov: ""+this.algProv};this.updateHex=function(hex){throw""updateHex(hex) not supported for this alg/prov: ""+this.algProv};this.doFinal=function(){throw""digest() not supported for this alg/prov: ""+this.algProv};this.doFinalString=function(str){throw""digestString(str) not supported for this alg/prov: ""+this.algProv};this.doFinalHex=function(hex){throw""digestHex(hex) not supported for this alg/prov: ""+this.algProv};if(params!==undefined){if(params.pass!==undefined){this.pass=params.pass}if(params.alg!==undefined){this.algName=params.alg;if(params.prov===undefined){this.provName=KJUR.crypto.Util.DEFAULTPROVIDER[this.algName]}this.setAlgAndProvider(this.algName,this.provName)}}};KJUR.crypto.Signature=function(o){var q=null;var n=null;var r=null;var c=null;var l=null;var d=null;var k=null;var h=null;var p=null;var e=null;var b=-1;var g=null;var j=null;var a=null;var i=null;var f=null;this._setAlgNames=function(){if(this.algName.match(/^(.+)with(.+)$/)){this.mdAlgName=RegExp.$1.toLowerCase();this.pubkeyAlgName=RegExp.$2.toLowerCase()}};this._zeroPaddingOfSignature=function(x,w){var v="""";var t=w/4-x.length;for(var u=0;u<t;u++){v=v+""0""}return v+x};this.setAlgAndProvider=function(u,t){this._setAlgNames();if(t!=""cryptojs/jsrsa""){throw""provider not supported: ""+t}if("":md5:sha1:sha224:sha256:sha384:sha512:ripemd160:"".indexOf(this.mdAlgName)!=-1){try{this.md=new KJUR.crypto.MessageDigest({alg:this.mdAlgName})}catch(s){throw""setAlgAndProvider hash alg set fail alg=""+this.mdAlgName+""/""+s}this.init=function(w,x){var y=null;try{if(x===undefined){y=KEYUTIL.getKey(w)}else{y=KEYUTIL.getKey(w,x)}}catch(v){throw""init failed:""+v}if(y.isPrivate===true){this.prvKey=y;this.state=""SIGN""}else{if(y.isPublic===true){this.pubKey=y;this.state=""VERIFY""}else{throw""init failed.:""+y}}};this.initSign=function(v){if(typeof v.ecprvhex==""string""&&typeof v.eccurvename==""string""){this.ecprvhex=v.ecprvhex;this.eccurvename=v.eccurvename}else{this.prvKey=v}this.state=""SIGN""};this.initVerifyByPublicKey=function(v){if(typeof v.ecpubhex==""string""&&typeof v.eccurvename==""string""){this.ecpubhex=v.ecpubhex;this.eccurvename=v.eccurvename}else{if(v instanceof KJUR.crypto.ECDSA){this.pubKey=v}else{if(v instanceof RSAKey){this.pubKey=v}}}this.state=""VERIFY""};this.initVerifyByCertificatePEM=function(v){var w=new X509();w.readCertPEM(v);this.pubKey=w.subjectPublicKeyRSA;this.state=""VERIFY""};this.updateString=function(v){this.md.updateString(v)};this.updateHex=function(v){this.md.updateHex(v)};this.sign=function(){this.sHashHex=this.md.digest();if(typeof this.ecprvhex!=""undefined""&&typeof this.eccurvename!=""undefined""){var v=new KJUR.crypto.ECDSA({curve:this.eccurvename});this.hSign=v.signHex(this.sHashHex,this.ecprvhex)}else{if(this.pubkeyAlgName==""rsaandmgf1""){this.hSign=this.prvKey.signWithMessageHashPSS(this.sHashHex,this.mdAlgName,this.pssSaltLen)}else{if(this.pubkeyAlgName==""rsa""){this.hSign=this.prvKey.signWithMessageHash(this.sHashHex,this.mdAlgName)}else{if(this.prvKey instanceof KJUR.crypto.ECDSA){this.hSign=this.prvKey.signWithMessageHash(this.sHashHex)}else{if(this.prvKey instanceof KJUR.crypto.DSA){this.hSign=this.prvKey.signWithMessageHash(this.sHashHex)}else{throw""Signature: unsupported public key alg: ""+this.pubkeyAlgName}}}}}return this.hSign};this.signString=function(v){this.updateString(v);this.sign()};this.signHex=function(v){this.updateHex(v);this.sign()};this.verify=function(v){this.sHashHex=this.md.digest();if(typeof this.ecpubhex!=""undefined""&&typeof this.eccurvename!=""undefined""){var w=new KJUR.crypto.ECDSA({curve:this.eccurvename});return w.verifyHex(this.sHashHex,v,this.ecpubhex)}else{if(this.pubkeyAlgName==""rsaandmgf1""){return this.pubKey.verifyWithMessageHashPSS(this.sHashHex,v,this.mdAlgName,this.pssSaltLen)}else{if(this.pubkeyAlgName==""rsa""){return this.pubKey.verifyWithMessageHash(this.sHashHex,v)}else{if(this.pubKey instanceof KJUR.crypto.ECDSA){return this.pubKey.verifyWithMessageHash(this.sHashHex,v)}else{if(this.pubKey instanceof KJUR.crypto.DSA){return this.pubKey.verifyWithMessageHash(this.sHashHex,v)}else{throw""Signature: unsupported public key alg: ""+this.pubkeyAlgName}}}}}}}};this.init=function(s,t){throw""init(key, pass) not supported for this alg:prov=""+this.algProvName};this.initVerifyByPublicKey=function(s){throw""initVerifyByPublicKey(rsaPubKeyy) not supported for this alg:prov=""+this.algProvName};this.initVerifyByCertificatePEM=function(s){throw""initVerifyByCertificatePEM(certPEM) not supported for this alg:prov=""+this.algProvName};this.initSign=function(s){throw""initSign(prvKey) not supported for this alg:prov=""+this.algProvName};this.updateString=function(s){throw""updateString(str) not supported for this alg:prov=""+this.algProvName};this.updateHex=function(s){throw""updateHex(hex) not supported for this alg:prov=""+this.algProvName};this.sign=function(){throw""sign() not supported for this alg:prov=""+this.algProvName};this.signString=function(s){throw""digestString(str) not supported for this alg:prov=""+this.algProvName};this.signHex=function(s){throw""digestHex(hex) not supported for this alg:prov=""+this.algProvName};this.verify=function(s){throw""verify(hSigVal) not supported for this alg:prov=""+this.algProvName};this.initParams=o;if(o!==undefined){if(o.alg!==undefined){this.algName=o.alg;if(o.prov===undefined){this.provName=KJUR.crypto.Util.DEFAULTPROVIDER[this.algName]}else{this.provName=o.prov}this.algProvName=this.algName+"":""+this.provName;this.setAlgAndProvider(this.algName,this.provName);this._setAlgNames()}if(o.psssaltlen!==undefined){this.pssSaltLen=o.psssaltlen}if(o.prvkeypem!==undefined){if(o.prvkeypas!==undefined){throw""both prvkeypem and prvkeypas parameters not supported""}else{try{var q=new RSAKey();q.readPrivateKeyFromPEMString(o.prvkeypem);this.initSign(q)}catch(m){throw""fatal error to load pem private key: ""+m}}}}};KJUR.crypto.OID=new function(){this.oidhex2name={""2a864886f70d010101"":""rsaEncryption"",""2a8648ce3d0201"":""ecPublicKey"",""2a8648ce380401"":""dsa"",""2a8648ce3d030107"":""secp256r1"",""2b8104001f"":""secp192k1"",""2b81040021"":""secp224r1"",""2b8104000a"":""secp256k1"",""2b81040023"":""secp521r1"",""2b81040022"":""secp384r1"",""2a8648ce380403"":""SHA1withDSA"",""608648016503040301"":""SHA224withDSA"",""608648016503040302"":""SHA256withDSA"",}}; /*! ecdsa-modified-1.0.4.js (c) Stephan Thomas, Kenji Urushima | github.com/bitcoinjs/bitcoinjs-lib/blob/master/LICENSE */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.crypto==""undefined""||!KJUR.crypto){KJUR.crypto={}}KJUR.crypto.ECDSA=function(h){var e=""secp256r1"";var g=null;var b=null;var f=null;var a=new SecureRandom();var d=null;this.type=""EC"";function c(s,o,r,n){var j=Math.max(o.bitLength(),n.bitLength());var t=s.add2D(r);var q=s.curve.getInfinity();for(var p=j-1;p>=0;--p){q=q.twice2D();q.z=BigInteger.ONE;if(o.testBit(p)){if(n.testBit(p)){q=q.add2D(t)}else{q=q.add2D(s)}}else{if(n.testBit(p)){q=q.add2D(r)}}}return q}this.getBigRandom=function(i){return new BigInteger(i.bitLength(),a).mod(i.subtract(BigInteger.ONE)).add(BigInteger.ONE)};this.setNamedCurve=function(i){this.ecparams=KJUR.crypto.ECParameterDB.getByName(i);this.prvKeyHex=null;this.pubKeyHex=null;this.curveName=i};this.setPrivateKeyHex=function(i){this.isPrivate=true;this.prvKeyHex=i};this.setPublicKeyHex=function(i){this.isPublic=true;this.pubKeyHex=i};this.generateKeyPairHex=function(){var k=this.ecparams.n;var n=this.getBigRandom(k);var l=this.ecparams.G.multiply(n);var q=l.getX().toBigInteger();var o=l.getY().toBigInteger();var i=this.ecparams.keylen/4;var m=(""0000000000""+n.toString(16)).slice(-i);var r=(""0000000000""+q.toString(16)).slice(-i);var p=(""0000000000""+o.toString(16)).slice(-i);var j=""04""+r+p;this.setPrivateKeyHex(m);this.setPublicKeyHex(j);return{ecprvhex:m,ecpubhex:j}};this.signWithMessageHash=function(i){return this.signHex(i,this.prvKeyHex)};this.signHex=function(o,j){var t=new BigInteger(j,16);var l=this.ecparams.n;var q=new BigInteger(o,16);do{var m=this.getBigRandom(l);var u=this.ecparams.G;var p=u.multiply(m);var i=p.getX().toBigInteger().mod(l)}while(i.compareTo(BigInteger.ZERO)<=0);var v=m.modInverse(l).multiply(q.add(t.multiply(i))).mod(l);return KJUR.crypto.ECDSA.biRSSigToASN1Sig(i,v)};this.sign=function(m,u){var q=u;var j=this.ecparams.n;var p=BigInteger.fromByteArrayUnsigned(m);do{var l=this.getBigRandom(j);var t=this.ecparams.G;var o=t.multiply(l);var i=o.getX().toBigInteger().mod(j)}while(i.compareTo(BigInteger.ZERO)<=0);var v=l.modInverse(j).multiply(p.add(q.multiply(i))).mod(j);return this.serializeSig(i,v)};this.verifyWithMessageHash=function(j,i){return this.verifyHex(j,i,this.pubKeyHex)};this.verifyHex=function(m,i,p){var l,j;var o=KJUR.crypto.ECDSA.parseSigHex(i);l=o.r;j=o.s;var k;k=ECPointFp.decodeFromHex(this.ecparams.curve,p);var n=new BigInteger(m,16);return this.verifyRaw(n,l,j,k)};this.verify=function(o,p,j){var l,i;if(Bitcoin.Util.isArray(p)){var n=this.parseSig(p);l=n.r;i=n.s}else{if(""object""===typeof p&&p.r&&p.s){l=p.r;i=p.s}else{throw""Invalid value for signature""}}var k;if(j instanceof ECPointFp){k=j}else{if(Bitcoin.Util.isArray(j)){k=ECPointFp.decodeFrom(this.ecparams.curve,j)}else{throw""Invalid format for pubkey value, must be byte array or ECPointFp""}}var m=BigInteger.fromByteArrayUnsigned(o);return this.verifyRaw(m,l,i,k)};this.verifyRaw=function(o,i,w,m){var l=this.ecparams.n;var u=this.ecparams.G;if(i.compareTo(BigInteger.ONE)<0||i.compareTo(l)>=0){return false}if(w.compareTo(BigInteger.ONE)<0||w.compareTo(l)>=0){return false}var p=w.modInverse(l);var k=o.multiply(p).mod(l);var j=i.multiply(p).mod(l);var q=u.multiply(k).add(m.multiply(j));var t=q.getX().toBigInteger().mod(l);return t.equals(i)};this.serializeSig=function(k,j){var l=k.toByteArraySigned();var i=j.toByteArraySigned();var m=[];m.push(2);m.push(l.length);m=m.concat(l);m.push(2);m.push(i.length);m=m.concat(i);m.unshift(m.length);m.unshift(48);return m};this.parseSig=function(n){var m;if(n[0]!=48){throw new Error(""Signature not a valid DERSequence"")}m=2;if(n[m]!=2){throw new Error(""First element in signature must be a DERInteger"")}var l=n.slice(m+2,m+2+n[m+1]);m+=2+n[m+1];if(n[m]!=2){throw new Error(""Second element in signature must be a DERInteger"")}var i=n.slice(m+2,m+2+n[m+1]);m+=2+n[m+1];var k=BigInteger.fromByteArrayUnsigned(l);var j=BigInteger.fromByteArrayUnsigned(i);return{r:k,s:j}};this.parseSigCompact=function(m){if(m.length!==65){throw""Signature has the wrong length""}var j=m[0]-27;if(j<0||j>7){throw""Invalid signature type""}var o=this.ecparams.n;var l=BigInteger.fromByteArrayUnsigned(m.slice(1,33)).mod(o);var k=BigInteger.fromByteArrayUnsigned(m.slice(33,65)).mod(o);return{r:l,s:k,i:j}};if(h!==undefined){if(h.curve!==undefined){this.curveName=h.curve}}if(this.curveName===undefined){this.curveName=e}this.setNamedCurve(this.curveName);if(h!==undefined){if(h.prv!==undefined){this.setPrivateKeyHex(h.prv)}if(h.pub!==undefined){this.setPublicKeyHex(h.pub)}}};KJUR.crypto.ECDSA.parseSigHex=function(a){var b=KJUR.crypto.ECDSA.parseSigHexInHexRS(a);var d=new BigInteger(b.r,16);var c=new BigInteger(b.s,16);return{r:d,s:c}};KJUR.crypto.ECDSA.parseSigHexInHexRS=function(c){if(c.substr(0,2)!=""30""){throw""signature is not a ASN.1 sequence""}var b=ASN1HEX.getPosArrayOfChildren_AtObj(c,0);if(b.length!=2){throw""number of signature ASN.1 sequence elements seem wrong""}var g=b[0];var f=b[1];if(c.substr(g,2)!=""02""){throw""1st item of sequene of signature is not ASN.1 integer""}if(c.substr(f,2)!=""02""){throw""2nd item of sequene of signature is not ASN.1 integer""}var e=ASN1HEX.getHexOfV_AtObj(c,g);var d=ASN1HEX.getHexOfV_AtObj(c,f);return{r:e,s:d}};KJUR.crypto.ECDSA.asn1SigToConcatSig=function(c){var d=KJUR.crypto.ECDSA.parseSigHexInHexRS(c);var b=d.r;var a=d.s;if(b.substr(0,2)==""00""&&(((b.length/2)*8)%(16*8))==8){b=b.substr(2)}if(a.substr(0,2)==""00""&&(((a.length/2)*8)%(16*8))==8){a=a.substr(2)}if((((b.length/2)*8)%(16*8))!=0){throw""unknown ECDSA sig r length error""}if((((a.length/2)*8)%(16*8))!=0){throw""unknown ECDSA sig s length error""}return b+a};KJUR.crypto.ECDSA.concatSigToASN1Sig=function(a){if((((a.length/2)*8)%(16*8))!=0){throw""unknown ECDSA concatinated r-s sig length error""}var c=a.substr(0,a.length/2);var b=a.substr(a.length/2);return KJUR.crypto.ECDSA.hexRSSigToASN1Sig(c,b)};KJUR.crypto.ECDSA.hexRSSigToASN1Sig=function(b,a){var d=new BigInteger(b,16);var c=new BigInteger(a,16);return KJUR.crypto.ECDSA.biRSSigToASN1Sig(d,c)};KJUR.crypto.ECDSA.biRSSigToASN1Sig=function(e,c){var b=new KJUR.asn1.DERInteger({bigint:e});var a=new KJUR.asn1.DERInteger({bigint:c});var d=new KJUR.asn1.DERSequence({array:[b,a]});return d.getEncodedHex()}; /*! ecparam-1.0.0.js (c) 2013 Kenji Urushima | kjur.github.com/jsrsasign/license */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.crypto==""undefined""||!KJUR.crypto){KJUR.crypto={}}KJUR.crypto.ECParameterDB=new function(){var b={};var c={};function a(d){return new BigInteger(d,16)}this.getByName=function(e){var d=e;if(typeof c[d]!=""undefined""){d=c[e]}if(typeof b[d]!=""undefined""){return b[d]}throw""unregistered EC curve name: ""+d};this.regist=function(A,l,o,g,m,e,j,f,k,u,d,x){b[A]={};var s=a(o);var z=a(g);var y=a(m);var t=a(e);var w=a(j);var r=new ECCurveFp(s,z,y);var q=r.decodePointHex(""04""+f+k);b[A][""name""]=A;b[A][""keylen""]=l;b[A][""curve""]=r;b[A][""G""]=q;b[A][""n""]=t;b[A][""h""]=w;b[A][""oid""]=d;b[A][""info""]=x;for(var v=0;v<u.length;v++){c[u[v]]=A}}};KJUR.crypto.ECParameterDB.regist(""secp128r1"",128,""FFFFFFFDFFFFFFFFFFFFFFFFFFFFFFFF"",""FFFFFFFDFFFFFFFFFFFFFFFFFFFFFFFC"",""E87579C11079F43DD824993C2CEE5ED3"",""FFFFFFFE0000000075A30D1B9038A115"",""1"",""161FF7528B899B2D0C28607CA52C5B86"",""CF5AC8395BAFEB13C02DA292DDED7A83"",[],"""",""secp128r1 : SECG curve over a 128 bit prime field"");KJUR.crypto.ECParameterDB.regist(""secp160k1"",160,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFAC73"",""0"",""7"",""0100000000000000000001B8FA16DFAB9ACA16B6B3"",""1"",""3B4C382CE37AA192A4019E763036F4F5DD4D7EBB"",""938CF935318FDCED6BC28286531733C3F03C4FEE"",[],"""",""secp160k1 : SECG curve over a 160 bit prime field"");KJUR.crypto.ECParameterDB.regist(""secp160r1"",160,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF7FFFFFFF"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF7FFFFFFC"",""1C97BEFC54BD7A8B65ACF89F81D4D4ADC565FA45"",""0100000000000000000001F4C8F927AED3CA752257"",""1"",""4A96B5688EF573284664698968C38BB913CBFC82"",""23A628553168947D59DCC912042351377AC5FB32"",[],"""",""secp160r1 : SECG curve over a 160 bit prime field"");KJUR.crypto.ECParameterDB.regist(""secp192k1"",192,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFEE37"",""0"",""3"",""FFFFFFFFFFFFFFFFFFFFFFFE26F2FC170F69466A74DEFD8D"",""1"",""DB4FF10EC057E9AE26B07D0280B7F4341DA5D1B1EAE06C7D"",""9B2F2F6D9C5628A7844163D015BE86344082AA88D95E2F9D"",[]);KJUR.crypto.ECParameterDB.regist(""secp192r1"",192,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFF"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFC"",""64210519E59C80E70FA7E9AB72243049FEB8DEECC146B9B1"",""FFFFFFFFFFFFFFFFFFFFFFFF99DEF836146BC9B1B4D22831"",""1"",""188DA80EB03090F67CBF20EB43A18800F4FF0AFD82FF1012"",""07192B95FFC8DA78631011ED6B24CDD573F977A11E794811"",[]);KJUR.crypto.ECParameterDB.regist(""secp224r1"",224,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF000000000000000000000001"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFE"",""B4050A850C04B3ABF54132565044B0B7D7BFD8BA270B39432355FFB4"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFF16A2E0B8F03E13DD29455C5C2A3D"",""1"",""B70E0CBD6BB4BF7F321390B94A03C1D356C21122343280D6115C1D21"",""BD376388B5F723FB4C22DFE6CD4375A05A07476444D5819985007E34"",[]);KJUR.crypto.ECParameterDB.regist(""secp256k1"",256,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F"",""0"",""7"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364141"",""1"",""79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798"",""483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8"",[]);KJUR.crypto.ECParameterDB.regist(""secp256r1"",256,""FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFF"",""FFFFFFFF00000001000000000000000000000000FFFFFFFFFFFFFFFFFFFFFFFC"",""5AC635D8AA3A93E7B3EBBD55769886BC651D06B0CC53B0F63BCE3C3E27D2604B"",""FFFFFFFF00000000FFFFFFFFFFFFFFFFBCE6FAADA7179E84F3B9CAC2FC632551"",""1"",""6B17D1F2E12C4247F8BCE6E563A440F277037D812DEB33A0F4A13945D898C296"",""4FE342E2FE1A7F9B8EE7EB4A7C0F9E162BCE33576B315ECECBB6406837BF51F5"",[""NIST P-256"",""P-256"",""prime256v1""]);KJUR.crypto.ECParameterDB.regist(""secp384r1"",384,""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFF"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFFFF0000000000000000FFFFFFFC"",""B3312FA7E23EE7E4988E056BE3F82D19181D9C6EFE8141120314088F5013875AC656398D8A2ED19D2A85C8EDD3EC2AEF"",""FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC7634D81F4372DDF581A0DB248B0A77AECEC196ACCC52973"",""1"",""AA87CA22BE8B05378EB1C71EF320AD746E1D3B628BA79B9859F741E082542A385502F25DBF55296C3A545E3872760AB7"",""3617de4a96262c6f5d9e98bf9292dc29f8f41dbd289a147ce9da3113b5f0b8c00a60b1ce1d7e819d7a431d7c90ea0e5f"",[""NIST P-384"",""P-384""]);KJUR.crypto.ECParameterDB.regist(""secp521r1"",521,""1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF"",""1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFC"",""051953EB9618E1C9A1F929A21A0B68540EEA2DA725B99B315F3B8B489918EF109E156193951EC7E937B1652C0BD3BB1BF073573DF883D2C34F1EF451FD46B503F00"",""1FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFA51868783BF2F966B7FCC0148F709A5D03BB5C9B8899C47AEBB6FB71E91386409"",""1"",""C6858E06B70404E9CD9E3ECB662395B4429C648139053FB521F828AF606B4D3DBAA14B5E77EFE75928FE1DC127A2FFA8DE3348B3C1856A429BF97E7E31C2E5BD66"",""011839296a789a3bc0045c8a5fb42c7d1bd998f54449579b446817afbd17273e662c97ee72995ef42640c550b9013fad0761353c7086a272c24088be94769fd16650"",[""NIST P-521"",""P-521""]); /*! dsa-modified-1.0.1.js (c) Recurity Labs GmbH, Kenji Urushimma | github.com/openpgpjs/openpgpjs/blob/master/LICENSE */ if(typeof KJUR==""undefined""||!KJUR){KJUR={}}if(typeof KJUR.crypto==""undefined""||!KJUR.crypto){KJUR.crypto={}}KJUR.crypto.DSA=function(){this.p=null;this.q=null;this.g=null;this.y=null;this.x=null;this.type=""DSA"";this.setPrivate=function(z,w,v,A,u){this.isPrivate=true;this.p=z;this.q=w;this.g=v;this.y=A;this.x=u};this.setPublic=function(w,v,u,z){this.isPublic=true;this.p=w;this.q=v;this.g=u;this.y=z;this.x=null};this.signWithMessageHash=function(z){var v=this.p;var u=this.q;var C=this.g;var D=this.y;var E=this.x;var A=z.substr(0,u.bitLength()/4);var B=new BigInteger(z,16);var w=n(BigInteger.ONE.add(BigInteger.ONE),u.subtract(BigInteger.ONE));var G=(C.modPow(w,v)).mod(u);var F=(w.modInverse(u).multiply(B.add(E.multiply(G)))).mod(u);var H=KJUR.asn1.ASN1Util.jsonToASN1HEX({seq:[{""int"":{bigint:G}},{""int"":{bigint:F}}]});return H};this.verifyWithMessageHash=function(C,B){var z=this.p;var u=this.q;var G=this.g;var H=this.y;var E=this.parseASN1Signature(B);var K=E[0];var J=E[1];var C=C.substr(0,u.bitLength()/4);var D=new BigInteger(C,16);if(BigInteger.ZERO.compareTo(K)>0||K.compareTo(u)>0||BigInteger.ZERO.compareTo(J)>0||J.compareTo(u)>0){throw""invalid DSA signature""}var I=J.modInverse(u);var A=D.multiply(I).mod(u);var v=K.multiply(I).mod(u);var F=G.modPow(A,z).multiply(H.modPow(v,z)).mod(z).mod(u);return F.compareTo(K)==0};this.parseASN1Signature=function(u){try{var y=new BigInteger(ASN1HEX.getVbyList(u,0,[0],""02""),16);var v=new BigInteger(ASN1HEX.getVbyList(u,0,[1],""02""),16);return[y,v]}catch(w){throw""malformed DSA signature""}};function d(E,w,B,v,u,C){var z=KJUR.crypto.Util.hashString(w,E.toLowerCase());var z=z.substr(0,u.bitLength()/4);var A=new BigInteger(z,16);var y=n(BigInteger.ONE.add(BigInteger.ONE),u.subtract(BigInteger.ONE));var F=(B.modPow(y,v)).mod(u);var D=(y.modInverse(u).multiply(A.add(C.multiply(F)))).mod(u);var G=new Array();G[0]=F;G[1]=D;return G}function r(v){var u=openpgp.config.config.prefer_hash_algorithm;switch(Math.round(v.bitLength()/8)){case 20:if(u!=2&&u>11&&u!=10&&u<8){return 2}return u;case 28:if(u>11&&u<8){return 11}return u;case 32:if(u>10&&u<8){return 8}return u;default:util.print_debug(""DSA select hash algorithm: returning null for an unknown length of q"");return null}}this.select_hash_algorithm=r;function m(I,K,J,B,z,u,F,G){var C=KJUR.crypto.Util.hashString(B,I.toLowerCase());var C=C.substr(0,u.bitLength()/4);var D=new BigInteger(C,16);if(BigInteger.ZERO.compareTo(K)>0||K.compareTo(u)>0||BigInteger.ZERO.compareTo(J)>0||J.compareTo(u)>0){util.print_error(""invalid DSA Signature"");return null}var H=J.modInverse(u);var A=D.multiply(H).mod(u);var v=K.multiply(H).mod(u);var E=F.modPow(A,z).multiply(G.modPow(v,z)).mod(z).mod(u);return E.compareTo(K)==0}function a(z){var A=new BigInteger(z,primeCenterie);var y=j(q,512);var u=t(p,q,z);var v;do{v=new BigInteger(q.bitCount(),rand)}while(x.compareTo(BigInteger.ZERO)!=1&&x.compareTo(q)!=-1);var w=g.modPow(x,p);return{x:v,q:A,p:y,g:u,y:w}}function j(y,z,w){if(z%64!=0){return false}var u;var v;do{u=w(bitcount,true);v=u.subtract(BigInteger.ONE);u=u.subtract(v.remainder(y))}while(!u.isProbablePrime(primeCenterie)||u.bitLength()!=l);return u}function t(B,z,A,w){var u=B.subtract(BigInteger.ONE);var y=u.divide(z);var v;do{v=w(A)}while(v.compareTo(u)!=-1&&v.compareTo(BigInteger.ONE)!=1);return v.modPow(y,B)}function o(w,y,u){var v;do{v=u(y,false)}while(v.compareTo(w)!=-1&&v.compareTo(BigInteger.ZERO)!=1);return v}function i(v,w){k=o(v);var u=g.modPow(k,w).mod(v);return u}function h(B,w,y,v,z,u){var A=B(v);s=(w.modInverse(z).multiply(A.add(u.multiply(y)))).mod(z);return s}this.sign=d;this.verify=m;function n(w,u){if(u.compareTo(w)<=0){return}var v=u.subtract(w);var y=e(v.bitLength());while(y>v){y=e(v.bitLength())}return w.add(y)}function e(w){if(w<0){return null}var u=Math.floor((w+7)/8);var v=c(u);if(w%8>0){v=String.fromCharCode((Math.pow(2,w%8)-1)&v.charCodeAt(0))+v.substring(1)}return new BigInteger(f(v),16)}function c(w){var u="""";for(var v=0;v<w;v++){u+=String.fromCharCode(b())}return u}function b(){var u=new Uint32Array(1);window.crypto.getRandomValues(u);return u[0]&255}function f(y){if(y==null){return""""}var v=[];var w=y.length;var z=0;var u;while(z<w){u=y[z++].charCodeAt().toString(16);while(u.length<2){u=""0""+u}v.push(""""+u)}return v.join("""")}this.getRandomBigIntegerInRange=n;this.getRandomBigInteger=e;this.getRandomBytes=c}; /*! pkcs5pkey-1.0.6.js (c) 2013-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ var PKCS5PKEY=function(){var c=function(n,p,o){return i(CryptoJS.AES,n,p,o)};var d=function(n,p,o){return i(CryptoJS.TripleDES,n,p,o)};var i=function(q,v,s,o){var p=CryptoJS.enc.Hex.parse(v);var u=CryptoJS.enc.Hex.parse(s);var n=CryptoJS.enc.Hex.parse(o);var r={};r.key=u;r.iv=n;r.ciphertext=p;var t=q.decrypt(r,u,{iv:n});return CryptoJS.enc.Hex.stringify(t)};var j=function(n,p,o){return e(CryptoJS.AES,n,p,o)};var m=function(n,p,o){return e(CryptoJS.TripleDES,n,p,o)};var e=function(s,x,v,p){var r=CryptoJS.enc.Hex.parse(x);var w=CryptoJS.enc.Hex.parse(v);var o=CryptoJS.enc.Hex.parse(p);var n={};var u=s.encrypt(r,w,{iv:o});var q=CryptoJS.enc.Hex.parse(u.toString());var t=CryptoJS.enc.Base64.stringify(q);return t};var g={""AES-256-CBC"":{proc:c,eproc:j,keylen:32,ivlen:16},""AES-192-CBC"":{proc:c,eproc:j,keylen:24,ivlen:16},""AES-128-CBC"":{proc:c,eproc:j,keylen:16,ivlen:16},""DES-EDE3-CBC"":{proc:d,eproc:m,keylen:24,ivlen:8}};var b=function(n){return g[n][""proc""]};var k=function(n){var p=CryptoJS.lib.WordArray.random(n);var o=CryptoJS.enc.Hex.stringify(p);return o};var l=function(q){var r={};if(q.match(new RegExp(""DEK-Info: ([^,]+),([0-9A-Fa-f]+)"",""m""))){r.cipher=RegExp.$1;r.ivsalt=RegExp.$2}if(q.match(new RegExp(""-----BEGIN ([A-Z]+) PRIVATE KEY-----""))){r.type=RegExp.$1}var p=-1;var t=0;if(q.indexOf(""\r\n\r\n"")!=-1){p=q.indexOf(""\r\n\r\n"");t=2}if(q.indexOf(""\n\n"")!=-1){p=q.indexOf(""\n\n"");t=1}var o=q.indexOf(""-----END"");if(p!=-1&&o!=-1){var n=q.substring(p+t*2,o-t);n=n.replace(/\s+/g,"""");r.data=n}return r};var h=function(o,w,n){var t=n.substring(0,16);var r=CryptoJS.enc.Hex.parse(t);var p=CryptoJS.enc.Utf8.parse(w);var s=g[o][""keylen""]+g[o][""ivlen""];var v="""";var u=null;for(;;){var q=CryptoJS.algo.MD5.create();if(u!=null){q.update(u)}q.update(p);q.update(r);u=q.finalize();v=v+CryptoJS.enc.Hex.stringify(u);if(v.length>=s*2){break}}var x={};x.keyhex=v.substr(0,g[o][""keylen""]*2);x.ivhex=v.substr(g[o][""keylen""]*2,g[o][""ivlen""]*2);return x};var a=function(n,t,p,u){var q=CryptoJS.enc.Base64.parse(n);var o=CryptoJS.enc.Hex.stringify(q);var s=g[t][""proc""];var r=s(o,p,u);return r};var f=function(n,q,o,s){var p=g[q][""eproc""];var r=p(n,o,s);return r};return{version:""1.0.5"",getHexFromPEM:function(o,r){var p=o;if(p.indexOf(""BEGIN ""+r)==-1){throw""can't find PEM header: ""+r}p=p.replace(""-----BEGIN ""+r+""-----"","""");p=p.replace(""-----END ""+r+""-----"","""");var q=p.replace(/\s+/g,"""");var n=b64tohex(q);return n},getDecryptedKeyHexByKeyIV:function(o,r,q,p){var n=b(r);return n(o,q,p)},parsePKCS5PEM:function(n){return l(n)},getKeyAndUnusedIvByPasscodeAndIvsalt:function(o,n,p){return h(o,n,p)},decryptKeyB64:function(n,p,o,q){return a(n,p,o,q)},getDecryptedKeyHex:function(w,v){var o=l(w);var r=o.type;var p=o.cipher;var n=o.ivsalt;var q=o.data;var u=h(p,v,n);var t=u.keyhex;var s=a(q,p,t,n);return s},getRSAKeyFromEncryptedPKCS5PEM:function(p,o){var q=this.getDecryptedKeyHex(p,o);var n=new RSAKey();n.readPrivateKeyFromASN1HexString(q);return n},getEryptedPKCS5PEMFromPrvKeyHex:function(q,x,r,p){var n="""";if(typeof r==""undefined""||r==null){r=""AES-256-CBC""}if(typeof g[r]==""undefined""){throw""PKCS5PKEY unsupported algorithm: ""+r}if(typeof p==""undefined""||p==null){var t=g[r][""ivlen""];var s=k(t);p=s.toUpperCase()}var w=h(r,x,p);var v=w.keyhex;var u=f(q,r,v,p);var o=u.replace(/(.{64})/g,""$1\r\n"");var n=""-----BEGIN RSA PRIVATE KEY-----\r\n"";n+=""Proc-Type: 4,ENCRYPTED\r\n"";n+=""DEK-Info: ""+r+"",""+p+""\r\n"";n+=""\r\n"";n+=o;n+=""\r\n-----END RSA PRIVATE KEY-----\r\n"";return n},getEryptedPKCS5PEMFromRSAKey:function(C,D,o,s){var A=new KJUR.asn1.DERInteger({""int"":0});var v=new KJUR.asn1.DERInteger({bigint:C.n});var z=new KJUR.asn1.DERInteger({""int"":C.e});var B=new KJUR.asn1.DERInteger({bigint:C.d});var t=new KJUR.asn1.DERInteger({bigint:C.p});var r=new KJUR.asn1.DERInteger({bigint:C.q});var y=new KJUR.asn1.DERInteger({bigint:C.dmp1});var u=new KJUR.asn1.DERInteger({bigint:C.dmq1});var x=new KJUR.asn1.DERInteger({bigint:C.coeff});var E=new KJUR.asn1.DERSequence({array:[A,v,z,B,t,r,y,u,x]});var w=E.getEncodedHex();return this.getEryptedPKCS5PEMFromPrvKeyHex(w,D,o,s)},newEncryptedPKCS5PEM:function(n,o,r,s){if(typeof o==""undefined""||o==null){o=1024}if(typeof r==""undefined""||r==null){r=""10001""}var p=new RSAKey();p.generate(o,r);var q=null;if(typeof s==""undefined""||s==null){q=this.getEncryptedPKCS5PEMFromRSAKey(pkey,n)}else{q=this.getEncryptedPKCS5PEMFromRSAKey(pkey,n,s)}return q},getRSAKeyFromPlainPKCS8PEM:function(p){if(p.match(/ENCRYPTED/)){throw""pem shall be not ENCRYPTED""}var o=this.getHexFromPEM(p,""PRIVATE KEY"");var n=this.getRSAKeyFromPlainPKCS8Hex(o);return n},getRSAKeyFromPlainPKCS8Hex:function(q){var p=ASN1HEX.getPosArrayOfChildren_AtObj(q,0);if(p.length!=3){throw""outer DERSequence shall have 3 elements: ""+p.length}var o=ASN1HEX.getHexOfTLV_AtObj(q,p[1]);if(o!=""300d06092a864886f70d0101010500""){throw""PKCS8 AlgorithmIdentifier is not rsaEnc: ""+o}var o=ASN1HEX.getHexOfTLV_AtObj(q,p[1]);var r=ASN1HEX.getHexOfTLV_AtObj(q,p[2]);var s=ASN1HEX.getHexOfV_AtObj(r,0);var n=new RSAKey();n.readPrivateKeyFromASN1HexString(s);return n},parseHexOfEncryptedPKCS8:function(u){var q={};var p=ASN1HEX.getPosArrayOfChildren_AtObj(u,0);if(p.length!=2){throw""malformed format: SEQUENCE(0).items != 2: ""+p.length}q.ciphertext=ASN1HEX.getHexOfV_AtObj(u,p[1]);var w=ASN1HEX.getPosArrayOfChildren_AtObj(u,p[0]);if(w.length!=2){throw""malformed format: SEQUENCE(0.0).items != 2: ""+w.length}if(ASN1HEX.getHexOfV_AtObj(u,w[0])!=""2a864886f70d01050d""){throw""this only supports pkcs5PBES2""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(u,w[1]);if(w.length!=2){throw""malformed format: SEQUENCE(0.0.1).items != 2: ""+n.length}var o=ASN1HEX.getPosArrayOfChildren_AtObj(u,n[1]);if(o.length!=2){throw""malformed format: SEQUENCE(0.0.1.1).items != 2: ""+o.length}if(ASN1HEX.getHexOfV_AtObj(u,o[0])!=""2a864886f70d0307""){throw""this only supports TripleDES""}q.encryptionSchemeAlg=""TripleDES"";q.encryptionSchemeIV=ASN1HEX.getHexOfV_AtObj(u,o[1]);var r=ASN1HEX.getPosArrayOfChildren_AtObj(u,n[0]);if(r.length!=2){throw""malformed format: SEQUENCE(0.0.1.0).items != 2: ""+r.length}if(ASN1HEX.getHexOfV_AtObj(u,r[0])!=""2a864886f70d01050c""){throw""this only supports pkcs5PBKDF2""}var v=ASN1HEX.getPosArrayOfChildren_AtObj(u,r[1]);if(v.length<2){throw""malformed format: SEQUENCE(0.0.1.0.1).items < 2: ""+v.length}q.pbkdf2Salt=ASN1HEX.getHexOfV_AtObj(u,v[0]);var s=ASN1HEX.getHexOfV_AtObj(u,v[1]);try{q.pbkdf2Iter=parseInt(s,16)}catch(t){throw""malformed format pbkdf2Iter: ""+s}return q},getPBKDF2KeyHexFromParam:function(s,n){var r=CryptoJS.enc.Hex.parse(s.pbkdf2Salt);var o=s.pbkdf2Iter;var q=CryptoJS.PBKDF2(n,r,{keySize:192/32,iterations:o});var p=CryptoJS.enc.Hex.stringify(q);return p},getPlainPKCS8HexFromEncryptedPKCS8PEM:function(v,w){var p=this.getHexFromPEM(v,""ENCRYPTED PRIVATE KEY"");var n=this.parseHexOfEncryptedPKCS8(p);var s=PKCS5PKEY.getPBKDF2KeyHexFromParam(n,w);var t={};t.ciphertext=CryptoJS.enc.Hex.parse(n.ciphertext);var r=CryptoJS.enc.Hex.parse(s);var q=CryptoJS.enc.Hex.parse(n.encryptionSchemeIV);var u=CryptoJS.TripleDES.decrypt(t,r,{iv:q});var o=CryptoJS.enc.Hex.stringify(u);return o},getRSAKeyFromEncryptedPKCS8PEM:function(q,p){var o=this.getPlainPKCS8HexFromEncryptedPKCS8PEM(q,p);var n=this.getRSAKeyFromPlainPKCS8Hex(o);return n},getKeyFromEncryptedPKCS8PEM:function(q,o){var n=this.getPlainPKCS8HexFromEncryptedPKCS8PEM(q,o);var p=this.getKeyFromPlainPrivatePKCS8Hex(n);return p},parsePlainPrivatePKCS8Hex:function(q){var o={};o.algparam=null;if(q.substr(0,2)!=""30""){throw""malformed plain PKCS8 private key(code:001)""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(q,0);if(p.length!=3){throw""malformed plain PKCS8 private key(code:002)""}if(q.substr(p[1],2)!=""30""){throw""malformed PKCS8 private key(code:003)""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(q,p[1]);if(n.length!=2){throw""malformed PKCS8 private key(code:004)""}if(q.substr(n[0],2)!=""06""){throw""malformed PKCS8 private key(code:005)""}o.algoid=ASN1HEX.getHexOfV_AtObj(q,n[0]);if(q.substr(n[1],2)==""06""){o.algparam=ASN1HEX.getHexOfV_AtObj(q,n[1])}if(q.substr(p[2],2)!=""04""){throw""malformed PKCS8 private key(code:006)""}o.keyidx=ASN1HEX.getStartPosOfV_AtObj(q,p[2]);return o},getKeyFromPlainPrivatePKCS8PEM:function(o){var n=this.getHexFromPEM(o,""PRIVATE KEY"");var p=this.getKeyFromPlainPrivatePKCS8Hex(n);return p},getKeyFromPlainPrivatePKCS8Hex:function(n){var p=this.parsePlainPrivatePKCS8Hex(n);if(p.algoid==""2a864886f70d010101""){this.parsePrivateRawRSAKeyHexAtObj(n,p);var o=p.key;var q=new RSAKey();q.setPrivateEx(o.n,o.e,o.d,o.p,o.q,o.dp,o.dq,o.co);return q}else{if(p.algoid==""2a8648ce3d0201""){this.parsePrivateRawECKeyHexAtObj(n,p);if(KJUR.crypto.OID.oidhex2name[p.algparam]===undefined){throw""KJUR.crypto.OID.oidhex2name undefined: ""+p.algparam}var r=KJUR.crypto.OID.oidhex2name[p.algparam];var q=new KJUR.crypto.ECDSA({curve:r,prv:p.key});return q}else{throw""unsupported private key algorithm""}}},getRSAKeyFromPublicPKCS8PEM:function(o){var p=this.getHexFromPEM(o,""PUBLIC KEY"");var n=this.getRSAKeyFromPublicPKCS8Hex(p);return n},getKeyFromPublicPKCS8PEM:function(o){var p=this.getHexFromPEM(o,""PUBLIC KEY"");var n=this.getKeyFromPublicPKCS8Hex(p);return n},getKeyFromPublicPKCS8Hex:function(o){var n=this.parsePublicPKCS8Hex(o);if(n.algoid==""2a864886f70d010101""){var r=this.parsePublicRawRSAKeyHex(n.key);var p=new RSAKey();p.setPublic(r.n,r.e);return p}else{if(n.algoid==""2a8648ce3d0201""){if(KJUR.crypto.OID.oidhex2name[n.algparam]===undefined){throw""KJUR.crypto.OID.oidhex2name undefined: ""+n.algparam}var q=KJUR.crypto.OID.oidhex2name[n.algparam];var p=new KJUR.crypto.ECDSA({curve:q,pub:n.key});return p}else{throw""unsupported public key algorithm""}}},parsePublicRawRSAKeyHex:function(p){var n={};if(p.substr(0,2)!=""30""){throw""malformed RSA key(code:001)""}var o=ASN1HEX.getPosArrayOfChildren_AtObj(p,0);if(o.length!=2){throw""malformed RSA key(code:002)""}if(p.substr(o[0],2)!=""02""){throw""malformed RSA key(code:003)""}n.n=ASN1HEX.getHexOfV_AtObj(p,o[0]);if(p.substr(o[1],2)!=""02""){throw""malformed RSA key(code:004)""}n.e=ASN1HEX.getHexOfV_AtObj(p,o[1]);return n},parsePrivateRawRSAKeyHexAtObj:function(o,q){var p=q.keyidx;if(o.substr(p,2)!=""30""){throw""malformed RSA private key(code:001)""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(o,p);if(n.length!=9){throw""malformed RSA private key(code:002)""}q.key={};q.key.n=ASN1HEX.getHexOfV_AtObj(o,n[1]);q.key.e=ASN1HEX.getHexOfV_AtObj(o,n[2]);q.key.d=ASN1HEX.getHexOfV_AtObj(o,n[3]);q.key.p=ASN1HEX.getHexOfV_AtObj(o,n[4]);q.key.q=ASN1HEX.getHexOfV_AtObj(o,n[5]);q.key.dp=ASN1HEX.getHexOfV_AtObj(o,n[6]);q.key.dq=ASN1HEX.getHexOfV_AtObj(o,n[7]);q.key.co=ASN1HEX.getHexOfV_AtObj(o,n[8])},parsePrivateRawECKeyHexAtObj:function(o,q){var p=q.keyidx;if(o.substr(p,2)!=""30""){throw""malformed ECC private key(code:001)""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(o,p);if(n.length!=3){throw""malformed ECC private key(code:002)""}if(o.substr(n[1],2)!=""04""){throw""malformed ECC private key(code:003)""}q.key=ASN1HEX.getHexOfV_AtObj(o,n[1])},parsePublicPKCS8Hex:function(q){var o={};o.algparam=null;var p=ASN1HEX.getPosArrayOfChildren_AtObj(q,0);if(p.length!=2){throw""outer DERSequence shall have 2 elements: ""+p.length}var r=p[0];if(q.substr(r,2)!=""30""){throw""malformed PKCS8 public key(code:001)""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(q,r);if(n.length!=2){throw""malformed PKCS8 public key(code:002)""}if(q.substr(n[0],2)!=""06""){throw""malformed PKCS8 public key(code:003)""}o.algoid=ASN1HEX.getHexOfV_AtObj(q,n[0]);if(q.substr(n[1],2)==""06""){o.algparam=ASN1HEX.getHexOfV_AtObj(q,n[1])}if(q.substr(p[1],2)!=""03""){throw""malformed PKCS8 public key(code:004)""}o.key=ASN1HEX.getHexOfV_AtObj(q,p[1]).substr(2);return o},getRSAKeyFromPublicPKCS8Hex:function(r){var q=ASN1HEX.getPosArrayOfChildren_AtObj(r,0);if(q.length!=2){throw""outer DERSequence shall have 2 elements: ""+q.length}var p=ASN1HEX.getHexOfTLV_AtObj(r,q[0]);if(p!=""300d06092a864886f70d0101010500""){throw""PKCS8 AlgorithmId is not rsaEncryption""}if(r.substr(q[1],2)!=""03""){throw""PKCS8 Public Key is not BITSTRING encapslated.""}var t=ASN1HEX.getStartPosOfV_AtObj(r,q[1])+2;if(r.substr(t,2)!=""30""){throw""PKCS8 Public Key is not SEQUENCE.""}var n=ASN1HEX.getPosArrayOfChildren_AtObj(r,t);if(n.length!=2){throw""inner DERSequence shall have 2 elements: ""+n.length}if(r.substr(n[0],2)!=""02""){throw""N is not ASN.1 INTEGER""}if(r.substr(n[1],2)!=""02""){throw""E is not ASN.1 INTEGER""}var u=ASN1HEX.getHexOfV_AtObj(r,n[0]);var s=ASN1HEX.getHexOfV_AtObj(r,n[1]);var o=new RSAKey();o.setPublic(u,s);return o},}}(); /*! keyutil-1.0.7.js (c) 2013-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ var KEYUTIL=function(){var d=function(p,r,q){return k(CryptoJS.AES,p,r,q)};var e=function(p,r,q){return k(CryptoJS.TripleDES,p,r,q)};var a=function(p,r,q){return k(CryptoJS.DES,p,r,q)};var k=function(s,x,u,q){var r=CryptoJS.enc.Hex.parse(x);var w=CryptoJS.enc.Hex.parse(u);var p=CryptoJS.enc.Hex.parse(q);var t={};t.key=w;t.iv=p;t.ciphertext=r;var v=s.decrypt(t,w,{iv:p});return CryptoJS.enc.Hex.stringify(v)};var l=function(p,r,q){return g(CryptoJS.AES,p,r,q)};var o=function(p,r,q){return g(CryptoJS.TripleDES,p,r,q)};var f=function(p,r,q){return g(CryptoJS.DES,p,r,q)};var g=function(t,y,v,q){var s=CryptoJS.enc.Hex.parse(y);var x=CryptoJS.enc.Hex.parse(v);var p=CryptoJS.enc.Hex.parse(q);var w=t.encrypt(s,x,{iv:p});var r=CryptoJS.enc.Hex.parse(w.toString());var u=CryptoJS.enc.Base64.stringify(r);return u};var i={""AES-256-CBC"":{proc:d,eproc:l,keylen:32,ivlen:16},""AES-192-CBC"":{proc:d,eproc:l,keylen:24,ivlen:16},""AES-128-CBC"":{proc:d,eproc:l,keylen:16,ivlen:16},""DES-EDE3-CBC"":{proc:e,eproc:o,keylen:24,ivlen:8},""DES-CBC"":{proc:a,eproc:f,keylen:8,ivlen:8}};var c=function(p){return i[p][""proc""]};var m=function(p){var r=CryptoJS.lib.WordArray.random(p);var q=CryptoJS.enc.Hex.stringify(r);return q};var n=function(t){var u={};if(t.match(new RegExp(""DEK-Info: ([^,]+),([0-9A-Fa-f]+)"",""m""))){u.cipher=RegExp.$1;u.ivsalt=RegExp.$2}if(t.match(new RegExp(""-----BEGIN ([A-Z]+) PRIVATE KEY-----""))){u.type=RegExp.$1}var r=-1;var v=0;if(t.indexOf(""\r\n\r\n"")!=-1){r=t.indexOf(""\r\n\r\n"");v=2}if(t.indexOf(""\n\n"")!=-1){r=t.indexOf(""\n\n"");v=1}var q=t.indexOf(""-----END"");if(r!=-1&&q!=-1){var p=t.substring(r+v*2,q-v);p=p.replace(/\s+/g,"""");u.data=p}return u};var j=function(q,y,p){var v=p.substring(0,16);var t=CryptoJS.enc.Hex.parse(v);var r=CryptoJS.enc.Utf8.parse(y);var u=i[q][""keylen""]+i[q][""ivlen""];var x="""";var w=null;for(;;){var s=CryptoJS.algo.MD5.create();if(w!=null){s.update(w)}s.update(r);s.update(t);w=s.finalize();x=x+CryptoJS.enc.Hex.stringify(w);if(x.length>=u*2){break}}var z={};z.keyhex=x.substr(0,i[q][""keylen""]*2);z.ivhex=x.substr(i[q][""keylen""]*2,i[q][""ivlen""]*2);return z};var b=function(p,v,r,w){var s=CryptoJS.enc.Base64.parse(p);var q=CryptoJS.enc.Hex.stringify(s);var u=i[v][""proc""];var t=u(q,r,w);return t};var h=function(p,s,q,u){var r=i[s][""eproc""];var t=r(p,q,u);return t};return{version:""1.0.0"",getHexFromPEM:function(q,u){var r=q;if(r.indexOf(""-----BEGIN "")==-1){throw""can't find PEM header: ""+u}if(typeof u==""string""&&u!=""""){r=r.replace(""-----BEGIN ""+u+""-----"","""");r=r.replace(""-----END ""+u+""-----"","""")}else{r=r.replace(/-----BEGIN [^-]+-----/,"""");r=r.replace(/-----END [^-]+-----/,"""")}var t=r.replace(/\s+/g,"""");var p=b64tohex(t);return p},getDecryptedKeyHexByKeyIV:function(q,t,s,r){var p=c(t);return p(q,s,r)},parsePKCS5PEM:function(p){return n(p)},getKeyAndUnusedIvByPasscodeAndIvsalt:function(q,p,r){return j(q,p,r)},decryptKeyB64:function(p,r,q,s){return b(p,r,q,s)},getDecryptedKeyHex:function(y,x){var q=n(y);var t=q.type;var r=q.cipher;var p=q.ivsalt;var s=q.data;var w=j(r,x,p);var v=w.keyhex;var u=b(s,r,v,p);return u},getRSAKeyFromEncryptedPKCS5PEM:function(r,q){var s=this.getDecryptedKeyHex(r,q);var p=new RSAKey();p.readPrivateKeyFromASN1HexString(s);return p},getEncryptedPKCS5PEMFromPrvKeyHex:function(x,s,A,t,r){var p="""";if(typeof t==""undefined""||t==null){t=""AES-256-CBC""}if(typeof i[t]==""undefined""){throw""KEYUTIL unsupported algorithm: ""+t}if(typeof r==""undefined""||r==null){var v=i[t][""ivlen""];var u=m(v);r=u.toUpperCase()}var z=j(t,A,r);var y=z.keyhex;var w=h(s,t,y,r);var q=w.replace(/(.{64})/g,""$1\r\n"");var p=""-----BEGIN ""+x+"" PRIVATE KEY-----\r\n"";p+=""Proc-Type: 4,ENCRYPTED\r\n"";p+=""DEK-Info: ""+t+"",""+r+""\r\n"";p+=""\r\n"";p+=q;p+=""\r\n-----END ""+x+"" PRIVATE KEY-----\r\n"";return p},getEncryptedPKCS5PEMFromRSAKey:function(D,E,r,t){var B=new KJUR.asn1.DERInteger({""int"":0});var w=new KJUR.asn1.DERInteger({bigint:D.n});var A=new KJUR.asn1.DERInteger({""int"":D.e});var C=new KJUR.asn1.DERInteger({bigint:D.d});var u=new KJUR.asn1.DERInteger({bigint:D.p});var s=new KJUR.asn1.DERInteger({bigint:D.q});var z=new KJUR.asn1.DERInteger({bigint:D.dmp1});var v=new KJUR.asn1.DERInteger({bigint:D.dmq1});var y=new KJUR.asn1.DERInteger({bigint:D.coeff});var F=new KJUR.asn1.DERSequence({array:[B,w,A,C,u,s,z,v,y]});var x=F.getEncodedHex();return this.getEncryptedPKCS5PEMFromPrvKeyHex(""RSA"",x,E,r,t)},newEncryptedPKCS5PEM:function(p,q,t,u){if(typeof q==""undefined""||q==null){q=1024}if(typeof t==""undefined""||t==null){t=""10001""}var r=new RSAKey();r.generate(q,t);var s=null;if(typeof u==""undefined""||u==null){s=this.getEncryptedPKCS5PEMFromRSAKey(r,p)}else{s=this.getEncryptedPKCS5PEMFromRSAKey(r,p,u)}return s},getRSAKeyFromPlainPKCS8PEM:function(r){if(r.match(/ENCRYPTED/)){throw""pem shall be not ENCRYPTED""}var q=this.getHexFromPEM(r,""PRIVATE KEY"");var p=this.getRSAKeyFromPlainPKCS8Hex(q);return p},getRSAKeyFromPlainPKCS8Hex:function(s){var r=ASN1HEX.getPosArrayOfChildren_AtObj(s,0);if(r.length!=3){throw""outer DERSequence shall have 3 elements: ""+r.length}var q=ASN1HEX.getHexOfTLV_AtObj(s,r[1]);if(q!=""300d06092a864886f70d0101010500""){throw""PKCS8 AlgorithmIdentifier is not rsaEnc: ""+q}var q=ASN1HEX.getHexOfTLV_AtObj(s,r[1]);var t=ASN1HEX.getHexOfTLV_AtObj(s,r[2]);var u=ASN1HEX.getHexOfV_AtObj(t,0);var p=new RSAKey();p.readPrivateKeyFromASN1HexString(u);return p},parseHexOfEncryptedPKCS8:function(w){var s={};var r=ASN1HEX.getPosArrayOfChildren_AtObj(w,0);if(r.length!=2){throw""malformed format: SEQUENCE(0).items != 2: ""+r.length}s.ciphertext=ASN1HEX.getHexOfV_AtObj(w,r[1]);var y=ASN1HEX.getPosArrayOfChildren_AtObj(w,r[0]);if(y.length!=2){throw""malformed format: SEQUENCE(0.0).items != 2: ""+y.length}if(ASN1HEX.getHexOfV_AtObj(w,y[0])!=""2a864886f70d01050d""){throw""this only supports pkcs5PBES2""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(w,y[1]);if(y.length!=2){throw""malformed format: SEQUENCE(0.0.1).items != 2: ""+p.length}var q=ASN1HEX.getPosArrayOfChildren_AtObj(w,p[1]);if(q.length!=2){throw""malformed format: SEQUENCE(0.0.1.1).items != 2: ""+q.length}if(ASN1HEX.getHexOfV_AtObj(w,q[0])!=""2a864886f70d0307""){throw""this only supports TripleDES""}s.encryptionSchemeAlg=""TripleDES"";s.encryptionSchemeIV=ASN1HEX.getHexOfV_AtObj(w,q[1]);var t=ASN1HEX.getPosArrayOfChildren_AtObj(w,p[0]);if(t.length!=2){throw""malformed format: SEQUENCE(0.0.1.0).items != 2: ""+t.length}if(ASN1HEX.getHexOfV_AtObj(w,t[0])!=""2a864886f70d01050c""){throw""this only supports pkcs5PBKDF2""}var x=ASN1HEX.getPosArrayOfChildren_AtObj(w,t[1]);if(x.length<2){throw""malformed format: SEQUENCE(0.0.1.0.1).items < 2: ""+x.length}s.pbkdf2Salt=ASN1HEX.getHexOfV_AtObj(w,x[0]);var u=ASN1HEX.getHexOfV_AtObj(w,x[1]);try{s.pbkdf2Iter=parseInt(u,16)}catch(v){throw""malformed format pbkdf2Iter: ""+u}return s},getPBKDF2KeyHexFromParam:function(u,p){var t=CryptoJS.enc.Hex.parse(u.pbkdf2Salt);var q=u.pbkdf2Iter;var s=CryptoJS.PBKDF2(p,t,{keySize:192/32,iterations:q});var r=CryptoJS.enc.Hex.stringify(s);return r},getPlainPKCS8HexFromEncryptedPKCS8PEM:function(x,y){var r=this.getHexFromPEM(x,""ENCRYPTED PRIVATE KEY"");var p=this.parseHexOfEncryptedPKCS8(r);var u=KEYUTIL.getPBKDF2KeyHexFromParam(p,y);var v={};v.ciphertext=CryptoJS.enc.Hex.parse(p.ciphertext);var t=CryptoJS.enc.Hex.parse(u);var s=CryptoJS.enc.Hex.parse(p.encryptionSchemeIV);var w=CryptoJS.TripleDES.decrypt(v,t,{iv:s});var q=CryptoJS.enc.Hex.stringify(w);return q},getRSAKeyFromEncryptedPKCS8PEM:function(s,r){var q=this.getPlainPKCS8HexFromEncryptedPKCS8PEM(s,r);var p=this.getRSAKeyFromPlainPKCS8Hex(q);return p},getKeyFromEncryptedPKCS8PEM:function(s,q){var p=this.getPlainPKCS8HexFromEncryptedPKCS8PEM(s,q);var r=this.getKeyFromPlainPrivatePKCS8Hex(p);return r},parsePlainPrivatePKCS8Hex:function(s){var q={};q.algparam=null;if(s.substr(0,2)!=""30""){throw""malformed plain PKCS8 private key(code:001)""}var r=ASN1HEX.getPosArrayOfChildren_AtObj(s,0);if(r.length!=3){throw""malformed plain PKCS8 private key(code:002)""}if(s.substr(r[1],2)!=""30""){throw""malformed PKCS8 private key(code:003)""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(s,r[1]);if(p.length!=2){throw""malformed PKCS8 private key(code:004)""}if(s.substr(p[0],2)!=""06""){throw""malformed PKCS8 private key(code:005)""}q.algoid=ASN1HEX.getHexOfV_AtObj(s,p[0]);if(s.substr(p[1],2)==""06""){q.algparam=ASN1HEX.getHexOfV_AtObj(s,p[1])}if(s.substr(r[2],2)!=""04""){throw""malformed PKCS8 private key(code:006)""}q.keyidx=ASN1HEX.getStartPosOfV_AtObj(s,r[2]);return q},getKeyFromPlainPrivatePKCS8PEM:function(q){var p=this.getHexFromPEM(q,""PRIVATE KEY"");var r=this.getKeyFromPlainPrivatePKCS8Hex(p);return r},getKeyFromPlainPrivatePKCS8Hex:function(p){var w=this.parsePlainPrivatePKCS8Hex(p);if(w.algoid==""2a864886f70d010101""){this.parsePrivateRawRSAKeyHexAtObj(p,w);var u=w.key;var z=new RSAKey();z.setPrivateEx(u.n,u.e,u.d,u.p,u.q,u.dp,u.dq,u.co);return z}else{if(w.algoid==""2a8648ce3d0201""){this.parsePrivateRawECKeyHexAtObj(p,w);if(KJUR.crypto.OID.oidhex2name[w.algparam]===undefined){throw""KJUR.crypto.OID.oidhex2name undefined: ""+w.algparam}var v=KJUR.crypto.OID.oidhex2name[w.algparam];var z=new KJUR.crypto.ECDSA({curve:v});z.setPublicKeyHex(w.pubkey);z.setPrivateKeyHex(w.key);z.isPublic=false;return z}else{if(w.algoid==""2a8648ce380401""){var t=ASN1HEX.getVbyList(p,0,[1,1,0],""02"");var s=ASN1HEX.getVbyList(p,0,[1,1,1],""02"");var y=ASN1HEX.getVbyList(p,0,[1,1,2],""02"");var B=ASN1HEX.getVbyList(p,0,[2,0],""02"");var r=new BigInteger(t,16);var q=new BigInteger(s,16);var x=new BigInteger(y,16);var A=new BigInteger(B,16);var z=new KJUR.crypto.DSA();z.setPrivate(r,q,x,null,A);return z}else{throw""unsupported private key algorithm""}}}},getRSAKeyFromPublicPKCS8PEM:function(q){var r=this.getHexFromPEM(q,""PUBLIC KEY"");var p=this.getRSAKeyFromPublicPKCS8Hex(r);return p},getKeyFromPublicPKCS8PEM:function(q){var r=this.getHexFromPEM(q,""PUBLIC KEY"");var p=this.getKeyFromPublicPKCS8Hex(r);return p},getKeyFromPublicPKCS8Hex:function(q){var p=this.parsePublicPKCS8Hex(q);if(p.algoid==""2a864886f70d010101""){var u=this.parsePublicRawRSAKeyHex(p.key);var r=new RSAKey();r.setPublic(u.n,u.e);return r}else{if(p.algoid==""2a8648ce3d0201""){if(KJUR.crypto.OID.oidhex2name[p.algparam]===undefined){throw""KJUR.crypto.OID.oidhex2name undefined: ""+p.algparam}var s=KJUR.crypto.OID.oidhex2name[p.algparam];var r=new KJUR.crypto.ECDSA({curve:s,pub:p.key});return r}else{if(p.algoid==""2a8648ce380401""){var t=p.algparam;var v=ASN1HEX.getHexOfV_AtObj(p.key,0);var r=new KJUR.crypto.DSA();r.setPublic(new BigInteger(t.p,16),new BigInteger(t.q,16),new BigInteger(t.g,16),new BigInteger(v,16));return r}else{throw""unsupported public key algorithm""}}}},parsePublicRawRSAKeyHex:function(r){var p={};if(r.substr(0,2)!=""30""){throw""malformed RSA key(code:001)""}var q=ASN1HEX.getPosArrayOfChildren_AtObj(r,0);if(q.length!=2){throw""malformed RSA key(code:002)""}if(r.substr(q[0],2)!=""02""){throw""malformed RSA key(code:003)""}p.n=ASN1HEX.getHexOfV_AtObj(r,q[0]);if(r.substr(q[1],2)!=""02""){throw""malformed RSA key(code:004)""}p.e=ASN1HEX.getHexOfV_AtObj(r,q[1]);return p},parsePrivateRawRSAKeyHexAtObj:function(q,s){var r=s.keyidx;if(q.substr(r,2)!=""30""){throw""malformed RSA private key(code:001)""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(q,r);if(p.length!=9){throw""malformed RSA private key(code:002)""}s.key={};s.key.n=ASN1HEX.getHexOfV_AtObj(q,p[1]);s.key.e=ASN1HEX.getHexOfV_AtObj(q,p[2]);s.key.d=ASN1HEX.getHexOfV_AtObj(q,p[3]);s.key.p=ASN1HEX.getHexOfV_AtObj(q,p[4]);s.key.q=ASN1HEX.getHexOfV_AtObj(q,p[5]);s.key.dp=ASN1HEX.getHexOfV_AtObj(q,p[6]);s.key.dq=ASN1HEX.getHexOfV_AtObj(q,p[7]);s.key.co=ASN1HEX.getHexOfV_AtObj(q,p[8])},parsePrivateRawECKeyHexAtObj:function(p,t){var q=t.keyidx;var r=ASN1HEX.getVbyList(p,q,[1],""04"");var s=ASN1HEX.getVbyList(p,q,[2,0],""03"").substr(2);t.key=r;t.pubkey=s},parsePublicPKCS8Hex:function(s){var q={};q.algparam=null;var r=ASN1HEX.getPosArrayOfChildren_AtObj(s,0);if(r.length!=2){throw""outer DERSequence shall have 2 elements: ""+r.length}var t=r[0];if(s.substr(t,2)!=""30""){throw""malformed PKCS8 public key(code:001)""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(s,t);if(p.length!=2){throw""malformed PKCS8 public key(code:002)""}if(s.substr(p[0],2)!=""06""){throw""malformed PKCS8 public key(code:003)""}q.algoid=ASN1HEX.getHexOfV_AtObj(s,p[0]);if(s.substr(p[1],2)==""06""){q.algparam=ASN1HEX.getHexOfV_AtObj(s,p[1])}else{if(s.substr(p[1],2)==""30""){q.algparam={};q.algparam.p=ASN1HEX.getVbyList(s,p[1],[0],""02"");q.algparam.q=ASN1HEX.getVbyList(s,p[1],[1],""02"");q.algparam.g=ASN1HEX.getVbyList(s,p[1],[2],""02"")}}if(s.substr(r[1],2)!=""03""){throw""malformed PKCS8 public key(code:004)""}q.key=ASN1HEX.getHexOfV_AtObj(s,r[1]).substr(2);return q},getRSAKeyFromPublicPKCS8Hex:function(t){var s=ASN1HEX.getPosArrayOfChildren_AtObj(t,0);if(s.length!=2){throw""outer DERSequence shall have 2 elements: ""+s.length}var r=ASN1HEX.getHexOfTLV_AtObj(t,s[0]);if(r!=""300d06092a864886f70d0101010500""){throw""PKCS8 AlgorithmId is not rsaEncryption""}if(t.substr(s[1],2)!=""03""){throw""PKCS8 Public Key is not BITSTRING encapslated.""}var v=ASN1HEX.getStartPosOfV_AtObj(t,s[1])+2;if(t.substr(v,2)!=""30""){throw""PKCS8 Public Key is not SEQUENCE.""}var p=ASN1HEX.getPosArrayOfChildren_AtObj(t,v);if(p.length!=2){throw""inner DERSequence shall have 2 elements: ""+p.length}if(t.substr(p[0],2)!=""02""){throw""N is not ASN.1 INTEGER""}if(t.substr(p[1],2)!=""02""){throw""E is not ASN.1 INTEGER""}var w=ASN1HEX.getHexOfV_AtObj(t,p[0]);var u=ASN1HEX.getHexOfV_AtObj(t,p[1]);var q=new RSAKey();q.setPublic(w,u);return q},}}();KEYUTIL.getKey=function(c,o,i){if(typeof RSAKey!=""undefined""&&c instanceof RSAKey){return c}if(typeof KJUR.crypto.ECDSA!=""undefined""&&c instanceof KJUR.crypto.ECDSA){return c}if(typeof KJUR.crypto.DSA!=""undefined""&&c instanceof KJUR.crypto.DSA){return c}if(c.xy!==undefined&&c.curve!==undefined){return new KJUR.crypto.ECDSA({prv:c.xy,curve:c.curve})}if(c.n!==undefined&&c.e!==undefined&&c.d!==undefined&&c.p!==undefined&&c.q!==undefined&&c.dp!==undefined&&c.dq!==undefined&&c.co!==undefined){var n=new RSAKey();n.setPrivateEx(c.n,c.e,c.d,c.p,c.q,c.dp,c.dq,c.co);return n}if(c.p!==undefined&&c.q!==undefined&&c.g!==undefined&&c.y!==undefined&&c.x!==undefined){var n=new KJUR.crypto.DSA();n.setPrivate(c.p,c.q,c.g,c.y,c.x);return n}if(c.d!==undefined&&c.curve!==undefined){return new KJUR.crypto.ECDSA({pub:c.d,curve:c.curve})}if(c.n!==undefined&&c.e){var n=new RSAKey();n.setPublic(c.n,c.e);return n}if(c.p!==undefined&&c.q!==undefined&&c.g!==undefined&&c.y!==undefined&&c.x===undefined){var n=new KJUR.crypto.DSA();n.setPublic(c.p,c.q,c.g,c.y);return n}if(c.indexOf(""-END CERTIFICATE-"",0)!=-1||c.indexOf(""-END X509 CERTIFICATE-"",0)!=-1||c.indexOf(""-END TRUSTED CERTIFICATE-"",0)!=-1){return X509.getPublicKeyFromCertPEM(c)}if(i===""pkcs8pub""){return KEYUTIL.getKeyFromPublicPKCS8Hex(c)}if(c.indexOf(""-END PUBLIC KEY-"")!=-1){return KEYUTIL.getKeyFromPublicPKCS8PEM(c)}if(i===""pkcs5prv""){var n=new RSAKey();n.readPrivateKeyFromASN1HexString(c);return n}if(i===""pkcs5prv""){var n=new RSAKey();n.readPrivateKeyFromASN1HexString(c);return n}if(c.indexOf(""-END RSA PRIVATE KEY-"")!=-1&&c.indexOf(""4,ENCRYPTED"")==-1){var n=new RSAKey();n.readPrivateKeyFromPEMString(c);return n}if(c.indexOf(""-END DSA PRIVATE KEY-"")!=-1&&c.indexOf(""4,ENCRYPTED"")==-1){var m=this.getHexFromPEM(c,""DSA PRIVATE KEY"");var b=ASN1HEX.getVbyList(m,0,[1],""02"");var a=ASN1HEX.getVbyList(m,0,[2],""02"");var e=ASN1HEX.getVbyList(m,0,[3],""02"");var k=ASN1HEX.getVbyList(m,0,[4],""02"");var l=ASN1HEX.getVbyList(m,0,[5],""02"");var n=new KJUR.crypto.DSA();n.setPrivate(new BigInteger(b,16),new BigInteger(a,16),new BigInteger(e,16),new BigInteger(k,16),new BigInteger(l,16));return n}if(c.indexOf(""-END PRIVATE KEY-"")!=-1){return KEYUTIL.getKeyFromPlainPrivatePKCS8PEM(c)}if(c.indexOf(""-END RSA PRIVATE KEY-"")!=-1&&c.indexOf(""4,ENCRYPTED"")!=-1){return KEYUTIL.getRSAKeyFromEncryptedPKCS5PEM(c,o)}if(c.indexOf(""-END EC PRIVATE KEY-"")!=-1&&c.indexOf(""4,ENCRYPTED"")!=-1){var m=KEYUTIL.getDecryptedKeyHex(c,o);var n=ASN1HEX.getVbyList(m,0,[1],""04"");var j=ASN1HEX.getVbyList(m,0,[2,0],""06"");var d=ASN1HEX.getVbyList(m,0,[3,0],""03"").substr(2);var h="""";if(KJUR.crypto.OID.oidhex2name[j]!==undefined){h=KJUR.crypto.OID.oidhex2name[j]}else{throw""undefined OID(hex) in KJUR.crypto.OID: ""+j}var f=new KJUR.crypto.ECDSA({name:h});f.setPublicKeyHex(d);f.setPrivateKeyHex(n);f.isPublic=false;return f}if(c.indexOf(""-END DSA PRIVATE KEY-"")!=-1&&c.indexOf(""4,ENCRYPTED"")!=-1){var m=KEYUTIL.getDecryptedKeyHex(c,o);var b=ASN1HEX.getVbyList(m,0,[1],""02"");var a=ASN1HEX.getVbyList(m,0,[2],""02"");var e=ASN1HEX.getVbyList(m,0,[3],""02"");var k=ASN1HEX.getVbyList(m,0,[4],""02"");var l=ASN1HEX.getVbyList(m,0,[5],""02"");var n=new KJUR.crypto.DSA();n.setPrivate(new BigInteger(b,16),new BigInteger(a,16),new BigInteger(e,16),new BigInteger(k,16),new BigInteger(l,16));return n}if(c.indexOf(""-END ENCRYPTED PRIVATE KEY-"")!=-1){return KEYUTIL.getKeyFromEncryptedPKCS8PEM(c,o)}throw""not supported argument""};KEYUTIL.generateKeypair=function(a,c){if(a==""RSA""){var b=c;var h=new RSAKey();h.generate(b,""10001"");h.isPrivate=true;h.isPublic=true;var f=new RSAKey();var e=h.n.toString(16);var i=h.e.toString(16);f.setPublic(e,i);f.isPrivate=false;f.isPublic=true;var k={};k.prvKeyObj=h;k.pubKeyObj=f;return k}else{if(a==""EC""){var d=c;var g=new KJUR.crypto.ECDSA({curve:d});var j=g.generateKeyPairHex();var h=new KJUR.crypto.ECDSA({curve:d});h.setPrivateKeyHex(j.ecprvhex);h.isPrivate=true;h.isPublic=false;var f=new KJUR.crypto.ECDSA({curve:d});f.setPublicKeyHex(j.ecpubhex);f.isPrivate=false;f.isPublic=true;var k={};k.prvKeyObj=h;k.pubKeyObj=f;return k}else{throw""unknown algorithm: ""+a}}};KEYUTIL.getPEM=function(a,r,o,g,j){var v=KJUR.asn1;var u=KJUR.crypto;function p(s){var w=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":0},{""int"":{bigint:s.n}},{""int"":s.e},{""int"":{bigint:s.d}},{""int"":{bigint:s.p}},{""int"":{bigint:s.q}},{""int"":{bigint:s.dmp1}},{""int"":{bigint:s.dmq1}},{""int"":{bigint:s.coeff}}]});return w}function q(w){var s=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":1},{octstr:{hex:w.prvKeyHex}},{tag:[""a0"",true,{oid:{name:w.curveName}}]},{tag:[""a1"",true,{bitstr:{hex:""00""+w.pubKeyHex}}]}]});return s}function n(s){var w=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":0},{""int"":{bigint:s.p}},{""int"":{bigint:s.q}},{""int"":{bigint:s.g}},{""int"":{bigint:s.y}},{""int"":{bigint:s.x}}]});return w}if(((typeof RSAKey!=""undefined""&&a instanceof RSAKey)||(typeof u.DSA!=""undefined""&&a instanceof u.DSA)||(typeof u.ECDSA!=""undefined""&&a instanceof u.ECDSA))&&a.isPublic==true&&(r===undefined||r==""PKCS8PUB"")){var t=new KJUR.asn1.x509.SubjectPublicKeyInfo(a);var m=t.getEncodedHex();return v.ASN1Util.getPEMStringFromHex(m,""PUBLIC KEY"")}if(r==""PKCS1PRV""&&typeof RSAKey!=""undefined""&&a instanceof RSAKey&&(o===undefined||o==null)&&a.isPrivate==true){var t=p(a);var m=t.getEncodedHex();return v.ASN1Util.getPEMStringFromHex(m,""RSA PRIVATE KEY"")}if(r==""PKCS1PRV""&&typeof RSAKey!=""undefined""&&a instanceof KJUR.crypto.ECDSA&&(o===undefined||o==null)&&a.isPrivate==true){var f=new KJUR.asn1.DERObjectIdentifier({name:a.curveName});var l=f.getEncodedHex();var e=q(a);var k=e.getEncodedHex();var i="""";i+=v.ASN1Util.getPEMStringFromHex(l,""EC PARAMETERS"");i+=v.ASN1Util.getPEMStringFromHex(k,""EC PRIVATE KEY"");return i}if(r==""PKCS1PRV""&&typeof KJUR.crypto.DSA!=""undefined""&&a instanceof KJUR.crypto.DSA&&(o===undefined||o==null)&&a.isPrivate==true){var t=n(a);var m=t.getEncodedHex();return v.ASN1Util.getPEMStringFromHex(m,""DSA PRIVATE KEY"")}if(r==""PKCS5PRV""&&typeof RSAKey!=""undefined""&&a instanceof RSAKey&&(o!==undefined&&o!=null)&&a.isPrivate==true){var t=p(a);var m=t.getEncodedHex();if(g===undefined){g=""DES-EDE3-CBC""}return this.getEncryptedPKCS5PEMFromPrvKeyHex(""RSA"",m,o,g)}if(r==""PKCS5PRV""&&typeof KJUR.crypto.ECDSA!=""undefined""&&a instanceof KJUR.crypto.ECDSA&&(o!==undefined&&o!=null)&&a.isPrivate==true){var t=q(a);var m=t.getEncodedHex();if(g===undefined){g=""DES-EDE3-CBC""}return this.getEncryptedPKCS5PEMFromPrvKeyHex(""EC"",m,o,g)}if(r==""PKCS5PRV""&&typeof KJUR.crypto.DSA!=""undefined""&&a instanceof KJUR.crypto.DSA&&(o!==undefined&&o!=null)&&a.isPrivate==true){var t=n(a);var m=t.getEncodedHex();if(g===undefined){g=""DES-EDE3-CBC""}return this.getEncryptedPKCS5PEMFromPrvKeyHex(""DSA"",m,o,g)}var h=function(w,s){var y=b(w,s);var x=new KJUR.asn1.ASN1Util.newObject({seq:[{seq:[{oid:{name:""pkcs5PBES2""}},{seq:[{seq:[{oid:{name:""pkcs5PBKDF2""}},{seq:[{octstr:{hex:y.pbkdf2Salt}},{""int"":y.pbkdf2Iter}]}]},{seq:[{oid:{name:""des-EDE3-CBC""}},{octstr:{hex:y.encryptionSchemeIV}}]}]}]},{octstr:{hex:y.ciphertext}}]});return x.getEncodedHex()};var b=function(D,E){var x=100;var C=CryptoJS.lib.WordArray.random(8);var B=""DES-EDE3-CBC"";var s=CryptoJS.lib.WordArray.random(8);var y=CryptoJS.PBKDF2(E,C,{keySize:192/32,iterations:x});var z=CryptoJS.enc.Hex.parse(D);var A=CryptoJS.TripleDES.encrypt(z,y,{iv:s})+"""";var w={};w.ciphertext=A;w.pbkdf2Salt=CryptoJS.enc.Hex.stringify(C);w.pbkdf2Iter=x;w.encryptionSchemeAlg=B;w.encryptionSchemeIV=CryptoJS.enc.Hex.stringify(s);return w};if(r==""PKCS8PRV""&&typeof RSAKey!=""undefined""&&a instanceof RSAKey&&a.isPrivate==true){var d=p(a);var c=d.getEncodedHex();var t=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":0},{seq:[{oid:{name:""rsaEncryption""}},{""null"":true}]},{octstr:{hex:c}}]});var m=t.getEncodedHex();if(o===undefined||o==null){return v.ASN1Util.getPEMStringFromHex(m,""PRIVATE KEY"")}else{var k=h(m,o);return v.ASN1Util.getPEMStringFromHex(k,""ENCRYPTED PRIVATE KEY"")}}if(r==""PKCS8PRV""&&typeof KJUR.crypto.ECDSA!=""undefined""&&a instanceof KJUR.crypto.ECDSA&&a.isPrivate==true){var d=new KJUR.asn1.ASN1Util.newObject({seq:[{""int"":1},{octstr:{hex:a.prvKeyHex}},{tag:[""a1"",true,{bitstr:{hex:""00""+a.pubKeyHex}}]}]});var c=d.getEncodedHex();var t=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":0},{seq:[{oid:{name:""ecPublicKey""}},{oid:{name:a.curveName}}]},{octstr:{hex:c}}]});var m=t.getEncodedHex();if(o===undefined||o==null){return v.ASN1Util.getPEMStringFromHex(m,""PRIVATE KEY"")}else{var k=h(m,o);return v.ASN1Util.getPEMStringFromHex(k,""ENCRYPTED PRIVATE KEY"")}}if(r==""PKCS8PRV""&&typeof KJUR.crypto.DSA!=""undefined""&&a instanceof KJUR.crypto.DSA&&a.isPrivate==true){var d=new KJUR.asn1.DERInteger({bigint:a.x});var c=d.getEncodedHex();var t=KJUR.asn1.ASN1Util.newObject({seq:[{""int"":0},{seq:[{oid:{name:""dsa""}},{seq:[{""int"":{bigint:a.p}},{""int"":{bigint:a.q}},{""int"":{bigint:a.g}}]}]},{octstr:{hex:c}}]});var m=t.getEncodedHex();if(o===undefined||o==null){return v.ASN1Util.getPEMStringFromHex(m,""PRIVATE KEY"")}else{var k=h(m,o);return v.ASN1Util.getPEMStringFromHex(k,""ENCRYPTED PRIVATE KEY"")}}throw""unsupported object nor format""};KEYUTIL.getKeyFromCSRPEM=function(b){var a=KEYUTIL.getHexFromPEM(b,""CERTIFICATE REQUEST"");var c=KEYUTIL.getKeyFromCSRHex(a);return c};KEYUTIL.getKeyFromCSRHex=function(a){var c=KEYUTIL.parseCSRHex(a);var b=KEYUTIL.getKey(c.p8pubkeyhex,null,""pkcs8pub"");return b};KEYUTIL.parseCSRHex=function(c){var b={};var e=c;if(e.substr(0,2)!=""30""){throw""malformed CSR(code:001)""}var d=ASN1HEX.getPosArrayOfChildren_AtObj(e,0);if(d.length<1){throw""malformed CSR(code:002)""}if(e.substr(d[0],2)!=""30""){throw""malformed CSR(code:003)""}var a=ASN1HEX.getPosArrayOfChildren_AtObj(e,d[0]);if(a.length<3){throw""malformed CSR(code:004)""}b.p8pubkeyhex=ASN1HEX.getHexOfTLV_AtObj(e,a[2]);return b}; /*! rsapem-1.1.js (c) 2012 Kenji Urushima | kjur.github.com/jsrsasign/license */ function _rsapem_pemToBase64(b){var a=b;a=a.replace(""-----BEGIN RSA PRIVATE KEY-----"","""");a=a.replace(""-----END RSA PRIVATE KEY-----"","""");a=a.replace(/[ \n]+/g,"""");return a}function _rsapem_getPosArrayOfChildrenFromHex(d){var j=new Array();var k=ASN1HEX.getStartPosOfV_AtObj(d,0);var f=ASN1HEX.getPosOfNextSibling_AtObj(d,k);var h=ASN1HEX.getPosOfNextSibling_AtObj(d,f);var b=ASN1HEX.getPosOfNextSibling_AtObj(d,h);var l=ASN1HEX.getPosOfNextSibling_AtObj(d,b);var e=ASN1HEX.getPosOfNextSibling_AtObj(d,l);var g=ASN1HEX.getPosOfNextSibling_AtObj(d,e);var c=ASN1HEX.getPosOfNextSibling_AtObj(d,g);var i=ASN1HEX.getPosOfNextSibling_AtObj(d,c);j.push(k,f,h,b,l,e,g,c,i);return j}function _rsapem_getHexValueArrayOfChildrenFromHex(i){var o=_rsapem_getPosArrayOfChildrenFromHex(i);var r=ASN1HEX.getHexOfV_AtObj(i,o[0]);var f=ASN1HEX.getHexOfV_AtObj(i,o[1]);var j=ASN1HEX.getHexOfV_AtObj(i,o[2]);var k=ASN1HEX.getHexOfV_AtObj(i,o[3]);var c=ASN1HEX.getHexOfV_AtObj(i,o[4]);var b=ASN1HEX.getHexOfV_AtObj(i,o[5]);var h=ASN1HEX.getHexOfV_AtObj(i,o[6]);var g=ASN1HEX.getHexOfV_AtObj(i,o[7]);var l=ASN1HEX.getHexOfV_AtObj(i,o[8]);var m=new Array();m.push(r,f,j,k,c,b,h,g,l);return m}function _rsapem_readPrivateKeyFromASN1HexString(c){var b=_rsapem_getHexValueArrayOfChildrenFromHex(c);this.setPrivateEx(b[1],b[2],b[3],b[4],b[5],b[6],b[7],b[8])}function _rsapem_readPrivateKeyFromPEMString(e){var c=_rsapem_pemToBase64(e);var d=b64tohex(c);var b=_rsapem_getHexValueArrayOfChildrenFromHex(d);this.setPrivateEx(b[1],b[2],b[3],b[4],b[5],b[6],b[7],b[8])}RSAKey.prototype.readPrivateKeyFromPEMString=_rsapem_readPrivateKeyFromPEMString;RSAKey.prototype.readPrivateKeyFromASN1HexString=_rsapem_readPrivateKeyFromASN1HexString; /*! rsasign-1.2.7.js (c) 2012 Kenji Urushima | kjur.github.com/jsrsasign/license */ var _RE_HEXDECONLY=new RegExp("""");_RE_HEXDECONLY.compile(""[^0-9a-f]"",""gi"");function _rsasign_getHexPaddedDigestInfoForString(d,e,a){var b=function(f){return KJUR.crypto.Util.hashString(f,a)};var c=b(d);return KJUR.crypto.Util.getPaddedDigestInfoHex(c,a,e)}function _zeroPaddingOfSignature(e,d){var c="""";var a=d/4-e.length;for(var b=0;b<a;b++){c=c+""0""}return c+e}function _rsasign_signString(d,a){var b=function(e){return KJUR.crypto.Util.hashString(e,a)};var c=b(d);return this.signWithMessageHash(c,a)}function _rsasign_signWithMessageHash(e,c){var f=KJUR.crypto.Util.getPaddedDigestInfoHex(e,c,this.n.bitLength());var b=parseBigInt(f,16);var d=this.doPrivate(b);var a=d.toString(16);return _zeroPaddingOfSignature(a,this.n.bitLength())}function _rsasign_signStringWithSHA1(a){return _rsasign_signString.call(this,a,""sha1"")}function _rsasign_signStringWithSHA256(a){return _rsasign_signString.call(this,a,""sha256"")}function pss_mgf1_str(c,a,e){var b="""",d=0;while(b.length<a){b+=hextorstr(e(rstrtohex(c+String.fromCharCode.apply(String,[(d&4278190080)>>24,(d&16711680)>>16,(d&65280)>>8,d&255]))));d+=1}return b}function _rsasign_signStringPSS(e,a,d){var c=function(f){return KJUR.crypto.Util.hashHex(f,a)};var b=c(rstrtohex(e));if(d===undefined){d=-1}return this.signWithMessageHashPSS(b,a,d)}function _rsasign_signWithMessageHashPSS(l,a,k){var b=hextorstr(l);var g=b.length;var m=this.n.bitLength()-1;var c=Math.ceil(m/8);var d;var o=function(i){return KJUR.crypto.Util.hashHex(i,a)};if(k===-1||k===undefined){k=g}else{if(k===-2){k=c-g-2}else{if(k<-2){throw""invalid salt length""}}}if(c<(g+k+2)){throw""data too long""}var f="""";if(k>0){f=new Array(k);new SecureRandom().nextBytes(f);f=String.fromCharCode.apply(String,f)}var n=hextorstr(o(rstrtohex(""\x00\x00\x00\x00\x00\x00\x00\x00""+b+f)));var j=[];for(d=0;d<c-k-g-2;d+=1){j[d]=0}var e=String.fromCharCode.apply(String,j)+""\x01""+f;var h=pss_mgf1_str(n,e.length,o);var q=[];for(d=0;d<e.length;d+=1){q[d]=e.charCodeAt(d)^h.charCodeAt(d)}var p=(65280>>(8*c-m))&255;q[0]&=~p;for(d=0;d<g;d++){q.push(n.charCodeAt(d))}q.push(188);return _zeroPaddingOfSignature(this.doPrivate(new BigInteger(q)).toString(16),this.n.bitLength())}function _rsasign_getDecryptSignatureBI(a,d,c){var b=new RSAKey();b.setPublic(d,c);var e=b.doPublic(a);return e}function _rsasign_getHexDigestInfoFromSig(a,c,b){var e=_rsasign_getDecryptSignatureBI(a,c,b);var d=e.toString(16).replace(/^1f+00/,"""");return d}function _rsasign_getAlgNameAndHashFromHexDisgestInfo(f){for(var e in KJUR.crypto.Util.DIGESTINFOHEAD){var d=KJUR.crypto.Util.DIGESTINFOHEAD[e];var b=d.length;if(f.substring(0,b)==d){var c=[e,f.substring(b)];return c}}return[]}function _rsasign_verifySignatureWithArgs(f,b,g,j){var e=_rsasign_getHexDigestInfoFromSig(b,g,j);var h=_rsasign_getAlgNameAndHashFromHexDisgestInfo(e);if(h.length==0){return false}var d=h[0];var i=h[1];var a=function(k){return KJUR.crypto.Util.hashString(k,d)};var c=a(f);return(i==c)}function _rsasign_verifyHexSignatureForMessage(c,b){var d=parseBigInt(c,16);var a=_rsasign_verifySignatureWithArgs(b,d,this.n.toString(16),this.e.toString(16));return a}function _rsasign_verifyString(f,j){j=j.replace(_RE_HEXDECONLY,"""");j=j.replace(/[ \n]+/g,"""");var b=parseBigInt(j,16);if(b.bitLength()>this.n.bitLength()){return 0}var i=this.doPublic(b);var e=i.toString(16).replace(/^1f+00/,"""");var g=_rsasign_getAlgNameAndHashFromHexDisgestInfo(e);if(g.length==0){return false}var d=g[0];var h=g[1];var a=function(k){return KJUR.crypto.Util.hashString(k,d)};var c=a(f);return(h==c)}function _rsasign_verifyWithMessageHash(e,a){a=a.replace(_RE_HEXDECONLY,"""");a=a.replace(/[ \n]+/g,"""");var b=parseBigInt(a,16);if(b.bitLength()>this.n.bitLength()){return 0}var h=this.doPublic(b);var g=h.toString(16).replace(/^1f+00/,"""");var c=_rsasign_getAlgNameAndHashFromHexDisgestInfo(g);if(c.length==0){return false}var d=c[0];var f=c[1];return(f==e)}function _rsasign_verifyStringPSS(c,b,a,f){var e=function(g){return KJUR.crypto.Util.hashHex(g,a)};var d=e(rstrtohex(c));if(f===undefined){f=-1}return this.verifyWithMessageHashPSS(d,b,a,f)}function _rsasign_verifyWithMessageHashPSS(f,s,l,c){var k=new BigInteger(s,16);if(k.bitLength()>this.n.bitLength()){return false}var r=function(i){return KJUR.crypto.Util.hashHex(i,l)};var j=hextorstr(f);var h=j.length;var g=this.n.bitLength()-1;var m=Math.ceil(g/8);var q;if(c===-1||c===undefined){c=h}else{if(c===-2){c=m-h-2}else{if(c<-2){throw""invalid salt length""}}}if(m<(h+c+2)){throw""data too long""}var a=this.doPublic(k).toByteArray();for(q=0;q<a.length;q+=1){a[q]&=255}while(a.length<m){a.unshift(0)}if(a[m-1]!==188){throw""encoded message does not end in 0xbc""}a=String.fromCharCode.apply(String,a);var d=a.substr(0,m-h-1);var e=a.substr(d.length,h);var p=(65280>>(8*m-g))&255;if((d.charCodeAt(0)&p)!==0){throw""bits beyond keysize not zero""}var n=pss_mgf1_str(e,d.length,r);var o=[];for(q=0;q<d.length;q+=1){o[q]=d.charCodeAt(q)^n.charCodeAt(q)}o[0]&=~p;var b=m-h-c-2;for(q=0;q<b;q+=1){if(o[q]!==0){throw""leftmost octets not zero""}}if(o[b]!==1){throw""0x01 marker not found""}return e===hextorstr(r(rstrtohex(""\x00\x00\x00\x00\x00\x00\x00\x00""+j+String.fromCharCode.apply(String,o.slice(-c)))))}RSAKey.prototype.signWithMessageHash=_rsasign_signWithMessageHash;RSAKey.prototype.signString=_rsasign_signString;RSAKey.prototype.signStringWithSHA1=_rsasign_signStringWithSHA1;RSAKey.prototype.signStringWithSHA256=_rsasign_signStringWithSHA256;RSAKey.prototype.sign=_rsasign_signString;RSAKey.prototype.signWithSHA1=_rsasign_signStringWithSHA1;RSAKey.prototype.signWithSHA256=_rsasign_signStringWithSHA256;RSAKey.prototype.signWithMessageHashPSS=_rsasign_signWithMessageHashPSS;RSAKey.prototype.signStringPSS=_rsasign_signStringPSS;RSAKey.prototype.signPSS=_rsasign_signStringPSS;RSAKey.SALT_LEN_HLEN=-1;RSAKey.SALT_LEN_MAX=-2;RSAKey.prototype.verifyWithMessageHash=_rsasign_verifyWithMessageHash;RSAKey.prototype.verifyString=_rsasign_verifyString;RSAKey.prototype.verifyHexSignatureForMessage=_rsasign_verifyHexSignatureForMessage;RSAKey.prototype.verify=_rsasign_verifyString;RSAKey.prototype.verifyHexSignatureForByteArrayMessage=_rsasign_verifyHexSignatureForMessage;RSAKey.prototype.verifyWithMessageHashPSS=_rsasign_verifyWithMessageHashPSS;RSAKey.prototype.verifyStringPSS=_rsasign_verifyStringPSS;RSAKey.prototype.verifyPSS=_rsasign_verifyStringPSS;RSAKey.SALT_LEN_RECOVER=-2; /*! x509-1.1.3.js (c) 2012-2014 Kenji Urushima | kjur.github.com/jsrsasign/license */ function X509(){this.subjectPublicKeyRSA=null;this.subjectPublicKeyRSA_hN=null;this.subjectPublicKeyRSA_hE=null;this.hex=null;this.getSerialNumberHex=function(){return ASN1HEX.getDecendantHexVByNthList(this.hex,0,[0,1])};this.getIssuerHex=function(){return ASN1HEX.getDecendantHexTLVByNthList(this.hex,0,[0,3])};this.getIssuerString=function(){return X509.hex2dn(ASN1HEX.getDecendantHexTLVByNthList(this.hex,0,[0,3]))};this.getSubjectHex=function(){return ASN1HEX.getDecendantHexTLVByNthList(this.hex,0,[0,5])};this.getSubjectString=function(){return X509.hex2dn(ASN1HEX.getDecendantHexTLVByNthList(this.hex,0,[0,5]))};this.getNotBefore=function(){var a=ASN1HEX.getDecendantHexVByNthList(this.hex,0,[0,4,0]);a=a.replace(/(..)/g,""%$1"");a=decodeURIComponent(a);return a};this.getNotAfter=function(){var a=ASN1HEX.getDecendantHexVByNthList(this.hex,0,[0,4,1]);a=a.replace(/(..)/g,""%$1"");a=decodeURIComponent(a);return a};this.readCertPEM=function(c){var e=X509.pemToHex(c);var b=X509.getPublicKeyHexArrayFromCertHex(e);var d=new RSAKey();d.setPublic(b[0],b[1]);this.subjectPublicKeyRSA=d;this.subjectPublicKeyRSA_hN=b[0];this.subjectPublicKeyRSA_hE=b[1];this.hex=e};this.readCertPEMWithoutRSAInit=function(c){var d=X509.pemToHex(c);var b=X509.getPublicKeyHexArrayFromCertHex(d);this.subjectPublicKeyRSA.setPublic(b[0],b[1]);this.subjectPublicKeyRSA_hN=b[0];this.subjectPublicKeyRSA_hE=b[1];this.hex=d}}X509.pemToBase64=function(a){var b=a;b=b.replace(""-----BEGIN CERTIFICATE-----"","""");b=b.replace(""-----END CERTIFICATE-----"","""");b=b.replace(/[ \n]+/g,"""");return b};X509.pemToHex=function(a){var c=X509.pemToBase64(a);var b=b64tohex(c);return b};X509.getSubjectPublicKeyPosFromCertHex=function(f){var e=X509.getSubjectPublicKeyInfoPosFromCertHex(f);if(e==-1){return -1}var b=ASN1HEX.getPosArrayOfChildren_AtObj(f,e);if(b.length!=2){return -1}var d=b[1];if(f.substring(d,d+2)!=""03""){return -1}var c=ASN1HEX.getStartPosOfV_AtObj(f,d);if(f.substring(c,c+2)!=""00""){return -1}return c+2};X509.getSubjectPublicKeyInfoPosFromCertHex=function(d){var c=ASN1HEX.getStartPosOfV_AtObj(d,0);var b=ASN1HEX.getPosArrayOfChildren_AtObj(d,c);if(b.length<1){return -1}if(d.substring(b[0],b[0]+10)==""a003020102""){if(b.length<6){return -1}return b[6]}else{if(b.length<5){return -1}return b[5]}};X509.getPublicKeyHexArrayFromCertHex=function(f){var e=X509.getSubjectPublicKeyPosFromCertHex(f);var b=ASN1HEX.getPosArrayOfChildren_AtObj(f,e);if(b.length!=2){return[]}var d=ASN1HEX.getHexOfV_AtObj(f,b[0]);var c=ASN1HEX.getHexOfV_AtObj(f,b[1]);if(d!=null&&c!=null){return[d,c]}else{return[]}};X509.getHexTbsCertificateFromCert=function(b){var a=ASN1HEX.getStartPosOfV_AtObj(b,0);return a};X509.getPublicKeyHexArrayFromCertPEM=function(c){var d=X509.pemToHex(c);var b=X509.getPublicKeyHexArrayFromCertHex(d);return b};X509.hex2dn=function(e){var f="""";var c=ASN1HEX.getPosArrayOfChildren_AtObj(e,0);for(var d=0;d<c.length;d++){var b=ASN1HEX.getHexOfTLV_AtObj(e,c[d]);f=f+""/""+X509.hex2rdn(b)}return f};X509.hex2rdn=function(a){var f=ASN1HEX.getDecendantHexTLVByNthList(a,0,[0,0]);var e=ASN1HEX.getDecendantHexVByNthList(a,0,[0,1]);var c="""";try{c=X509.DN_ATTRHEX[f]}catch(b){c=f}e=e.replace(/(..)/g,""%$1"");var d=decodeURIComponent(e);return c+""=""+d};X509.DN_ATTRHEX={""0603550406"":""C"",""060355040a"":""O"",""060355040b"":""OU"",""0603550403"":""CN"",""0603550405"":""SN"",""0603550408"":""ST"",""0603550407"":""L"",};X509.getPublicKeyFromCertPEM=function(f){var c=X509.getPublicKeyInfoPropOfCertPEM(f);if(c.algoid==""2a864886f70d010101""){var i=KEYUTIL.parsePublicRawRSAKeyHex(c.keyhex);var j=new RSAKey();j.setPublic(i.n,i.e);return j}else{if(c.algoid==""2a8648ce3d0201""){var e=KJUR.crypto.OID.oidhex2name[c.algparam];var j=new KJUR.crypto.ECDSA({curve:e,info:c.keyhex});j.setPublicKeyHex(c.keyhex);return j}else{if(c.algoid==""2a8648ce380401""){var b=ASN1HEX.getVbyList(c.algparam,0,[0],""02"");var a=ASN1HEX.getVbyList(c.algparam,0,[1],""02"");var d=ASN1HEX.getVbyList(c.algparam,0,[2],""02"");var h=ASN1HEX.getHexOfV_AtObj(c.keyhex,0);h=h.substr(2);var j=new KJUR.crypto.DSA();j.setPublic(new BigInteger(b,16),new BigInteger(a,16),new BigInteger(d,16),new BigInteger(h,16));return j}else{throw""unsupported key""}}}};X509.getPublicKeyInfoPropOfCertPEM=function(e){var c={};c.algparam=null;var g=X509.pemToHex(e);var d=ASN1HEX.getPosArrayOfChildren_AtObj(g,0);if(d.length!=3){throw""malformed X.509 certificate PEM (code:001)""}if(g.substr(d[0],2)!=""30""){throw""malformed X.509 certificate PEM (code:002)""}var b=ASN1HEX.getPosArrayOfChildren_AtObj(g,d[0]);if(b.length<7){throw""malformed X.509 certificate PEM (code:003)""}var h=ASN1HEX.getPosArrayOfChildren_AtObj(g,b[6]);if(h.length!=2){throw""malformed X.509 certificate PEM (code:004)""}var f=ASN1HEX.getPosArrayOfChildren_AtObj(g,h[0]);if(f.length!=2){throw""malformed X.509 certificate PEM (code:005)""}c.algoid=ASN1HEX.getHexOfV_AtObj(g,f[0]);if(g.substr(f[1],2)==""06""){c.algparam=ASN1HEX.getHexOfV_AtObj(g,f[1])}else{if(g.substr(f[1],2)==""30""){c.algparam=ASN1HEX.getHexOfTLV_AtObj(g,f[1])}}if(g.substr(h[1],2)!=""03""){throw""malformed X.509 certificate PEM (code:006)""}var a=ASN1HEX.getHexOfV_AtObj(g,h[1]);c.keyhex=a.substr(2);return c};",,459,70
openstack%2Fdjango_openstack_auth~master~Ib8125abc3650b9d9d82e15658e2b5959428556d0,openstack/django_openstack_auth,master,Ib8125abc3650b9d9d82e15658e2b5959428556d0,Authenticate with K2K Federation at Login Time,ABANDONED,2016-06-06 13:14:05.000000000,2017-02-17 17:14:08.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6482}, {'_account_id': 8571}, {'_account_id': 9237}, {'_account_id': 16046}, {'_account_id': 17579}]","[{'number': 1, 'created': '2016-06-06 13:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/da955e9d781b183eb4983b7a1ced865b78b8be2e', 'message': 'WIP Authenticate to a single sp using K2K Federation at Login Time\n\nThis is an alternative option than the K2K method used in\nhttps://review.openstack.org/#/c/159910/. In 159910 the\nlist of service providers the user could login is loaded at login time.\nThe user could use the region drop down to switch between the idp\nand sp at during login.\n\nThis patch uses a different method where the user selects the provider\nfrom the dropdown during login time.\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 2, 'created': '2016-06-06 13:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/b5c09d503a6f6a51539f651da46f3e583dc7a873', 'message': 'WIP Authenticate to a single sp using K2K Federation at Login Time\n\nThis is an alternative option than the K2K method used in\nhttps://review.openstack.org/#/c/159910/. In 159910 the\nlist of service providers the user could login to is loaded at login time and\nthe user could use the region drop down to switch.\n\nThis patch uses a different method where the user selects the provider\nfrom the dropdown during login time. It does not allow the user to between\nproviders without logging out.\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 3, 'created': '2016-06-07 16:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/0100b145f01dad2e8ce0e5a5de89b93e74705899', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for KeyStone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 4, 'created': '2016-07-13 14:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/cc1f5d60a11f1e63c0b828dde3c5f064a99ed2df', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for KeyStone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 5, 'created': '2016-08-30 21:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/f42fa8de9a55d3ed6a23ceb47323105262d40ed0', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for KeyStone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 6, 'created': '2016-10-12 21:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/ebb43826b01a5ef78e4b39f724c4642deef6020c', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for KeyStone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 7, 'created': '2016-10-14 14:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/682bc67f2fd03a19ff4626c7d562cc6e0df4dd56', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for KeyStone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 8, 'created': '2016-11-03 20:22:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/3014e38c53171f65d394e1bd8f9eadea5f1b6eca', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for Keystone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 9, 'created': '2016-11-04 14:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/f7c05ca035da6911e16e981ca7471ba2c9f82b6d', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for Keystone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}, {'number': 10, 'created': '2016-11-04 15:31:36.000000000', 'files': ['openstack_auth/tests/tests.py', 'openstack_auth/plugin/k2k.py', 'openstack_auth/forms.py', 'openstack_auth/plugin/base.py', 'openstack_auth/plugin/__init__.py', 'openstack_auth/backend.py', 'openstack_auth/tests/data_v3.py', 'openstack_auth/utils.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/304e47660a0f66b01cee98efead80b3f15718d3c', 'message': 'Authenticate with K2K Federation at Login Time\n\nThis enables a drop down on the login screen that\nselects a service provider for Keystone to Keystone federation.\nThe user enters their local identity provider user/pass, selects a\nservice provider, and will then be authenticated\ninto the remote service provider.\n\nOnce authenticated, horizon will be able to use services on\nthe service providers on behalf of the user.\n\nThe k2k auth plugin has been added to the list of available\nopenstack_auth plugins.\n\nThe horizon admin will be able to configure the list of service providers\nin the dropdown by configuring local_settings.py\n\nexample:\nK2K_SELECTION_AT_LOGIN_ENABLED = True\nK2K_INITIAL_CHOICE = k2kf-idp\nK2K_CHOICES = (\n    (""k2kf-idp"", _(""Keystone Authentication"")),\n    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))\n)\n\nChange-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0\n'}]",34,325901,304e47660a0f66b01cee98efead80b3f15718d3c,40,7,10,17579,,,0,"Authenticate with K2K Federation at Login Time

This enables a drop down on the login screen that
selects a service provider for Keystone to Keystone federation.
The user enters their local identity provider user/pass, selects a
service provider, and will then be authenticated
into the remote service provider.

Once authenticated, horizon will be able to use services on
the service providers on behalf of the user.

The k2k auth plugin has been added to the list of available
openstack_auth plugins.

The horizon admin will be able to configure the list of service providers
in the dropdown by configuring local_settings.py

example:
K2K_SELECTION_AT_LOGIN_ENABLED = True
K2K_INITIAL_CHOICE = k2kf-idp
K2K_CHOICES = (
    (""k2kf-idp"", _(""Keystone Authentication"")),
    (""k2kf-sp"", _(""Service_Provider k2kf-sp""))
)

Change-Id: Ib8125abc3650b9d9d82e15658e2b5959428556d0
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/01/325901/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/tests/tests.py', 'openstack_auth/plugin/k2k.py', 'openstack_auth/forms.py', 'openstack_auth/plugin/__init__.py', 'openstack_auth/backend.py', 'openstack_auth/utils.py']",6,da955e9d781b183eb4983b7a1ced865b78b8be2e,bp/k2k-horizon,"from django.utils.translation import ugettext_lazy as _ from keystoneauth1 import exceptions as keystone_exceptionsfrom openstack_auth import exceptionsdef get_access_info(unscoped_auth): session = get_session() try: unscoped_auth_ref = unscoped_auth.get_access(session) except keystone_exceptions.ConnectFailure as exc: LOG.error(str(exc)) msg = _('Unable to establish connection to keystone endpoint.') raise exceptions.KeystoneAuthException(msg) except (keystone_exceptions.Unauthorized, keystone_exceptions.Forbidden, keystone_exceptions.NotFound) as exc: LOG.debug(str(exc)) raise exceptions.KeystoneAuthException(_('Invalid credentials.')) except (keystone_exceptions.ClientException, keystone_exceptions.AuthorizationFailure) as exc: msg = _(""An error occurred authenticating. "" ""Please try again later."") LOG.debug(str(exc)) raise exceptions.KeystoneAuthException(msg) return unscoped_auth_ref def is_k2k_federation_at_login_enabled(): """"""Check if K2K federation selection list at login is enabled. Here are the example settings: # Feature Flag, default is false K2K_SELECTION_AT_LOGIN_ENABLED = True # IDP ID, default is 'k2k-idp'. # If user selects IDP, then k2k authentication is skipped. K2K_IDP_CHOICE = k2kf-idp #Service Provider choices, value return should be SP ID K2K_CHOICES = ( (""k2kf-idp"", _(""Keystone Authentication"")), (""k2kf-sp"", _(""Service_Provider k2kf-sp"")) ) """""" k2k_enabled = getattr(settings, 'K2K_SELECTION_AT_LOGIN_ENABLED', False) keystonev3_plus = (get_keystone_version() >= 3) return k2k_enabled and keystonev3_plus ",,171,25
openstack%2Fhorizon~master~Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64,openstack/horizon,master,Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64,filter projects in the local domain,ABANDONED,2017-01-05 22:30:26.000000000,2017-02-17 17:14:07.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7400}, {'_account_id': 9576}, {'_account_id': 17172}]","[{'number': 1, 'created': '2017-01-05 22:30:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cb6e5004168bd9583f177a5ee587c62c23399470', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}, {'number': 2, 'created': '2017-01-05 23:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a481abb9957accc5e09a0de20bcfceb49697f77c', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}, {'number': 3, 'created': '2017-01-05 23:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8a05e0ef98b8da8336b5602e97d009f4a20e86ac', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}, {'number': 4, 'created': '2017-01-06 01:54:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ad99c8446a0409e579712707a0620bc8088e52b7', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}, {'number': 5, 'created': '2017-01-06 02:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/17431e6664b2eb7db89376a4b2f77a2f52e97f8a', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}, {'number': 6, 'created': '2017-01-06 02:58:43.000000000', 'files': ['openstack_dashboard/templatetags/context_selection.py', 'openstack_dashboard/dashboards/admin/images/tests.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/11a431457424b1e2cb1a8bc2b9f5869ee077206a', 'message': 'filter projects in the local domain\n\nChange-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64\n'}]",7,417221,11a431457424b1e2cb1a8bc2b9f5869ee077206a,21,5,6,7400,,,0,"filter projects in the local domain

Change-Id: Iaa4ed6b9e79c6990fac62fecda8e6b883da27f64
",git fetch https://review.opendev.org/openstack/horizon refs/changes/21/417221/5 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/templatetags/context_selection.py'],1,cb6e5004168bd9583f177a5ee587c62c23399470,417221, # Filter projects in the local domain local_domain = request.session['domain_token'].domain_id projects = [p for p in projects if p.domain_id == local_domain],,3,0
openstack%2Fhorizon~master~I3a1cf7d640c09d4192db19cd8e4e5000a220a65e,openstack/horizon,master,I3a1cf7d640c09d4192db19cd8e4e5000a220a65e,Adds API and tests for QoS panel in Horizon,ABANDONED,2017-01-09 14:16:42.000000000,2017-02-17 17:14:06.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 13995}, {'_account_id': 16628}]","[{'number': 1, 'created': '2017-01-09 14:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9cdb139df6f1b5e013971561e7a3fcb9c4fc804c', 'message': 'Adds API and tests for QoS panel in Horizon\n\nThis patch adds the API and test files for the QoS panel which will\ndisplay QoS policies.\n\nBased on initial commit: https://review.openstack.org/#/c/247997\nCo-Authored-By: Masco <mkaliyam@redhat.com>\n\nChange-Id: I3a1cf7d640c09d4192db19cd8e4e5000a220a65e\n'}, {'number': 2, 'created': '2017-01-19 12:45:25.000000000', 'files': ['openstack_dashboard/api/rest/neutron.py', 'openstack_dashboard/api/neutron_qos.py', 'openstack_dashboard/static/app/core/openstack-service-api/neutron.service.js', 'doc/source/topics/settings.rst', 'openstack_dashboard/api/__init__.py', 'openstack_dashboard/test/api_tests/neutron_qos_tests.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/test/settings.py', 'openstack_dashboard/test/test_data/neutron_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b631b2ed105a2df0d2fec7c396f16cf30f028967', 'message': 'Adds API and tests for QoS panel in Horizon\n\nThis patch adds the API and test files for the QoS panel which will\ndisplay QoS policies.\n\nBased on initial commit: https://review.openstack.org/#/c/247997\nCo-Authored-By: Masco <mkaliyam@redhat.com>\n\nChange-Id: I3a1cf7d640c09d4192db19cd8e4e5000a220a65e\n'}]",1,417893,b631b2ed105a2df0d2fec7c396f16cf30f028967,8,4,2,16628,,,0,"Adds API and tests for QoS panel in Horizon

This patch adds the API and test files for the QoS panel which will
display QoS policies.

Based on initial commit: https://review.openstack.org/#/c/247997
Co-Authored-By: Masco <mkaliyam@redhat.com>

Change-Id: I3a1cf7d640c09d4192db19cd8e4e5000a220a65e
",git fetch https://review.opendev.org/openstack/horizon refs/changes/93/417893/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/neutron.py', 'openstack_dashboard/api/neutron_qos.py', 'doc/source/topics/settings.rst', 'openstack_dashboard/static/app/core/openstack-service-api/neutron.service.js', 'openstack_dashboard/api/__init__.py', 'openstack_dashboard/test/api_tests/neutron_qos_tests.py', 'openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/test/settings.py', 'openstack_dashboard/test/test_data/neutron_data.py']",9,9cdb139df6f1b5e013971561e7a3fcb9c4fc804c,angular-qos-panel,"from openstack_dashboard.api import neutron_qos TEST.qos_policies = utils.TestDataContainer() TEST.api_qos_policies = utils.TestDataContainer() # qos policies policy_dict = {'id': 'a21dcd22-7189-cccc-aa32-22adafaf16a7', 'name': 'policy 1', 'tenant_id': '1'} TEST.api_qos_policies.add(policy_dict) TEST.qos_policies.add(neutron_qos.QoSPolicy(policy_dict)) policy_dict1 = {'id': 'a21dcd22-7189-ssss-aa32-22adafaf16a7', 'name': 'policy 2', 'tenant_id': '1'} TEST.api_qos_policies.add(policy_dict1) TEST.qos_policies.add(neutron_qos.QoSPolicy(policy_dict1))",,218,1
openstack%2Fhorizon~master~I3b9e9ddffc60e85d0486f043f4933f8670771a80,openstack/horizon,master,I3b9e9ddffc60e85d0486f043f4933f8670771a80,WIP Added actions to angular qos panel,ABANDONED,2017-01-19 12:53:51.000000000,2017-02-17 17:14:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}]","[{'number': 1, 'created': '2017-01-19 12:53:51.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/batch-delete-action.service.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/batch-delete-action.service.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/delete-action.service.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/delete-action.service.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ba826277538afc18e103d293d4dca84f16f94d49', 'message': 'WIP Added actions to angular qos panel\n\nChange-Id: I3b9e9ddffc60e85d0486f043f4933f8670771a80\n'}]",0,422595,ba826277538afc18e103d293d4dca84f16f94d49,4,2,1,16628,,,0,"WIP Added actions to angular qos panel

Change-Id: I3b9e9ddffc60e85d0486f043f4933f8670771a80
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/422595/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/batch-delete-action.service.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/batch-delete-action.service.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/delete-action.service.spec.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/network_qos/actions/delete-action.service.js']",4,ba826277538afc18e103d293d4dca84f16f94d49,angular-qos-panel,"/* * (c) Copyright 2015, 2016 Red Hat, Inc. * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function() { 'use strict'; angular .module('horizon.dashboard.project.network_qos') .factory('horizon.dashboard.project.network_qos.actions.deleteService', deleteService); deleteService.$inject = [ 'horizon.dashboard.project.network_qos.actions.deleteQoSPolicyService', 'horizon.framework.util.i18n.gettext', 'horizon.framework.util.q.extensions' ]; /** * @ngDoc factory * @name horizon.dashboard.project.network_qos.actions.deleteService * * @Description * Brings up the delete policy confirmation modal dialog. * On submit, delete selected policy. * On cancel, do nothing. */ function deleteService( deleteQoSPolicyService, gettext, $qExtensions ) { var labels = { title: gettext('Confirm Delete QoS Policy'), /* eslint-disable max-len */ message: gettext('You have selected ""%s"". Please confirm your selection. This cannot be undone.'), /* eslint-enable max-len */ submit: gettext('Delete Policy'), success: gettext('Deleted Policy: %s.'), error: gettext('Unable to delete Policy: %s.') }; var service = { initScope: initScope, allowed: allowed, perform: perform }; return service; ////////////// // include this function in your service // if you plan to emit events to the parent controller function initScope(newScope) { deleteQoSPolicyService.initScope(newScope); } // delete selected policy function perform(policy) { deleteQoSPolicyService.open([{id: policy.id, name: policy.name}], labels); } function allowed() { return $qExtensions.booleanAsPromise(true); } } // end of deleteService })(); // end of IIFE ",,321,0
openstack%2Fhorizon~master~I0f559a3c3fc7e6828991df937e2ab46d4da6afaa,openstack/horizon,master,I0f559a3c3fc7e6828991df937e2ab46d4da6afaa,EXPERIMENTAL: Remove Legacy Flavors code,ABANDONED,2016-07-21 17:53:51.000000000,2017-02-17 17:14:01.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 12826}, {'_account_id': 14124}]","[{'number': 1, 'created': '2016-07-21 17:53:51.000000000', 'files': ['openstack_dashboard/test/integration_tests/tests/test_flavors.py', 'openstack_dashboard/dashboards/admin/flavors/tables.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/update.html', 'openstack_dashboard/dashboards/admin/flavors/urls.py', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/admin/flavors/constants.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/index.html', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/create.html', 'openstack_dashboard/test/integration_tests/pages/admin/system/flavorspage.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/569a889a0802d79dc556d8730f2c56ad43e1af23', 'message': 'EXPERIMENTAL: Remove Legacy Flavors code\n\nThis is experimenting largely to see how much code is removed as part of this\nexercise.\n\nChange-Id: I0f559a3c3fc7e6828991df937e2ab46d4da6afaa\n'}]",0,345582,569a889a0802d79dc556d8730f2c56ad43e1af23,7,5,1,14124,,,0,"EXPERIMENTAL: Remove Legacy Flavors code

This is experimenting largely to see how much code is removed as part of this
exercise.

Change-Id: I0f559a3c3fc7e6828991df937e2ab46d4da6afaa
",git fetch https://review.opendev.org/openstack/horizon refs/changes/82/345582/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/flavors/tables.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/update.html', 'openstack_dashboard/dashboards/admin/flavors/urls.py', 'openstack_dashboard/test/integration_tests/tests/test_flavors.py', 'openstack_dashboard/dashboards/admin/flavors/workflows.py', 'openstack_dashboard/dashboards/admin/flavors/views.py', 'openstack_dashboard/dashboards/admin/flavors/constants.py', 'openstack_dashboard/dashboards/admin/flavors/tests.py', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/create.html', 'openstack_dashboard/dashboards/admin/flavors/templates/flavors/index.html', 'openstack_dashboard/test/integration_tests/pages/admin/system/flavorspage.py']",11,569a889a0802d79dc556d8730f2c56ad43e1af23,remove-legacy-flavor,," CREATE_FLAVOR_FORM_FIELDS = ((""name"", ""flavor_id"", ""vcpus"", ""memory_mb"", ""disk_gb"", ""eph_gb"", ""swap_mb"", ""rxtx_factor""), {""members"": menus.MembershipMenuRegion}) UPDATE_FLAVOR_FORM_FIELDS = ((""name"", ""vcpus"", ""memory_mb"", ""disk_gb"", ""eph_gb"", ""swap_mb"", ""rxtx_factor""), {""members"": menus.MembershipMenuRegion}) @tables.bind_table_action('create') def create_flavor(self, create_button): create_button.click() return forms.TabbedFormRegion( self.driver, self.conf, field_mappings=self.CREATE_FLAVOR_FORM_FIELDS ) @tables.bind_row_action('update') def update_flavor_info(self, edit_button, row): edit_button.click() return forms.TabbedFormRegion( self.driver, self.conf, field_mappings=self.UPDATE_FLAVOR_FORM_FIELDS ) @tables.bind_row_action('projects') def update_flavor_access(self, update_button, row): update_button.click() return forms.TabbedFormRegion( self.driver, self.conf, field_mappings=self.UPDATE_FLAVOR_FORM_FIELDS, default_tab=1 ) @tables.bind_row_action('delete') def delete_by_row(self, delete_button, row): delete_button.click() return forms.BaseFormRegion(self.driver, self.conf) FLAVORS_TABLE_NAME_COLUMN = 'name' FLAVORS_TABLE_VCPUS_COLUMN = 'vcpus' FLAVORS_TABLE_RAM_COLUMN = 'ram' FLAVORS_TABLE_DISK_COLUMN = 'disk' FLAVORS_TABLE_PUBLIC_COLUMN = 'public' @property def flavors_table(self): return FlavorsTable(self.driver, self.conf) def _get_flavor_row(self, name): return self.flavors_table.get_row(self.FLAVORS_TABLE_NAME_COLUMN, name) def create_flavor(self, name, id_=DEFAULT_ID, vcpus=None, ram=None, root_disk=None, ephemeral_disk=None, swap_disk=None): create_flavor_form = self.flavors_table.create_flavor() create_flavor_form.name.text = name if id_ is not None: create_flavor_form.flavor_id.text = id_ create_flavor_form.vcpus.value = vcpus create_flavor_form.memory_mb.value = ram create_flavor_form.disk_gb.value = root_disk create_flavor_form.eph_gb.value = ephemeral_disk create_flavor_form.swap_mb.value = swap_disk create_flavor_form.submit() def is_flavor_present(self, name): return bool(self._get_flavor_row(name)) def update_flavor_info(self, name, add_up): row = self._get_flavor_row(name) update_flavor_form = self.flavors_table.update_flavor_info(row) update_flavor_form.name.text = ""edited-"" + name update_flavor_form.vcpus.value = \ int(update_flavor_form.vcpus.value) + add_up update_flavor_form.memory_mb.value =\ int(update_flavor_form.memory_mb.value) + add_up update_flavor_form.disk_gb.value =\ int(update_flavor_form.disk_gb.value) + add_up update_flavor_form.submit() def update_flavor_access(self, name, project_name, allocate=True): row = self._get_flavor_row(name) update_flavor_form = self.flavors_table.update_flavor_access(row) if allocate: update_flavor_form.members.allocate_member(project_name) else: update_flavor_form.members.deallocate_member(project_name) update_flavor_form.submit() def delete_flavor_by_row(self, name): row = self._get_flavor_row(name) delete_form = self.flavors_table.delete_by_row(row) delete_form.submit() def get_flavor_vcpus(self, name): row = self._get_flavor_row(name) return row.cells[self.FLAVORS_TABLE_VCPUS_COLUMN].text def get_flavor_ram(self, name): row = self._get_flavor_row(name) return row.cells[self.FLAVORS_TABLE_RAM_COLUMN].text def get_flavor_disk(self, name): row = self._get_flavor_row(name) return row.cells[self.FLAVORS_TABLE_DISK_COLUMN].text def is_flavor_public(self, name): row = self._get_flavor_row(name) return row.cells[self.FLAVORS_TABLE_PUBLIC_COLUMN].text == ""Yes""",6,1830
openstack%2Fhorizon~master~Ia84bb35a985979bc735e18da30950b39380902a4,openstack/horizon,master,Ia84bb35a985979bc735e18da30950b39380902a4,Fix help_txt message about ICMP type and code range,ABANDONED,2015-12-17 08:42:45.000000000,2017-02-17 17:14:00.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1653}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 7307}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 17172}, {'_account_id': 17645}, {'_account_id': 17776}, {'_account_id': 19226}]","[{'number': 1, 'created': '2015-12-17 08:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/70359c27cb178811d8b2faeba29572f34f067a14', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 2, 'created': '2015-12-18 01:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f37ef4fe44a80d2d9ca1c9fc5c07d2d9646e657d', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 3, 'created': '2015-12-18 03:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/513577e76f04bcffc8f662ebc4d88a8ac67ad523', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 4, 'created': '2015-12-18 05:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1a74bb541fcd8091806b66430bbf06aa692fe7c5', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 5, 'created': '2015-12-18 09:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1857447bd6fcb9924c65ab605227bb098adb2d40', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 6, 'created': '2015-12-18 09:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/986c697481c415db45bb2655c9090df2b345123a', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 7, 'created': '2015-12-21 07:08:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4453b01371194e8b78374c7f01cff86e46fccf8b', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 8, 'created': '2015-12-22 05:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/98cdfc6757470fc54a2669206b91709976d0e6fc', 'message': 'Fix help_txt message about ICMP type and code range\n\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 9, 'created': '2015-12-24 02:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ef693d5a7de6f29b04f5f7acb26b261d69f04727', 'message': 'Fix help_txt message about ICMP type and code range\n\nICMP type and code help_txt display value range (-1:255)\n\nThis patch fix dashboard help_txt range to (0, 255)\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}, {'number': 10, 'created': '2016-01-05 07:11:42.000000000', 'files': ['openstack_dashboard/dashboards/project/access_and_security/security_groups/tests.py', 'openstack_dashboard/dashboards/project/access_and_security/security_groups/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/c7a0f4f9ef5723bb8a60a3f2b74776c93de19ead', 'message': 'Fix help_txt message about ICMP type and code range\n\nICMP type and code help_txt display value range (-1:255)\n\nThis patch fix dashboard help_txt range to (0, 255)\nChange-Id: Ia84bb35a985979bc735e18da30950b39380902a4\nCloses-Bug: #1527132\n'}]",6,258869,c7a0f4f9ef5723bb8a60a3f2b74776c93de19ead,50,16,10,19226,,,0,"Fix help_txt message about ICMP type and code range

ICMP type and code help_txt display value range (-1:255)

This patch fix dashboard help_txt range to (0, 255)
Change-Id: Ia84bb35a985979bc735e18da30950b39380902a4
Closes-Bug: #1527132
",git fetch https://review.opendev.org/openstack/horizon refs/changes/69/258869/8 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/access_and_security/security_groups/forms.py'],1,70359c27cb178811d8b2faeba29572f34f067a14,abc," ""in the range (0: 255)""), ""in the range (0: 255)""), msg = _('The ICMP type not in range (0, 255)') msg = _('The ICMP code not in range (0, 255)')"," ""in the range (-1: 255)""), ""in the range (-1: 255)""), msg = _('The ICMP type not in range (-1, 255)') msg = _('The ICMP code not in range (-1, 255)')",4,4
openstack%2Fhorizon~master~I188a4be8f2e6d132e2f84c092198a2f0e948ce78,openstack/horizon,master,I188a4be8f2e6d132e2f84c092198a2f0e948ce78,Compression Madness!!!,ABANDONED,2016-08-26 15:33:56.000000000,2017-02-17 17:13:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 11778}]","[{'number': 1, 'created': '2016-08-26 15:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bf33c6572a7afff0f40302699ba93adb3619e201', 'message': 'Compression Madness!!!\n\nChange-Id: I188a4be8f2e6d132e2f84c092198a2f0e948ce78\n'}, {'number': 2, 'created': '2016-08-26 15:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/3c5e014e4d7579a8c5e43e1dccb87fb27cce479d', 'message': 'Compression Madness!!!\n\nChange-Id: I188a4be8f2e6d132e2f84c092198a2f0e948ce78\n'}, {'number': 3, 'created': '2016-11-03 20:46:52.000000000', 'files': ['openstack_dashboard/templates/header/_theme_list.html', 'horizon/themes.py', 'openstack_dashboard/contrib/developer/theme_preview/templates/theme_preview/index.html', 'openstack_dashboard/templates/horizon/_scripts.html', 'openstack_dashboard/themes/material/templates/header/_header.html', 'openstack_dashboard/templatetags/themes.py', 'openstack_dashboard/settings.py', 'openstack_dashboard/templates/_stylesheets.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a43061538bf98234e34b853b7ceb50937cb1ff9b', 'message': 'Compression Madness!!!\n\nChange-Id: I188a4be8f2e6d132e2f84c092198a2f0e948ce78\n'}]",0,361312,a43061538bf98234e34b853b7ceb50937cb1ff9b,9,3,3,11778,,,0,"Compression Madness!!!

Change-Id: I188a4be8f2e6d132e2f84c092198a2f0e948ce78
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/361312/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/templates/header/_theme_list.html', 'horizon/themes.py', 'openstack_dashboard/contrib/developer/theme_preview/templates/theme_preview/index.html', 'openstack_dashboard/templates/horizon/_scripts.html', 'openstack_dashboard/themes/material/templates/header/_header.html', 'openstack_dashboard/templatetags/themes.py', 'openstack_dashboard/context_processors.py', 'openstack_dashboard/settings.py', 'openstack_dashboard/templates/_stylesheets.html']",9,bf33c6572a7afff0f40302699ba93adb3619e201,361312," <div id=""foo"">{{ THEME }}:{{ THEME_DIR }}</div>", {% current_theme as current_theme %} {% theme_dir as theme_dir %} {% with THEME=current_theme THEME_DIR=theme_dir %}{% endwith %},43,38
openstack%2Fhorizon~master~Ie9a5d2c6e688cbf07e52c9fcf702c65c41c93b07,openstack/horizon,master,Ie9a5d2c6e688cbf07e52c9fcf702c65c41c93b07,Alert message in 'Create Network' Modal does not have col-* class modification,ABANDONED,2016-11-18 12:34:23.000000000,2017-02-17 17:13:56.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-11-18 12:34:23.000000000', 'files': ['openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.controller.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d4b672d6b05d5fba2a8e1cab44b64e3087716671', 'message': ""Alert message in 'Create Network' Modal does not have col-* class modification\n\nChange-Id: Ie9a5d2c6e688cbf07e52c9fcf702c65c41c93b07\n""}]",0,399575,d4b672d6b05d5fba2a8e1cab44b64e3087716671,5,3,1,24130,,,0,"Alert message in 'Create Network' Modal does not have col-* class modification

Change-Id: Ie9a5d2c6e688cbf07e52c9fcf702c65c41c93b07
",git fetch https://review.opendev.org/openstack/horizon refs/changes/75/399575/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/local/local_settings.py.example', 'openstack_dashboard/settings.py', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/network/network.controller.js']",3,d4b672d6b05d5fba2a8e1cab44b64e3087716671,refs/meta/config,,console.log($scope.model.networks);,0,4
openstack%2Fhorizon~master~Ib502a8ae9cd1107f3c3459238bbab3ce522397af,openstack/horizon,master,Ib502a8ae9cd1107f3c3459238bbab3ce522397af,"error message do not disappear after click ""cancel"" button on form page",ABANDONED,2016-09-12 07:56:05.000000000,2017-02-17 17:13:55.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 10068}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-09-12 07:56:05.000000000', 'files': ['openstack_dashboard/settings.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/35b882fc60b948dea13c742a8fed9a94fee55696', 'message': 'error message do not disappear after click ""cancel"" button on form page\n\nError message will be disappeared\n\nChange-Id: Ib502a8ae9cd1107f3c3459238bbab3ce522397af\nCloses-Bug: #1520043\n'}]",0,368612,35b882fc60b948dea13c742a8fed9a94fee55696,6,4,1,23191,,,0,"error message do not disappear after click ""cancel"" button on form page

Error message will be disappeared

Change-Id: Ib502a8ae9cd1107f3c3459238bbab3ce522397af
Closes-Bug: #1520043
",git fetch https://review.opendev.org/openstack/horizon refs/changes/12/368612/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/settings.py'],1,35b882fc60b948dea13c742a8fed9a94fee55696,," 'types': ['alert-success', 'alert-info', 'alert-danger']"," 'types': ['alert-success', 'alert-info']",1,1
openstack%2Fhorizon~master~Iff211ae7dc2416ad4455fdbd8a2338bec4b887cd,openstack/horizon,master,Iff211ae7dc2416ad4455fdbd8a2338bec4b887cd,Add Member form of LoadBalancers has a missing ast erisk for 'Members' list,ABANDONED,2016-09-06 13:24:04.000000000,2017-02-17 17:13:53.000000000,,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 14151}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-09-06 13:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5953dce7172e7cfeb791b9e377c6e0bcb86c0079', 'message': ""Add Member form of LoadBalancers has a missing ast\nerisk for 'Members' list\n\nImplemented validation for Member Instance field\n\nChange-Id: Iff211ae7dc2416ad4455fdbd8a2338bec4b887cd\nCloses-Bug: #1396983\n""}, {'number': 2, 'created': '2016-09-07 05:59:29.000000000', 'files': ['openstack_dashboard/dashboards/project/loadbalancers/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a14d7a762e63195e50972d7ac47f48d67acf8752', 'message': ""Add Member form of LoadBalancers has a missing ast\nerisk for 'Members' list\n\nImplemented validation for Member Instance field\n\nChange-Id: Iff211ae7dc2416ad4455fdbd8a2338bec4b887cd\nCloses-Bug: #1396983\n""}]",1,366130,a14d7a762e63195e50972d7ac47f48d67acf8752,10,5,2,23105,,,0,"Add Member form of LoadBalancers has a missing ast
erisk for 'Members' list

Implemented validation for Member Instance field

Change-Id: Iff211ae7dc2416ad4455fdbd8a2338bec4b887cd
Closes-Bug: #1396983
",git fetch https://review.opendev.org/openstack/horizon refs/changes/30/366130/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/loadbalancers/workflows.py'],1,5953dce7172e7cfeb791b9e377c6e0bcb86c0079,," required=True,"," required=False,",1,1
openstack%2Fhorizon~master~I7ccef5011811ef6297d49076a887c9424eccce4a,openstack/horizon,master,I7ccef5011811ef6297d49076a887c9424eccce4a,Delete some included files in MANIFEST.IN,ABANDONED,2016-09-25 03:01:22.000000000,2017-02-17 17:13:52.000000000,,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 12826}, {'_account_id': 22587}, {'_account_id': 22689}, {'_account_id': 22863}]","[{'number': 1, 'created': '2016-09-25 03:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ea256718a5c3d7e180235cabe6844d90676b124b', 'message': 'Delete the files in MANIFEST.IN\n\nPBR can and does do a bunch of things which in MANIFEST.IN,\nso we do not need any more.\n\nChange-Id: I7ccef5011811ef6297d49076a887c9424eccce4a\n'}, {'number': 2, 'created': '2016-09-26 02:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32ca0dbc9a3acef8090d60155e0a6530ec3522fe', 'message': 'Delete some included files in MANIFEST.IN\n\nPBR can and does do a bunch of things which in MANIFEST.IN,\nsuch as: AUTHORS: Generate AUTHORS file from git log\n         ChangeLog: Generate ChangeLog from git log\n         Requirements: Store your dependencies in a pip requirements file\n         long_description: Use your README file as a long_description\nfor more information in [1], so we could remove some files to make code clean.\n\n[1]http://docs.openstack.org/developer/pbr/\n\nChange-Id: I7ccef5011811ef6297d49076a887c9424eccce4a\n'}, {'number': 3, 'created': '2016-09-30 09:32:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/718bbb19698c83b1ded55b5a61ca1084245772a4', 'message': 'Delete some included files in MANIFEST.IN\n\nPBR can and does do a bunch of things which in MANIFEST.IN,\nsuch as: AUTHORS: Generate AUTHORS file from git log\n         ChangeLog: Generate ChangeLog from git log\n         Requirements: Store your dependencies in a pip requirements file\n         long_description: Use your README file as a long_description\nfor more information in [1], so we could remove some files to make code clean.\n\n[1]http://docs.openstack.org/developer/pbr/\n\nChange-Id: I7ccef5011811ef6297d49076a887c9424eccce4a\n'}, {'number': 4, 'created': '2016-10-17 02:19:21.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1b38b583e00aa41a213e8da01047f2b6e29f426', 'message': 'Delete some included files in MANIFEST.IN\n\nPBR can and does do a bunch of things which in MANIFEST.IN,\nsuch as: AUTHORS: Generate AUTHORS file from git log\n         ChangeLog: Generate ChangeLog from git log\n         Requirements: Store your dependencies in a pip requirements file\n         long_description: Use your README file as a long_description\nfor more information in [1], so we could remove some files to make code clean.\n\n[1]http://docs.openstack.org/developer/pbr/\n\nChange-Id: I7ccef5011811ef6297d49076a887c9424eccce4a\n'}]",2,375922,f1b38b583e00aa41a213e8da01047f2b6e29f426,15,7,4,22863,,,0,"Delete some included files in MANIFEST.IN

PBR can and does do a bunch of things which in MANIFEST.IN,
such as: AUTHORS: Generate AUTHORS file from git log
         ChangeLog: Generate ChangeLog from git log
         Requirements: Store your dependencies in a pip requirements file
         long_description: Use your README file as a long_description
for more information in [1], so we could remove some files to make code clean.

[1]http://docs.openstack.org/developer/pbr/

Change-Id: I7ccef5011811ef6297d49076a887c9424eccce4a
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/375922/4 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,ea256718a5c3d7e180235cabe6844d90676b124b,remove-MANIFEST.in,,recursive-include doc *.py *.rst *.scss *.js *.html *.conf *.jpg *.gif *.png recursive-include horizon *.html *.scss *.js *.csv *.template *.tmpl *.mo *.po recursive-include openstack_dashboard *.html *.js *.scss *.mo *.po *.example *.eot *.svg *.ttf *.woff *.png *.ico *.wsgi *.gif *.csv *.template recursive-include tools *.py *.sh include AUTHORS include ChangeLog include LICENSE include Makefile include manage.py include README.rst include run_tests.sh include tox.ini include doc/Makefile include doc/source/_templates/.placeholder include requirements.txt include test-requirements.txt exclude openstack_dashboard/local/local_settings.py ,0,19
openstack%2Ftripleo-ci~master~Ie0c701731723cae813a91aab94478d2ec703b3ab,openstack/tripleo-ci,master,Ie0c701731723cae813a91aab94478d2ec703b3ab,TEST: Don't override worker counts,ABANDONED,2017-02-15 00:14:24.000000000,2017-02-17 17:10:13.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-15 00:14:24.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e16b9e067e62efb231f7d7e0bdb19494385e3014', 'message': ""TEST: Don't override worker counts\n\nI'm just curious what, if any, effect this has on our ha job deploy\ntimes.\n\nChange-Id: Ie0c701731723cae813a91aab94478d2ec703b3ab\n""}]",0,433992,e16b9e067e62efb231f7d7e0bdb19494385e3014,4,1,1,6928,,,0,"TEST: Don't override worker counts

I'm just curious what, if any, effect this has on our ha job deploy
times.

Change-Id: Ie0c701731723cae813a91aab94478d2ec703b3ab
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/92/433992/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,e16b9e067e62efb231f7d7e0bdb19494385e3014,nothing,,"# Limit worker counts to avoid overloading our limited resources if [[ ""${STABLE_RELEASE}"" = ""mitaka"" ]] ; then OVERCLOUD_DEPLOY_ARGS=""$OVERCLOUD_DEPLOY_ARGS -e $TRIPLEO_ROOT/tripleo-ci/test-environments/worker-config-mitaka-and-below.yaml"" elif [[ ""${OVERCLOUD_MAJOR_UPGRADE}"" == ""1"" ]]; then OVERCLOUD_DEPLOY_ARGS=""$OVERCLOUD_DEPLOY_ARGS -e /usr/share/openstack-tripleo-heat-templates/environments/low-memory-usage.yaml"" else OVERCLOUD_DEPLOY_ARGS=""$OVERCLOUD_DEPLOY_ARGS -e $TRIPLEO_ROOT/tripleo-ci/test-environments/worker-config.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/low-memory-usage.yaml"" fi",1,8
openstack%2Ftripleo-ci~master~I9386747d9362aed421dbd1a66ad97c0374cc8244,openstack/tripleo-ci,master,I9386747d9362aed421dbd1a66ad97c0374cc8244,TEST: Enable ConfigDebug,ABANDONED,2017-02-14 22:17:56.000000000,2017-02-17 17:10:00.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2017-02-14 22:17:56.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/08ada2fe2ecbdacd1985b9360d84223455a162d4', 'message': 'TEST: Enable ConfigDebug\n\nChange-Id: I9386747d9362aed421dbd1a66ad97c0374cc8244\n'}]",0,433953,08ada2fe2ecbdacd1985b9360d84223455a162d4,4,1,1,6928,,,0,"TEST: Enable ConfigDebug

Change-Id: I9386747d9362aed421dbd1a66ad97c0374cc8244
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/53/433953/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,08ada2fe2ecbdacd1985b9360d84223455a162d4,nothing,"export OVERCLOUD_DEPLOY_ARGS=""$OVERCLOUD_DEPLOY_ARGS --libvirt-type=qemu -t $OVERCLOUD_DEPLOY_TIMEOUT -e /usr/share/openstack-tripleo-heat-templates/environments/debug.yaml -e /usr/share/openstack-tripleo-heat-templates/environments/config-debug.yaml""","export OVERCLOUD_DEPLOY_ARGS=""$OVERCLOUD_DEPLOY_ARGS --libvirt-type=qemu -t $OVERCLOUD_DEPLOY_TIMEOUT -e /usr/share/openstack-tripleo-heat-templates/environments/debug.yaml""",1,1
openstack%2Fnetworking-sfc~master~I1b861f84b24044ea99f48ac7cb17e341a2968000,openstack/networking-sfc,master,I1b861f84b24044ea99f48ac7cb17e341a2968000,General clean up and optimize the code after PyCharm inspect code.,MERGED,2017-02-16 02:14:04.000000000,2017-02-17 17:09:19.000000000,2017-02-17 17:09:19.000000000,"[{'_account_id': 3}, {'_account_id': 9396}, {'_account_id': 11313}, {'_account_id': 11907}, {'_account_id': 14037}, {'_account_id': 21284}, {'_account_id': 21798}]","[{'number': 1, 'created': '2017-02-16 02:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/fd5c6d7b9e237b56188b224155716c79b71bc2e0', 'message': 'General clean up and optimize the code after PyCharm inspect code.\n\nThe following issues were addressed:\n - Assignment can be replaced with augmented assignment\n - Class must implement all abstract methods\n - Dictionary creation could be rewritten by dictionary literal\n - PEP 8 naming convention violation\n - Unused local\n\nChange-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000\n'}, {'number': 2, 'created': '2017-02-16 02:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/b89a001f1e6f8a3b388e882bfbed3d988e6a1d1f', 'message': 'General clean up and optimize the code after PyCharm inspect code.\n\nThe following issues were addressed:\n - Assignment can be replaced with augmented assignment\n - Dictionary creation could be rewritten by dictionary literal\n - PEP 8 naming convention violation\n - Unused local\n\nChange-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000\n'}, {'number': 3, 'created': '2017-02-16 03:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/4ebb77890ee47b4c1d7c2e3f6fae9beb99ca8822', 'message': 'General clean up and optimize the code after PyCharm inspect code.\n\nThe following issues were addressed:\n - Assignment can be replaced with augmented assignment\n - Dictionary creation could be rewritten by dictionary literal\n - PEP 8 naming convention violation\n - Unused local\n\nChange-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000\n'}, {'number': 4, 'created': '2017-02-16 03:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/25192b8151dc424fbc72ac82338b4097b9bedfab', 'message': 'General clean up and optimize the code after PyCharm inspect code.\n\nThe following issues were addressed:\n - Assignment can be replaced with augmented assignment\n - Dictionary creation could be rewritten by dictionary literal\n - PEP 8 naming convention violation\n - Unused local\n\nChange-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000\n'}, {'number': 5, 'created': '2017-02-16 19:26:09.000000000', 'files': ['networking_sfc/cli/flow_classifier.py', 'networking_sfc/osc/sfc/port_chain.py', 'networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/services/sfc/common/ovs_ext_lib.py', 'networking_sfc/services/sfc/drivers/ovs/driver.py', 'networking_sfc/services/sfc/drivers/ovs/rpc.py', 'networking_sfc/osc/sfc/port_pair_group.py'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/0be24a71c5af23075193197730302c1a466e4c9d', 'message': 'General clean up and optimize the code after PyCharm inspect code.\n\nThe following issues were addressed:\n - Dictionary creation could be rewritten by dictionary literal\n - PEP 8 naming convention violation\n - Unused local\n\nChange-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000\n'}]",8,434583,0be24a71c5af23075193197730302c1a466e4c9d,22,7,5,14037,,,0,"General clean up and optimize the code after PyCharm inspect code.

The following issues were addressed:
 - Dictionary creation could be rewritten by dictionary literal
 - PEP 8 naming convention violation
 - Unused local

Change-Id: I1b861f84b24044ea99f48ac7cb17e341a2968000
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/83/434583/3 && git format-patch -1 --stdout FETCH_HEAD,"['networking_sfc/cli/port_pair.py', 'networking_sfc/cli/flow_classifier.py', 'networking_sfc/cli/port_chain.py', 'networking_sfc/cli/port_pair_group.py', 'networking_sfc/osc/sfc/port_chain.py', 'networking_sfc/services/sfc/agent/extensions/openvswitch/sfc_driver.py', 'networking_sfc/services/sfc/common/ovs_ext_lib.py', 'networking_sfc/services/sfc/drivers/ovs/driver.py', 'networking_sfc/services/sfc/drivers/ovs/rpc.py', 'networking_sfc/osc/sfc/port_pair_group.py']",10,fd5c6d7b9e237b56188b224155716c79b71bc2e0,general_improvements," attrs = _get_common_attrs(self.app.client_manager, parsed_args) attrs = _get_common_attrs(self.app.client_manager, parsed_args, field for field in value.split('&') if field])def _get_common_attrs(client_manager, parsed_args, is_create=True): client_manager.neutronclient, 'port_pair', pp)) _get_attrs(attrs, parsed_args)def _get_attrs(attrs, parsed_args): if 'port_pair_group_parameters' in parsed_args and \ parsed_args.port_pair_group_parameters is not None:"," attrs = _get_common_attrs(self, self.app.client_manager, parsed_args) attrs = _get_common_attrs(self, self.app.client_manager, parsed_args, field for field in value.split('&') if field])def _get_common_attrs(self, client_manager, parsed_args, is_create=True): client_manager.neutronclient, 'port_pair', pp)) _get_attrs(client_manager, attrs, parsed_args)def _get_attrs(client_manager, attrs, parsed_args): if ('port_pair_group_parameters' in parsed_args and parsed_args.port_pair_group_parameters is not None):",46,51
openstack%2Fcongress~master~I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f,openstack/congress,master,I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f,Exclude atomic rule from dependency graph,MERGED,2017-02-17 08:06:27.000000000,2017-02-17 16:57:14.000000000,2017-02-17 16:57:14.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2017-02-17 08:06:27.000000000', 'files': ['congress/tests/policy_engines/test_agnostic.py', 'congress/datalog/compile.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/989e8019d5b466f5eef40ba7154284bca0084300', 'message': 'Exclude atomic rule from dependency graph\n\nDependency graph used by agnostic excludes positive literals\nof type compile.Literal. But when a policy is deleted, the facts\nin the policy are deleted as atomic rules of type compile.Rule. As\na result, some nodes in the dependency graph are prematurely deleted\nbecause the deleting of facts (type compile.Rule) via policy delete\ndecreased ref counters that had not been correspondingly increased\nby the adding of those same facts (type compile.Literal). When a\ndependency graph is thus corrupted, congress gives Internal Server\nError on all future attempts to add/delete/sync rules.\n\nThis patch fixes the problem by having agnostic treat an atomic rule\n(type compile.Rule) the same way it treats an atom\n(type compile.Literal) in the dependency graph -- ignore both.\n\nCloses-Bug: 1662809\n\nChange-Id: I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f\n'}]",0,435294,989e8019d5b466f5eef40ba7154284bca0084300,7,2,1,18591,,,0,"Exclude atomic rule from dependency graph

Dependency graph used by agnostic excludes positive literals
of type compile.Literal. But when a policy is deleted, the facts
in the policy are deleted as atomic rules of type compile.Rule. As
a result, some nodes in the dependency graph are prematurely deleted
because the deleting of facts (type compile.Rule) via policy delete
decreased ref counters that had not been correspondingly increased
by the adding of those same facts (type compile.Literal). When a
dependency graph is thus corrupted, congress gives Internal Server
Error on all future attempts to add/delete/sync rules.

This patch fixes the problem by having agnostic treat an atomic rule
(type compile.Rule) the same way it treats an atom
(type compile.Literal) in the dependency graph -- ignore both.

Closes-Bug: 1662809

Change-Id: I8080cbb7c375d90259f7b8a2a62d714ebe4aee5f
",git fetch https://review.opendev.org/openstack/congress refs/changes/94/435294/1 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/policy_engines/test_agnostic.py', 'congress/datalog/compile.py']",2,989e8019d5b466f5eef40ba7154284bca0084300,bug/1662809, if is_atom_like(formula):def is_atom_rule(x): return is_regular_rule(x) and len(x.body) == 0 and is_literal(x.heads[0]) def is_literal_rule(x): return is_regular_rule(x) and len(x.body) == 0 and is_literal(x.heads[0]) def is_atom_like(x): return is_atom(x) or is_atom_rule(x) def is_literal_like(x): return is_literal(x) or is_literal_rule(x) , if is_atom(formula):,37,1
openstack%2Fnova~master~I7d29ecc00f99724731d120ff94b4bf3210f3a64e,openstack/nova,master,I7d29ecc00f99724731d120ff94b4bf3210f3a64e,Use a service account to make vendordata requests.,MERGED,2016-12-29 05:38:31.000000000,2017-02-17 16:56:44.000000000,2017-01-27 02:10:17.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 6873}, {'_account_id': 7662}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 9796}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 20040}]","[{'number': 1, 'created': '2016-12-29 05:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b00e28b2290121b90305098054f2b9b140be652f', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 2, 'created': '2016-12-31 19:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d875b761a5d6afd5cef70966363cd54e80b2d6ae', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 3, 'created': '2017-01-04 00:59:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/020fcfdfdeb14bcd7ba05b8719b31485dd82b240', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 4, 'created': '2017-01-09 08:24:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd4346842c2b60a1e1e957fda82ad79f35dcb436', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 5, 'created': '2017-01-26 09:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/328fb7a5912701ccdb397e3325c0af1162e3ea27', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 6, 'created': '2017-01-26 10:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/658c44126c704f620f62d524b1944e3d4686ad3d', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\n'}, {'number': 7, 'created': '2017-01-26 11:50:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a45143b7ac8f3049e0f6496738425ab1f7a3d58c', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\nCo-Authored-By: Stephen Finucane <sfinucan@redhat.com>\n'}, {'number': 8, 'created': '2017-01-26 13:40:50.000000000', 'files': ['nova/tests/unit/test_metadata.py', 'nova/conf/__init__.py', 'releasenotes/notes/vendordata-service-tokens-876505167395a56d.yaml', 'nova/conf/vendordata.py', 'nova/api/metadata/vendordata_dynamic.py', 'nova/tests/functional/test_metadata.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1f53bfcc7998f63f130a2cedaf15b41a4506c568', 'message': 'Use a service account to make vendordata requests.\n\nWe should use a service account to make requests to external\nvendordata services. This something which we got wrong in the\nnewton cycle, and discussed how to resolve at the ocata summit.\n\nIt is intended that this fix be backported to newton as well.\n\nThere is a sample external vendordata server which has been\ntested with this implementat at:\n\n   https://github.com/mikalstill/vendordata\n\nChange-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e\nCo-Authored-By: Stephen Finucane <sfinucan@redhat.com>\n'}]",15,415597,1f53bfcc7998f63f130a2cedaf15b41a4506c568,112,20,8,2271,,,0,"Use a service account to make vendordata requests.

We should use a service account to make requests to external
vendordata services. This something which we got wrong in the
newton cycle, and discussed how to resolve at the ocata summit.

It is intended that this fix be backported to newton as well.

There is a sample external vendordata server which has been
tested with this implementat at:

   https://github.com/mikalstill/vendordata

Change-Id: I7d29ecc00f99724731d120ff94b4bf3210f3a64e
Co-Authored-By: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/415597/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_metadata.py', 'nova/conf/__init__.py', 'nova/conf/vendordata.py', 'nova/api/metadata/vendordata_dynamic.py', 'nova/tests/functional/test_metadata.py']",5,b00e28b2290121b90305098054f2b9b140be652f,bp/vendordata-reboot-ocata,"def fake_request(obj, url, method, **kwargs): self.useFixture(fixtures.MonkeyPatch( 'keystoneauth1.session.Session.request', fake_request)) self.useFixture(fixtures.MonkeyPatch( 'keystoneauth1.session.Session.request', fake_request)) self.useFixture(fixtures.MonkeyPatch( 'keystoneauth1.session.Session.request', fake_request))","def fake_request(method, url, **kwargs): self.useFixture(fixtures.MonkeyPatch('requests.request', fake_request)) self.useFixture(fixtures.MonkeyPatch('requests.request', fake_request)) self.useFixture(fixtures.MonkeyPatch('requests.request', fake_request))",72,31
openstack%2Fopenstack-ansible-ops~master~I42b2a63b899cd1254669569dee04f0821cb08ba0,openstack/openstack-ansible-ops,master,I42b2a63b899cd1254669569dee04f0821cb08ba0,Use Trusty sources for any 14.04 build,MERGED,2017-02-17 16:27:31.000000000,2017-02-17 16:55:35.000000000,2017-02-17 16:55:35.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 14805}]","[{'number': 1, 'created': '2017-02-17 16:27:31.000000000', 'files': ['multi-node-aio/setup-cobbler.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/1b40ea4cf32d831440d3169a05b4bb11d6d9297e', 'message': 'Use Trusty sources for any 14.04 build\n\nChange-Id: I42b2a63b899cd1254669569dee04f0821cb08ba0\n'}]",0,435516,1b40ea4cf32d831440d3169a05b4bb11d6d9297e,7,3,1,7784,,,0,"Use Trusty sources for any 14.04 build

Change-Id: I42b2a63b899cd1254669569dee04f0821cb08ba0
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/16/435516/1 && git format-patch -1 --stdout FETCH_HEAD,['multi-node-aio/setup-cobbler.sh'],1,1b40ea4cf32d831440d3169a05b4bb11d6d9297e,trusty-sources,"if [[ $DEFAULT_IMAGE == ""14.04.""* ]]; then","if [[ ""14.04.4"" == $DEFAULT_IMAGE ]]; then",1,1
openstack%2Fgovernance~master~I02ce8501de2c0e6c5873edc73b5585505c869c36,openstack/governance,master,I02ce8501de2c0e6c5873edc73b5585505c869c36,Add stable branch assertion tag for Barbican,MERGED,2017-01-17 14:06:01.000000000,2017-02-17 16:55:06.000000000,2017-02-17 16:55:06.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 6482}, {'_account_id': 7973}, {'_account_id': 11561}, {'_account_id': 12898}, {'_account_id': 21797}]","[{'number': 1, 'created': '2017-01-17 14:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/51597381afdee6a131c137a1f685a18b6c50ba8d', 'message': 'Add stable branch assertion tag for Barbican\n\nSince inception, Barbican has followed the stable branch policy.\nThis patch asserts those polcies are followed by the Barbican\ncommunity.\n\nChange-Id: I02ce8501de2c0e6c5873edc73b5585505c869c36\n'}, {'number': 2, 'created': '2017-02-16 12:20:45.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/cb2183e3cd5d6f07ea035067b7669baace743430', 'message': 'Add stable branch assertion tag for Barbican\n\nSince inception, Barbican has followed the stable branch policy.\nThis patch asserts those polcies are followed by the Barbican\ncommunity.\n\nAlso in this patch, moving the deliverables tags under deliverables,\ninstead of under team.  Barbican has stable branches; we make no such\nassertion on the team. ;-)\n\nChange-Id: I02ce8501de2c0e6c5873edc73b5585505c869c36\n'}]",0,421283,cb2183e3cd5d6f07ea035067b7669baace743430,25,7,2,11561,,,0,"Add stable branch assertion tag for Barbican

Since inception, Barbican has followed the stable branch policy.
This patch asserts those polcies are followed by the Barbican
community.

Also in this patch, moving the deliverables tags under deliverables,
instead of under team.  Barbican has stable branches; we make no such
assertion on the team. ;-)

Change-Id: I02ce8501de2c0e6c5873edc73b5585505c869c36
",git fetch https://review.opendev.org/openstack/governance refs/changes/83/421283/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,51597381afdee6a131c137a1f685a18b6c50ba8d,assert-stable, - stable:follows-policy,,1,0
openstack%2Fopenstack-ansible-tests~master~Id66582a8c684ab9473623debc2fd72801197d6f5,openstack/openstack-ansible-tests,master,Id66582a8c684ab9473623debc2fd72801197d6f5,Reduce MariaDB buffer size to 256M for tests,MERGED,2017-02-17 13:53:00.000000000,2017-02-17 16:42:55.000000000,2017-02-17 16:42:31.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-17 13:53:00.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/e3d2caabe5b113c84445a3e36cd6bc5379c5fd61', 'message': ""Reduce MariaDB buffer size to 256M for tests\n\nThis helps reduce the frequency of out-of-memory errors\nwhen executing tests. We don't need a large buffer, we\njust want things to work.\n\nChange-Id: Id66582a8c684ab9473623debc2fd72801197d6f5\n""}]",0,435451,e3d2caabe5b113c84445a3e36cd6bc5379c5fd61,8,3,1,6816,,,0,"Reduce MariaDB buffer size to 256M for tests

This helps reduce the frequency of out-of-memory errors
when executing tests. We don't need a large buffer, we
just want things to work.

Change-Id: Id66582a8c684ab9473623debc2fd72801197d6f5
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/51/435451/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,e3d2caabe5b113c84445a3e36cd6bc5379c5fd61,,galera_innodb_buffer_pool_size: 256M,galera_innodb_buffer_pool_size: 512M,1,1
openstack%2Fsushy~master~I2e0c420826df536f8fc27578c29bd50946c5f3bb,openstack/sushy,master,I2e0c420826df536f8fc27578c29bd50946c5f3bb,Updated from global requirements,MERGED,2017-02-17 09:43:52.000000000,2017-02-17 16:41:55.000000000,2017-02-17 16:41:55.000000000,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-02-17 09:43:52.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/sushy/commit/ac9d56efc2740b6541a6ad4623f50137a9620674', 'message': 'Updated from global requirements\n\nChange-Id: I2e0c420826df536f8fc27578c29bd50946c5f3bb\n'}]",0,435331,ac9d56efc2740b6541a6ad4623f50137a9620674,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I2e0c420826df536f8fc27578c29bd50946c5f3bb
",git fetch https://review.opendev.org/openstack/sushy refs/changes/31/435331/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,ac9d56efc2740b6541a6ad4623f50137a9620674,openstack/requirements,"hacking<0.13,>=0.12.0 # Apache-2.0sphinx>=1.5.1 # BSDtestrepository>=0.0.18 # Apache-2.0/BSD testscenarios>=0.4 # Apache-2.0/BSD","hacking>=0.12.0,<0.13 # Apache-2.0sphinx>=1.2.1,!=1.3b1,<1.4 # BSDtestrepository>=0.0.18 # Apache-2.0/BSD testscenarios>=0.4 # Apache-2.0/BSD",5,5
openstack%2Fpatrole~master~I4a32fbb6fc5027e9669a2e37142609b4a719e0cb,openstack/patrole,master,I4a32fbb6fc5027e9669a2e37142609b4a719e0cb,Fix for typo of correct volume status,MERGED,2017-02-16 18:31:15.000000000,2017-02-17 16:32:09.000000000,2017-02-17 16:32:09.000000000,"[{'_account_id': 3}, {'_account_id': 23184}, {'_account_id': 23185}, {'_account_id': 23186}]","[{'number': 1, 'created': '2017-02-16 18:31:15.000000000', 'files': ['patrole_tempest_plugin/tests/api/volume/test_volumes_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/1b17ee28eb6290aef2827fd6745be5f30663e7a9', 'message': 'Fix for typo of correct volume status\n\nVolume API RBAC test ""test_volume_reset_status"" is failing because of\ntypo error in volume status.\n\nThis patch provide fix for this problem.\n\nChange-Id: I4a32fbb6fc5027e9669a2e37142609b4a719e0cb\nCloses-Bug: #1665428\n'}]",0,435060,1b17ee28eb6290aef2827fd6745be5f30663e7a9,8,4,1,8205,,,0,"Fix for typo of correct volume status

Volume API RBAC test ""test_volume_reset_status"" is failing because of
typo error in volume status.

This patch provide fix for this problem.

Change-Id: I4a32fbb6fc5027e9669a2e37142609b4a719e0cb
Closes-Bug: #1665428
",git fetch https://review.opendev.org/openstack/patrole refs/changes/60/435060/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_volumes_rbac.py'],1,1b17ee28eb6290aef2827fd6745be5f30663e7a9,bug/1665428," self.client.reset_volume_status(volume['id'], status='available')"," self.client.reset_volume_status(volume['id'], status='availble')",1,1
openstack%2Fkolla-ansible~master~I19efb96605bee3b16df3a0b78cd681e5f15499f6,openstack/kolla-ansible,master,I19efb96605bee3b16df3a0b78cd681e5f15499f6,Support kolla-ansible installed in a virtualenv,MERGED,2017-02-16 13:50:10.000000000,2017-02-17 16:29:59.000000000,2017-02-17 16:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 10787}, {'_account_id': 14119}, {'_account_id': 16620}, {'_account_id': 18723}, {'_account_id': 22165}, {'_account_id': 23717}, {'_account_id': 24408}]","[{'number': 1, 'created': '2017-02-16 13:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0f782345b1716fd518c3839cbbda3b9f9234d7a0', 'message': 'Support kolla-ansible installed in a virtualenv\n\nCurrently it is not possible to use kolla-ansible when it has been\ninstalled in a virtualenv. Virtualenv-based installation may be\ndesirable when a suitable system package (e.g. RPM, .deb) is not\navailable, as it allows the user to install kolla-ansible and its\ndependencies without affecting the system-wide packages.\n\nThis change checks for the presence of the $VIRTUAL_ENV environment\nvariable to determine whether we are running in an virtualenv. Since\nkolla-ansible is not a python script, this comes with the caveat that we\nmust source the virtualenv activation script ($VIRTUAL_ENV/bin/activate)\nbefore executing kolla-ansible.\n\nChange-Id: I19efb96605bee3b16df3a0b78cd681e5f15499f6\nCloses-Bug: #1530319\n'}, {'number': 2, 'created': '2017-02-16 15:32:10.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dbc5967f7364489ba9a590969c3bba1a553b64fb', 'message': 'Support kolla-ansible installed in a virtualenv\n\nCurrently it is not possible to use kolla-ansible when it has been\ninstalled in a virtualenv. Virtualenv-based installation may be\ndesirable when a suitable system package (e.g. RPM, .deb) is not\navailable, as it allows the user to install kolla-ansible and its\ndependencies without affecting the system-wide packages.\n\nThis change checks for the presence of the $VIRTUAL_ENV environment\nvariable to determine whether we are running in an virtualenv. Since\nkolla-ansible is not a python script, this comes with the caveat that we\nmust source the virtualenv activation script ($VIRTUAL_ENV/bin/activate)\nbefore executing kolla-ansible.\n\nChange-Id: I19efb96605bee3b16df3a0b78cd681e5f15499f6\nCloses-Bug: #1530319\n'}]",0,434917,dbc5967f7364489ba9a590969c3bba1a553b64fb,17,9,2,14826,,,0,"Support kolla-ansible installed in a virtualenv

Currently it is not possible to use kolla-ansible when it has been
installed in a virtualenv. Virtualenv-based installation may be
desirable when a suitable system package (e.g. RPM, .deb) is not
available, as it allows the user to install kolla-ansible and its
dependencies without affecting the system-wide packages.

This change checks for the presence of the $VIRTUAL_ENV environment
variable to determine whether we are running in an virtualenv. Since
kolla-ansible is not a python script, this comes with the caveat that we
must source the virtualenv activation script ($VIRTUAL_ENV/bin/activate)
before executing kolla-ansible.

Change-Id: I19efb96605bee3b16df3a0b78cd681e5f15499f6
Closes-Bug: #1530319
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/17/434917/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/kolla-ansible'],1,0f782345b1716fd518c3839cbbda3b9f9234d7a0,bug/1530319," elif [[ -n ${VIRTUAL_ENV} ]] && [[ ${dir_name} == ""${VIRTUAL_ENV}/bin"" ]]; then BASEDIR=""${VIRTUAL_ENV}/share/kolla-ansible""",,2,0
openstack%2Fpython-magnumclient~stable%2Focata~I1f4adc6aa29386b1706b4e82c060029ad5d7de42,openstack/python-magnumclient,stable/ocata,I1f4adc6aa29386b1706b4e82c060029ad5d7de42,Update UPPER_CONSTRAINTS_FILE for stable/ocata,MERGED,2017-02-17 16:08:44.000000000,2017-02-17 16:24:23.000000000,2017-02-17 16:24:23.000000000,"[{'_account_id': 3}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-17 16:08:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/1810099438d0c96b5ef1def0401c00774edf6ce4', 'message': 'Update UPPER_CONSTRAINTS_FILE for stable/ocata\n\nChange-Id: I1f4adc6aa29386b1706b4e82c060029ad5d7de42\n'}]",0,435510,1810099438d0c96b5ef1def0401c00774edf6ce4,7,2,1,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/ocata

Change-Id: I1f4adc6aa29386b1706b4e82c060029ad5d7de42
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/10/435510/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1810099438d0c96b5ef1def0401c00774edf6ce4,create-ocata, {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/ocata} {opts} {packages}, {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fpython-magnumclient~stable%2Focata~I69c7918f3ba05d7c4383d77f1a6499ff8df9558e,openstack/python-magnumclient,stable/ocata,I69c7918f3ba05d7c4383d77f1a6499ff8df9558e,Update .gitreview for stable/ocata,MERGED,2017-02-17 16:08:43.000000000,2017-02-17 16:23:57.000000000,2017-02-17 16:23:57.000000000,"[{'_account_id': 3}, {'_account_id': 20498}]","[{'number': 1, 'created': '2017-02-17 16:08:43.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/e67bb3b2f86e098acbe960a9b7f60eb6a485d034', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: I69c7918f3ba05d7c4383d77f1a6499ff8df9558e\n'}]",0,435509,e67bb3b2f86e098acbe960a9b7f60eb6a485d034,6,2,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: I69c7918f3ba05d7c4383d77f1a6499ff8df9558e
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/09/435509/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,e67bb3b2f86e098acbe960a9b7f60eb6a485d034,create-ocata,defaultbranch=stable/ocata,,1,0
openstack%2Fsushy~master~Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801,openstack/sushy,master,Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801,Add a mockup for controlling VMs with libvirt,MERGED,2017-02-17 13:04:15.000000000,2017-02-17 16:17:04.000000000,2017-02-17 16:17:04.000000000,"[{'_account_id': 3}, {'_account_id': 6773}]","[{'number': 1, 'created': '2017-02-17 13:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/891d3a550ac9ed651a90dc7e875cb9710959e0cf', 'message': 'Add a mockup for controlling VMs with libvirt\n\nThis patch is adding the tools/mockup_server_libvirt, which is a small\nscript that allows users to control virtual machines using the Redfish\nprotocol. This is another way to help people developing and testing\nSushy.\n\nChange-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801\n'}, {'number': 2, 'created': '2017-02-17 15:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/d2b10c52549e41f20701eff5fc43b6652382ef87', 'message': 'Add a mockup for controlling VMs with libvirt\n\nThis patch is adding the tools/mockup_server_libvirt, which is a small\nscript that allows users to control virtual machines using the Redfish\nprotocol. This is another way to help people developing and testing\nSushy.\n\nChange-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801\n'}, {'number': 3, 'created': '2017-02-17 16:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/2002b78912de8a15ba0a0e8ee20c3e918e1bdc61', 'message': 'Add a mockup for controlling VMs with libvirt\n\nThis patch is adding the tools/mockup_server_libvirt, which is a small\nscript that allows users to control virtual machines using the Redfish\nprotocol. This is another way to help people developing and testing\nSushy.\n\nChange-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801\n'}, {'number': 4, 'created': '2017-02-17 16:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sushy/commit/19045e2bf233636f4039f58c0a08d2dc6a22c8b0', 'message': 'Add a mockup for controlling VMs with libvirt\n\nThis patch is adding the tools/mockup_server_libvirt, which is a small\nscript that allows users to control virtual machines using the Redfish\nprotocol. This is another way to help people developing and testing\nSushy.\n\nChange-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801\n'}, {'number': 5, 'created': '2017-02-17 16:03:51.000000000', 'files': ['tools/mockup_server_libvirt/templates/system.json', 'doc/source/usage.rst', 'tools/mockup_server_libvirt/mockup_server_libvirt.py', 'tools/mockup_server_libvirt/requirements.txt', 'tools/mockup_server_libvirt/templates/root.json', 'tools/mockup_server_libvirt/templates/system_collection.json', 'tools/mockup_server_libvirt/__init__.py'], 'web_link': 'https://opendev.org/openstack/sushy/commit/7ef29e361d8c0b0572ec07d7a8e18f8b2295edc2', 'message': 'Add a mockup for controlling VMs with libvirt\n\nThis patch is adding the tools/mockup_server_libvirt, which is a small\nscript that allows users to control virtual machines using the Redfish\nprotocol. This is another way to help people developing and testing\nSushy.\n\nChange-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801\n'}]",0,435435,7ef29e361d8c0b0572ec07d7a8e18f8b2295edc2,13,2,5,6773,,,0,"Add a mockup for controlling VMs with libvirt

This patch is adding the tools/mockup_server_libvirt, which is a small
script that allows users to control virtual machines using the Redfish
protocol. This is another way to help people developing and testing
Sushy.

Change-Id: Ief0b92e8758a8720d0de9c14f02edd9ba7c5e801
",git fetch https://review.opendev.org/openstack/sushy refs/changes/35/435435/5 && git format-patch -1 --stdout FETCH_HEAD,"['tools/mockup_server_libvirt/templates/system.json', 'tools/mockup_server_libvirt/mockup_server_libvirt.py', 'tools/mockup_server_libvirt/requirements.txt', 'tools/mockup_server_libvirt/templates/root.json', 'tools/mockup_server_libvirt/__init__.py', 'tools/mockup_server_libvirt/templates/system_collection.json']",6,891d3a550ac9ed651a90dc7e875cb9710959e0cf,mockup-server-libvirt,"{ ""@odata.type"": ""#ComputerSystemCollection.ComputerSystemCollection"", ""Name"": ""Computer System Collection"", ""Members@odata.count"": {{ system_count }}, ""Members"": [ {% for system in systems %} { ""@odata.id"": ""/redfish/v1/Systems/{{ system }}"" }{% if not loop.last %},{% endif %} {% endfor %} ], ""@odata.context"": ""/redfish/v1/$metadata#ComputerSystemCollection.ComputerSystemCollection"", ""@odata.id"": ""/redfish/v1/Systems"", ""@Redfish.Copyright"": ""Copyright 2014-2016 Distributed Management Task Force, Inc. (DMTF). For the full DMTF copyright policy, see http://www.dmtf.org/about/policies/copyright."" } ",,295,0
openstack%2Fopenstack-ansible-tests~master~Iab871aecfdd34c08fdab2d5aad7e41170ad72e79,openstack/openstack-ansible-tests,master,Iab871aecfdd34c08fdab2d5aad7e41170ad72e79,Update the location of the ARA callback,MERGED,2017-02-17 14:37:45.000000000,2017-02-17 16:16:34.000000000,2017-02-17 16:15:18.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-17 14:37:45.000000000', 'files': ['test-ansible-env-prep.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/dc6c990134a590794bb5c334bf7eae7afec0d319', 'message': 'Update the location of the ARA callback\n\nThe callback path at /ara/callback was removed in\nhttps://review.openstack.org/#/c/432795/ after being deprecated\nsince October 2016. This took effect in the ARA 0.11 release.\n\nUpdate to the new location at /ara/plugins/callbacks.\n\nChange-Id: Iab871aecfdd34c08fdab2d5aad7e41170ad72e79\n'}]",0,435475,dc6c990134a590794bb5c334bf7eae7afec0d319,8,3,1,9061,,,0,"Update the location of the ARA callback

The callback path at /ara/callback was removed in
https://review.openstack.org/#/c/432795/ after being deprecated
since October 2016. This took effect in the ARA 0.11 release.

Update to the new location at /ara/plugins/callbacks.

Change-Id: Iab871aecfdd34c08fdab2d5aad7e41170ad72e79
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/75/435475/1 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-env-prep.sh'],1,dc6c990134a590794bb5c334bf7eae7afec0d319,,"if [ -d ""${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/plugins/callbacks"" ]; then echo ""Linking ${ANSIBLE_PLUGIN_DIR}/callback/ara to ${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/plugins/callbacks/"" ln -sf ""${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/plugins/callbacks"" ""${ANSIBLE_PLUGIN_DIR}/callback/ara/""","if [ -d ""${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/callback/"" ]; then echo ""Linking ${ANSIBLE_PLUGIN_DIR}/callback/ara to ${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/callback/"" ln -sf ""${WORKING_DIR}/.tox/functional/lib/python2.7/site-packages/ara/callback/"" ""${ANSIBLE_PLUGIN_DIR}/callback/ara/""",3,3
openstack%2Fopenstack-ansible-tests~stable%2Focata~I1106df61785db724221794deb38eae765d0f4cd9,openstack/openstack-ansible-tests,stable/ocata,I1106df61785db724221794deb38eae765d0f4cd9,Revert swift git install branch to master,MERGED,2017-02-10 13:40:56.000000000,2017-02-17 16:14:03.000000000,2017-02-10 14:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 2799}]","[{'number': 1, 'created': '2017-02-10 13:40:56.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/bd7e9e2c251f6b719f816665b42d34141742652b', 'message': 'Revert swift git install branch to master\n\nSwift does not yet have a stable/ocata branch.\n\nChange-Id: I1106df61785db724221794deb38eae765d0f4cd9\n'}]",0,432311,bd7e9e2c251f6b719f816665b42d34141742652b,8,2,1,6816,,,0,"Revert swift git install branch to master

Swift does not yet have a stable/ocata branch.

Change-Id: I1106df61785db724221794deb38eae765d0f4cd9
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/11/432311/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,bd7e9e2c251f6b719f816665b42d34141742652b,create-ocata,swift_git_install_branch: master,swift_git_install_branch: stable/ocata,1,1
openstack%2Fopenstack-ansible-os_nova~stable%2Focata~I02bb69c5f39b4686402bb815bdd0b978bcb05b06,openstack/openstack-ansible-os_nova,stable/ocata,I02bb69c5f39b4686402bb815bdd0b978bcb05b06,Enable cell auto enrollment,MERGED,2017-02-16 13:01:28.000000000,2017-02-17 16:11:22.000000000,2017-02-17 16:11:22.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-16 13:01:28.000000000', 'files': ['tasks/main.yml', 'templates/nova.conf.j2', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/7108da4ad2e17afc09a30518b83bf5184e2ddee5', 'message': 'Enable cell auto enrollment\n\nWhen discover_hosts_in_cells_interval is disabled, we need to wait\nfor the nova-compute service to register itself in the service\ndatabase or else it may not be started in time for cell enrollment\nto occur.\n\nHowever, when automatic enrollment is enabled in the scheduler, we\ndo not need to wait for the service to start because the scheduler\nwill enroll it automatically using a periodic task.\n\nBy default we use an automatic enrollment interval of 60 seconds when 10\nor less compute hosts or present, or 300 seconds when >10 compute hosts\nare in the deployment.\n\nChange-Id: I02bb69c5f39b4686402bb815bdd0b978bcb05b06\n(cherry picked from commit 1ad0bb78cedece76064c647ebda3882cf9c7c6d0)\n'}]",0,434889,7108da4ad2e17afc09a30518b83bf5184e2ddee5,7,3,1,6816,,,0,"Enable cell auto enrollment

When discover_hosts_in_cells_interval is disabled, we need to wait
for the nova-compute service to register itself in the service
database or else it may not be started in time for cell enrollment
to occur.

However, when automatic enrollment is enabled in the scheduler, we
do not need to wait for the service to start because the scheduler
will enroll it automatically using a periodic task.

By default we use an automatic enrollment interval of 60 seconds when 10
or less compute hosts or present, or 300 seconds when >10 compute hosts
are in the deployment.

Change-Id: I02bb69c5f39b4686402bb815bdd0b978bcb05b06
(cherry picked from commit 1ad0bb78cedece76064c647ebda3882cf9c7c6d0)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/89/434889/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'templates/nova.conf.j2', 'defaults/main.yml']",3,7108da4ad2e17afc09a30518b83bf5184e2ddee5,skip-service-wait,"# This should be tuned depending on the number of compute hosts present in the # deployment. Large clouds may wish to disable automatic discovery by setting # this value to -1. nova_discover_hosts_in_cells_interval: ""{{ 300 if groups['nova_compute'] | length > 10 else 60 }}"" ",,7,0
openstack%2Freleases~master~I7ab1e3de205510a6522ae12bedbb8381f1f4001e,openstack/releases,master,I7ab1e3de205510a6522ae12bedbb8381f1f4001e,Release senlin ocata rc2,MERGED,2017-02-17 07:28:39.000000000,2017-02-17 16:11:02.000000000,2017-02-17 16:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2017-02-17 07:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fcc70fa2654549b8c6c8efb5f241cafed58a6f43', 'message': 'Release senlin ocata rc2\n\nChange-Id: I7ab1e3de205510a6522ae12bedbb8381f1f4001e\n'}, {'number': 2, 'created': '2017-02-17 09:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/752d57491f9a22653bc3c5cabf99a554933417d9', 'message': 'Release senlin ocata rc2\n\nChange-Id: I7ab1e3de205510a6522ae12bedbb8381f1f4001e\n'}, {'number': 3, 'created': '2017-02-17 15:55:11.000000000', 'files': ['deliverables/ocata/senlin.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/9e548ccce3ce2331720f3dc0100ff9eea7cf1688', 'message': 'Release senlin ocata rc2\n\nChange-Id: I7ab1e3de205510a6522ae12bedbb8381f1f4001e\n'}]",0,435282,9e548ccce3ce2331720f3dc0100ff9eea7cf1688,18,5,3,11034,,,0,"Release senlin ocata rc2

Change-Id: I7ab1e3de205510a6522ae12bedbb8381f1f4001e
",git fetch https://review.opendev.org/openstack/releases refs/changes/82/435282/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/senlin.yaml'],1,fcc70fa2654549b8c6c8efb5f241cafed58a6f43,senlin-ocata-rc2, - version: 3.0.0.0rc2 projects: - repo: openstack/senlin hash: a8a84b5217ba7e50f61711e3450f593ffce323e7,,4,0
openstack%2Freleases~master~Icc87b3fce58983a0f8b4d07cbd4e7403d0c210e8,openstack/releases,master,Icc87b3fce58983a0f8b4d07cbd4e7403d0c210e8,Pike is under development,MERGED,2017-02-17 15:49:56.000000000,2017-02-17 16:10:56.000000000,2017-02-17 16:10:56.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-17 15:49:56.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/55f37a00a13512346522a4901a069ba07db7c53f', 'message': 'Pike is under development\n\nChange status for Pike on releases.o.o\n\nChange-Id: Icc87b3fce58983a0f8b4d07cbd4e7403d0c210e8\n'}]",0,435500,55f37a00a13512346522a4901a069ba07db7c53f,7,3,1,308,,,0,"Pike is under development

Change status for Pike on releases.o.o

Change-Id: Icc87b3fce58983a0f8b4d07cbd4e7403d0c210e8
",git fetch https://review.opendev.org/openstack/releases refs/changes/00/435500/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,55f37a00a13512346522a4901a069ba07db7c53f,pike-started, * :doc:`Under Development <pike/schedule>` * :doc:`Pre-release freeze <ocata/schedule>`, * :doc:`Future <pike/schedule>` * :doc:`Under Development <ocata/schedule>`,2,2
openstack%2Freleases~master~I70cda8b8bdd0e90a6cb609b39bd9c8b18c190153,openstack/releases,master,I70cda8b8bdd0e90a6cb609b39bd9c8b18c190153,Updated Ocata Release for python-magnumclient,MERGED,2017-02-17 04:47:38.000000000,2017-02-17 16:06:03.000000000,2017-02-17 16:06:03.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-17 04:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/a02ebe871e63c5972f32850586bef2d2f5187c70', 'message': 'Updated Ocata Release for python-magnumclient\n\nThis adds missing commands without changing the API, and bug fixes.\nThe osc-lib was added to requirements.txt and unit tests were added\nfor the previously missing commands.\n\nChange-Id: I70cda8b8bdd0e90a6cb609b39bd9c8b18c190153\n'}, {'number': 2, 'created': '2017-02-17 15:43:27.000000000', 'files': ['deliverables/ocata/python-magnumclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f57ced390e586b003774ed35b5a9a792e05c853d', 'message': 'Updated Ocata Release for python-magnumclient\n\nThis adds missing commands without changing the API, and bug fixes.\nThe osc-lib was added to requirements.txt and unit tests were added\nfor the previously missing commands.\n\nChange-Id: I70cda8b8bdd0e90a6cb609b39bd9c8b18c190153\n'}]",0,435241,f57ced390e586b003774ed35b5a9a792e05c853d,10,3,2,668,,,0,"Updated Ocata Release for python-magnumclient

This adds missing commands without changing the API, and bug fixes.
The osc-lib was added to requirements.txt and unit tests were added
for the previously missing commands.

Change-Id: I70cda8b8bdd0e90a6cb609b39bd9c8b18c190153
",git fetch https://review.opendev.org/openstack/releases refs/changes/41/435241/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/ocata/python-magnumclient.yaml'],1,a02ebe871e63c5972f32850586bef2d2f5187c70,, - version: 2.5.0 projects: - repo: openstack/python-magnumclient hash: e6329a75f9536828c07fb2b65a30df20b18092ae,,4,0
openstack%2Fopenstack-ansible-tests~stable%2Focata~Idca42607457c1908921aa0773cb3e48599c1e0e5,openstack/openstack-ansible-tests,stable/ocata,Idca42607457c1908921aa0773cb3e48599c1e0e5,Disable cells auto enrollment in testing repo,MERGED,2017-02-16 14:29:39.000000000,2017-02-17 16:05:57.000000000,2017-02-17 16:05:57.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-16 14:29:39.000000000', 'files': ['test-vars.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/8dde0b40188a7d77a80c29284925c3393a967642', 'message': 'Disable cells auto enrollment in testing repo\n\nThis causes the role to wait until nova-compute has started and\nregistered itself in the service database before continuing with\nenrollment.\n\nChange-Id: Idca42607457c1908921aa0773cb3e48599c1e0e5\n(cherry picked from commit 21d5795b17cce221bcf60909ff9ef92a277a77b2)\n'}]",0,434937,8dde0b40188a7d77a80c29284925c3393a967642,7,3,1,6816,,,0,"Disable cells auto enrollment in testing repo

This causes the role to wait until nova-compute has started and
registered itself in the service database before continuing with
enrollment.

Change-Id: Idca42607457c1908921aa0773cb3e48599c1e0e5
(cherry picked from commit 21d5795b17cce221bcf60909ff9ef92a277a77b2)
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/37/434937/1 && git format-patch -1 --stdout FETCH_HEAD,['test-vars.yml'],1,8dde0b40188a7d77a80c29284925c3393a967642,disable-cell-autoenroll,nova_discover_hosts_in_cells_interval: '-1',,1,0
openstack%2Fnova~stable%2Fmitaka~Id7e8351026ca86694fc9814002b96260f6ba10f9,openstack/nova,stable/mitaka,Id7e8351026ca86694fc9814002b96260f6ba10f9,Skip test_stamp_pattern in cells v1 job,MERGED,2017-02-14 17:49:26.000000000,2017-02-17 16:02:02.000000000,2017-02-17 16:02:01.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2017-02-14 17:49:26.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb1b9f224d6f05674667a7ddf7c8ba77f4f257aa', 'message': 'Skip test_stamp_pattern in cells v1 job\n\ntest_stamp_pattern was recently unskipped:\n\nI2c13099595d8ee8099e02e3f06096078c7d27c34\n\nIt uses security groups which cells v1 does\nnot support, so we have to skip this test in\nthe cells v1 job.\n\nConflicts:\n        devstack/tempest-dsvm-cells-rc\n\nNOTE(mriedem): The conflict is due to not having\nb113cb13e95b4d9305f093342ad4d34378aee8bb in mitaka.\n\nChange-Id: Id7e8351026ca86694fc9814002b96260f6ba10f9\nCloses-Bug: #1664607\n(cherry picked from commit d12535839817c4385986ccaffe52b5903d3088ca)\n(cherry picked from commit 18fb0a17298dce2b361cc47f16d0d1500484f0d1)\n(cherry picked from commit db075faf2a767cf3f62768e85a79c3cff200d3cb)\n'}]",0,433825,fb1b9f224d6f05674667a7ddf7c8ba77f4f257aa,38,4,1,6873,,,0,"Skip test_stamp_pattern in cells v1 job

test_stamp_pattern was recently unskipped:

I2c13099595d8ee8099e02e3f06096078c7d27c34

It uses security groups which cells v1 does
not support, so we have to skip this test in
the cells v1 job.

Conflicts:
        devstack/tempest-dsvm-cells-rc

NOTE(mriedem): The conflict is due to not having
b113cb13e95b4d9305f093342ad4d34378aee8bb in mitaka.

Change-Id: Id7e8351026ca86694fc9814002b96260f6ba10f9
Closes-Bug: #1664607
(cherry picked from commit d12535839817c4385986ccaffe52b5903d3088ca)
(cherry picked from commit 18fb0a17298dce2b361cc47f16d0d1500484f0d1)
(cherry picked from commit db075faf2a767cf3f62768e85a79c3cff200d3cb)
",git fetch https://review.opendev.org/openstack/nova refs/changes/25/433825/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,fb1b9f224d6f05674667a7ddf7c8ba77f4f257aa,bug/1664607,"# test_stamp_pattern uses security groups which aren't supported in cells v1 # tempest.scenario.test_stamp_pattern.TestStampPattern.test_stamp_pattern r=""$r|(?:.*id\-10fd234a\-515c\-41e5\-b092\-8323060598c5.*)""",,3,0
openstack%2Fpuppet-tripleo~stable%2Focata~Icdfa6567168f9ecc555489ed67405f98544bd910,openstack/puppet-tripleo,stable/ocata,Icdfa6567168f9ecc555489ed67405f98544bd910,Add virtual_packages support to norpm provider,MERGED,2017-02-17 00:50:54.000000000,2017-02-17 15:57:10.000000000,2017-02-17 15:57:10.000000000,"[{'_account_id': 3}, {'_account_id': 14985}]","[{'number': 1, 'created': '2017-02-17 00:50:54.000000000', 'files': ['lib/puppet/provider/package/norpm.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/81071f69e9efdc185f36ff68fda70d4d468da987', 'message': ""Add virtual_packages support to norpm provider\n\nThe norpm provider is supposed to noop package installs/updates but if a\npackage name in puppet does not match the installed package, it is being\nreported as not installed.  The provider then 'installs' it every time\nwhich can trigger unwanted service restarts.\n\nChange-Id: Icdfa6567168f9ecc555489ed67405f98544bd910\nCloses-Bug: #1665405\n(cherry picked from commit 525a2c379ba2e2433217af2aa78018dfd8cb0b44)\n""}]",0,435181,81071f69e9efdc185f36ff68fda70d4d468da987,7,2,1,3153,,,0,"Add virtual_packages support to norpm provider

The norpm provider is supposed to noop package installs/updates but if a
package name in puppet does not match the installed package, it is being
reported as not installed.  The provider then 'installs' it every time
which can trigger unwanted service restarts.

Change-Id: Icdfa6567168f9ecc555489ed67405f98544bd910
Closes-Bug: #1665405
(cherry picked from commit 525a2c379ba2e2433217af2aa78018dfd8cb0b44)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/81/435181/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/package/norpm.rb'],1,81071f69e9efdc185f36ff68fda70d4d468da987,bug/1665405, has_feature :virtual_packages ,,2,0
openstack%2Fpuppet-tripleo~stable%2Focata~I875c39b838dcb4e99df66bacc190647367836dc7,openstack/puppet-tripleo,stable/ocata,I875c39b838dcb4e99df66bacc190647367836dc7,Update .gitreview for stable/ocata,MERGED,2017-02-16 12:59:09.000000000,2017-02-17 15:56:58.000000000,2017-02-17 15:56:58.000000000,"[{'_account_id': 3}, {'_account_id': 3153}]","[{'number': 1, 'created': '2017-02-16 12:59:09.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7fb1f9b1b84909c93516e63bf61c3e40b4c53194', 'message': 'Update .gitreview for stable/ocata\n\nChange-Id: I875c39b838dcb4e99df66bacc190647367836dc7\n'}]",0,434874,7fb1f9b1b84909c93516e63bf61c3e40b4c53194,10,2,1,22816,,,0,"Update .gitreview for stable/ocata

Change-Id: I875c39b838dcb4e99df66bacc190647367836dc7
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/74/434874/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,7fb1f9b1b84909c93516e63bf61c3e40b4c53194,create-ocata,defaultbranch=stable/ocata,,1,0
openstack%2Ftripleo-heat-templates~stable%2Fmitaka~I22a9f1cde99c010d00c653861cc7cf34ab4cc06e,openstack/tripleo-heat-templates,stable/mitaka,I22a9f1cde99c010d00c653861cc7cf34ab4cc06e,Ensure working compute node during the whole migration.,MERGED,2017-02-02 11:21:14.000000000,2017-02-17 15:56:51.000000000,2017-02-17 15:56:51.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8297}, {'_account_id': 11933}, {'_account_id': 20172}]","[{'number': 1, 'created': '2017-02-02 11:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d30d4f1357d0c5e889bccebd63962365acc08ed3', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 2, 'created': '2017-02-02 11:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68f6f016ab4c94b343bdf914f9507c6f4e131e4e', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 3, 'created': '2017-02-02 11:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/39113c3aa3f0d8d5bfb64f0e525a95d4f294d86c', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 4, 'created': '2017-02-02 14:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d6df54229d00a413409f205de2808f1023b3420c', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 5, 'created': '2017-02-02 16:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a2cc0c777d5bf108e484d79f56741fb98d65acf7', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 6, 'created': '2017-02-03 11:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ca74643f07fb07e18daf6867e0ee4e8dc3c74ac', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 7, 'created': '2017-02-03 13:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/df1f95dd9026b310d97d8bda7d37cafe6b5a98dd', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 8, 'created': '2017-02-03 13:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d9b4088581ad17d2243dd578493985e11632e09c', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 9, 'created': '2017-02-03 17:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c12d556422aba03d4969dd0282a688458a79539', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 10, 'created': '2017-02-03 17:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/47e460540df7f6966395dfdb555402d8605b3620', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 11, 'created': '2017-02-03 18:22:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/508b1784011a1faf32d37a02f9b6502d546aff21', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 12, 'created': '2017-02-06 10:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/788588f3ab037a8198934eb284b6ca5e89a47a38', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 13, 'created': '2017-02-06 10:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f35ba78cb314096a10fbe5508d7ca53e052ca45f', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 14, 'created': '2017-02-06 11:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/de9cdae349a97d13c52058960d860f4a4ffad71b', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.\n\nThis is a rewrite at having the possibility for the operator to manipulate\ninstance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 15, 'created': '2017-02-06 11:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e4ec27b0e6cc50663b11958367487b7e5bcab2d', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for the service.  This happens only at convergence step\nwhere the database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 16, 'created': '2017-02-06 13:12:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a18e485257b691bc0f729cdc9e04d7b65cc44572', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for the service.  This happens only at convergence step\nwhere the database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 17, 'created': '2017-02-07 09:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4700c43f8ec60373eab1342f8a65e204a3b1152f', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for the service.  This happens only at convergence step\nwhere the database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 18, 'created': '2017-02-07 09:34:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0c6c2aaae029a9561a9871e3d941f7af32ff238d', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for services.  This happens only at convergence step where\nthe database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 19, 'created': '2017-02-10 17:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fdb76cb869ad62baba090875d1d28108e832b5a7', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for services.  This happens only at convergence step where\nthe database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 20, 'created': '2017-02-15 12:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2b28dfdecb5db222f23c85ef415e0d03bc184f6a', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for services.  This happens only at convergence step where\nthe database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}, {'number': 21, 'created': '2017-02-16 08:22:20.000000000', 'files': ['extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade_conf.pp', 'extraconfig/tasks/major_upgrade_pacemaker_init.yaml', 'extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp', 'extraconfig/tasks/major_upgrade_compute.sh', 'extraconfig/tasks/major_upgrade_pacemaker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b2bc3a4081b6eff947acdb13e32e2d64ceb1823c', 'message': 'Ensure working compute node during the whole migration.\n\nFix subtile error introduced during the attempt to get the vm migration\nafter controller upgrade working.  Namely the server.cnf in the my.cnf.d\ndirectory was updated with default values, which include listening to\n127.0.0.1.  This overwrite the galera.cnf configuration and break the\nlink between the haproxy and the database, making the database\nunavailable for services.  This happens only at convergence step where\nthe database is eventually restarted.\n\nBeside fixing this bug, this is a rewrite at having the possibility for\nthe operator to manipulate instance during those states:\n - controllers upgraded/compute not upgraded (vm migration)\n - controllers upgraded/part of compute upgraded (vm migration)\n - controllers upgraded/all computes upgraded/no convergence\n\nChange-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e\nCloses-Bug: #1661202\n'}]",0,428093,b2bc3a4081b6eff947acdb13e32e2d64ceb1823c,72,5,21,8297,,,0,"Ensure working compute node during the whole migration.

Fix subtile error introduced during the attempt to get the vm migration
after controller upgrade working.  Namely the server.cnf in the my.cnf.d
directory was updated with default values, which include listening to
127.0.0.1.  This overwrite the galera.cnf configuration and break the
link between the haproxy and the database, making the database
unavailable for services.  This happens only at convergence step where
the database is eventually restarted.

Beside fixing this bug, this is a rewrite at having the possibility for
the operator to manipulate instance during those states:
 - controllers upgraded/compute not upgraded (vm migration)
 - controllers upgraded/part of compute upgraded (vm migration)
 - controllers upgraded/all computes upgraded/no convergence

Change-Id: I22a9f1cde99c010d00c653861cc7cf34ab4cc06e
Closes-Bug: #1661202
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/93/428093/21 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/tasks/liberty_to_mitaka_compute_nova_api_upgrade.pp', 'extraconfig/tasks/major_upgrade_pacemaker_init.yaml', 'extraconfig/tasks/liberty_to_mitaka_nova_api_upgrade.pp', 'extraconfig/tasks/major_upgrade_compute.sh', 'extraconfig/tasks/major_upgrade_pacemaker.yaml']",5,d30d4f1357d0c5e889bccebd63962365acc08ed3,bug/1661202, NovaApiComputePostConfig: type: OS::Heat::SoftwareConfig properties: group: puppet config: get_file: liberty_to_mitaka_compute_nova_api_upgrade.pp NovaApiComputePostUpgradeDeployment: type: OS::Heat::SoftwareDeploymentGroup depends_on: NovaApiDatabasePostUpgradeDeployment properties: name: NovaApiComputePostUpgradeDeployment servers: {get_param: compute_servers} config: {get_resource: NovaApiComputePostConfig},,53,24
openstack%2Ftripleo-heat-templates~master~Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a,openstack/tripleo-heat-templates,master,Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a,Add docker_puppet_tasks initialization on primary node,MERGED,2017-01-29 13:12:37.000000000,2017-02-17 15:56:44.000000000,2017-02-17 15:56:43.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4571}, {'_account_id': 6159}, {'_account_id': 8042}]","[{'number': 1, 'created': '2017-01-29 13:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e6e8851a87c3ef63be3d6af5e72e5717048bbdeb', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 2, 'created': '2017-01-29 13:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a5573b69bdf55b34b3538c948315f44cba095c1', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 3, 'created': '2017-02-02 16:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9d498ae10d924178b748c45f618f3d58c82d09fb', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 4, 'created': '2017-02-02 17:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81ab7dd3c293dcb1ccf11dee884f554b48cc9e2b', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 5, 'created': '2017-02-03 20:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d982d1e20d9dbff0486fdfbfb58891ea530fa229', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 6, 'created': '2017-02-09 03:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/71d34b18721b4ba28c7f11964dab881828ac6431', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 7, 'created': '2017-02-09 14:33:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6849df5da56b554f583a7a083f2a3912715a87cc', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 8, 'created': '2017-02-10 15:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e9647b3f10731ad0d1c32689762c8f0c15a7bad7', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 9, 'created': '2017-02-10 15:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2dc9b0ca6e67ae7449733084a985d28a1e11636c', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}, {'number': 10, 'created': '2017-02-15 18:10:46.000000000', 'files': ['docker/post.j2.yaml', 'docker/services/services.yaml', 'docker/services/README.rst', 'docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/84626c82cc54a0b1de595cbac06336045947dc4a', 'message': ""Add docker_puppet_tasks initialization on primary node\n\nThis patch adds a new (optional) section to the docker post.j2.yaml\nthat collects any 'docker_puppet_tasks' data from enabled\nservices and applies it on the primary role node (the\nfirst node in the primary (first) role).\n\nThe use case for this is although we are generally only using\npuppet for configuration there are several exceptions that we\ndesire to make use of today for parity with baremetal. This\nincludes things like database creation and keystone endpoint\ninitialization which we rely on configuration via hiera variables\ncontrolled by the puppet services.\n\nChange-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a\n""}]",1,426565,84626c82cc54a0b1de595cbac06336045947dc4a,39,5,10,360,,,0,"Add docker_puppet_tasks initialization on primary node

This patch adds a new (optional) section to the docker post.j2.yaml
that collects any 'docker_puppet_tasks' data from enabled
services and applies it on the primary role node (the
first node in the primary (first) role).

The use case for this is although we are generally only using
puppet for configuration there are several exceptions that we
desire to make use of today for parity with baremetal. This
includes things like database creation and keystone endpoint
initialization which we rely on configuration via hiera variables
controlled by the puppet services.

Change-Id: Ic14ef48f26de761b0d0eabd0e1c0eae52d90e68a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/65/426565/10 && git format-patch -1 --stdout FETCH_HEAD,"['docker/post.j2.yaml', 'docker/services/services.yaml', 'docker/services/README.rst', 'docker/docker-puppet.py']",4,e6e8851a87c3ef63be3d6af5e72e5717048bbdeb,docker_arch2, if service is None: continue,,77,8
openstack%2Ftripleo-heat-templates~stable%2Focata~I0c7a32194c0069b63a501a913c17907b47c9cc16,openstack/tripleo-heat-templates,stable/ocata,I0c7a32194c0069b63a501a913c17907b47c9cc16,Add Newton to Ocata UpgradeInitCommonCommand,MERGED,2017-02-17 01:30:37.000000000,2017-02-17 15:55:52.000000000,2017-02-17 15:55:52.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6924}, {'_account_id': 8449}, {'_account_id': 18851}]","[{'number': 1, 'created': '2017-02-17 01:30:37.000000000', 'files': ['puppet/compute-role.yaml', 'environments/major-upgrade-composable-steps.yaml', 'puppet/cephstorage-role.yaml', 'puppet/role.role.j2.yaml', 'puppet/objectstorage-role.yaml', 'puppet/blockstorage-role.yaml', 'puppet/controller-role.yaml', 'environments/major-upgrade-converge.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/824c54d313145ffd79b70047bdb3b51c11d1e26a', 'message': ""Add Newton to Ocata UpgradeInitCommonCommand\n\nThis adds the UpgradeInitCommonCommand for newton..ocata common\nUpgradeInit commands. This comes before the ansible upgrade steps\nso we need to do things like remove the old newton hieradata and\ninstall the ansible-pacemaker module and ansible heat-agent plugin\n\nThis defaults to '' and is set in the major-upgrade-composable-steps\nand unset in the major-upgrade-converge environment files.\n\nChange-Id: I0c7a32194c0069b63a501a913c17907b47c9cc16\n(cherry picked from commit 01a91d37199f592aa4273e3847eb1f4f1d27da02)\n""}]",0,435190,824c54d313145ffd79b70047bdb3b51c11d1e26a,13,5,1,3153,,,0,"Add Newton to Ocata UpgradeInitCommonCommand

This adds the UpgradeInitCommonCommand for newton..ocata common
UpgradeInit commands. This comes before the ansible upgrade steps
so we need to do things like remove the old newton hieradata and
install the ansible-pacemaker module and ansible heat-agent plugin

This defaults to '' and is set in the major-upgrade-composable-steps
and unset in the major-upgrade-converge environment files.

Change-Id: I0c7a32194c0069b63a501a913c17907b47c9cc16
(cherry picked from commit 01a91d37199f592aa4273e3847eb1f4f1d27da02)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/90/435190/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/compute-role.yaml', 'environments/major-upgrade-composable-steps.yaml', 'puppet/cephstorage-role.yaml', 'puppet/objectstorage-role.yaml', 'puppet/role.role.j2.yaml', 'puppet/blockstorage-role.yaml', 'puppet/controller-role.yaml', 'environments/major-upgrade-converge.yaml']",8,824c54d313145ffd79b70047bdb3b51c11d1e26a,bp/overcloud-upgrades-per-service, UpgradeInitCommonCommand: '',,66,1
openstack%2Fopenstack-ansible-openstack_hosts~stable%2Fnewton~I148492e691e552add6787fdc3937e65bd1366772,openstack/openstack-ansible-openstack_hosts,stable/newton,I148492e691e552add6787fdc3937e65bd1366772,Allow user sysctl list,MERGED,2017-02-17 15:36:46.000000000,2017-02-17 15:51:38.000000000,2017-02-17 15:51:38.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-17 15:36:46.000000000', 'files': ['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/b60c8e1486e5fffa6861e09834698f67f4700851', 'message': 'Allow user sysctl list\n\nLet operators feed the role a list of sysctl settings to set without\noverriding the default openstack_kernel_options list.\n\nChange-Id: I148492e691e552add6787fdc3937e65bd1366772\n(cherry picked from commit f5caf08b972ffb37907668fed4601f8882ad6881)\n'}]",0,435496,b60c8e1486e5fffa6861e09834698f67f4700851,7,3,1,17799,,,0,"Allow user sysctl list

Let operators feed the role a list of sysctl settings to set without
overriding the default openstack_kernel_options list.

Change-Id: I148492e691e552add6787fdc3937e65bd1366772
(cherry picked from commit f5caf08b972ffb37907668fed4601f8882ad6881)
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/96/435496/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml']",2,b60c8e1486e5fffa6861e09834698f67f4700851,user-kernel-options,# Optional user defined list of sysctl options in the same dict item format as # above. openstack_user_kernel_options: [] ,,5,1
openstack%2Fopenstack-ansible-openstack_hosts~stable%2Focata~I148492e691e552add6787fdc3937e65bd1366772,openstack/openstack-ansible-openstack_hosts,stable/ocata,I148492e691e552add6787fdc3937e65bd1366772,Allow user sysctl list,MERGED,2017-02-17 15:36:41.000000000,2017-02-17 15:51:02.000000000,2017-02-17 15:51:02.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17068}]","[{'number': 1, 'created': '2017-02-17 15:36:41.000000000', 'files': ['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/9499c3377cc26cc0ec5102403c0b0e091a2b403d', 'message': 'Allow user sysctl list\n\nLet operators feed the role a list of sysctl settings to set without\noverriding the default openstack_kernel_options list.\n\nChange-Id: I148492e691e552add6787fdc3937e65bd1366772\n(cherry picked from commit f5caf08b972ffb37907668fed4601f8882ad6881)\n'}]",0,435494,9499c3377cc26cc0ec5102403c0b0e091a2b403d,7,3,1,17799,,,0,"Allow user sysctl list

Let operators feed the role a list of sysctl settings to set without
overriding the default openstack_kernel_options list.

Change-Id: I148492e691e552add6787fdc3937e65bd1366772
(cherry picked from commit f5caf08b972ffb37907668fed4601f8882ad6881)
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/94/435494/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml']",2,9499c3377cc26cc0ec5102403c0b0e091a2b403d,user-kernel-options,# Optional user defined list of sysctl options in the same dict item format as # above. openstack_user_kernel_options: [] ,,5,1
openstack%2Fsenlin~stable%2Focata~Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b,openstack/senlin,stable/ocata,Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b,Rename get_service_context to get_service_credentials,MERGED,2017-02-17 14:13:42.000000000,2017-02-17 15:45:07.000000000,2017-02-17 15:45:06.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 14:13:42.000000000', 'files': ['senlin/api/middleware/webhook.py', 'senlin/engine/health_manager.py', 'senlin/tests/unit/policies/test_policy.py', 'senlin/api/middleware/trust.py', 'senlin/policies/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py', 'senlin/tests/unit/api/middleware/test_trust.py', 'senlin/profiles/base.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/receivers/test_receiver.py', 'senlin/tests/unit/profiles/test_profile_base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/54effec5fbb5476db6012be8f4ab0100f9625e80', 'message': 'Rename get_service_context to get_service_credentials\n\nThis rename is to avoid misunderstanding that the function is not\nreturning a RequestContext object.\n\nChange-Id: Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b\n(cherry picked from commit 3be51b20eaec0f6bab54eaca3f4aca2f205e4b81)\n'}]",0,435462,54effec5fbb5476db6012be8f4ab0100f9625e80,6,2,1,8246,,,0,"Rename get_service_context to get_service_credentials

This rename is to avoid misunderstanding that the function is not
returning a RequestContext object.

Change-Id: Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b
(cherry picked from commit 3be51b20eaec0f6bab54eaca3f4aca2f205e4b81)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/62/435462/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/middleware/webhook.py', 'senlin/engine/health_manager.py', 'senlin/tests/unit/policies/test_policy.py', 'senlin/api/middleware/trust.py', 'senlin/policies/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py', 'senlin/tests/unit/api/middleware/test_trust.py', 'senlin/profiles/base.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/receivers/test_receiver.py', 'senlin/tests/unit/profiles/test_profile_base.py']",12,54effec5fbb5476db6012be8f4ab0100f9625e80,get-svc-ctx," @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_init(self, mock_creds): mock_creds.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_init_with_context(self, mock_creds): mock_creds.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_create(self, mock_creds): mock_creds.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_create_failed_validation(self, mock_creds, mock_validate): mock_creds.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context_for_real(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context_for_real_with_data(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with(region_name='region_dist')"," @mock.patch.object(senlin_ctx, 'get_service_context') def test_init(self, mock_ctx): mock_ctx.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_context') def test_init_with_context(self, mock_ctx): mock_ctx.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_context') def test_create(self, mock_context): mock_context.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_context') def test_create_failed_validation(self, mock_context, mock_validate): mock_context.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context_for_real(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context_for_real_with_data(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with(region_name='region_dist')",82,77
openstack%2Freleases~master~Id022410613a851d7f0da1f78ec583d21f30c7e55,openstack/releases,master,Id022410613a851d7f0da1f78ec583d21f30c7e55,Pike release schedule,MERGED,2017-01-25 16:06:07.000000000,2017-02-17 15:43:43.000000000,2017-02-17 15:43:43.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2417}, {'_account_id': 2472}, {'_account_id': 3153}, {'_account_id': 5046}, {'_account_id': 5314}, {'_account_id': 5638}, {'_account_id': 11750}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 16708}, {'_account_id': 19810}]","[{'number': 1, 'created': '2017-01-25 16:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e584c054368a9b17337d3a79318c6cee080b160e', 'message': 'Strawman Pike release schedule\n\nPending confirmation of the PTG2 date, this is a proposed schedule\nfor the Pike cycle. Please let us know of any problems.\n\nChange-Id: Id022410613a851d7f0da1f78ec583d21f30c7e55\n'}, {'number': 2, 'created': '2017-02-07 12:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/02267e10f8479dc8a36dc772c5b90e29c05f1a31', 'message': 'Strawman Pike release schedule\n\nPending confirmation of the PTG2 date, this is a proposed schedule\nfor the Pike cycle. Please let us know of any problems.\n\nChange-Id: Id022410613a851d7f0da1f78ec583d21f30c7e55\n'}, {'number': 3, 'created': '2017-02-14 12:06:23.000000000', 'files': ['doc/source/pike/schedule.rst', 'doc/source/index.rst', 'doc/source/pike/schedule.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5c1505582cbd433f0390fceb424a081a2537a501', 'message': 'Pike release schedule\n\nPTG2 is now 99% sure to happen on Sept 11-15 week. Here is the\nproposed schedule for the Pike cycle.\n\nChange-Id: Id022410613a851d7f0da1f78ec583d21f30c7e55\n'}]",4,425254,5c1505582cbd433f0390fceb424a081a2537a501,32,13,3,308,,,0,"Pike release schedule

PTG2 is now 99% sure to happen on Sept 11-15 week. Here is the
proposed schedule for the Pike cycle.

Change-Id: Id022410613a851d7f0da1f78ec583d21f30c7e55
",git fetch https://review.opendev.org/openstack/releases refs/changes/54/425254/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/pike/schedule.rst', 'doc/source/index.rst', 'doc/source/pike/schedule.yaml']",3,e584c054368a9b17337d3a79318c6cee080b160e,pike-release-schedule,--- start-week: 2017-02-27 release-week: 2017-08-28 cycle: - end: '2017-02-24' start: '2017-02-20' x-project: - o-release - p-ptg0 - p-goals-research - end: '2017-03-03' name: R-26 start: '2017-02-27' - end: '2017-03-10' name: R-25 start: '2017-03-06' - end: '2017-03-17' name: R-24 start: '2017-03-13' - end: '2017-03-24' name: R-23 start: '2017-03-20' - end: '2017-03-31' name: R-22 start: '2017-03-27' - end: '2017-04-07' name: R-21 start: '2017-04-03' - end: '2017-04-14' name: R-20 start: '2017-04-10' x-project: - p-1 - end: '2017-04-21' name: R-19 start: '2017-04-17' - end: '2017-04-28' name: R-18 start: '2017-04-24' - end: '2017-05-05' name: R-17 start: '2017-05-01' - end: '2017-05-12' name: R-16 start: '2017-05-08' x-project: - p-summit - end: '2017-05-19' name: R-15 start: '2017-05-15' - end: '2017-05-26' name: R-14 start: '2017-05-22' - end: '2017-06-02' name: R-13 start: '2017-05-29' - end: '2017-06-09' name: R-12 start: '2017-06-05' x-project: - p-2 - p-mf - end: '2017-06-16' name: R-11 start: '2017-06-12' - end: '2017-06-23' name: R-10 start: '2017-06-19' - end: '2017-06-30' name: R-9 start: '2017-06-26' - end: '2017-07-07' name: R-8 start: '2017-07-03' - end: '2017-07-14' name: R-7 start: '2017-07-10' x-project: - p-extra-atcs - end: '2017-07-21' name: R-6 start: '2017-07-17' - end: '2017-07-28' name: R-5 start: '2017-07-24' x-project: - p-3 - p-ff - p-final-clientlib - p-soft-sf - p-rf - p-goals-complete - end: '2017-08-04' name: R-4 start: '2017-07-31' - end: '2017-08-11' name: R-3 start: '2017-08-07' x-project: - p-rc1 - p-hard-sf - end: '2017-08-18' name: R-2 start: '2017-08-14' - end: '2017-08-25' name: R-1 start: '2017-08-21' x-project: - p-finalrc - end: '2017-09-01' name: R+0 start: '2017-08-28' x-project: - p-release - end: '2017-09-08' name: R+1 start: '2017-09-04' - end: '2017-09-15' name: R+2 start: '2017-09-11' x-project: - p-trailing ,,172,49
openstack%2Ffuel-library~stable%2Fnewton~Icd6e3d0338809e19e0a2fb0a4527cdf7cefdd02e,openstack/fuel-library,stable/newton,Icd6e3d0338809e19e0a2fb0a4527cdf7cefdd02e,httpd: explicitly load mod_reqtimeout,MERGED,2017-01-27 12:08:14.000000000,2017-02-17 15:42:13.000000000,2017-02-17 15:38:38.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11827}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-01-27 12:08:14.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/apache_api_proxy.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5e79fd2a440c1bdf54b7308614073e37292f303c', 'message': 'httpd: explicitly load mod_reqtimeout\n\nOn rhel7 this module is not loaded by default, thus\napache_api_proxy.pp fails. It worth to load it explicitly.\n\nChange-Id: Icd6e3d0338809e19e0a2fb0a4527cdf7cefdd02e\nCloses-Bug: #1623905\nSigned-off-by: Pavel Glushchak <pglushchak@virtuozzo.com>\n(cherry picked from commit b460f39291ee84d40d5964cfbdc5f41d4a0da369)\n'}]",0,426198,5e79fd2a440c1bdf54b7308614073e37292f303c,32,8,1,13344,,,0,"httpd: explicitly load mod_reqtimeout

On rhel7 this module is not loaded by default, thus
apache_api_proxy.pp fails. It worth to load it explicitly.

Change-Id: Icd6e3d0338809e19e0a2fb0a4527cdf7cefdd02e
Closes-Bug: #1623905
Signed-off-by: Pavel Glushchak <pglushchak@virtuozzo.com>
(cherry picked from commit b460f39291ee84d40d5964cfbdc5f41d4a0da369)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/98/426198/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/apache_api_proxy.pp'],1,5e79fd2a440c1bdf54b7308614073e37292f303c,bug/1623905, include ::apache::mod::proxy include ::apache::mod::proxy_connect include ::apache::mod::proxy_http include ::apache::mod::headers include ::apache::mod::reqtimeout," class {""::apache::mod::proxy"": } class {""::apache::mod::proxy_connect"": } class {""::apache::mod::proxy_http"": } class {""::apache::mod::headers"": }",5,4
openstack%2Fopenstack-ansible-pip_install~master~Ied2960ba3870da8dd88c6f616357ace359b83694,openstack/openstack-ansible-pip_install,master,Ied2960ba3870da8dd88c6f616357ace359b83694,vars: suse.yml: Add SUSE support,MERGED,2017-02-15 14:55:41.000000000,2017-02-17 15:42:10.000000000,2017-02-17 15:42:10.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-02-15 14:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/fb538908ae03cf34cf4572879c469075e0552d30', 'message': 'vars: suse.yml: Add SUSE support\n\nAdd new variables file for SUSE based distributions\n\nChange-Id: Ied2960ba3870da8dd88c6f616357ace359b83694\n'}, {'number': 2, 'created': '2017-02-15 16:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/46d4bc69b2642d64f8c128ebb3c9d502058e06c3', 'message': ""vars: suse.yml: Add SUSE support\n\nAdd new variables file for SUSE based distributions. SUSE doesn't\nprovide a keyring package so we set the\npip_install_external_repo_key_package to an empty string by default.\n\nChange-Id: Ied2960ba3870da8dd88c6f616357ace359b83694\n""}, {'number': 3, 'created': '2017-02-15 16:17:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/59a3c41a69abe28065e63b76cb4979ea1e31bf69', 'message': ""vars: suse.yml: Add SUSE support\n\nAdd new variables file for SUSE based distributions. SUSE doesn't\nprovide a keyring package so we set the\npip_install_external_repo_key_package to an empty string by default.\n\nChange-Id: Ied2960ba3870da8dd88c6f616357ace359b83694\n""}, {'number': 4, 'created': '2017-02-17 10:22:06.000000000', 'files': ['tasks/pre_install.yml', 'releasenotes/notes/suse-support-7919a5e43ebdd793.yaml', 'vars/suse.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/1a378b5ddb8f97574b56f2dbf6116a92e49f0f4d', 'message': ""vars: suse.yml: Add SUSE support\n\nAdd new variables file for SUSE based distributions. SUSE doesn't\nprovide a keyring package and all requires packages are available in\nthe default repositories so we skip the relevant tasks.\n\nChange-Id: Ied2960ba3870da8dd88c6f616357ace359b83694\n""}]",3,434328,1a378b5ddb8f97574b56f2dbf6116a92e49f0f4d,16,4,4,23163,,,0,"vars: suse.yml: Add SUSE support

Add new variables file for SUSE based distributions. SUSE doesn't
provide a keyring package and all requires packages are available in
the default repositories so we skip the relevant tasks.

Change-Id: Ied2960ba3870da8dd88c6f616357ace359b83694
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/28/434328/3 && git format-patch -1 --stdout FETCH_HEAD,['vars/suse.yml'],1,fb538908ae03cf34cf4572879c469075e0552d30,add-suse-support,"--- # Copyright 2017, SUSE LINUX GmbH. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. pip_install_distro_build_packages: - gcc - libffi-devel - libopenssl-devel - python-devel - python-pyasn1 - python-pyOpenSSL pip_required_pip_packages: - ndg-httpsclient # SSL SNI support - requests # SSL SNI support ",,26,0
openstack%2Fsenlin~stable%2Focata~I1543ad718778afa0350f21f8e69e37efaf66d45a,openstack/senlin,stable/ocata,I1543ad718778afa0350f21f8e69e37efaf66d45a,Fix start checking  condition,MERGED,2017-02-17 12:53:18.000000000,2017-02-17 15:39:33.000000000,2017-02-17 15:39:33.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-17 12:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f0d58442921a7f0f09e382f560881dfee9ea64b4', 'message': 'Fix start checking  condition\n\nThis patch fixes start checking condition when claiming and registry\ncluster.\n\nChange-Id: I1543ad718778afa0350f21f8e69e37efaf66d45a\n(cherry picked from commit df669a6164b0f934112548b1a55c49af072a698d)\n'}, {'number': 2, 'created': '2017-02-17 13:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a4ba2316e969b903e8374c14942a54cbfb02a935', 'message': 'Fix start checking  condition\n\nThis patch fixes start checking condition when claiming and registry\ncluster.\n\nChange-Id: I1543ad718778afa0350f21f8e69e37efaf66d45a\n(cherry picked from commit df669a6164b0f934112548b1a55c49af072a698d)\n'}, {'number': 3, 'created': '2017-02-17 14:17:16.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a7dcfdfe7542f6748cc7d47928d9d7ad761df9e0', 'message': 'Fix start checking  condition\n\nThis patch fixes start checking condition when claiming and registry\ncluster.\n\nChange-Id: I1543ad718778afa0350f21f8e69e37efaf66d45a\n(cherry picked from commit df669a6164b0f934112548b1a55c49af072a698d)\n'}]",0,435430,a7dcfdfe7542f6748cc7d47928d9d7ad761df9e0,9,3,3,8246,,,0,"Fix start checking  condition

This patch fixes start checking condition when claiming and registry
cluster.

Change-Id: I1543ad718778afa0350f21f8e69e37efaf66d45a
(cherry picked from commit df669a6164b0f934112548b1a55c49af072a698d)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/30/435430/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py']",2,f0d58442921a7f0f09e382f560881dfee9ea64b4,health-checking,"from senlin import objects @mock.patch.object(objects.HealthRegistry, 'update') def test__load_runtime_registry(self, mock_update, mock_claim): mock.call(12, self.hm._poll_cluster, None, 'CID1', 12) @mock.patch.object(hr.HealthRegistry, 'create') def test_register_cluster_not_enabled(self, mock_reg_create): ctx = mock.Mock() timer = mock.Mock() mock_add_tm = self.patchobject(self.hm.TG, 'add_dynamic_timer', return_value=timer) mock_poll = self.patchobject(self.hm, '_poll_cluster', return_value=mock.Mock()) x_reg = mock.Mock(cluster_id='CLUSTER_ID', check_type=consts.NODE_STATUS_POLLING, interval=50, params={}, enabled=False) mock_reg_create.return_value = x_reg self.hm.register_cluster(ctx, cluster_id='CLUSTER_ID', check_type=consts.NODE_STATUS_POLLING, interval=50, enabled=x_reg.enabled) mock_reg_create.assert_called_once_with( ctx, 'CLUSTER_ID', consts.NODE_STATUS_POLLING, 50, {}, 'ENGINE_ID', enabled=False) mock_add_tm.assert_not_called() mock_poll.assert_not_called() self.assertEqual(1, len(self.hm.registries)) "," def test__load_runtime_registry(self, mock_claim): mock.call(12, self.hm._poll_cluster, None, 'CID1', 12), mock.call(34, self.hm._poll_cluster, None, 'CID2', 34) 'timer': timer2,",37,7
openstack%2Fbifrost~master~Ia169af2c36acd42723138dc23a964a64664bbda1,openstack/bifrost,master,Ia169af2c36acd42723138dc23a964a64664bbda1,WiP do not restart libvirt net unless needed,ABANDONED,2017-02-16 17:18:20.000000000,2017-02-17 15:38:39.000000000,,"[{'_account_id': 3}, {'_account_id': 9542}, {'_account_id': 22474}, {'_account_id': 23163}]","[{'number': 1, 'created': '2017-02-16 17:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/0a858d87cc9790618ada0f6f917761976844ae57', 'message': ""WiP Re-create the libvirt network from scratch\n\nThis is an attempt to overcome our libvirt networking problems in gates.\n\nThe patch first removes the requested network from libvirt, and then\nre-defines from XML template and starts it again.\n\nMost parts of network template are customizable, with defaults\ncorresponding to standard libvirt's 'default' network\n(as of Ubuntu Xenial).\n\nChange-Id: Ia169af2c36acd42723138dc23a964a64664bbda1\nRelated-Bug: #1650025\nRelated-Bug: #1660953\n""}, {'number': 2, 'created': '2017-02-16 18:14:37.000000000', 'files': ['playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml', 'playbooks/roles/bifrost-create-vm-nodes/templates/net.xml.j2', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/710a2d862d61003dc75da542346df57e56196ced', 'message': ""WiP do not restart libvirt net unless needed\n\nThis is an attempt to overcome our libvirt networking problems in gates.\n\nThis patch tries to use ansible modules to ensure that the libvirt\nnetwork exists (and create it from template only if it does not),\nand then that it is running.\n\nMost parts of network template are customizable, with defaults\ncorresponding to standard libvirt's 'default' network\n(as of Ubuntu Xenial).\n\nChange-Id: Ia169af2c36acd42723138dc23a964a64664bbda1\nRelated-Bug: #1650025\nRelated-Bug: #1660953\n""}]",3,435036,710a2d862d61003dc75da542346df57e56196ced,9,4,2,9542,,,0,"WiP do not restart libvirt net unless needed

This is an attempt to overcome our libvirt networking problems in gates.

This patch tries to use ansible modules to ensure that the libvirt
network exists (and create it from template only if it does not),
and then that it is running.

Most parts of network template are customizable, with defaults
corresponding to standard libvirt's 'default' network
(as of Ubuntu Xenial).

Change-Id: Ia169af2c36acd42723138dc23a964a64664bbda1
Related-Bug: #1650025
Related-Bug: #1660953
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/36/435036/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml', 'playbooks/roles/bifrost-create-vm-nodes/templates/net.xml.j2', 'playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml']",3,0a858d87cc9790618ada0f6f917761976844ae57,bug/1650025," # NOTE(pas-ha) name and default are chosen to be the same # as in 'bifrost-ironic-install' role network_interface: ""virbr0"" # NOTE(pas-ha) these correspond to settings for the libvirt network created by defaulttest_vm_network_ip: ""192.168.122.1"" test_vm_network_netmask: ""255.255.255.0"" test_vm_network_enable_dhcp: true test_vm_network_dhcp_start: ""192.168.122.2"" test_vm_network_dhcp_end: ""192.168.122.254"" ",,52,4
openstack%2Fopenstack-ansible~master~Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65,openstack/openstack-ansible,master,Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65,SHA Bump for master 15-02-2017,MERGED,2017-02-15 11:37:05.000000000,2017-02-17 15:37:05.000000000,2017-02-17 15:37:05.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 11268}, {'_account_id': 17799}]","[{'number': 1, 'created': '2017-02-15 11:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/94ae2223cb08fc6fa6629dfe8f2678238bea1657', 'message': 'SHA Bump for master 15-02-2017\n\nChange-Id: Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65\n'}, {'number': 2, 'created': '2017-02-16 14:28:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5f9082adc36f32b32092176134c641e5ec931155', 'message': 'SHA Bump for master 15-02-2017\n\nAdditionally set the thread count for the nova-placement uwsgi service\nto reduce memory footprint, and reduce the galera server memory\nfootprint.\n\nChange-Id: Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65\n'}, {'number': 3, 'created': '2017-02-16 16:34:42.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'scripts/scripts-library.sh', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2', 'playbooks/inventory/group_vars/all.yml', 'playbooks/defaults/repo_packages/openstack_testing.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2b21dc28afbee0c86bd2919a3e2a7040eb7d9550', 'message': 'SHA Bump for master 15-02-2017\n\nAdditionally set the thread count for the nova-placement uwsgi service\nto reduce memory footprint, and reduce the galera server memory\nfootprint.\n\nChange-Id: Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65\n'}]",1,434234,2b21dc28afbee0c86bd2919a3e2a7040eb7d9550,23,5,3,2799,,,0,"SHA Bump for master 15-02-2017

Additionally set the thread count for the nova-placement uwsgi service
to reduce memory footprint, and reduce the galera server memory
footprint.

Change-Id: Ic8b3c3632218f7dbe848f75c0cfa431cefb7eb65
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/34/434234/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'global-requirement-pins.txt', 'playbooks/defaults/repo_packages/gnocchi.yml', 'playbooks/defaults/repo_packages/nova_consoles.yml', 'scripts/scripts-library.sh', 'playbooks/defaults/repo_packages/openstack_testing.yml', 'playbooks/inventory/group_vars/all.yml']",7,94ae2223cb08fc6fa6629dfe8f2678238bea1657,sha-update, - setuptools==34.2.0, - setuptools==34.1.0,38,38
openstack%2Fopenstack-ansible-openstack_hosts~master~I148492e691e552add6787fdc3937e65bd1366772,openstack/openstack-ansible-openstack_hosts,master,I148492e691e552add6787fdc3937e65bd1366772,Allow user sysctl list,MERGED,2017-02-17 04:38:08.000000000,2017-02-17 15:36:46.000000000,2017-02-17 15:36:12.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-17 04:38:08.000000000', 'files': ['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/f5caf08b972ffb37907668fed4601f8882ad6881', 'message': 'Allow user sysctl list\n\nLet operators feed the role a list of sysctl settings to set without\noverriding the default openstack_kernel_options list.\n\nChange-Id: I148492e691e552add6787fdc3937e65bd1366772\n'}]",0,435237,f5caf08b972ffb37907668fed4601f8882ad6881,10,3,1,17799,,,0,"Allow user sysctl list

Let operators feed the role a list of sysctl settings to set without
overriding the default openstack_kernel_options list.

Change-Id: I148492e691e552add6787fdc3937e65bd1366772
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/37/435237/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/openstack_kernel_tuning.yml', 'defaults/main.yml']",2,f5caf08b972ffb37907668fed4601f8882ad6881,user-kernel-options,# Optional user defined list of sysctl options in the same dict item format as # above. openstack_user_kernel_options: [] ,,5,1
openstack%2Fsenlin~stable%2Focata~I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba,openstack/senlin,stable/ocata,I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba,Support 'enabled' in attach callback,MERGED,2017-02-17 14:14:28.000000000,2017-02-17 15:33:54.000000000,2017-02-17 15:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 14:14:28.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/tests/unit/fakes.py', 'senlin/policies/lb_policy.py', 'senlin/engine/cluster.py', 'senlin/policies/base.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/policies/affinity_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/dc2e77d6fd3ccf787a68b9666da716a3326422b0', 'message': ""Support 'enabled' in attach callback\n\nWe have supported 'enabled' option in api/db when attaching policy\nto a cluster. This patch supports 'enabled' in attach callback, or else\nwe will get bug when we run 'senlin cluster-policy-attach' with\n'enabled'=False.\n\nCloses-Bug: #1664208\nChange-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba\n(cherry picked from commit fb240766a2505d5ad527ba314913c90a9f8da6b1)\n""}]",0,435463,dc2e77d6fd3ccf787a68b9666da716a3326422b0,6,2,1,8246,,,0,"Support 'enabled' in attach callback

We have supported 'enabled' option in api/db when attaching policy
to a cluster. This patch supports 'enabled' in attach callback, or else
we will get bug when we run 'senlin cluster-policy-attach' with
'enabled'=False.

Closes-Bug: #1664208
Change-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba
(cherry picked from commit fb240766a2505d5ad527ba314913c90a9f8da6b1)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/63/435463/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/tests/unit/fakes.py', 'senlin/policies/lb_policy.py', 'senlin/engine/cluster.py', 'senlin/policies/base.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/policies/affinity_policy.py']",8,dc2e77d6fd3ccf787a68b9666da716a3326422b0,bug/1664208," def attach(self, cluster, enabled=True): :para cluster: The cluster to which the policy is being attached to. :param enabled: The attached cluster policy is enabled or disabled."," def attach(self, cluster): :para cluster: The target cluster to attach to;",20,13
openstack%2Fnova-specs~master~Id9d36f723dbc20c65293f22a4eaee55715b235d2,openstack/nova-specs,master,Id9d36f723dbc20c65293f22a4eaee55715b235d2,Virtual guest device role tagging,MERGED,2017-02-17 11:42:13.000000000,2017-02-17 15:33:25.000000000,2017-02-17 15:33:25.000000000,"[{'_account_id': 3}, {'_account_id': 6873}, {'_account_id': 8864}]","[{'number': 1, 'created': '2017-02-17 11:42:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/51b1cefdb0c1c38318f605a3d36837699aba493e', 'message': 'Virtual guest device role tagging\n\nThis will provide a mechanism for the user to tag a device they\nhave assigned to their guest with a specific role. The tag will\nbe matched to the hardware address of the device and this mapping\nexposed to the guest OS via metadata service/cloud-init\n\nSpec for bp/virt-device-tagged-attach-detach\n\nAPIImpact\n\nChange-Id: Id9d36f723dbc20c65293f22a4eaee55715b235d2\nPreviously-approved: Ocata\n'}, {'number': 2, 'created': '2017-02-17 14:37:59.000000000', 'files': ['specs/pike/approved/virt-device-tagged-attach-detach.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7fcda788571021310e3ce0a7be2e681434a0f038', 'message': 'Virtual guest device role tagging\n\nThis will provide a mechanism for the user to tag a device they\nhave assigned to their guest with a specific role. The tag will\nbe matched to the hardware address of the device and this mapping\nexposed to the guest OS via metadata service/cloud-init\n\nSpec for bp/virt-device-tagged-attach-detach\n\nAPIImpact\n\nChange-Id: Id9d36f723dbc20c65293f22a4eaee55715b235d2\nPreviously-approved: Ocata\n'}]",2,435397,7fcda788571021310e3ce0a7be2e681434a0f038,10,3,2,8864,,,0,"Virtual guest device role tagging

This will provide a mechanism for the user to tag a device they
have assigned to their guest with a specific role. The tag will
be matched to the hardware address of the device and this mapping
exposed to the guest OS via metadata service/cloud-init

Spec for bp/virt-device-tagged-attach-detach

APIImpact

Change-Id: Id9d36f723dbc20c65293f22a4eaee55715b235d2
Previously-approved: Ocata
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/97/435397/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/pike/approved/virt-device-role-tagging.rst'],1,51b1cefdb0c1c38318f605a3d36837699aba493e,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= Virtual guest device role tagging ================================= https://blueprints.launchpad.net/nova/+spec/virt-device-tagged-attach-detach This will provide a mechanism for the user to tag a device they have assigned to their guest with a specific role. The tag will be matched to the hardware address of the device and this mapping exposed to the guest OS via metadata service/cloud-init. Problem description =================== It is common to create virtual instances which have multiple network devices or disk drives. The tenant user creating the instance will often have a specific role in mind for each of the devices. For example, a particular disk may be intended for use as Oracle database storage, or as a Squid webcache storage, etc. Similarly there may be specific network interfaces intended for use by a network service application running in the guest. The tenant user who is creating the instance does not have an explicit way to communicate the intended usage of each device to the application running inside the guest OS. It may appear possible to identify a device via some aspect that the tenant user knows, and then use the cloud-init / metadata service to provide a mapping to the guest. For example, a MAC address could potentially be used to identify NICs, or a disk device name string could be used to identify disks. The user would then set a metadata tag. For example: .. code-block:: console # nova boot \ --image mywebappimage \ --flavor m1.large \ --meta oracledata=vda \ --meta apachefrontend=02:10:22:32:33:22 \ mywebapp The problem is that, because Nova tries to hide as much detail of the guest hardware setup as possible, it is not easy for the tenant user to know what the unique identifiers for each device are. For example, while with emulated NICs, it is possible to know the MAC address before booting the instance, when using PCI assigned devices, this is not available. Another approach might appear to be to identify devices based on the order in which they appear to guests. eg the application in the guest could be set to use the 3rd PCI NIC, or the 2nd disk on the SCSI bus. The problem with this is that neither Nova nor the underlying hypervisor is able to provide a strong guarantee around the device ordering in the guest. By good fortune, the order in which disks are listed on the nova boot command line, often matches the order in which device letters are assigned by Linux, but nothing guarantees this to be the case long term. Use Cases ---------- The tenant user needs to provide information to the guest instance to identify which device to use for a desired guest application role. For example, the tenant user wishes to instruct the Oracle database to use a particular SCSI disk for its data storage, because they have configured that disk to use a particular cinder volume that is built for high throughput. Or they may wish to instruct an NFV application that it should process data from a particular network interface, because that interface is connected to an interface in a second guest which is sending the required network traffic. The tenant needs to be able to provide this identification information to the guest OS, without knowing about how the particular hypervisor will configure the virtual hardware. Proposed change =============== The proposal is to extend the REST API so that when adding disks or network interfaces to a guest instance, it is possible to pass an opaque string ""tag"". When booting a guest, Nova will determine what PCI, USB, SCSI address corresponds to the device the user asked for, and create a metadata file that maps the user provided tag to the hypervisor assigned device address. This metadata file will be provided via either cloud-init or the metadata service. When the guest OS image boots up, it will read this metadata file to determine which devices need to be used for particular application services running in the instance. How the guest OS does this is outside the scope of this spec. Nova is merely defining a file format and a set of information it will contain, which the guest OS and/or applications can consume in a manner which they prefer. There are no current standards in this area, so it is a greenfield design for the file format. For example, consider that the user created a new instance with a number of NICs and block devices attached. These devices could be tagged, as shown below: .. code-block:: console nova boot \ --image mywebappimage \ --flavor m1.large \ --nic net-id=12345,tag=nfvfunc1 \ --nic net-id=56789,tag=nfvfunc2 \ --block-device volume_id=12345,bus=scsi,tag=oracledb \ --block-device volume_id=56789,bus=virtio,tag=squidcache \ mynfvapp Then Nova could auto-generate a metadata file that contained the following, based on information reported by the Nova libvirt driver for the guest instance: .. code-block:: json { ""devices"": [ { ""type"": ""nic"", ""bus"": ""pci"", ""address"": ""0000:00:02.0"", ""mac"": ""01:22:22:42:22:21"", ""tags"": [""nfvfunc1""] }, { ""type"": ""nic"", ""bus"": ""pci"", ""address"": ""0000:00:03.0"", ""mac"": ""01:22:22:42:22:21"", ""tags"": [""nfvfunc2""] }, { ""type"": ""disk"", ""bus"": ""scsi"", ""address"": ""1:0:2:0"", ""serial"": ""disk-vol-2352423"", ""tags"": [""oracledb""] }, { ""type"": ""disk"", ""bus"": ""pci"", ""address"": ""0000:00:07.0"", ""serial"": ""disk-vol-24235252"", ""tags"": [""squidcache""] } ] } In this example, we have provide a few bits of information about the devices * The type of device info is provided for. Currently this is 'nic' or 'disk'. Other types will be provided in the future. * The bus the device is attached to. This can be ""pci"", ""scsi"", ""usb"", ""ide"" and similar things. This is basically saying how to interpret the device address. The bus may be ""none"" in the case of containers, or where the device is integrated into the platform board. * The device address. The format of the address varies based on the bus, but would be the PCI address, or SCSI address, of USB port, or IDE channel, etc. * The network device MAC address, if type==nic. * The disk drive serial string (if set & type==disk). * The network device name, if type==nic and the hypervisor supports explicit device names (ie containers) * The disk device name, if type==disk and the hypervisor supports explicit device names (ie containers) * It is possible for the same tag to appear multiple times against different device types * If the hypervisor provides two devices which mapo to the same backend, it is possible for the same tag to appear in both. This is the case with Xen HVM guests where a single block device is exposed via both Xen paravirt disk and IDE emulated disk. The guest chooses which to use. * Although the syntax supports setting of multiple tags per device, initially the impl will only allow a single tag. The syntax just allows for future extension should there be a need. Note that not all architectures support PCI buses, for example armv7 and s390 don't, so if a guest OS wishes to be portable it must not assume it will get devices of a particular type. As such for device addressing, only the ""bus"" attribute would be considered mandatory, the ""address"" attribute may be omitted if that data is not available. Network devices would always have a ""mac"" attribute present. Disk devices would have a ""serial"" attribute present if the disk had an associated unique serial set. The virt drivers in Nova would endeavour to make available as much information as possible. The data reported to the guest OS will be considered a stable API that must be maintained across future Nova releases in a backwards compatible manner. As such, the data will be made to conform to a formal JSON schema, which will be append-only to ensure future compatibility. .. code-block:: json { ""$schema"": ""http://json-schema.org/schema#"", ""id"": ""http://openstack.org/schemas/nova/metadata/device-role-tagging/1.0"", ""definitions"": { ""nonedevicebus"": { ""type"": ""object"", ""properties"": { ""bus"": { ""type"": ""string"", ""pattern"": ""none"" } }, ""required"": [ ""bus"" ] }, ""pcidevicebus"": { ""type"": ""object"", ""properties"": { ""bus"": { ""type"": ""string"", ""pattern"": ""pci"" }, ""address"": { ""type"": ""string"", ""pattern"": ""[a-f0-9]{4}:[a-f0-9]{2}:[a-f0-9]{2}.[a-f0-9]"" } }, ""required"": [ ""bus"" ] }, ""usbdevicebus"": { ""type"": ""object"", ""properties"": { ""bus"": { ""type"": ""string"", ""pattern"": ""usb"" }, ""address"": { ""type"": ""string"", ""pattern"": ""[a-f0-9]+:[a-f0-9]+"" } }, ""required"": [ ""bus"" ] }, ""scsidevicebus"": { ""type"": ""object"", ""properties"": { ""bus"": { ""type"": ""string"", ""pattern"": ""scsi"" }, ""address"": { ""type"": ""string"", ""pattern"": ""[a-f0-9]+:[a-f0-9]+:[a-f0-9]+:[a-f0-9]+"" } }, ""required"": [ ""bus"" ] }, ""idedevicebus"": { ""type"": ""object"", ""properties"": { ""bus"": { ""type"": ""string"", ""pattern"": ""ide"" }, ""address"": { ""type"": ""string"", ""pattern"": ""[0-1]:[0-1]"" } }, ""required"": [ ""bus"" ] }, ""anydevicebus"": { ""type"": ""object"", ""oneOf"": [ { ""$ref"": ""#/definitions/pcidevicebus"" }, { ""$ref"": ""#/definitions/usbdevicebus"" }, { ""$ref"": ""#/definitions/idedevicebus"" }, { ""$ref"": ""#/definitions/scsidevicebus"" }, { ""$ref"": ""#/definitions/nonedevicebus"" } ] }, ""nicdevice"": { ""type"": ""object"", ""properties"": { ""mac"": { ""type"": ""string"" } ""devname"": { ""type"": ""string"" } }, ""required"": [""mac""], ""additionalProperties"": { ""allOf"": [ { ""$ref"": ""#/definitions/anydevicebus"" } ] } }, ""diskdevice"": { ""type"": ""object"", ""properties"": { ""serial"": { ""type"": ""string"" }, ""path"": { ""type"": ""string"" } }, ""additionalProperties"": { ""allOf"": [ { ""$ref"": ""#/definitions/anydevicebus"" } ] } } }, ""type"": ""object"", ""properties"": { ""devices"": { ""type"": ""array"", ""items"": { ""type"": [ { ""$ref"": ""#/definitions/nicdevice"" }, { ""$ref"": ""#/definitions/diskdevice"" } ] } } } } The implementation will consist of several parts. There will be a set of python classes defined in nova/virt/metadata.py that are capable of representing the data described by the JSON schema above, and generating a compliant JSON document. The virt drivers will be extended to populate instances of these classes with the data associated with each instance. The initial implementation will be done for the Libvirt driver, however, other virt driver maintainers are encouraged to provide the same functionality. The metadata API will be extended to be capable of reporting this data associated with a guest instance. This has a chicken and egg scenario for network configuration. Guests relying on the metadata service will need to do a minimal network configuration to reach the metadata service and obtain the info from Nova. They can then re-configure networking based on the device tag information. The config driver generator will be extended to be capable of including this JSON data associated with a guest instance. This is the preferred method where guests need to rely on tags to confgure networking, as it has no chicken & egg scenario. In the future QEMU will be able export metadata directly via the firmware so it will be available directly from the very earliest stages of boot. It is expected this will be used as an additional optional transport in the future. Outside the scope of the Nova work, a simple tool will be created that can parse this metadata file and set tags against devices in the udev database. It is anticipated that cloud-init would trigger this tool. Thus (Linux) applications / OS images would not need to directly understand this Nova JSON format. Instead they could just query udev to ask for details of the device with a particular tag. This avoids the applications needing to deal with the countless different device bus types or addressing formats. Example for Xen HVM with dual-disk devices .. code-block:: json { ""devices"": [ { ""type"": ""nic"", ""bus"": ""xen"", ""address"": ""0"", ""mac"": ""01:22:22:42:22:21"", ""tags"": [""nfvfunc1""] }, { ""type"": ""nic"", ""bus"": ""xen"", ""address"": ""1"", ""mac"": ""01:22:22:42:22:21"", ""tags"": [""nfvfunc2""] }, { ""type"": ""disk"", ""bus"": ""ide"", ""address"": ""0:0"", ""serial"": ""disk-vol-123456"", ""tags"": [""oracledb""] }, { ""type"": ""disk"", ""bus"": ""xen"", ""address"": ""0"", ""path"": ""/dev/xvda"", ""serial"": ""disk-vol-123456"", ""tags"": [""oracledb""] } { ""type"": ""disk"", ""bus"": ""ide"", ""address"": ""0:1"", ""serial"": ""disk-vol-789321"", ""tags"": [""squidcache""] }, { ""type"": ""disk"", ""bus"": ""xen"", ""address"": ""1"", ""path"": ""/dev/xvdb"", ""serial"": ""disk-vol-789321"", ""tags"": [""squidcache""] } ] } Some things to note about this Xen example. * There are two logical disks here, which Xen has exposed as *both* IDE and Xen paravirt. * For the Xen paravirt disks, Xen can also provide a fixed guest path. * The address for devices on Xen bus is just an integer which maps into the XenBus namespace. Example for LXC container .. code-block:: json { ""devices"": [ { ""type"": ""nic"", ""bus"": ""none"", ""mac"": ""01:22:22:42:22:21"", ""devname"": ""eth0"", ""tags"": [""nfvfunc1""] }, { ""type"": ""nic"", ""bus"": ""none"", ""mac"": ""01:22:22:42:22:21"", ""devname"": ""eth1"", ""tags"": [""nfvfunc2""] }, { ""type"": ""disk"", ""bus"": ""none"", ""serial"": ""disk-vol-2352423"", ""path"": ""/dev/sda"", ""tags"": [""oracledb""] }, { ""type"": ""disk"", ""bus"": ""none"", ""serial"": ""disk-vol-24235252"", ""path"": ""/dev/sdb"", ""tags"": [""squidcache""] } ] } Some things to note about this LXC example: * Containers do not export device buses to guests, as they don't emulate hardware. Thus the 'bus' is 'none' and there is no corresponding 'address' * Containers are able to provide fixed disk paths and NIC device names Alternatives ------------ Many users facing this problem have requested that Nova allow them to specify a fixed PCI address when creating disks and/or network interfaces. In a traditional data center virtualization world this would be an acceptable request, but a goal of the cloud is to isolate tenant users from the specifics of guest hardware configuration. Such configuration requires intimate knowledge of the underlying hypervisor which is simply not available to tenant users, nor should they be expected to learn that. In view of this, it is considered inappropriate to allow tenant users to control the guest device addressing via the REST API. As noted in the problem description another approach is for the tenant user to manually set tags via the existing mechanism for providing user metadata to guests. This however relies on the user knowing some unique identifying attribute for the device upfront. In some cases this is possible, but there are a number of cases where no such information is available. Data model impact ----------------- The BlockDeviceMapping object (and associated table) will gain a freeform string attribute, named ""tag"". The NetworkRequest object (and associated table) will gain a freeform string attribute, named ""tag"". In future other device types, such as PCI devices or serial ports, may also gain similar ""tag"" attributes. For the initial implementation only the disk and network objects are to be dealt with. REST API impact --------------- The block device mapping data format will gain a new freeform string parameter, named ""tag"", which can be set against each disk device. This would affect the APIs for booting instances and hot-adding disks. In terms of the Nova client this would be visible as a new supported key against the --block-device flag. e.g. .. code-block:: console $ nova boot --block-device id=UUID,source=image,tag=database The volume attach API will similarly gain a new freeform string parameter in the ""volumeAttachment"" data dict, named ""tag"". In terms of the Nova client this would be visible as a new flag. e.g. .. code-block:: console $ nova volume-attach --tag=database INSTANCE-ID VOLUME-ID The server create API gain a new freeform string parameter in the ""network"" data dict, named ""tag"", for each virtual interface. In terms of the Nova client this would be visible as a new supported key against the --nic flag. e.g. .. code-block:: console $ nova boot --nic net-id=UUID,port-id=UUID,tag=database The interface attach API will similarly gain a new freeform string parameter in the ""interfaceAttachment"" data dict, named ""tag"". In terms of the Nova client this would be visible as a new flag. e.g. .. code-block:: console $ nova interface-attach UUID --net-id UUID --port-id UUID --tag database In all cases there will need to be validation performed to ensure that the supplied ""tag"" string is unique within the scope of (instance, device-type). ie you cannot have two NICs on the same instance with the same ""tag"", but you can have a disk and a NIC with the same ""tag"". If no tag is defined against a device, the corresponding device entry in the metadata file will not have any tags listed. Since this is intended as an end user feature, it is not considered appropriate for Nova to auto-generate tags itself. This will require a new API microversion Security impact --------------- None, this is merely providing some user metadata to the guest OS. Notifications impact -------------------- None Other end user impact --------------------- There will be new fields available when specifying disks or network interfaces for virtual instances. The metadata service and cloud-init will have a new data file made available containing the user tags & address information. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Artom Lifshitz Other contributors: Daniel Berrange Work Items ---------- * Define new attribute for BlockDeviceMapping object (Newton) * Define new attribute for NetworkRequest object (Newton) * Define new parameters for block device in REST API(s) (Newton) * Define new parameters for network requests in REST API(s) (Newton) * Define new parameters for network interface attachment in REST API(s) * Define new parameters for volume attachment in REST API(s) * Define a set of classes to represent the device metadata (Newton) * Modify the metadata API to be able to serve the new data document (Newton) * Modify the config drive generator to be able to include the new data document * Modify the libvirt driver to populate the metadata about devices that have tags present (Newton) * Modify the Nova client to allow the extra tag parameter to be provided (Newton) Dependencies ============ An external GIT repository will be created that provides a tool that is capable of parsing the Nova tag metadata and setting udev tags. This is not strictly a dependency, but a highly desirable feature to facilite the use of this tag information from Linux guests. Cloud-init will be enhanced to invoke this tool when it finds the JSON tag metadata is available from Nova. Testing ======= Tempest tests will create a guest with various NICs and disks, assign tags to them, and then check the guest facing metadata file is present and contains sensible data. NB, the actual data it contains will vary according to the hypervisor running the tests, so care will need to be taken to ensure any test is portable. Documentation Impact ==================== The API documentation will need to be updated to list the new tag parameter that is allowed against disk and network devices The user documentation for cloud-init will need to describe the newly available metadata file and its semantics. References ========== None History ======= .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Liberty - Introduced * - Mitaka - Re-proposed * - Newton - Implemented booting instances with tagged devices * - Ocata - Re-proposed to finish implementing attaching and detaching tagged devices * - Pike - Re-proposed to finish what was started in Ocata ",,659,0
openstack%2Frequirements~master~I180cc1b44f17c778eaa9422bad591ab0106ad055,openstack/requirements,master,I180cc1b44f17c778eaa9422bad591ab0106ad055,Updated from generate-constraints,MERGED,2017-02-17 12:28:09.000000000,2017-02-17 15:30:50.000000000,2017-02-17 15:30:50.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2017-02-17 12:28:09.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/498bc76f83248491ca00f103ac672203e17d56be', 'message': 'Updated from generate-constraints\n\nChange-Id: I180cc1b44f17c778eaa9422bad591ab0106ad055\n'}]",0,435417,498bc76f83248491ca00f103ac672203e17d56be,6,2,1,5638,,,0,"Updated from generate-constraints

Change-Id: I180cc1b44f17c778eaa9422bad591ab0106ad055
",git fetch https://review.opendev.org/openstack/requirements refs/changes/17/435417/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,498bc76f83248491ca00f103ac672203e17d56be,,botocore===1.5.13croniter===0.3.15docker===2.1.0monasca-common===1.5.0tripleo-common===5.8.0,botocore===1.5.12croniter===0.3.14docker===2.0.2monasca-common===1.4.0tripleo-common===5.7.0,5,5
openstack%2Ffuel-library~stable%2F7.0~I8696bf02fc5aded3b919699b45c576de626bc9f3,openstack/fuel-library,stable/7.0,I8696bf02fc5aded3b919699b45c576de626bc9f3,Disable logrotate cron job in nailgun and keystone containers,MERGED,2017-02-17 10:50:52.000000000,2017-02-17 15:29:32.000000000,2017-02-17 15:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 14610}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-17 10:50:52.000000000', 'files': ['deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/examples/keystone-only.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b7535fdaef901f42acb407238a1bf3405edac59b', 'message': 'Disable logrotate cron job in nailgun and keystone containers\n\nSome nailgun and keystone jobs are started periodically with\ndedicated cron jobs. By default, logrotate cron job is\nconfigured to run daily and to use configuration files from\nlogrotate.d directory. Some packages like cobbler, nginx and\napache are shipped with specific logrotate configuration file\nthat will be added to logrotate.d directory after install.\n\nAs a result, we do not rotate some log files correctly, since\nit is impossible to restart process from another container.\nThis patch will disable logrotate cron job for nailgun and\nkeystone containers.\n\n(cherry-picked from commit b0d0afe5ce284f8da6816f653cfbc6aff5771b66)\n\nChange-Id: I8696bf02fc5aded3b919699b45c576de626bc9f3\nCloses-bug: #1642794\n'}]",0,435360,b7535fdaef901f42acb407238a1bf3405edac59b,30,6,1,19234,,,0,"Disable logrotate cron job in nailgun and keystone containers

Some nailgun and keystone jobs are started periodically with
dedicated cron jobs. By default, logrotate cron job is
configured to run daily and to use configuration files from
logrotate.d directory. Some packages like cobbler, nginx and
apache are shipped with specific logrotate configuration file
that will be added to logrotate.d directory after install.

As a result, we do not rotate some log files correctly, since
it is impossible to restart process from another container.
This patch will disable logrotate cron job for nailgun and
keystone containers.

(cherry-picked from commit b0d0afe5ce284f8da6816f653cfbc6aff5771b66)

Change-Id: I8696bf02fc5aded3b919699b45c576de626bc9f3
Closes-bug: #1642794
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/60/435360/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/nailgun/examples/nailgun-only.pp', 'deployment/puppet/nailgun/examples/keystone-only.pp']",2,b7535fdaef901f42acb407238a1bf3405edac59b,bug/1642794," file {'cron.daily/logrotate': path => '/etc/cron.daily/logrotate', ensure => absent, } service { 'crond': ensure => running, enable => true, require => File['cron.daily/logrotate'],"," service { 'crond': ensure => running, enable => true,",14,2
openstack%2Fshade~master~Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d,openstack/shade,master,Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d,Convert test_object to use .register_uris,MERGED,2017-02-15 21:51:50.000000000,2017-02-17 15:21:27.000000000,2017-02-17 15:21:27.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2017-02-15 21:51:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/50f0d55de51f6597b3a6b8570ea445ee41587b0c', 'message': 'Convert test_object to use .register_uris\n\nConvert test_object tests to use .register_uris. .register_uri is\nno longer used and deleted.\n\nChange-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d\n'}, {'number': 2, 'created': '2017-02-16 21:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/179adb2883c1e2fc11e24687b83394e7a2e97d16', 'message': 'Convert test_object to use .register_uris\n\nConvert test_object tests to use .register_uris. .register_uri is\nno longer used and deleted.\n\nChange-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d\n'}, {'number': 3, 'created': '2017-02-17 05:05:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/ba7960ea70076f7ca39b539d4b78bdb7ccfd50e4', 'message': 'Convert test_object to use .register_uris\n\nConvert test_object tests to use .register_uris. .register_uri is\nno longer used and deleted.\n\nChange-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d\n'}, {'number': 4, 'created': '2017-02-17 05:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/119a8551964ebab531ff2557f7c5bae59e56ba0f', 'message': 'Convert test_object to use .register_uris\n\nConvert test_object tests to use .register_uris. .register_uri is\nno longer used and deleted.\n\nChange-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d\n'}, {'number': 5, 'created': '2017-02-17 05:44:41.000000000', 'files': ['shade/tests/unit/test_object.py', 'shade/tests/unit/base.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/80709fd9a488d83563ed5c5354cca6628c08445a', 'message': 'Convert test_object to use .register_uris\n\nConvert test_object tests to use .register_uris. .register_uri is\nno longer used and deleted.\n\nChange-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d\n'}]",0,434532,80709fd9a488d83563ed5c5354cca6628c08445a,17,3,5,2903,,,0,"Convert test_object to use .register_uris

Convert test_object tests to use .register_uris. .register_uri is
no longer used and deleted.

Change-Id: Iee156afd5ee5931ca4087a70dd92bb3b0df2f62d
",git fetch https://review.opendev.org/openstack/shade refs/changes/32/434532/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_object.py', 'shade/tests/unit/base.py']",2,50f0d55de51f6597b3a6b8570ea445ee41587b0c,,," def register_uri(self, method, uri, **kwargs): self.__do_register_uris([ dict(method=method, uri=uri, **kwargs)]) ",489,512
openstack%2Ftripleo-heat-templates~master~Icde47cb28f17c255f7e6b99026365a5160b75c9d,openstack/tripleo-heat-templates,master,Icde47cb28f17c255f7e6b99026365a5160b75c9d,ovn: Add iptable rules for OVN DB server ports,ABANDONED,2017-02-16 04:33:32.000000000,2017-02-17 15:18:26.000000000,,"[{'_account_id': 3}, {'_account_id': 10237}]","[{'number': 1, 'created': '2017-02-16 04:33:32.000000000', 'files': ['puppet/services/ovn-dbs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f56c2982ba02705df0405fab15e613061db5143', 'message': 'ovn: Add iptable rules for OVN DB server ports\n\nTODO: Update the release notes\n\nChange-Id: Icde47cb28f17c255f7e6b99026365a5160b75c9d\n'}]",0,434643,7f56c2982ba02705df0405fab15e613061db5143,5,2,1,10237,,,0,"ovn: Add iptable rules for OVN DB server ports

TODO: Update the release notes

Change-Id: Icde47cb28f17c255f7e6b99026365a5160b75c9d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/43/434643/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/ovn-dbs.yaml'],1,7f56c2982ba02705df0405fab15e613061db5143,, tripleo.neutron_compute_plugin_ovn.firewall_rules: '121 OVN DB server ports': proto: 'tcp' dport: - {get_param: OVNNorthboundServerPort} - {get_param: OVNSouthboundServerPort},,6,0
openstack%2Fshade~master~Ibf909d4b81361fab690c5514e616870bf9274a60,openstack/shade,master,Ibf909d4b81361fab690c5514e616870bf9274a60,Convert use of .register_uri to .register_uris,MERGED,2017-02-15 21:04:53.000000000,2017-02-17 15:17:59.000000000,2017-02-17 15:17:59.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 2903}]","[{'number': 1, 'created': '2017-02-15 21:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/a4feceb5d771ce5db55fbedfcd9f7fc6535503c7', 'message': 'Convert use of .register_uri to .register_uris\n\nThis patch converts the use of .register_uri to .register_uris for the\nfollowing files: test_image, test_project, test_meta.\n\nChange-Id: Ibf909d4b81361fab690c5514e616870bf9274a60\n'}, {'number': 2, 'created': '2017-02-16 21:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/60ec1c50c485ea405e035c50da9cabac84a290d3', 'message': 'Convert use of .register_uri to .register_uris\n\nThis patch converts the use of .register_uri to .register_uris for the\nfollowing files: test_image, test_project, test_meta.\n\nChange-Id: Ibf909d4b81361fab690c5514e616870bf9274a60\n'}, {'number': 3, 'created': '2017-02-17 05:05:00.000000000', 'files': ['shade/tests/unit/test_meta.py', 'shade/tests/unit/test_project.py', 'shade/tests/unit/test_image.py', 'shade/tests/unit/base.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/759b2b4845fcfe2b7865ccd4469797c980c17720', 'message': 'Convert use of .register_uri to .register_uris\n\nThis patch converts the use of .register_uri to .register_uris for the\nfollowing files: test_image, test_project, test_meta.\n\nChange-Id: Ibf909d4b81361fab690c5514e616870bf9274a60\n'}]",1,434516,759b2b4845fcfe2b7865ccd4469797c980c17720,16,3,3,2903,,,0,"Convert use of .register_uri to .register_uris

This patch converts the use of .register_uri to .register_uris for the
following files: test_image, test_project, test_meta.

Change-Id: Ibf909d4b81361fab690c5514e616870bf9274a60
",git fetch https://review.opendev.org/openstack/shade refs/changes/16/434516/3 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_meta.py', 'shade/tests/unit/test_project.py', 'shade/tests/unit/test_image.py', 'shade/tests/unit/base.py']",4,a4feceb5d771ce5db55fbedfcd9f7fc6535503c7,," uri_mock_list = [] if list_get: uri_mock_list.append( dict(method='GET', uri=self.get_mock_url( service_type='identity', interface='admin', resource='projects', base_url_append=base_url_append), status_code=200, json={'projects': [p.json_response['project'] for p in project_list]}) ) uri_mock_list.append( dict(method='GET', uri=self.get_mock_url( service_type='identity', interface='admin', resource='projects', append=[p.project_id], base_url_append=base_url_append), status_code=200, json=p.json_response) ) self.__do_register_uris(uri_mock_list) self.__do_register_uris([ dict(method='GET', uri='https://identity.example.com/', text=open(self.discovery_json, 'r').read()), dict(method='POST', uri='https://identity.example.com/v3/auth/tokens', headers={ 'X-Subject-Token': self.getUniqueString('KeystoneToken')}, text=open(os.path.join( self.fixtures_directory, 'catalog-v3.json'), 'r').read() ) ]) self.__do_register_uris([ dict(method='GET', uri='https://identity.example.com/', text=open(self.discovery_json, 'r').read()), dict(method='POST', uri='https://identity.example.com/v2.0/tokens', text=open(os.path.join( self.fixtures_directory, 'catalog-v2.json'), 'r').read() ), dict(method='GET', uri='https://identity.example.com/', text=open(self.discovery_json, 'r').read()), dict(method='GET', uri='https://identity.example.com/', text=open(self.discovery_json, 'r').read()) ]) self.__do_register_uris([ dict(method='GET', uri='https://identity.example.com/', text=open(self.discovery_json, 'r').read())]) def get_glance_discovery_mock_dict( self, image_version_json='image-version.json'): return dict(method='GET', uri='https://image.example.com/', text=open(discovery_fixture, 'r').read()) def use_glance(self, image_version_json='image-version.json'): # NOTE(notmorgan): This method is only meant to be used in ""setUp"" # where the ordering of the url being registered is tightly controlled # if the functionality of .use_glance is meant to be used during an # actual test case, use .get_glance_discovery_mock and apply to the # right location in the mock_uris when calling .register_uris self.__do_register_uris([ self.get_glance_discovery_mock_dict(image_version_json)]) def register_uris(self, uri_mock_list=None): :type uri_mock_list: list self.__do_register_uris(uri_mock_list or []) self.__register_uris_called = True def __do_register_uris(self, uri_mock_list=None): for to_mock in uri_mock_list: kw_params = {k: to_mock.pop(k) for k in ('request_headers', 'complete_qs', '_real_http') if k in to_mock} # NOTE(notmorgan): make sure the delimiter is non-url-safe, in this # case ""|"" is used so that the split can be a bit easier on # maintainers of this code. key = '{method}|{uri}|{params}'.format( method=method, uri=uri, params=kw_params) self._uri_registry.setdefault( key, {'response_list': [], 'kw_params': kw_params}) if self._uri_registry[key]['kw_params'] != kw_params: raise AssertionError( 'PROGRAMMING ERROR: key-word-params ' 'should be part of the uri_key and cannot change, ' 'it will affect the matcher in requests_mock. ' '%(old)r != %(new)r' % {'old': self._uri_registry[key]['kw_params'], 'new': kw_params}) self._uri_registry[key]['response_list'].append(to_mock) for mocked, params in self._uri_registry.items(): mock_method, mock_uri, _ignored = mocked.split('|', 2) self.adapter.register_uri( mock_method, mock_uri, params['response_list'], **params['kw_params']) self.__do_register_uris([ dict(method=method, uri=uri, **kwargs)])"," if list_get: self.register_uri( 'GET', self.get_mock_url( service_type='identity', interface='admin', resource='projects', base_url_append=base_url_append), status_code=200, json={'projects': [p.json_response['project'] for p in project_list]}) self.register_uri( 'GET', self.get_mock_url( service_type='identity', interface='admin', resource='projects', append=[p.project_id], base_url_append=base_url_append), status_code=200, json=p.json_response) self.register_uri('GET', 'https://identity.example.com/', text=open(self.discovery_json, 'r').read()) self.register_uri( 'POST', 'https://identity.example.com/v3/auth/tokens', headers={ 'X-Subject-Token': self.getUniqueString()}, text=open( os.path.join( self.fixtures_directory, 'catalog-v3.json'), 'r').read()) self.register_uri('GET', 'https://identity.example.com/', text=open(self.discovery_json, 'r').read()) self.register_uri( 'POST', 'https://identity.example.com/v2.0/tokens', text=open( os.path.join( self.fixtures_directory, 'catalog-v2.json'), 'r').read()) self.register_uri('GET', 'https://identity.example.com/', text=open(self.discovery_json, 'r').read()) self.register_uri('GET', 'https://identity.example.com/', text=open(self.discovery_json, 'r').read()) self.register_uri('GET', 'https://identity.example.com/', text=open(self.discovery_json, 'r').read()) def use_glance(self, image_version_json='image-version.json'): self.register_uri( 'GET', 'https://image.example.com/', text=open(discovery_fixture, 'r').read()) def register_uris(self, uri_mock_list): for to_mock in uri_mock_list: key = '{method}:{uri}'.format(method=method, uri=uri) self._uri_registry.setdefault(key, []).append(to_mock) for mock_method_uri, params in self._uri_registry.items(): mock_method, mock_uri = mock_method_uri.split(':', 1) self.adapter.register_uri(mock_method, mock_uri, params) self.__register_uris_called = True validate = kwargs.pop('validate', {}) key = '{method}:{uri}'.format(method=method, uri=uri) headers = structures.CaseInsensitiveDict(kwargs.pop('headers', {})) if 'content-type' not in headers: headers[u'content-type'] = 'application/json' kwargs['headers'] = headers if key in self._uri_registry: self._uri_registry[key].append(kwargs) self.adapter.register_uri(method, uri, self._uri_registry[key]) else: self._uri_registry[key] = [kwargs] self.adapter.register_uri(method, uri, **kwargs) self.calls += [ dict( method=method, url=uri, **validate) ]",583,567
openstack%2Foslo-specs~master~I26e9ad8914c05b55f0a770d64aa636c93161508f,openstack/oslo-specs,master,I26e9ad8914c05b55f0a770d64aa636c93161508f,Add initial directory for any pike specs,MERGED,2017-02-17 11:53:58.000000000,2017-02-17 15:17:08.000000000,2017-02-17 15:17:08.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2017-02-17 11:53:58.000000000', 'files': ['doc/source/index.rst', 'specs/pike/index.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/46a51711c1ab2a5cdbcb29b13b9735d550944acb', 'message': ""Add initial directory for any pike specs\n\nWe don't have summit work session from Pike, use PTG\netherpad instead of summit planning etherpad.\n\nChange-Id: I26e9ad8914c05b55f0a770d64aa636c93161508f\n""}]",0,435403,46a51711c1ab2a5cdbcb29b13b9735d550944acb,7,4,1,9796,,,0,"Add initial directory for any pike specs

We don't have summit work session from Pike, use PTG
etherpad instead of summit planning etherpad.

Change-Id: I26e9ad8914c05b55f0a770d64aa636c93161508f
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/03/435403/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/pike/index.rst']",2,46a51711c1ab2a5cdbcb29b13b9735d550944acb,pike,============== Pike Release ============== * PTG planning: https://etherpad.openstack.org/p/oslo-ptg-pike ,,14,0
openstack%2Ftripleo-quickstart~master~Ic852b38a3c98d3e4562028a9b2e0093d4adf4bde,openstack/tripleo-quickstart,master,Ic852b38a3c98d3e4562028a9b2e0093d4adf4bde,Fix gate-check test patch,MERGED,2017-02-17 13:53:42.000000000,2017-02-17 15:16:02.000000000,2017-02-17 15:16:02.000000000,"[{'_account_id': 3}, {'_account_id': 8652}, {'_account_id': 10022}]","[{'number': 1, 'created': '2017-02-17 13:53:42.000000000', 'files': ['ci-scripts/full-deploy.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/e858c646255095c8dd793047ebd257b254b26dac', 'message': 'Fix gate-check test patch\n\nChange-Id: Ic852b38a3c98d3e4562028a9b2e0093d4adf4bde\n'}]",0,435453,e858c646255095c8dd793047ebd257b254b26dac,9,3,1,12715,,,0,"Fix gate-check test patch

Change-Id: Ic852b38a3c98d3e4562028a9b2e0093d4adf4bde
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/53/435453/1 && git format-patch -1 --stdout FETCH_HEAD,['ci-scripts/full-deploy.sh'],1,e858c646255095c8dd793047ebd257b254b26dac,gate-check, export ZUUL_CHANGES=openstack/tripleo-ui:master:refs/changes/25/422025/2, export ZUUL_CHANGES=openstack/tripleo-ui:master:refs/changes/25/422025/1,1,1
openstack%2Fcharm-ceph-mon~master~Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12,openstack/charm-ceph-mon,master,Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12,Only check for upgrades if bootstrapped,MERGED,2017-02-16 20:00:14.000000000,2017-02-17 15:12:33.000000000,2017-02-17 15:12:33.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20812}]","[{'number': 1, 'created': '2017-02-16 20:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/7c5877f5a2621b7ef943b865c6be194d6e36d54f', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nPartial-Bug: 1662943\n'}, {'number': 2, 'created': '2017-02-16 20:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/72b859abfda2ee7193f3a6a1eb5b2c3f79a2f518', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nPartial-Bug: 1662943\n'}, {'number': 3, 'created': '2017-02-17 10:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/5f3bfd1e33f1730fad8c1b54cad63a0a56a3ba23', 'message': 'Bail if we have the same source as previous\n\nThis ensures that upgrades are not attempted when the\nsource configuration option has not changes, but the\ninitial source value != distro  (for trusty installs).\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nCloses-Bug: 1662943\n'}, {'number': 4, 'created': '2017-02-17 10:41:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/84fc6bdd21934087e301a47ba8f81080d65b0d8c', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nCloses-Bug: 1662943\n'}, {'number': 5, 'created': '2017-02-17 10:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/e2281284f7b1a56c7d4571773a60907d5dbbd5f1', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nCloses-Bug: 1662943\n'}, {'number': 6, 'created': '2017-02-17 10:52:39.000000000', 'files': ['hooks/ceph_hooks.py', 'unit_tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/5e1ffebc94f82a4419a7c87b6ff657d5098b5410', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12\nCloses-Bug: 1662943\n'}]",1,435087,5e1ffebc94f82a4419a7c87b6ff657d5098b5410,22,6,6,20634,,,0,"Only check for upgrades if bootstrapped

Only check for upgrade requests if the local unit is installed
and bootstrapped, avoiding attempts to upgrade on initial
execution of config-changed for trusty UCA pockets.

Note that the upgrade process relies on a running ceph cluster.

Change-Id: Ia3cfcedc6bdc4aff3f50f1bba8f524ca850bbf12
Closes-Bug: 1662943
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/87/435087/5 && git format-patch -1 --stdout FETCH_HEAD,['hooks/ceph_hooks.py'],1,7c5877f5a2621b7ef943b865c6be194d6e36d54f,bug/1662943, if c.previous('source') == hookenv.config('source'): return,,2,0
openstack%2Fcharm-ceph-osd~master~Ic7e427368a373ed853111d837a0223a75b46ce8e,openstack/charm-ceph-osd,master,Ic7e427368a373ed853111d837a0223a75b46ce8e,Only check for upgrades if bootstrapped,MERGED,2017-02-16 20:00:36.000000000,2017-02-17 15:11:52.000000000,2017-02-17 15:11:52.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20812}]","[{'number': 1, 'created': '2017-02-16 20:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/c1e689ca238610a0d5c5c4ce2755c576bc1f0596', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ic7e427368a373ed853111d837a0223a75b46ce8e\nPartial-Bug: 1662943\n'}, {'number': 2, 'created': '2017-02-16 20:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/542dafc5d8e2d74d5a499f0fac227c18fd6dc94c', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ic7e427368a373ed853111d837a0223a75b46ce8e\nPartial-Bug: 1662943\n'}, {'number': 3, 'created': '2017-02-17 10:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/b84d13012496e9ed3068df4d3024782234fd65e1', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ic7e427368a373ed853111d837a0223a75b46ce8e\nCloses-Bug: 1662943\n'}, {'number': 4, 'created': '2017-02-17 12:29:55.000000000', 'files': ['hooks/ceph_hooks.py', 'unit_tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-osd/commit/9a5a710a1b1899ae6dacfe89a6eebe70bd8037e6', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ic7e427368a373ed853111d837a0223a75b46ce8e\nCloses-Bug: 1662943\n'}]",1,435088,9a5a710a1b1899ae6dacfe89a6eebe70bd8037e6,19,6,4,20634,,,0,"Only check for upgrades if bootstrapped

Only check for upgrade requests if the local unit is installed
and bootstrapped, avoiding attempts to upgrade on initial
execution of config-changed for trusty UCA pockets.

Note that the upgrade process relies on a running ceph cluster.

Change-Id: Ic7e427368a373ed853111d837a0223a75b46ce8e
Closes-Bug: 1662943
",git fetch https://review.opendev.org/openstack/charm-ceph-osd refs/changes/88/435088/4 && git format-patch -1 --stdout FETCH_HEAD,['hooks/ceph_hooks.py'],1,c1e689ca238610a0d5c5c4ce2755c576bc1f0596,bug/1662943, if c.previous('source') == hookenv.config('source'): return,,2,0
openstack%2Fcharm-ceph~master~Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2,openstack/charm-ceph,master,Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2,Only check for upgrades if bootstrapped,MERGED,2017-02-16 19:59:52.000000000,2017-02-17 15:11:46.000000000,2017-02-17 15:11:46.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20812}]","[{'number': 1, 'created': '2017-02-16 19:59:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/05f975d4e040e9a6eb166cae81d48578b0828bf5', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2\nPartial-Bug: 1662943\n'}, {'number': 2, 'created': '2017-02-16 20:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/e75cc7e88ac677e0927356f22767373fae0105e3', 'message': 'Bail if we have the same source as previous\n\nChange-Id: Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2\nPartial-Bug: 1662943\n'}, {'number': 3, 'created': '2017-02-17 10:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/0419429b6cbc70761f385eff5fedfe097457a0b1', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2\nCloses-Bug: 1662943\n'}, {'number': 4, 'created': '2017-02-17 12:31:02.000000000', 'files': ['hooks/ceph_hooks.py', 'unit_tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/d3cf8bb3aba40f588de63a13531a4d36c84dc09a', 'message': 'Only check for upgrades if bootstrapped\n\nOnly check for upgrade requests if the local unit is installed\nand bootstrapped, avoiding attempts to upgrade on initial\nexecution of config-changed for trusty UCA pockets.\n\nNote that the upgrade process relies on a running ceph cluster.\n\nChange-Id: Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2\nCloses-Bug: 1662943\n'}]",0,435086,d3cf8bb3aba40f588de63a13531a4d36c84dc09a,19,6,4,20634,,,0,"Only check for upgrades if bootstrapped

Only check for upgrade requests if the local unit is installed
and bootstrapped, avoiding attempts to upgrade on initial
execution of config-changed for trusty UCA pockets.

Note that the upgrade process relies on a running ceph cluster.

Change-Id: Ia3efe2f8cfdac4317809681e7d169725c6bd9ef2
Closes-Bug: 1662943
",git fetch https://review.opendev.org/openstack/charm-ceph refs/changes/86/435086/3 && git format-patch -1 --stdout FETCH_HEAD,['hooks/ceph_hooks.py'],1,05f975d4e040e9a6eb166cae81d48578b0828bf5,bug/1662943, if c.previous('source') == hookenv.config('source'): return,,2,0
openstack%2Ffuel-library~stable%2Fnewton~I34f9dedf62d29eecf7f261b81972d76102983607,openstack/fuel-library,stable/newton,I34f9dedf62d29eecf7f261b81972d76102983607,fixed wsrep_provider and mysql_socket paths for rhel,MERGED,2017-01-27 12:09:38.000000000,2017-02-17 15:07:53.000000000,2017-02-17 15:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-01-27 12:09:38.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/database/database.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a3b25085c9aa8a107d06de11046cdd3dc4630238', 'message': 'fixed wsrep_provider and mysql_socket paths for rhel\n\nRHEL based distributions have different locations of\nwsrep_provider library and socket.\n\nCloses-Bug: #1623948\nChange-Id: I34f9dedf62d29eecf7f261b81972d76102983607\nSigned-off-by: Pavel Glushchak <pglushchak@virtuozzo.com>\n(cherry picked from commit 26957bd6d56fcd808bdf41bb7fb262ab265781eb)\n'}]",0,426199,a3b25085c9aa8a107d06de11046cdd3dc4630238,32,7,1,13344,,,0,"fixed wsrep_provider and mysql_socket paths for rhel

RHEL based distributions have different locations of
wsrep_provider library and socket.

Closes-Bug: #1623948
Change-Id: I34f9dedf62d29eecf7f261b81972d76102983607
Signed-off-by: Pavel Glushchak <pglushchak@virtuozzo.com>
(cherry picked from commit 26957bd6d56fcd808bdf41bb7fb262ab265781eb)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/99/426199/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/database/database.pp'],1,a3b25085c9aa8a107d06de11046cdd3dc4630238,bug/1623948, case $::osfamily { 'Debian': { $wsrep_provider = '/usr/lib/galera/libgalera_smm.so' $mysql_socket = '/var/run/mysqld/mysqld.sock' } 'RedHat': { $wsrep_provider = '/usr/lib64/galera-3/libgalera_smm.so' $mysql_socket = '/var/lib/mysql/mysql.sock' } } $vendor_override_options = { 'mysqld' => { 'wsrep_provider' => $wsrep_provider } }, $vendor_override_options = { 'mysqld' => { 'wsrep_provider' => '/usr/lib/galera/libgalera_smm.so' } } $mysql_socket = '/var/run/mysqld/mysqld.sock',14,4
openstack%2Frally~master~I86c92794d3ba37973407b635e1024a1fd96e9fb8,openstack/rally,master,I86c92794d3ba37973407b635e1024a1fd96e9fb8,[CI] Increase SLA values to improve stability of CI,MERGED,2017-01-18 11:56:27.000000000,2017-02-17 15:06:06.000000000,2017-02-17 15:06:06.000000000,"[{'_account_id': 3}, {'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 13340}, {'_account_id': 13404}, {'_account_id': 14817}, {'_account_id': 19011}, {'_account_id': 23435}]","[{'number': 1, 'created': '2017-01-18 11:56:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e85bedf01cb8d376965f23c07fad23e6a0cf371c', 'message': '[Rally profile] Increase sla rates\n\nslightly increases max_avg_duration_per_atomic values\nto improve stability of CI.\n\nChange-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8\n'}, {'number': 2, 'created': '2017-01-19 08:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ae7803ca3991848cc255917ce96e136910355432', 'message': '[CI] Increase SLA and http timeout to improve stability of CI\n\n* slightly increases max_avg_duration_per_atomic values\n* increases openstack_client_http_timeout by 90 sec\n\nChange-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8\n'}, {'number': 3, 'created': '2017-01-19 10:27:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a0d965e323c2aec10ed939855dd3b40505613dca', 'message': '[CI] Increase SLA and http timeout to improve stability of CI\n\n* slightly increases max_avg_duration_per_atomic values\n* increases openstack_client_http_timeout by 90 sec\n\nChange-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8\n'}, {'number': 4, 'created': '2017-02-16 15:20:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e6180cd52007d8938afa5c770cb3ddaec4431b88', 'message': '[CI] Increase SLA values to improve stability of CI\n\n* slightly increases max_avg_duration_per_atomic values\n  for RallyProfile scenarios.\n\nChange-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8\n'}, {'number': 5, 'created': '2017-02-16 18:28:13.000000000', 'files': ['rally-jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/rally/commit/dee35b980bdb95c4324db989c9f68a0ae822b86c', 'message': '[CI] Increase SLA values to improve stability of CI\n\n* slightly increases max_avg_duration_per_atomic values\n  for RallyProfile scenarios.\n\nChange-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8\n'}]",0,421853,dee35b980bdb95c4324db989c9f68a0ae822b86c,55,8,5,19011,,,0,"[CI] Increase SLA values to improve stability of CI

* slightly increases max_avg_duration_per_atomic values
  for RallyProfile scenarios.

Change-Id: I86c92794d3ba37973407b635e1024a1fd96e9fb8
",git fetch https://review.opendev.org/openstack/rally refs/changes/53/421853/4 && git format-patch -1 --stdout FETCH_HEAD,['rally-jobs/rally.yaml'],1,e85bedf01cb8d376965f23c07fad23e6a0cf371c,fix-rally-profile, generate_100_names: 0.015 generate_1000_names: 0.1 generate_10000_names: 1 calculate_100_atomics: 0.04 calculate_500_atomics: 0.5, generate_100_names: 0.01 generate_1000_names: 0.075 generate_10000_names: 0.75 calculate_100_atomics: 0.025 calculate_500_atomics: 0.46,5,5
openstack%2Ffuel-library~stable%2Fnewton~I7bff98b9fe89134ba1820807946e95a94e2f8517,openstack/fuel-library,stable/newton,I7bff98b9fe89134ba1820807946e95a94e2f8517,"Update author,author-email,home-page in setup.cfg",MERGED,2017-02-08 12:38:41.000000000,2017-02-17 15:01:22.000000000,2017-02-17 14:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18795}, {'_account_id': 20656}, {'_account_id': 24061}]","[{'number': 1, 'created': '2017-02-08 12:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d2bd3a25364a98d0c056886e42e448b4fa3ea039', 'message': 'Update author,author-email,home-page in setup.cfg\n\nChange-Id: I7bff98b9fe89134ba1820807946e95a94e2f8517\n(cherry picked from commit ef6f4710fe81a087315096fa90dc7401d29a35bd)\n'}, {'number': 2, 'created': '2017-02-13 14:22:39.000000000', 'files': ['utils/fuel-tasklib/setup.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7c0738fbbd7cf1b287200bea8fb526558b4fb5f5', 'message': 'Update author,author-email,home-page in setup.cfg\n\nChange-Id: I7bff98b9fe89134ba1820807946e95a94e2f8517\n(cherry picked from commit ef6f4710fe81a087315096fa90dc7401d29a35bd)\n'}]",0,430879,7c0738fbbd7cf1b287200bea8fb526558b4fb5f5,50,9,2,13344,,,0,"Update author,author-email,home-page in setup.cfg

Change-Id: I7bff98b9fe89134ba1820807946e95a94e2f8517
(cherry picked from commit ef6f4710fe81a087315096fa90dc7401d29a35bd)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/430879/2 && git format-patch -1 --stdout FETCH_HEAD,['utils/fuel-tasklib/setup.cfg'],1,d2bd3a25364a98d0c056886e42e448b4fa3ea039,author,author = OpenStack author-email = openstack-dev@lists.openstack.org home-page = https://wiki.openstack.org/wiki/Fuel/Library_and_Upstream_Modules,author = Mirantis Inc. author-email = product@mirantis.com home-page = http://mirantis.com,3,3
openstack%2Ffuel-library~stable%2Fnewton~Ia203c457e76cc45b70532674f6366928acc09b48,openstack/fuel-library,stable/newton,Ia203c457e76cc45b70532674f6366928acc09b48,Adjust order of entries in /etc/hosts,MERGED,2017-02-08 12:34:28.000000000,2017-02-17 15:01:19.000000000,2017-02-17 14:57:34.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 17638}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-08 12:34:28.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/hosts/hosts.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a17d2e4666d2d9ddc399e2b12ba5e49958007f9a', 'message': 'Adjust order of entries in /etc/hosts\n\nOrder of all entries will be fqdn before prefix-fqdn.\n\nChange-Id: Ia203c457e76cc45b70532674f6366928acc09b48\nCloses-bug: #1624143\n(cherry picked from commit 9382a3eb5facec5b4e6dd8fe6ac03749e4c55b4e)\n'}]",0,430873,a17d2e4666d2d9ddc399e2b12ba5e49958007f9a,34,10,1,13344,,,0,"Adjust order of entries in /etc/hosts

Order of all entries will be fqdn before prefix-fqdn.

Change-Id: Ia203c457e76cc45b70532674f6366928acc09b48
Closes-bug: #1624143
(cherry picked from commit 9382a3eb5facec5b4e6dd8fe6ac03749e4c55b4e)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/73/430873/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/manifests/hosts/hosts.pp'],1,a17d2e4666d2d9ddc399e2b12ba5e49958007f9a,bug/1624143," # Bug LP1624143 : hosts should be consistently ordered create_resources(host, $host_resources, { tag => 'host_resources' } ) create_resources(host, $messaging_host_resources, { tag => 'messaging_host_resources' } ) Host<| tag == 'host_resources' |> -> Host<| tag == 'messaging_host_resources' |> "," $host_hash = merge($host_resources, $messaging_host_resources) create_resources(host, $host_hash)",7,2
openstack%2Fsenlin~stable%2Focata~I06db7ecee48f4ba82a6dc550cc36e7f45f0db922,openstack/senlin,stable/ocata,I06db7ecee48f4ba82a6dc550cc36e7f45f0db922,Release notes for final RC of Ocata,MERGED,2017-02-17 14:18:55.000000000,2017-02-17 14:57:41.000000000,2017-02-17 14:57:41.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2017-02-17 14:18:55.000000000', 'files': ['releasenotes/notes/policy-enabling-61d0c38aecf314eb.yaml', 'releasenotes/notes/server-image-id-27c1619fa818c6a0.yaml', 'releasenotes/notes/dynamic-timer-67f053499f4b32e2.yaml', 'releasenotes/notes/event-purge-db868a063e18eafb.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6c484a0d9e7be5b6970befbc5f846b88d4eb6476', 'message': 'Release notes for final RC of Ocata\n\nChange-Id: I06db7ecee48f4ba82a6dc550cc36e7f45f0db922\n(cherry picked from commit 0797111efb4a3c0c8d1ed884f9866aa267ca8979)\n'}]",0,435468,6c484a0d9e7be5b6970befbc5f846b88d4eb6476,6,2,1,8246,,,0,"Release notes for final RC of Ocata

Change-Id: I06db7ecee48f4ba82a6dc550cc36e7f45f0db922
(cherry picked from commit 0797111efb4a3c0c8d1ed884f9866aa267ca8979)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/68/435468/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/policy-enabling-61d0c38aecf314eb.yaml', 'releasenotes/notes/server-image-id-27c1619fa818c6a0.yaml', 'releasenotes/notes/dynamic-timer-67f053499f4b32e2.yaml', 'releasenotes/notes/event-purge-db868a063e18eafb.yaml']",4,6c484a0d9e7be5b6970befbc5f846b88d4eb6476,relnote-rc,--- features: - A event_purge subcommand is added to senlin-manage tool for purging events generated in a specific project. ,,17,0
openstack%2Ffuel-library~stable%2Fnewton~I1d2bf737e88bba37e08e19c0be1f86c74f1dbd5c,openstack/fuel-library,stable/newton,I1d2bf737e88bba37e08e19c0be1f86c74f1dbd5c,Fix apt pins generation,MERGED,2017-02-08 13:54:22.000000000,2017-02-17 14:55:59.000000000,2017-02-17 14:52:15.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11827}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 17638}, {'_account_id': 18795}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-08 13:54:22.000000000', 'files': ['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_apt_pins.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9741cc4ef434fd677e37b99a0aace10515b04b77', 'message': 'Fix apt pins generation\n\nIn Puppet 4 null value in\nyaml backend is treated as Undef symbol. This\nbehaviour causes generate_apt_pins() function\nto create pins with zero priority.\n\nCloses-Bug: #1655961\n\nChange-Id: I1d2bf737e88bba37e08e19c0be1f86c74f1dbd5c\n(cherry picked from commit 4e37655b4ea33e52ef6fb37e3c9671a9d101b858)\n'}]",0,430928,9741cc4ef434fd677e37b99a0aace10515b04b77,33,10,1,13344,,,0,"Fix apt pins generation

In Puppet 4 null value in
yaml backend is treated as Undef symbol. This
behaviour causes generate_apt_pins() function
to create pins with zero priority.

Closes-Bug: #1655961

Change-Id: I1d2bf737e88bba37e08e19c0be1f86c74f1dbd5c
(cherry picked from commit 4e37655b4ea33e52ef6fb37e3c9671a9d101b858)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/28/430928/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_apt_pins.rb'],1,9741cc4ef434fd677e37b99a0aace10515b04b77,bug/1655961, next unless repo['priority'] and repo['priority'] != :undef, next unless repo['priority'],1,1
openstack%2Fnetworking-bagpipe~master~I88a42ef55390a55160962c4fe083e8829e09bffb,openstack/networking-bagpipe,master,I88a42ef55390a55160962c4fe083e8829e09bffb,Updated from global requirements,MERGED,2017-02-10 05:51:46.000000000,2017-02-17 14:54:06.000000000,2017-02-17 14:54:06.000000000,"[{'_account_id': 3}, {'_account_id': 12021}]","[{'number': 1, 'created': '2017-02-10 05:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/9a364553f606b9fd6cd693478142bcc9ad258f58', 'message': 'Updated from global requirements\n\nChange-Id: I88a42ef55390a55160962c4fe083e8829e09bffb\n'}, {'number': 2, 'created': '2017-02-16 01:21:52.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/a92fb7b626b217c59cd4eb1969d69861d39d33ca', 'message': 'Updated from global requirements\n\nChange-Id: I88a42ef55390a55160962c4fe083e8829e09bffb\n'}]",0,431987,a92fb7b626b217c59cd4eb1969d69861d39d33ca,9,2,2,11131,,,0,"Updated from global requirements

Change-Id: I88a42ef55390a55160962c4fe083e8829e09bffb
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/87/431987/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,9a364553f606b9fd6cd693478142bcc9ad258f58,openstack/requirements,sphinx>=1.5.1 # BSD,"sphinx!=1.3b1,<1.4,>=1.2.1 # BSD",1,1
openstack%2Fnetworking-bagpipe~master~Ib3f1627deb0a7eea3322aed749bafcd23630baee,openstack/networking-bagpipe,master,Ib3f1627deb0a7eea3322aed749bafcd23630baee,tox_install will follow stable/ocata,ABANDONED,2017-02-17 13:36:18.000000000,2017-02-17 14:53:45.000000000,,[],"[{'number': 1, 'created': '2017-02-17 13:36:18.000000000', 'files': ['tools/tox_install.sh'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/ce9bed998a57636f97ff608904dce12efcdf7109', 'message': 'tox_install will follow stable/ocata\n\nChange-Id: Ib3f1627deb0a7eea3322aed749bafcd23630baee\n'}]",0,435445,ce9bed998a57636f97ff608904dce12efcdf7109,2,0,1,12021,,,0,"tox_install will follow stable/ocata

Change-Id: Ib3f1627deb0a7eea3322aed749bafcd23630baee
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/45/435445/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install.sh'],1,ce9bed998a57636f97ff608904dce12efcdf7109,tox_install_ocata,openstack_branch=stable/ocata,openstack_branch=master,1,1
openstack%2Fmanila~master~I9215524d35646de7485504e4c5ff86fd91a1d09f,openstack/manila,master,I9215524d35646de7485504e4c5ff86fd91a1d09f,doc: verify all rst files,MERGED,2017-02-15 06:08:59.000000000,2017-02-17 14:51:02.000000000,2017-02-16 21:34:19.000000000,"[{'_account_id': 3}, {'_account_id': 9064}, {'_account_id': 12017}, {'_account_id': 14567}, {'_account_id': 16643}, {'_account_id': 20695}, {'_account_id': 22248}]","[{'number': 1, 'created': '2017-02-15 06:08:59.000000000', 'files': ['doc/source/devref/manila.rst', 'install-guide/source/common/dhss-true-mode-intro.rst', 'doc/source/devref/threading.rst', 'doc/source/devref/driver_filter_goodness_weigher.rst', 'test-requirements.txt', 'doc/source/devref/container_driver.rst', 'doc/source/devref/emc_unity_driver.rst', 'doc/source/devref/fakes.rst', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/a8ec3317be53b1bef23522e713a3f6e02ebbb505', 'message': ""doc: verify all rst files\n\nMake use of doc8 to verify all rst files which are not\nautogenerated for errors and fail if there are any issues\nfound. The doc8 checks are now part of the tox 'docs'\nenvironment and ran automatically. Checks can also be called\ndirecly via 'tox -e docs'.\n\nFix all issues found by doc8.\n\nCloses-Bug: #1664841\n\nChange-Id: I9215524d35646de7485504e4c5ff86fd91a1d09f\nSigned-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>\n""}]",5,434086,a8ec3317be53b1bef23522e713a3f6e02ebbb505,32,7,1,9064,,,0,"doc: verify all rst files

Make use of doc8 to verify all rst files which are not
autogenerated for errors and fail if there are any issues
found. The doc8 checks are now part of the tox 'docs'
environment and ran automatically. Checks can also be called
direcly via 'tox -e docs'.

Fix all issues found by doc8.

Closes-Bug: #1664841

Change-Id: I9215524d35646de7485504e4c5ff86fd91a1d09f
Signed-off-by: Danny Al-Gaaf <danny.al-gaaf@bisect.de>
",git fetch https://review.opendev.org/openstack/manila refs/changes/86/434086/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/devref/manila.rst', 'install-guide/source/common/dhss-true-mode-intro.rst', 'doc/source/devref/driver_filter_goodness_weigher.rst', 'doc/source/devref/threading.rst', 'test-requirements.txt', 'doc/source/devref/container_driver.rst', 'doc/source/devref/emc_unity_driver.rst', 'doc/source/devref/fakes.rst', 'tox.ini', 'HACKING.rst']",10,a8ec3317be53b1bef23522e713a3f6e02ebbb505,bug/1664841,=========================- [M333] ``oslo_`` should be used instead of ``oslo.``,=======================- [M333] 'oslo_' should be used instead of 'oslo.',22,15
openstack%2Fmanila~master~I88df15446ffe34f3f12770d53c3e03d232f495c2,openstack/manila,master,I88df15446ffe34f3f12770d53c3e03d232f495c2,Fix migration_success before completing,MERGED,2017-02-15 18:51:59.000000000,2017-02-17 14:49:08.000000000,2017-02-17 11:56:45.000000000,"[{'_account_id': 3}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 12017}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 16643}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 20695}, {'_account_id': 22236}, {'_account_id': 22248}, {'_account_id': 24594}]","[{'number': 1, 'created': '2017-02-15 18:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/b502ba5dc643b4dace97f72d3b4514c232bc7ac5', 'message': ""Fix migration_success before completing\n\nShare task_state was set to migration_success\nbefore completing migration. There was still\nupdates to the share model to be performed\nbefore completing.\n\nAlso, small refactoring in host-assisted\nmigration's migration_complete that was not\nsetting the task_state migration_completing\nat the proper time, allowing a bigger window\nfor 2 concurrent migration_complete calls.\n\nChange-Id: I88df15446ffe34f3f12770d53c3e03d232f495c2\nCloses-bug: #1665072\n""}, {'number': 2, 'created': '2017-02-15 19:06:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a1f1f0b352f13ebdba6f80f5625847f15bf60b57', 'message': ""Fix migration_success before completing\n\nShare task_state was set to migration_success\nbefore completing migration. There was still\nupdates to the share model to be performed\nbefore completing.\n\nAlso, small refactoring in host-assisted\nmigration's migration_complete that was not\nsetting the task_state migration_completing\nat the proper time, allowing a bigger window\nfor 2 concurrent migration_complete calls.\n\nChange-Id: I88df15446ffe34f3f12770d53c3e03d232f495c2\nCloses-bug: #1665072\n""}, {'number': 3, 'created': '2017-02-16 10:50:33.000000000', 'files': ['manila/share/manager.py', 'releasenotes/notes/bug-1665072-migration-success-fix-3da1e80fbab666de.yaml', 'manila/tests/share/test_manager.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/41813736718e2b81d1d907bf49feb1940c1e990f', 'message': ""Fix migration_success before completing\n\nShare task_state was set to migration_success\nbefore completing migration. There was still\nupdates to the share model to be performed\nbefore completing.\n\nAlso, small refactoring in host-assisted\nmigration's migration_complete that was not\nsetting the task_state migration_completing\nat the proper time, allowing a bigger window\nfor 2 concurrent migration_complete calls.\n\nChange-Id: I88df15446ffe34f3f12770d53c3e03d232f495c2\nCloses-bug: #1665072\n""}]",0,434462,41813736718e2b81d1d907bf49feb1940c1e990f,44,14,3,14567,,,0,"Fix migration_success before completing

Share task_state was set to migration_success
before completing migration. There was still
updates to the share model to be performed
before completing.

Also, small refactoring in host-assisted
migration's migration_complete that was not
setting the task_state migration_completing
at the proper time, allowing a bigger window
for 2 concurrent migration_complete calls.

Change-Id: I88df15446ffe34f3f12770d53c3e03d232f495c2
Closes-bug: #1665072
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/434462/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/manager.py', 'releasenotes/notes/bug-1665072-migration-success-fix-3da1e80fbab666de.yaml', 'manila/tests/share/test_manager.py']",3,b502ba5dc643b4dace97f72d3b4514c232bc7ac5,bug/1665072," si_update = self.mock_object( self.share_manager.db, 'share_instance_update') instance_delete = self.mock_object( self.share_manager, '_migration_delete_instance') self.share_manager.db.share_update.assert_has_calls([ mock.call( self.context, share['id'], model_type_update), mock.call( self.context, instance_2['share_id'], {'task_state': constants.TASK_STATE_MIGRATION_SUCCESS})]) instance_delete.assert_called_once_with( self.context, instance_1['id']) si_update.assert_called_once_with( self.context, instance_2['id'], {'status': constants.STATUS_AVAILABLE}) self.share_manager.db.share_update.assert_called_once_with( {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING}) self.share_manager.db.share_update.assert_called_once_with( {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING})"," self.mock_object(self.share_manager.db, 'share_instance_update') self.share_manager.db.share_update.assert_called_once_with( self.context, share['id'], model_type_update) self.mock_object(self.share_manager.db, 'share_instance_update') self.mock_object(self.share_manager, '_migration_delete_instance') self.share_manager._migration_delete_instance.assert_called_once_with( self.context, src_instance['id']) self.share_manager.db.share_instance_update.assert_called_once_with( self.context, dest_instance['id'], {'status': constants.STATUS_AVAILABLE}) self.share_manager.db.share_update.assert_has_calls([ mock.call( {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING}), mock.call( self.context, dest_instance['share_id'], {'task_state': constants.TASK_STATE_MIGRATION_SUCCESS})]) self.mock_object(self.share_manager.db, 'share_instance_update') 'delete_instance_and_wait') self.mock_object(migration_api.ShareMigrationHelper, self.share_manager.db.share_instance_update.assert_has_calls([ mock.call(self.context, new_instance['id'], {'status': constants.STATUS_AVAILABLE}), mock.call(self.context, instance['id'], {'status': constants.STATUS_INACTIVE}) ]) self.share_manager.db.share_update.assert_has_calls([ mock.call( {'task_state': constants.TASK_STATE_MIGRATION_COMPLETING}), mock.call( self.context, share['id'], {'task_state': constants.TASK_STATE_MIGRATION_SUCCESS}), ]) migration_api.ShareMigrationHelper.delete_instance_and_wait.\ assert_called_once_with(instance)",45,62
openstack%2Fopenstack-ansible-os_swift~master~Ic2199ccc393b25a60af82af3aa638f21f19a6418,openstack/openstack-ansible-os_swift,master,Ic2199ccc393b25a60af82af3aa638f21f19a6418,Make swift_rings threading react to bad return codes,MERGED,2017-02-10 04:00:37.000000000,2017-02-17 14:43:45.000000000,2017-02-17 14:43:45.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 10881}]","[{'number': 1, 'created': '2017-02-10 04:00:37.000000000', 'files': ['templates/swift_rings.py.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/0dd92296cda02bc46c91835209516558193eab69', 'message': ""Make swift_rings threading react to bad return codes\n\nThe swift_rings.py script creates a thread and calls out to\nswift's ringbuilder cli interface. It wasn't failing if\nringbuilder failed.\n\nThis change changes the threading to capture the threads exit\ncode and sys.exit on a bad one.\n\nChange-Id: Ic2199ccc393b25a60af82af3aa638f21f19a6418\n""}]",0,431869,0dd92296cda02bc46c91835209516558193eab69,8,4,1,7233,,,0,"Make swift_rings threading react to bad return codes

The swift_rings.py script creates a thread and calls out to
swift's ringbuilder cli interface. It wasn't failing if
ringbuilder failed.

This change changes the threading to capture the threads exit
code and sys.exit on a bad one.

Change-Id: Ic2199ccc393b25a60af82af3aa638f21f19a6418
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/69/431869/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/swift_rings.py.j2'],1,0dd92296cda02bc46c91835209516558193eab69,,"class ThreadWithErr(threading.Thread): def run(self): try: threading.Thread.run(self) except BaseException as err: self.err = err else: self.err = None t = ThreadWithErr(target=func, args=args) t.join() if t.err and t.err.code > 0: sys.exit(t.err.code)"," t = threading.Thread(target=func, args=args) return t.join()",14,2
openstack%2Fopenstack-ansible~stable%2Focata~I26c18826f04bb206767cd5c7f9454f62faa726fa,openstack/openstack-ansible,stable/ocata,I26c18826f04bb206767cd5c7f9454f62faa726fa,Get conf files from local git server rather than upstream,MERGED,2017-02-13 09:12:46.000000000,2017-02-17 14:37:51.000000000,2017-02-17 14:37:51.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}]","[{'number': 1, 'created': '2017-02-13 09:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9d3558895625ca1d63823bf64f7383ba67b03450', 'message': 'Get conf files from local git server rather than upstream\n\nNow that gnocchi and ceilometer are pulling conf files from git\nrepositories rather than storing them in the role, we should ensure we\npull these files from the repo server rather than the upstream\ngit.openstack.org location when setting up gnocchi and ceilometer.\n\nChange-Id: I26c18826f04bb206767cd5c7f9454f62faa726fa\nDepends-On: I86389c1f7643a0634a85f165f62f089a316f040c\n(cherry picked from commit 06cd163c5722e85461a1dc73d33875edfa24bc11)\n'}, {'number': 2, 'created': '2017-02-13 10:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fd8823ef5bca3c54e2b16620088a5f139c16b246', 'message': 'Get conf files from local git server rather than upstream\n\nNow that gnocchi and ceilometer are pulling conf files from git\nrepositories rather than storing them in the role, we should ensure we\npull these files from the repo server rather than the upstream\ngit.openstack.org location when setting up gnocchi and ceilometer.\n\nChange-Id: I26c18826f04bb206767cd5c7f9454f62faa726fa\nDepends-On: I86389c1f7643a0634a85f165f62f089a316f040c\n(cherry picked from commit 06cd163c5722e85461a1dc73d33875edfa24bc11)\n'}, {'number': 3, 'created': '2017-02-13 10:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/96f546c2a2d4b9d226be5c33dda0ced6c86234ba', 'message': 'Get conf files from local git server rather than upstream\n\nNow that gnocchi and ceilometer are pulling conf files from git\nrepositories rather than storing them in the role, we should ensure we\npull these files from the repo server rather than the upstream\ngit.openstack.org location when setting up gnocchi and ceilometer.\n\nThis is not a clean back-port, it includes a SHA bump the os_gnocchi\nrole to correctly set the base path for fetching the config files.\n\nChange-Id: I26c18826f04bb206767cd5c7f9454f62faa726fa\nDepends-On: I86389c1f7643a0634a85f165f62f089a316f040c\n(cherry picked from commit 06cd163c5722e85461a1dc73d33875edfa24bc11)\n'}, {'number': 4, 'created': '2017-02-17 10:47:38.000000000', 'files': ['playbooks/inventory/group_vars/gnocchi_all.yml', 'playbooks/inventory/group_vars/ceilometer_all.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/22b1dc076ca4b9ea2579473bcba7d845cd513185', 'message': 'Get conf files from local git server rather than upstream\n\nNow that gnocchi and ceilometer are pulling conf files from git\nrepositories rather than storing them in the role, we should ensure we\npull these files from the repo server rather than the upstream\ngit.openstack.org location when setting up gnocchi and ceilometer.\n\nThis is not a clean back-port, it includes a SHA bump the os_gnocchi\nrole to correctly set the base path for fetching the config files.\n\nChange-Id: I26c18826f04bb206767cd5c7f9454f62faa726fa\nDepends-On: I86389c1f7643a0634a85f165f62f089a316f040c\n(cherry picked from commit 06cd163c5722e85461a1dc73d33875edfa24bc11)\n'}]",0,432930,22b1dc076ca4b9ea2579473bcba7d845cd513185,16,4,4,6816,,,0,"Get conf files from local git server rather than upstream

Now that gnocchi and ceilometer are pulling conf files from git
repositories rather than storing them in the role, we should ensure we
pull these files from the repo server rather than the upstream
git.openstack.org location when setting up gnocchi and ceilometer.

This is not a clean back-port, it includes a SHA bump the os_gnocchi
role to correctly set the base path for fetching the config files.

Change-Id: I26c18826f04bb206767cd5c7f9454f62faa726fa
Depends-On: I86389c1f7643a0634a85f165f62f089a316f040c
(cherry picked from commit 06cd163c5722e85461a1dc73d33875edfa24bc11)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/30/432930/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/inventory/group_vars/gnocchi_all.yml', 'playbooks/inventory/group_vars/ceilometer_all.yml']",2,9d3558895625ca1d63823bf64f7383ba67b03450,template_repo,"ceilometer_git_config_lookup_location: ""http://{{ internal_lb_vip_address }}:{{ repo_server_port }}/openstackgit/ceilometer/""",,2,0
openstack%2Fheat~stable%2Fnewton~I37b2781c07f2e1c38c6fbd68ddf57bfaa739862f,openstack/heat,stable/newton,I37b2781c07f2e1c38c6fbd68ddf57bfaa739862f,ResourceGroup fix issue with batch create and zero count,MERGED,2017-02-02 09:53:24.000000000,2017-02-17 14:36:56.000000000,2017-02-17 14:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 12404}]","[{'number': 1, 'created': '2017-02-02 09:53:24.000000000', 'files': ['heat/engine/resources/openstack/heat/resource_group.py', 'heat/tests/openstack/heat/test_resource_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/b019d2806566213fe7a029093dce42dcf4dd0810', 'message': 'ResourceGroup fix issue with batch create and zero count\n\nWe need to avoid derefencing an empty list here when the count is zero.\n\nChange-Id: I37b2781c07f2e1c38c6fbd68ddf57bfaa739862f\nCloses-Bug: #1661049\n(cherry picked from commit 057f563640a3d9a1d5eaf96150702e2faf5d1cec)\n'}]",0,428063,b019d2806566213fe7a029093dce42dcf4dd0810,8,4,1,4328,,,0,"ResourceGroup fix issue with batch create and zero count

We need to avoid derefencing an empty list here when the count is zero.

Change-Id: I37b2781c07f2e1c38c6fbd68ddf57bfaa739862f
Closes-Bug: #1661049
(cherry picked from commit 057f563640a3d9a1d5eaf96150702e2faf5d1cec)
",git fetch https://review.opendev.org/openstack/heat refs/changes/63/428063/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/heat/resource_group.py', 'heat/tests/openstack/heat/test_resource_group.py']",2,b019d2806566213fe7a029093dce42dcf4dd0810,bug/1661049," def test_handle_create_with_batching_zero_count(self): stack = utils.parse_stack(tmpl_with_default_updt_policy()) defn = stack.t.resource_definitions(stack)['group1'] props = stack.t.t['resources']['group1']['properties'].copy() props['count'] = 0 update_policy = {'batch_create': {'max_batch_size': 1}} snip = defn.freeze(properties=props, update_policy=update_policy) resgrp = resource_group.ResourceGroup('test', snip, stack) self.patchobject(scheduler.TaskRunner, 'start') checkers = resgrp.handle_create() self.assertEqual(0, len(checkers)) ",,14,1
openstack%2Fpuppet-openstack-guide~master~I14f36b0c4d64044679fb2419af1afaaee5b679f3,openstack/puppet-openstack-guide,master,I14f36b0c4d64044679fb2419af1afaaee5b679f3,Update puppet-congress release,MERGED,2017-02-17 14:25:44.000000000,2017-02-17 14:36:12.000000000,2017-02-17 14:36:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 15519}]","[{'number': 1, 'created': '2017-02-17 14:25:44.000000000', 'files': ['doc/source/releases.rst'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-guide/commit/3bd0dcd6ab0ae69ecb507a39523b89c8685910ff', 'message': 'Update puppet-congress release\n\nThe puppet-congress has been released[0].\n\n[0]https://review.openstack.org/#/c/431151/\n\nChange-Id: I14f36b0c4d64044679fb2419af1afaaee5b679f3\n'}]",0,435470,3bd0dcd6ab0ae69ecb507a39523b89c8685910ff,7,3,1,9414,,,0,"Update puppet-congress release

The puppet-congress has been released[0].

[0]https://review.openstack.org/#/c/431151/

Change-Id: I14f36b0c4d64044679fb2419af1afaaee5b679f3
",git fetch https://review.opendev.org/openstack/puppet-openstack-guide refs/changes/70/435470/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/releases.rst'],1,3bd0dcd6ab0ae69ecb507a39523b89c8685910ff,fix_congress_ocata,| puppet-congress_ | `10.3.0 <http://docs.openstack.org/releasenotes/puppet-congress`__ |,| puppet-congress_ | None |,1,1
openstack%2Fshade~master~Ia429b4ac270f22aba54923354bc160aa66c76a1f,openstack/shade,master,Ia429b4ac270f22aba54923354bc160aa66c76a1f,DNM - Patch to verify 2.0 usage payload behavior,ABANDONED,2017-02-15 19:49:57.000000000,2017-02-17 14:34:43.000000000,,"[{'_account_id': 3}, {'_account_id': 16907}]","[{'number': 1, 'created': '2017-02-15 19:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/52e956ba7843b3d0879d8a382458242618e6f54a', 'message': 'DNM - Patch to verify 2.0 usage payload behavior\n\nThis should fail the usage test and then print all of the API\ninteractions.\n\nChange-Id: Ia429b4ac270f22aba54923354bc160aa66c76a1f\n'}, {'number': 2, 'created': '2017-02-17 00:00:12.000000000', 'files': ['shade/tests/functional/test_usage.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/67a73ff3709717ee86a4b87e3822e57798200836', 'message': 'DNM - Patch to verify 2.0 usage payload behavior\n\nThis should fail the usage test and then print all of the API\ninteractions.\n\nChange-Id: Ia429b4ac270f22aba54923354bc160aa66c76a1f\n'}]",0,434482,67a73ff3709717ee86a4b87e3822e57798200836,8,2,2,2,,,0,"DNM - Patch to verify 2.0 usage payload behavior

This should fail the usage test and then print all of the API
interactions.

Change-Id: Ia429b4ac270f22aba54923354bc160aa66c76a1f
",git fetch https://review.opendev.org/openstack/shade refs/changes/82/434482/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/functional/test_usage.py', 'shade/openstackcloud.py']",2,52e956ba7843b3d0879d8a382458242618e6f54a,switch-to-rest," 'compute', novaclient.client.Client, version='2.0')"," 'compute', novaclient.client.Client)",2,2
openstack%2Fsenlin~stable%2Focata~I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8,openstack/senlin,stable/ocata,I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8,Fix receiver reference documentation,MERGED,2017-02-17 14:15:06.000000000,2017-02-17 14:33:28.000000000,2017-02-17 14:33:28.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 14:15:06.000000000', 'files': ['doc/source/user/receivers.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/651ebcd61ac27b14f05530c0987f4e4be0bed5e5', 'message': 'Fix receiver reference documentation\n\nChange-Id: I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8\n(cherry picked from commit 5318c6e1a11ab013650f8bae46ef6cd5f07ac615)\n'}]",0,435464,651ebcd61ac27b14f05530c0987f4e4be0bed5e5,6,2,1,8246,,,0,"Fix receiver reference documentation

Change-Id: I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8
(cherry picked from commit 5318c6e1a11ab013650f8bae46ef6cd5f07ac615)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/64/435464/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/receivers.rst'],1,651ebcd61ac27b14f05530c0987f4e4be0bed5e5,fix-receiver-doc,"Creating and Using a Receiver ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Currently, Senlin supports two receiver types: ""``webhook``"" and ""``message``"". For the former one, a permanent webhook url is generated for users to triggerSuch a message is used to notify the Senlin service to initiate an action on aWebhook Receiver ---------------- When creating a webhook receiver, you are expected to use the option :option:`--cluster` to specify the target cluster and the option :option:`--action` to specify the action name. By default, the :program:`openstack cluster receiver create` command line creates a receiver of type ""``webhook``"". User can also explicitly specify the receiver type using the option :option:`--type`, for example: .. code-block:: console $ openstack cluster receiver create \ --cluster test-cluster \ --action CLUSTER_SCALE_OUT \ --type webhook \ test-receiver Senlin service will return the receiver information with its channel ready to receive HTTP POST requests. For a webhook receiver, this means you can check the ""``alarm_url``"" field of the ""``channel``"" property. You can use this URL to trigger the action you specified. The following command triggers the receiver by sending a ``POST`` request to the URL obtained from its ``channel`` property, for example: .. code-block:: console $ curl -X POST <alarm_url> Message Receiver ---------------- A message receiver is different from a webhook receiver in that it can trigger different actions on different clusters. Therefore, option :option:`--cluster` and option :option:`--action` can be omitted when creating a message receiver. Senlin will check if the incoming message contains such properties. You will need to specify the receiver type ""``message``"" using the option :option:`--type` when creating a message receiver, for example: .. code-block:: console $ openstack cluster receiver create \ --type message \ test-receiver Senlin service will return the receiver information with its channel ready to receive messages. For a message receiver, this means you can check the ""``queue_name``"" field of the ""``channel``"" property. Once a message receiver is created, you (or some software) can send messages with the following format to the named Zaqar queue to request Senlin service: .. code-block:: pythonMore examples on sending message to a Zaqar queue can be found here: http://git.openstack.org/cgit/openstack/python-zaqarclient/tree/examples .. note:: Users are permitted to trigger multiple actions at the same time by sending more than one message to a Zaqar queue in the same request. In that case, the order of actions generated depends on how Zaqar sorts those messages.","Creating a Receiver ~~~~~~~~~~~~~~~~~~~ Currently, we support two receiver types: ``webhook`` and ``message``. For the former one, a permanent webhook url is generated for users to triggerSuch a message is used to notify the Senlin service to start an action on aCreating a Webhook Receiver --------------------------- 1. Create a cluster named ""``test-cluster``"", with its desired capacity set to 2, its minimum size set to 1 and its maximum size set to 5, e.g.:: $ senlin cluster-create --profile $PROFILE_ID \ --desired-capacity 2 --min-size 1 --max-size 5 \ test-cluster 2. Attach a ScalingPolicy to the cluster:: $ openstack cluster policy attach --policy $POLICY_ID test-cluster 3. Create a webhook receiver, use the option :option:`--cluster` to specify ""``test-cluster``"" as the targeted cluster and use the option :option:`--action` to specify ""``CLUSTER_SCALE_OUT``"" or ""``CLUSTER_SCALE_IN``"" as the action name. By default, the :program:`openstack cluster receiver create` command line creates a receiver of type :term:`webhook`. User can also explicitly specify the receiver type using the option :option:`--type`, for example:: $ openstack cluster receiver create \ --cluster test-cluster \ --action CLUSTER_SCALE_OUT \ --type webhook \ test-receiver Senlin service will return the receiver information with its channel ready to receive signals. For a webhook receiver, this means you can check the ""``alarm_url``"" field of the ""``channel``"" property. You can use this url to trigger the action you specified. 4. Trigger the receiver by sending a ``POST`` request to its URL, for example:: $ curl -X POST <alarm_url> Creating a Message Receiver --------------------------- 1. Different from a webhook receiver which can only be used to trigger a specific action on a specific cluster, a message receiver is designed to trigger different actions on different clusters. Therefore, option :option:`--cluster` and option :option:`--action` could be omitted when creating a message receiver. Users need to specify the receiver type ``message`` using the option :option:`--type`, for example:: $ openstack cluster receiver create \ --type message \ test-receiver Senlin service will return the receiver information with its channel ready to receive messages. For a message receiver, this means you can check the ""``queue_name``"" field of the ""``channel``"" property and then send messages with the following format to this Zaqar queue to request Senlin service:: Examples for sending message to Zaqar queue can be found here: http://git.openstack.org/cgit/openstack/python-zaqarclient/tree/examples Note: Users are allowed to trigger multiple actions at the same time by sending more than one message to a Zaqar queue in the same request. In that case, the order of actions generated depends on how Zaqar sorts those messages.",55,53
openstack%2Fcharm-nova-cloud-controller~master~I68186c66b69bae9e97f25a4fb68693c79fe315e2,openstack/charm-nova-cloud-controller,master,I68186c66b69bae9e97f25a4fb68693c79fe315e2,Add cells v2 minimal database support,ABANDONED,2017-02-08 12:35:18.000000000,2017-02-17 14:23:17.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-08 12:35:18.000000000', 'files': ['templates/ocata/nova.conf', 'hooks/nova_cc_utils.py', 'hooks/nova_cc_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/a58212a423c37596ecd11edff21ec3e88fee2742', 'message': 'Add cells v2 minimal database support\n\nChange-Id: I68186c66b69bae9e97f25a4fb68693c79fe315e2\n'}]",0,430877,a58212a423c37596ecd11edff21ec3e88fee2742,7,4,1,11805,,,0,"Add cells v2 minimal database support

Change-Id: I68186c66b69bae9e97f25a4fb68693c79fe315e2
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/77/430877/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/ocata/nova.conf', 'hooks/nova_cc_utils.py', 'hooks/nova_cc_hooks.py']",3,a58212a423c37596ecd11edff21ec3e88fee2742,," add_hosts_to_cell, if os_release('nova-common') >= 'ocata': # NOTE: ocata requires cells v2 relation_set(novacell0_database='nova_cell0', novacell0_username=config('database-user'), novacell0_hostname=host, relation_id=relation_id) #add_hosts_to_cell() ",,221,4
openstack%2Fsenlin~master~I06db7ecee48f4ba82a6dc550cc36e7f45f0db922,openstack/senlin,master,I06db7ecee48f4ba82a6dc550cc36e7f45f0db922,Release notes for final RC of Ocata,MERGED,2017-02-15 01:42:49.000000000,2017-02-17 14:18:55.000000000,2017-02-15 05:35:54.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2017-02-15 01:42:49.000000000', 'files': ['releasenotes/notes/policy-enabling-61d0c38aecf314eb.yaml', 'releasenotes/notes/server-image-id-27c1619fa818c6a0.yaml', 'releasenotes/notes/dynamic-timer-67f053499f4b32e2.yaml', 'releasenotes/notes/event-purge-db868a063e18eafb.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/0797111efb4a3c0c8d1ed884f9866aa267ca8979', 'message': 'Release notes for final RC of Ocata\n\nChange-Id: I06db7ecee48f4ba82a6dc550cc36e7f45f0db922\n'}]",0,434013,0797111efb4a3c0c8d1ed884f9866aa267ca8979,10,3,1,8246,,,0,"Release notes for final RC of Ocata

Change-Id: I06db7ecee48f4ba82a6dc550cc36e7f45f0db922
",git fetch https://review.opendev.org/openstack/senlin refs/changes/13/434013/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/policy-enabling-61d0c38aecf314eb.yaml', 'releasenotes/notes/server-image-id-27c1619fa818c6a0.yaml', 'releasenotes/notes/dynamic-timer-67f053499f4b32e2.yaml', 'releasenotes/notes/event-purge-db868a063e18eafb.yaml']",4,0797111efb4a3c0c8d1ed884f9866aa267ca8979,relnote-rc,--- features: - A event_purge subcommand is added to senlin-manage tool for purging events generated in a specific project. ,,17,0
openstack%2Fsenlin~master~I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8,openstack/senlin,master,I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8,Fix receiver reference documentation,MERGED,2017-02-08 03:11:58.000000000,2017-02-17 14:15:06.000000000,2017-02-15 03:02:22.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-08 03:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/ed8ed52f60e7ae16214e3701cdc254f7cf535364', 'message': 'Fix receiver reference documentation\n\nChange-Id: I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8\n'}, {'number': 2, 'created': '2017-02-15 02:48:48.000000000', 'files': ['doc/source/user/receivers.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/5318c6e1a11ab013650f8bae46ef6cd5f07ac615', 'message': 'Fix receiver reference documentation\n\nChange-Id: I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8\n'}]",0,430527,5318c6e1a11ab013650f8bae46ef6cd5f07ac615,11,2,2,8246,,,0,"Fix receiver reference documentation

Change-Id: I94e2104c8780ac2eb5e37ccfa3be69f9b56fbac8
",git fetch https://review.opendev.org/openstack/senlin refs/changes/27/430527/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/receivers.rst'],1,ed8ed52f60e7ae16214e3701cdc254f7cf535364,fix-receiver-doc,"Creating and Using a Receiver ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Currently, Senlin supports two receiver types: ""``webhook``"" and ""``message``"". For the former one, a permanent webhook url is generated for users to triggerSuch a message is used to notify the Senlin service to initiate an action on aWebhook Receiver ---------------- When creating a webhook receiver, you are expected to use the option :option:`--cluster` to specify the target cluster and the option :option:`--action` to specify the action name. By default, the :program:`openstack cluster receiver create` command line creates a receiver of type ""``webhook``"". User can also explicitly specify the receiver type using the option :option:`--type`, for example: .. code-block:: console $ openstack cluster receiver create \ --cluster test-cluster \ --action CLUSTER_SCALE_OUT \ --type webhook \ test-receiver Senlin service will return the receiver information with its channel ready to receive HTTP POST requests. For a webhook receiver, this means you can check the ""``alarm_url``"" field of the ""``channel``"" property. You can use this URL to trigger the action you specified. The following command triggers the receiver by sending a ``POST`` request to the URL obtained from its ``channel`` property, for example: .. code-block:: console $ curl -X POST <alarm_url> Message Receiver ---------------- A message receiver is different from a webhook receiver in that it can trigger different actions on different clusters. Therefore, option :option:`--cluster` and option :option:`--action` can be omitted when creating a message receiver. Senlin will check if the incoming message contains such properties. You will need to specify the receiver type ""``message``"" using the option :option:`--type` when creating a message receiver, for example: .. code-block:: console $ openstack cluster receiver create \ --type message \ test-receiver Senlin service will return the receiver information with its channel ready to receive messages. For a message receiver, this means you can check the ""``queue_name``"" field of the ""``channel``"" property. Once a message receiver is created, you (or some software) can send messages with the following format to the named Zaqar queue to request Senlin service: .. code-block:: pythonMore examples on sending message to a Zaqar queue can be found here: http://git.openstack.org/cgit/openstack/python-zaqarclient/tree/examples .. note:: Users are permitted to trigger multiple actions at the same time by sending more than one message to a Zaqar queue in the same request. In that case, the order of actions generated depends on how Zaqar sorts those messages.","Creating a Receiver ~~~~~~~~~~~~~~~~~~~ Currently, we support two receiver types: ``webhook`` and ``message``. For the former one, a permanent webhook url is generated for users to triggerSuch a message is used to notify the Senlin service to start an action on aCreating a Webhook Receiver --------------------------- 1. Create a cluster named ""``test-cluster``"", with its desired capacity set to 2, its minimum size set to 1 and its maximum size set to 5, e.g.:: $ senlin cluster-create --profile $PROFILE_ID \ --desired-capacity 2 --min-size 1 --max-size 5 \ test-cluster 2. Attach a ScalingPolicy to the cluster:: $ openstack cluster policy attach --policy $POLICY_ID test-cluster 3. Create a webhook receiver, use the option :option:`--cluster` to specify ""``test-cluster``"" as the targeted cluster and use the option :option:`--action` to specify ""``CLUSTER_SCALE_OUT``"" or ""``CLUSTER_SCALE_IN``"" as the action name. By default, the :program:`openstack cluster receiver create` command line creates a receiver of type :term:`webhook`. User can also explicitly specify the receiver type using the option :option:`--type`, for example:: $ openstack cluster receiver create \ --cluster test-cluster \ --action CLUSTER_SCALE_OUT \ --type webhook \ test-receiver Senlin service will return the receiver information with its channel ready to receive signals. For a webhook receiver, this means you can check the ""``alarm_url``"" field of the ""``channel``"" property. You can use this url to trigger the action you specified. 4. Trigger the receiver by sending a ``POST`` request to its URL, for example:: $ curl -X POST <alarm_url> Creating a Message Receiver --------------------------- 1. Different from a webhook receiver which can only be used to trigger a specific action on a specific cluster, a message receiver is designed to trigger different actions on different clusters. Therefore, option :option:`--cluster` and option :option:`--action` could be omitted when creating a message receiver. Users need to specify the receiver type ``message`` using the option :option:`--type`, for example:: $ openstack cluster receiver create \ --type message \ test-receiver Senlin service will return the receiver information with its channel ready to receive messages. For a message receiver, this means you can check the ""``queue_name``"" field of the ""``channel``"" property and then send messages with the following format to this Zaqar queue to request Senlin service:: Examples for sending message to Zaqar queue can be found here: http://git.openstack.org/cgit/openstack/python-zaqarclient/tree/examples Note: Users are allowed to trigger multiple actions at the same time by sending more than one message to a Zaqar queue in the same request. In that case, the order of actions generated depends on how Zaqar sorts those messages.",55,53
openstack%2Fsenlin~master~I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba,openstack/senlin,master,I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba,Support 'enabled' in attach callback,MERGED,2017-02-13 17:00:05.000000000,2017-02-17 14:14:29.000000000,2017-02-14 10:09:34.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-13 17:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/89c4c57877c8fb209eb42be70056669a9d082e9b', 'message': ""Support 'enabled' in attach callback\n\nWe have supported 'enabled' option in api/db when attaching policy\nto a cluster. This patch sports 'enabled' in attach callback, or else\nwe will met bug when we run 'senlin cluster-policy-attach' with\n'enabled'=False.\n\nCloses-Bug: #1664208\nChange-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba\n""}, {'number': 2, 'created': '2017-02-14 07:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1aa223723ae6bb7942b294c56091d6ed19a5a5e8', 'message': ""Support 'enabled' in attach callback\n\nWe have supported 'enabled' option in api/db when attaching policy\nto a cluster. This patch supports 'enabled' in attach callback, or else\nwe will get bug when we run 'senlin cluster-policy-attach' with\n'enabled'=False.\n\nCloses-Bug: #1664208\nChange-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba\n""}, {'number': 3, 'created': '2017-02-14 07:39:47.000000000', 'files': ['senlin/policies/health_policy.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/tests/unit/fakes.py', 'senlin/policies/lb_policy.py', 'senlin/engine/cluster.py', 'senlin/policies/base.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/policies/affinity_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/fb240766a2505d5ad527ba314913c90a9f8da6b1', 'message': ""Support 'enabled' in attach callback\n\nWe have supported 'enabled' option in api/db when attaching policy\nto a cluster. This patch supports 'enabled' in attach callback, or else\nwe will get bug when we run 'senlin cluster-policy-attach' with\n'enabled'=False.\n\nCloses-Bug: #1664208\nChange-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba\n""}]",4,433188,fb240766a2505d5ad527ba314913c90a9f8da6b1,15,3,3,22998,,,0,"Support 'enabled' in attach callback

We have supported 'enabled' option in api/db when attaching policy
to a cluster. This patch supports 'enabled' in attach callback, or else
we will get bug when we run 'senlin cluster-policy-attach' with
'enabled'=False.

Closes-Bug: #1664208
Change-Id: I75d3eec974bf728c51cd31b2b8c1c31b7e43d1ba
",git fetch https://review.opendev.org/openstack/senlin refs/changes/88/433188/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/health_policy.py', 'senlin/tests/unit/engine/test_cluster.py', 'senlin/tests/unit/fakes.py', 'senlin/policies/lb_policy.py', 'senlin/engine/cluster.py', 'senlin/policies/base.py', 'senlin/tests/unit/policies/test_health_policy.py', 'senlin/policies/affinity_policy.py']",8,89c4c57877c8fb209eb42be70056669a9d082e9b,bug/1664208," def attach(self, cluster, enabled=True):"," def attach(self, cluster):",12,9
openstack%2Fsenlin~master~Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b,openstack/senlin,master,Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b,Rename get_service_context to get_service_credentials,MERGED,2017-02-14 05:14:05.000000000,2017-02-17 14:13:42.000000000,2017-02-14 10:16:09.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 22998}]","[{'number': 1, 'created': '2017-02-14 05:14:05.000000000', 'files': ['senlin/api/middleware/webhook.py', 'senlin/engine/health_manager.py', 'senlin/tests/unit/policies/test_policy.py', 'senlin/api/middleware/trust.py', 'senlin/policies/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py', 'senlin/tests/unit/api/middleware/test_trust.py', 'senlin/profiles/base.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/receivers/test_receiver.py', 'senlin/tests/unit/profiles/test_profile_base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3be51b20eaec0f6bab54eaca3f4aca2f205e4b81', 'message': 'Rename get_service_context to get_service_credentials\n\nThis rename is to avoid misunderstanding that the function is not\nreturning a RequestContext object.\n\nChange-Id: Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b\n'}]",0,433443,3be51b20eaec0f6bab54eaca3f4aca2f205e4b81,8,3,1,8246,,,0,"Rename get_service_context to get_service_credentials

This rename is to avoid misunderstanding that the function is not
returning a RequestContext object.

Change-Id: Iade09ca0e99c99c7d02a2cd01e22fe44c02da26b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/43/433443/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/middleware/webhook.py', 'senlin/engine/health_manager.py', 'senlin/tests/unit/policies/test_policy.py', 'senlin/api/middleware/trust.py', 'senlin/policies/base.py', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/common/context.py', 'senlin/tests/unit/api/middleware/test_trust.py', 'senlin/profiles/base.py', 'senlin/engine/receivers/base.py', 'senlin/tests/unit/engine/receivers/test_receiver.py', 'senlin/tests/unit/profiles/test_profile_base.py']",12,3be51b20eaec0f6bab54eaca3f4aca2f205e4b81,get-svc-ctx," @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_init(self, mock_creds): mock_creds.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_init_with_context(self, mock_creds): mock_creds.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_create(self, mock_creds): mock_creds.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test_create_failed_validation(self, mock_creds, mock_validate): mock_creds.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context_for_real(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_credentials') def test__init_context_for_real_with_data(self, mock_creds): mock_creds.return_value = fake_ctx mock_creds.assert_called_once_with(region_name='region_dist')"," @mock.patch.object(senlin_ctx, 'get_service_context') def test_init(self, mock_ctx): mock_ctx.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_context') def test_init_with_context(self, mock_ctx): mock_ctx.return_value = {'foo': 'bar'} @mock.patch.object(senlin_ctx, 'get_service_context') def test_create(self, mock_context): mock_context.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_context') def test_create_failed_validation(self, mock_context, mock_validate): mock_context.return_value = {} @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context_for_real(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with() @mock.patch.object(senlin_ctx, 'get_service_context') def test__init_context_for_real_with_data(self, mock_get): mock_get.return_value = fake_ctx mock_get.assert_called_once_with(region_name='region_dist')",82,77
openstack%2Fsenlin~stable%2Focata~I5bbabf1f5be000000a960df1df0279992ab75683,openstack/senlin,stable/ocata,I5bbabf1f5be000000a960df1df0279992ab75683,Fix node show detail image id error,MERGED,2017-02-17 12:31:23.000000000,2017-02-17 14:10:38.000000000,2017-02-17 14:10:38.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 12:31:23.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9a36b10758e6d8fa515ecd4b782866ec8cc47c44', 'message': 'Fix node show detail image id error\n\nThis patch fix if image is not in server boot,Node detail\nreturn dict\n\nCloses-Bug:#1662053\n\nChange-Id: I5bbabf1f5be000000a960df1df0279992ab75683\n(cherry picked from commit fa6252d9d34d10548e6279c07325a2bc36a1eeba)\n'}]",0,435423,9a36b10758e6d8fa515ecd4b782866ec8cc47c44,6,2,1,8246,,,0,"Fix node show detail image id error

This patch fix if image is not in server boot,Node detail
return dict

Closes-Bug:#1662053

Change-Id: I5bbabf1f5be000000a960df1df0279992ab75683
(cherry picked from commit fa6252d9d34d10548e6279c07325a2bc36a1eeba)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/23/435423/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py']",2,9a36b10758e6d8fa515ecd4b782866ec8cc47c44,bug/1662053," def test_do_get_details_image_no_id_key(self): cc = mock.Mock() profile = server.ServerProfile('t', self.spec) profile._computeclient = cc node_obj = mock.Mock(physical_id='FAKE_ID') # Test normal path nova_server = mock.Mock() nova_server.to_dict.return_value = { 'addresses': { 'private': [{ 'version': 4, 'addr': '10.0.0.3', }] }, 'flavor': { 'id': 'FAKE_FLAVOR', }, 'id': 'FAKE_ID', 'image': {}, 'security_groups': [{'name': 'default'}], } cc.server_get.return_value = nova_server res = profile.do_get_details(node_obj) expected = { 'flavor': 'FAKE_FLAVOR', 'id': 'FAKE_ID', 'image': {}, 'addresses': { 'private': [{ 'version': 4, 'addr': '10.0.0.3', }] }, 'security_groups': 'default', } self.assertEqual(expected, res) cc.server_get.assert_called_once_with('FAKE_ID') ",,44,1
openstack%2Fnova-powervm~master~Icd3e806dcd02a9c89270e24a245eec862f319321,openstack/nova-powervm,master,Icd3e806dcd02a9c89270e24a245eec862f319321,Add imagecache information to devref,MERGED,2017-02-15 15:55:33.000000000,2017-02-17 14:07:29.000000000,2017-02-17 14:07:29.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 13883}, {'_account_id': 16128}]","[{'number': 1, 'created': '2017-02-15 15:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b0194ea5d350371f2e1da1f969b0f74aba68c1e3', 'message': 'Add imagecache information to devref\n\nMention the fact that images will be cached on the volume group.\n\nChange-Id: Icd3e806dcd02a9c89270e24a245eec862f319321\n'}, {'number': 2, 'created': '2017-02-16 16:54:56.000000000', 'files': ['doc/source/devref/project_structure.rst'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/b27ce8e2873187a451ab9969177e0d2200ae7b10', 'message': 'Add imagecache information to devref\n\nMention the fact that images will be cached on the same VG as VMs,\nand that the image_cache_manager_interval setting is used to\nperiodically remove cached images.\n\nChange-Id: Icd3e806dcd02a9c89270e24a245eec862f319321\n'}]",2,434358,b27ce8e2873187a451ab9969177e0d2200ae7b10,16,4,2,21099,,,0,"Add imagecache information to devref

Mention the fact that images will be cached on the same VG as VMs,
and that the image_cache_manager_interval setting is used to
periodically remove cached images.

Change-Id: Icd3e806dcd02a9c89270e24a245eec862f319321
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/58/434358/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/project_structure.rst'],1,b0194ea5d350371f2e1da1f969b0f74aba68c1e3,doc/imagecache," physical disks local to their system. Images will be cached on the volume group until the Nova imagecache manager is run, determined by the ``nova.conf`` setting: image_cache_manager_interval.", physical disks local to their system.,3,1
openstack%2Ffuel-library~master~Ie98af501c1cd130098381a8463452f892898470b,openstack/fuel-library,master,Ie98af501c1cd130098381a8463452f892898470b,Handle the InnoDB restore phase as part of SST,MERGED,2017-02-17 10:27:36.000000000,2017-02-17 14:06:58.000000000,2017-02-17 14:03:37.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 20656}, {'_account_id': 24418}]","[{'number': 1, 'created': '2017-02-17 10:27:36.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7f81f3aea2412ee703c8d20894b731859b0e5243', 'message': 'Handle the InnoDB restore phase as part of SST\n\nPreviously, the backup restoration phase was not considered part of the\nState Snapshot Transfer, as only the backup creation and transportation\nprocesses are checked for this purpose. To cover the missing phase as\nwell, it is more reasonable to monitor the appropriate process that\ncontrols the entire State Snapshot Transfer.\n\nCloses-Bug: 1660275\n\nChange-Id: Ie98af501c1cd130098381a8463452f892898470b\nSigned-off-by: Gabor Orosz <gabor.orosz@ericsson.com>\n'}]",0,435352,7f81f3aea2412ee703c8d20894b731859b0e5243,34,5,1,8786,,,0,"Handle the InnoDB restore phase as part of SST

Previously, the backup restoration phase was not considered part of the
State Snapshot Transfer, as only the backup creation and transportation
processes are checked for this purpose. To cover the missing phase as
well, it is more reasonable to monitor the appropriate process that
controls the entire State Snapshot Transfer.

Closes-Bug: 1660275

Change-Id: Ie98af501c1cd130098381a8463452f892898470b
Signed-off-by: Gabor Orosz <gabor.orosz@ericsson.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/435352/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,7f81f3aea2412ee703c8d20894b731859b0e5243,," # Match a MySQLd pid by the datadir, exclude position recovery local pid=$(ps -C mysqld -o pid= -o command= -o args= | grep ""${OCF_RESKEY_datadir}"" | \ # MySQLd's running and may be blocked, check for signs of SST local wsrep_sst_method=$(awk '/^wsrep_sst_method/ {print $3}' ${OCF_RESKEY_config}) local wsrep_sst_command=""wsrep_sst_${wsrep_sst_method}"" local wsrep_sst_pid=$(ps -C ${wsrep_sst_command} -o pid= -o command= | \ awk '!/defunct/ {print $1}' | head -1) if [ ""${wsrep_sst_pid}"" ]; then","OCF_RESKEY_streamfmt_default=""xbstream"" OCF_RESKEY_transferfmt_default=""socat"": ${OCF_RESKEY_streamfmt=${OCF_RESKEY_streamfmt_default}} : ${OCF_RESKEY_transferfmt=${OCF_RESKEY_transferfmt_default}} <parameter name=""streamfmt"" unique=""0"" required=""0""> <longdesc lang=""en""> The streamfmt setting for xtrabackup-v2 SST config </longdesc> <shortdesc lang=""en"">SST streamfmt</shortdesc> <content type=""string"" default=""${OCF_RESKEY_streamfmt_default}""/> </parameter> <parameter name=""transferfmt"" unique=""0"" required=""0""> <longdesc lang=""en""> The transferfmt setting for xtrabackup-v2 SST config </longdesc> <shortdesc lang=""en"">SST transferfmt</shortdesc> <content type=""string"" default=""${OCF_RESKEY_transferfmt_default}""/> </parameter> local pid local pid2 local pid3 local pid4 # Match a mysqld pid by the datadir, exclude position recovery pid=$(ps -C mysqld -o pid= -o command= -o args= | grep ""${OCF_RESKEY_datadir}"" | \ # Myslqd's running and may be blocked, check for signs of SST pid2=$(ps -C ${OCF_RESKEY_streamfmt} -o pid= -o command= | awk '!/defunct/ {print $1}') pid3=$(ps -C ${OCF_RESKEY_transferfmt} -o pid= -o command= | awk '!/defunct/ {print $1}') pid4=$(ps -C innobackupex -o pid= -o command= | awk '!/defunct/ {print $1}') if [ ""${pid2}"" -o ""${pid3}"" -o ""${pid4}"" ]; then",8,29
openstack%2Fopenstack-ansible-os_swift~master~Ib78ac0a8891874b1c2e777fac8f3fb89304e6872,openstack/openstack-ansible-os_swift,master,Ib78ac0a8891874b1c2e777fac8f3fb89304e6872,Move away from include statsd.j2,MERGED,2017-02-13 15:07:48.000000000,2017-02-17 13:56:39.000000000,2017-02-14 17:33:05.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2017-02-13 15:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/bba7aad4ce3a29763e28b81c8b0cde5d7eade3dc', 'message': ""Move away from include statsd.j2\n\nThe statsd.j2 include approach is great, but it is hitting an ansible\nbug with Jinja2==2.9.5 which hasn't been fixed with Ansible and doens't\nseem to be fixed anytime soon.\n\nHere is an example bug:\nhttps://github.com/ansible/ansible/issues/20494\n\nChange-Id: Ib78ac0a8891874b1c2e777fac8f3fb89304e6872\n""}, {'number': 2, 'created': '2017-02-13 15:40:03.000000000', 'files': ['templates/object-server-replicator.conf.j2', 'tasks/main.yml', 'templates/container-server-replicator.conf.j2', 'templates/object-expirer.conf.j2', 'templates/account-server-replicator.conf.j2', 'templates/account-server.conf.j2', 'templates/proxy-server.conf.j2', 'templates/container-reconciler.conf.j2', 'templates/statsd.j2', 'templates/object-server.conf.j2', 'templates/container-server.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/352969e2d11d80b74485664737a5c0c49b87b14d', 'message': ""Move away from include statsd.j2\n\nThe statsd.j2 include approach is great, but it is hitting an ansible\nbug with Jinja2==2.9.5 which hasn't been fixed with Ansible and doens't\nseem to be fixed anytime soon.\n\nHere is an example bug:\nhttps://github.com/ansible/ansible/issues/20494\n\nThis patch also refactors the statsd.j2 import parts, a lot of\nif/else statements were not required.\n\nChange-Id: Ib78ac0a8891874b1c2e777fac8f3fb89304e6872\n""}]",0,433107,352969e2d11d80b74485664737a5c0c49b87b14d,12,3,2,2799,,,0,"Move away from include statsd.j2

The statsd.j2 include approach is great, but it is hitting an ansible
bug with Jinja2==2.9.5 which hasn't been fixed with Ansible and doens't
seem to be fixed anytime soon.

Here is an example bug:
https://github.com/ansible/ansible/issues/20494

This patch also refactors the statsd.j2 import parts, a lot of
if/else statements were not required.

Change-Id: Ib78ac0a8891874b1c2e777fac8f3fb89304e6872
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/07/433107/1 && git format-patch -1 --stdout FETCH_HEAD,"['templates/object-server-replicator.conf.j2', 'templates/container-server-replicator.conf.j2', 'templates/object-expirer.conf.j2', 'templates/account-server-replicator.conf.j2', 'templates/account-server.conf.j2', 'templates/container-reconciler.conf.j2', 'templates/statsd.j2', 'templates/object-server.conf.j2', 'templates/container-server.conf.j2']",9,bba7aad4ce3a29763e28b81c8b0cde5d7eade3dc,include_fix, {% if swift_vars is defined %} {% if swift_vars.statsd_host is defined %} {% set statsd = 1 %} log_statsd_host = {{ swift_vars.statsd_host | default(statsd_host) }} {% elif swift.statsd_host is defined %} {% set statsd =1 %} log_statsd_host = {{ swift.statsd_host | default(statsd_host) }} {% endif %} {% if statsd is defined %} {% if swift_vars.statsd_port is defined %} log_statsd_port = {{ swift_vars.statsd_port }} {% else %} log_statsd_port = {{ swift.statsd_port | default(statsd_port) }} {% endif %} {% if swift_vars.statsd_default_sample_rate is defined %} log_statsd_default_sample_rate = {{ swift_vars.statsd_default_sample_rate }} {% else %} log_statsd_default_sample_rate = {{ swift.statsd_default_sample_rate | default(statsd_default_sample_rate) }} {% endif %} {% if swift_vars.statsd_sample_rate_factor is defined %} log_statsd_sample_rate_factor = {{ swift_vars.statsd_sample_rate_factor }} {% else %} log_statsd_sample_rate_factor = {{ swift.statsd_sample_rate_factor | default(statsd_sample_rate_factor) }} {% endif %} {% if swift_vars.statsd_metric_prefix is defined %} log_statsd_metric_prefix = {{ swift_vars.statsd_metric_prefix }} {% else %} log_statsd_metric_prefix = {{ swift.statsd_metric_prefix | default(inventory_hostname) }} {% endif %} {% endif %} {% endif %},"{% include ""statsd.j2"" %}",256,40
openstack%2Fsenlin~stable%2Focata~Id9320f809ac7aee9afd2c47dc325d345ff9e7dd1,openstack/senlin,stable/ocata,Id9320f809ac7aee9afd2c47dc325d345ff9e7dd1,Add db purge in senlin manage,MERGED,2017-02-17 12:30:51.000000000,2017-02-17 13:54:41.000000000,2017-02-17 13:54:41.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 12:30:51.000000000', 'files': ['senlin/tests/unit/db/test_event_api.py', 'senlin/db/api.py', 'senlin/cmd/manage.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9de60c48c1f38fa64bd62b4c01c102736c9ac6ab', 'message': 'Add db purge in senlin manage\n\nThis patch adds db purge in senlin-manage for deleting events.\n\nblueprint: db-purge-for-deleting-events\nhttps://blueprints.launchpad.net/senlin/+spec/db-purge-for-deleting-events\n\nChange-Id: Id9320f809ac7aee9afd2c47dc325d345ff9e7dd1\n(cherry picked from commit 720e13f0ed50513e25305bf6570b21ff91cb7d23)\n'}]",0,435421,9de60c48c1f38fa64bd62b4c01c102736c9ac6ab,6,2,1,8246,,,0,"Add db purge in senlin manage

This patch adds db purge in senlin-manage for deleting events.

blueprint: db-purge-for-deleting-events
https://blueprints.launchpad.net/senlin/+spec/db-purge-for-deleting-events

Change-Id: Id9320f809ac7aee9afd2c47dc325d345ff9e7dd1
(cherry picked from commit 720e13f0ed50513e25305bf6570b21ff91cb7d23)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/21/435421/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/db/test_event_api.py', 'senlin/cmd/manage.py', 'senlin/db/api.py', 'senlin/db/sqlalchemy/api.py']",4,9de60c48c1f38fa64bd62b4c01c102736c9ac6ab,bp/db-purge-for-deleting-events,"import datetimedef event_purge(project, granularity='days', age=30): with session_for_write() as session: query = session.query(models.Event).with_for_update() if project is not None: query = query.filter(models.Event.project.in_(project)) if granularity is not None and age is not None: if granularity == 'days': age = age * 86400 elif granularity == 'hours': age = age * 3600 elif granularity == 'minutes': age = age * 60 time_line = timeutils.utcnow() - datetime.timedelta(seconds=age) query = query.filter(models.Event.timestamp < time_line) return query.delete(synchronize_session='fetch') ",,84,0
openstack%2Ffuel-library~stable%2Fnewton~Ifbac52e0e28db073d8773c9ff49019f480641385,openstack/fuel-library,stable/newton,Ifbac52e0e28db073d8773c9ff49019f480641385,Safely get the ceph tuning settings,MERGED,2017-02-07 07:28:25.000000000,2017-02-17 13:52:50.000000000,2017-02-17 13:49:27.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 20656}, {'_account_id': 22328}]","[{'number': 1, 'created': '2017-02-07 07:28:25.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/378528c9d6201a0c8fd7598d4ceaef5b13028652', 'message': ""Safely get the ceph tuning settings\n\nAvoid case when storage data ain't changed\nthat triggers calculating a non-existent key.\n\nChange-Id: Ifbac52e0e28db073d8773c9ff49019f480641385\nCloses-Bug: #1658699\n(cherry picked from commit 57a64b40327fd9f27ea7288eced8f764a5f2b70c)\n""}]",0,430105,378528c9d6201a0c8fd7598d4ceaef5b13028652,33,7,1,16771,,,0,"Safely get the ceph tuning settings

Avoid case when storage data ain't changed
that triggers calculating a non-existent key.

Change-Id: Ifbac52e0e28db073d8773c9ff49019f480641385
Closes-Bug: #1658699
(cherry picked from commit 57a64b40327fd9f27ea7288eced8f764a5f2b70c)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/05/430105/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml'],1,378528c9d6201a0c8fd7598d4ceaef5b13028652,ceph_tuning_settings," changedAny($.storage, $.get('ceph_tuning_settings'), $.get('use_ssl'),"," changedAny($.storage, $.ceph_tuning_settings, $.get('use_ssl'),",1,1
openstack%2Fkolla-kubernetes~master~I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd,openstack/kolla-kubernetes,master,I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd,Helm Ceph Initial Mon,MERGED,2016-12-14 09:41:06.000000000,2017-02-17 13:45:44.000000000,2017-02-17 13:45:44.000000000,"[{'_account_id': 3}, {'_account_id': 9237}, {'_account_id': 11869}, {'_account_id': 17591}, {'_account_id': 19384}, {'_account_id': 19741}, {'_account_id': 22582}, {'_account_id': 23928}]","[{'number': 1, 'created': '2016-12-14 09:41:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/9d7e767ba8b7d596249249f1dab2609b038862c1', 'message': 'Helm Ceph Initial Mon\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 2, 'created': '2016-12-14 09:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/68054e27a0b87918bb56f40a50fd75674343562a', 'message': 'Helm Ceph Initial Mon\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 3, 'created': '2016-12-14 09:59:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/91d64bb2822a4a49d40222e839825e6c64155086', 'message': 'Helm Ceph Initial Mon\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 4, 'created': '2016-12-14 10:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/1205d8a876231ac8d796a3a53fb319c3cb77e6a7', 'message': 'Helm Ceph Initial Mon\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 5, 'created': '2016-12-30 07:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/b9fa3a8869fe55c804b1f670202bcb47987dc8a2', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 6, 'created': '2016-12-30 07:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/3706c63ac44751cb80a409002c08b31d80696b98', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 7, 'created': '2017-01-04 04:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/2178c7c4e34f8e7f431857f0dd2d0e06cb36a069', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 8, 'created': '2017-01-13 06:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/4d553cd4ac38f86121246ca81f88e994d3d23393', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 9, 'created': '2017-01-16 02:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/d811fc822ea0e762c1a41300838bd83823c2eb53', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 10, 'created': '2017-02-14 15:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/a4b18bd274078ab2976f4e1db5cfd04999df63cc', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 11, 'created': '2017-02-14 17:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/7b4d5079f75b9dfe6f11918d672fbe6786a21f3e', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 12, 'created': '2017-02-14 17:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/4e7575fbdd6dd79719ead182607ad28ce77f522d', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 13, 'created': '2017-02-14 17:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/355a7f45512bdc17d8f4d7ede740c8c1146d880a', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 14, 'created': '2017-02-14 18:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/18ec9af27500566ec8e80c3f6777731762e35bbf', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 15, 'created': '2017-02-14 18:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/63fd0ebb80da10412829f90b817b44ef169f25d9', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 16, 'created': '2017-02-14 18:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/04c41bbf4fb572cb32d5531bcd671050b363cf1f', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 17, 'created': '2017-02-14 19:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/108727710c87dfe6b3210b60ab2d13cf2df4badc', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 18, 'created': '2017-02-14 20:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/a591952b81da03e6d1eeacd0208d2c1941f7099e', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 19, 'created': '2017-02-14 20:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/f470a45805558f230fa8bef161a6c3cb052036b2', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 20, 'created': '2017-02-15 00:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/40a725ab934bc5815349f4f5be7f091856bb0b98', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 21, 'created': '2017-02-15 01:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/447224a878421d0ddb156d41e3eec9906cb6e37e', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 22, 'created': '2017-02-15 01:46:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/600f9460e842b4c9c372ae5b536221a2aa453e83', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 23, 'created': '2017-02-16 00:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/6748094002f85f276caf8df804e63a1101908403', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}, {'number': 24, 'created': '2017-02-16 00:23:26.000000000', 'files': ['tools/setup_gate_ceph.sh', 'helm/microservice/test-ceph-init-mon-job/templates/test_ceph_init_mon_job.yaml', 'helm/all_values.yaml', 'helm/microservice/test-ceph-init-mon-job/Chart.yaml', 'tests/bin/build_test_ceph.sh', 'tools/setup-ceph-secrets.sh'], 'web_link': 'https://opendev.org/openstack/kolla-kubernetes/commit/4e22b97466f569c15ceb905f600858e9487a9030', 'message': 'Helm Ceph Initial Mon\n\nCo-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>\n\nChange-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd\nPartially-Implements: blueprint helm-microservices\n'}]",12,410641,4e22b97466f569c15ceb905f600858e9487a9030,63,8,24,23928,,,0,"Helm Ceph Initial Mon

Co-Authored-By: Duong Ha-Quang <duonghq@vn.fujitsu.com>

Change-Id: I6bc9b38b2c6bfde625265bc5cc5c88c084c9afcd
Partially-Implements: blueprint helm-microservices
",git fetch https://review.opendev.org/openstack/kolla-kubernetes refs/changes/41/410641/24 && git format-patch -1 --stdout FETCH_HEAD,"['helm/microservice/ceph-initial-mon/templates/ceph_initial_mon.yaml', 'helm/all_values.yaml', 'helm/microservice/ceph-initial-mon/Chart.yaml', 'tests/bin/build_test_ceph.sh']",4,9d7e767ba8b7d596249249f1dab2609b038862c1,bp/helm-microservices,"kollakube template bootstrap ceph-bootstrap-initial-mon helm install kolla/ceph-initial-mon --version 3.0.0-1 \ --namespace kolla \ --name ceph-initial-mon \ --set ""node=$(hostname -s)"" --debug",kollakube res create bootstrap ceph-bootstrap-initial-mon,108,1
openstack%2Ffuel-agent~master~I05e0b33420058772216220bb9fcd5f61c40f3e27,openstack/fuel-agent,master,I05e0b33420058772216220bb9fcd5f61c40f3e27,Add rsync dependency for fuel-agent,MERGED,2017-02-16 09:38:32.000000000,2017-02-17 13:42:36.000000000,2017-02-17 12:47:17.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 18455}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-16 09:38:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/4129caec3c3af07c002b93919b32f93618e09fcb', 'message': 'Add rsync dependsy for fuel-agent\n\nChange-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27\nCo-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>\nPartial-Bug: 1664152\n'}, {'number': 2, 'created': '2017-02-16 09:39:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/7f74c30880fe2844b847b429f717d36c9ea2f8ea', 'message': 'Add rsync dependency for fuel-agent\n\nChange-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27\nCo-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>\nPartial-Bug: 1664152\n'}, {'number': 3, 'created': '2017-02-16 09:45:01.000000000', 'files': ['specs/fuel-agent.spec', 'debian/control'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/9f40d27bbecbee5ddf55fb69a2fb4cadf205ce25', 'message': 'Add rsync dependency for fuel-agent\n\nChange-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27\nCo-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>\nPartial-Bug: 1664152\n'}]",0,434770,9f40d27bbecbee5ddf55fb69a2fb4cadf205ce25,39,6,3,10288,,,0,"Add rsync dependency for fuel-agent

Change-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27
Co-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>
Partial-Bug: 1664152
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/70/434770/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/fuel-agent.spec', 'debian/control']",2,4129caec3c3af07c002b93919b32f93618e09fcb,bug/1664152," rsync,",,2,0
openstack%2Ffuel-library~stable%2Fmitaka~I200673d68c49e5ce59f24718c6d131fb5a04b74c,openstack/fuel-library,stable/mitaka,I200673d68c49e5ce59f24718c6d131fb5a04b74c,"Accept ""ip link"" changed output format",MERGED,2017-01-23 15:30:54.000000000,2017-02-17 13:41:06.000000000,2017-02-17 13:37:41.000000000,"[{'_account_id': 3}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 13344}, {'_account_id': 14610}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18795}, {'_account_id': 20517}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-01-23 15:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d79c95464cf9ecdc99577441b6fd179b6f86ef51', 'message': 'Accept ""ip link"" changed output format\n\nNow ""ip link"" has ""@""-signes in 2nd columnt,\nhere are outputs:\nroot@14.04:~# ip link | grep vr-host-base\n17: vr-host-base: <BROADCAST,MULTI...\nroot@16.04:~# ip link | grep vr-host-base\n1708: vr-host-base@if1707: <BROADCAST,MULTI...\n\nCloses-bug: #1581058\n\nChange-Id: I200673d68c49e5ce59f24718c6d131fb5a04b74c\n(cherry picked from commit 88f90b85280aff91b593f39da32bb6daf779fa4b)\n'}, {'number': 2, 'created': '2017-02-07 15:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ed75c58978443d26cf391b212b09cc7e50a5bce7', 'message': 'Accept ""ip link"" changed output format\n\nNow ""ip link"" has ""@""-signes in 2nd columnt,\nhere are outputs:\nroot@14.04:~# ip link | grep vr-host-base\n17: vr-host-base: <BROADCAST,MULTI...\nroot@16.04:~# ip link | grep vr-host-base\n1708: vr-host-base@if1707: <BROADCAST,MULTI...\n\nCloses-bug: #1581058\n\nChange-Id: I200673d68c49e5ce59f24718c6d131fb5a04b74c\n(cherry picked from commit 88f90b85280aff91b593f39da32bb6daf779fa4b)\n'}, {'number': 3, 'created': '2017-02-08 15:01:32.000000000', 'files': ['files/fuel-ha-utils/ocf/ns_haproxy', 'files/fuel-ha-utils/ocf/ns_vrouter'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/93613247a21a6afcda6e627b44625d91859c5fd5', 'message': 'Accept ""ip link"" changed output format\n\nNow ""ip link"" has ""@""-signes in 2nd columnt,\nhere are outputs:\nroot@14.04:~# ip link | grep vr-host-base\n17: vr-host-base: <BROADCAST,MULTI...\nroot@16.04:~# ip link | grep vr-host-base\n1708: vr-host-base@if1707: <BROADCAST,MULTI...\n\nCloses-bug: #1581058\n\nChange-Id: I200673d68c49e5ce59f24718c6d131fb5a04b74c\n(cherry picked from commit 88f90b85280aff91b593f39da32bb6daf779fa4b)\n'}]",0,424196,93613247a21a6afcda6e627b44625d91859c5fd5,91,12,3,13344,,,0,"Accept ""ip link"" changed output format

Now ""ip link"" has ""@""-signes in 2nd columnt,
here are outputs:
root@14.04:~# ip link | grep vr-host-base
17: vr-host-base: <BROADCAST,MULTI...
root@16.04:~# ip link | grep vr-host-base
1708: vr-host-base@if1707: <BROADCAST,MULTI...

Closes-bug: #1581058

Change-Id: I200673d68c49e5ce59f24718c6d131fb5a04b74c
(cherry picked from commit 88f90b85280aff91b593f39da32bb6daf779fa4b)
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/96/424196/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/fuel-ha-utils/ocf/ns_haproxy', 'files/fuel-ha-utils/ocf/ns_vrouter']",2,d79c95464cf9ecdc99577441b6fd179b6f86ef51,," ip link | grep -q '^[[:digit:]]\+:[[:space:]]\+'""${OCF_RESKEY_host_interface}""'[@:]' ip link | grep -q '^[[:digit:]]\+:[[:space:]]\+'""${OCF_RESKEY_namespace_interface}""'[@:]'"," ip link | grep -q ""${OCF_RESKEY_host_interface}:"" ip link | grep -q ""${OCF_RESKEY_namespace_interface}:""",4,4
openstack%2Fcharm-ceph-mon~master~I44378d301c68f8ee771bdd0ba0c67c559c1b9200,openstack/charm-ceph-mon,master,I44378d301c68f8ee771bdd0ba0c67c559c1b9200,Remove old revision file,MERGED,2017-02-01 18:18:57.000000000,2017-02-17 13:39:35.000000000,2017-02-17 13:39:34.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-01 18:18:57.000000000', 'files': ['revision'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/e9c52674de570a083a913ee2932f8980a1002aaa', 'message': 'Remove old revision file\n\nThis file is likely an artifact of old charm store\nrevision tracking and should not be in the code\ntree.\n\nChange-Id: I44378d301c68f8ee771bdd0ba0c67c559c1b9200\n'}]",0,427845,e9c52674de570a083a913ee2932f8980a1002aaa,11,3,1,20635,,,0,"Remove old revision file

This file is likely an artifact of old charm store
revision tracking and should not be in the code
tree.

Change-Id: I44378d301c68f8ee771bdd0ba0c67c559c1b9200
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/45/427845/1 && git format-patch -1 --stdout FETCH_HEAD,['revision'],1,e9c52674de570a083a913ee2932f8980a1002aaa,cleanup,,105,0,1
openstack%2Fcharm-ceph-radosgw~master~I5bb974064f0980a3f599eae3e2ba86b405f917ac,openstack/charm-ceph-radosgw,master,I5bb974064f0980a3f599eae3e2ba86b405f917ac,Add Keystone v3 support,MERGED,2017-02-07 11:14:57.000000000,2017-02-17 13:34:50.000000000,2017-02-17 13:34:50.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-07 11:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/e28a7ded73b288d591a025a175ece8b8aaae7e5a', 'message': 'Add Keystone v3 support\n\nCloses-Bug: 1585708\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\n'}, {'number': 2, 'created': '2017-02-07 12:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/005b685fc8dbafe7f80f6a94608babf79ed065b3', 'message': 'Add Keystone v3 support\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}, {'number': 3, 'created': '2017-02-07 13:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/3187e49c51bcaee3f68a0b43a3c55d8ac3c6da76', 'message': 'Add Keystone v3 support\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}, {'number': 4, 'created': '2017-02-11 12:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/0432eca178c0273f2708883f0ca2557866e00d01', 'message': 'Add Keystone v3 support\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}, {'number': 5, 'created': '2017-02-14 08:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/0901fcac644b268f8555f77fdc8c279d5b730360', 'message': 'Add Keystone v3 support\n\nSync charm-helpers\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}, {'number': 6, 'created': '2017-02-14 11:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/64b8097d8817e3dda9c4242d57d47334dcbc6c38', 'message': 'Add Keystone v3 support\n\nSync charm-helpers\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}, {'number': 7, 'created': '2017-02-15 10:00:13.000000000', 'files': ['unit_tests/test_ceph_radosgw_context.py', 'hooks/ceph_radosgw_context.py', 'tests/basic_deployment.py', 'templates/ceph.conf'], 'web_link': 'https://opendev.org/openstack/charm-ceph-radosgw/commit/7fa6639ab3fde7dc89131fb204f018fd4339e82f', 'message': 'Add Keystone v3 support\n\nChange-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac\nCloses-Bug: 1585708\n'}]",0,430203,7fa6639ab3fde7dc89131fb204f018fd4339e82f,49,4,7,13686,,,0,"Add Keystone v3 support

Change-Id: I5bb974064f0980a3f599eae3e2ba86b405f917ac
Closes-Bug: 1585708
",git fetch https://review.opendev.org/openstack/charm-ceph-radosgw refs/changes/03/430203/5 && git format-patch -1 --stdout FETCH_HEAD,['templates/ceph.conf'],1,e28a7ded73b288d591a025a175ece8b8aaae7e5a,bug/1585708,{% if api_version == '3' -%} rgw keystone api version = 3 rgw keystone admin user = {{ admin_user }} rgw keystone admin password = {{ admin_password }} rgw keystone admin domain = {{ admin_domain_name }} rgw keystone admin project = {{ admin_tenant_name }} {% else -%}{% endif -%},,8,0
openstack%2Fcharm-aodh~master~I3e288e3011c730c4c69aa8a0441b75fd0d665861,openstack/charm-aodh,master,I3e288e3011c730c4c69aa8a0441b75fd0d665861,Remove support for py34,ABANDONED,2017-02-08 07:58:48.000000000,2017-02-17 13:31:37.000000000,,"[{'_account_id': 3}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 25173}]","[{'number': 1, 'created': '2017-02-08 07:58:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-aodh/commit/a1374b0d8bfc372daf4841ef7436bcfdaaf44f64', 'message': 'Remove support for py34\n\nThe gating on python 3.4 is restricted to <= Mitaka. This is due\nto the change from Ubuntu Trusty to Xenial, where only python3.5\nis available. There is no need to continue to keep these settings.\n\nChange-Id: I3e288e3011c730c4c69aa8a0441b75fd0d665861\n'}]",0,430623,a1374b0d8bfc372daf4841ef7436bcfdaaf44f64,6,4,1,22484,,,0,"Remove support for py34

The gating on python 3.4 is restricted to <= Mitaka. This is due
to the change from Ubuntu Trusty to Xenial, where only python3.5
is available. There is no need to continue to keep these settings.

Change-Id: I3e288e3011c730c4c69aa8a0441b75fd0d665861
",git fetch https://review.opendev.org/openstack/charm-aodh refs/changes/23/430623/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a1374b0d8bfc372daf4841ef7436bcfdaaf44f64,bug/gengchc,"envlist = pep8,py35","envlist = pep8,py34,py35",1,1
openstack%2Fcharm-trove~master~I8f1896d8eb1f820a4349e600aa92e27134bf5654,openstack/charm-trove,master,I8f1896d8eb1f820a4349e600aa92e27134bf5654,Enable newton and ocata amulet tests,ABANDONED,2017-02-10 21:37:23.000000000,2017-02-17 13:31:09.000000000,,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-10 21:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-trove/commit/cf7d79f71268157a13a8ec27e30b54c59128119a', 'message': 'Enable newton and ocata amulet tests\n\nChange-Id: I8f1896d8eb1f820a4349e600aa92e27134bf5654\n'}, {'number': 2, 'created': '2017-02-13 09:59:52.000000000', 'files': ['src/tests/gate-basic-xenial-newton', 'src/tests/gate-basic-xenial-ocata'], 'web_link': 'https://opendev.org/openstack/charm-trove/commit/aa30d3a594bd50d0b2c609c170725338ba375daf', 'message': 'Enable newton and ocata amulet tests\n\nChange-Id: I8f1896d8eb1f820a4349e600aa92e27134bf5654\n'}]",0,432466,aa30d3a594bd50d0b2c609c170725338ba375daf,11,3,2,935,,,0,"Enable newton and ocata amulet tests

Change-Id: I8f1896d8eb1f820a4349e600aa92e27134bf5654
",git fetch https://review.opendev.org/openstack/charm-trove refs/changes/66/432466/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/gate-basic-xenial-newton', 'src/tests/gate-basic-xenial-ocata']",2,cf7d79f71268157a13a8ec27e30b54c59128119a,enable-ocata,"#!/usr/bin/env python # Copyright 2016 TransCirrus Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic Trove deployment on trusty-mitaka."""""" from basic_deployment import TroveBasicDeployment if __name__ == '__main__': deployment = TroveBasicDeployment(series='xenial', openstack_origin='cloud:xenial-ocata') deployment.run_tests() ",,50,0
openstack%2Fcharm-ceph~master~I0b5a9d3db94a43f60e785c3c2cb73a7ed84e208b,openstack/charm-ceph,master,I0b5a9d3db94a43f60e785c3c2cb73a7ed84e208b,Fix parse_key,MERGED,2017-02-16 19:49:42.000000000,2017-02-17 13:30:54.000000000,2017-02-17 13:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-16 19:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/75021414277a3eba4f5167a54d96f1273a8afaa7', 'message': 'Fix parse_key\n\nparse_key returns incorrect data when the cephx key\ncontains [caps]\n\nFixes-Bug: 1665149\nChange-Id: I0b5a9d3db94a43f60e785c3c2cb73a7ed84e208b\n'}, {'number': 2, 'created': '2017-02-17 11:17:56.000000000', 'files': ['lib/ceph/__init__.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph/commit/ea87ae4feb2dd673c979b8610848efcd6dd33cfa', 'message': 'Fix parse_key\n\nparse_key returns incorrect data when the cephx key\ncontains [caps].\n\nCloses-Bug: 1665149\nChange-Id: I0b5a9d3db94a43f60e785c3c2cb73a7ed84e208b\n'}]",0,435084,ea87ae4feb2dd673c979b8610848efcd6dd33cfa,13,4,2,20812,,,0,"Fix parse_key

parse_key returns incorrect data when the cephx key
contains [caps].

Closes-Bug: 1665149
Change-Id: I0b5a9d3db94a43f60e785c3c2cb73a7ed84e208b
",git fetch https://review.opendev.org/openstack/charm-ceph refs/changes/84/435084/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/__init__.py'],1,75021414277a3eba4f5167a54d96f1273a8afaa7,bug/1665149, return element.split(' = ')[1].strip() # IGNORE:E1103, key = element.split(' = ')[1].strip() # IGNORE:E1103,1,1
openstack%2Fcharm-manila-generic~master~Id5e909ae352d73239354002abc62e9491c9a42b7,openstack/charm-manila-generic,master,Id5e909ae352d73239354002abc62e9491c9a42b7,Update manila-generic configuration charm for updated plugin i/f,MERGED,2017-02-03 17:56:00.000000000,2017-02-17 13:29:59.000000000,2017-02-17 13:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20648}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-02-03 17:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/154e9665c2d9b0f34169986c107abe7153ac2815', 'message': 'Update manila-generic configuration charm for updated plugin i/f\n\nThe manila-plugin interface has been changed to simplify how backend\nconfiguration charms can generate their config for the manila.conf file\nin the manila principal charm.  This change enables the use of a\ntemplate/Jinja2 templating which simplifies the charm.\n\nChange-Id: Id5e909ae352d73239354002abc62e9491c9a42b7\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}, {'number': 2, 'created': '2017-02-06 10:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/ea9e29d698348ca8864356b9782dc16db00e6a50', 'message': 'Update manila-generic configuration charm for updated plugin i/f\n\nThe manila-plugin interface has been changed to simplify how backend\nconfiguration charms can generate their config for the manila.conf file\nin the manila principal charm.  This change enables the use of a\ntemplate/Jinja2 templating which simplifies the charm.\n\nChange-Id: Id5e909ae352d73239354002abc62e9491c9a42b7\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}, {'number': 3, 'created': '2017-02-06 15:57:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/352944a6ad66369c90a886090ea8f0353b8791cb', 'message': 'Update manila-generic configuration charm for updated plugin i/f\n\nThe manila-plugin interface has been changed to simplify how backend\nconfiguration charms can generate their config for the manila.conf file\nin the manila principal charm.  This change enables the use of a\ntemplate/Jinja2 templating which simplifies the charm.\n\nChange-Id: Id5e909ae352d73239354002abc62e9491c9a42b7\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}, {'number': 4, 'created': '2017-02-17 10:34:44.000000000', 'files': ['src/lib/charm/openstack/manila_generic.py', 'src/tests/basic_deployment.py', 'unit_tests/test_lib_charm_openstack_manila_generic.py', 'src/templates/mitaka/manila.conf', 'unit_tests/test_manila_generic_handlers.py', 'src/reactive/manila_generic_handlers.py'], 'web_link': 'https://opendev.org/openstack/charm-manila-generic/commit/480f5051f0e941b7a7b3a059aa1a5336581d957b', 'message': 'Update manila-generic configuration charm for updated plugin i/f\n\nThe manila-plugin interface has been changed to simplify how backend\nconfiguration charms can generate their config for the manila.conf file\nin the manila principal charm.  This change enables the use of a\ntemplate/Jinja2 templating which simplifies the charm.\n\nChange-Id: Id5e909ae352d73239354002abc62e9491c9a42b7\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}]",0,428839,480f5051f0e941b7a7b3a059aa1a5336581d957b,25,4,4,20870,,,0,"Update manila-generic configuration charm for updated plugin i/f

The manila-plugin interface has been changed to simplify how backend
configuration charms can generate their config for the manila.conf file
in the manila principal charm.  This change enables the use of a
template/Jinja2 templating which simplifies the charm.

Change-Id: Id5e909ae352d73239354002abc62e9491c9a42b7
Depends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71
",git fetch https://review.opendev.org/openstack/charm-manila-generic refs/changes/39/428839/2 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/openstack/manila_generic.py', 'src/tests/basic_deployment.py', 'unit_tests/test_lib_charm_openstack_manila_generic.py', 'src/templates/mitaka/manila.conf', 'unit_tests/test_manila_generic_handlers.py', 'src/reactive/manila_generic_handlers.py']",6,154e9665c2d9b0f34169986c107abe7153ac2815,,"@charms.reactive.when('manila-plugin.changed') @charms.reactive.when_not('config.changed', 'update-status') manila_plugin.clear_changed()@charms.reactive.when_not('update-status')",@charms.reactive.when('manila-plugin.available') @charms.reactive.when_not('config.changed'),189,273
openstack%2Fcharm-designate~master~I9b9d1d9f54119e50d8804f3b535c7ad381f3308f,openstack/charm-designate,master,I9b9d1d9f54119e50d8804f3b535c7ad381f3308f,Use upper-constraints for tox envs,ABANDONED,2016-10-21 06:54:43.000000000,2017-02-17 13:29:56.000000000,,"[{'_account_id': 3}, {'_account_id': 20635}, {'_account_id': 20648}]","[{'number': 1, 'created': '2016-10-21 06:54:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-designate/commit/1fc2e656a57779e3d452104d5ef95a2d1d891f16', 'message': 'Use upper-constraints for tox envs\n\nPin tox environments to upper-constraints to avoid conflicts with\nlibrary releases.\n\nChange-Id: I9b9d1d9f54119e50d8804f3b535c7ad381f3308f\nCloses-Bug:#1628597\n'}]",0,389555,1fc2e656a57779e3d452104d5ef95a2d1d891f16,5,3,1,21204,,,0,"Use upper-constraints for tox envs

Pin tox environments to upper-constraints to avoid conflicts with
library releases.

Change-Id: I9b9d1d9f54119e50d8804f3b535c7ad381f3308f
Closes-Bug:#1628597
",git fetch https://review.opendev.org/openstack/charm-designate refs/changes/55/389555/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,1fc2e656a57779e3d452104d5ef95a2d1d891f16,bug/1628597, pip install -c{env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} -U {opts} {packages}, pip install {opts} {packages},1,1
openstack%2Fcharm-manila~master~I260ce1d1287a7127838198d5aefea64454de8d3c,openstack/charm-manila,master,I260ce1d1287a7127838198d5aefea64454de8d3c,Update manila to support new interface for configuration,MERGED,2017-02-03 17:48:55.000000000,2017-02-17 13:29:38.000000000,2017-02-17 13:29:38.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20870}]","[{'number': 1, 'created': '2017-02-03 17:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/9bec18c46ea12b5a23b44c6cc8cf3ba75774b24d', 'message': 'Update manila to support new interface for configuration\n\nThe manila-plugin interface is changed to make writing configuration\nplugin charms easier to write.  This updates the manila charm to support\nthat interface.\n\nChange-Id: I260ce1d1287a7127838198d5aefea64454de8d3c\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}, {'number': 2, 'created': '2017-02-06 10:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/be574e4f57b4d28c0d706ed48f4a4568bbebc358', 'message': 'Update manila to support new interface for configuration\n\nThe manila-plugin interface is changed to make writing configuration\nplugin charms easier to write.  This updates the manila charm to support\nthat interface.\n\nChange-Id: I260ce1d1287a7127838198d5aefea64454de8d3c\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}, {'number': 3, 'created': '2017-02-17 10:31:36.000000000', 'files': ['unit_tests/test_manila_handlers.py', 'src/tests/basic_deployment.py', 'src/reactive/manila_handlers.py', 'src/lib/charm/openstack/manila.py', 'unit_tests/test_lib_charm_openstack_manila.py'], 'web_link': 'https://opendev.org/openstack/charm-manila/commit/417a70eb01cf334a5012dc4f84034429eb57b1bc', 'message': 'Update manila to support new interface for configuration\n\nThe manila-plugin interface is changed to make writing configuration\nplugin charms easier to write.  This updates the manila charm to support\nthat interface.\n\nChange-Id: I260ce1d1287a7127838198d5aefea64454de8d3c\nDepends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71\n'}]",0,428833,417a70eb01cf334a5012dc4f84034429eb57b1bc,27,5,3,20870,,,0,"Update manila to support new interface for configuration

The manila-plugin interface is changed to make writing configuration
plugin charms easier to write.  This updates the manila charm to support
that interface.

Change-Id: I260ce1d1287a7127838198d5aefea64454de8d3c
Depends-On: I76866007e3c89bb16bc7985a692fbd8f3e136a71
",git fetch https://review.opendev.org/openstack/charm-manila refs/changes/33/428833/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_manila_handlers.py', 'src/tests/basic_deployment.py', 'src/reactive/manila_handlers.py', 'src/lib/charm/openstack/manila.py', 'unit_tests/test_lib_charm_openstack_manila.py']",5,9bec18c46ea12b5a23b44c6cc8cf3ba75774b24d,," 'other-end': { 'conf': ""conf-string"", 'conf2': ""conf2-string"", 'conf3': ""conf3-string"", self.assertEqual(c.config_lines_for('conf'), [""conf-string"", '']) self.assertEqual(c.config_lines_for('conf2'), [""conf2-string"", '']) self.assertEqual(c.config_lines_for('conf3'), [""conf3-string"", ''])"," 'conf': { 'complete': True, '[section1]': ( 'line1', 'line2'), '[section2]': ( 'line3', ), }, 'conf2': { 'complete': True, '[section3]': ( 'line4', 'line5'), }, 'conf3': { 'complete': False, '[section4]': ( 'line6', 'line7'), self.assertEqual(c.config_lines_for('conf'), [ '[section1]', 'line1', 'line2', '', '[section2]', 'line3', '']) self.assertEqual(c.config_lines_for('conf2'), [ '[section3]', 'line4', 'line5', '']) self.assertEqual(c.config_lines_for('conf3'), [])",97,60
openstack%2Fcharm-ceph-mon~master~I61aa5fd888e19f778151239436fb7654d7cc48b5,openstack/charm-ceph-mon,master,I61aa5fd888e19f778151239436fb7654d7cc48b5,Fix parse_key,MERGED,2017-02-16 19:49:46.000000000,2017-02-17 13:29:27.000000000,2017-02-17 13:29:27.000000000,"[{'_account_id': 3}, {'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-16 19:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/1d35888ce4569151192e5f9e1e45d950f2cd39f9', 'message': 'Fix parse_key\n\nparse_key returns incorrect data when the cephx key\ncontains [caps]\n\nFixes-Bug: 1665149\nChange-Id: I61aa5fd888e19f778151239436fb7654d7cc48b5\n'}, {'number': 2, 'created': '2017-02-17 11:06:36.000000000', 'files': ['lib/ceph/__init__.py'], 'web_link': 'https://opendev.org/openstack/charm-ceph-mon/commit/1d0406f0c4b9352b0df2a5b3c2abbc65f86cff4a', 'message': 'Fix parse_key\n\nparse_key returns incorrect data when the cephx key\ncontains [caps].\n\nChange-Id: I61aa5fd888e19f778151239436fb7654d7cc48b5\nCloses-Bug: 1665149\n'}]",0,435085,1d0406f0c4b9352b0df2a5b3c2abbc65f86cff4a,13,4,2,20812,,,0,"Fix parse_key

parse_key returns incorrect data when the cephx key
contains [caps].

Change-Id: I61aa5fd888e19f778151239436fb7654d7cc48b5
Closes-Bug: 1665149
",git fetch https://review.opendev.org/openstack/charm-ceph-mon refs/changes/85/435085/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ceph/__init__.py'],1,1d35888ce4569151192e5f9e1e45d950f2cd39f9,bug/1665149, return element.split(' = ')[1].strip() # IGNORE:E1103, key = element.split(' = ')[1].strip() # IGNORE:E1103,1,1
openstack%2Fos-win~master~I9fba30143bb0f653f1aaf7c97e5c3008a9f03120,openstack/os-win,master,I9fba30143bb0f653f1aaf7c97e5c3008a9f03120,Allow setting VM snapshot types,MERGED,2017-01-19 21:15:02.000000000,2017-02-17 13:24:17.000000000,2017-02-17 13:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8543}, {'_account_id': 17019}, {'_account_id': 24544}, {'_account_id': 25134}]","[{'number': 1, 'created': '2017-01-19 21:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/a68b457a0182fb1ebf45a9e902363751ac4aceb8', 'message': '[WIP] Allow setting VM snapshot types\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n'}, {'number': 2, 'created': '2017-02-09 14:03:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/871a67a4fcfeac448e411585c4f1ac903beea9e2', 'message': ""Allow setting VM snapshot types\n\nOn WS 2016, Hyper-V will attempt to take production checkpoints by\ndefault, if the guest advertises this feature. The issue is that\nthe mechanism that automatically detects the VM checkpoint type\nsupported by the guest is not entirely safe.\n\nWe've had issues with older LIS versions in which case this feature\nwas not properly advertised and production checkpoints were attempted\nbut failed.\n\nThis change will allow explicitly setting the VM snapshot type to\nbe used for a given instance.\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n""}, {'number': 3, 'created': '2017-02-15 11:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/48d2110c0aed27688e8c79cc5645b334fcbe9be7', 'message': ""Allow setting VM snapshot types\n\nOn WS 2016, Hyper-V will attempt to take production checkpoints by\ndefault, if the guest advertises this feature. The issue is that\nthe mechanism that automatically detects the VM checkpoint type\nsupported by the guest is not entirely safe.\n\nWe've had issues with older LIS versions in which case this feature\nwas not properly advertised and production checkpoints were attempted\nbut failed.\n\nThis change will allow explicitly setting the VM snapshot type to\nbe used for a given instance.\n\nPartial-Bug: #1664941\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n""}, {'number': 4, 'created': '2017-02-15 13:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/616fc126ebdb7cfa565fba91d898a7fb9d6fc2c4', 'message': ""Allow setting VM snapshot types\n\nOn WS 2016, Hyper-V will attempt to take production checkpoints by\ndefault, if the guest advertises this feature. The issue is that\nthe mechanism that automatically detects the VM checkpoint type\nsupported by the guest is not entirely safe.\n\nWe've had issues with older LIS versions in which case this feature\nwas not properly advertised and production checkpoints were attempted\nbut failed.\n\nThis change will allow explicitly setting the VM snapshot type to\nbe used for a given instance.\n\nPartial-Bug: #1664941\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n""}, {'number': 5, 'created': '2017-02-16 09:48:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-win/commit/b18801fff85465a1146b8ddc84c12538331b4cd7', 'message': ""Allow setting VM snapshot types\n\nOn WS 2016, Hyper-V will attempt to take production checkpoints by\ndefault, if the guest advertises this feature. The issue is that\nthe mechanism that automatically detects the VM checkpoint type\nsupported by the guest is not entirely safe.\n\nWe've had issues with older LIS versions in which case this feature\nwas not properly advertised and production checkpoints were attempted\nbut failed.\n\nThis change will allow explicitly setting the VM snapshot type to\nbe used for a given instance.\n\nPartial-Bug: #1664941\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n""}, {'number': 6, 'created': '2017-02-17 11:07:57.000000000', 'files': ['os_win/constants.py', 'os_win/tests/unit/utils/compute/test_vmutils.py', 'os_win/utils/compute/vmutils.py', 'os_win/tests/unit/utils/compute/test_vmutils10.py', 'os_win/utils/compute/vmutils10.py'], 'web_link': 'https://opendev.org/openstack/os-win/commit/4ddc77bbe2e01f0f9eb9132c3c1fcb94b20d96a6', 'message': ""Allow setting VM snapshot types\n\nOn WS 2016, Hyper-V will attempt to take production checkpoints by\ndefault, if the guest advertises this feature. The issue is that\nthe mechanism that automatically detects the VM checkpoint type\nsupported by the guest is not entirely safe.\n\nWe've had issues with older LIS versions in which case this feature\nwas not properly advertised and production checkpoints were attempted\nbut failed.\n\nThis change will allow explicitly setting the VM snapshot type to\nbe used for a given instance.\n\nPartial-Bug: #1664941\n\nChange-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120\n""}]",4,422875,4ddc77bbe2e01f0f9eb9132c3c1fcb94b20d96a6,38,7,6,8543,,,0,"Allow setting VM snapshot types

On WS 2016, Hyper-V will attempt to take production checkpoints by
default, if the guest advertises this feature. The issue is that
the mechanism that automatically detects the VM checkpoint type
supported by the guest is not entirely safe.

We've had issues with older LIS versions in which case this feature
was not properly advertised and production checkpoints were attempted
but failed.

This change will allow explicitly setting the VM snapshot type to
be used for a given instance.

Partial-Bug: #1664941

Change-Id: I9fba30143bb0f653f1aaf7c97e5c3008a9f03120
",git fetch https://review.opendev.org/openstack/os-win refs/changes/75/422875/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_win/constants.py', 'os_win/utils/compute/vmutils.py', 'os_win/utils/compute/vmutils10.py']",3,a68b457a0182fb1ebf45a9e902363751ac4aceb8,bug/1664941," def _set_vm_snapshot_type(self, vmsettings, snapshot_type): vmsettings.UserSnapshotType = snapshot_type",,17,4
openstack%2Fcharm-mistral~master~Ib34bcee7ce5bf6b10d5ed3ea36cb50a28f475eb5,openstack/charm-mistral,master,Ib34bcee7ce5bf6b10d5ed3ea36cb50a28f475eb5,Add gate test for xenial-ocata,ABANDONED,2017-02-10 21:28:21.000000000,2017-02-17 13:22:32.000000000,,"[{'_account_id': 3}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-10 21:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mistral/commit/ccdd1319cdd84e72ae6c53af8e84b35817560ff8', 'message': 'Add gate test for xenial-ocata\n\nChange-Id: Ib34bcee7ce5bf6b10d5ed3ea36cb50a28f475eb5\n'}, {'number': 2, 'created': '2017-02-10 21:33:04.000000000', 'files': ['.gitreview', '.testr.conf', 'src/tests/gate-basic-xenial-ocata'], 'web_link': 'https://opendev.org/openstack/charm-mistral/commit/3a5bbb7e117fef0c17849e08742ace83d451c084', 'message': 'Add gate test for xenial-ocata\n\nAdd .gitreview\n\nAdd .testr.conf\n\nChange-Id: Ib34bcee7ce5bf6b10d5ed3ea36cb50a28f475eb5\n'}]",0,432463,3a5bbb7e117fef0c17849e08742ace83d451c084,6,2,2,935,,,0,"Add gate test for xenial-ocata

Add .gitreview

Add .testr.conf

Change-Id: Ib34bcee7ce5bf6b10d5ed3ea36cb50a28f475eb5
",git fetch https://review.opendev.org/openstack/charm-mistral refs/changes/63/432463/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'src/tests/gate-basic-xenial-ocata']",2,ccdd1319cdd84e72ae6c53af8e84b35817560ff8,test-review,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic designate deployment on xenial-newton."""""" from basic_deployment import MistralBasicDeployment if __name__ == '__main__': deployment = MistralBasicDeployment(series='xenial', openstack='cloud:xenial-ocata', source='cloud:xenial-updates/ocata') deployment.run_tests() ",,29,0
openstack%2Fcharm-murano~master~Ic6c062b2fd9ca31f06de31db273b84195982879e,openstack/charm-murano,master,Ic6c062b2fd9ca31f06de31db273b84195982879e,Ocata release enablement,ABANDONED,2017-02-10 21:31:17.000000000,2017-02-17 13:22:21.000000000,,"[{'_account_id': 3}, {'_account_id': 20648}]","[{'number': 1, 'created': '2017-02-10 21:31:17.000000000', 'files': ['.gitreview', 'src/tests/gate-basic-xenial-newton', 'src/tests/gate-basic-xenial-ocata'], 'web_link': 'https://opendev.org/openstack/charm-murano/commit/f016dc0024022d35db46a941ad6b2c034dcc0f82', 'message': 'Ocata release enablement\n\nAdd .gitreview.\n\nAdd Newton and Ocata tests.\n\nChange-Id: Ic6c062b2fd9ca31f06de31db273b84195982879e\n'}]",0,432464,f016dc0024022d35db46a941ad6b2c034dcc0f82,4,2,1,935,,,0,"Ocata release enablement

Add .gitreview.

Add Newton and Ocata tests.

Change-Id: Ic6c062b2fd9ca31f06de31db273b84195982879e
",git fetch https://review.opendev.org/openstack/charm-murano refs/changes/64/432464/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'src/tests/gate-basic-xenial-newton', 'src/tests/gate-basic-xenial-ocata']",3,f016dc0024022d35db46a941ad6b2c034dcc0f82,ocata-release,"#!/usr/bin/env python # # Copyright 2016 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """"""Amulet tests on a basic Murano Charm deployment on xenial-mitaka."""""" from basic_deployment import MuranoBasicDeployment if __name__ == '__main__': deployment = MuranoBasicDeployment(series='xenial', openstack_origin='cloud:xenial-ocata') deployment.run_tests() ",,52,0
openstack%2Frpm-packaging~master~I84e3545a1674d669f2ba638c76736279326952e5,openstack/rpm-packaging,master,I84e3545a1674d669f2ba638c76736279326952e5,Update monasca-common to 1.4.0,MERGED,2017-01-25 01:23:48.000000000,2017-02-17 13:20:29.000000000,2017-02-17 13:18:55.000000000,"[{'_account_id': 3}, {'_account_id': 6593}, {'_account_id': 7102}, {'_account_id': 12542}, {'_account_id': 13294}, {'_account_id': 13404}, {'_account_id': 15905}, {'_account_id': 16168}, {'_account_id': 19648}, {'_account_id': 20656}, {'_account_id': 23181}]","[{'number': 1, 'created': '2017-01-25 01:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/d11e009bee607fd3367dbd0913f337cdb6afdc42', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 2, 'created': '2017-02-06 03:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/1da03921a2aff0ad1a15f7c0783f65de0a0589a8', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 3, 'created': '2017-02-06 07:55:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ad882c12ef6c15f65dab29cebe8a6e7efd55af05', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 4, 'created': '2017-02-07 03:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a88eb827248549d57439aa46b3d1391470f1c693', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\nDepends-on: I67f4f5fa73997dadfd2ec4625c827fb949c6b617\n'}, {'number': 5, 'created': '2017-02-16 09:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/224a35151180eaeb96fa0be041579af07ae75d6c', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\nDepends-on: I67f4f5fa73997dadfd2ec4625c827fb949c6b617\n'}, {'number': 6, 'created': '2017-02-16 09:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/24837c515d941b1cb38dcc60fb6e5c586c3b5625', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\nDepends-on: I67f4f5fa73997dadfd2ec4625c827fb949c6b617\n'}, {'number': 7, 'created': '2017-02-16 10:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/01a660a161bb1feb11eef146289e4820b188bc14', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 8, 'created': '2017-02-16 10:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/260d7afc01f6bd09d977e2b21807d1c06abe94c3', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 9, 'created': '2017-02-16 11:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/9e3d97ac0210261abd4ea872a8004a349de9e76b', 'message': 'Update monasca-common to 1.4.0\n\nDepends-On: I67f4f5fa73997dadfd2ec4625c827fb949c6b617\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 10, 'created': '2017-02-16 21:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/b035725ab926dd1ae8f4384b62b186ea13edca12', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}, {'number': 11, 'created': '2017-02-16 21:05:44.000000000', 'files': ['openstack/monasca-common/monasca-common.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/c97e6b84ea4451d447dfc37df96de0c6eb7764c5', 'message': 'Update monasca-common to 1.4.0\n\nChange-Id: I84e3545a1674d669f2ba638c76736279326952e5\n'}]",9,424919,c97e6b84ea4451d447dfc37df96de0c6eb7764c5,105,11,11,15905,,,0,"Update monasca-common to 1.4.0

Change-Id: I84e3545a1674d669f2ba638c76736279326952e5
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/19/424919/9 && git format-patch -1 --stdout FETCH_HEAD,['openstack/monasca-common/monasca-common.spec.j2'],1,d11e009bee607fd3367dbd0913f337cdb6afdc42,update-monasca-common,Version: 1.4.0,Version: 1.3.0,1,1
openstack%2Fkolla~master~I1b351ccfea5684aeb1394e5a12ee848eb62447fe,openstack/kolla,master,I1b351ccfea5684aeb1394e5a12ee848eb62447fe,Use correct inventory file for Bifrost,MERGED,2017-02-16 18:20:27.000000000,2017-02-17 13:09:22.000000000,2017-02-17 13:09:22.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 10787}]","[{'number': 1, 'created': '2017-02-16 18:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8d8a441c0b735b3434192994985307c4199ecd67', 'message': ""Use correct inventory file for Bifrost\n\nBifrost now targets the play in the install.yml playbook at the\ntarget Ansible group instead of localhost.\n\nThis change uses the target inventory file to pick up this group\nand avoid a 'noop' playbook.\n\nChange-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe\nClosesBug: #1665413\n""}, {'number': 2, 'created': '2017-02-16 18:33:44.000000000', 'files': ['docker/bifrost/bifrost-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/39e48f2cf9380144e1d12bf3738752f9f0cce9ce', 'message': ""Use correct inventory file for Bifrost\n\nBifrost now targets the play in the install.yml playbook at the\ntarget Ansible group instead of localhost.\n\nThis change uses the target inventory file to pick up this group\nand avoid a 'noop' playbook.\n\nChange-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe\nCloses-Bug: #1665413\n""}]",0,435058,39e48f2cf9380144e1d12bf3738752f9f0cce9ce,18,3,2,14826,,,0,"Use correct inventory file for Bifrost

Bifrost now targets the play in the install.yml playbook at the
target Ansible group instead of localhost.

This change uses the target inventory file to pick up this group
and avoid a 'noop' playbook.

Change-Id: I1b351ccfea5684aeb1394e5a12ee848eb62447fe
Closes-Bug: #1665413
",git fetch https://review.opendev.org/openstack/kolla refs/changes/58/435058/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/bifrost/bifrost-base/Dockerfile.j2'],1,8d8a441c0b735b3434192994985307c4199ecd67,bug/1665413, ansible-playbook -vvvv -i /bifrost/playbooks/inventory/target /bifrost/playbooks/install.yaml \, ansible-playbook -vvvv -i /bifrost/playbooks/inventory/localhost /bifrost/playbooks/install.yaml \,1,1
openstack%2Fsecurity-doc~master~I506180f7c85d7d521c016e4827b7dfcfcad6bf4d,openstack/security-doc,master,I506180f7c85d7d521c016e4827b7dfcfcad6bf4d,Updated from openstack-manuals,MERGED,2017-02-17 12:54:39.000000000,2017-02-17 13:03:51.000000000,2017-02-17 13:03:51.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2017-02-17 12:54:39.000000000', 'files': ['common/glossary.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/6a45da8c41d60ee378a160531c984b29572a937e', 'message': 'Updated from openstack-manuals\n\nChange-Id: I506180f7c85d7d521c016e4827b7dfcfcad6bf4d\n'}]",0,435431,6a45da8c41d60ee378a160531c984b29572a937e,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I506180f7c85d7d521c016e4827b7dfcfcad6bf4d
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/31/435431/1 && git format-patch -1 --stdout FETCH_HEAD,['common/glossary.rst'],1,6a45da8c41d60ee378a160531c984b29572a937e,openstack/openstack-manuals, An open source community project by SUSE that aims to provide all necessary services to quickly deploy and manage clouds., An open source community project by Dell that aims to provide all necessary services to quickly deploy clouds.,2,2
openstack%2Ffuel-agent~stable%2Fnewton~I05e0b33420058772216220bb9fcd5f61c40f3e27,openstack/fuel-agent,stable/newton,I05e0b33420058772216220bb9fcd5f61c40f3e27,Add rsync dependency for fuel-agent,MERGED,2017-02-16 10:37:07.000000000,2017-02-17 13:03:01.000000000,2017-02-17 12:59:46.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8971}, {'_account_id': 20656}]","[{'number': 1, 'created': '2017-02-16 10:37:07.000000000', 'files': ['specs/fuel-agent.spec', 'debian/control'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/99b0cd6b3e46b75b1a9d7810bb81de1f2ff0a866', 'message': 'Add rsync dependency for fuel-agent\n\nChange-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27\nCo-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>\nPartial-Bug: 1664152\n'}]",0,434802,99b0cd6b3e46b75b1a9d7810bb81de1f2ff0a866,13,4,1,10288,,,0,"Add rsync dependency for fuel-agent

Change-Id: I05e0b33420058772216220bb9fcd5f61c40f3e27
Co-Authored-By: Ivan Suzdal <isuzdal@mirantis.com>
Partial-Bug: 1664152
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/02/434802/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/fuel-agent.spec', 'debian/control']",2,99b0cd6b3e46b75b1a9d7810bb81de1f2ff0a866,bug/1664152," rsync,",,2,0
openstack%2Fkolla-ansible~master~Iccd12af7dc6a51e3f3ca896998ec9358a52ec83b,openstack/kolla-ansible,master,Iccd12af7dc6a51e3f3ca896998ec9358a52ec83b,Adding export OS_IMAGE_API_VERSION=2 to admin-openrc.sh.j2,ABANDONED,2017-02-13 07:36:00.000000000,2017-02-17 13:02:57.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 7488}]","[{'number': 1, 'created': '2017-02-13 07:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/136555a85b04e0aed9b7fe3a275ddedc31ceceb8', 'message': 'Adding export OS_IMAGE_API_VERSION=2 to admin-openrc.\nAs per openstack installation guide, this variable is set in\nadmin-openrc.sh\nCloses-Bug: 1664130\n\nChange-Id: Iccd12af7dc6a51e3f3ca896998ec9358a52ec83b\n'}, {'number': 2, 'created': '2017-02-13 07:44:24.000000000', 'files': ['ansible/roles/common/templates/admin-openrc.sh.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3f31f1b93f9fadd4d5f5a3bc23759e418400886c', 'message': 'Adding export OS_IMAGE_API_VERSION=2 to admin-openrc.sh.j2\n\nAs per openstack installation guide, this variable is set in\nadmin-openrc.sh.j2\n\nCloses-Bug: #1664130\nChange-Id: Iccd12af7dc6a51e3f3ca896998ec9358a52ec83b\n'}]",2,432890,3f31f1b93f9fadd4d5f5a3bc23759e418400886c,6,3,2,25101,,,0,"Adding export OS_IMAGE_API_VERSION=2 to admin-openrc.sh.j2

As per openstack installation guide, this variable is set in
admin-openrc.sh.j2

Closes-Bug: #1664130
Change-Id: Iccd12af7dc6a51e3f3ca896998ec9358a52ec83b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/90/432890/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/common/templates/admin-openrc.sh.j2'],1,136555a85b04e0aed9b7fe3a275ddedc31ceceb8,bug/1664130,export OS_IMAGE_API_VERSION=2,,1,0
openstack%2Fsenlin~stable%2Focata~Ie7612c1387ce2fa2390dce7ce0d20f41adb7ee4a,openstack/senlin,stable/ocata,Ie7612c1387ce2fa2390dce7ce0d20f41adb7ee4a,User reference doc for deletion policy,MERGED,2017-02-17 12:30:41.000000000,2017-02-17 13:00:58.000000000,2017-02-17 13:00:58.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 12:30:41.000000000', 'files': ['doc/source/user/policy_types/deletion.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/58142991610977255ff6ed002d90e78324e63958', 'message': 'User reference doc for deletion policy\n\nChange-Id: Ie7612c1387ce2fa2390dce7ce0d20f41adb7ee4a\n(cherry picked from commit 657b5ac9fb1adfc28ea99b4e94db0537340508ac)\n'}]",0,435420,58142991610977255ff6ed002d90e78324e63958,6,2,1,8246,,,0,"User reference doc for deletion policy

Change-Id: Ie7612c1387ce2fa2390dce7ce0d20f41adb7ee4a
(cherry picked from commit 657b5ac9fb1adfc28ea99b4e94db0537340508ac)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/20/435420/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/deletion.rst'],1,58142991610977255ff6ed002d90e78324e63958,ref-deletion-policy,".. _ref-deletion-policy:The deletion policy is provided to help users control the election of victim nodes when a cluster is about to be shrank. In other words, when the size of a cluster is to be decreased, which node(s) should be removed first. Currently, this policy is applicable to clusters of all profile types and it is enforced when the cluster's size is about to be reduced. Properties ~~~~~~~~~~ Below is a typical spec for a deletion policy: .. code-block:: yaml type: senlin.policy.deletion version: 1.0 properties: criteria: OLDEST_FIRST destroy_after_deletion: false grace_period: 30 reduce_desired_capacity: true The valid values for the ""``criteria`` property include: - ``OLDEST_FIRST``: always select node(s) which were created earlier than other nodes. - ``YOUNGEST_FIRST``: always select node(s) which were created recently instead of those created earlier. - ``OLDEST_PROFILE_FIRST``: compare the profile used by each individual nodes and select the node(s) whose profile(s) were created earlier than others. - ``RANDOM``: randomly select node(s) from the cluster for deletion. This is the default criteria if omitted. .. NOTE:: There is an implicit rule (criteria) when electing victim nodes. Senlin engine always rank those nodes which are not in ACTIVE state before others. There are more several actions that can trigger a deletion policy. Some of them may already carry a list of candidates to remove, e.g. ``CLUSTER_DEL_NODES`` or ``NODE_DELETE``; others may only carry a number of nodes to remove, e.g. ``CLUSTER_SCALE_IN`` or ``CLUSTER_RESIZE``. For actions that already have a list of candidates, the deletion policy will respect the action inputs. The election of victims only happens when no such candidates have been identified. Deletion vs Destroy ~~~~~~~~~~~~~~~~~~~ There are cases where you don't want the node(s) removed from a cluster to be destroyed. Instead, you prefer them to become ""orphan"" nodes so that in future you can quickly add them back to the cluster without having to create new nodes. If this is your situation, you may want to set ``destroy_after_deletion`` to ``false``. Senlin engine won't delete the node(s) after removing them from the cluster. The default behavior is to delete (destroy) the node(s) after they are deprived of their cluster membership. Grace Period ~~~~~~~~~~~~ Another common scenario is to grant a node a period of time for it to shutdown gracefully. Even if a node doesn't have a builtin logic to perform a graceful shutdown, granting them some extra time may still help ensure the resources they were using have been properly released. The default value for ``grace_period`` property is 0, which means the node deletion happens as soon as it is removed from the cluster. You can customize this value according to your need. Note that the grace period will be granted to all node(s) deleted. When setting this value to a large number, be sure it will not exceed the typical timeout value for action execution. Or else the node deletion will be a failure. Reduce Desired Capacity or Not? ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ In most cases, users would anticipate the ""desired_capacity"" of a cluster be reduced when there are nodes removed from it. Since the victim selection algorithm always pick nodes in non-ACTIVE status over ACTIVE ones, you can actually remove erroneous nodes by taking advantage of this rule. For example, there are 4 nodes in a cluster and 2 of them are known to be in inactive status. You can use the command :command:`openstack cluster members del` to remove the bad nodes. If you have a deletion policy attached to the cluster, you get a chance to tell the Senlin engine that you don't want to change the capacity of the cluster. Instead, you only want the bad nodes removed. With the help of other cluster health related commands, you can quickly recover the cluster to a healthy status. You don't have to change the desired capacity of the cluster to a smaller value and then change it back. If this is your use case, you can set ``reduce_desired_capacity`` to ``false`` in the policy spec. The cluster's desired capacity won't be changed after cluster membership is modified. Deleting Nodes Across Regions ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ With the help of :ref:`ref-region-policy`, you will be able to distribute a cluster's nodes into different regions as instructed. However, when you are removing nodes from more than one regions, the same distribution rule has to be respected as well. When there is a region placement policy in effect, the deletion policy will first determine the number of nodes to be removed from each region. Then in each region, the policy performs a victim election based on the criteria you specified in the policy spec. Deleting Nodes Across Availability Zones ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Similarly, when there is a zone placement policy attached to the cluster in question, nodes in the cluster may get distributed across a few availability zones based on a preset algorithm. The deletion policy, when triggered, will first determine the number for nodes to be removed from each availability zone. Then it proceeds to elect victim nodes based on the criteria specified in the policy spec within each availability zone.",<TBD>,130,1
openstack%2Fsenlin~stable%2Focata~If6960bf803ed34962b2b8834e69216bc8c2cb6f2,openstack/senlin,stable/ocata,If6960bf803ed34962b2b8834e69216bc8c2cb6f2,User reference documentation for zone policy,MERGED,2017-02-17 12:30:29.000000000,2017-02-17 13:00:33.000000000,2017-02-17 13:00:33.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 12:30:29.000000000', 'files': ['doc/source/user/policy_types/zone_placement.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/6c821d68398b8cd1a23507e24da993d2e4d1a0b6', 'message': 'User reference documentation for zone policy\n\nThis adds a user reference documentation for the zone placement policy.\n\nChange-Id: If6960bf803ed34962b2b8834e69216bc8c2cb6f2\n(cherry picked from commit 32b16a663107f9990ecf99370f2915a5cb88da1b)\n'}]",0,435419,6c821d68398b8cd1a23507e24da993d2e4d1a0b6,6,2,1,8246,,,0,"User reference documentation for zone policy

This adds a user reference documentation for the zone placement policy.

Change-Id: If6960bf803ed34962b2b8834e69216bc8c2cb6f2
(cherry picked from commit 32b16a663107f9990ecf99370f2915a5cb88da1b)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/19/435419/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/policy_types/zone_placement.rst'],1,6c821d68398b8cd1a23507e24da993d2e4d1a0b6,ref-zone-policy,".. _ref-zone-policy:The zone placement policy is designed to enable the deployment and management resource pools across multiple availability zones. Note that the current design is only concerned with the availability zones configured to Nova compute service. Support to Cinder availability zones and Neutron availability zones may be added in future when we have volume storage specific or network specific profile types. The current implementation of the zone placement policy works with clusters of Nova virtual machines only. Properties ~~~~~~~~~~ A typical spec for a zone placement policy is exemplified in the following sample: .. code-block:: yaml type: senlin.policy.zone_placement version: 1.0 properties: regions: - name: az_1 weight: 100 - name: az_2 weight: 200 In this sample spec, two availability zones are provided, namely ""``az_1``"" and ""``az_2``"". Each availability zone can have an optional ""``weight``"" attribute associated with it. The ""``weight``"" value is to be interpreted as a relative number. The value assigned to one zone has to be compared to those assigned to other zones for an assessment. In the sample shown above, ``az_1`` and ``az_2`` are assigned weights of 100 and 200 respectively. This means that among every 3 nodes creation, one is expected to be scheduled to ``az_1`` and the other 2 are expected to be scheduled to ``az_2``. In other words, the chance for ``az_2`` receiving a node creation request is twice of that for ``az_1``. The ""``weight``"" value has to be a positive integer, if specified. The default value is 100 for all zones whose weight is omitted. Validation ~~~~~~~~~~ When creating a zone placement policy, the Senlin engine validates whether the zone names given are all known to be usable availability zones by the Nova compute service. Do NOT pass in an invalid availability zone name and hope Senlin can create a zone for you. Later on when the zone placement policy is triggered upon node creation or node deletion actions, it always validates if the provided availability zones are still valid and usable. Node Distribution ~~~~~~~~~~~~~~~~~ After a zone placement polic is attached to a cluster and enabled, all future node creations (by cluster scaling for example) will trigger an evaluation of the policy. Similarly, a node deletion action will also trigger an evaluation of it because the policy's goal is to maintain the node distribution based on the one computed from the weight distribution of all zones. The zone placement policy will favor availability zones with highest weight values when selecting a zone for nodes to be created.",<TBD>,69,1
openstack%2Fsenlin~stable%2Focata~I7d894ee55d386670281610abefbd69898a172d9b,openstack/senlin,stable/ocata,I7d894ee55d386670281610abefbd69898a172d9b,Use dynamic timer for cluster status polling,MERGED,2017-02-17 11:03:46.000000000,2017-02-17 13:00:27.000000000,2017-02-17 13:00:27.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 11:03:46.000000000', 'files': ['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/aa2ded7a65255d574fb4f973edb0121f2a973da4', 'message': 'Use dynamic timer for cluster status polling\n\nIn the current implementation, we have a fixed-interval timer for\npolling each cluster when appropriate. However, this could be very\ndangerous because we cannot guarantee that the polling will complete\nduring the given interval. This situation is worsened when we later\nadded the triggering of NODE_RECOVER actions.\n\nFor example, if the polling interval is specified as 2 seconds, it\nmeans that the user wants the cluster health to be triggered every 2\nseconds. Even if a previous checking is still ongoing, the next checking\nloop will be fired off nonetheless.\n\nThis patch fixes this situation by using ""dynamic timers"". A timer is\nfired with a callback function to be executed (_poll_cluster in this\ncase). The function is supposed to check if it has taken a longer time\nto complete its job. A warning message will be emitted if so (possible\nimprovement is to fire an event? ) Suppose the _poll_cluster operation\nhas taken 5 seconds to finish. The expected behavior is now:\n\n - A warning message is logged saying that the poller has missed two\n   intervals.\n\n - The poller will return a sugguested time for sleep, which is 1 in\n   this case.\n\nAfter sleeping for 1 second, the _poll_cluster function will be invoked\nagain as if nothing has happened. In the revised logic, we are no longer\nguaranteeing that the poller will always be triggered. But whenever we\nfailed to do a poll in time, we log a warning.\n\nChange-Id: I7d894ee55d386670281610abefbd69898a172d9b\n(cherry picked from commit 0bc8f0351f145f3e69580a5f4355e30f016707ff)\n'}]",0,435368,aa2ded7a65255d574fb4f973edb0121f2a973da4,6,2,1,8246,,,0,"Use dynamic timer for cluster status polling

In the current implementation, we have a fixed-interval timer for
polling each cluster when appropriate. However, this could be very
dangerous because we cannot guarantee that the polling will complete
during the given interval. This situation is worsened when we later
added the triggering of NODE_RECOVER actions.

For example, if the polling interval is specified as 2 seconds, it
means that the user wants the cluster health to be triggered every 2
seconds. Even if a previous checking is still ongoing, the next checking
loop will be fired off nonetheless.

This patch fixes this situation by using ""dynamic timers"". A timer is
fired with a callback function to be executed (_poll_cluster in this
case). The function is supposed to check if it has taken a longer time
to complete its job. A warning message will be emitted if so (possible
improvement is to fire an event? ) Suppose the _poll_cluster operation
has taken 5 seconds to finish. The expected behavior is now:

 - A warning message is logged saying that the poller has missed two
   intervals.

 - The poller will return a sugguested time for sleep, which is 1 in
   this case.

After sleeping for 1 second, the _poll_cluster function will be invoked
again as if nothing has happened. In the revised logic, we are no longer
guaranteeing that the poller will always be triggered. But whenever we
failed to do a poll in time, we log a warning.

Change-Id: I7d894ee55d386670281610abefbd69898a172d9b
(cherry picked from commit 0bc8f0351f145f3e69580a5f4355e30f016707ff)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/68/435368/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/health_manager.py', 'senlin/tests/unit/engine/test_health_manager.py']",2,aa2ded7a65255d574fb4f973edb0121f2a973da4,hm-one-shot-timer,"import timefrom oslo_utils import timeutils as tuclass TestChaseUp(base.SenlinTestCase): def test_less_than_one_interval(self): start = tu.utcnow(True) # we assume that the delay before next line is < 5 seconds res = hm._chase_up(start, 5) self.assertTrue(res <= 5) def test_more_than_one_interval(self): start = tu.utcnow(True) time.sleep(2) # we assume that the delay before next line is < 5 seconds res = hm._chase_up(start, 1) self.assertTrue(res <= 1) mock_add_timer = self.patchobject(self.hm.TG, 'add_dynamic_timer', mock.call(self.hm._poll_cluster, None, None, 'CID1', 12), mock.call(self.hm._poll_cluster, None, None, 'CID2', 34) @mock.patch.object(hm, ""_chase_up"") mock_wait, mock_nodes, mock_chase): res = self.hm._poll_cluster('CLUSTER_ID', 456) self.assertEqual(mock_chase.return_value, res) mock_chase.assert_called_once_with(mock.ANY, 456) @mock.patch.object(hm, ""_chase_up"") def test__poll_cluster_not_found(self, mock_check, mock_get, mock_chase): res = self.hm._poll_cluster('CLUSTER_ID', 123) self.assertEqual(mock_chase.return_value, res) mock_chase.assert_called_once_with(mock.ANY, 123) @mock.patch.object(hm, ""_chase_up"") mock_ctx, mock_sctx, mock_chase): res = self.hm._poll_cluster('CLUSTER_ID', 123) self.assertEqual(mock_chase.return_value, res) mock_chase.assert_called_once_with(mock.ANY, 123) @mock.patch.object(hm, ""_chase_up"") mock_get, mock_wait, mock_chase): res = self.hm._poll_cluster('CLUSTER_ID', 456) self.assertEqual(mock_chase.return_value, res) mock_chase.assert_called_once_with(mock.ANY, 456) mock_add_timer = self.patchobject(self.hm.TG, 'add_dynamic_timer', mock_add_timer.assert_called_once_with( self.hm._poll_cluster, None, None, 'CCID', 12) mock_add_timer.assert_called_once_with( cfg.CONF.periodic_interval, self.hm._dummy_task) mock_add_tm = self.patchobject(self.hm.TG, 'add_dynamic_timer', mock_add_tm.assert_called_with(mock_poll, None, None, 'CLUSTER_ID', 50)"," mock_add_timer = self.patchobject(self.hm.TG, 'add_timer', mock.call(12, self.hm._poll_cluster, None, 'CID1', 12), mock.call(34, self.hm._poll_cluster, None, 'CID2', 34) mock_wait, mock_nodes): self.hm._poll_cluster('CLUSTER_ID', 456) def test__poll_cluster_not_found(self, mock_check, mock_get): self.hm._poll_cluster('CLUSTER_ID', 123) mock_ctx, mock_sctx): self.hm._poll_cluster('CLUSTER_ID', 123) mock_get, mock_wait): self.hm._poll_cluster('CLUSTER_ID', 456) mock_add_timer = self.patchobject(self.hm.TG, 'add_timer', mock_add_timer.assert_called_once_with(12, self.hm._poll_cluster, None, 'CCID', 12) mock_add_timer.assert_called_once_with(cfg.CONF.periodic_interval, self.hm._dummy_task) mock_add_tm = self.patchobject(self.hm.TG, 'add_timer', mock_add_tm.assert_called_with(50, mock_poll, None, 'CLUSTER_ID', 50)",78,24
openstack%2Fsenlin~stable%2Focata~Ifb32d6a694bfd4b2e69cf595a4dbf3cfe58f4a31,openstack/senlin,stable/ocata,Ifb32d6a694bfd4b2e69cf595a4dbf3cfe58f4a31,User reference documentation for LB policy (1),MERGED,2017-02-17 11:07:03.000000000,2017-02-17 13:00:21.000000000,2017-02-17 13:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2017-02-17 11:07:03.000000000', 'files': ['senlin/policies/lb_policy.py', 'doc/source/user/policy_types/load_balancing.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/660826e1c5e40ae6fd1abd6700fe14350d99f48c', 'message': 'User reference documentation for LB policy (1)\n\nThis adds the first part of the user reference documentation for the\nLB policy. It also adds a TODO item in the policy implementation.\n\nChange-Id: Ifb32d6a694bfd4b2e69cf595a4dbf3cfe58f4a31\n(cherry picked from commit 55618d41d6b036ae54e49d7979372fc37eea5658)\n'}]",0,435374,660826e1c5e40ae6fd1abd6700fe14350d99f48c,6,2,1,8246,,,0,"User reference documentation for LB policy (1)

This adds the first part of the user reference documentation for the
LB policy. It also adds a TODO item in the policy implementation.

Change-Id: Ifb32d6a694bfd4b2e69cf595a4dbf3cfe58f4a31
(cherry picked from commit 55618d41d6b036ae54e49d7979372fc37eea5658)
",git fetch https://review.opendev.org/openstack/senlin refs/changes/74/435374/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/policies/lb_policy.py', 'doc/source/user/policy_types/load_balancing.rst']",2,660826e1c5e40ae6fd1abd6700fe14350d99f48c,ref-lb-policy-1,".. _ref-lb-policy:The load-balancing policy is an encapsulation of the LBaaS v2 service that distributes the network load evenly among members in a pool. Users are in general not interested in the implementation details although they have a strong requirement of the features provided by a load-balancer, such as load-balancing, health-monitoring etc. The load-balancing policy is designed to be applicable to a cluster of virtual machines or some variants or extensions of basic virtual machines. Currently, Senlin only supports the load balancing for Nova servers. Future revisions may extend this to more types of clusters. Before using this policy, you will have to make sure the LBaaS v2 service is installed and configured properly. Properties ~~~~~~~~~~ The design of the load-balancing policy faithfully follows the interface and properties exposed by the LBaaS v2 service. A sample spec is shown below: .. code-block:: yaml type: senlin.policy.loadbalance version: 1.1 properties: pool: protocol: HTTP protocol_port: 80 subnet: private_subnet lb_method: ROUND_ROBIN admin_state_up: true session_persistence: type: HTTP_COOKIE cookie_name: my_cookie vip: subnet: public_subnet address: 12.34.56.78 connection_limit: 5000 protocol: HTTP protocol_port: 80 admin_state_up: true health_monitor: type: HTTP delay: 20 timeout: 5 max_retries: 3 admin_state_up: true http_method: GET url_path: /health expected_codes: 200 lb_status_timeout: 300 As you can see, there are many properties related to the policy. The good news is that for most of them, there are reasonable default values. All properties are optional except for the following few: - ``pool.subnet``: This property provides the name or ID of the subnet for the port on which nodes can be connected. - ``vip.subnet``: This property provides the name or ID of the subnet on which the virtual IP (VIP) is allocated. The following subsections describe each and every group of properties and the general rules on using them. Note that you can create and configure load-balancers all by yourself when you have a good reason to do so. However, by using the load-balancing policy, you no longer have to manage the load-balancer's lifecycle manually and you don't have to update the load-balancer manually when cluster membership changes. Load Balancer Pools ~~~~~~~~~~~~~~~~~~~ The load balancer pool is managed automatically when you have a load-balancing policy attached to a cluster. The policy automatically adds existing nodes to the load balancer pool when attaching the policy. Later on, when new nodes are added to the cluster (e.g. by cluster scaling) or existing nodes are removed from the cluster, the policy will update the pool's status to reflect the change in membership. Each pool is supposed to use the same protocol and the same port number for load sharing. By default, the protocol (i.e. ``pool.protocol``) is set to ""``HTTP``"" which can be customized to ""``HTTPS``"" or ""``TCP``"" in your setup. The default port number is 80, which also can be modified to suit your service configuration. All nodes in a pool are supposed to reside on the same subnet, and the subnet specified in the ``pool.subnet`` property must be compatible to the subnets of existing nodes. The LBaaS service is capable of load balance among nodes in different ways which are collectively called the ``lb_method``. Valid values for this property are: - ``ROUND_ROBIN``: The load balancer will select a node for workload handling on a round-robin basis. Each node gets an equal pressure to handle workloads. - ``LEAST_CONNECTIONS``: The load balancer will choose a node based on the number of established connections from client. The node will the lowest number of connections will be chosen. - ``SOURCE_IP``: The load balancer will compute hash values based on the IP addresses of the clients and the server and then use the hash value for routing. This ensures the requests from the same client always go to the same server even in the face of broken connections. The ``pool.admin_state_up`` property for the most time can be safely ignored. It is useful only when you want to debug the details of a load-balancer. The last property that needs some attention is ``pool.session_persistence`` which is used to persist client sessions even if the connections may break now and then. There are three types of session persistence supported: - ``SOURCE_IP``: The load balancer will try resume a broken connection based on the client's IP address. You don't have to configure the ``cookie_name`` property in this case. - ``HTTP_COOKIE``: The load balancer will check a named, general HTTP cookie using the name specified in the ``cookie_name`` property and then resume the connection based on the cookie contents. - ``APP_COOKIE``: The load balancer will check the application specific cookie using the name specified in the ``cookie_name`` and resume connection based on the cookie contents. Virtual IP ~~~~~~~~~~ The Virtual IP (or ""VIP"" for short) refers to the IP address visible from the client side. It is the single IP address used by all clients to access the application or service running on the pool nodes. You have to specify a value for the ``vip.subnet`` property even though you don't have a preference about the actual VIP allocated. However, if you do have a preferred VIP address to use, you will need to provide both ``vip.subnet`` and ``vip.address`` values. The LBaaS service will check if both values are valid. Note that if you choose to omit the ``vip.address`` property, the LBaaS service will allocate an address for you from the provided subnet. You will have to check the cluster's ``data`` property after the load-balancing policy has been successfully attached to your cluster. For example: .. code-block:: console $ openstack cluster show my_cluster +------------------+------------------------------------------------+ | Field | Value | +------------------+------------------------------------------------+ | created_at | 2017-01-21T06:25:42Z | | data | { | | | ""loadbalancers"": { | | | ""1040ad51-87e8-4579-873b-0f420aa0d273"": { | | | ""vip_address"": ""11.22.33.44"" | | | } | | | } | | | } | | dependents | {} | | desired_capacity | 10 | | domain_id | None | | id | 30d7ef94-114f-4163-9120-412b78ba38bb | | ... | ... | The output above shows you that the cluster has a load-balancer created for you and the VIP used to access that cluster is ""11.22.33.44"".",<TBD>,171,1
