id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fproject-config~master~Iaa6a94e3f1e3bff5f4d2986c4926078bd9090b42,openstack/project-config,master,Iaa6a94e3f1e3bff5f4d2986c4926078bd9090b42,Check for astra misspelling,MERGED,2016-02-11 15:33:09.000000000,2016-02-16 08:07:53.000000000,2016-02-16 08:07:53.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}, {'_account_id': 16237}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-11 15:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d6519c135ddc6cae4ec3b59bec4434f76f729e4d', 'message': 'Check for astra misspelling\n\nChange-Id: Iaa6a94e3f1e3bff5f4d2986c4926078bd9090b42\n'}, {'number': 2, 'created': '2016-02-11 15:52:10.000000000', 'files': ['gerrit/projects.yaml', 'tools/check_valid_gerrit_projects.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/03d0680e41095f582dc99efff47a4f35fcbc2798', 'message': 'Check for astra misspelling\n\nAdd common missspellings, fix also the one issue it caught.\n\nChange-Id: Iaa6a94e3f1e3bff5f4d2986c4926078bd9090b42\n'}]",0,279143,03d0680e41095f582dc99efff47a4f35fcbc2798,11,6,2,6547,,,0,"Check for astra misspelling

Add common missspellings, fix also the one issue it caught.

Change-Id: Iaa6a94e3f1e3bff5f4d2986c4926078bd9090b42
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/279143/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/check_valid_gerrit_projects.py'],1,d6519c135ddc6cae4ec3b59bec4434f76f729e4d,astara," (('Devstack', 'devstack'), 'DevStack'), (('astra', 'astara'), 'Astara')"," (('Devstack', 'devstack'), 'DevStack')",2,1
openstack%2Fproject-config~master~Icdf9c1f99221a3be051330630132f6382da71059,openstack/project-config,master,Icdf9c1f99221a3be051330630132f6382da71059,Promote neutron-src-neutron-lib job to check/gate,MERGED,2016-02-15 23:28:32.000000000,2016-02-16 08:06:57.000000000,2016-02-16 08:06:57.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-15 23:28:32.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/73abb78d130245942d0940be2378ef4c7331096b', 'message': ""Promote neutron-src-neutron-lib job to check/gate\n\nPassing on experimental, now let's gate so we avoid backwards\nincompat changes.\n\nChange-Id: Icdf9c1f99221a3be051330630132f6382da71059\n""}]",0,280443,73abb78d130245942d0940be2378ef4c7331096b,7,3,1,10980,,,0,"Promote neutron-src-neutron-lib job to check/gate

Passing on experimental, now let's gate so we avoid backwards
incompat changes.

Change-Id: Icdf9c1f99221a3be051330630132f6382da71059
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/280443/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,73abb78d130245942d0940be2378ef4c7331096b,src-job-gate, check: - gate-tempest-dsvm-neutron-src-neutron-lib gate:, experimental:,3,1
openstack%2Fsenlin-dashboard~master~I3be553c4f29952c6936f1ea9d4e2d5636be4d11f,openstack/senlin-dashboard,master,I3be553c4f29952c6936f1ea9d4e2d5636be4d11f,Add event table in cluster detail,MERGED,2016-01-21 06:54:31.000000000,2016-02-16 08:02:40.000000000,2016-02-16 08:02:40.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-01-21 06:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/d25287a808ea6c80fc575de4c551bdb450ac6d6f', 'message': 'Add event table in cluster detail\n\nPartially implements blueprint senlin-dashboard-event\n\nChange-Id: I3be553c4f29952c6936f1ea9d4e2d5636be4d11f\n'}, {'number': 2, 'created': '2016-02-16 07:37:44.000000000', 'files': ['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/clusters/tabs.py', 'senlin_dashboard/test/test_data/senlin_data.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/23ca1aafa3daefe621466831bdba2c266f42602c', 'message': 'Add event table in cluster detail\n\nPartially implements blueprint senlin-dashboard-event\n\nChange-Id: I3be553c4f29952c6936f1ea9d4e2d5636be4d11f\n'}]",4,270624,23ca1aafa3daefe621466831bdba2c266f42602c,12,3,2,6763,,,0,"Add event table in cluster detail

Partially implements blueprint senlin-dashboard-event

Change-Id: I3be553c4f29952c6936f1ea9d4e2d5636be4d11f
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/24/270624/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/clusters/tabs.py', 'senlin_dashboard/test/test_data/senlin_data.py']",3,d25287a808ea6c80fc575de4c551bdb450ac6d6f,bp/senlin-dashboard-event," cluster_1.id = ""123456""",,40,3
openstack%2Fsenlin-dashboard~master~I15dc8c86ac538516eeeeff9f35452e398a0501eb,openstack/senlin-dashboard,master,I15dc8c86ac538516eeeeff9f35452e398a0501eb,"As a common practice, we should remove the copyright notice",MERGED,2016-02-16 07:08:14.000000000,2016-02-16 08:02:34.000000000,2016-02-16 08:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-16 07:08:14.000000000', 'files': ['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/clusters/forms.py', 'senlin_dashboard/cluster/policies/tests.py', 'senlin_dashboard/test/test_data/exceptions.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/219a87e681b75840bc611e958624448125ae2db2', 'message': 'As a common practice, we should remove the copyright notice\n\nChange-Id: I15dc8c86ac538516eeeeff9f35452e398a0501eb\n'}]",0,280523,219a87e681b75840bc611e958624448125ae2db2,7,3,1,6763,,,0,"As a common practice, we should remove the copyright notice

Change-Id: I15dc8c86ac538516eeeeff9f35452e398a0501eb
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/23/280523/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/clusters/forms.py', 'senlin_dashboard/cluster/policies/tests.py', 'senlin_dashboard/test/test_data/exceptions.py']",4,219a87e681b75840bc611e958624448125ae2db2,remove_copyright,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0# Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.","# Copyright 2015 99Cloud Technologies Co., Ltd.# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at# http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License.",36,44
openstack%2Fvitrage-specs~master~Idce4da45c082436e4b922f6c6f9e50214a40a527,openstack/vitrage-specs,master,Idce4da45c082436e4b922f6c6f9e50214a40a527,fix documentation rest api,ABANDONED,2016-01-10 13:39:09.000000000,2016-02-16 07:46:23.000000000,,"[{'_account_id': 3}, {'_account_id': 19159}, {'_account_id': 19765}]","[{'number': 1, 'created': '2016-01-10 13:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/3bb6051d96c4059e847032f680c1c848ca8d798c', 'message': 'fix documentation rest api\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}, {'number': 2, 'created': '2016-01-11 14:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/24730a1cdea97024116535e2568d604f7872f13c', 'message': 'fix documentation rest api\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}, {'number': 3, 'created': '2016-01-11 14:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/39b951406900e001b9cd2f5f34a3141531e645ef', 'message': 'fix documentation rest api\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}, {'number': 4, 'created': '2016-01-12 08:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/e0bfcb1affe4ee9478fc07ce33f96f270840ec0b', 'message': 'fix documentation rest api\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}, {'number': 5, 'created': '2016-01-18 12:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/b042653a2dea19cfd027c34734d570d892beff5e', 'message': 'fix documentation rest api\n\nadd show resource and list resources\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}, {'number': 6, 'created': '2016-01-18 13:48:10.000000000', 'files': ['specs/mitaka/vitrage-api-get-topology.rst'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/ae406aac85b82e3309d687923eb4e9026335714d', 'message': 'fix documentation rest api\n\nadd show resource and list resources\n\nImplements: blueprint get-topology-api\nChange-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527\n'}]",9,265638,ae406aac85b82e3309d687923eb4e9026335714d,15,3,6,19134,,,0,"fix documentation rest api

add show resource and list resources

Implements: blueprint get-topology-api
Change-Id: Idce4da45c082436e4b922f6c6f9e50214a40a527
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/38/265638/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/vitrage-api-get-topology.rst'],1,3bb6051d96c4059e847032f680c1c848ca8d798c,bp/get-topology-api,"POST /v1.0/topology/ ~~~~~~~~~~~~~~~~~~~~NoneConsists of a topology request definition which has the following properties: * root - (string, optional) the root node to start defaults to the openstack node * depth - (int, optional) the depth of the topology graph defaults to max depth * graph_type-(string, optional) can be either tree or graph defaults to graph * query - (string, optional) a json query filter to filter the graph components defaults to return all the graph query expression ~~~~~~~~~~~~~~~~ :: query := expression expression := simple_expression|complex_expression simple_expression := {simple_operator: {field_name: value}} simple_operator := = | != | < | <= | > | >= complex_expression := {complex_operator: [expression, expression, ...]} | not_expression not_expression := {not: expression} complex_operator := and | or Query example ^^^^^^^^^^^^^ POST /v1/topology/ { ""query"" : { ""or"": [ ""="": { ""type"":""host"" }, ""="": { ""type"":""vm"" } ] } ""graph_type"" : ""tree"" limit : 4 } ","GET /v1.0/topology/ ~~~~~~~~~~~~~~~~~~~- edges (string(255), optional) - name of edges to filter. - vertices (string, optional) - name of vertices to filter. - depth (int, optional) - the depth of graph required. - graph type ([tree,graph], optional) - The type of graph required defaults to graphNone. Request Examples ^^^^^^^^^^^^^^^^ GET /v1/topology/?graph_type=tree&depth=4&edges=vm&edges=host&edges=zone &vertices=contains",44,12
openstack%2Fproject-config~master~Iae0741782e9004715d65bd5799ad502ca641a84f,openstack/project-config,master,Iae0741782e9004715d65bd5799ad502ca641a84f,Specify master branch for the devstack plugins periodic job,MERGED,2016-02-15 22:02:19.000000000,2016-02-16 07:20:07.000000000,2016-02-16 07:20:07.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-15 22:02:19.000000000', 'files': ['jenkins/jobs/devstack.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0253d28c5022e5b957ddfd55a7f9ba3ab5794b6a', 'message': 'Specify master branch for the devstack plugins periodic job\n\nChange-Id: Iae0741782e9004715d65bd5799ad502ca641a84f\n'}]",0,280425,0253d28c5022e5b957ddfd55a7f9ba3ab5794b6a,8,3,1,16272,,,0,"Specify master branch for the devstack plugins periodic job

Change-Id: Iae0741782e9004715d65bd5799ad502ca641a84f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/280425/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack.yaml'],1,0253d28c5022e5b957ddfd55a7f9ba3ab5794b6a,autogen-devstack-plugins-list, - branch-git-prep: branch: master,,2,0
openstack%2Fproject-config~master~I6af12ce0030797f815d9a71c5a38b9ed51e22d80,openstack/project-config,master,I6af12ce0030797f815d9a71c5a38b9ed51e22d80,Normalize projects.yaml,MERGED,2016-02-16 06:37:10.000000000,2016-02-16 07:17:35.000000000,2016-02-16 07:17:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-16 06:37:10.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/74b89ba10f02c7e4566e56371e30fd1bdf94da7f', 'message': 'Normalize projects.yaml\n\nChange-Id: I6af12ce0030797f815d9a71c5a38b9ed51e22d80\n'}]",0,280516,74b89ba10f02c7e4566e56371e30fd1bdf94da7f,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I6af12ce0030797f815d9a71c5a38b9ed51e22d80
",git fetch https://review.opendev.org/openstack/project-config refs/changes/16/280516/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,74b89ba10f02c7e4566e56371e30fd1bdf94da7f,project-yaml-normalization, description: broadview-lib provides an API for interaction with Broadcom BroadView agents., upstream: https://github.com/pabelanger/ansible-role-nginx.git description: broadview-lib provides an API for interaction with Broadcom BroadView agents. upstream: https://github.com/redhat-openstack/puppet-pacemaker.git,2,3
openstack%2Fproject-config~master~I5a878b586c256ece6d5699bb653737709e0fff64,openstack/project-config,master,I5a878b586c256ece6d5699bb653737709e0fff64,Change networking-ovn rally job to use devstackgaterc,MERGED,2016-02-14 06:37:55.000000000,2016-02-16 07:14:41.000000000,2016-02-16 07:14:41.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-14 06:37:55.000000000', 'files': ['jenkins/jobs/networking-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3c1657eca450d82eadcb545c535047c58cf3744c', 'message': 'Change networking-ovn rally job to use devstackgaterc\n\nOther jobs take the enabled services from the devstackrgaterc\nfile in the networking-ovn repository.\nconvert the rally job to do the same\n\nChange-Id: I5a878b586c256ece6d5699bb653737709e0fff64\n'}]",3,279927,3c1657eca450d82eadcb545c535047c58cf3744c,11,5,1,11343,,,0,"Change networking-ovn rally job to use devstackgaterc

Other jobs take the enabled services from the devstackrgaterc
file in the networking-ovn repository.
convert the rally job to do the same

Change-Id: I5a878b586c256ece6d5699bb653737709e0fff64
",git fetch https://review.opendev.org/openstack/project-config refs/changes/27/279927/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/networking-ovn.yaml'],1,3c1657eca450d82eadcb545c535047c58cf3744c,, export DEVSTACK_GATE_SETTINGS=/opt/stack/new/networking-ovn/devstack/devstackgaterc," export OVERRIDE_ENABLED_SERVICES=key,rally,n-api,n-cpu,n-cond,n-sch,n-crt,n-cauth,g-api,g-reg,rabbit,tempest,mysql,dstat,ovn-northd,ovn-controller,q-svc,q-dhcp,q-l3 # n-obj has been removed from mitaka if [[ ""stable/kilo stable/liberty"" =~ $ZUUL_BRANCH ]]; then OVERRIDE_ENABLED_SERVICES+=,n-obj, fi export OVERRIDE_ENABLED_SERVICES",1,6
openstack%2Fproject-config~master~I701d9ab8f7087a4ffea71bf034885dca809543a9,openstack/project-config,master,I701d9ab8f7087a4ffea71bf034885dca809543a9,puppet-ceph: do not run integ jobs for scenario002,MERGED,2016-02-09 20:25:23.000000000,2016-02-16 07:14:12.000000000,2016-02-16 07:14:12.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 8797}, {'_account_id': 9061}]","[{'number': 1, 'created': '2016-02-09 20:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/68f3f14d42e3fe85a1ce21a11c3011f24b5daf92', 'message': ""puppet-ceph: do not run integ jobs for scenario002\n\nIn Puppet OpenStack Integration CI, we install puppet-ceph on\nscenario001 but not on scenario002\n\nTo save nodes, this patch will avoid to run useless jobs that won't run\nCeph for puppet-ceph gating.\n\n[1] https://github.com/openstack/puppet-openstack-integration#description\n\nChange-Id: I701d9ab8f7087a4ffea71bf034885dca809543a9\n""}, {'number': 2, 'created': '2016-02-15 22:48:23.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/09ea7fd874a2a140c4ffa24c69d0daf596de1c04', 'message': ""puppet-ceph: do not run integ jobs for scenario002\n\nIn Puppet OpenStack Integration CI, we install puppet-ceph on\nscenario001 but not on scenario002\n\nTo save nodes, this patch will avoid to run useless jobs that won't run\nCeph for puppet-ceph gating.\n\n[1] https://github.com/openstack/puppet-openstack-integration#description\n\nChange-Id: I701d9ab8f7087a4ffea71bf034885dca809543a9\n""}]",0,278072,09ea7fd874a2a140c4ffa24c69d0daf596de1c04,13,6,2,3153,,,0,"puppet-ceph: do not run integ jobs for scenario002

In Puppet OpenStack Integration CI, we install puppet-ceph on
scenario001 but not on scenario002

To save nodes, this patch will avoid to run useless jobs that won't run
Ceph for puppet-ceph gating.

[1] https://github.com/openstack/puppet-openstack-integration#description

Change-Id: I701d9ab8f7087a4ffea71bf034885dca809543a9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/278072/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,68f3f14d42e3fe85a1ce21a11c3011f24b5daf92,puppet/ceph, # ceph is only installed on scenario001 - name: ^gate-puppet-openstack-integration-scenario002-tempest-dsvm-.*$ skip-if: - project: ^openstack/puppet-ceph ,,5,0
openstack%2Fnova~stable%2Fliberty~Ideecab1c21b240bcca71973ed74b0374afb20e5e,openstack/nova,stable/liberty,Ideecab1c21b240bcca71973ed74b0374afb20e5e,Disable IPv6 on bridge devices,MERGED,2016-02-01 17:18:43.000000000,2016-02-16 07:12:19.000000000,2016-02-16 06:04:45.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 11255}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-02-01 17:18:43.000000000', 'files': ['nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/libvirt/test_vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/44401727235c5a9736c4229f7fc581e6a970ff91', 'message': ""Disable IPv6 on bridge devices\n\nThe qbr bridge should not have any IPv6 addresses, either\nlink-local, or on the tenant's private network due to the\nbridge processing Router Advertisements from Neutron and\nauto-configuring addresses, since it will allow access to\nthe hypervisor from a tenant VM.\n\nThe bridge only exists to allow the Neutron security group\ncode to work with OVS, so we can safely disable IPv6 on it.\n\nCloses-bug: 1470931\nPartial-bug: 1302080\n\nConflicts:\n\tnova/tests/unit/virt/libvirt/test_vif.py\n\nChange-Id: Ideecab1c21b240bcca71973ed74b0374afb20e5e\n(cherry picked from commit 5ab1b1b1c456b8b43edbd1bddd74b96b56ab80e6)\n""}]",0,274796,44401727235c5a9736c4229f7fc581e6a970ff91,19,7,1,16800,,,0,"Disable IPv6 on bridge devices

The qbr bridge should not have any IPv6 addresses, either
link-local, or on the tenant's private network due to the
bridge processing Router Advertisements from Neutron and
auto-configuring addresses, since it will allow access to
the hypervisor from a tenant VM.

The bridge only exists to allow the Neutron security group
code to work with OVS, so we can safely disable IPv6 on it.

Closes-bug: 1470931
Partial-bug: 1302080

Conflicts:
	nova/tests/unit/virt/libvirt/test_vif.py

Change-Id: Ideecab1c21b240bcca71973ed74b0374afb20e5e
(cherry picked from commit 5ab1b1b1c456b8b43edbd1bddd74b96b56ab80e6)
",git fetch https://review.opendev.org/openstack/nova refs/changes/96/274796/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/vif.py', 'nova/tests/unit/virt/libvirt/test_vif.py']",2,44401727235c5a9736c4229f7fc581e6a970ff91,bug/1470931,"import os def _test_plug_ovs_hybrid(self, ipv6_exists): check_exit_code=[0, 1])], # The disable_ipv6 call needs to be added in the middle, if required if ipv6_exists: calls['execute'].extend([ mock.call('tee', ('/proc/sys/net/ipv6/conf' '/qbrvif-xxx-yyy/disable_ipv6'), process_input='1', run_as_root=True, check_exit_code=[0, 1])]) calls['execute'].extend([ mock.call('ip', 'link', 'set', 'qbrvif-xxx-yyy', 'up', run_as_root=True), mock.call('brctl', 'addif', 'qbrvif-xxx-yyy', 'qvbvif-xxx-yyy', run_as_root=True)]) mock.patch.object(linux_net, 'create_ovs_vif_port'), mock.patch.object(os.path, 'exists', return_value=ipv6_exists) ) as (device_exists, execute, _create_veth_pair, create_ovs_vif_port, path_exists): def test_plug_ovs_hybrid_ipv6(self): self._test_plug_ovs_hybrid(ipv6_exists=True) def test_plug_ovs_hybrid_no_ipv6(self): self._test_plug_ovs_hybrid(ipv6_exists=False) mock.call('tee', ('/proc/sys/net/ipv6/conf' '/qbrvif-xxx-yyy/disable_ipv6'), process_input='1', run_as_root=True, check_exit_code=[0, 1]), mock.patch.object(linux_net, 'create_ivs_vif_port'), mock.patch.object(os.path, 'exists', return_value=True) ) as (device_exists, execute, _create_veth_pair, create_ivs_vif_port, path_exists):"," def test_plug_ovs_hybrid(self): check_exit_code=[0, 1]), mock.call('ip', 'link', 'set', 'qbrvif-xxx-yyy', 'up', run_as_root=True), mock.call('brctl', 'addif', 'qbrvif-xxx-yyy', 'qvbvif-xxx-yyy', run_as_root=True)], mock.patch.object(linux_net, 'create_ovs_vif_port') ) as (device_exists, execute, _create_veth_pair, create_ovs_vif_port): mock.patch.object(linux_net, 'create_ivs_vif_port') ) as (device_exists, execute, _create_veth_pair, create_ivs_vif_port):",40,10
openstack%2Fneutron~master~I641cee523068ec6824ae5243208a8ffd68331f5c,openstack/neutron,master,I641cee523068ec6824ae5243208a8ffd68331f5c,Cleanup unused conf variables,MERGED,2016-02-16 01:04:11.000000000,2016-02-16 07:11:51.000000000,2016-02-16 07:11:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-02-16 01:04:11.000000000', 'files': ['neutron/tests/api/test_extension_driver_port_security.py', 'neutron/tests/api/test_qos.py', 'neutron/tests/api/test_address_scopes.py', 'neutron/tests/api/test_subnetpools.py', 'neutron/tests/api/test_subnetpools_negative.py', 'neutron/tests/api/admin/test_shared_network_extension.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/10b8243dc4802408212a4717fd5e12120127c367', 'message': 'Cleanup unused conf variables\n\nI noticed in nova that we had a lot of unused conf variables. I\nwondered if this was a thing in other projects as well. Turns out\nit is.\n\nChange-Id: I641cee523068ec6824ae5243208a8ffd68331f5c\n'}]",0,280459,10b8243dc4802408212a4717fd5e12120127c367,21,6,1,2271,,,0,"Cleanup unused conf variables

I noticed in nova that we had a lot of unused conf variables. I
wondered if this was a thing in other projects as well. Turns out
it is.

Change-Id: I641cee523068ec6824ae5243208a8ffd68331f5c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/280459/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/api/test_extension_driver_port_security.py', 'neutron/tests/api/test_qos.py', 'neutron/tests/api/test_address_scopes.py', 'neutron/tests/api/test_subnetpools.py', 'neutron/tests/api/test_subnetpools_negative.py', 'neutron/tests/api/admin/test_shared_network_extension.py']",6,10b8243dc4802408212a4717fd5e12120127c367,unused_conf,,from neutron.tests.tempest import config CONF = config.CONF,1,15
openstack%2Fceilometer~master~I4bcf9283912e857a9902c62df25d0d5090670b10,openstack/ceilometer,master,I4bcf9283912e857a9902c62df25d0d5090670b10,Set None explicitly to filter options.,MERGED,2016-02-02 07:40:13.000000000,2016-02-16 07:10:04.000000000,2016-02-16 07:10:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 8290}, {'_account_id': 8358}, {'_account_id': 10987}, {'_account_id': 18895}]","[{'number': 1, 'created': '2016-02-02 07:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/f2dd036402a5f47562eb36881a7771c0897c2101', 'message': ""Set None explicitly to filter options.\n\nWhen user is set to None in query, string value 'None'\nwas set instead of None.\n\nNote: This fix is for mysql.\nFix for mongo is provided in:\nhttps://review.openstack.org/#/c/260331/\n\nChange-Id: I4bcf9283912e857a9902c62df25d0d5090670b10\nPartial-Bug: #1388680\n""}, {'number': 2, 'created': '2016-02-02 10:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e558ca92b27080f41571afb30d1619bd62fc6095', 'message': ""Set None explicitly to filter options.\n\nWhen user is set to None in query, string value 'None'\nwas set instead of None.\n\nNote: This fix is for mysql.\nFix for mongo is provided in:\nhttps://review.openstack.org/#/c/260331/\n\nChange-Id: I4bcf9283912e857a9902c62df25d0d5090670b10\nPartial-Bug: #1388680\n""}, {'number': 3, 'created': '2016-02-11 14:27:03.000000000', 'files': ['ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/impl_sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c25c0447419e787facbec11ee96a692be589cee0', 'message': ""Set None explicitly to filter options.\n\nWhen user is set to None in query, string value 'None'\nwas set instead of None.\n\nNote: This fix is for mysql.\nFix for mongo is provided in:\nhttps://review.openstack.org/#/c/260331/\n\nNote2: Here, test for resource_id is removed as,\nin sqlalchemy implementation, resource_id cannot be None.\n\nChange-Id: I4bcf9283912e857a9902c62df25d0d5090670b10\nPartial-Bug: #1388680\n""}]",1,275054,c25c0447419e787facbec11ee96a692be589cee0,16,9,3,18895,,,0,"Set None explicitly to filter options.

When user is set to None in query, string value 'None'
was set instead of None.

Note: This fix is for mysql.
Fix for mongo is provided in:
https://review.openstack.org/#/c/260331/

Note2: Here, test for resource_id is removed as,
in sqlalchemy implementation, resource_id cannot be None.

Change-Id: I4bcf9283912e857a9902c62df25d0d5090670b10
Partial-Bug: #1388680
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/54/275054/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/functional/storage/test_impl_sqlalchemy.py', 'ceilometer/storage/impl_sqlalchemy.py']",2,f2dd036402a5f47562eb36881a7771c0897c2101,bug/1388680, if sample_filter.user is not None: if sample_filter.user == 'None': sample_filter.user = None if sample_filter.project is not None: if sample_filter.project == 'None': sample_filter.project = None if sample_filter.resource is not None: if sample_filter.resource == 'None': sample_filter.resource = None, if sample_filter.user: if sample_filter.project: if sample_filter.resource:,77,3
openstack%2Fbarbican~master~Ia192b78384a1e32918169f6ca73f24eeaba6a611,openstack/barbican,master,Ia192b78384a1e32918169f6ca73f24eeaba6a611,Use local images instead of references,MERGED,2016-02-07 21:42:49.000000000,2016-02-16 07:03:51.000000000,2016-02-16 07:03:51.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 6783}, {'_account_id': 10873}, {'_account_id': 12920}, {'_account_id': 14926}, {'_account_id': 15274}]","[{'number': 1, 'created': '2016-02-07 21:42:49.000000000', 'files': ['doc/source/images/barbican-components.gif', 'doc/source/images/barbican-overall-architecture.gif', 'doc/source/contribute/architecture.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6d541ffa284f9d5898031053cd069b80a42e06e3', 'message': ""Use local images instead of references\n\nIn doc/source/contribute/architecture.rst, there's reference to\n.gif files hosted at rackcdn.com. This is considered a privacy\nbreach in Debian. This patch uses local images rather than a\nreference.\n\nChange-Id: Ia192b78384a1e32918169f6ca73f24eeaba6a611\nCloses-Bug: 1537346\n""}]",0,277202,6d541ffa284f9d5898031053cd069b80a42e06e3,11,7,1,16046,,,0,"Use local images instead of references

In doc/source/contribute/architecture.rst, there's reference to
.gif files hosted at rackcdn.com. This is considered a privacy
breach in Debian. This patch uses local images rather than a
reference.

Change-Id: Ia192b78384a1e32918169f6ca73f24eeaba6a611
Closes-Bug: 1537346
",git fetch https://review.opendev.org/openstack/barbican refs/changes/02/277202/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/images/barbican-components.gif', 'doc/source/images/barbican-overall-architecture.gif', 'doc/source/contribute/architecture.rst']",3,6d541ffa284f9d5898031053cd069b80a42e06e3,bug/1537346,.. image:: ./../images/barbican-overall-architecture.gif.. image:: ./../images/barbican-components.gif,.. image:: http://0a5aa9029f70acecc898-b578de5fa5a4bf8c8b1d7c616994834b.r11.cf1.rackcdn.com/barbican-overall-architecture.gif.. image:: http://0a5aa9029f70acecc898-b578de5fa5a4bf8c8b1d7c616994834b.r11.cf1.rackcdn.com/barbican-components.gif,2,2
openstack%2Fkeystone~master~Icddd0cd72d8592d00651de14cc451b160e224ff7,openstack/keystone,master,Icddd0cd72d8592d00651de14cc451b160e224ff7,Fixes parameter in duplicate project name creation,MERGED,2016-02-15 23:57:09.000000000,2016-02-16 06:50:57.000000000,2016-02-16 06:50:57.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17591}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-02-15 23:57:09.000000000', 'files': ['keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/6ccabf7017ebc779b5ccc1bf990c3f2faf22967e', 'message': 'Fixes parameter in duplicate project name creation\n\nThis patches passes the correct project_id to a call that\nexpects to receive a Conflict. The test worked beause the\nConflict happened due to an ID conflict, instead of a\nname conflict, as the test expects.\n\nChange-Id: Icddd0cd72d8592d00651de14cc451b160e224ff7\n'}]",0,280448,6ccabf7017ebc779b5ccc1bf990c3f2faf22967e,14,4,1,10046,,,0,"Fixes parameter in duplicate project name creation

This patches passes the correct project_id to a call that
expects to receive a Conflict. The test worked beause the
Conflict happened due to an ID conflict, instead of a
name conflict, as the test expects.

Change-Id: Icddd0cd72d8592d00651de14cc451b160e224ff7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/48/280448/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_backend.py'],1,6ccabf7017ebc779b5ccc1bf990c3f2faf22967e,," project['id'],"," project_id,",1,1
openstack%2Fpython-ironicclient~master~Iad7c87aed7aa2c41a8174a97dfce9633e6266627,openstack/python-ironicclient,master,Iad7c87aed7aa2c41a8174a97dfce9633e6266627,Add '--node' to port-list,ABANDONED,2015-11-17 06:58:51.000000000,2016-02-16 06:48:50.000000000,,"[{'_account_id': 3}, {'_account_id': 8106}, {'_account_id': 10439}, {'_account_id': 13362}, {'_account_id': 14810}]","[{'number': 1, 'created': '2015-11-17 06:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9919de217a85288facef58400fc91946caf1bc75', 'message': ""Add '--node' to port-list to support list port with this node\n\nAdd '--node' parameter to port-list. This will only list all nodes\nbind to the node, which can be name or UUID of this node.\n\nChange-Id: Iad7c87aed7aa2c41a8174a97dfce9633e6266627\n""}, {'number': 2, 'created': '2015-11-18 02:31:32.000000000', 'files': ['ironicclient/tests/unit/v1/test_port.py', 'ironicclient/tests/unit/v1/test_port_shell.py', 'ironicclient/v1/port_shell.py', 'ironicclient/v1/port.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/3c262855439e223ca37280a26d6b45598844f5f9', 'message': ""Add '--node' to port-list\n\nAdd '--node' parameter to port-list. This will only list ports\nbind to the node. `node` can be name or UUID of this node.\n\nThis seems a duplicate functionality to node-port-list, but as\nIronic service provides both of them: '/v1/nodes/%(node)s/ports'\nand '/v1/ports/?node=%(node)s', it is better to explore both\nand let users choose by themselfs.\n\nChange-Id: Iad7c87aed7aa2c41a8174a97dfce9633e6266627\n""}]",6,246216,3c262855439e223ca37280a26d6b45598844f5f9,10,5,2,13362,,,0,"Add '--node' to port-list

Add '--node' parameter to port-list. This will only list ports
bind to the node. `node` can be name or UUID of this node.

This seems a duplicate functionality to node-port-list, but as
Ironic service provides both of them: '/v1/nodes/%(node)s/ports'
and '/v1/ports/?node=%(node)s', it is better to explore both
and let users choose by themselfs.

Change-Id: Iad7c87aed7aa2c41a8174a97dfce9633e6266627
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/16/246216/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/unit/v1/test_port.py', 'ironicclient/tests/unit/v1/test_port_shell.py', 'ironicclient/v1/port_shell.py', 'ironicclient/v1/port.py']",4,9919de217a85288facef58400fc91946caf1bc75,port_list," def list(self, node=None, address=None, limit=None, marker=None, sort_key=None, sort_dir=None, detail=False, fields=None): :param node: Optional, Name or UUID of a node, Only show ports for this node. if node is not None: filters.append('node=%s' % node) "," def list(self, address=None, limit=None, marker=None, sort_key=None, sort_dir=None, detail=False, fields=None):",56,5
openstack%2Fopenstack-manuals~stable%2Fliberty~I260733556a54740b9762eff6d8e57a9106e3709c,openstack/openstack-manuals,stable/liberty,I260733556a54740b9762eff6d8e57a9106e3709c,Imported Translations from Zanata,MERGED,2016-02-16 06:11:22.000000000,2016-02-16 06:43:01.000000000,2016-02-16 06:43:00.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-16 06:11:22.000000000', 'files': ['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e1776d783efb855711954d956eacba75d37252b1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I260733556a54740b9762eff6d8e57a9106e3709c\n'}]",0,280510,e1776d783efb855711954d956eacba75d37252b1,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I260733556a54740b9762eff6d8e57a9106e3709c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/10/280510/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'],1,e1776d783efb855711954d956eacba75d37252b1,zanata/translations,"""PO-Revision-Date: 2016-02-15 04:00+0000\n""""Before you install and configure the Compute service, you must create a "" ""database, service credentials, and API endpoints."" msgstr """" ""Avant d'installer et configurer le service Compute, vous devez créer une "" ""base de données, des credentials de service, et des endpoints API."" msgid """"""By default, Compute uses an internal firewall service. Since Networking "" ""includes a firewall service, you must disable the Compute firewall service "" ""by using the ``nova.virt.firewall.NoopFirewallDriver`` firewall driver."" msgstr """" ""Par défaut, Compute utilise un service de firewall interne. Comme le service "" ""Réseau inclut un service de firewall, vous devez désactiver le service de "" ""firewall Compute en utilisant le driver firewall ``nova.virt.firewall."" ""NoopFirewallDriver``."" msgid """"msgid """" ""Database population occurs later for Networking because the script requires "" ""complete server and plug-in configuration files."" msgstr """" ""Le remplissage de la base de données a lieu plus tard pour le service Réseau "" ""parce que le script a besoin des fichiers de configuration complets pour le "" ""serveur et les plugin."" msgid ""Ensure the kernel module ``nbd`` is loaded."" msgstr ""S'assurer que le module noyau ``nbd`` est chargé."" msgid """" ""Ensure the module will be loaded on every boot by adding ``nbd`` in the ``/"" ""etc/modules-load.d/nbd.conf`` file."" msgstr """" ""S'assurer que le module sera chargé à chaque boot en ajoutant ``nbd`` au "" ""fichier ``/etc/modules-load.d/nbd.conf``."" msgid ""For both networking options:"" msgstr ""Pour les 2 options de mise en réseau:"" msgid ""For networking option 2, also enable and start the layer-3 service:"" msgstr """" ""Pour le Réseau option 2, activer et démarrer également le service layer-3."" msgid ""For networking option 2, also restart the layer-3 service:"" msgstr ""Pour le Réseau option 2, redémarrer également le service layer-3."" ""If the web browser to access remote consoles resides on a host that cannot "" ""resolve the ``controller`` hostname, you must replace ``controller`` with "" ""the management interface IP address of the controller node."" msgstr """" ""Si le navigateur web pour accéder aux consoles distantes tourne sur un hôte "" ""qui ne peut pas résoudre le nom de host du ``controller``, vous devez "" ""remplacer ``controller`` par l'adresse IP de l'interface de management de "" ""votre nœud contrôleur. "" msgid """" ""If this command returns a value of ``one or greater``, your compute node "" ""supports hardware acceleration which typically requires no additional "" ""configuration."" msgstr """" ""Si la commande retourne une valeur de ``un ou plus``, votre nœud compute "" ""supporte l'accélération matérielle ce qui ne nécessite généralement aucune "" ""configuration complémentaire."" msgid """" ""If this command returns a value of ``zero``, your compute node does not "" ""support hardware acceleration and you must configure ``libvirt`` to use QEMU "" ""instead of KVM."" msgstr """" ""Si la commande retourne la valeur ``zero``, votre nœud compute ne supporte "" ""pas l'accélération matérielle et vous devez configurer ``libvirt`` pour "" ""utiliser QEMU à la place de KVM."" msgid """"msgid ""Ignore any warnings in this output."" msgstr ""Ignorer les warnings éventuels dans la sortie écran."" msgid """" ""Implement a deployment tool such as Ansible, Chef, Puppet, or Salt to "" ""automate deployment and management of the production environment."" msgstr """" ""Implémenter un outils de déploiement comme Ansible, Chef, Puppet, ou Salt "" ""pour automatiser les déploiements et la gestion de l'environnement de "" ""production. "" ""In the ``[DEFAULT]`` and [oslo_messaging_rabbit] sections, configure "" ""``RabbitMQ`` message queue access:"" msgstr """" ""Dans les sections ``[DEFAULT]`` et ``[oslo_messaging_rabbit]``, configurer "" ""l'accès à la file de messages ``RabbitMQ``:"" msgid """"""In the ``[DEFAULT]`` section, enable support for the Networking service:"" msgstr """" ""Dans la section ``[DEFAULT]``, activer le support du service de Réseau:"" msgid """"""In the ``[glance]`` section, configure the location of the Image service:"" msgstr """" ""Dans la section ``[glance]``, configurer l'emplacement du service d'Image:"" msgid """"msgid """" ""In the ``[vnc]`` section, configure the VNC proxy to use the management "" ""interface IP address of the controller node:"" msgstr """" ""Dans la section ``[vnc]``, configurer le proxy VNC pour utiliser l'adresse "" ""IP de l'interface de management du nœud contrôleur:"" msgid ""In the ``[vnc]`` section, enable and configure remote console access:"" msgstr """" ""Dans la section ``[vnc]``, activer et configurer l'accès à la console "" ""distante:"" msgid """" ""Increase security using methods such as firewalls, encryption, and service "" ""policies."" msgstr """" ""Accroitre la sécurité en utilisant des méthodes comme les firewalls, le "" ""chiffrement, et les politiques de service."" msgid """" ""List API endpoints in the Identity service to verify connectivity with the "" ""Identity service:"" msgstr """" ""Lister les endpoints API du service d'Identité pour vérifier la connectivité "" ""avec le service d'Identité:"" msgid ""List agents to verify successful launch of the neutron agents:"" msgstr ""Lister les agents pour vérifier le bon lancement des agents neutron:"" ""List images in the Image service catalog to verify connectivity with the "" ""Image service:"" msgstr """" ""Lister les images du catalogue de service d'Image pour vérifier la "" ""connectivité avec le service d'Image:"" msgid """" ""List loaded extensions to verify successful launch of the ``neutron-server`` "" ""process:"" msgstr """" ""Lister les extensions chargées pour vérifier le bon démarrage du processus "" ""``neutron-server``:"" msgid """"""OpenStack provides an :term:`Infrastructure-as-a-Service (IaaS)<IaaS>` "" ""solution through a variety of complemental services. Each service offers an :"" ""term:`application programming interface (API)<API>` that facilitates this "" ""integration."" msgstr """" ""OpenStack fournit une solution d':term:`Infrastructure-as-a-Service "" ""(IaaS)<IaaS>` à travers un éventail de services complémentaires. Chaque "" ""service offre une :term:`application programming interface (API)<API>` qui "" ""facilite cette intégration."" msgid """"""management network interface on your compute node, typically 10.0.0.31 for "" ""the first node in the :ref:`example architecture <overview-example-"" ""architectures>`."" msgstr """" ""Remplacer ``MANAGEMENT_INTERFACE_IP_ADDRESS`` par l'adresse IP de "" ""l'interface réseau de management de votre nœud compute, généralement "" ""10.0.0.31 pour le premier nœud dans l':ref:`exemple d'architecture <overview-"" ""example-architectures>`."" msgid """" ""Replace ``MANAGEMENT_INTERFACE_IP_ADDRESS`` with the IP address of the """"Start the Networking services and configure them to start when the system "" ""boots."" msgstr """" ""Démarrer les services réseau et les configurer pour démarrer au boot du "" ""système:"" msgid """"""The :term:`OpenStack` project is an open source cloud computing platform "" ""that supports all types of cloud environments. The project aims for simple "" ""implementation, massive scalability, and a rich set of features. Cloud "" ""computing experts from around the world contribute to the project."" msgstr """" ""Le projet :term:`OpenStack` est une plateforme de cloud computing open "" ""source qui supporte tout types d'environnements cloud. Le projet vise une "" ""implémentation simple, une scalabilité massive, et un ensemble varié de "" ""fonctionnalités. Des experts Cloud computing du monde entier contribuent au "" ""projet. "" msgid """"""The Networking service initialization scripts expect a symbolic link ``/etc/"" ""neutron/plugin.ini`` pointing to the ML2 plug-in configuration file, ``/etc/"" ""neutron/plugins/ml2/ml2_conf.ini``. If this symbolic link does not exist, "" ""create it using the following command:"" msgstr """" ""Les scripts d'initialisation du service Réseau s'attendent à trouver un lien "" ""symbolique ``/etc/neutron/plugin.ini`` pointant vers le fichier de "" ""configuration du plugin ML2, ``/etc/neutron/plugins/ml2/ml2_conf.ini``. Si "" ""ce lien symbolique n'existe pas, le créer à l'aide de la commande suivante:"" msgid """"""The output should indicate four agents on the controller node and one agent "" ""on each compute node."" msgstr """" ""La sortie d'écran devrait indiquer quatre agents sur le nœud contrôleur et "" ""un agent sur chaque nœud compute."" msgid """" ""The output should indicate three agents on the controller node and one agent "" ""on each compute node."" msgstr """" ""La sortie d'écran devrait indiquer trois agents sur le nœud contrôleur et un "" ""agent sur chaque nœud compute."" msgid """"""The server component listens on all IP addresses and the proxy component "" ""only listens on the management interface IP address of the compute node. The "" ""base URL indicates the location where you can use a web browser to access "" ""remote consoles of instances on this compute node."" msgstr """" ""Le composant serveur écoute sur toutes les adresses IP et le composant proxy "" ""écoute seulement sur l'adresse IP de l'interface de management du nœud "" ""compute. L'URL de base indique l'emplacement où vous pouvez utiliser un "" ""navigateur web pour accéder aux consoles distantes des instances sur ce nœud "" ""compute."" msgid """"""This chapter explains how to install and configure the OpenStack Networking "" ""service (neutron) using the :ref:`provider networks <network1>` or :ref:"" ""`self-service networks <network2>` option. For more information about the "" ""Networking service including virtual networking components, layout, and "" ""traffic flows, see the `Networking Guide <http://docs.openstack.org/liberty/"" ""networking-guide>`__."" msgstr """" ""Ce chapitre explique comment installer et configurer le service Réseau "" ""OpenStack (neutron) en utilisant l'option :ref:`réseaux fournisseur "" ""<network1>` ou :ref:`réseaux libre-service <network2>`. Pour plus "" ""d'informations sur le service de Mise en Réseau incluant les composants de "" ""réseau virtuel, la structure, et les flux de trafic, voir le `Guide "" ""Networking <http://docs.openstack.org/liberty/networking-guide>`__."" msgid """"msgid """" ""This guide covers step-by-step deployment of the following major OpenStack "" ""services using a functional example architecture suitable for new users of "" ""OpenStack with sufficient Linux experience:"" msgstr """" ""Ce guide couvre le déploiement pas à pas des services OpenStack principaux "" ""suivants, en utilisant un exemple d'architecture fonctionnelle adaptée à des "" ""nouveaux utilisateurs d'OpenStack ayant une expérience suffisante de Linux:"" ""This output should indicate four service components enabled on the "" ""controller node and one service component enabled on the compute node."" msgstr """" ""La sortie d'écran devrait indiquer quatre composants de service activés sur "" ""le nœud contrôleur et un composant de service activé sur le nœud compute."" msgid """"""This section assumes that you are following the instructions in this guide "" ""step-by-step to configure the first compute node. If you want to configure "" ""additional compute nodes, prepare them in a similar fashion to the first "" ""compute node in the :ref:`example architectures <overview-example-"" ""architectures>` section. Each additional compute node requires a unique IP "" ""address."" msgstr """" ""Cette section assume que vous suiviez pas à pas les instructions dans ce "" ""guide pour configurer le premier nœud compute. Si vous souhaitez configurer "" ""des nœuds compute supplémentaires, préparez-les de la même façon que le "" ""premier nœud compute dans la section :ref:`exemples d'architecture <overview-"" ""example-architectures>`. Chaque nœud supplémentaire nécessite une adresse IP "" ""unique."" msgid """"""This section describes how to install and configure the Compute service on a "" ""compute node. The service supports several :term:`hypervisors <hypervisor>` "" ""to deploy :term:`instances <instance>` or :term:`VMs <virtual machine "" ""(VM)>`. For simplicity, this configuration uses the :term:`QEMU <Quick "" ""EMUlator (QEMU)>` hypervisor with the :term:`KVM <kernel-based VM (KVM)>` "" ""extension on compute nodes that support hardware acceleration for virtual "" ""machines. On legacy hardware, this configuration uses the generic QEMU "" ""hypervisor. You can follow these instructions with minor modifications to "" ""horizontally scale your environment with additional compute nodes."" msgstr """" ""Cette section décrit comment installer et configurer le service Compute sur "" ""un nœud compute. Le service supporte plusieurs :term:`hyperviseurs "" ""<hypervisor>` pour déployer les :term:`instances <instance>` ou :term:`VMs "" ""<virtual machine (VM)>`. Pour simplifier, cette configuration utilise "" ""l'hyperviseur :term:`QEMU <Quick EMUlator (QEMU)>` avec l'extension :term:"" ""`KVM <kernel-based VM (KVM)>` sur des nœuds compute qui supportent "" ""l'accélération hardware pour les machines virtuelles. Sur du matériel "" ""ancien, cette configuration utilise l'hyperviseur générique QEMU. Vous "" ""pouvez aussi suivre ces instructions avec peu de modifications pour scaler "" ""horizontalement votre environnement avec des nœuds compute additionnels."" msgid """"msgid """" ""Use the verification section for the networking option that you chose to "" ""deploy."" msgstr """" ""Utiliser la section de vérification pour l'option réseau que vous avez "" ""choisie de déployer."" #, fuzzy msgid """" ""Your OpenStack environment now includes the core components necessary to "" ""launch a basic instance. You can :ref:`launch-instance` or add more "" ""OpenStack services to your environment."" msgstr """" ""Votre environnement OpenStack inclut maintenant les composants essentiels "" ""nécessaires au lancement d'une instance basique. Vous pouvez :ref:`launch-"" ""instance` ou ajouter d'autres services OpenStack à votre environnement."" msgid """" ""`Block Storage <http://www.openstack.org/software/releases/liberty/"" ""components/cinder>`_"" msgstr """" ""`Stockage par Blocs <http://www.openstack.org/software/releases/liberty/"" ""components/cinder>`_"" ","""PO-Revision-Date: 2016-02-15 12:15+0000\n""",315,1
openstack%2Fneutron~master~I5a718749dd171ccdc1fa30aff4d36e26cbd3f633,openstack/neutron,master,I5a718749dd171ccdc1fa30aff4d36e26cbd3f633,Fix RuntimeError when dnsmasq_config_file is not given,ABANDONED,2016-02-08 01:15:20.000000000,2016-02-16 06:18:49.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14562}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-08 01:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7cf71183e1fa209907e82828a34f2a09a392c30', 'message': 'Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n'}, {'number': 2, 'created': '2016-02-08 03:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/737dae9bf88779d84fb4c17eef33f80b00dd4251', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}, {'number': 3, 'created': '2016-02-08 06:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf44ec094a6593f41f353608178b450c4f7c1b03', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}, {'number': 4, 'created': '2016-02-09 01:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a563bdde63a65b84b563120a81551be406e26115', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}, {'number': 5, 'created': '2016-02-10 01:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/10e51f0e9e097ac2fae1c5e814088234b206e6b0', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}, {'number': 6, 'created': '2016-02-11 01:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d45ded4436051c29da6dd9e1ffee0e54b1fec68', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}, {'number': 7, 'created': '2016-02-15 08:29:36.000000000', 'files': ['neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a37dcd2a728f2e4fe372d5970edb619d2e6f2a99', 'message': ""Fix RuntimeError when dnsmasq_config_file is not given\n\nWe should check whether the configuration named dnsmasq_config_file\nexists.\n\nIf dnsmasq_config_file doesn't exists, RuntimeError will happen.\n\nCloses-Bug: #1542962\nChange-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633\n""}]",9,277218,a37dcd2a728f2e4fe372d5970edb619d2e6f2a99,107,21,7,14562,,,0,"Fix RuntimeError when dnsmasq_config_file is not given

We should check whether the configuration named dnsmasq_config_file
exists.

If dnsmasq_config_file doesn't exists, RuntimeError will happen.

Closes-Bug: #1542962
Change-Id: I5a718749dd171ccdc1fa30aff4d36e26cbd3f633
",git fetch https://review.opendev.org/openstack/neutron refs/changes/18/277218/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/dhcp.py'],1,b7cf71183e1fa209907e82828a34f2a09a392c30,bug/1542962, if os.path.exists(self.conf.dnsmasq_config_file): cmd.append('--conf-file=%s' % self.conf.dnsmasq_config_file), cmd.append('--conf-file=%s' % self.conf.dnsmasq_config_file),2,1
openstack%2Fha-guide~master~Iaee6b96bcf5e033348ba3e9fc74ea76396823464,openstack/ha-guide,master,Iaee6b96bcf5e033348ba3e9fc74ea76396823464,Imported Translations from Zanata,MERGED,2016-02-16 06:00:36.000000000,2016-02-16 06:09:59.000000000,2016-02-16 06:09:59.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-16 06:00:36.000000000', 'files': ['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/f89e05b73061d8da725ed5dc71b42a8b67a82c27', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Iaee6b96bcf5e033348ba3e9fc74ea76396823464\n'}]",0,280507,f89e05b73061d8da725ed5dc71b42a8b67a82c27,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Iaee6b96bcf5e033348ba3e9fc74ea76396823464
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/07/280507/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po'],1,f89e05b73061d8da725ed5dc71b42a8b67a82c27,zanata/translations,"""PO-Revision-Date: 2016-02-16 05:53+0000\n""msgid """" ""**wsrep Provider** The Galera Replication Plugin serves as the wsrep "" ""Provider for Galera Cluster. It is installed on your system as the "" ""``libgalera_smm.so`` file. You must define the path to this file in your "" ""``my.cnf``."" msgstr """" ""**wsrep Provider** Galera Replication Plugin は、Galera Cluster の wsrep "" ""Provider として動作します。お使いのシステムに ``libgalera_smm.so`` ファイルと"" ""してインストールされます。このファイルへのパスを ``my.cnf`` に定義する必要が"" ""あります。"" msgid """" ""A sample votequorum service configuration in the :file:`corosync.com` file "" ""is:"" msgstr "":file:`corosync.com` ファイルの votequorum サービス設定例:"" msgid """" ""Add the repository to your sources list. Using your preferred text editor, "" ""create a ``galera.list`` file in the ``/etc/apt/sources.list.d/`` directory. "" ""For the contents of this file, use the lines that pertain to the software "" ""repository you want to install:"" msgstr """" ""リポジトリーをソースリストに追加します。お好きなテキストエディターを使用し"" ""て、``/etc/apt/sources.list.d/`` ディレクトリーに ``galera.list`` を作成しま"" ""す。このファイルの内容は、インストールしたいソフトウェアリポジトリーに関する"" ""行を使用します。"" msgid """" ""Bear in mind, while setting this parameter to ``1`` or ``2`` can improve "" ""performance, it introduces certain dangers. Operating system failures can "" ""erase the last second of transactions. While you can recover this data from "" ""another node, if the cluster goes down at the same time (in the event of a "" ""data center power outage), you lose this data permanently."" msgstr """" ""このパラメーターを ``1`` か ``2`` に設定することにより、性能を改善できます"" ""が、ある種の危険性があることを覚えておいてください。オペレーティングシステム"" ""の障害が、最後の数秒のトランザクションを消去する可能性があります。このデータ"" ""を他のノードから復旧することもできますが、クラスターが同時に停止した場合 "" ""(データセンターの電源障害時)、このデータを完全に失います。"" msgid """" ""By default, cluster nodes do not start as part of a Primary Component. "" ""Instead they assume that one exists somewhere and attempts to establish a "" ""connection with it. To create a Primary Component, you must start one "" ""cluster node using the ``--wsrep-new-cluster`` option. You can do this using "" ""any cluster node, it is not important which you choose. In the Primary "" ""Component, replication and state transfers bring all databases to the same "" ""state."" msgstr """" ""クラスターノードは、デフォルトで Primary Component の一部として起動しません。"" ""代わりに、それがどこかに存在すると仮定し、そこへの接続を確立しようとします。"" ""1 つのクラスターノードを ``--wsrep-new-cluster``オプションを付けて起動して、"" ""Primary Component を作成する必要があります。任意のクラスターノードを使用して"" ""実行でき、どれを選択するかは重要ではありません。Primary Component において、"" ""レプリケーションと状態転送により、すべてのデータベースが同じ状態になります。"" ""Ceph RBD provides object replication capabilities by storing Block Storage "" ""volumes as Ceph RBD objects; Ceph RBD ensures that each replica of an object "" ""is stored on a different node. This means that your volumes are protected "" ""against hard drive and node failures or even the failure of the data center "" ""itself."" msgstr """" ""Ceph RBD は、Ceph RBD オブジェクトとして Block Storage のボリュームを保存する"" ""ことにより、オブジェクトレプリケーション機能を提供します。オブジェクトの各レ"" ""プリカが別々のノードに保存されることを保証します。このことは、お使いのボ"" ""リュームがハードディスクやノードの障害時、データセンター自体の障害時にも保護"" ""されることを意味します。"" msgid """"msgid """" ""Each configured interface must have a unique ``ringnumber``, starting with 0."" msgstr """" ""設定済みの各インターフェースは、0 から始まる一意な ``ringnumber`` を持つ必要"" ""があります。"" msgid """" ""Ephemeral storage is allocated for an instance and is deleted when the "" ""instance is deleted. The Compute service manages ephemeral storage. By "" ""default, Compute stores ephemeral drives as files on local disks on the "" ""Compute node but Ceph RBD can instead be used as the storage back end for "" ""ephemeral storage."" msgstr """" ""一時ストレージは、インスタンスのために割り当てられ、インスタンスの削除時に削"" ""除されます。Compute サービスが一時ストレージを管理します。Compute はデフォル"" ""トで、コンピュートノードのローカルディスクにファイルとして一時ディスクを保存"" ""します。代わりに、Ceph RBD が一時ストレージのストレージバックエンドとして使用"" ""できます。"" ""For detailed instructions about installing HAProxy on your nodes, see its "" ""`official documentation <http://www.haproxy.org/#docs>`_."" msgstr """" ""お使いのノードに HAProxy をインストールする方法の詳細は `公式ドキュメント "" ""<http://www.haproxy.org/#docs>`_ を参照してください。"" msgid """"""In the event that you already installed the standalone version of MySQL, "" ""MariaDB or Percona XtraDB, this installation purges all privileges on your "" ""OpenStack database server. You must reapply the privileges listed in the "" ""installation guide."" msgstr """" ""すでに MySQL、MariaDB、Percona XtraDB のスタンドアロン版をインストールしてい"" ""る場合、このインストールにより、お使いの OpenStack データベースサーバーにおい"" ""て、すべての権限が削除されます。インストールガイドにまとめられている権限を再"" ""適用する必要があります。"" msgid """"""In the event that you need to restart any cluster node, you can do so. When "" ""the database server comes back it, it establishes connectivity with the "" ""Primary Component and updates itself to any changes it may have missed while "" ""down."" msgstr """" ""クラスターノードをどれか再起動する必要がある場合、実行できます。データベース"" ""サーバーが戻ってきたとき、Primary Component との接続を確立して、停止中に失っ"" ""た変更をすべて自身に適用します。"" msgid """"""In the text: Replace ``DISTRO`` with the name of the distribution you use, "" ""such as ``sles`` or ``opensuse``. Replace ``RELEASE`` with the version "" ""number of that distribution."" msgstr """" ""``DISTRO`` を使用する ``sles`` や ``opensuse`` などのディストリビューションの"" ""名前で置き換えます。 ``RELEASE`` をディストリビューションのバージョン番号に置"" ""き換えます。"" msgid """" ""In the text: Replace ``VERSION`` with the version of MariaDB you want to "" ""install, such as ``5.6`` or ``10.0``. Replace package with the package "" ""architecture you want to use, such as ``opensuse13-amd64``."" msgstr """" ""テキストにおいて、インストールしたい MariaDB のバージョン、``5.6`` や "" ""``10.0`` などで ``VERSION`` を置き換えます。使用したいパッケージアーキテク"" ""チャー、``opensuse13-amd64`` などで package を置き換えます。"" msgid """"msgid """" ""Initialize the Primary Component on one cluster node. For servers that use "" ""``init``, run the following command:"" msgstr """" ""1 つのクラスターノードにおいて Primary Component を初期化します。``init`` を"" ""使用するサーバーの場合、以下のコマンドを実行します。"" msgid """" ""Memcached is a memory cache demon that can be used by most OpenStack "" ""services to store ephemeral data, such as tokens."" msgstr """" ""Memcached は、ほとんどの OpenStack サービスがトークンなどの一時的なデータを保"" ""存するために使用できる、メモリーキャッシュのデーモンです。"" ""Most of this guide concerns the control plane of high availability: ensuring "" ""that services continue to run even if a component fails. Ensuring that data "" ""is not lost is the data plane component of high availability; this is "" ""discussed here."" msgstr """" ""このガイドのほとんどは、コントロールプレーンの高可用性を取り扱います。コン"" ""ポーネントが故障した場合でも、そのサービスが動作しつづけることを保証します。"" ""データ失われないことを保証することは、データプレーンのコンポーネントの高可用"" ""性です。それは、ここで議論します。"" msgid """"""Once configured (see example file below), add HAProxy to the cluster and "" ""ensure the VIPs can only run on machines where HAProxy is active:"" msgstr """" ""設定すると (以下のサンプルファイル参照)、HAProxy をクラスターに追加して、仮"" ""想 IP が HAProxy の動作しているマシンにおいてのみ動作できることを確認してくだ"" ""さい。"" msgid """"msgid """" ""OpenStack services are configured with the list of these IP addresses so "" ""they can select one of the addresses from those available."" msgstr """" ""OpenStack サービスは、利用できるものから 1 つを選択できるよう、これらの IP ア"" ""ドレスの一覧を用いて設定されます。"" msgid """" ""Specifying ``corosync_votequorum`` enables the votequorum library; this is "" ""the only required option."" msgstr """" ""``corosync_votequorum`` を指定することにより、votequorum ライブラリーを有効化"" ""します。これは唯一の必須オプションです。"" ""The ``bindnetaddr`` is the network address of the interfaces to bind to. The "" ""example uses two network addresses of /24 IPv4 subnets."" msgstr """" ""``bindnetaddr`` は、バインドするインターフェースのネットワークアドレスです。"" ""この例は、2 つの /24 IPv4 サブネットを使用します。"" msgid """"msgid ""The steps to implement the Pacemaker cluster stack are:"" msgstr ""Pacemaker クラスタースタックを実行する手順は、次のとおりです。"" ""These agents must conform to one of the `OCF <https://github.com/"" ""ClusterLabs/ OCF-spec/blob/master/ra/resource-agent-api.md>`_, `SysV Init "" ""<http://refspecs.linux-foundation.org/LSB_3.0.0/LSB-Core-generic/ LSB-Core-"" ""generic/iniscrptact.html>`_, Upstart, or Systemd standards."" msgstr """" ""これらのエージェントは、 `OCF <https://github.com/ClusterLabs/ OCF-spec/blob/"" ""master/ra/resource-agent-api.md>`_, `SysV Init <http://refspecs.linux-"" ""foundation.org/LSB_3.0.0/LSB-Core-generic/ LSB-Core-generic/iniscrptact."" ""html>`_, Upstart, Systemd 標準に従う必要があります。"" msgid """"""This value increments with each transaction, so the most advanced node has "" ""the highest sequence number, and therefore is the most up to date."" msgstr """" ""この値は各トランザクションによりインクリメントされます。ほとんどの高度なノー"" ""ドは、最大のシーケンス番号を持つため、ほとんど最新です。"" msgid """"""Use the :command:`corosync-objctl` utility to dump the Corosync cluster "" ""member list:"" msgstr """" "":command:`corosync-objctl` ユーティリティーを使用して、Corosync クラスターの"" ""メンバー一覧を出力します。"" msgid """"""When each cluster node starts, it checks the IP addresses given to the "" ""``wsrep_cluster_address`` parameter and attempts to establish network "" ""connectivity with a database server running there. Once it establishes a "" ""connection, it attempts to join the Primary Component, requesting a state "" ""transfer as needed to bring itself into sync with the cluster."" msgstr """" ""各クラスターノードが起動したとき、``wsrep_cluster_address`` パラメーターに指"" ""定された IP アドレスを確認して、それで動作しているデータベースサーバーへの"" ""ネットワーク接続性を確立しようとします。接続が確立されると、クラスターを同期"" ""するために必要となる状態転送を要求する、Primary Component に参加しようとしま"" ""す。"" msgid """"""When you finish enabling the software repository for Galera Cluster, you can "" ""install it using your package manager. The particular command and packages "" ""you need to install varies depending on which database server you want to "" ""install and which Linux distribution you use:"" msgstr """" ""Galera Cluster のソフトウェアリポジトリーを有効化すると、パッケージマネー"" ""ジャーを使用してインストールできます。インストールに必要となる具体的なコマン"" ""ドやパッケージは、インストールしたいデータベースサーバーと使用する Linux ディ"" ""ストリビューションにより異なります。"" msgid """"""You can achieve high availability for the OpenStack database in many "" ""different ways, depending on the type of database that you want to use. "" ""There are three implementations of Galera Cluster available to you:"" msgstr """" ""使用したいデータベースの種類に応じて、さまざまな情報で OpenStack のデータベー"" ""スの高可用性を実現できます。Galera Cluster は 3 種類の実装があります。"" msgid """"msgid """" ""`Ceph RBD <http://ceph.com/>`_ is an innately high availability storage back "" ""end. It creates a storage cluster with multiple nodes that communicate with "" ""each other to replicate and redistribute data dynamically. A Ceph RBD "" ""storage cluster provides a single shared set of storage nodes that can "" ""handle all classes of persistent and ephemeral data -- glance, cinder, and "" ""nova -- that are required for OpenStack instances."" msgstr """" ""`Ceph RBD <http://ceph.com/>`_ は、本質的に高可用性なストレージバックエンドで"" ""す。複数のノードを用いてストレージクラスターを作成し、お互いに通信して動的に"" ""レプリケーションとデータ再配布を実行します。Ceph RBD ストレージクラスターは、"" ""OpenStack インスタンスに必要となる、すべての種類の永続データと一時データ "" ""(glance、cinder、nova) を取り扱える、単一の共有ストレージノードを提供します。"" ","""PO-Revision-Date: 2016-02-15 05:37+0000\n""",263,1
openstack%2Ffuel-web~master~Idc8cbb34934313c11aacb2380b9d5acca8755789,openstack/fuel-web,master,Idc8cbb34934313c11aacb2380b9d5acca8755789,Refactoring of create_node method,ABANDONED,2016-02-12 13:38:16.000000000,2016-02-16 06:05:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6571}, {'_account_id': 8971}]","[{'number': 1, 'created': '2016-02-12 13:38:16.000000000', 'files': ['nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/base.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4700ab7048f56514f07b45b5563eacaee4992073', 'message': 'Refactoring of create_node method\n\nChange-Id: Idc8cbb34934313c11aacb2380b9d5acca8755789\n'}]",0,279534,4700ab7048f56514f07b45b5563eacaee4992073,12,3,1,6571,,,0,"Refactoring of create_node method

Change-Id: Idc8cbb34934313c11aacb2380b9d5acca8755789
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/34/279534/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/unit/test_node_disks.py', 'nailgun/nailgun/test/base.py']",2,4700ab7048f56514f07b45b5563eacaee4992073,multi_proof," if node_kwargs.get(""api""): del node_kwargs['api'] self.create_node_api(**node_kwargs) else: self.create_node(**node_kwargs) def _create_node_data(self, exclude=None, **kwargs): update_metadata = kwargs.get('meta', {}) default_metadata.update(update_metadata) if not update_metadata or 'interfaces' not in update_metadata: return node_data def create_node(self, **kwargs): node = Node.create(self._create_node_data(**kwargs)) db().commit() self.nodes.append(node) return node def _fix_api_disk_data(self, disks): return disks # blocks = [] # for disk in disks: # api_disk = { # 'size': disk['size'], # 'udevadm_info': (""DEVNAME=/dev/{disk}"" # ""ID_MODEL={model}"").format(**disk), # 'removable': disk.get('removable', False) # } # blocks.append(api_disk) # api_disks = { # 'blocks': blocks, # 'dmsetup_info': """", # } # return api_disks def create_node_api(self, exclude=None, expect_http=201, expected_error=None, **kwargs): node_data = self._create_node_data(exclude, **kwargs) disks = node_data['meta']['disks'] node_data['meta']['disks'] = self._fix_api_disk_data(disks) resp = self.app.post( reverse('NodeCollectionHandler'), jsonutils.dumps(node_data), headers=self.default_headers, expect_errors=True ) self.tester.assertEqual(resp.status_code, expect_http, resp.body) if expected_error: self.tester.assertEqual( resp.json_body[""message""], expected_error ) if str(expect_http)[0] != ""2"": return None self.tester.assertEqual(resp.status_code, expect_http) node = resp.json_body node_db = Node.get_by_uid(node['id']) if 'interfaces' not in node_data['meta'] \ or not node_data['meta']['interfaces']: self._set_interfaces_if_not_set_in_meta( node_db.id, kwargs.get('meta', None)) self.nodes.append(node_db)"," node_kwargs.setdefault(""api"", False) self.create_node( **node_kwargs ) def create_node( self, api=False, exclude=None, expect_http=201, expected_error=None, **kwargs): # TODO(alekseyk) Simplify 'interfaces' and 'mac' manipulation logic metadata = kwargs.get('meta', {}) default_metadata.update(metadata) if not metadata or 'interfaces' not in metadata: if api: resp = self.app.post( reverse('NodeCollectionHandler'), jsonutils.dumps(node_data), headers=self.default_headers, expect_errors=True ) self.tester.assertEqual(resp.status_code, expect_http, resp.body) if expected_error: self.tester.assertEqual( resp.json_body[""message""], expected_error ) if str(expect_http)[0] != ""2"": return None self.tester.assertEqual(resp.status_code, expect_http) node = resp.json_body node_db = Node.get_by_uid(node['id']) if 'interfaces' not in node_data['meta'] \ or not node_data['meta']['interfaces']: self._set_interfaces_if_not_set_in_meta( node_db.id, kwargs.get('meta', None)) self.nodes.append(node_db) else: node = Node.create(node_data) db().commit() self.nodes.append(node) ",66,50
openstack%2Fkeystone~master~I5148e4d3dfdeed8031c460405baa84b67bc93295,openstack/keystone,master,I5148e4d3dfdeed8031c460405baa84b67bc93295,Updating sample configuration file,MERGED,2016-02-16 02:39:24.000000000,2016-02-16 06:05:11.000000000,2016-02-16 06:05:11.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-02-16 02:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b607271208159100ae6bff0e3772861f80d3da36', 'message': 'Updating sample configuration file\n\nChange-Id: I5148e4d3dfdeed8031c460405baa84b67bc93295\n'}, {'number': 2, 'created': '2016-02-16 03:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4b74eb8a7dcf090a2e0f9807e64b9aca0d4f3113', 'message': 'Updating sample configuration file\n\nChange-Id: I5148e4d3dfdeed8031c460405baa84b67bc93295\n'}, {'number': 3, 'created': '2016-02-16 03:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4e62cddcf6e5623ab77d1e62614406d3590ff781', 'message': 'Updating sample configuration file\n\nChange-Id: I5148e4d3dfdeed8031c460405baa84b67bc93295\n'}, {'number': 4, 'created': '2016-02-16 03:42:28.000000000', 'files': ['etc/keystone.conf.sample'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c24c26d17c6ab712045765f934d590b41d73e1ba', 'message': 'Updating sample configuration file\n\nChange-Id: I5148e4d3dfdeed8031c460405baa84b67bc93295\n'}]",0,280477,c24c26d17c6ab712045765f934d590b41d73e1ba,9,2,4,11131,,,0,"Updating sample configuration file

Change-Id: I5148e4d3dfdeed8031c460405baa84b67bc93295
",git fetch https://review.opendev.org/openstack/keystone refs/changes/77/280477/4 && git format-patch -1 --stdout FETCH_HEAD,['etc/keystone.conf.sample'],1,b607271208159100ae6bff0e3772861f80d3da36,openstack/keystone/genconf,"# configuration files are used then all logging configuration is set in the# example, logging_context_format_string). (string value)# Seconds to wait before a cast expires (TTL). The default value of -1 # specifies an infinite linger period. The value of 0 specifies no linger # period. Pending messages shall be discarded immediately when the socket is # closed. Only supported by impl_zmq. (integer value) #rpc_cast_timeout = -1# EXPERIMENTAL: Possible values are: gzip, bz2. If not set compression will not # be used. This option may notbe available in future versions. (string value) #kombu_compression = <None> ","# configuration files are used all logging configuration is defined in the# example, log_format). (string value)# DEPRECATED. A logging.Formatter log message format string which may use any # of the available logging.LogRecord attributes. This option is deprecated. # Please use logging_context_format_string and logging_default_format_string # instead. This option is ignored if log_config_append is set. (string value) #log_format = <None> # Seconds to wait before a cast expires (TTL). Only supported by impl_zmq. # (integer value) #rpc_cast_timeout = 30# Host to locate redis. (string value) #host = 127.0.0.1 # Use this port to connect to redis host. (port value) # Minimum value: 0 # Maximum value: 65535 #port = 6379 # Password for Redis server (optional). (string value) #password = # List of Redis Sentinel hosts (fault tolerance mode) e.g. # [host:port, host1:port ... ] (list value) #sentinel_hosts = # Redis replica set name. (string value) #sentinel_group_name = oslo-messaging-zeromq # Time in ms to wait between connection attempts. (integer value) #wait_timeout = 500 # Time in ms to wait before the transaction is killed. (integer value) #check_timeout = 20000 # Timeout in ms on blocking socket operations (integer value) #socket_timeout = 1000 ",11,38
openstack%2Fneutron~master~I28779cf0da6a9b369922566998ec388679593819,openstack/neutron,master,I28779cf0da6a9b369922566998ec388679593819,Call Ryu's clean up function when ovs_neutron_agent.main terminates,MERGED,2015-12-14 08:13:37.000000000,2016-02-16 06:04:26.000000000,2016-02-16 06:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2888}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9200}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14215}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 18369}]","[{'number': 1, 'created': '2015-12-14 08:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bacfbd39643f6e93d67efa13988a6698d004d7b7', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}, {'number': 2, 'created': '2015-12-16 03:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/42f5d858e8151d637e0bbb81997d0a80d33bfc3b', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}, {'number': 3, 'created': '2015-12-24 06:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/73b633b9c83bc739cd6de8ab53cf0484c97b6d0d', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}, {'number': 4, 'created': '2016-01-06 02:57:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/811f41645cc137435343d5b16442851f378cb1ec', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}, {'number': 5, 'created': '2016-01-15 03:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/360b682bb056eea09561905a4343eb6da50a85ab', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}, {'number': 6, 'created': '2016-02-05 05:17:08.000000000', 'files': ['neutron/tests/functional/agent/test_ovs_flows.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ovs_ryuapp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f01affa0935026f001916f41514b9ff12fa73bb1', 'message': ""Call Ryu's clean up function when ovs_neutron_agent.main terminates\n\nWhen the of_interface=native configuration is active, Ryu's event loop\nmust be explicitly terminated.\n\nChange-Id: I28779cf0da6a9b369922566998ec388679593819\nCloses-bug: 1525780\n""}]",4,257204,f01affa0935026f001916f41514b9ff12fa73bb1,100,21,6,9200,,,0,"Call Ryu's clean up function when ovs_neutron_agent.main terminates

When the of_interface=native configuration is active, Ryu's event loop
must be explicitly terminated.

Change-Id: I28779cf0da6a9b369922566998ec388679593819
Closes-bug: 1525780
",git fetch https://review.opendev.org/openstack/neutron refs/changes/04/257204/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/agent/openflow/native/ovs_ryuapp.py'],1,bacfbd39643f6e93d67efa13988a6698d004d7b7,measure_ovs_agent,"def agent_main_wrapper(bridge_classes): ovs_agent.main(bridge_classes) app_manager.AppManager.get_instance().close() return hub.spawn(agent_main_wrapper, bridge_classes)"," return hub.spawn(ovs_agent.main, bridge_classes)",6,1
openstack%2Fbandit~master~Iaf5bcad52678f768375182175cde8d3efb17b6a3,openstack/bandit,master,Iaf5bcad52678f768375182175cde8d3efb17b6a3,Adding JSON output for baseline results,MERGED,2016-02-10 23:28:24.000000000,2016-02-16 06:00:59.000000000,2016-02-16 06:00:59.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 8119}, {'_account_id': 11029}, {'_account_id': 11861}]","[{'number': 1, 'created': '2016-02-10 23:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/5571ce15d1f74a07307534131c00f9830674f18e', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 2, 'created': '2016-02-10 23:40:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/d18e106a6d7527a4188814054f89ce74654c97fe', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 3, 'created': '2016-02-10 23:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/a6eb20f64eadaba1784aa93ee40129ee9e95d2a4', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 4, 'created': '2016-02-11 16:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/5991ceb5e2d1441915a5ebd1ffd257b46c6f15a8', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 5, 'created': '2016-02-11 16:14:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/81c6d48865300492a26d8c3d2375726f72834493', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 6, 'created': '2016-02-12 20:28:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/58169d5e36e8fbf0cf951aa8395fcba235144763', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}, {'number': 7, 'created': '2016-02-12 21:02:07.000000000', 'files': ['README.rst', 'bandit/formatters/json.py', 'bandit/cli/baseline.py', 'tests/unit/formatters/test_json.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/49780b38aff1caf0eb83b165e4467d13559a0ac9', 'message': ""Adding JSON output for baseline results\n\nThis commit adds baseline functionality to the JSON formatter.\nIssues will be listed as normal, however if multiple candidates\nexist for an issue they'll be listed in 'candidates' with a value\nof the list of prospective candidates.\n\nChange-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3\n""}]",2,278794,49780b38aff1caf0eb83b165e4467d13559a0ac9,21,5,7,11861,,,0,"Adding JSON output for baseline results

This commit adds baseline functionality to the JSON formatter.
Issues will be listed as normal, however if multiple candidates
exist for an issue they'll be listed in 'candidates' with a value
of the list of prospective candidates.

Change-Id: Iaf5bcad52678f768375182175cde8d3efb17b6a3
",git fetch https://review.opendev.org/openstack/bandit refs/changes/94/278794/1 && git format-patch -1 --stdout FETCH_HEAD,"['bandit/formatters/json.py', 'bandit/cli/baseline.py', 'tests/unit/formatters/test_json.py']",3,5571ce15d1f74a07307534131c00f9830674f18e,add-json-baseline,"from collections import OrderedDictimport mock self.candidates = [issue.Issue(bandit.LOW, bandit.LOW, 'Candidate A', lineno=1), issue.Issue(bandit.HIGH, bandit.HIGH, 'Candiate B', lineno=2)] @mock.patch('bandit.core.manager.BanditManager.get_issue_list') def test_report(self, get_issue_list): get_issue_list.return_value = OrderedDict([(self.issue, self.candidates)]) self.assertIn('candidates', data['results'][0])", def test_report(self):,27,3
openstack%2Fbandit~master~I63edd7ae4ee14b745663cc6378b843c8bd5e96ed,openstack/bandit,master,I63edd7ae4ee14b745663cc6378b843c8bd5e96ed,Fixing bug with output chars in formatters,MERGED,2016-02-12 20:14:20.000000000,2016-02-16 05:42:37.000000000,2016-02-16 05:42:37.000000000,"[{'_account_id': 3}, {'_account_id': 8119}, {'_account_id': 11029}]","[{'number': 1, 'created': '2016-02-12 20:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/2bd01023da14307e2ec4d7d4df9df85128db51a1', 'message': 'Fixing bug with output chars in formatters\n\nWhile scanning byte sequences, formatters would try to output\nwithout first decoding to unicode.  Some formatters, like text\nwould then try to convert to string which was causing a\nUnicodeEncodeError.  This addresses the issue by ensuring that\ncode snippets are first encoded in unicode, and then preserved\nas unicode throughout the display process.\n\nCloses-Bug: #1544371\nChange-Id: I63edd7ae4ee14b745663cc6378b843c8bd5e96ed\n'}, {'number': 2, 'created': '2016-02-12 20:43:21.000000000', 'files': ['bandit/core/issue.py', 'tests/unit/formatters/test_text.py', 'bandit/formatters/screen.py', 'bandit/formatters/text.py', 'tests/unit/formatters/test_screen.py', 'bandit/formatters/html.py'], 'web_link': 'https://opendev.org/openstack/bandit/commit/54bf3cbe1213237342e904e023130587c6f71c51', 'message': 'Fixing bug with output chars in formatters\n\nWhile scanning byte sequences, formatters would try to output\nwithout first decoding to unicode.  Some formatters, like text\nwould then try to convert to string which was causing a\nUnicodeEncodeError.  This addresses the issue by ensuring that\ncode snippets are first encoded in unicode, and then preserved\nas unicode throughout the display process.\n\nCloses-Bug: #1544371\nChange-Id: I63edd7ae4ee14b745663cc6378b843c8bd5e96ed\n'}]",3,279767,54bf3cbe1213237342e904e023130587c6f71c51,15,3,2,11861,,,0,"Fixing bug with output chars in formatters

While scanning byte sequences, formatters would try to output
without first decoding to unicode.  Some formatters, like text
would then try to convert to string which was causing a
UnicodeEncodeError.  This addresses the issue by ensuring that
code snippets are first encoded in unicode, and then preserved
as unicode throughout the display process.

Closes-Bug: #1544371
Change-Id: I63edd7ae4ee14b745663cc6378b843c8bd5e96ed
",git fetch https://review.opendev.org/openstack/bandit refs/changes/67/279767/2 && git format-patch -1 --stdout FETCH_HEAD,"['bandit/core/issue.py', 'tests/unit/formatters/test_text.py', 'bandit/formatters/screen.py', 'bandit/formatters/text.py', 'tests/unit/formatters/test_screen.py', 'bandit/formatters/html.py']",6,2bd01023da14307e2ec4d7d4df9df85128db51a1,bug/1544371," header_block = u"""""" report_block = u"""""" issue_block = u"""""" code_block = u"""""" candidate_block = u"""""" candidate_issue = u"""""" skipped_block = u"""""" metrics_block = u"""""""," header_block = """""" report_block = """""" issue_block = """""" code_block = """""" candidate_block = """""" candidate_issue = """""" skipped_block = """""" metrics_block = """"""",27,16
openstack%2Fkeystoneauth~master~I570265af939f0cec2861efd8580e62066e422d1f,openstack/keystoneauth,master,I570265af939f0cec2861efd8580e62066e422d1f,Cleanup test-requirements.txt,MERGED,2016-02-13 09:46:32.000000000,2016-02-16 05:11:08.000000000,2016-02-16 05:11:08.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 7191}]","[{'number': 1, 'created': '2016-02-13 09:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/2e4ffba8dc396937012a7aafe73857146b050d7b', 'message': ""Remove tempest-lib from test-requirements.txt\n\nIt's not used so not needed.\n\nChange-Id: I570265af939f0cec2861efd8580e62066e422d1f\n""}, {'number': 2, 'created': '2016-02-13 09:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/55d1e51f5f4e37268678d12ee7b7467ae80d300b', 'message': 'Cleanup test-requirements.txt\n\nRemove\n- tempest-lib\n- oauthlib\n- WebOb\n\nAll are not used in the code.\n\nChange-Id: I570265af939f0cec2861efd8580e62066e422d1f\n'}, {'number': 3, 'created': '2016-02-13 21:28:51.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/787c4d12ddec7aedc9e9ff341d377f6a60e4d3bd', 'message': 'Cleanup test-requirements.txt\n\nRemove:\n- tempest-lib\n- oauthlib\n- WebOb\n\nAdd:\n- oslo.utils\n\nChange-Id: I570265af939f0cec2861efd8580e62066e422d1f\n'}]",0,279872,787c4d12ddec7aedc9e9ff341d377f6a60e4d3bd,12,3,3,7102,,,0,"Cleanup test-requirements.txt

Remove:
- tempest-lib
- oauthlib
- WebOb

Add:
- oslo.utils

Change-Id: I570265af939f0cec2861efd8580e62066e422d1f
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/72/279872/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,2e4ffba8dc396937012a7aafe73857146b050d7b,,,tempest-lib>=0.14.0 # Apache-2.0,0,1
openstack%2Fpython-senlinclient~master~Ib4658b6fea9c097ecd043c394522dac88b97fb94,openstack/python-senlinclient,master,Ib4658b6fea9c097ecd043c394522dac88b97fb94,Add OpenstackClient plugin for cluster profile show,MERGED,2016-01-31 16:06:51.000000000,2016-02-16 05:00:30.000000000,2016-02-16 05:00:30.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-01-31 16:06:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/d679f68c72c09334669b6ed03a9d52304c776dc5', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-02-01 05:18:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/b7ace39168a11c84b37ec3d9959b566dbc4791d8', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 3, 'created': '2016-02-01 08:37:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/0e95e45833dba81fdf76ce7af7d96560e1441070', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 4, 'created': '2016-02-01 09:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/d0eff7a08eee3963c408d88ac6c2693e80397c60', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 5, 'created': '2016-02-14 12:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/813f3acd7e51e6fc7dc57c5f0b6e0e4b580e54dd', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 6, 'created': '2016-02-14 12:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/28e3b463ad7129b81be504bdb1ee1cb84ab14aef', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}, {'number': 7, 'created': '2016-02-16 03:45:36.000000000', 'files': ['requirements.txt', 'senlinclient/osc/v1/profile.py', 'senlinclient/tests/unit/osc/fakes.py', 'senlinclient/tests/unit/osc/v1/test_profile.py', 'senlinclient/osc/v1/__init__.py', 'senlinclient/osc/plugin.py', 'senlinclient/tests/unit/osc/__init__.py', 'setup.cfg', 'senlinclient/tests/unit/osc/v1/__init__.py', 'senlinclient/tests/unit/osc/v1/fakes.py', 'senlinclient/osc/__init__.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/993081ab1073782ba41fd577f2fec5a2ca8c7f9b', 'message': 'Add OpenstackClient plugin for cluster profile show\n\nThis change implements the ""openstack cluster profile show"" command\n  Based on the existing senlin command: senlin profile-show\n\nChange-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94\nBlueprint: senlin-support-python-openstackclient\n'}]",30,274443,993081ab1073782ba41fd577f2fec5a2ca8c7f9b,35,5,7,18389,,,0,"Add OpenstackClient plugin for cluster profile show

This change implements the ""openstack cluster profile show"" command
  Based on the existing senlin command: senlin profile-show

Change-Id: Ib4658b6fea9c097ecd043c394522dac88b97fb94
Blueprint: senlin-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/43/274443/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/tests/unit/osc/utils.py', 'requirements.txt', 'senlinclient/osc/v1/profile.py', 'senlinclient/tests/unit/osc/fakes.py', 'senlinclient/osc/v1/__init__.py', 'senlinclient/osc/plugin.py', 'senlinclient/tests/unit/osc/__init__.py', 'setup.cfg', 'senlinclient/tests/unit/osc/v1/__init__.py', 'senlinclient/tests/unit/osc/v1/fakes.py', 'senlinclient/osc/__init__.py']",11,d679f68c72c09334669b6ed03a9d52304c776dc5,bp/senlin-support-python-openstackclient,,,512,0
openstack%2Ftempest~master~I998ed8aa009b24b2c548d8892f09f44a727bd8fa,openstack/tempest,master,I998ed8aa009b24b2c548d8892f09f44a727bd8fa,Adding negative test cases to Zaqar v1.0,ABANDONED,2016-02-15 05:55:28.000000000,2016-02-16 04:54:50.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-15 05:55:28.000000000', 'files': ['tempest/services/messaging/json/messaging_client.py', 'tempest/api/messaging/test_queues_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/0222c3fd9c1e7fa80e694765fdac11e460b8d002', 'message': 'Adding negative test cases to Zaqar v1.0\n\nChange-Id: I998ed8aa009b24b2c548d8892f09f44a727bd8fa\n'}]",0,280071,0222c3fd9c1e7fa80e694765fdac11e460b8d002,5,3,1,15285,,,0,"Adding negative test cases to Zaqar v1.0

Change-Id: I998ed8aa009b24b2c548d8892f09f44a727bd8fa
",git fetch https://review.opendev.org/openstack/tempest refs/changes/71/280071/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/messaging/json/messaging_client.py', 'tempest/api/messaging/test_queues_negative.py']",2,0222c3fd9c1e7fa80e694765fdac11e460b8d002,bp/tempest-tests-zaqar,"# -*- coding: utf-8 -*- # Copyright (c) 2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. from six import moves from tempest.api.messaging import base from tempest import test from tempest_lib.common.utils import data_utils from tempest_lib import exceptions as lib_exc class QueueNegativeTestJSON(base.BaseMessagingTest): @classmethod def resource_setup(cls): super(QueueNegativeTestJSON, cls).resource_setup() cls.queues = list() for _ in moves.xrange(3): queue_name = data_utils.rand_name('Queues-Test') cls.queues.append(queue_name) cls.client.create_queue(queue_name) # Create Queues @test.attr(type=['negative']) @test.idempotent_id('3dea9d94-a0cf-406c-bbec-c7cd54a5e016') def test_queue_has_a_long_name(self): # the length of queue name should >= 1 and <=64 bytes queue_name = 'q' * 65 self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('9664222b-b580-4e28-86fe-7d700e8f5ec4') def test_queue_name_is_not_specified(self): # the length of queue name should >= 1 and <=64 bytes queue_name = ' ' self.assertRaises(lib_exc.UnexpectedResponseCode, self.client.create_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('04a2d0b9-7777-4afd-a32b-8ccb78057d04') def test_queue_name_has_a_invalid_character_set(self): # invalid name with characters queue_name = '@$@^qw@' self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('1545a382-6697-4cef-9050-fd1a668d20cf') def test_queue_name_with_non_ASCII_characters(self): # invalid name with non-ASCII characters queue_name = data_utils.rand_name('\u6c49\u5b57\u6f22\u5b57') self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('300c81d0-a3f5-4682-9ed0-950f45e4f516') def test_queue_name_with_numeric_values(self): # Test queue name with numbers queue_name = data_utils.rand_int_id() resp, _ = self.client.create_queue(queue_name) self.assertEqual('201', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('d59fca29-b383-44b0-88b6-c2ebc7b77572') def test_create_queue_with_invalid_auth_token(self): # trying to create queue with empty headers # X-Auth-Token is not provided queue_name = data_utils.rand_name(name='queue') self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.create_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('989cd2fa-db83-46e8-81db-5ed623f612e2') def test_check_queue_head_for_nonexistent_queue(self): # check non-existant queue head nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.head_queue, nonexistent_queuename) # List Queues @test.attr(type=['negative']) @test.idempotent_id('663348b2-934f-42d7-a1ba-05d1bf224adc') def test_request_a_nonexistent_queue(self): # List a non-existent queue nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue, nonexistent_queuename) @test.attr(type=['negative']) @test.idempotent_id('a6405879-5021-438c-8686-db45b57fccaf') def test_request_after_deleting_queue(self): # Request queue after deleting the queue # DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue, queue_name) @test.attr(type=['negative']) @test.idempotent_id('26576882-6c81-4f5e-b62f-a263cd65ac0c') def test_request_with_a_greater_limit_value(self): # The limit for listing queues is between 1 - 20 , configurable params = {'limit': '200'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) @test.idempotent_id('915d3480-2cc4-4bbd-8a60-c5ff60cc798b') def test_request_with_zero_limit_value(self): # The limit for listing queues is between 1 to 20 , configurable params = {'limit': '0'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) @test.idempotent_id('952d75c0-a520-4260-952b-e95c30594f08') def test_request_with_negative_limit_value(self): # The limit for listing queues is from 1 to 20 , configurable params = {'limit': '-1'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) @test.idempotent_id('0e5d195b-81a1-4f93-90f7-323a53cac991') def test_request_with_malformed_marker(self): # Listing queues with invalid marker value params = {'marker': 'ZZZzzz..WakeUp!'} resp, _ = self.client.list_queues_with_params(params) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('6105741d-9497-4288-b8a0-07b8f7239db4') def test_with_non_boolean_value_for_detailed(self): # Value for detailed parameter should be true or false params = {'detailed': 'None'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params) @test.attr(type=['negative']) @test.idempotent_id('ced334e7-9877-4a77-9b37-ff91ff240c6b') def test_request_with_invalid_params(self): # Params for listing queues are limit, marker ,detailed params = {'Invalid': 'ImAnInvalidParam'} resp, _ = self.client.list_queues_with_params(params) self.assertEqual('200', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('edd0b6d1-0a29-4322-99cb-465fefec4b6b') def test_list_queues_with_invalid_auth_token(self): # List queue with empty headers # X-Auth-Token is not provided self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.list_queues) # Set Queue Metadata @test.attr(type=['negative']) @test.idempotent_id('08b7802c-4cb3-48a8-915c-cee428854920') def test_queue_metadata_with_empty_request_body(self): # Passing empty metadata body to a queue queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] req_body = "" "" self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, req_body) @test.attr(type=['negative']) @test.idempotent_id('6b210142-ce20-4292-bed9-c9c0ad7a8bb0') def test_queue_metadata_with_long_metadata_key(self): queue_name = data_utils.rand_name('Queue_Test') self.create_queue(queue_name) req_body = {""key"" * 1000: ""v"" * 6} resp, _ = self.client.set_queue_metadata(queue_name, req_body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('41ed1c29-c9ee-44d7-94b0-3bb9f98d03cc') def test_by_adding_metadata_to_queue_with_existing_metadata(self): # Updates the current metadata value to new metadata value queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] req_body = {""Key"": ""Value""} resp, _ = self.client.set_queue_metadata(queue_name, req_body) new_req_body = {""New_Key"": ""New_Value""} resp, _ = self.client.set_queue_metadata(queue_name, new_req_body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('163db66a-bacf-45d9-be31-60ede19f9454') def test_request_add_metadata_to_a_nonexistent_queue(self): # Add metadata to a non-existent queue nonexistent_queuename = data_utils.rand_name('rand_queuename') body = {""Key"": ""Value""} self.assertRaises(lib_exc.NotFound, self.client.set_queue_metadata, nonexistent_queuename, body) @test.attr(type=['negative']) @test.idempotent_id('c8b87abe-f321-43e1-ae2a-07e4d0312df8') def test_queue_metadata_with_non_JSON_body(self): # Passing the body in a non-JSON format queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] req_body = ""123"" self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, req_body) @test.attr(type=['negative']) @test.idempotent_id('d7fda173-1c80-4457-aa1b-32ac668b3ec0') def test_metadata_with_request_body_greater_than_configured_bytes(self): # The maximum metadata size for a queue is 65536, configurable queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] value = ""a"" * 655367 req_body = dict() req_body[(""key"")] = value self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, req_body) @test.attr(type=['negative']) @test.idempotent_id('9be80fbd-ddf8-4b8a-b6cb-bf6de5832c84') def test_queue_metadata_with_empty_metadata_key_value(self): queue_name = data_utils.rand_name('Queue_Test') self.create_queue(queue_name) body = {"" "": ""data1""} resp, _ = self.client.set_queue_metadata(queue_name, body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('b4d46a49-6964-45d2-a178-d2a0024bdbbc') def test_set_queue_metadata_with_invalid_auth_token(self): # trying to set queue metadata with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] body = {""metadata"": ""My Queue""} self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.set_queue_metadata, queue_name, body) # Get Queue Metadata @test.attr(type=['negative']) @test.idempotent_id('72995dee-08ea-4353-953c-d15ada29fa15') def test_request_when_no_metadata_exists_for_the_queue(self): # show queue metadata for a queue with no metadata queue_name = data_utils.rand_name('Queue_Test') self.create_queue(queue_name) resp, _ = self.client.show_queue_metadata(queue_name) self.assertEqual('200', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('81a8c760-e175-4608-9fc7-bc6aab0243f0') def test_request_metadata_for_nonexistent_queue(self): # show metadata for a non-existent queue nonexistent_queuename = data_utils.rand_name('Rand_Queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue_metadata, nonexistent_queuename) @test.attr(type=['negative']) @test.idempotent_id('4e6f8b81-59cd-4031-9cad-001533683443') def test_request_metadata_after_deleting_queue(self): # Get queue metadata after deleting the queue # DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue_metadata, queue_name) @test.attr(type=['negative']) @test.idempotent_id('111f8d68-8c23-402d-a1f7-dfbae25ef771') def test_get_queue_metadata_with_invalid_auth_token(self): # Get queue metadata with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.show_queue_metadata, queue_name) # Get Queue Stats @test.attr(type=['negative']) @test.idempotent_id('6c4620ed-5aef-4c69-a7e9-7398f1e5fc52') def test_request_stats_for_a_non_existing_queue(self): # Show stats for a non-existent queue nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue_stats, nonexistent_queuename) @test.attr(type=['negative']) @test.idempotent_id('8586a5d9-251e-4563-a2f4-7eb86078e140') def test_request_queue_stats_after_deleting_queue(self): # List queue stats after deleting the queue # DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue_stats, queue_name) @test.attr(type=['negative']) @test.idempotent_id('70a07763-8a39-4346-9a53-86e6b26a71c5') def test_request_queue_stats_with_invalid_auth_token(self): # Get queue stats with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.show_queue_stats, queue_name) # Delete Queues @test.attr(type=['negative']) @test.idempotent_id('815317b1-6fac-4a80-8bdd-b52bb1c1e1c9') def test_delete_a_non_existent_queue(self): # Delete is an idempotent operation non_existent_queue = data_utils.rand_name('Queue_name') resp, _ = self.client.delete_queue(non_existent_queue) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('996b0947-defe-4459-a2b2-aeea0d4bc980') def test_delete_the_deleted_queue(self): # Delete is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) # Delete again resp, _ = self.client.delete_queue(queue_name) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) @test.idempotent_id('665cbcd2-6048-4562-a30f-b859c6a5b0ac') def test_delete_queue_with_invalid_auth_token(self): # Delete queue with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.delete_queue, queue_name) @classmethod def resource_cleanup(cls): for queue_name in cls.queues: cls.client.delete_queue(queue_name) super(QueueNegativeTestJSON, cls).resource_cleanup() ",,413,0
openstack%2Fpython-heatclient~master~Id0772d456d01f9eb5c67ad92584290844f9eeeb3,openstack/python-heatclient,master,Id0772d456d01f9eb5c67ad92584290844f9eeeb3,Add OpenstackClient plugin for software deployment show,MERGED,2015-11-24 08:35:34.000000000,2016-02-16 04:37:02.000000000,2016-02-16 04:37:02.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 12404}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-24 08:35:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3faedfeacac2e78b831aa756bfa11f2094149abc', 'message': 'OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack deployment show"" command\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 2, 'created': '2015-11-24 11:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2bc924dde2f3eec73202a0e8394f2b5fc81195ac', 'message': 'OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack deployment show"" command\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 3, 'created': '2015-11-25 07:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/075965042be1dab6087d83034c9385e62d1f7237', 'message': 'OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 4, 'created': '2015-12-16 05:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/bf6163dd83f8906d36cfe838f23b95be2902dc56', 'message': 'OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 5, 'created': '2016-01-17 14:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/c70f7b4550b03c1da4fe6fde24f560fb54473b94', 'message': 'OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 6, 'created': '2016-01-22 02:48:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/471d2b1b0b6e017503ab85d121b3d7549797de61', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-list\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 7, 'created': '2016-01-22 02:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6f6d58ab6d1a739a4b290c3558357076fa8abd0c', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 8, 'created': '2016-01-27 01:58:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/b4b0790e542ff84fc1a93e64cede88ae14af940b', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 9, 'created': '2016-02-02 05:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/97847c6e1817b68a25793ebe08d8a7850ff5a95e', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 10, 'created': '2016-02-03 06:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dcb8a47f789f784ce7b7a5d17364fd85af661a3e', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 11, 'created': '2016-02-14 03:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6eb6c3fe34219756ada0a278910eea7b178a8b08', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 12, 'created': '2016-02-16 02:02:38.000000000', 'files': ['heatclient/osc/v1/software_deployment.py', 'heatclient/tests/unit/osc/v1/test_software_deployment.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/c6221b0975e758d406fa2e9316c1aedfada7edfd', 'message': 'Add OpenstackClient plugin for software deployment show\n\nThis change implements the ""openstack software deployment show"" command\n\nBased on the existing heat command:\n    heat deployment-show\n\nChange-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3\nBlueprint: heat-support-python-openstackclient\n'}]",19,249067,c6221b0975e758d406fa2e9316c1aedfada7edfd,54,8,12,18389,,,0,"Add OpenstackClient plugin for software deployment show

This change implements the ""openstack software deployment show"" command

Based on the existing heat command:
    heat deployment-show

Change-Id: Id0772d456d01f9eb5c67ad92584290844f9eeeb3
Blueprint: heat-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/67/249067/9 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/software_deployment.py', 'heatclient/tests/unit/osc/v1/test_deployment.py', 'setup.cfg']",3,3faedfeacac2e78b831aa756bfa11f2094149abc,bp/heat-support-python-openstackclient, deployment_show = heatclient.osc.v1.software_deployment:ShowDeployment,,146,1
openstack%2Fpython-heatclient~master~I863631b393586d1ecd20c94988e16ef85fb8ad5a,openstack/python-heatclient,master,I863631b393586d1ecd20c94988e16ef85fb8ad5a,Add openstack client stack snapshot restore,MERGED,2016-01-14 17:38:31.000000000,2016-02-16 04:35:38.000000000,2016-02-16 04:35:38.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 10487}, {'_account_id': 14033}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-01-14 17:38:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ccb5496d1fe3bd04982dfca8046e9685691558c7', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-01-14 18:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/df9be23f20beb42b5cba5eab561bf2096634ca13', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 3, 'created': '2016-01-15 16:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/94469b50bf8ccb76bba57b49e337c98323eb5a9c', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 4, 'created': '2016-02-03 16:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e542517e6a5fb663f5a372056049c4ede3f5acd7', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 5, 'created': '2016-02-05 16:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/9d8027f8b4b242dee07abdf1338dc11184197fca', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 6, 'created': '2016-02-09 17:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a0c73648dc690432a4735c8dd37771bbe1ed67b5', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 7, 'created': '2016-02-10 15:13:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/772321b5c075bcd83ead8a1add906c8396db4eaa', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 8, 'created': '2016-02-12 15:37:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3a9730b70e9a1a30ff6a5ec6bc7c27dd3e914660', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 9, 'created': '2016-02-15 16:03:32.000000000', 'files': ['heatclient/osc/v1/snapshot.py', 'heatclient/tests/unit/osc/v1/test_snapshot.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/06be732705a19ba1f9da3bb96722d6cfd062575d', 'message': 'Add openstack client stack snapshot restore\n\nBased from the existing heat command:\n   heat stack-restore\n\nChange-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a\nBlueprint: heat-support-python-openstackclient\n'}]",4,267731,06be732705a19ba1f9da3bb96722d6cfd062575d,46,6,9,7128,,,0,"Add openstack client stack snapshot restore

Based from the existing heat command:
   heat stack-restore

Change-Id: I863631b393586d1ecd20c94988e16ef85fb8ad5a
Blueprint: heat-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/31/267731/6 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/snapshot.py', 'heatclient/tests/unit/osc/v1/test_snapshot.py', 'setup.cfg']",3,ccb5496d1fe3bd04982dfca8046e9685691558c7,bp/heat-support-python-openstackclient, stack_snapshot_restore = heatclient.osc.v1.snapshot:RestoreSnapshot,,111,1
openstack%2Fproject-config~master~I6c686312de102cbe438585e26bf6986e06b6f41c,openstack/project-config,master,I6c686312de102cbe438585e26bf6986e06b6f41c,Cleanup the early devstack clone script,MERGED,2016-01-18 06:27:00.000000000,2016-02-16 04:25:36.000000000,2016-02-16 04:25:35.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-01-18 06:27:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/dcd4f97a4a4b98a45b86ec96fccefdf16f06884e', 'message': ""Cleanup the early devstack clone script\n\nThis script is unnecessarily complex for what it is doing, which is\nessentially pre-seeding the source-repositories cache for devstack.\nAs we can see from I41e81d6bac98875eecde2376e0865784626e11a8 it's very\nconfusing having large parts of the source-repositories script\ncopy-pasted as a separate element and has led several of us down the\nwrong path.\n\nStrip this script back to the simple thing it is doing, which is\nchecking out/updating the source-repositories devstack cache.\n\nI have tested this by building an image with a warm cache and with a\ncold cache, in both cases the checkout was found and the list of\nimages to cache in 55-cache-devstack-repos was found.\n\nChange-Id: I6c686312de102cbe438585e26bf6986e06b6f41c\n""}, {'number': 2, 'created': '2016-01-18 06:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/78b1067165a6a63cefa524b9dabe971cecb5251e', 'message': ""Cleanup the early devstack clone script\n\nThis script is unnecessarily complex for what it is doing, which is\nessentially pre-seeding the source-repositories cache for devstack.\nAs we can see from I41e81d6bac98875eecde2376e0865784626e11a8 it's very\nconfusing having large parts of the source-repositories script\ncopy-pasted as a separate element and has led several of us down the\nwrong path.\n\nStrip this script back to the simple thing it is doing, which is\nchecking out/updating the source-repositories devstack cache.\n\nI have tested this by building an image with a warm cache and with a\ncold cache, in both cases the checkout was found and the list of\nimages to cache in 55-cache-devstack-repos was found.\n\nChange-Id: I6c686312de102cbe438585e26bf6986e06b6f41c\n""}, {'number': 3, 'created': '2016-01-19 00:11:42.000000000', 'files': ['nodepool/elements/cache-devstack/extra-data.d/50-early-source-repo'], 'web_link': 'https://opendev.org/openstack/project-config/commit/abbbf317ce5c848951091689a6dd946b449e0873', 'message': ""Cleanup the early devstack clone script\n\nThis script is unnecessarily complex for what it is doing, which is\nessentially pre-seeding the source-repositories cache for devstack.\nAs we can see from I41e81d6bac98875eecde2376e0865784626e11a8 it's very\nconfusing having large parts of the source-repositories script\ncopy-pasted as a separate element and has led several of us down the\nwrong path.\n\nStrip this script back to the simple thing it is doing, which is\nchecking out/updating the source-repositories devstack cache.\n\nI have tested this by building an image with a warm cache and with a\ncold cache, in both cases the checkout was found and the list of\nimages to cache in 55-cache-devstack-repos was found.\n\nChange-Id: I6c686312de102cbe438585e26bf6986e06b6f41c\n""}]",0,268888,abbbf317ce5c848951091689a6dd946b449e0873,19,5,3,7118,,,0,"Cleanup the early devstack clone script

This script is unnecessarily complex for what it is doing, which is
essentially pre-seeding the source-repositories cache for devstack.
As we can see from I41e81d6bac98875eecde2376e0865784626e11a8 it's very
confusing having large parts of the source-repositories script
copy-pasted as a separate element and has led several of us down the
wrong path.

Strip this script back to the simple thing it is doing, which is
checking out/updating the source-repositories devstack cache.

I have tested this by building an image with a warm cache and with a
cold cache, in both cases the checkout was found and the list of
images to cache in 55-cache-devstack-repos was found.

Change-Id: I6c686312de102cbe438585e26bf6986e06b6f41c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/88/268888/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/cache-devstack/extra-data.d/50-early-source-repo'],1,dcd4f97a4a4b98a45b86ec96fccefdf16f06884e,devstack-clone-cleanup,"# We need a copy of the devstack repo to query for the list of image # files to cached by the source-repositories element (see # 55-cache-devstack-repos) # # This script is a hack to use the source-repositories repo cache to # get early access to the devstack checkout (rather than doing a whole # separate clone of the devstack tree). In essence, this script knows # the path of the devstack in the source-repositories cache and # creates/updates it. To get the gist of where this comes from, see # dib's # elements/source-repositories/extra-data.d/98-source-repositories # # This could be removed if we could ever source and call the # clone/update functions asynchronously from the source-repositories # dib element. function get_devstack_from_cache { local REPONAME=devstack local REPOTYPE=git local REPOPATH=/opt/git/openstack-dev/devstack local REPOLOCATION=git://git.openstack.org/openstack-dev/devstack.git local REPOREF=master local REPO_DEST=$TMP_MOUNT_PATH$REPOPATH local REPO_SUB_DIRECTORY=$(dirname $REPO_DEST) sudo mkdir -p $REPO_SUB_DIRECTORY # build the same cache name as source-repositories CACHE_NAME=$(echo ""${REPOTYPE}_${REPOLOCATION}"" | sha1sum | awk '{ print $1 }' ) CACHE_NAME=${REPONAME//[^A-Za-z0-9]/_}_${CACHE_NAME} CACHE_PATH=${CACHE_BASE}/$CACHE_NAME # clone repo if not in cache if [ ! -e ""$CACHE_PATH"" ] ; then echo ""early-source-repo: Caching $REPONAME from $REPOLOCATION in $CACHE_PATH"" git clone $REPOLOCATION $CACHE_PATH.tmp mv ${CACHE_PATH}{.tmp,} # update cached repo if [ -z ""$DIB_OFFLINE"" ] ; then echo ""early-source-repo: Updating cache of $REPOLOCATION in $CACHE_PATH with ref $REPOREF"" git --git-dir=$CACHE_PATH/.git fetch --prune --update-head-ok \ $REPOLOCATION +refs/heads/*:refs/heads/* fi # clone the updated repo to our destination sudo git clone $CACHE_PATH $REPO_DEST } # in case source-repositories hasn't run yet, make the cache get_devstack_from_cache","# We need a copy of the devstack repo so that we can read it so that # we can generate the list of repos that we need to get. We'd like to # use the normal repo fetching and caching routines for that, so use # a modified version. # The bulk of this code is copied from # elements/source-repositories/extra-data.d/98-source-repositories # Most of it should be removed when we can source and call the # functions directly GIT_BASE=${GIT_BASE:-git://git.openstack.org} # If the old cache exists, move it to the new name function make_new_cache(){ local OLD_CACHE_BASE=$1 local CACHE_BASE=$2 # If the old cache name exists, move it to the new cache name if [ -e ""$OLD_CACHE_BASE"" ] ; then if [ ! -e ""$CACHE_BASE"" ] ; then mv -n $OLD_CACHE_BASE $CACHE_BASE else echo ""Not replacing new cache location with old cache"" fi} # Gets repositories or individual files listed in the a repository file # and places them in the specified destination path. # The format of the repository file is one or more lines matching # <name> <type> <destination> <location> [<ref>] function get_repos_for_element(){ local REPO_SOURCES=$1 local CACHE_URL=$TMP_HOOKS_PATH/bin/cache-url local REGEX=""^([^ ]+) (git|tar|file|package) ?(/[^ ]+)? ?([^ ]+)? ?([^ ]*)$"" while read line; do # expand variables line=$(eval echo $line) # ignore blank lines and lines beginning in '#' [[ ""$line"" == \#* ]] || [[ -z ""$line"" ]] && continue if [[ ""$line"" =~ $REGEX ]] ; then local REPONAME=${BASH_REMATCH[1]} local REPOTYPE=${BASH_REMATCH[2]} local REPOPATH=${BASH_REMATCH[3]} local REPOLOCATION=${BASH_REMATCH[4]} local REPO_ORIG_LOCATION=$REPOLOCATION local REPOREF=${BASH_REMATCH[5]:-master} local REPO_DEST=$TMP_MOUNT_PATH$REPOPATH local REPO_SUB_DIRECTORY=$(dirname $REPO_DEST) # REPOTYPE can be overridden with DIB_REPOTYPE_{name} local REPOTYPE_OVERRIDE=DIB_REPOTYPE_${REPONAME//[^A-Za-z0-9]/_} REPOTYPE=${!REPOTYPE_OVERRIDE:-$REPOTYPE} # REPOLOCATION can be overridden with DIB_REPOLOCATION_{name} local REPOLOCATION_OVERRIDE=DIB_REPOLOCATION_${REPONAME//[^A-Za-z0-9]/_} REPOLOCATION=${!REPOLOCATION_OVERRIDE:-$REPOLOCATION} # REPOREF can be overridden with DIB_REPOREF_{name} local REPOREF_OVERRIDE=DIB_REPOREF_${REPONAME//[^A-Za-z0-9]/_} REPOREF=${!REPOREF_OVERRIDE:-$REPOREF} # Determine a unique cache path for this repo CACHE_NAME=$(echo ""${REPOTYPE}_${REPOLOCATION}"" | sha1sum | awk '{ print $1 }' ) OLD_CACHE_PATH=${CACHE_BASE}/${CACHE_NAME} # Add the repo name to the sha1sum for readability CACHE_NAME=${REPONAME//[^A-Za-z0-9]/_}_${CACHE_NAME} CACHE_PATH=${CACHE_BASE}/$CACHE_NAME make_new_cache $OLD_CACHE_PATH $CACHE_PATH # Return if install type is not source local INSTALL_TYPE_VAR=DIB_INSTALLTYPE_${REPONAME//[^A-Za-z0-9]/_} local INSTALL_TYPE=${!INSTALL_TYPE_VAR:-source} if [ ! $INSTALL_TYPE = ""source"" ]; then echo ""$REPONAME install type not set to source"" continue fi case $REPOTYPE in git) if [ -z ""${!REPOLOCATION_OVERRIDE:-""""}"" -a -n ""${DIB_GITREPOBASE:-""""}"" ] ; then # Transform the current repo base to the new one local NEW_REPOLOCATION=$(echo $REPOLOCATION |\ sed ""s,^[^:]\+://[^/]\+/\(~[^/]\+\)\?\(.*\)$,${DIB_GITREPOBASE}\2,g"") echo ""Transformed ${REPOLOCATION} to ${NEW_REPOLOCATION}"" REPOLOCATION=$NEW_REPOLOCATION # Also update the cache location CACHE_NAME=$(echo ""${REPOTYPE}_${REPOLOCATION}"" | sha1sum | awk '{ print $1 }' ) CACHE_PATH=~/.cache/image-create/repository-sources/$CACHE_NAME fi sudo mkdir -p $REPO_SUB_DIRECTORY if [ ! -e ""$CACHE_PATH"" ] ; then echo ""Caching $REPONAME from $REPOLOCATION in $CACHE_PATH"" git clone $REPOLOCATION $CACHE_PATH.tmp mv ${CACHE_PATH}{.tmp,} fi HAS_REF=$(git --git-dir=$CACHE_PATH/.git name-rev $REPOREF 2>/dev/null || true) if [ -z ""$DIB_OFFLINE"" -o -z ""$HAS_REF"" ] ; then echo ""Updating cache of $REPOLOCATION in $CACHE_PATH with ref $REPOREF"" git --git-dir=$CACHE_PATH/.git fetch --update-head-ok --prune \ $REPOLOCATION +refs/heads/*:refs/heads/* fi echo ""Cloning from $REPONAME cache and applying ref $REPOREF"" sudo git clone $CACHE_PATH $REPO_DEST pushd $REPO_DEST sudo git fetch $CACHE_PATH $REPOREF sudo git reset --hard FETCH_HEAD # Get the reference in use git_ref=$(git rev-parse FETCH_HEAD) popd # Write the reference being used into the source-repositories manifest echo ""$REPONAME git $REPOPATH $REPOLOCATION $git_ref"" >> $GIT_MANIFEST ;; tar) # The top level directory of the tarball mightn't have a fixed name i.e. # it could contain version numbers etc... so we write it to a tmpdir # the then move the contents into the directory we want it in, this does # assume the tarball only contains a single top level directory local tmpdir=$(mktemp --tmpdir=$TMP_MOUNT_PATH/tmp -d) if [ -n ""$CACHE_PATH"" ] ; then echo ""Caching $REPONAME tarball from $REPOLOCATION in $CACHE_PATH"" if [ ! -f ""$CACHE_PATH"" -o -z ""$DIB_OFFLINE"" ] ; then $CACHE_URL $REPOLOCATION $CACHE_PATH fi tar -C $tmpdir -xzf $CACHE_PATH else echo ""Fetching $REPONAME tarball from $REPOLOCATION"" curl $REPOLOCATION | tar -C $tmpdir -xzf - fi sudo mkdir -p $REPO_DEST sudo mv $tmpdir/*/* $REPO_DEST rm -rf $tmpdir ;; file) sudo mkdir -p $REPO_SUB_DIRECTORY if [ -n ""$CACHE_PATH"" ] ; then echo ""Caching $REPONAME file from $REPOLOCATION in $CACHE_PATH"" if [ ! -f ""$CACHE_PATH"" -o -z ""$DIB_OFFLINE"" ] ; then $CACHE_URL $REPOLOCATION $CACHE_PATH fi sudo cp $CACHE_PATH $REPO_DEST else echo ""Fetching $REPONAME file from $REPOLOCATION"" sudo curl $REPOLOCATION -o $REPO_DEST fi ;; *) echo ""Unsupported repository type: $REPOTYPE"" return 1 ;; esac # Capture the in-instance repository path for later review / other # elements (like a pypi dependency cache). echo ""$REPOPATH"" | sudo dd of=$TMP_MOUNT_PATH/etc/dib-source-repositories oflag=append conv=notrunc else echo ""Couldn't parse '$line' as a source repository"" return 1 fi done < $REPO_SOURCES } OLD_CACHE_BASE=$DIB_IMAGE_CACHE/repository-sources make_new_cache $OLD_CACHE_BASE $CACHE_BASE# Use the IMAGE_NAME from the calling script, and make it unique with the temporary path GIT_MANIFEST_NAME=dib-manifest-git-$(basename ${IMAGE_NAME}) GIT_MANIFEST_CACHE_NAME=${GIT_MANIFEST_NAME}_$(dirname ${TMP_MOUNT_PATH##*.}) GIT_MANIFEST=$CACHE_BASE/${GIT_MANIFEST_CACHE_NAME} rm -f $GIT_MANIFEST # Get source repositories for the target echo ""devstack git /opt/git/openstack-dev/devstack $GIT_BASE/openstack-dev/devstack.git"" > $TMP_HOOKS_PATH/early-source-repository-config for _SOURCEREPO in $(find $TMP_HOOKS_PATH -maxdepth 1 -name ""early-source-repository-*"" -not -name '*~'); do get_repos_for_element $_SOURCEREPO done # Copy the manifest into the image if it exists (there may be no git repositories used) if [ -e ""$GIT_MANIFEST"" ] ; then sudo cp $GIT_MANIFEST $TMP_MOUNT_PATH/${DIB_MANIFEST_IMAGE_DIR}/$GIT_MANIFEST_NAME fi",48,184
openstack%2Fpython-heatclient~master~I3b3628d86b71d448feea197f6c92d3d3d19726b5,openstack/python-heatclient,master,I3b3628d86b71d448feea197f6c92d3d3d19726b5,Add openstack client stack resource signal,MERGED,2015-12-11 19:48:39.000000000,2016-02-16 04:18:43.000000000,2016-02-16 04:18:43.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 7404}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-12-11 19:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a120be395401ad7e8b7149216cf088d1ef0deed3', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 2, 'created': '2016-01-13 18:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e705a229299dbde237c69dcb2d28f77568c83cf6', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 3, 'created': '2016-01-15 16:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2f75836ae4ed4be8e465ffe97e900eeeecaf0640', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 4, 'created': '2016-01-18 15:43:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/535bde7e98232cc41d8e1770ad1e3602015d01f8', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 5, 'created': '2016-02-03 15:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/8afa8b9f536509a5490c6b6587e687a94df98224', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 6, 'created': '2016-02-05 16:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a290df2162a459168a2292776940bca539cf2ce1', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 7, 'created': '2016-02-09 17:51:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/41e5fce2547b59b6a30e3bddce21d10e3af4c760', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 8, 'created': '2016-02-09 21:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7cd8574eb6c2c977fc303c1d17fa184036f1e54c', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 9, 'created': '2016-02-12 15:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/fc21399731bb40da39f18042370977a5ed971517', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 10, 'created': '2016-02-12 15:20:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/5c54e7d15e81fabdb25ae5915e7c2231e5002f02', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}, {'number': 11, 'created': '2016-02-15 15:55:07.000000000', 'files': ['heatclient/osc/v1/resources.py', 'heatclient/tests/unit/osc/v1/test_resources.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0306a41fa0e5bf81b14466b5cd8618b4dd589070', 'message': 'Add openstack client stack resource signal\n\nAdd the openstack stack resource signal\ncommand.\n\nBased from the existing heat commands:\n   heat resource-signal\n\nChange-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5\nBlueprint: heat-support-python-openstackclient\n'}]",19,256641,0306a41fa0e5bf81b14466b5cd8618b4dd589070,57,7,11,7128,,,0,"Add openstack client stack resource signal

Add the openstack stack resource signal
command.

Based from the existing heat commands:
   heat resource-signal

Change-Id: I3b3628d86b71d448feea197f6c92d3d3d19726b5
Blueprint: heat-support-python-openstackclient
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/41/256641/9 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,a120be395401ad7e8b7149216cf088d1ef0deed3,bp/heat-support-python-openstackclient, stack_resource_signal = heatclient.osc.v1.resources:ResourceSignal,,1,1
openstack%2Fhacking~master~I4c75d8d9954219b419c7818438daf8bf25dff3a9,openstack/hacking,master,I4c75d8d9954219b419c7818438daf8bf25dff3a9,Add a new check for warn method deprecation.,ABANDONED,2015-12-20 04:08:08.000000000,2016-02-16 04:18:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6601}, {'_account_id': 9625}, {'_account_id': 11224}, {'_account_id': 12000}, {'_account_id': 14867}, {'_account_id': 16896}, {'_account_id': 18015}]","[{'number': 1, 'created': '2015-12-20 04:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/b2100d648898680ca8d6de7ad2f789a8f8d623b9', 'message': 'Adding a new check for warn method deprecation.\n\nPython 3 deprecated the logger.warn method in favor of warning\nthis change would detect warn usage in the code.\n\nAlso this closes a bug which says db type could not be\ndetermined which occurs due to py34 env coming after\npy2x in tox env lists.\n\nChange-Id: I4c75d8d9954219b419c7818438daf8bf25dff3a9\nCloses-Bug: #1489059\n'}, {'number': 2, 'created': '2015-12-28 17:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/6f2a01f68212d28b6ed847a0e03ba34a76d0fc66', 'message': 'Adding a new check for warn method deprecation.\n\nPython 3 deprecated the logger.warn method in favor of warning\nthis change would detect warn usage in the code.\n\nChange-Id: I4c75d8d9954219b419c7818438daf8bf25dff3a9\n'}, {'number': 3, 'created': '2015-12-28 17:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/hacking/commit/da7eb0debb62ca4c2aceb7bbe36837863f2335ad', 'message': 'Add a new check for warn method deprecation.\n\nPython 3 deprecated the logger.warn method in favor of warning\nthis change would detect warn usage in the code.\n\nChange-Id: I4c75d8d9954219b419c7818438daf8bf25dff3a9\n'}, {'number': 4, 'created': '2015-12-28 17:29:16.000000000', 'files': ['hacking/checks/python23.py', 'setup.cfg', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/hacking/commit/bb54db4d85d05c81946a1e8fa43d62827fa6e2c8', 'message': 'Add a new check for warn method deprecation.\n\nPython 3 deprecated the logger.warn method in favor of warning\nthis change would detect warn usage in the code.\n\nChange-Id: I4c75d8d9954219b419c7818438daf8bf25dff3a9\n'}]",8,259729,bb54db4d85d05c81946a1e8fa43d62827fa6e2c8,24,8,4,14867,,,0,"Add a new check for warn method deprecation.

Python 3 deprecated the logger.warn method in favor of warning
this change would detect warn usage in the code.

Change-Id: I4c75d8d9954219b419c7818438daf8bf25dff3a9
",git fetch https://review.opendev.org/openstack/hacking refs/changes/29/259729/2 && git format-patch -1 --stdout FETCH_HEAD,"['hacking/checks/python23.py', 'setup.cfg', 'tox.ini', 'HACKING.rst']",4,b2100d648898680ca8d6de7ad2f789a8f8d623b9,warn_check,"- [H239] Logger's ``warn`` method is deprecated in python 3.x, use ``warning`` instead. ",,24,1
openstack%2Fpycadf~master~I01ebad7b70cf61dd80d3c06c6808d8178fbdd634,openstack/pycadf,master,I01ebad7b70cf61dd80d3c06c6808d8178fbdd634,Add docstring validation,MERGED,2015-10-02 03:25:12.000000000,2016-02-16 04:11:39.000000000,2016-02-16 04:11:39.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 6482}, {'_account_id': 6537}, {'_account_id': 16237}, {'_account_id': 17860}]","[{'number': 1, 'created': '2015-10-02 03:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/319750fd25fb015ad90a31d2db782edc74e948c3', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\nRelated-Bug: 1501544\nDepends-On: I60adf0dca4aa32f4ef6bca61250b375c8a3703c6\n'}, {'number': 2, 'created': '2016-02-01 16:36:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/384fb1935d14dc54834c7eeb2a5a5d5cb598e2eb', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\nRelated-Bug: 1501544\nDepends-On: I60adf0dca4aa32f4ef6bca61250b375c8a3703c6\n'}, {'number': 3, 'created': '2016-02-12 07:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/4e5386c6fb3ed78f5f3d604ed839168da62995fb', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\nRelated-Bug: 1501544\nDepends-On: I60adf0dca4aa32f4ef6bca61250b375c8a3703c6\n'}, {'number': 4, 'created': '2016-02-12 07:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pycadf/commit/7bfd0cb40807c897a601b82bbe31cfb76b0e737a', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nRelated-Bug: 1501544\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\n'}, {'number': 5, 'created': '2016-02-12 15:03:12.000000000', 'files': ['test-requirements.txt', 'pycadf/identifier.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/pycadf/commit/9c4100b85d277b558143b1af9dc9ffdc37802e37', 'message': 'Add docstring validation\n\nThis introduces a linter for PEP257 to avoid trivial nitpicking of\ndocstrings in code reviews. Because flake8_docstrings simply provides a\nplugin to add pep257 to flake8, you can run it via `tox -e pep8`.\n\nPEP257 checks which we are currently violating are ignored in tox.ini.\nWe can remove them from the ignored list as they are fixed.\n\nRelated-Bug: 1501544\nChange-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634\n'}]",0,230257,9c4100b85d277b558143b1af9dc9ffdc37802e37,27,6,5,4,,,0,"Add docstring validation

This introduces a linter for PEP257 to avoid trivial nitpicking of
docstrings in code reviews. Because flake8_docstrings simply provides a
plugin to add pep257 to flake8, you can run it via `tox -e pep8`.

PEP257 checks which we are currently violating are ignored in tox.ini.
We can remove them from the ignored list as they are fixed.

Related-Bug: 1501544
Change-Id: I01ebad7b70cf61dd80d3c06c6808d8178fbdd634
",git fetch https://review.opendev.org/openstack/pycadf refs/changes/57/230257/4 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini']",2,319750fd25fb015ad90a31d2db782edc74e948c3,bug/1501544,"# D100: Missing docstring in public module # D101: Missing docstring in public class # D102: Missing docstring in public method # D103: Missing docstring in public function # D104: Missing docstring in public package # D200: One-line docstring should fit on one line with quotes # D202: No blank lines allowed after function docstring # D203: 1 blank required before class docstring # D204: 1 blank line required after class docstring # D205: 1 blank line required between summary line and description # D208: Docstring is over-indented # D400: First line should end with a period # D401: First line should be in imperative mood ignore = H405,D100,D101,D102,D103,D200,D202,D203,D204,D205,D208,D400,D401",ignore = H405,15,1
openstack%2Fproject-config~master~I68f8fbd01927ead42e9fab1ff41360f035275d4a,openstack/project-config,master,I68f8fbd01927ead42e9fab1ff41360f035275d4a,Remove restrict-memory,MERGED,2016-02-15 18:59:17.000000000,2016-02-16 04:04:25.000000000,2016-02-16 04:04:25.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 5545}, {'_account_id': 7118}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-15 18:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1549b64cac37df852c598e12f5dc52518dfc5d37', 'message': 'Fix dib gate\n\ndib-lint checks that only #!/bin/bash is used, remove extra -xe, these\nare set later in the file.\n\nThis is needed to merge any nodepool changes.\n\nChange-Id: I68f8fbd01927ead42e9fab1ff41360f035275d4a\n'}, {'number': 2, 'created': '2016-02-15 19:04:51.000000000', 'files': ['nodepool/scripts/restrict_memory.sh', 'nodepool/scripts/prepare_node_bare.sh', 'nodepool/scripts/prepare_node_devstack_virt_preview.sh', 'nodepool/elements/nodepool-base/finalise.d/99-restrict-memory', 'nodepool/scripts/prepare_node_devstack.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/71d84bed47df5be748cad1a0983e51ac350205a2', 'message': 'Remove restrict-memory\n\nWe do not have HP cloud anymore, remove the restrict-memory files.\n\nChange-Id: I68f8fbd01927ead42e9fab1ff41360f035275d4a\n'}]",0,280364,71d84bed47df5be748cad1a0983e51ac350205a2,12,6,2,6547,,,0,"Remove restrict-memory

We do not have HP cloud anymore, remove the restrict-memory files.

Change-Id: I68f8fbd01927ead42e9fab1ff41360f035275d4a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/280364/2 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/elements/nodepool-base/finalise.d/99-restrict-memory'],1,1549b64cac37df852c598e12f5dc52518dfc5d37,fix-dib-gate,#!/bin/bash,#!/bin/bash -xe,1,1
openstack%2Ftrove-integration~master~I8b12bfeffa7c78eec73fbbad9a10be31a8ab0034,openstack/trove-integration,master,I8b12bfeffa7c78eec73fbbad9a10be31a8ab0034,Test commit,ABANDONED,2016-02-11 21:45:59.000000000,2016-02-16 04:04:15.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-11 21:45:59.000000000', 'files': ['scripts/redstack'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/cdba4d1913d8dfe940bf90a8ea2a4c05457fb12c', 'message': 'Test commit\n\nDO NOT MERGE!\n\nChange-Id: I8b12bfeffa7c78eec73fbbad9a10be31a8ab0034\n'}]",0,279277,cdba4d1913d8dfe940bf90a8ea2a4c05457fb12c,3,1,1,5293,,,0,"Test commit

DO NOT MERGE!

Change-Id: I8b12bfeffa7c78eec73fbbad9a10be31a8ab0034
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/77/279277/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/redstack'],1,cdba4d1913d8dfe940bf90a8ea2a4c05457fb12c,, find /etc/apt exit ,,3,0
openstack%2Fpuppet-keystone~master~I6a51747bdb776d0bd41d175e213314febb4608f3,openstack/puppet-keystone,master,I6a51747bdb776d0bd41d175e213314febb4608f3,WIP Keystone hooks support,ABANDONED,2016-02-15 16:09:07.000000000,2016-02-16 04:02:13.000000000,,"[{'_account_id': 3}, {'_account_id': 9060}]","[{'number': 1, 'created': '2016-02-15 16:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/bb9e2b76e08eb139a8c51ebcd44515be560ca84f', 'message': ""WIP Keystone hooks support\n\nChange-Id: I6a51747bdb776d0bd41d175e213314febb4608f3\nCo-Author: Clayton O'Neill <clayton.oneill@twcable.com>\n""}, {'number': 2, 'created': '2016-02-15 16:10:26.000000000', 'files': ['manifests/init.pp', 'manifests/deps.pp', 'spec/classes/keystone_deps_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/eace35847e07ec94db4caefd5bc534e4da39b443', 'message': ""WIP Keystone hooks support\n\nChange-Id: I6a51747bdb776d0bd41d175e213314febb4608f3\nCo-Author: Clayton O'Neill <clayton.oneill@twcable.com>\n""}]",0,280304,eace35847e07ec94db4caefd5bc534e4da39b443,5,2,2,9500,,,0,"WIP Keystone hooks support

Change-Id: I6a51747bdb776d0bd41d175e213314febb4608f3
Co-Author: Clayton O'Neill <clayton.oneill@twcable.com>
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/04/280304/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/init.pp'],1,bb9e2b76e08eb139a8c51ebcd44515be560ca84f,upstream-master, include ::keystone::deps tag => ['openstack']," file { ['/etc/keystone', '/var/log/keystone', '/var/lib/keystone']: ensure => directory, mode => '0750', owner => 'keystone', group => 'keystone', require => Package['keystone'], notify => Service[$service_name], } file { '/etc/keystone/keystone.conf': ensure => present, mode => '0600', owner => 'keystone', group => 'keystone', require => Package['keystone'], notify => Service[$service_name], } ",2,18
openstack%2Fkeystone~master~I4bcfbda1b542f09172f5b53185f063c6bea27205,openstack/keystone,master,I4bcfbda1b542f09172f5b53185f063c6bea27205,Allow project_id in catalog substitutions,MERGED,2016-02-12 14:49:00.000000000,2016-02-16 03:41:02.000000000,2016-02-16 03:41:02.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4}, {'_account_id': 2750}, {'_account_id': 6460}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-02-12 14:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/87b0cd9a73646740b6e0c02159bb64e7c9072254', 'message': ""Allow project_id in catalog substitutions\n\nWe allowed 'tenant_id' in catalog substitutions. The 'tenant' term is\ndeprecated in favor of 'project'. Also allow 'project_id' so that\nusers can stop using the deprecated term in one more place.\n\nChange-Id: I4bcfbda1b542f09172f5b53185f063c6bea27205\n""}, {'number': 2, 'created': '2016-02-12 15:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6800b2ea665d9e70a135a49ef15410f6e72cf08a', 'message': ""Allow project_id in catalog substitutions\n\nWe allowed 'tenant_id' in catalog substitutions. The 'tenant' term is\ndeprecated in favor of 'project'. Also allow 'project_id' so that\nusers can stop using the deprecated term in one more place.\n\nChange-Id: I4bcfbda1b542f09172f5b53185f063c6bea27205\n""}, {'number': 3, 'created': '2016-02-15 16:55:26.000000000', 'files': ['keystone/catalog/backends/templated.py', 'keystone/tests/unit/catalog/test_core.py', 'keystone/tests/unit/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/core.py', 'releasenotes/notes/catalog_project_id-519f5a70f9f7c4c6.yaml', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0d472c86e3e5c3c7a5077b1974cdac6bd686b83a', 'message': ""Allow project_id in catalog substitutions\n\nWe allowed 'tenant_id' in catalog substitutions. The 'tenant' term is\ndeprecated in favor of 'project'. Also allow 'project_id' so that\nusers can stop using the deprecated term in one more place.\n\nChange-Id: I4bcfbda1b542f09172f5b53185f063c6bea27205\n""}]",5,279576,0d472c86e3e5c3c7a5077b1974cdac6bd686b83a,17,8,3,6486,,,0,"Allow project_id in catalog substitutions

We allowed 'tenant_id' in catalog substitutions. The 'tenant' term is
deprecated in favor of 'project'. Also allow 'project_id' so that
users can stop using the deprecated term in one more place.

Change-Id: I4bcfbda1b542f09172f5b53185f063c6bea27205
",git fetch https://review.opendev.org/openstack/keystone refs/changes/76/279576/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/catalog/backends/templated.py', 'keystone/tests/unit/catalog/test_core.py', 'keystone/tests/unit/test_v3_catalog.py', 'keystone/catalog/backends/sql.py', 'keystone/catalog/core.py', 'keystone/contrib/endpoint_filter/backends/catalog_sql.py']",6,87b0cd9a73646740b6e0c02159bb64e7c9072254,support_project_id_subst," substitutions.update({ 'tenant_id': project_id, 'project_id': project_id, 'user_id': user_id, })"," substitutions.update({'tenant_id': project_id, 'user_id': user_id})",50,12
openstack%2Fsenlin~master~I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0,openstack/senlin,master,I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0,Add functional test for cluster node add/del,MERGED,2016-02-15 05:49:46.000000000,2016-02-16 03:33:20.000000000,2016-02-16 03:33:20.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-15 05:49:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/189fc45c2f25fa0337346c3e43c31179dffd26c9', 'message': 'Add functional test for cluster node add/del\n\nThis patch adds functional test for cluster node add/del cases.\n\nChange-Id: I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0\nCloses-Bug: #1545549\n'}, {'number': 2, 'created': '2016-02-16 02:12:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/8bde244a192c087602adb84465c857f31c9fb94e', 'message': 'Add functional test for cluster node add/del\n\nThis patch adds functional test for cluster node add/del cases.\n\nChange-Id: I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0\nCloses-Bug: #1545549\n'}, {'number': 3, 'created': '2016-02-16 02:51:31.000000000', 'files': ['senlin/tests/functional/test_cluster_membership.py', 'senlin/tests/functional/drivers/openstack/nova_v2.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/62bdeae0d78b7ee35b197374fda548f660d1c7fb', 'message': 'Add functional test for cluster node add/del\n\nThis patch adds functional test for cluster node add/del cases.\n\nChange-Id: I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0\nCloses-Bug: #1545549\n'}]",1,280069,62bdeae0d78b7ee35b197374fda548f660d1c7fb,19,4,3,11034,,,0,"Add functional test for cluster node add/del

This patch adds functional test for cluster node add/del cases.

Change-Id: I3840156cdbb7488d2c16b7b7fbf22ebb6a6aa1a0
Closes-Bug: #1545549
",git fetch https://review.opendev.org/openstack/senlin refs/changes/69/280069/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/functional/test_cluster_basic.py', 'senlin/tests/functional/drivers/openstack/nova_v2.py']",2,189fc45c2f25fa0337346c3e43c31179dffd26c9,bug/1545549," def server_metadata_get(self, server): def server_metadata_update(self, server, metadata): return def server_metadata_delete(self, server, key):"," def server_metadata_get(self, **params): def server_metadata_update(self, **params):",90,2
openstack%2Fpython-glanceclient~master~I123d206866914b92ce0f14d482b143502812c481,openstack/python-glanceclient,master,I123d206866914b92ce0f14d482b143502812c481,Support create images with locations in v2,ABANDONED,2015-12-31 08:49:51.000000000,2016-02-16 03:23:18.000000000,,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 14676}, {'_account_id': 15054}, {'_account_id': 17116}]","[{'number': 1, 'created': '2015-12-31 08:49:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f573768fcbe6eaa9be38e0b0a12799e74aec4de9', 'message': ""Support create images with locations in v2\n\nNow, it's only support create images with file in v2. It's useful\nto support locations as well to keep the same with v1.\n\nChange-Id: I123d206866914b92ce0f14d482b143502812c481\n""}, {'number': 2, 'created': '2015-12-31 09:54:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/40f5cc0095c2c2eff58b1c6cd61e3eff85261419', 'message': ""Support create images with locations in v2\n\nNow, it's only support create images with file in v2. It's useful\nto support locations as well to keep the same with v1.\n\nChange-Id: I123d206866914b92ce0f14d482b143502812c481\n""}, {'number': 3, 'created': '2016-01-05 03:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/7d123a408ea19e2c78d0708f7b465729835b1b15', 'message': ""Support create images with locations in v2\n\nNow, it's only support create images with file in v2. It's useful\nto support locations as well to keep the same with v1.\n\nCloses-bug: #1531050\nChange-Id: I123d206866914b92ce0f14d482b143502812c481\n""}, {'number': 4, 'created': '2016-01-12 03:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/87b124b02ab8869db7e3097e5d20cb6ed467e739', 'message': ""Support create images with locations in v2\n\nNow, it's only support create images with file in v2. It's useful\nto support locations as well to keep the same with v1.\n\nCloses-bug: #1531050\nChange-Id: I123d206866914b92ce0f14d482b143502812c481\n""}, {'number': 5, 'created': '2016-01-12 03:58:37.000000000', 'files': ['glanceclient/tests/unit/v2/test_shell_v2.py', 'glanceclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/b925cc756dc8966b203be83df3f242b4309a2c63', 'message': ""Support create images with locations in v2\n\nNow, it's only support create images with file in v2. It's useful\nto support locations as well to keep the same with v1.\n\nCloses-bug: #1531050\nChange-Id: I123d206866914b92ce0f14d482b143502812c481\n""}]",9,262712,b925cc756dc8966b203be83df3f242b4309a2c63,18,6,5,15054,,,0,"Support create images with locations in v2

Now, it's only support create images with file in v2. It's useful
to support locations as well to keep the same with v1.

Closes-bug: #1531050
Change-Id: I123d206866914b92ce0f14d482b143502812c481
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/12/262712/5 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/v2/shell.py'],1,f573768fcbe6eaa9be38e0b0a12799e74aec4de9,bug/1531050,"@utils.arg('--locations', metavar='<IMAGE_URL>', help=('URL where the data for this image already resides. For ' 'example, if the image data is stored in swift, you could ' 'specify \'swift+http://tenant%%3Aaccount:key@auth_url/' 'v2.0/container/obj\'. ' '(Note: \'%%3A\' is \':\' URL encoded.)')) location = fields.pop('locations', None) if location and file_name: utils.exit(""It's invalid to provide multiple image sources."") if location: args.id = image['id'] args.url = location args.metadata = '{}' do_location_add(gc, args) image = gc.images.get(args.id) finally: if file_name: utils.print_image(image)", finally: utils.print_image(image),17,1
openstack%2Fkeystone~master~I153e5568cd73c55608b02c72d4e44cec1682b17b,openstack/keystone,master,I153e5568cd73c55608b02c72d4e44cec1682b17b,"Avoid ""non-Pythonic"" method names",MERGED,2016-02-15 16:15:28.000000000,2016-02-16 03:22:21.000000000,2016-02-16 03:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-02-15 16:15:28.000000000', 'files': ['keystone/tests/unit/common/test_ldap.py', 'keystone/common/ldap/core.py', 'keystone/identity/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/b3a78840a0d9423c86f3f283ae45e6c07abc0590', 'message': 'Avoid ""non-Pythonic"" method names\n\nPython methods should follow this pattern: \'[a-z_][a-z0-9_]{2,}$\', e.g.,\n\'great_method_name\'. Change this  method name to comply with naming\nconventions.\n\nChange-Id: I153e5568cd73c55608b02c72d4e44cec1682b17b\n'}]",1,280309,b3a78840a0d9423c86f3f283ae45e6c07abc0590,8,3,1,8866,,,0,"Avoid ""non-Pythonic"" method names

Python methods should follow this pattern: '[a-z_][a-z0-9_]{2,}$', e.g.,
'great_method_name'. Change this  method name to comply with naming
conventions.

Change-Id: I153e5568cd73c55608b02c72d4e44cec1682b17b
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/280309/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/common/test_ldap.py', 'keystone/common/ldap/core.py', 'keystone/identity/backends/ldap.py']",3,b3a78840a0d9423c86f3f283ae45e6c07abc0590,avoid-non-pythonic-method-names," super(GroupApi, self).delete_tree(group_id)"," super(GroupApi, self).deleteTree(group_id)",7,7
openstack%2Fglance-specs~master~Ie3153a0eff93aa1caeebe256a05455c9c14e1de1,openstack/glance-specs,master,Ie3153a0eff93aa1caeebe256a05455c9c14e1de1,Add location manage mechanism,ABANDONED,2015-09-21 04:14:30.000000000,2016-02-16 03:22:09.000000000,,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 15054}, {'_account_id': 15309}, {'_account_id': 16683}]","[{'number': 1, 'created': '2015-09-21 04:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/1a6d9654f486e309c702b2867eeaf42068708c53', 'message': ""Add location manage mechanism\n\nNow,Now,when user delete an image, the image's file will be deleted as\nwell.This will cause some problems. Such as the image file which was\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image went wrong. So we need add a mechanism\nto distinguish the location file's owner. The image could be deleted\nonly by the owner.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 2, 'created': '2015-09-21 06:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/56f31f723530fa6bd059a49814e2309c346b9db3', 'message': ""Add location manage mechanism\n\nNow,Now,when user delete an image, the image's file will be deleted as\nwell.This will cause some problems. Such as the image file which was\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image went wrong. So we need add a mechanism\nto distinguish the location file's owner. The image could be deleted\nonly by the owner.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 3, 'created': '2015-09-21 06:28:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/c4a7e1db33dd88fa28e21b94371e1d11ffdef849', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 4, 'created': '2015-09-30 07:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/f0d21cd98decddbb4ea52502f751e2bec6f890bd', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 5, 'created': '2015-10-08 01:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/63e5f5e178122dd377b1e0dfba5310e8fd3ed4be', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 6, 'created': '2015-10-08 02:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/71aed6c1cf38f20e70c548637a94394f7e93694c', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 7, 'created': '2015-10-12 06:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/47849255a0f5da6e17631978a213d95a322f48c3', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 8, 'created': '2015-11-09 02:47:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/befdd1a293712171af18c0cbdcf75082f00211d2', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}, {'number': 9, 'created': '2015-11-09 04:08:48.000000000', 'files': ['specs/mitaka/add-location-manage-mechanism.rst'], 'web_link': 'https://opendev.org/openstack/glance-specs/commit/59991388fbd991da612f5f2b208a5d8b4cae5087', 'message': ""Add location manage mechanism\n\nNow when user delete an image, the image's file will be deleted as\nwell. This will cause some problems. Such as the image file which is\nusing by other image or Glance at the same time will be deleted too.\nThis will lead the other image works wrong. So we need add a mechanism\nto distinguish the location file's owner. So that we can delete the image\nfile under control.\n\nChange-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1\nImplements: blueprint add-location-manage-mechanism\n""}]",4,225547,59991388fbd991da612f5f2b208a5d8b4cae5087,27,7,9,15054,,,0,"Add location manage mechanism

Now when user delete an image, the image's file will be deleted as
well. This will cause some problems. Such as the image file which is
using by other image or Glance at the same time will be deleted too.
This will lead the other image works wrong. So we need add a mechanism
to distinguish the location file's owner. So that we can delete the image
file under control.

Change-Id: Ie3153a0eff93aa1caeebe256a05455c9c14e1de1
Implements: blueprint add-location-manage-mechanism
",git fetch https://review.opendev.org/openstack/glance-specs refs/changes/47/225547/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/add-location-manage-mechanism.rst'],1,1a6d9654f486e309c702b2867eeaf42068708c53,bp/add-location-manage-mechanism,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================= Add location manage mechanism ============================= https://blueprints.launchpad.net/glance/+spec/add-location-manage-mechanism Now when user delete an image, the image's file will be deleted as well. This will cause some problems. Such as the image file which was using by other image or Glance service at the same time will be deleted too. This will lead the other image went wrong. So we need add a mechanism to distinguish the location file's owner. So that we can delete the image file in control. Problem description =================== Here are two situations about the problem: 1.Create an image 'A' with image file and create another image 'B' refer to the A's location. Then delete image B. The image file will be deleted as well. Finally, A can't be use anymore. But the image file was uploaded by A and A did nothing.User may confuse that why an active image (A) can't be use. 2.Suppose there is an image file in store backend already. Create two images 'A' and 'B' with this image file. Then one of the image. The image file will be deleted and the other image could not be use anymore. But the image file doesn't belong to the Glance. If another Glance use the same backend file in image C at the same time. C can't be use any more. In the first situation, the image file belongs to A. So when delete B , image file should not be deleted. It will only be deleted when A is deleted. In the second situation, the image file doesn't belong to any image. So whenever A,B or C be deleted. the image file should not be deleted as well. It could be deleted by store backend administrator. Proposed change =============== 1.Add a column to enhance the image location table in db to indicate whether the image own the image file. 2.Add a new boolean property to image model. It will get the value from the image location table. and this value will pass to locations.py to be used by location model. Alternatives ------------ Don't modify the db. Only modify the location check logic. But in this way, we should traversing the image location table. It will reduce the performance. Data model impact ----------------- We will add a boolean property in the image model to show whether the image file belong to the image. REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- The image files which not belong to the images will not be deleted. User need to delete them by self if they want. Performance Impact ------------------ The new code will be called once deleting the image.There is no influence on performance,security or locking. Other deployer impact --------------------- This bp will be split into three patch.Until the last patch be merged, it doesn't take immediate effect. Developer impact ---------------- The image model will be added a new property. So developer should take a notice on it. Implementation ============== Assignee(s) ----------- wangxiyuan Reviewers --------- Work Items ---------- 1.DB change 2.Image model change 3.Location verify change 4.Add tests code. Dependencies ============ None Testing ======= Simple functional and unit tests is enough. Documentation Impact ==================== None References ========== None ",,149,0
openstack%2Fkeystone~master~I8af004437938408af6604af4ba0c594da217cca8,openstack/keystone,master,I8af004437938408af6604af4ba0c594da217cca8,Fix terms from patch 275706,MERGED,2016-02-15 23:00:59.000000000,2016-02-16 03:15:26.000000000,2016-02-16 03:15:26.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 17860}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-02-15 23:00:59.000000000', 'files': ['keystone/tests/unit/test_backend.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/46d21e6a5a0694ddc91110059ee3174b1d5deb5f', 'message': ""Fix terms from patch 275706\n\nPatch 275706 mentions 'domains roles' instead of 'domain role\nassignments', which may cause some confusion when domain specific\nroles become widely-used.\n\nChange-Id: I8af004437938408af6604af4ba0c594da217cca8\n""}]",0,280436,46d21e6a5a0694ddc91110059ee3174b1d5deb5f,8,4,1,10046,,,0,"Fix terms from patch 275706

Patch 275706 mentions 'domains roles' instead of 'domain role
assignments', which may cause some confusion when domain specific
roles become widely-used.

Change-Id: I8af004437938408af6604af4ba0c594da217cca8
",git fetch https://review.opendev.org/openstack/keystone refs/changes/36/280436/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_backend.py'],1,46d21e6a5a0694ddc91110059ee3174b1d5deb5f,," * Domain assignments must stay intact. domain_assignments = self.assignment_api.list_role_assignments( self.assertThat(domain_assignments, matchers.HasLength(2)) project_assignments = self.assignment_api.list_role_assignments( self.assertThat(project_assignments, matchers.HasLength(2)) project_assignments = self.assignment_api.list_role_assignments( self.assertThat(project_assignments, matchers.HasLength(0)) domain_assignments = self.assignment_api.list_role_assignments( self.assertThat(domain_assignments, matchers.HasLength(2)) # Make sure these remaining assignments are domain-related for assignment in domain_assignments: self.assertThat(assignment.keys(), matchers.Contains('domain_id'))"," * Domain roles must stay intact. domain_roles = self.assignment_api.list_role_assignments( self.assertThat(domain_roles, matchers.HasLength(2)) project_roles = self.assignment_api.list_role_assignments( self.assertThat(project_roles, matchers.HasLength(2)) project_roles = self.assignment_api.list_role_assignments( self.assertThat(project_roles, matchers.HasLength(0)) domain_roles = self.assignment_api.list_role_assignments( self.assertThat(domain_roles, matchers.HasLength(2)) # Make sure these remaining roles are domain-related for role in domain_roles: self.assertThat(role.keys(), matchers.Contains('domain_id'))",12,12
openstack%2Fnetworking-ovn~master~I13acae861390a79e29f59fa0e56a97ed5be6f831,openstack/networking-ovn,master,I13acae861390a79e29f59fa0e56a97ed5be6f831,Vagrant: Modify services,MERGED,2016-02-13 05:56:20.000000000,2016-02-16 03:00:50.000000000,2016-02-16 03:00:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 9515}]","[{'number': 1, 'created': '2016-02-13 05:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bff013f797cbf0fcf12f8a18843f8b2ef2546a60', 'message': 'Vagrant: Modify services\n\n1) Disable the ovn-controller service on the controller node\n   because no services depend on it.\n2) Disable OVS services on the controller node because no\n   neutron services depend on it.\n3) Disable OVN provider network configuration on the\n   controller node because we disable OVS on it.\n4) Move configuration of OVN_* environment variables to\n   DevStack.\n5) Move creation of host route for private network to\n   compute nodes.\n6) Enable DevStack logging to files and disable screen.\n7) Improve documentation.\n\nChange-Id: I13acae861390a79e29f59fa0e56a97ed5be6f831\n'}, {'number': 2, 'created': '2016-02-15 16:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/fb8d4ccde35725cda1c047ac34bf59e283711eef', 'message': 'Vagrant: Modify services\n\n1) Disable the ovn-controller service on the controller node\n   because no services depend on it.\n2) Disable OVS services on the controller node because no\n   neutron services depend on it.\n3) Disable OVN provider network configuration on the\n   controller node because we disable OVS on it.\n4) Move configuration of OVN_* environment variables to\n   DevStack.\n5) Move creation of host route for private network to\n   compute nodes.\n6) Enable DevStack logging to files and disable screen.\n7) Improve documentation.\n\nChange-Id: I13acae861390a79e29f59fa0e56a97ed5be6f831\n'}, {'number': 3, 'created': '2016-02-15 18:19:03.000000000', 'files': ['vagrant/provisioning/setup-compute.sh', 'vagrant/provisioning/setup-controller.sh', 'vagrant/provisioning/setup-db.sh'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/aed20c3ab44de5d1a4aba457ef0f8ddf95ccdf66', 'message': 'Vagrant: Modify services\n\n1) Disable the ovn-controller service on the controller node\n   because no services depend on it.\n2) Disable OVS services on the controller node because no\n   neutron services depend on it.\n3) Disable OVN provider network configuration on the\n   controller node because we disable OVS on it.\n4) Move configuration of OVN_* environment variables to\n   DevStack.\n5) Move creation of host route for private network to\n   compute nodes.\n6) Enable DevStack logging to files and disable screen.\n7) Improve documentation.\n\nChange-Id: I13acae861390a79e29f59fa0e56a97ed5be6f831\n'}]",1,279860,aed20c3ab44de5d1a4aba457ef0f8ddf95ccdf66,15,4,3,9515,,,0,"Vagrant: Modify services

1) Disable the ovn-controller service on the controller node
   because no services depend on it.
2) Disable OVS services on the controller node because no
   neutron services depend on it.
3) Disable OVN provider network configuration on the
   controller node because we disable OVS on it.
4) Move configuration of OVN_* environment variables to
   DevStack.
5) Move creation of host route for private network to
   compute nodes.
6) Enable DevStack logging to files and disable screen.
7) Improve documentation.

Change-Id: I13acae861390a79e29f59fa0e56a97ed5be6f831
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/60/279860/1 && git format-patch -1 --stdout FETCH_HEAD,"['vagrant/provisioning/setup-compute.sh', 'vagrant/provisioning/setup-controller.sh', 'vagrant/provisioning/setup-db.sh']",3,bff013f797cbf0fcf12f8a18843f8b2ef2546a60,vagrant-services1, # Enable logging to files. LOGFILE=/opt/stack/log/stack.sh.log USE_SCREEN=FALSE SCREEN_LOGDIR=/opt/stack/log/data,,66,42
openstack%2Fproject-config~master~I535d7f8170706b3af19ee8c060493c8246e2ce31,openstack/project-config,master,I535d7f8170706b3af19ee8c060493c8246e2ce31,Allow ironic jobs to run with tempest plugin,MERGED,2016-01-08 15:34:30.000000000,2016-02-16 02:44:24.000000000,2016-02-16 02:44:24.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4146}, {'_account_id': 5174}, {'_account_id': 6547}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7118}, {'_account_id': 7882}, {'_account_id': 7979}, {'_account_id': 8556}, {'_account_id': 10343}, {'_account_id': 11278}, {'_account_id': 11929}, {'_account_id': 14525}]","[{'number': 1, 'created': '2016-01-08 15:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2a1b8a8ebd15d1fc07f28d64702fb948af99b021', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso adjusts DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 2, 'created': '2016-01-12 15:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/98d3d7785be5abc616f1dc131a166267f06557a2', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso adjusts DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 3, 'created': '2016-01-12 15:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cf668716ec1d79b1bc4872c8ea0cafab245bf69b', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso adjusts DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nDepends-On: I6a26b1d1fcf088d5218b92e13911c48708af4ec8\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 4, 'created': '2016-01-12 15:22:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5eade42cd19648e882744e3b48535a4c3b54d46f', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nDepends-On: I6a26b1d1fcf088d5218b92e13911c48708af4ec8\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 5, 'created': '2016-01-12 15:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/23d863b566d33b7969fbdbd3bac9eb63f462159d', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 6, 'created': '2016-01-19 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0d97188fb025c3115bf4ef2a8842022314cbf714', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nThis patch retains the current 'baremetal' regex for the stable/kilo and\nstable/liberty branches. That support can be removed in the future.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 7, 'created': '2016-01-19 16:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/73dba2554ca479c7934a7b6c2a7d90d0b3f18349', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nThis patch retains the current 'baremetal' regex for the stable/kilo and\nstable/liberty branches. That support can be removed in the future.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 8, 'created': '2016-02-03 16:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c6f2cda9f414d45c2e76cd8c7104d7a16e450cde', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nThis patch retains the current 'baremetal' regex for the stable/kilo and\nstable/liberty branches. That support can be removed in the future.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 9, 'created': '2016-02-11 11:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/bd0c6bd1e72c345618c3d155cb4d958b38cb59d6', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nThis patch retains the current 'baremetal' regex for the stable/kilo and\nstable/liberty branches. That support can be removed in the future.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}, {'number': 10, 'created': '2016-02-14 20:07:56.000000000', 'files': ['jenkins/jobs/ironic.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/07c2233d8d5e0ba1b3db7db6f43b82fdf600a639', 'message': ""Allow ironic jobs to run with tempest plugin\n\nIronic is migrating to a tempest plugin. This change sets\nDEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and\nalso changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'\nin the name, as the plugin doesn't have 'baremetal' in all test names.\n\nThis patch retains the current 'baremetal' regex for the stable/kilo and\nstable/liberty branches. That support can be removed in the future.\n\nDepends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af\nChange-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31\n""}]",10,265311,07c2233d8d5e0ba1b3db7db6f43b82fdf600a639,61,15,10,10343,,,0,"Allow ironic jobs to run with tempest plugin

Ironic is migrating to a tempest plugin. This change sets
DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 so that the plugin is loaded, and
also changes DEVSTACK_GATE_TEMPEST_REGEX to include tests with 'ironic'
in the name, as the plugin doesn't have 'baremetal' in all test names.

This patch retains the current 'baremetal' regex for the stable/kilo and
stable/liberty branches. That support can be removed in the future.

Depends-On: Ic52806987dae9f9df561ebd662f12c3445d0e2af
Change-Id: I535d7f8170706b3af19ee8c060493c8246e2ce31
",git fetch https://review.opendev.org/openstack/project-config refs/changes/11/265311/9 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/ironic.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,2a1b8a8ebd15d1fc07f28d64702fb948af99b021,jroll," export DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" export DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 export DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic' tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" tempest-env: ""DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"" export DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1 export DEVSTACK_GATE_TEMPEST_REGEX='baremetal|ironic'"," tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' export DEVSTACK_GATE_TEMPEST_REGEX=""baremetal"" tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' export DEVSTACK_GATE_TEMPEST_REGEX=""baremetal""",16,12
openstack%2Fsenlin~master~Id20f39372f91579789d7916b5aeed2eddc864fc1,openstack/senlin,master,Id20f39372f91579789d7916b5aeed2eddc864fc1,Enforce 'max_clusters_per_project' quota,MERGED,2016-02-15 08:55:20.000000000,2016-02-16 02:39:52.000000000,2016-02-16 02:39:52.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 08:55:20.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py', 'senlin/common/exception.py', 'senlin/db/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/369b758142d0e17252afcda3e1d1db9b465b9b9f', 'message': ""Enforce 'max_clusters_per_project' quota\n\nThis patch enforces the clusters number quota per project. The intent is\nfor deployers to control how many resources can be consumed per project.\n\nChange-Id: Id20f39372f91579789d7916b5aeed2eddc864fc1\n""}]",0,280110,369b758142d0e17252afcda3e1d1db9b465b9b9f,7,3,1,8246,,,0,"Enforce 'max_clusters_per_project' quota

This patch enforces the clusters number quota per project. The intent is
for deployers to control how many resources can be consumed per project.

Change-Id: Id20f39372f91579789d7916b5aeed2eddc864fc1
",git fetch https://review.opendev.org/openstack/senlin refs/changes/10/280110/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_clusters.py', 'senlin/common/exception.py', 'senlin/db/api.py']",4,369b758142d0e17252afcda3e1d1db9b465b9b9f,enforce-cluster-quota,"def cluster_count_all(context, filters=None, project_safe=True): project_safe=project_safe)","def cluster_count_all(context, filters=None, project_safe=True, show_nested=False): project_safe=project_safe, show_nested=show_nested)",77,13
openstack%2Fsenlin~master~I19b11d77d4a53d55ea8add01dca64fa57da434b9,openstack/senlin,master,I19b11d77d4a53d55ea8add01dca64fa57da434b9,Rework unit tests for profile operations,MERGED,2016-02-15 06:25:34.000000000,2016-02-16 02:39:39.000000000,2016-02-16 02:39:39.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 06:25:34.000000000', 'files': ['senlin/tests/unit/engine/service/test_policies.py', 'senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_profiles.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/baa5812109e5aecc997bf07c56f8bf3b6c6ff6e6', 'message': 'Rework unit tests for profile operations\n\nThis reworks the unit tests for profile interfaces in service engine.\nThe intent is to make unit tests just unit tests rather than some\nsemi-functional tests.\n\nChange-Id: I19b11d77d4a53d55ea8add01dca64fa57da434b9\n'}]",0,280080,baa5812109e5aecc997bf07c56f8bf3b6c6ff6e6,7,3,1,8246,,,0,"Rework unit tests for profile operations

This reworks the unit tests for profile interfaces in service engine.
The intent is to make unit tests just unit tests rather than some
semi-functional tests.

Change-Id: I19b11d77d4a53d55ea8add01dca64fa57da434b9
",git fetch https://review.opendev.org/openstack/senlin refs/changes/80/280080/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_policies.py', 'senlin/tests/unit/engine/service/test_profiles.py']",3,baa5812109e5aecc997bf07c56f8bf3b6c6ff6e6,ut-profile,"import mockfrom oslo_utils import uuidutilsfrom senlin.common import exception as exc from senlin.db.sqlalchemy import api as db_apifrom senlin.profiles import base as profile_mod def _setup_fakes(self): """"""Set up fake proflie for the purpose of testing. This method is provided in a standalone function because not all test cases need such a set up. """""" @mock.patch.object(db_api, 'profile_get') def test_profile_find_by_uuid(self, mock_get): x_profile = mock.Mock() mock_get.return_value = x_profile aid = uuidutils.generate_uuid() result = self.eng.profile_find(self.ctx, aid) self.assertEqual(x_profile, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'profile_get_by_name') @mock.patch.object(db_api, 'profile_get') def test_profile_find_by_uuid_as_name(self, mock_get, mock_get_name): x_profile = mock.Mock() mock_get_name.return_value = x_profile mock_get.return_value = None aid = uuidutils.generate_uuid() result = self.eng.profile_find(self.ctx, aid) self.assertEqual(x_profile, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'profile_get_by_name') def test_profile_find_by_name(self, mock_get_name): x_profile = mock.Mock() mock_get_name.return_value = x_profile aid = 'this-is-not-uuid' result = self.eng.profile_find(self.ctx, aid) self.assertEqual(x_profile, result) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'profile_get_by_short_id') @mock.patch.object(db_api, 'profile_get_by_name') def test_profile_find_by_shortid(self, mock_get_name, mock_get_shortid): x_profile = mock.Mock() mock_get_shortid.return_value = x_profile mock_get_name.return_value = None aid = 'abcd-1234-abcd' result = self.eng.profile_find(self.ctx, aid) self.assertEqual(x_profile, result) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) mock_get_shortid.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'profile_get_by_name') def test_profile_find_not_found(self, mock_get_name): mock_get_name.return_value = None ex = self.assertRaises(exc.ProfileNotFound, self.eng.profile_find, self.ctx, 'Bogus') self.assertEqual('The profile (Bogus) could not be found.', six.text_type(ex)) mock_get_name.assert_called_once_with(self.ctx, 'Bogus', project_safe=True) @mock.patch.object(profile_mod.Profile, 'load_all') def test_profile_list(self, mock_load): x_obj_1 = mock.Mock() x_obj_1.to_dict.return_value = {'k': 'v1'} x_obj_2 = mock.Mock() x_obj_2.to_dict.return_value = {'k': 'v2'} mock_load.return_value = [x_obj_1, x_obj_2] result = self.eng.profile_list(self.ctx) self.assertEqual([{'k': 'v1'}, {'k': 'v2'}], result) mock_load.assert_called_once_with(self.ctx, limit=None, marker=None, filters=None, sort=None, project_safe=True) @mock.patch.object(profile_mod.Profile, 'load_all') def test_profile_list_with_params(self, mock_load): mock_load.return_value = [] result = self.eng.profile_list(self.ctx, limit=10, marker='KEY', filters={'foo': 'bar'}, sort='k:asc', project_safe=False) self.assertEqual([], result) mock_load.assert_called_once_with(self.ctx, limit=10, marker='KEY', filters={'foo': 'bar'}, sort='k:asc', project_safe=False) def test_profile_list_bad_param(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.profile_list, self.ctx, limit='no') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.profile_list, self.ctx, project_safe='no') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) def test_profile_create_default(self): self._setup_fakes() @mock.patch.object(db_api, 'profile_get_by_name') def test_profile_create_name_conflict(self, mock_get): mock_get.return_value = mock.Mock() spec = { 'type': 'FakeProfile', 'version': '1.0', 'properties': { 'LIST': ['A', 'B'], 'MAP': {'KEY1': 11, 'KEY2': 12}, } } self.ctx, 'FAKE_NAME', spec) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(""The request is malformed: A profile named "" ""'FAKE_NAME' already exists."", mock_get.assert_called_once_with(self.ctx, 'FAKE_NAME', project_safe=True) # We skip the fakes setup, so we won't get the proper profile type spec = { 'type': 'FakeProfile', 'version': '1.0', 'properties': { 'LIST': ['A', 'B'], 'MAP': {'KEY1': 11, 'KEY2': 12}, } } self.ctx, 'p-2', spec) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) ""type (FakeProfile-1.0) is not found."", # This test is for the profile object constructor which may throw # exceptions if the spec is invalid self._setup_fakes() self.ctx, 'FAKE_PROFILE', self.spec) self.assertEqual(exc.SpecValidationFailed, ex.exc_info[0]) self.assertEqual('Unrecognizable spec item ""KEY3""', six.text_type(ex.exc_info[1])) self._setup_fakes() mock_validate = self.patchobject(fakes.TestProfile, 'validate') mock_validate.side_effect = exc.InvalidSpec(message='BOOM') self.eng.profile_create, self.ctx, 'p-2', self.spec) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: BOOM', six.text_type(ex.exc_info[1])) @mock.patch.object(profile_mod.Profile, 'load') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_get(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_profile = mock.Mock() x_profile.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_profile result = self.eng.profile_get(self.ctx, 'FAKE_PROFILE') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_load.assert_called_once_with(self.ctx, profile=x_obj) @mock.patch.object(service.EngineService, 'profile_find') def test_profile_get_not_found(self, mock_find): mock_find.side_effect = exc.ProfileNotFound(profile='Bogus') self.assertEqual(exc.ProfileNotFound, ex.exc_info[0]) self.assertEqual('The profile (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(profile_mod.Profile, 'load') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_update(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_profile = mock.Mock() x_profile.name = 'OLD_NAME' x_profile.metadata = {'V': 'K'} x_profile.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_profile result = self.eng.profile_update(self.ctx, 'FAKE_PROFILE', name='NEW_NAME', metadata={'K': 'V'}) self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_load.assert_called_once_with(self.ctx, profile=x_obj) self.assertEqual('NEW_NAME', x_profile.name) self.assertEqual({'K': 'V', 'V': 'K'}, x_profile.metadata) x_profile.store.assert_called_once_with(self.ctx) @mock.patch.object(service.EngineService, 'profile_find') def test_profile_update_not_found(self, mock_find): mock_find.side_effect = exc.ProfileNotFound(profile='Bogus') self.ctx, 'Bogus', name='NEW_NAME') self.assertEqual(exc.ProfileNotFound, ex.exc_info[0]) self.assertEqual('The profile (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(profile_mod.Profile, 'load') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_update_no_change(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_profile = mock.Mock() x_profile.name = 'OLD_NAME' x_profile.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_profile result = self.eng.profile_update(self.ctx, 'FAKE_PROFILE', name='OLD_NAME') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_load.assert_called_once_with(self.ctx, profile=x_obj) self.assertEqual(0, x_profile.store.call_count) self.assertEqual('OLD_NAME', x_profile.name) @mock.patch.object(profile_mod.Profile, 'delete') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_delete(self, mock_find, mock_delete): x_obj = mock.Mock(id='PROFILE_ID') mock_find.return_value = x_obj mock_delete.return_value = None result = self.eng.profile_delete(self.ctx, 'FAKE_PROFILE') mock_find.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_delete.assert_called_once_with(self.ctx, 'PROFILE_ID') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_delete_not_found(self, mock_find): mock_find.side_effect = exc.ProfileNotFound(profile='Bogus') self.eng.profile_delete, self.ctx, 'Bogus') self.assertEqual(exc.ProfileNotFound, ex.exc_info[0]) self.assertEqual('The profile (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(profile_mod.Profile, 'delete') @mock.patch.object(service.EngineService, 'profile_find') def test_profile_delete_profile_in_use(self, mock_find, mock_delete): x_obj = mock.Mock(id='PROFILE_ID') mock_find.return_value = x_obj err = exc.ResourceBusyError(resource_type='profile', resource_id='PROFILE_ID') mock_delete.side_effect = err self.eng.profile_delete, self.ctx, 'FAKE_PROFILE') self.assertEqual(exc.ResourceInUse, ex.exc_info[0]) self.assertEqual('The profile (PROFILE_ID) is still in use.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_delete.assert_called_once_with(self.ctx, 'PROFILE_ID')","from senlin.common import exception from senlin.common.i18n import _ self.eng.init_tgm() def test_profile_create_default(self): self.assertIsInstance(result, dict) def test_profile_create_already_exists(self): result = self.eng.profile_create(self.ctx, 'p-1', self.spec) self.assertIsNotNone(result) self.ctx, 'p-1', self.spec) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(_(""The request is malformed: The profile (p-1) "" ""already exists.""), def test_profile_create_with_metadata(self): metadata = {'group': 'mars'} result = self.eng.profile_create(self.ctx, 'p-1', self.spec, metadata=metadata) self.assertEqual(metadata, result['metadata']) self.spec['type'] = 'Bogus' self.ctx, 'p', self.spec) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) ""type (Bogus-1.0) is not supported."", self.ctx, 'p', self.spec) self.assertEqual(exception.SpecValidationFailed, ex.exc_info[0]) self.spec['properties'] = {'INT': 1} self.patchobject(fakes.TestProfile, 'validate', side_effect=exception.InvalidSpec(message='BOOM')) self.eng.profile_create, self.ctx, 'p', self.spec) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) def test_profile_get(self): p = self.eng.profile_create(self.ctx, 'p-1', self.spec) for identity in [p['id'], p['id'][:6], 'p-1']: result = self.eng.profile_get(self.ctx, identity) self.assertIsInstance(result, dict) self.assertEqual(p['id'], result['id']) self.assertEqual(exception.ProfileNotFound, ex.exc_info[0]) def test_profile_list(self): p1 = self.eng.profile_create(self.ctx, 'p-1', self.spec) p2 = self.eng.profile_create(self.ctx, 'p-2', self.spec) result = self.eng.profile_list(self.ctx) self.assertIsInstance(result, list) names = [p['name'] for p in result] ids = [p['id'] for p in result] self.assertIn(p1['name'], names) self.assertIn(p2['name'], names) self.assertIn(p1['id'], ids) self.assertIn(p2['id'], ids) def test_profile_list_with_limit_marker(self): p1 = self.eng.profile_create(self.ctx, 'p-1', self.spec) p2 = self.eng.profile_create(self.ctx, 'p-2', self.spec) result = self.eng.profile_list(self.ctx, limit=0) self.assertEqual(0, len(result)) result = self.eng.profile_list(self.ctx, limit=1) self.assertEqual(1, len(result)) result = self.eng.profile_list(self.ctx, limit=2) self.assertEqual(2, len(result)) result = self.eng.profile_list(self.ctx, limit=3) self.assertEqual(2, len(result)) result = self.eng.profile_list(self.ctx, marker=p1['id']) self.assertEqual(1, len(result)) result = self.eng.profile_list(self.ctx, marker=p2['id']) self.assertEqual(0, len(result)) self.eng.profile_create(self.ctx, 'p-3', self.spec) result = self.eng.profile_list(self.ctx, limit=1, marker=p1['id']) self.assertEqual(1, len(result)) result = self.eng.profile_list(self.ctx, limit=2, marker=p1['id']) self.assertEqual(2, len(result)) def test_profile_list_with_sorting(self): p1 = self.eng.profile_create(self.ctx, 'p-B', self.spec) p2 = self.eng.profile_create(self.ctx, 'p-A', self.spec) p3 = self.eng.profile_create(self.ctx, 'p-C', self.spec) # default by created_at result = self.eng.profile_list(self.ctx) self.assertEqual(p1['id'], result[0]['id']) self.assertEqual(p2['id'], result[1]['id']) # use name for sorting result = self.eng.profile_list(self.ctx, sort='name') self.assertEqual(p2['id'], result[0]['id']) self.assertEqual(p1['id'], result[1]['id']) # use name for sorting (descending) result = self.eng.profile_list(self.ctx, sort='name:desc') self.assertEqual(p3['id'], result[0]['id']) result = self.eng.profile_list(self.ctx, sort='duang') self.assertIsNotNone(result) def test_profile_list_with_filters(self): self.eng.profile_create(self.ctx, 'p-B', self.spec) self.eng.profile_create(self.ctx, 'p-A', self.spec) self.eng.profile_create(self.ctx, 'p-C', self.spec) result = self.eng.profile_list(self.ctx, filters={'name': 'p-B'}) self.assertEqual(1, len(result)) self.assertEqual('p-B', result[0]['name']) result = self.eng.profile_list(self.ctx, filters={'name': 'p-D'}) self.assertEqual(0, len(result)) def test_profile_list_bad_param(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.profile_list, self.ctx, limit='no') self.assertEqual(exception.InvalidParameter, ex.exc_info[0]) def test_profile_list_empty(self): result = self.eng.profile_list(self.ctx) self.assertIsInstance(result, list) self.assertEqual(0, len(result)) def test_profile_find(self): p = self.eng.profile_create(self.ctx, 'p-1', self.spec) pid = p['id'] result = self.eng.profile_find(self.ctx, pid) self.assertIsNotNone(result) # short id result = self.eng.profile_find(self.ctx, pid[:5]) self.assertIsNotNone(result) # name result = self.eng.profile_find(self.ctx, 'p-1') self.assertIsNotNone(result) # others self.assertRaises(exception.ProfileNotFound, self.eng.profile_find, self.ctx, 'Bogus') def test_profile_update_fields(self): p1 = self.eng.profile_create(self.ctx, 'p-1', self.spec, metadata={'foo': 'bar'}) pid = p1['id'] self.assertEqual(self.spec, p1['spec']) # 1. update name p2 = self.eng.profile_update(self.ctx, pid, name='p-2') self.assertEqual(pid, p2['id']) self.assertEqual('p-2', p2['name']) # check persisted into db p = self.eng.profile_get(self.ctx, pid) self.assertEqual('p-2', p['name']) # 2. update metadata p2 = self.eng.profile_update(self.ctx, pid, metadata={'bar': 'foo'}) self.assertEqual(pid, p2['id']) self.assertEqual({'bar': 'foo'}, p2['metadata']) # check persisted into db p = self.eng.profile_get(self.ctx, pid) self.assertEqual({'bar': 'foo'}, p['metadata']) def test_profile_update_not_found(self): self.ctx, 'Bogus', name='new name') self.assertEqual(exception.ProfileNotFound, ex.exc_info[0]) def test_profile_update_using_find(self): p1 = self.eng.profile_create(self.ctx, 'p-1', self.spec, metadata={'foo': 'bar'}) pid = p1['id'] p2 = self.eng.profile_update(self.ctx, pid, name='p-2') self.assertEqual(pid, p2['id']) self.assertEqual('p-2', p2['name']) # use short id p3 = self.eng.profile_update(self.ctx, pid[:6], name='p-3') self.assertEqual(pid, p3['id']) self.assertEqual('p-3', p3['name']) p4 = self.eng.profile_update(self.ctx, 'p-3', name='p-4') self.assertEqual(pid, p4['id']) self.assertEqual('p-4', p4['name']) def test_profile_delete(self): p1 = self.eng.profile_create(self.ctx, 'p-1', self.spec, metadata={'foo': 'bar'}) pid = p1['id'] result = self.eng.profile_delete(self.ctx, pid) self.eng.profile_get, self.ctx, pid) self.assertEqual(exception.ProfileNotFound, ex.exc_info[0]) def test_profile_delete_not_found(self): self.eng.profile_get, self.ctx, 'Bogus') self.assertEqual(exception.ProfileNotFound, ex.exc_info[0])",331,195
openstack%2Fheat-translator~master~Id78964fe12a9fba814d74695f7e05257112f5990,openstack/heat-translator,master,Id78964fe12a9fba814d74695f7e05257112f5990,Treat OS version as an optional property,MERGED,2016-02-15 23:01:44.000000000,2016-02-16 02:37:55.000000000,2016-02-16 02:37:55.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2016-02-15 23:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/17a254cce2f3d748807d5c27df23ada049a26041', 'message': 'Treat OS version as an optional property\n\nTOSCA Compute capability OS has version as an optional property, treat it\naccordinly.\n\nChange-Id: Id78964fe12a9fba814d74695f7e05257112f5990\nCloses-Bug: #1545870\n'}, {'number': 2, 'created': '2016-02-16 02:20:20.000000000', 'files': ['translator/hot/tosca/tosca_compute.py', 'translator/tests/data/test_single_server_without_optional_version_prop.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/tests/data/hot_output/hot_single_server_without_tosca_os_version.yaml'], 'web_link': 'https://opendev.org/openstack/heat-translator/commit/18763928c2b3f95aec02708a139677a1113593fd', 'message': 'Treat OS version as an optional property\n\nTOSCA Compute capability OS has version as an optional property, treat it\naccordinly.\n\nChange-Id: Id78964fe12a9fba814d74695f7e05257112f5990\nCloses-Bug: #1545870\n'}]",0,280437,18763928c2b3f95aec02708a139677a1113593fd,8,2,2,6456,,,0,"Treat OS version as an optional property

TOSCA Compute capability OS has version as an optional property, treat it
accordinly.

Change-Id: Id78964fe12a9fba814d74695f7e05257112f5990
Closes-Bug: #1545870
",git fetch https://review.opendev.org/openstack/heat-translator refs/changes/37/280437/2 && git format-patch -1 --stdout FETCH_HEAD,"['translator/hot/tosca/tosca_compute.py', 'translator/tests/data/test_single_server_without_optional_version_prop.yaml', 'translator/tests/test_tosca_hot_translation.py', 'translator/tests/data/hot_output/hot_single_server_without_tosca_os_version.yaml']",4,17a254cce2f3d748807d5c27df23ada049a26041,bug/1545870,"heat_template_version: 2013-05-23 description: > TOSCA simple profile that just defines a single compute instance and selects a flavor and host Operating System for the Compute node. Note, this is just a test template showing Compute without optional 'version' property of OS capability. In general, you should have version to narrow down your image selection. parameters: {} resources: my_server: type: OS::Nova::Server properties: flavor: m1.medium image: ubuntu-12.04-software-config-os-init key_name: userkey user_data_format: SOFTWARE_CONFIG outputs: {} ",,54,2
openstack%2Fkeystone~master~I810854f50257b9dc805248ff1017521cc82d5d73,openstack/keystone,master,I810854f50257b9dc805248ff1017521cc82d5d73,Avoid `None` as a redundant argument to dict.get(),MERGED,2016-02-15 16:41:02.000000000,2016-02-16 02:36:52.000000000,2016-02-16 02:36:52.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 10873}, {'_account_id': 17860}, {'_account_id': 19779}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-02-15 16:41:02.000000000', 'files': ['keystone/tests/unit/fakeldap.py', 'keystone/tests/unit/core.py', 'keystone/revoke/model.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d32d9de2aa45c01eea58f23500cf683d57427783', 'message': ""Avoid `None` as a redundant argument to dict.get()\n\n`dict.get()` returns `None` by default, if a key wasn't found.\nRemoving `None` as second argument to avoid redundancy.\n\nChange-Id: I810854f50257b9dc805248ff1017521cc82d5d73\n""}]",0,280319,d32d9de2aa45c01eea58f23500cf683d57427783,10,6,1,8866,,,0,"Avoid `None` as a redundant argument to dict.get()

`dict.get()` returns `None` by default, if a key wasn't found.
Removing `None` as second argument to avoid redundancy.

Change-Id: I810854f50257b9dc805248ff1017521cc82d5d73
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/280319/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/fakeldap.py', 'keystone/tests/unit/core.py', 'keystone/revoke/model.py']",3,d32d9de2aa45c01eea58f23500cf683d57427783,, v = kwargs.get(k)," v = kwargs.get(k, None)",3,3
openstack%2Fdiskimage-builder~master~I27da31be9a8335037d407763fe80032819663d4f,openstack/diskimage-builder,master,I27da31be9a8335037d407763fe80032819663d4f,Don't remove yum in 99-remove-extra-packages,ABANDONED,2015-11-25 03:41:47.000000000,2016-02-16 02:34:01.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 6928}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-11-25 03:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/3bfb45641eec05415b9b6aca918f195958dc15a0', 'message': ""Don't remove yum in 99-remove-extra-packages\n\nThe only reason yum was on the system was because of the install of\nyum-utils in I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03.  With this\nconverted to a dnf command we can just use the standard YUM variable\nthat the fedora elements will set to dnf\n\nChange-Id: I27da31be9a8335037d407763fe80032819663d4f\n""}, {'number': 2, 'created': '2015-11-25 04:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/66797e9d6bcc5ad22719eb7a1699c173cad4cee5', 'message': ""Don't remove yum in 99-remove-extra-packages\n\nThe only reason yum was on the system was because of the install of\nyum-utils in I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03.  With this\nconverted to a dnf command we can just use the standard YUM variable\nthat the fedora elements will set to dnf\n\nChange-Id: I27da31be9a8335037d407763fe80032819663d4f\n""}, {'number': 3, 'created': '2015-12-02 07:32:17.000000000', 'files': ['elements/ironic-agent/finalise.d/99-remove-extra-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/26376f5430593e3f2b5ba93522512ca93b319fc5', 'message': ""Don't remove yum in 99-remove-extra-packages\n\nThe only reason yum was on the system was because of the install of\nyum-utils in I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03.  With this\nconverted to a dnf command we can just use the standard YUM variable\nthat the fedora elements will set to dnf\n\nChange-Id: I27da31be9a8335037d407763fe80032819663d4f\n""}]",0,249540,26376f5430593e3f2b5ba93522512ca93b319fc5,16,4,3,7118,,,0,"Don't remove yum in 99-remove-extra-packages

The only reason yum was on the system was because of the install of
yum-utils in I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03.  With this
converted to a dnf command we can just use the standard YUM variable
that the fedora elements will set to dnf

Change-Id: I27da31be9a8335037d407763fe80032819663d4f
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/40/249540/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/ironic-agent/finalise.d/99-remove-extra-packages'],1,3bfb45641eec05415b9b6aca918f195958dc15a0,f23,YUM=${YUM:-yum} ${YUM} clean all," if [ $DIB_RELEASE -ge 22 ]; then # Remove yum, >= F22 defaults to dnf dnf remove yum -y # Remove package manager cache dnf clean all else # Remove package manager cache yum clean all fi",3,9
openstack%2Ftosca-parser~master~Idb2454d78ab6b26366355817d76885799d90c08e,openstack/tosca-parser,master,Idb2454d78ab6b26366355817d76885799d90c08e,Implement LoadBalancer node type per TOSCA v1.0 spec,MERGED,2016-02-04 20:25:43.000000000,2016-02-16 02:15:04.000000000,2016-02-16 02:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 6456}, {'_account_id': 7514}]","[{'number': 1, 'created': '2016-02-04 20:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/7a1cc73673732219c8effc2cb25339b290a57cd2', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 2, 'created': '2016-02-09 19:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/4c21fba4317d9fd9ac05ac461ddbb4ea27a64603', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 3, 'created': '2016-02-09 23:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/b7dcc64821536725de19691cbef08f22abf79a41', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 4, 'created': '2016-02-10 20:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/faed76b35048a4bf36dbec3dadb4e9e762c51c1d', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 5, 'created': '2016-02-11 01:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/4cb763aaa9553069fef8e61b91543a05d82416cf', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 6, 'created': '2016-02-11 03:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/dc02d5aec542f25f771038e4637ce6eda5b30784', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 7, 'created': '2016-02-12 21:53:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/a1f0b6ce4dbad6bdd6df2322aea0a10cfac0ea7b', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 8, 'created': '2016-02-13 06:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/9a0000cba895e8dc9a611a36ac497eea3930fbdb', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 9, 'created': '2016-02-13 06:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/2b03e8caa5291778a64df2970340281c70c0bd93', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 10, 'created': '2016-02-13 06:28:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/0e694c538bca723984a252f66bafe4717a563b64', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 11, 'created': '2016-02-15 21:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/74cee955a2fbee1139474f5e55250a8252131a81', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}, {'number': 12, 'created': '2016-02-15 22:37:42.000000000', 'files': ['toscaparser/tests/data/tosca_load_balancer.yaml', 'toscaparser/elements/TOSCA_definition_1_0.yaml', 'toscaparser/tests/test_datatypes.py', 'toscaparser/elements/property_definition.py', 'toscaparser/tests/test_toscatplvalidation.py', 'toscaparser/common/exception.py', 'toscaparser/tests/test_properties.py', 'toscaparser/entity_template.py'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/3135ba26041a73c2fe0d9c2369bc21164e20b4bd', 'message': 'Implement LoadBalancer node type per TOSCA v1.0 spec\n\nImplement the schema with validation for a TOSCA LoadBalancer\nnode type as per definition in TOSCA Simple Profile in YAML\nversion 1.0 specification.\n\nChange-Id: Idb2454d78ab6b26366355817d76885799d90c08e\n'}]",36,276432,3135ba26041a73c2fe0d9c2369bc21164e20b4bd,41,3,12,7514,,,0,"Implement LoadBalancer node type per TOSCA v1.0 spec

Implement the schema with validation for a TOSCA LoadBalancer
node type as per definition in TOSCA Simple Profile in YAML
version 1.0 specification.

Change-Id: Idb2454d78ab6b26366355817d76885799d90c08e
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/32/276432/12 && git format-patch -1 --stdout FETCH_HEAD,"['toscaparser/tests/data/tosca_load_balancer.yaml', 'toscaparser/elements/TOSCA_definition_1_0.yaml']",2,7a1cc73673732219c8effc2cb25339b290a57cd2,bp/tosca-load-balancer,"tosca.nodes.LoadBalancer: derived_from: tosca.nodes.Root properties: algorithm: type: string required: false status: experimental capabilities: client: type: tosca.capabilities.Endpoint.Public occurrences: [0, UNBOUNDED] description: the Floating (IP) client’s on the public network can connect to requirements: - application: capability: tosca.capabilities.Endpoint relationship: tosca.relationships.RoutesTo occurrences: [0, UNBOUNDED] description: Connection to one or more load balanced applications ",,94,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I69fb3a1911cfe3baea3349da8f3e185dddf60a95,openstack/tripleo-heat-templates,stable/liberty,I69fb3a1911cfe3baea3349da8f3e185dddf60a95,Fix MidoNet errors,MERGED,2016-02-09 09:02:08.000000000,2016-02-16 02:14:14.000000000,2016-02-16 02:14:13.000000000,"[{'_account_id': 3}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-02-09 09:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/04952619253fe966efcd9342221ae63a4755ea25', 'message': 'Fix MidoNet errors\n\nSome assignments must be fixed in order to make run midonet with HA\npacemaker properly and when the network isolation is enabled.\n\nChange-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95\n(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)\n'}, {'number': 2, 'created': '2016-02-12 16:31:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2143954c23e4d2a2b29b0469d3373ecc3f5b6d46', 'message': 'Fix MidoNet errors\n\nSome assignments must be fixed in order to make run midonet with HA\npacemaker properly and when the network isolation is enabled.\n\nChange-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95\n(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)\n'}, {'number': 3, 'created': '2016-02-15 16:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2fc6d4c07214412c651be65580d9ade32f814cf0', 'message': 'Fix MidoNet errors\n\nSome assignments must be fixed in order to make run midonet with HA\npacemaker properly and when the network isolation is enabled.\n\nChange-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95\n(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)\n'}, {'number': 4, 'created': '2016-02-15 16:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2c9288e3c57bf021ea11dd403835cf140c13f3c8', 'message': 'Fix MidoNet errors\n\nSome assignments must be fixed in order to make run midonet with HA\npacemaker properly and when the network isolation is enabled.\n\nChange-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95\n(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)\n'}, {'number': 5, 'created': '2016-02-15 20:11:02.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/vip-config.yaml', 'puppet/all-nodes-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/58270f55f586f4f4b6695944d0d1f1fdaf7e0fa7', 'message': 'Fix MidoNet errors\n\nSome assignments must be fixed in order to make run midonet with HA\npacemaker properly and when the network isolation is enabled.\n\nChange-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95\n(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)\n'}]",0,277742,58270f55f586f4f4b6695944d0d1f1fdaf7e0fa7,20,2,5,7505,,,0,"Fix MidoNet errors

Some assignments must be fixed in order to make run midonet with HA
pacemaker properly and when the network isolation is enabled.

Change-Id: I69fb3a1911cfe3baea3349da8f3e185dddf60a95
(cherry picked from commit b2593e0722925c733128af41ae0d0b9925d035de)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/42/277742/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/vip-config.yaml', 'puppet/all-nodes-config.yaml']",4,04952619253fe966efcd9342221ae63a4755ea25,cherrypick_enable_services," # TODO: pass a `midonet_api_node_ips` var midonet_api_node_ips: str_replace: template: ""['SERVERS_LIST']"" params: SERVERS_LIST: list_join: - ""','"" - {get_param: neutron_api_node_ips}",,31,14
openstack%2Fhorizon~master~I641c99253dbeed092e8aa0caa8d6a54f1ec0995d,openstack/horizon,master,I641c99253dbeed092e8aa0caa8d6a54f1ec0995d,Fix issue with some modals are missing backdrop,ABANDONED,2016-02-16 02:06:09.000000000,2016-02-16 02:11:20.000000000,,[],"[{'number': 1, 'created': '2016-02-16 02:06:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13e4d51a1a1420552de66ae37663544a13102b3a', 'message': ""Fix issue with some modals are missing backdrop\n\nSome modal views are inheriting from ModalFormMixin directly instead of\nfrom ModalFormView (i.e. NonMembersView). This causes inconsistency with\nsome modal does not have a backdrop (not inheriting ModalBackdropMixin).\nThere are 7 places that inherit from ModalFormView directly now, and\nthey appear to be needing a backdrop; it'd be logical that\nModalFormMixin inherit from ModalBackdropMixin.\n\nChange-Id: I641c99253dbeed092e8aa0caa8d6a54f1ec0995d\nCloses-Bug: #1543251\n""}, {'number': 2, 'created': '2016-02-16 02:08:09.000000000', 'files': ['horizon/forms/views.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/5020c053636ad9f780690690e019efb65fcf85c0', 'message': ""Fix issue with some modals are missing backdrop\n\nSome modal views are inheriting from ModalFormMixin directly instead of\nfrom ModalFormView (i.e. NonMembersView). This causes inconsistency with\nsome modal does not have a backdrop (not inheriting ModalBackdropMixin).\nThere are 7 places that inherit from ModalFormView directly now, and\nthey appear to be needing a backdrop; it'd be logical that\nModalFormMixin inherit from ModalBackdropMixin.\n\nChange-Id: I641c99253dbeed092e8aa0caa8d6a54f1ec0995d\nCloses-Bug: #1543251\n""}]",0,280470,5020c053636ad9f780690690e019efb65fcf85c0,3,0,2,14078,,,0,"Fix issue with some modals are missing backdrop

Some modal views are inheriting from ModalFormMixin directly instead of
from ModalFormView (i.e. NonMembersView). This causes inconsistency with
some modal does not have a backdrop (not inheriting ModalBackdropMixin).
There are 7 places that inherit from ModalFormView directly now, and
they appear to be needing a backdrop; it'd be logical that
ModalFormMixin inherit from ModalBackdropMixin.

Change-Id: I641c99253dbeed092e8aa0caa8d6a54f1ec0995d
Closes-Bug: #1543251
",git fetch https://review.opendev.org/openstack/horizon refs/changes/70/280470/2 && git format-patch -1 --stdout FETCH_HEAD,['horizon/forms/views.py'],1,13e4d51a1a1420552de66ae37663544a13102b3a,bug/1543251,"class ModalFormMixin(ModalBackdropMixin):class ModalFormView(ModalBackdropMixin, views.HorizonFormView):","class ModalFormMixin(object):class ModalFormView(ModalBackdropMixin, ModalFormMixin, views.HorizonFormView):",2,2
openstack%2Fheat~master~I792747c24df7009d02590f6092beef397ca753b5,openstack/heat,master,I792747c24df7009d02590f6092beef397ca753b5,Add floating_ip property to Nova::Server nics,MERGED,2015-08-27 15:02:18.000000000,2016-02-16 02:06:10.000000000,2016-02-16 02:06:10.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 12321}, {'_account_id': 12404}, {'_account_id': 13009}]","[{'number': 1, 'created': '2015-08-27 15:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d035529efae40ddc40f98f861855fbc468de721d', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nbp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 2, 'created': '2015-08-27 15:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d9c6f68e64bfbe8eafc660c0a49cbbc93c74e811', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nbp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 3, 'created': '2015-08-28 11:46:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fd12804d6faba0763b9b11c15de29f1c561886cf', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nbp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 4, 'created': '2015-08-28 13:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5027ebb70e3262e7bb7bef0ea0829557dad83d77', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 5, 'created': '2015-08-31 07:54:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4988f6bda9f3483b8eac24f09a44833d355b3255', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 6, 'created': '2015-08-31 15:31:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9d8dd7a301a01fded6a6f00fe68fb27e0aebb1d7', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 7, 'created': '2015-08-31 16:04:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f810c034a3e28c5136df754f53f86f94b8730ff8', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 8, 'created': '2015-09-01 11:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e0b4bc29568c6eeb8e7d5f3c272fb3ea7d465ecc', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 9, 'created': '2015-09-02 11:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4c4533f2b7ccb4f200d8885936142d1a0ca65e8d', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 10, 'created': '2015-09-03 02:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4f7850fca9d8b9ad76832610b636584672d36d7b', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 11, 'created': '2015-09-03 14:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/012e60ef582e03b56dcf840896a2156207102dfa', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 12, 'created': '2015-09-06 19:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/34225fdc6c06f1344f6f73cc76ef74b76637484c', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 13, 'created': '2015-09-10 11:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/64ec56a2bf92cac682b715859257112ca05ca7ad', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 14, 'created': '2015-09-16 13:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ab80e7540e93b3a42cc55fb551c360b152bc9543', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 15, 'created': '2015-09-21 12:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/914142aa43270ff78c07f6e9624ca3c1b641b625', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 16, 'created': '2015-10-05 13:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/02ae8c36ca11ae21e22bd8ed072012f1e70f6f25', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 17, 'created': '2015-10-08 11:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b240b0b53ef255543b639738fe6a10c78e036588', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 18, 'created': '2015-10-09 07:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8d57938f247c9584cff9f0746797ece6d02cb3bf', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 19, 'created': '2015-10-12 10:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8cfcd2221a6c32a7fec6fd0be9cba9bb1ecaf74b', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 20, 'created': '2015-11-05 12:09:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b704344f043370a869f6eabb1f6d0016139ad278', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 21, 'created': '2015-11-09 11:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/524cf2756ce15bdd048bc3957317b83e73958bd2', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 22, 'created': '2015-11-17 05:49:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/18502cec79c1d63b7e0f23a0967d9cba06e1d223', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 23, 'created': '2015-11-20 06:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4166d7ad473b6416b169fc6e98c25db3f12f7362', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 24, 'created': '2015-12-08 04:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a5b5b4342eee76f4b53423ba8263276cfae44043', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 25, 'created': '2015-12-11 07:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0896804617ce06c5e96cfb67d9db984fa928aebc', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 26, 'created': '2016-01-05 11:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7765d14a38250b3ad32c2eb4c8ba5bee4b894095', 'message': 'Add floating_ip property to Nova::Server nics\n\nAdd floating_ip property to Nova::Server networks\nproperty for association.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 27, 'created': '2016-01-05 12:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c7dc495ead914540481f8a9284ae25ad82559006', 'message': 'Add floating_ip property to Nova::Server nics\n\n1. Add floating_ip property to Nova::Server networks\n   property for association.\n\n2. Add floating ip association with server for neutron\n   and nova fipa.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 28, 'created': '2016-01-05 12:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fe38c8b8c71db907cb7f0cec573ad3b53f9f233f', 'message': 'Add floating_ip property to Nova::Server nics\n\n1. Add floating_ip property to Nova::Server networks\n   property for association.\n\n2. Add floating ip association with server for neutron\n   and nova fipa.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 29, 'created': '2016-01-14 15:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a0c395860578728f8e86298f302c696874c930dd', 'message': 'Add floating_ip property to Nova::Server nics\n\n1. Add floating_ip property to Nova::Server networks\n   property for association.\n\n2. Add floating ip association with server for neutron\n   and nova fipa.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 30, 'created': '2016-01-25 07:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ad63c226099db6adf6f003ca6db7fe051870e931', 'message': 'Add floating_ip property to Nova::Server nics\n\n1. Add floating_ip property to Nova::Server networks\n   property for association.\n\n2. Add floating ip association with server for neutron\n   and nova fipa.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}, {'number': 31, 'created': '2016-02-05 13:59:18.000000000', 'files': ['heat/engine/resources/openstack/nova/server.py', 'heat/engine/resources/openstack/nova/server_network_mixin.py', 'heat/tests/openstack/nova/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/348e4b74cefc7f266f649f31ad6cf232daa9067d', 'message': 'Add floating_ip property to Nova::Server nics\n\n1. Add floating_ip property to Nova::Server networks\n   property for association.\n\n2. Add floating ip association with server for neutron\n   and nova fipa.\n\nimplements bp rich-network-prop\n\nChange-Id: I792747c24df7009d02590f6092beef397ca753b5\n'}]",29,217754,348e4b74cefc7f266f649f31ad6cf232daa9067d,102,11,31,13009,,,0,"Add floating_ip property to Nova::Server nics

1. Add floating_ip property to Nova::Server networks
   property for association.

2. Add floating ip association with server for neutron
   and nova fipa.

implements bp rich-network-prop

Change-Id: I792747c24df7009d02590f6092beef397ca753b5
",git fetch https://review.opendev.org/openstack/heat refs/changes/54/217754/30 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/nova/test_server.py', 'heat/engine/resources/openstack/nova/server.py', 'heat/engine/resources/openstack/nova/server_network_mixin.py']",3,d035529efae40ddc40f98f861855fbc468de721d,bp/rich-network-prop," def _floating_ips_associate(self): networks = self.properties.get(self.NETWORKS) or [] for idx, network in enumerate(networks): floating_ip = network.get(self.NETWORK_FLOATING_IP) if floating_ip is not None: kwargs = {'port_id': network.get(self.NETWORK_PORT) or self._get_internal_port_by_idx(idx)} fixed_ip = network.get(self.NETWORK_FIXED_IP) if fixed_ip is not None: kwargs['fixed_ip_address'] = fixed_ip self._floating_ip_associate(floating_ip, kwargs) def _floating_ip_associate(self, floating_ip, floating_ip_data): if self.is_using_neutron(): self.client('neutron').update_floatingip( floating_ip, {'floatingip': floating_ip_data}) else: fl_ip = self.client().floating_ips.get(floating_ip) self.client().servers.add_floating_ip(self.resource_id, fl_ip.ip) def _floating_ips_disassociate(self): networks = self.properties[self.NETWORKS] or [] for network in networks: floating_ip = network.get(self.NETWORK_FLOATING_IP) if floating_ip is not None: self._floating_ip_disassociate(floating_ip) def _floating_ip_disassociate(self, floating_ip): if self.is_using_neutron(): self.client('neutron').update_floatingip( floating_ip, {'floatingip': {'port_id': None}}) else: fl_ip = self.client().floating_ips.get(floating_ip) self.client().servers.remove_floating_ip(self.resource_id, fl_ip.ip) if net.get(self.NETWORK_FLOATING_IP): self._floating_ip_disassociate( net.get(self.NETWORK_FLOATING_IP)) if net.get(self.NETWORK_FLOATING_IP): body = {'port_id': handler_kwargs['port_id']} if handler_kwargs.get('fip'): body['fixed_ip_address'] = handler_kwargs['fip'] self._floating_ip_associate(net.get(self.NETWORK_FLOATING_IP), body) ",,69,7
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ib6653f59ae90c10cb1dfc03ee3691b64403706c0,openstack/tripleo-heat-templates,stable/liberty,Ib6653f59ae90c10cb1dfc03ee3691b64403706c0,Include big switch puppet modules for deploying overcloud,ABANDONED,2016-01-25 08:58:24.000000000,2016-02-16 02:05:21.000000000,,"[{'_account_id': 3}, {'_account_id': 15342}]","[{'number': 1, 'created': '2016-01-25 08:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc2c7181f5e4d0f5d3e27a8bec7e05999e139d02', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes.\n\nIt is back-ported from https://review.openstack.org/#/c/271940/,\nwhich cannot be cherry-picked due conflicts\n\nChange-Id: Ib6653f59ae90c10cb1dfc03ee3691b64403706c0\n'}, {'number': 2, 'created': '2016-01-29 22:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f4e7498262baa5c0e0b4653233d49450d956e7c0', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes.\n\nIt is back-ported from https://review.openstack.org/#/c/271940/,\nwhich cannot be cherry-picked due to conflicts\n\nChange-Id: Ib6653f59ae90c10cb1dfc03ee3691b64403706c0\n'}, {'number': 3, 'created': '2016-02-09 17:59:34.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/pre_deploy/controller/neutron-ml2-bigswitch.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4a92a9ff4721879ad803de2107b8cfe8dfc32c5', 'message': 'Include big switch puppet modules for deploying overcloud\n\nThis change includes puppet modules for deploying controller\nand compute nodes.\n\nIt is back-ported from https://review.openstack.org/#/c/271940/,\nwhich cannot be cherry-picked due to conflicts\n\nChange-Id: Ib6653f59ae90c10cb1dfc03ee3691b64403706c0\n'}]",0,271953,b4a92a9ff4721879ad803de2107b8cfe8dfc32c5,17,2,3,15342,,,0,"Include big switch puppet modules for deploying overcloud

This change includes puppet modules for deploying controller
and compute nodes.

It is back-ported from https://review.openstack.org/#/c/271940/,
which cannot be cherry-picked due to conflicts

Change-Id: Ib6653f59ae90c10cb1dfc03ee3691b64403706c0
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/53/271953/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",3,dc2c7181f5e4d0f5d3e27a8bec7e05999e139d02,, if 'bsn_ml2' in hiera('neutron_mechanism_drivers') { include ::neutron::agents::bigswitch," if hiera('neutron_enable_bigswitch_ml2', false) {",8,2
openstack%2Fgnocchi~master~Ia12b03a3fe05f6499e4221c0a773277a26723955,openstack/gnocchi,master,Ia12b03a3fe05f6499e4221c0a773277a26723955,add randomness/chaos to metricd - POC,ABANDONED,2016-02-04 22:43:54.000000000,2016-02-16 01:58:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-04 22:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/d26c9fe7a79bdd5afb99f9ea81b3884342d500b1', 'message': 'add randomness/chaos to metricd - POC\n\ncurrently metricd workers will work against roughly the same measures\nwhen processing them for storage (see: first x measures). this patch adds\nsome additional partitions (based on workers) and weighted randomisation\nas to what partition to process.\n\nthe randomisation is weighted more to initial partition similar to\nhow it functions today. there is a chance, a worker may partition\nnothing especially if the backlog is small(er).\n\nthis patch also adds a limit to swift results. by default, swift pulls\n10k objects which seems excessive.\n\nChange-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955\nRelated-Bug: #\n'}, {'number': 2, 'created': '2016-02-05 13:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/8f29549f483639d97f70d70080a48e0b0b7eb58c', 'message': 'add randomness/chaos to metricd - POC\n\ncurrently metricd workers will work against roughly the same measures\nwhen processing them for storage (see: first x measures). this patch adds\nsome additional partitions (based on workers) and weighted randomisation\nas to what partition to process.\n\nthe randomisation is weighted more to initial partition similar to\nhow it functions today. there is a chance, a worker may partition\nnothing especially if the backlog is small(er).\n\nthis patch also adds a limit to swift results. by default, swift pulls\n10k objects which seems excessive.\n\nChange-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955\nRelated-Bug: #\n'}, {'number': 3, 'created': '2016-02-05 22:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/e9df8bf7e7bde1f44748a3083d760545712534ed', 'message': 'add randomness/chaos to metricd - POC\n\ncurrently metricd workers will work against roughly the same measures\nwhen processing them for storage (see: first x measures). this patch adds\nsome additional partitions (based on workers) and weighted randomisation\nas to what partition to process.\n\nthe randomisation is weighted more to initial partition similar to\nhow it functions today. there is a chance, a worker may partition\nnothing especially if the backlog is small(er).\n\nthis patch also adds a limit to swift results. by default, swift pulls\n10k objects which seems excessive.\n\nChange-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955\nRelated-Bug: #\n'}, {'number': 4, 'created': '2016-02-08 13:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/c3119cf2ef4ffedc255346436bae199be2c35b00', 'message': 'add randomness/chaos to metricd - POC\n\ncurrently metricd workers will work against roughly the same measures\nwhen processing them for storage (see: first x measures). this patch adds\nsome additional partitions (based on workers) and weighted randomisation\nas to what partition to process.\n\nthe randomisation is weighted more to initial partition similar to\nhow it functions today. there is a chance, a worker may partition\nnothing especially if the backlog is small(er).\n\nthis patch also adds a limit to swift results. by default, swift pulls\n10k objects which seems excessive.\n\nChange-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955\nRelated-Bug: #\n'}, {'number': 5, 'created': '2016-02-08 17:46:38.000000000', 'files': ['gnocchi/storage/ceph.py', 'gnocchi/tests/base.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/storage/swift.py', 'gnocchi/cli.py', 'gnocchi/storage/file.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/dc2fd9f19d181c90eb6de62d27863f85bb0c72ef', 'message': 'add randomness/chaos to metricd - POC\n\ncurrently metricd workers will work against roughly the same measures\nwhen processing them for storage (see: first x measures). this patch adds\nsome additional partitions (based on workers) and weighted randomisation\nas to what partition to process.\n\nthe randomisation is weighted more to initial partition similar to\nhow it functions today. there is a chance, a worker may partition\nnothing especially if the backlog is small(er).\n\nthis patch also adds a limit to swift results. by default, swift pulls\n10k objects which seems excessive.\n\nChange-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955\nRelated-Bug: #\n'}]",5,276485,dc2fd9f19d181c90eb6de62d27863f85bb0c72ef,23,3,5,6537,,,0,"add randomness/chaos to metricd - POC

currently metricd workers will work against roughly the same measures
when processing them for storage (see: first x measures). this patch adds
some additional partitions (based on workers) and weighted randomisation
as to what partition to process.

the randomisation is weighted more to initial partition similar to
how it functions today. there is a chance, a worker may partition
nothing especially if the backlog is small(er).

this patch also adds a limit to swift results. by default, swift pulls
10k objects which seems excessive.

Change-Id: Ia12b03a3fe05f6499e4221c0a773277a26723955
Related-Bug: #
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/85/276485/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/storage/ceph.py', 'gnocchi/storage/_carbonara.py', 'gnocchi/storage/swift.py', 'gnocchi/storage/file.py']",4,d26c9fe7a79bdd5afb99f9ea81b3884342d500b1,chaos, part = self._get_random_partition() return os.listdir(self.measure_path)[ self.METRIC_WITH_MEASURES_TO_PROCESS_BATCH_SIZE * part: self.METRIC_WITH_MEASURES_TO_PROCESS_BATCH_SIZE * (part + 1)], return os.listdir(self.measure_path),28,6
openstack%2Fnetworking-midonet~master~Iacb973b5d5cd186f66f1d8b672e48fbf813df3a4,openstack/networking-midonet,master,Iacb973b5d5cd186f66f1d8b672e48fbf813df3a4,Remove uniqueness validation for vtep_address in remote_mac_entry.,MERGED,2016-02-15 10:42:34.000000000,2016-02-16 01:43:17.000000000,2016-02-16 01:43:17.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 6854}, {'_account_id': 8837}]","[{'number': 1, 'created': '2016-02-15 10:42:34.000000000', 'files': ['midonet/neutron/extensions/gateway_device.py', 'midonet/neutron/db/gateway_device.py', 'midonet/neutron/db/migration/alembic_migration/versions/mitaka/expand/cfe0dea89aa_add_gateway_device_management.py', 'midonet/neutron/tests/unit/test_extension_gateway_device.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/fa853b575ba8e41cae5d2d4d7cc85d9ba8894ff2', 'message': 'Remove uniqueness validation for vtep_address in remote_mac_entry.\n\nThis patch removes uniqueness validation for vtep_address in remote_mac_entry\nto allow deploying multiple router under single VTEP router.\n\nChange-Id: Iacb973b5d5cd186f66f1d8b672e48fbf813df3a4\nCloses-Bug: #1545571\n'}]",0,280148,fa853b575ba8e41cae5d2d4d7cc85d9ba8894ff2,7,5,1,17133,,,0,"Remove uniqueness validation for vtep_address in remote_mac_entry.

This patch removes uniqueness validation for vtep_address in remote_mac_entry
to allow deploying multiple router under single VTEP router.

Change-Id: Iacb973b5d5cd186f66f1d8b672e48fbf813df3a4
Closes-Bug: #1545571
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/48/280148/1 && git format-patch -1 --stdout FETCH_HEAD,"['midonet/neutron/extensions/gateway_device.py', 'midonet/neutron/db/gateway_device.py', 'midonet/neutron/db/migration/alembic_migration/versions/mitaka/expand/cfe0dea89aa_add_gateway_device_management.py', 'midonet/neutron/tests/unit/test_extension_gateway_device.py']",4,fa853b575ba8e41cae5d2d4d7cc85d9ba8894ff2,bug/1545571," def test_create_remote_mac_with_same_vtep_address(self): with self.gateway_device_type_router_vtep( resource_id=self._router_id) as gw_dev: with self.remote_mac_entry(gw_dev['gateway_device']['id']): with self.remote_mac_entry(gw_dev['gateway_device']['id'], mac_address=FAKE_MAC_ADDRESS2): req = self.new_list_request('gw/gateway_devices/' + gw_dev['gateway_device']['id'] + '/remote_mac_entries') res = self.deserialize( self.fmt, req.get_response(self.ext_api)) self.assertEqual(len(res['remote_mac_entries']), 2) "," def test_create_remote_mac_with_duplicate_vtep_address(self): with self.gateway_device_type_router_vtep( resource_id=self._router_id) as gw_dev: with self.remote_mac_entry(gw_dev['gateway_device']['id']): res = self._create_remote_mac_entry( gw_dev['gateway_device']['id'], mac_address=FAKE_MAC_ADDRESS2, vtep_address=FAKE_VTEP_ADDRESS) self.deserialize(self.fmt, res) self.assertEqual(webob.exc.HTTPConflict.code, res.status_int) ",17,17
openstack%2Fkolla~master~I8e4ede8d9867393f066cb1748247245855a4fdae,openstack/kolla,master,I8e4ede8d9867393f066cb1748247245855a4fdae,Ensure that /var/lib/zookeeper is owned by user,MERGED,2016-02-15 23:42:15.000000000,2016-02-16 01:41:51.000000000,2016-02-16 01:41:50.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 14119}, {'_account_id': 17591}]","[{'number': 1, 'created': '2016-02-15 23:42:15.000000000', 'files': ['docker/zookeeper/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2b45dc47de87573f0faa9c6de793a9a55db18b65', 'message': 'Ensure that /var/lib/zookeeper is owned by user\n\nTrivialFix\n\nChange-Id: I8e4ede8d9867393f066cb1748247245855a4fdae\n'}]",0,280445,2b45dc47de87573f0faa9c6de793a9a55db18b65,8,4,1,14027,,,0,"Ensure that /var/lib/zookeeper is owned by user

TrivialFix

Change-Id: I8e4ede8d9867393f066cb1748247245855a4fdae
",git fetch https://review.opendev.org/openstack/kolla refs/changes/45/280445/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/zookeeper/extend_start.sh'],1,2b45dc47de87573f0faa9c6de793a9a55db18b65,zk_volume,"# Only update permissions if permissions need to be updated if [[ $(stat -c %U:%G /var/lib/zookeeper) != ""zookeeper:zookeeper"" ]]; then","if [[ ""${!KOLLA_BOOTSTRAP[@]}"" ]]; then exit 0",2,2
openstack%2Fzaqar~master~Ifd8cc204e77dd41acfef57f0829c75dd681324f3,openstack/zaqar,master,Ifd8cc204e77dd41acfef57f0829c75dd681324f3,Queue NotFound should return 404,ABANDONED,2016-02-15 08:41:17.000000000,2016-02-16 01:16:24.000000000,,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 12321}, {'_account_id': 18683}]","[{'number': 1, 'created': '2016-02-15 08:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/13fab97accafccad21075304acd1b4e01bbf79c7', 'message': ""Queue NotFound should return 404\n\nnow in v1.1 and v2, if users try to get a queue which is not\nexist, it will return 200 OK. But it should return 404. The reason\nis that zaqar doesn't raise the error in data layer.\n\nChange-Id: Ifd8cc204e77dd41acfef57f0829c75dd681324f3\nCloses-bug: #1545622\n""}, {'number': 2, 'created': '2016-02-15 08:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ce92cae023c04901a5e83556dd590586b3ac6484', 'message': ""Queue NotFound should return 404\n\nnow in v1.1 and v2, if users try to get a queue which is not\nexist, it will return 200 OK. But it should return 404. The reason\nis that zaqar doesn't raise the error in data layer.\n\nChange-Id: Ifd8cc204e77dd41acfef57f0829c75dd681324f3\nCloses-bug: #1545622\n""}, {'number': 3, 'created': '2016-02-15 09:25:54.000000000', 'files': ['zaqar/storage/sqlalchemy/queues.py', 'zaqar/storage/mongodb/queues.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/91c303557a45c7557eb323037dadc7fc433f5ea3', 'message': ""Queue NotFound should return 404\n\nnow in v1.1 and v2, if users try to get a queue which is not\nexist, it will return 200 OK. But it should return 404. The reason\nis that zaqar doesn't raise the error in data layer.\n\nAPIImpact\n\nChange-Id: Ifd8cc204e77dd41acfef57f0829c75dd681324f3\nCloses-bug: #1545622\n""}]",1,280106,91c303557a45c7557eb323037dadc7fc433f5ea3,9,4,3,15054,,,0,"Queue NotFound should return 404

now in v1.1 and v2, if users try to get a queue which is not
exist, it will return 200 OK. But it should return 404. The reason
is that zaqar doesn't raise the error in data layer.

APIImpact

Change-Id: Ifd8cc204e77dd41acfef57f0829c75dd681324f3
Closes-bug: #1545622
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/06/280106/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/transport/wsgi/v1_1/queues.py', 'zaqar/storage/sqlalchemy/queues.py', 'zaqar/transport/wsgi/v2_0/queues.py', 'zaqar/storage/mongodb/queues.py']",4,13fab97accafccad21075304acd1b4e01bbf79c7,bug/1545622," """"""Obtain the metadata from the queue."""""" return self.get_metadata(name, project)"," try: return self.get_metadata(name, project) except errors.QueueDoesNotExist: return {}",6,10
openstack%2Fsecurity-doc~master~I6a0222be0e1f1378f36b2a31011391ae4bbec164,openstack/security-doc,master,I6a0222be0e1f1378f36b2a31011391ae4bbec164,Add README.rst to security-doc repo,MERGED,2016-02-14 00:43:46.000000000,2016-02-16 01:04:24.000000000,2016-02-16 01:04:24.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 12325}, {'_account_id': 13642}]","[{'number': 1, 'created': '2016-02-14 00:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/7ef35e90e5028eb616c3c8c705b6204c62bbad27', 'message': 'Add README.rst to security-doc repo\n\nThe security-doc repository has very useful documentation needed for the\nOpenStack Security Guide. But, unlike the openstack-manuals repo, the\nsecurity-doc repo does not have a README.rst file.\n\nHence, this patch set adds README.rst to security-doc with all the information\nneeded for a new contributor.\n\nThe README.rst in this patch set will also create a nice landing page for the\nsecurity-doc repo in GitHub at https://github.com/openstack/security-doc.\n\nChange-Id: I6a0222be0e1f1378f36b2a31011391ae4bbec164\nCloses-Bug: 1545355\n'}, {'number': 2, 'created': '2016-02-14 18:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/1067c159f0d36e0d8411e9d2278ff1d1e1e5d6ae', 'message': 'Add README.rst to security-doc repo\n\nThe security-doc repository has very useful documentation needed for the\nOpenStack Security Guide. But, unlike the openstack-manuals repo, the\nsecurity-doc repo does not have a README.rst file.\n\nHence, this patch set adds README.rst to security-doc with all the information\nneeded for a new contributor.\n\nThe README.rst in this patch set will also create a nice landing page for the\nsecurity-doc repo in GitHub at https://github.com/openstack/security-doc.\n\nChange-Id: I6a0222be0e1f1378f36b2a31011391ae4bbec164\nCloses-Bug: 1545355\n'}, {'number': 3, 'created': '2016-02-15 03:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/bed37d59fd9f69d9965b0ba3d5e178881615ca96', 'message': 'Add README.rst to security-doc repo\n\nThe security-doc repository has very useful documentation needed for the\nOpenStack Security Guide. But, unlike the openstack-manuals repo, the\nsecurity-doc repo does not have a README.rst file.\n\nHence, this patch set adds README.rst to security-doc with all the information\nneeded for a new contributor.\n\nThe README.rst in this patch set will also create a nice landing page for the\nsecurity-doc repo in GitHub at https://github.com/openstack/security-doc.\n\nChange-Id: I6a0222be0e1f1378f36b2a31011391ae4bbec164\nCloses-Bug: 1545355\n'}, {'number': 4, 'created': '2016-02-15 19:34:23.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/39e42975c44866946e5180b5b4c070605e5e23d5', 'message': 'Add README.rst to security-doc repo\n\nThe security-doc repository has very useful documentation needed for the\nOpenStack Security Guide. But, unlike the openstack-manuals repo, the\nsecurity-doc repo does not have a README.rst file.\n\nHence, this patch set adds README.rst to security-doc with all the information\nneeded for a new contributor.\n\nThe README.rst in this patch set will also create a nice landing page for the\nsecurity-doc repo in GitHub at https://github.com/openstack/security-doc.\n\nChange-Id: I6a0222be0e1f1378f36b2a31011391ae4bbec164\nCloses-Bug: 1545355\n'}]",16,279906,39e42975c44866946e5180b5b4c070605e5e23d5,21,5,4,13642,,,0,"Add README.rst to security-doc repo

The security-doc repository has very useful documentation needed for the
OpenStack Security Guide. But, unlike the openstack-manuals repo, the
security-doc repo does not have a README.rst file.

Hence, this patch set adds README.rst to security-doc with all the information
needed for a new contributor.

The README.rst in this patch set will also create a nice landing page for the
security-doc repo in GitHub at https://github.com/openstack/security-doc.

Change-Id: I6a0222be0e1f1378f36b2a31011391ae4bbec164
Closes-Bug: 1545355
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/06/279906/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,7ef35e90e5028eb616c3c8c705b6204c62bbad27,bug/1545355,"OpenStack Security Guide ++++++++++++++++++++++++ This repository contains documentation for the OpenStack Security Guide. For more details, see the `OpenStack Documentation Contributor Guide <http://docs.openstack.org/contributor-guide/>`_. It includes these manuals: * Security Guide * Security Notes Guides ------ Various security guides are in the RST format in the directory ``security-guide/source``. The security notes are in the directory ``security-notes``. Testing of changes and building of the guides ============================================= Install the python tox package and run ``tox`` from the top-level directory to use the same tests that are done as part of our Jenkins gating jobs. tox Contributing ============ Our community welcomes all people interested in open source cloud computing, and encourages you to join the `OpenStack Foundation <http://www.openstack.org/join>`_. The best way to get involved with the community is to talk with others online or at a meet up and offer contributions through our processes, the `OpenStack wiki <http://wiki.openstack.org>`_, blogs, or on IRC at ``#openstack`` on ``irc.freenode.net``. We welcome all types of contributions, from blueprint designs to documentation to testing to deployment scripts. If you would like to contribute to the documents, please see the `OpenStack Documentation contributor guide <http://docs.openstack.org/contributor-guide/>`_. Bugs ==== Bugs should be filed on Launchpad, not GitHub: https://bugs.launchpad.net/openstack-manuals Installing ========== Refer to http://docs.openstack.org/security-guide to see where these documents are published and to learn more about the OpenStack Security Guide. ",,64,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba,openstack/tripleo-heat-templates,stable/liberty,I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba,MidoNet heat templates,MERGED,2015-12-22 09:38:51.000000000,2016-02-16 01:01:58.000000000,2016-02-16 01:01:57.000000000,"[{'_account_id': 3}, {'_account_id': 6681}, {'_account_id': 7144}, {'_account_id': 7505}, {'_account_id': 8449}, {'_account_id': 11933}]","[{'number': 1, 'created': '2015-12-22 09:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/33969a6ac35536bdac840ae2f70c75930fc320a8', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n'}, {'number': 2, 'created': '2015-12-22 09:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5fe387a37fb6ba6f3275fd43e59207b149fc2468', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\n'}, {'number': 3, 'created': '2016-01-08 17:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9081a6a576290a42cd729680a611a5965f2ee46c', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n'}, {'number': 4, 'created': '2016-01-12 16:15:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a8cf7a11b145c979419bde921b14e7982c96a639', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\n'}, {'number': 5, 'created': '2016-01-14 09:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/386d8b31b7c2d8ed28b762964d597bc830eaf222', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\n'}, {'number': 6, 'created': '2016-01-14 09:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d59819e3ba90b1a12a744d12600b62bec688fec6', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\n'}, {'number': 7, 'created': '2016-01-22 11:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1aff2f65d57fb48d2d0048bb6cb8edf46599ba11', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}, {'number': 8, 'created': '2016-02-11 11:41:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f87a36370a533caf80c6d6ba43c2afdc9f8e894f', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}, {'number': 9, 'created': '2016-02-11 20:52:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/21aab5fbdd91affa9b7c18c8ed212c4651f65120', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nDepends-On: If069686583b7988e871dde281df2453b33bf2c0f\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}, {'number': 10, 'created': '2016-02-15 16:51:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/718178914731541b5d2492330c6c3c891df96054', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nDepends-On: If069686583b7988e871dde281df2453b33bf2c0f\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}, {'number': 11, 'created': '2016-02-15 16:52:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9d75fed5399c2c83887bb05a183772b21f4ce904', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}, {'number': 12, 'created': '2016-02-15 20:11:02.000000000', 'files': ['environments/neutron-midonet.yaml', 'puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/all_nodes/neutron-midonet-all-nodes.yaml', 'puppet/controller.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f65fac909f10e3d582f83fe5659a48337271ff64', 'message': 'MidoNet heat templates\n\nDeploy a TripleO overcloud with networking midonet. MidoNet is a\nmonolithic plugin and quite changes on the puppet manifest must be done.\n\nDepends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b\nDepends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0\nDepends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf\nChange-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba\n(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)\nConflicts:\n\tpuppet/manifests/overcloud_compute.pp\n\tpuppet/manifests/overcloud_controller.pp\n'}]",3,260415,f65fac909f10e3d582f83fe5659a48337271ff64,65,6,12,7505,,,0,"MidoNet heat templates

Deploy a TripleO overcloud with networking midonet. MidoNet is a
monolithic plugin and quite changes on the puppet manifest must be done.

Depends-On: I72f21036fda795b54312a7d39f04c30bbf16c41b
Depends-On: I6f1ac659297b8cf6671e11ad23284f8f543568b0
Depends-On: Icea9bd96e4c80a26b9e813d383f84099c736d7bf
Change-Id: I9692e2ef566ea37e0235a6059b1ae1ceeb9725ba
(cherry picked from commit de90b568fc39ac0b1c02dc3131cce718adfe8f3a)
Conflicts:
	puppet/manifests/overcloud_compute.pp
	puppet/manifests/overcloud_controller.pp
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/260415/1 && git format-patch -1 --stdout FETCH_HEAD,"['environments/neutron-midonet.yaml', 'puppet/manifests/overcloud_controller.pp', 'puppet/extraconfig/all_nodes/neutron-midonet-all-nodes.yaml', 'puppet/controller.yaml', 'puppet/manifests/overcloud_compute.pp', 'puppet/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp']",7,33969a6ac35536bdac840ae2f70c75930fc320a8,cherrypick_enable_services," if hiera('neutron::core_plugin') == 'midonet.neutron.plugin_v1.MidonetPluginV2' { # TODO(devvesa) provide non-controller ips for these services $zookeeper_node_ips = hiera('neutron_api_node_ips') $cassandra_node_ips = hiera('neutron_api_node_ips') # Run zookeeper in the controller if configured if hiera('enable_zookeeper_on_controller') { class {'::tripleo::cluster::zookeeper': zookeeper_server_ips => $zookeeper_node_ips, zookeeper_client_ip => $ipaddress, zookeeper_hostnames => hiera('controller_node_names') } } # Run cassandra in the controller if configured if hiera('enable_cassandra_on_controller') { class {'::tripleo::cluster::cassandra': cassandra_servers => $cassandra_node_ips, cassandra_ip => $ipaddress } } class {'::tripleo::network::midonet::agent': zookeeper_servers => $zookeeper_node_ips, cassandra_seeds => $cassandra_node_ips } class {'::tripleo::network::midonet::api': zookeeper_servers => hiera('neutron_api_node_ips'), vip => $public_vip, keystone_ip => $public_vip, keystone_admin_token => hiera('keystone::admin_token'), bind_address => $ipaddress, admin_password => hiera('admin_password') } # Configure Neutron class {'::neutron': service_plugins => [] } } else { # Neutron class definitions include ::neutron } if hiera('neutron::core_plugin') == 'midonet.neutron.plugin_v1.MidonetPluginV2' { class {'::neutron::plugins::midonet': midonet_api_ip => $public_vip, keystone_tenant => hiera('neutron::server::auth_tenant'), keystone_password => hiera('neutron::server::auth_password') } } if hiera('neutron::core_plugin') == 'midonet.neutron.plugin_v1.MidonetPluginV2' { pacemaker::resource::service {'tomcat': clone_params => 'interleave=true', } } if hiera('neutron::core_plugin') == 'midonet.neutron.plugin_v1.MidonetPluginV2' { #midonet-chain chain keystone-->neutron-server-->dhcp-->metadata->tomcat pacemaker::constraint::base { 'neutron-server-to-dhcp-agent-constraint': constraint_type => 'order', first_resource => ""${::neutron::params::server_service}-clone"", second_resource => ""${::neutron::params::dhcp_agent_service}-clone"", first_action => 'start', second_action => 'start', require => [Pacemaker::Resource::Service[$::neutron::params::server_service], Pacemaker::Resource::Service[$::neutron::params::dhcp_agent_service]], } pacemaker::constraint::base { 'neutron-dhcp-agent-to-metadata-agent-constraint': constraint_type => 'order', first_resource => ""${::neutron::params::dhcp_agent_service}-clone"", second_resource => ""${::neutron::params::metadata_agent_service}-clone"", first_action => 'start', second_action => 'start', require => [Pacemaker::Resource::Service[$::neutron::params::dhcp_agent_service], Pacemaker::Resource::Service[$::neutron::params::metadata_agent_service]], } pacemaker::constraint::base { 'neutron-metadata-agent-to-tomcat-constraint': constraint_type => 'order', first_resource => ""${::neutron::params::metadata_agent_service}-clone"", second_resource => 'tomcat-clone', first_action => 'start', second_action => 'start', require => [Pacemaker::Resource::Service[$::neutron::params::metadata_agent_service], Pacemaker::Resource::Service['tomcat']], } pacemaker::constraint::colocation { 'neutron-dhcp-agent-to-metadata-agent-colocation': source => ""${::neutron::params::metadata_agent_service}-clone"", target => ""${::neutron::params::dhcp_agent_service}-clone"", score => 'INFINITY', require => [Pacemaker::Resource::Service[$::neutron::params::dhcp_agent_service], Pacemaker::Resource::Service[$::neutron::params::metadata_agent_service]], } }", # Neutron class definitions include ::neutron #another chain keystone-->neutron-server-->ovs-agent-->dhcp-->l3,352,36
openstack%2Fnetworking-ovn~master~I7252171121d1111da1a7514b84839ec34bf6e16c,openstack/networking-ovn,master,I7252171121d1111da1a7514b84839ec34bf6e16c,Add notes for switching ovn_l3_mode from False to True,MERGED,2016-02-15 20:45:25.000000000,2016-02-16 00:54:56.000000000,2016-02-16 00:54:55.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 9515}]","[{'number': 1, 'created': '2016-02-15 20:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4cc8885d67eab8b14135baa1e7d980067d0f5ca6', 'message': ""Add notes for switching ovn_l3_mode from False to True\n\nWe don't support and there is no plan to support data conversion\nwhen switching ovn_l3_mode from False to True. This patch add a note\nin the help text of ovn_l3_mode, so that user can understand to\ndo manual cleanup beforehand instead of facing unexpected neutron\nrestart failure.\n\nChange-Id: I7252171121d1111da1a7514b84839ec34bf6e16c\nCloses-bug: 1545599\n""}, {'number': 2, 'created': '2016-02-15 21:29:18.000000000', 'files': ['networking_ovn/common/config.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/cc24385d13ebfd8f87608ba2934eb47c92d1ba5e', 'message': ""Add notes for switching ovn_l3_mode from False to True\n\nWe don't support and there is no plan to support data conversion\nwhen switching ovn_l3_mode from False to True. This patch add a note\nin the help text of ovn_l3_mode, so that user can understand to\ndo manual cleanup beforehand instead of facing unexpected neutron\nrestart failure.\n\nChange-Id: I7252171121d1111da1a7514b84839ec34bf6e16c\nCloses-bug: 1545599\n""}]",2,280392,cc24385d13ebfd8f87608ba2934eb47c92d1ba5e,15,4,2,11762,,,0,"Add notes for switching ovn_l3_mode from False to True

We don't support and there is no plan to support data conversion
when switching ovn_l3_mode from False to True. This patch add a note
in the help text of ovn_l3_mode, so that user can understand to
do manual cleanup beforehand instead of facing unexpected neutron
restart failure.

Change-Id: I7252171121d1111da1a7514b84839ec34bf6e16c
Closes-bug: 1545599
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/92/280392/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/common/config.py'],1,4cc8885d67eab8b14135baa1e7d980067d0f5ca6,bug/1545599," help=_('Whether to use OVN L3 support. Note that any routers ' 'and/or router-interfaces created when ' 'ovn_l3_mode=False need to be deleted by user before ' 'switching ovn_l3_mode to True, and then recreated ' 'after switching the mode.')),"," help=_('Whether to use OVN L3 support')),",5,1
openstack%2Fneutron-lib~master~I192d84012bb192f5380918d56c1bc28bb2e2ae04,openstack/neutron-lib,master,I192d84012bb192f5380918d56c1bc28bb2e2ae04,WIP - build test,ABANDONED,2016-01-26 07:19:57.000000000,2016-02-16 00:31:21.000000000,,"[{'_account_id': 3}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-01-26 07:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/707c0d8decb31b4f9dd2feb6debfba6974bc3001', 'message': 'WIP - build test\n\nChange-Id: I192d84012bb192f5380918d56c1bc28bb2e2ae04\n'}, {'number': 2, 'created': '2016-02-10 03:00:55.000000000', 'files': ['DO_NOT_MERGE'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/65826e513a498cd9260555867b895f9d2dbc00a0', 'message': 'WIP - build test\n\nChange-Id: I192d84012bb192f5380918d56c1bc28bb2e2ae04\n'}]",0,272413,65826e513a498cd9260555867b895f9d2dbc00a0,16,2,2,10980,,,0,"WIP - build test

Change-Id: I192d84012bb192f5380918d56c1bc28bb2e2ae04
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/13/272413/2 && git format-patch -1 --stdout FETCH_HEAD,['DO_NOT_MERGE'],1,707c0d8decb31b4f9dd2feb6debfba6974bc3001,do-not-merge,,,0,0
openstack%2Fneutron-lbaas~master~Ie4c65c20617bbb6b4a34bb504fbc3797de5ef15c,openstack/neutron-lbaas,master,Ie4c65c20617bbb6b4a34bb504fbc3797de5ef15c,"WIP - do not merge, negative CI test",ABANDONED,2016-02-08 20:56:43.000000000,2016-02-16 00:31:04.000000000,,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10980}, {'_account_id': 12040}]","[{'number': 1, 'created': '2016-02-08 20:56:43.000000000', 'files': ['neutron_lbaas/services/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/691ec6c15a9c22522ed5c457525575a0d194a2cd', 'message': 'WIP - do not merge, negative CI test\n\nChange-Id: Ie4c65c20617bbb6b4a34bb504fbc3797de5ef15c\n'}]",0,277557,691ec6c15a9c22522ed5c457525575a0d194a2cd,11,4,1,10980,,,0,"WIP - do not merge, negative CI test

Change-Id: Ie4c65c20617bbb6b4a34bb504fbc3797de5ef15c
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/57/277557/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/services/__init__.py'],1,691ec6c15a9c22522ed5c457525575a0d194a2cd,negative-ci-tet, gooberfar ,,3,0
openstack%2Fnova~master~I2219f6c73d882efc787127f02fda937f3e3b44eb,openstack/nova,master,I2219f6c73d882efc787127f02fda937f3e3b44eb,Reorder name normalization for DNS,MERGED,2016-02-12 21:23:46.000000000,2016-02-16 00:23:10.000000000,2016-02-15 19:30:47.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 748}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7448}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-12 21:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84b7a0400d28b3591dcab8948e1352c1295194e4', 'message': 'Reorder name normalization for DNS\n\nHaving the truncation step as the last one meant we could truncate to\na trailing hyphen. This could potential cause a failure for an invalid\nname. This commit reorders the normalization to put the truncation as\nthe first step which should avoid that problem.\n\nChange-Id: I2219f6c73d882efc787127f02fda937f3e3b44eb\nCloses-Bug: #1545153\n'}, {'number': 2, 'created': '2016-02-12 21:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/91cd34f926d4176de6a4b5e5a1e64b05b3ff819a', 'message': 'Reorder name normalization for DNS\n\nHaving the truncation step as the last one meant we could truncate to\na trailing hyphen. This could potential cause a failure for an invalid\nname. This commit reorders the normalization to put the truncation as\nthe first step which should avoid that problem.\n\nChange-Id: I2219f6c73d882efc787127f02fda937f3e3b44eb\nCloses-Bug: #1545153\n'}, {'number': 3, 'created': '2016-02-15 17:21:40.000000000', 'files': ['nova/tests/unit/test_utils.py', 'nova/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7e79d83641545e8134a2a142ade8a2fc0b96eade', 'message': 'Reorder name normalization for DNS\n\nHaving the truncation step as the last one meant we could truncate to\na trailing hyphen. This could potential cause a failure for an invalid\nname. This commit reorders the normalization to put the truncation as\nthe first step which should avoid that problem.\n\nChange-Id: I2219f6c73d882efc787127f02fda937f3e3b44eb\nCloses-Bug: #1545153\n'}]",6,279799,7e79d83641545e8134a2a142ade8a2fc0b96eade,34,11,3,5196,,,0,"Reorder name normalization for DNS

Having the truncation step as the last one meant we could truncate to
a trailing hyphen. This could potential cause a failure for an invalid
name. This commit reorders the normalization to put the truncation as
the first step which should avoid that problem.

Change-Id: I2219f6c73d882efc787127f02fda937f3e3b44eb
Closes-Bug: #1545153
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/279799/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/utils.py'],1,84b7a0400d28b3591dcab8948e1352c1295194e4,bug/1545153, hostname = truncate_hostname(hostname) return hostname, return truncate_hostname(hostname) ,2,3
openstack%2Fheat~master~I63af65d2a409ddf4179672ebb054852a8732a1fe,openstack/heat,master,I63af65d2a409ddf4179672ebb054852a8732a1fe,Remove db refresh in Stack object get,MERGED,2016-02-10 06:39:54.000000000,2016-02-16 00:19:35.000000000,2016-02-16 00:19:35.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7256}]","[{'number': 1, 'created': '2016-02-10 06:39:54.000000000', 'files': ['heat/objects/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/5c0378255536d3817e507ebee8b3e4fd4bc6c269', 'message': ""Remove db refresh in Stack object get\n\nWhen refreshing a Stack object, we first retrive the object from the\ndatabase (which handle NotFound errors) and then call refresh in a\ndifferent transaction. By that time, the db object can be gone and\nrefresh would fail, and it also doesn't bring any benefit, so let's\nremove that call.\n\nChange-Id: I63af65d2a409ddf4179672ebb054852a8732a1fe\nCloses-Bug: #1543922\n""}]",0,278225,5c0378255536d3817e507ebee8b3e4fd4bc6c269,11,3,1,7385,,,0,"Remove db refresh in Stack object get

When refreshing a Stack object, we first retrive the object from the
database (which handle NotFound errors) and then call refresh in a
different transaction. By that time, the db object can be gone and
refresh would fail, and it also doesn't bring any benefit, so let's
remove that call.

Change-Id: I63af65d2a409ddf4179672ebb054852a8732a1fe
Closes-Bug: #1543922
",git fetch https://review.opendev.org/openstack/heat refs/changes/25/278225/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/objects/stack.py'],1,5c0378255536d3817e507ebee8b3e4fd4bc6c269,bug/1543922,, db_stack.refresh(),0,1
openstack%2Fmanila~master~I4d8d4f8b256194cfc2c557e8969525caf510eace,openstack/manila,master,I4d8d4f8b256194cfc2c557e8969525caf510eace,Add space to message in manila_tempest_tests/tests/api/test_shares.py,ABANDONED,2016-01-26 07:49:04.000000000,2016-02-16 00:07:35.000000000,,"[{'_account_id': 3}, {'_account_id': 8851}, {'_account_id': 11865}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16237}, {'_account_id': 16522}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17780}, {'_account_id': 18128}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-01-26 07:49:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d2d08fe6131e9a64e2fb3b9cf4fe7b5fe63c4918', 'message': 'Add space to message in manila_tempest_tests/tests/api/test_shares.py\n\nThere isn\'t space between ""for"" and ""share"".\nThis patch adds space after ""for"".\n\nChange-Id: I4d8d4f8b256194cfc2c557e8969525caf510eace\n'}, {'number': 2, 'created': '2016-02-03 07:01:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/fcb73250034ae99fb8aff0f99bf680e1d8be9048', 'message': 'Add space to message in manila_tempest_tests/tests/api/test_shares.py\n\nThere isn\'t space between ""for"" and ""share"".\nThis patch adds space after ""for"".\n\nChange-Id: I4d8d4f8b256194cfc2c557e8969525caf510eace\n'}, {'number': 3, 'created': '2016-02-13 10:40:22.000000000', 'files': ['manila_tempest_tests/tests/api/test_shares.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/b7cb078a359d172d4c2b47224fdfce684fb71b63', 'message': 'Add space to message in manila_tempest_tests/tests/api/test_shares.py\n\nThere isn\'t space between ""for"" and ""share"".\nThis patch adds space after ""for"".\n\nChange-Id: I4d8d4f8b256194cfc2c557e8969525caf510eace\n'}]",0,272415,b7cb078a359d172d4c2b47224fdfce684fb71b63,59,12,3,16522,,,0,"Add space to message in manila_tempest_tests/tests/api/test_shares.py

There isn't space between ""for"" and ""share"".
This patch adds space after ""for"".

Change-Id: I4d8d4f8b256194cfc2c557e8969525caf510eace
",git fetch https://review.opendev.org/openstack/manila refs/changes/15/272415/2 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/test_shares.py'],1,d2d08fe6131e9a64e2fb3b9cf4fe7b5fe63c4918,fix-message," msg = (""Expected share_network_id %(expected_sn)s for """," msg = (""Expected share_network_id %(expected_sn)s for""",1,1
openstack%2Fdiskimage-builder~master~I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03,openstack/diskimage-builder,master,I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03,Use dnf to cleanup old kernels,MERGED,2015-11-25 03:41:47.000000000,2016-02-15 23:55:03.000000000,2016-02-15 22:56:11.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 10035}]","[{'number': 1, 'created': '2015-11-25 03:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c7fdb3692b6fdb2ce0ec1c87785a4d331cbe777d', 'message': ""Use dnf to cleanup old kernels\n\nAs described in the comment, there is a dnf equivalent of this command\nthat doesn't require us installing yum-utils (which drags in yum on\ndnf-only systems such as f23)\n\nChange-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03\n""}, {'number': 2, 'created': '2015-11-25 04:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/44e08b7186c7690297858050b0437f8ae8291ca7', 'message': ""Use dnf to cleanup old kernels\n\nAs described in the comment, there is a dnf equivalent of this command\nthat doesn't require us installing yum-utils (which drags in yum on\ndnf-only systems such as f23)\n\nChange-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03\n""}, {'number': 3, 'created': '2015-12-02 07:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/c8fc953394b3aa267d51f9335e31ebd65f36319b', 'message': ""Use dnf to cleanup old kernels\n\nAs described in the comment, there is a dnf equivalent of this command\nthat doesn't require us installing yum-utils (which drags in yum on\ndnf-only systems such as f23)\n\nChange-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03\n""}, {'number': 4, 'created': '2016-02-08 03:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a50b84213e20949e24681576e6f45ed3e3cd82d8', 'message': 'Use dnf to cleanup old kernels\n\nAs described in the comment, there is a dnf equivalent of this command\nthat doesn\'t require us installing yum-utils (which drags in yum on\ndnf-only systems such as f23)\n\nThis is a small consequence to this -- due to us not installing\nyum-utils some installs will now be completely yum free.  This causes\na breakage in ironic-agent 99-remove-extra-packages where we remove\nthe yum package.  There is a long-standing bug/feature where missing\npackages in a group of packages do not cause yum/dnf to exit with\nfailure, but uninstalling a single package will.  Because we have made\nthe systems yum-free, the uninstall of yum can fail in this corner\ncase.\n\nIt has always been like this, so I\'m in favour of the ""ain\'t broke""\napproach.  To work-around this, I have just put yum into the existing\nlist of packages to be cleaned up.  I have added a note to the yum\ninstaller taking note of this behaviour for future reference.\n\nChange-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03\n'}, {'number': 5, 'created': '2016-02-08 03:21:09.000000000', 'files': ['elements/redhat-common/finalise.d/01-clean-old-kernels', 'elements/ironic-agent/finalise.d/99-remove-extra-packages', 'elements/yum/bin/install-packages'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cb0e0e903dc0dbfb130622c752788629f01d80d9', 'message': 'Use dnf to cleanup old kernels\n\nAs described in the comment, there is a dnf equivalent of this command\nthat doesn\'t require us installing yum-utils (which drags in yum on\ndnf-only systems such as f23)\n\nThis is a small consequence to this -- due to us not installing\nyum-utils some installs will now be completely yum free.  This causes\na breakage in ironic-agent 99-remove-extra-packages where we remove\nthe yum package.  There is a long-standing bug/feature where missing\npackages in a group of packages do not cause yum/dnf to exit with\nfailure, but uninstalling a single package will.  Because we have made\nthe systems yum-free, the uninstall of yum can fail in this corner\ncase.\n\nIt has always been like this, so I\'m in favour of the ""ain\'t broke""\napproach.  To work-around this, I have just put yum into the existing\nlist of packages to be cleaned up.  I have added a note to the yum\ninstaller taking note of this behaviour for future reference.\n\nChange-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03\n'}]",0,249539,cb0e0e903dc0dbfb130622c752788629f01d80d9,41,4,5,7118,,,0,"Use dnf to cleanup old kernels

As described in the comment, there is a dnf equivalent of this command
that doesn't require us installing yum-utils (which drags in yum on
dnf-only systems such as f23)

This is a small consequence to this -- due to us not installing
yum-utils some installs will now be completely yum free.  This causes
a breakage in ironic-agent 99-remove-extra-packages where we remove
the yum package.  There is a long-standing bug/feature where missing
packages in a group of packages do not cause yum/dnf to exit with
failure, but uninstalling a single package will.  Because we have made
the systems yum-free, the uninstall of yum can fail in this corner
case.

It has always been like this, so I'm in favour of the ""ain't broke""
approach.  To work-around this, I have just put yum into the existing
list of packages to be cleaned up.  I have added a note to the yum
installer taking note of this behaviour for future reference.

Change-Id: I8bbdc07ccdb89a105b4fc70d5a215077c42fcd03
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/39/249539/3 && git format-patch -1 --stdout FETCH_HEAD,['elements/redhat-common/finalise.d/01-clean-old-kernels'],1,c7fdb3692b6fdb2ce0ec1c87785a4d331cbe777d,kernel-cleanup-dnf,"YUM=${YUM:-yum} if [[ ${YUM} == ""dnf"" ]]; then # cribbed from # http://dnf.readthedocs.org/en/latest/cli_vs_yum.html dnf remove $(dnf repoquery --installonly --latest-limit -1 -q) else install-packages yum-utils package-cleanup --oldkernels -y --count=1 fi",install-packages yum-utils package-cleanup --oldkernels -y --count=1,9,2
openstack%2Fsenlin~master~Icca41fba41c4336b27bcf9c49a376a232b1ac65b,openstack/senlin,master,Icca41fba41c4336b27bcf9c49a376a232b1ac65b,tools/setup-service: Add email info when user-create,MERGED,2016-02-14 11:23:05.000000000,2016-02-15 23:46:45.000000000,2016-02-15 23:46:45.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-14 11:23:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/d687cc0f2c5fb3f5940c74b090e04a0943aff7bc', 'message': 'tools/setup-service: Add email info when user-create\n\nChange-Id: Icca41fba41c4336b27bcf9c49a376a232b1ac65b\n'}, {'number': 2, 'created': '2016-02-15 15:07:12.000000000', 'files': ['tools/setup-service'], 'web_link': 'https://opendev.org/openstack/senlin/commit/33342641a58bb90609ce6a74c84c0f37d0551b7b', 'message': 'tools/setup-service: Add email info when user-create\n\nChange-Id: Icca41fba41c4336b27bcf9c49a376a232b1ac65b\n'}]",0,279958,33342641a58bb90609ce6a74c84c0f37d0551b7b,10,3,2,8358,,,0,"tools/setup-service: Add email info when user-create

Change-Id: Icca41fba41c4336b27bcf9c49a376a232b1ac65b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/58/279958/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/setup-service'],1,d687cc0f2c5fb3f5940c74b090e04a0943aff7bc,add-email, --email senlin@localhost,,1,0
openstack%2Fkeystone~master~I684149b3529c660e85f0f9194ad9ca494b09bf2e,openstack/keystone,master,I684149b3529c660e85f0f9194ad9ca494b09bf2e,Consolidate trust tests into a single class,ABANDONED,2016-02-10 20:57:15.000000000,2016-02-15 23:45:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 13152}, {'_account_id': 17860}]","[{'number': 1, 'created': '2016-02-10 20:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1417902bf11ab8e4e95f4795bcedfdfcf04f6e0e', 'message': 'Consolidate trust tests into a single class\n\nPreviously, trust auth tests were seperated into different test\nclasses. This consolidates the trust tests to be contained within one\nclass that details the trust behavior. This makes it easier to run\ntrust tests against different keystone configurations.\n\nChange-Id: I684149b3529c660e85f0f9194ad9ca494b09bf2e\n'}, {'number': 2, 'created': '2016-02-11 15:45:57.000000000', 'files': ['keystone/tests/unit/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/c35d7691cbacb642c0544b7195a02405d5d9dbc9', 'message': 'Consolidate trust tests into a single class\n\nPreviously, trust auth tests were seperated into different test\nclasses. This consolidates the trust tests to be contained within one\nclass that details the trust behavior. This makes it easier to run\ntrust tests against different keystone configurations.\n\nChange-Id: I684149b3529c660e85f0f9194ad9ca494b09bf2e\n'}]",3,278628,c35d7691cbacb642c0544b7195a02405d5d9dbc9,8,6,2,13152,,,0,"Consolidate trust tests into a single class

Previously, trust auth tests were seperated into different test
classes. This consolidates the trust tests to be contained within one
class that details the trust behavior. This makes it easier to run
trust tests against different keystone configurations.

Change-Id: I684149b3529c660e85f0f9194ad9ca494b09bf2e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/28/278628/2 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_v3_auth.py'],1,1417902bf11ab8e4e95f4795bcedfdfcf04f6e0e,bug/1538626,"class TrustAPIBehavior(test_v3.RestfulTestCase): super(TrustAPIBehavior, self).config_overrides() super(TrustAPIBehavior, self).setUp() def setup_trust_chain(self): """"""Create a trust chain using redelegation. A trust chain is a series of trusts that are redelegated. For example, self.user_list consists of userA, userB, and userC. The first trust in the trust chain is going to be established between self.user and userA, call it trustA. Then, userA is going to obtain a trust scoped token using trustA, and with that token create a trust between userA and userB called trustB. This pattern will continue with userB creating a trust with userC. So the trust chain should look something like: trustA -> trustB -> trustC Where: self.user is trusting userA with trustA userA is trusting userB with trustB userB is trusting userC with trustC """""" self.user_list = list() self.trust_chain = list() for _ in range(3): user = unit.create_user(self.identity_api, domain_id=self.domain_id) self.user_list.append(user) # trustor->trustee redelegation with impersonation trustee = self.user_list[0] # Set update redelegated_trust_ref self.redelegated_trust_ref.update( trustee_user_id=trustee['id'], redelegation_count=3) # Create a trust between self.user and the first user in the list r = self.post('/OS-TRUST/trusts', body={'trust': self.redelegated_trust_ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'], trust_id=trust['id']) # Generate a trusted token for the first user trust_token = self.get_requested_token(auth_data) self.trust_chain.append(trust) # Loop through the user to create a chain of redelegated trust. for next_trustee in self.user_list[1:]: # Update trustee user on self.chained_trust_ref self.chained_trust_ref['trustee_user_id'] = next_trustee['id'] r = self.post('/OS-TRUST/trusts', body={'trust': self.chained_trust_ref}, token=trust_token) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=next_trustee['id'], password=next_trustee['password'], trust_id=trust['id']) trust_token = self.get_requested_token(auth_data) self.trust_chain.append(trust) trustee = self.user_list[-1] trust = self.trust_chain[-1] auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'], trust_id=trust['id']) self.last_token = self.get_requested_token(auth_data) def assert_user_authenticate(self, user): auth_data = self.build_authentication_request( user_id=user['id'], password=user['password'] ) r = self.v3_create_token(auth_data) self.assertValidTokenResponse(r) def assert_trust_tokens_revoked(self, trust_id): self.setup_trust_chain() trustee = self.user_list[0] auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'] ) r = self.v3_create_token(auth_data) self.assertValidTokenResponse(r) revocation_response = self.get('/OS-REVOKE/events') revocation_events = revocation_response.json_body['events'] found = False for event in revocation_events: if event.get('OS-TRUST:trust_id') == trust_id: found = True self.assertTrue(found, 'event with trust_id %s not found in list' % trust_id) # Trust redelegation scenarios # Trust chain scenarios self.setup_trust_chain() self.setup_trust_chain() self.setup_trust_chain() self.setup_trust_chain() self.setup_trust_chain()","class TestTrustRedelegation(test_v3.RestfulTestCase): super(TestTrustRedelegation, self).config_overrides() super(TestTrustRedelegation, self).setUp() class TestTrustChain(test_v3.RestfulTestCase): def config_overrides(self): super(TestTrustChain, self).config_overrides() self.config_fixture.config( group='trust', enabled=True, allow_redelegation=True, max_redelegation_count=10 ) def setUp(self): super(TestTrustChain, self).setUp() """"""Create a trust chain using redelegation. A trust chain is a series of trusts that are redelegated. For example, self.user_list consists of userA, userB, and userC. The first trust in the trust chain is going to be established between self.user and userA, call it trustA. Then, userA is going to obtain a trust scoped token using trustA, and with that token create a trust between userA and userB called trustB. This pattern will continue with userB creating a trust with userC. So the trust chain should look something like: trustA -> trustB -> trustC Where: self.user is trusting userA with trustA userA is trusting userB with trustB userB is trusting userC with trustC """""" self.user_list = list() self.trust_chain = list() for _ in range(3): user = unit.create_user(self.identity_api, domain_id=self.domain_id) self.user_list.append(user) # trustor->trustee redelegation with impersonation trustee = self.user_list[0] trust_ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=trustee['id'], project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id], allow_redelegation=True, redelegation_count=3) # Create a trust between self.user and the first user in the list r = self.post('/OS-TRUST/trusts', body={'trust': trust_ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'], trust_id=trust['id']) # Generate a trusted token for the first user trust_token = self.get_requested_token(auth_data) self.trust_chain.append(trust) # Loop through the user to create a chain of redelegated trust. for next_trustee in self.user_list[1:]: trust_ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=next_trustee['id'], project_id=self.project_id, impersonation=True, role_ids=[self.role_id], allow_redelegation=True) r = self.post('/OS-TRUST/trusts', body={'trust': trust_ref}, token=trust_token) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=next_trustee['id'], password=next_trustee['password'], trust_id=trust['id']) trust_token = self.get_requested_token(auth_data) self.trust_chain.append(trust) trustee = self.user_list[-1] trust = self.trust_chain[-1] auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'], trust_id=trust['id']) self.last_token = self.get_requested_token(auth_data) def assert_user_authenticate(self, user): auth_data = self.build_authentication_request( user_id=user['id'], password=user['password'] ) r = self.v3_create_token(auth_data) self.assertValidTokenResponse(r) def assert_trust_tokens_revoked(self, trust_id): trustee = self.user_list[0] auth_data = self.build_authentication_request( user_id=trustee['id'], password=trustee['password'] ) r = self.v3_create_token(auth_data) self.assertValidTokenResponse(r) revocation_response = self.get('/OS-REVOKE/events') revocation_events = revocation_response.json_body['events'] found = False for event in revocation_events: if event.get('OS-TRUST:trust_id') == trust_id: found = True self.assertTrue(found, 'event with trust_id %s not found in list' % trust_id)",110,121
openstack%2Ftempest~master~Ie9af231ced0ecdce41375122a7b626355a7d73cc,openstack/tempest,master,Ie9af231ced0ecdce41375122a7b626355a7d73cc,Make create_test_server function to accept original kwargs,ABANDONED,2015-12-24 07:10:47.000000000,2016-02-15 23:42:34.000000000,,"[{'_account_id': 3}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10016}, {'_account_id': 10385}, {'_account_id': 12017}]","[{'number': 1, 'created': '2015-12-24 07:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/181b5c221836144001a687fdf7d87bda21010440', 'message': ""Make create_test_server function to accept original kwargs\n\ncommon/compute.py->create_test_server function take 'image_id'\nand 'flavor' in kwargs and then convert those to 'ImageRef'\nand 'flavorRef' respectively.\n\nThis is confusing and error prone as user of this methods needs to\npass different set of kwargs than the actual ones which are used to\ncreate server. And other wrapper of this function also use it same way.\n\nThis commit makes this common function to start accepting all original\nkwargs for creating servers and use those without any alteration.\n\nChange-Id: Ie9af231ced0ecdce41375122a7b626355a7d73cc\n""}, {'number': 2, 'created': '2015-12-24 07:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/20bce1bd8c78f74ec48df03a6eb14f4c3b3aecfa', 'message': ""Make create_test_server function to accept original kwargs\n\ncommon/compute.py->create_test_server function take 'image_id'\nand 'flavor' in kwargs and then convert those to 'ImageRef'\nand 'flavorRef' respectively.\n\nThis is confusing and error prone as user of this methods needs to\npass different set of kwargs than the actual ones which are used to\ncreate server. And other wrapper of this function also use it same way.\n\nThis commit makes this common function to start accepting all original\nkwargs for creating servers and use those without any alteration.\n\nChange-Id: Ie9af231ced0ecdce41375122a7b626355a7d73cc\n""}, {'number': 3, 'created': '2015-12-24 08:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/858ae7c940793ae3d56e8fecb6c91b59f68d633d', 'message': ""Make create_test_server function to accept original kwargs\n\ncommon/compute.py->create_test_server function take 'image_id'\nand 'flavor' in kwargs and then convert those to 'ImageRef'\nand 'flavorRef' respectively.\n\nThis is confusing and error prone as user of this methods needs to\npass different set of kwargs than the actual ones which are used to\ncreate server. And other wrapper of this function also use it same way.\n\nThis commit makes this common function to start accepting all original\nkwargs for creating servers and use those without any alteration.\n\nChange-Id: Ie9af231ced0ecdce41375122a7b626355a7d73cc\n""}, {'number': 4, 'created': '2016-01-06 05:45:50.000000000', 'files': ['tempest/api/compute/servers/test_servers_negative.py', 'tempest/api/compute/servers/test_create_server.py', 'tempest/scenario/test_minimum_basic.py', 'tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/api/compute/servers/test_list_server_filters.py', 'tempest/scenario/test_encrypted_cinder_volumes.py', 'tempest/scenario/test_snapshot_pattern.py', 'tempest/common/compute.py', 'tempest/scenario/test_shelve_instance.py', 'tempest/scenario/test_stamp_pattern.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/d258e763934eebdf3a925bc2aea61a83041eff13', 'message': ""Make create_test_server function to accept original kwargs\n\ncommon/compute.py->create_test_server function take 'image_id'\nand 'flavor' in kwargs and then convert those to 'ImageRef'\nand 'flavorRef' respectively.\n\nThis is confusing and error prone as user of this methods needs to\npass different set of kwargs than the actual ones which are used to\ncreate server. And other wrapper of this function also use it same way.\n\nThis commit makes this common function to start accepting all original\nkwargs for creating servers and use those without any alteration.\n\nChange-Id: Ie9af231ced0ecdce41375122a7b626355a7d73cc\n""}]",5,261204,d258e763934eebdf3a925bc2aea61a83041eff13,36,9,4,8556,,,0,"Make create_test_server function to accept original kwargs

common/compute.py->create_test_server function take 'image_id'
and 'flavor' in kwargs and then convert those to 'ImageRef'
and 'flavorRef' respectively.

This is confusing and error prone as user of this methods needs to
pass different set of kwargs than the actual ones which are used to
create server. And other wrapper of this function also use it same way.

This commit makes this common function to start accepting all original
kwargs for creating servers and use those without any alteration.

Change-Id: Ie9af231ced0ecdce41375122a7b626355a7d73cc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/04/261204/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_minimum_basic.py', 'tempest/scenario/test_server_basic_ops.py', 'tempest/scenario/test_volume_boot_pattern.py', 'tempest/scenario/test_encrypted_cinder_volumes.py', 'tempest/scenario/test_snapshot_pattern.py', 'tempest/common/compute.py', 'tempest/scenario/test_shelve_instance.py', 'tempest/scenario/test_stamp_pattern.py']",8,181b5c221836144001a687fdf7d87bda21010440,(detached," imageRef=CONF.compute.image_ref, imageRef=snapshot_image['id'],"," image_id=CONF.compute.image_ref, image_id=snapshot_image['id'],",23,18
openstack%2Ftempest~master~I556fa1669e9e7bc0d665a4fdf926394671321bca,openstack/tempest,master,I556fa1669e9e7bc0d665a4fdf926394671321bca,Skip list server for specified tenant tests,ABANDONED,2015-06-26 05:21:12.000000000,2016-02-15 23:40:02.000000000,,"[{'_account_id': 3}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-06-26 05:21:12.000000000', 'files': ['tempest/api/compute/admin/test_servers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9ed7dfa0982ddc002cb3289139c738b850345f61', 'message': ""Skip list server for specified tenant tests\n\nThere is bug in nova (#1468992) that server list with specified\ntenant does not work as expected till 'all_tenant' option is specified.\n\nI0c576e39f16dd85b62e3adad735acc8f391ca0ca fix that bug on nova side.\nwhich needs this Tempest tests to skip which test the current behavior\nof Nova.\n\nAfter Nova patch lands, this tests will be unskipped and modified\nto tests correct nova behavior.\n\nChange-Id: I556fa1669e9e7bc0d665a4fdf926394671321bca\nRelated-Bug: #1468992\n""}]",2,195869,9ed7dfa0982ddc002cb3289139c738b850345f61,11,4,1,8556,,,0,"Skip list server for specified tenant tests

There is bug in nova (#1468992) that server list with specified
tenant does not work as expected till 'all_tenant' option is specified.

I0c576e39f16dd85b62e3adad735acc8f391ca0ca fix that bug on nova side.
which needs this Tempest tests to skip which test the current behavior
of Nova.

After Nova patch lands, this tests will be unskipped and modified
to tests correct nova behavior.

Change-Id: I556fa1669e9e7bc0d665a4fdf926394671321bca
Related-Bug: #1468992
",git fetch https://review.opendev.org/openstack/tempest refs/changes/69/195869/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/admin/test_servers.py'],1,9ed7dfa0982ddc002cb3289139c738b850345f61,skip_all_tenant, @decorators.skip_because(bug='1398350'),,1,0
openstack%2Fnova~master~If88beeb3983705621fe736995939ac20b2daf1f3,openstack/nova,master,If88beeb3983705621fe736995939ac20b2daf1f3,Tolerate installation of pycryptodome,MERGED,2016-02-14 02:29:41.000000000,2016-02-15 23:34:35.000000000,2016-02-15 23:34:34.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 8119}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-14 02:29:41.000000000', 'files': ['nova/crypto.py', 'nova/tests/unit/test_crypto.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1fd0f4f69b21cbd20c0eb0e2f8f4506061f4a211', 'message': 'Tolerate installation of pycryptodome\n\nNewer versions of pysaml2 uses pycryptodome, so if by\naccident if this library gets installed, Nova breaks.\n\nparamiko folks are working on this:\nhttps://github.com/paramiko/paramiko/issues/637\n\nIn the meanwhile, we should tolerate if either pycrypto\nor pycryptodome is installed.\n\nCloses-Bug: #1545370\nChange-Id: If88beeb3983705621fe736995939ac20b2daf1f3\n'}]",0,279909,1fd0f4f69b21cbd20c0eb0e2f8f4506061f4a211,16,6,1,5638,,,0,"Tolerate installation of pycryptodome

Newer versions of pysaml2 uses pycryptodome, so if by
accident if this library gets installed, Nova breaks.

paramiko folks are working on this:
https://github.com/paramiko/paramiko/issues/637

In the meanwhile, we should tolerate if either pycrypto
or pycryptodome is installed.

Closes-Bug: #1545370
Change-Id: If88beeb3983705621fe736995939ac20b2daf1f3
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/279909/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/crypto.py', 'nova/tests/unit/test_crypto.py']",2,1fd0f4f69b21cbd20c0eb0e2f8f4506061f4a211,bug/1545370," with mock.patch.object(crypto, 'generate_key') as mock_generate:"," with mock.patch.object(paramiko.RSAKey, 'generate') as mock_generate:",22,2
openstack%2Fhorizon~master~I281da92cfa5df7e04755097f81ede2b1b7ac835b,openstack/horizon,master,I281da92cfa5df7e04755097f81ede2b1b7ac835b,Add isCurrentProject to userSession service,MERGED,2016-02-11 20:04:48.000000000,2016-02-15 23:33:32.000000000,2016-02-15 23:33:31.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 9622}]","[{'number': 1, 'created': '2016-02-11 20:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aff11056da37dc7de470b783f11cb7f483326990', 'message': ""Add isOwner to userSession service\n\nSeveral times we've wanted to make a decision based on whether the current\nuser's project matches that of some given project on an item.  Rather than\nrewriting this code all over the place, this patch centralizes the logic\nso we can use this determination of ownership for all sorts of things\nneeding that kind of promise.\n\nChange-Id: I281da92cfa5df7e04755097f81ede2b1b7ac835b\nPartially-Implements: blueprint angularize-image-table\n""}, {'number': 2, 'created': '2016-02-12 20:41:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1b01c992af9c7fdb754bdb120f8522c4ac497c5b', 'message': ""Add isCurrentProject to userSession service\n\nSeveral times we've wanted to make a decision based on whether the current\nuser's project matches that of some given project on an item.  Rather than\nrewriting this code all over the place, this patch centralizes the logic\nso we can use this determination of ownership for all sorts of things\nneeding that kind of promise.\n\nChange-Id: I281da92cfa5df7e04755097f81ede2b1b7ac835b\nPartially-Implements: blueprint angularize-image-table\n""}, {'number': 3, 'created': '2016-02-12 21:04:51.000000000', 'files': ['openstack_dashboard/static/app/core/openstack-service-api/user-session.service.spec.js', 'openstack_dashboard/static/app/core/openstack-service-api/user-session.service.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d2a606289a4fba29f24925521fde3efc93053f25', 'message': ""Add isCurrentProject to userSession service\n\nSeveral times we've wanted to make a decision based on whether the current\nuser's project matches that of some given project on an item.  Rather than\nrewriting this code all over the place, this patch centralizes the logic\nso we can use this determination of ownership for all sorts of things\nneeding that kind of promise.\n\nChange-Id: I281da92cfa5df7e04755097f81ede2b1b7ac835b\nPartially-Implements: blueprint angularize-image-table\n""}]",4,279245,d2a606289a4fba29f24925521fde3efc93053f25,15,4,3,14124,,,0,"Add isCurrentProject to userSession service

Several times we've wanted to make a decision based on whether the current
user's project matches that of some given project on an item.  Rather than
rewriting this code all over the place, this patch centralizes the logic
so we can use this determination of ownership for all sorts of things
needing that kind of promise.

Change-Id: I281da92cfa5df7e04755097f81ede2b1b7ac835b
Partially-Implements: blueprint angularize-image-table
",git fetch https://review.opendev.org/openstack/horizon refs/changes/45/279245/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/app/core/openstack-service-api/user-session.service.spec.js', 'openstack_dashboard/static/app/core/openstack-service-api/user-session.service.js']",2,aff11056da37dc7de470b783f11cb7f483326990,bp/angularize-images-table," '$q', function userSession($cacheFactory, $q, keystoneAPI) { get: get, isOwner: isOwner /* * @ngdoc function * @name isOwner * @description * Given a project ID, returns a promise that either resolves or rejects * based on whether the user's project ID matches or doesn't. */ function isOwner(projectId) { var deferred = $q.defer(); get().then(onUserSessionGet); return deferred.promise; function onUserSessionGet(userSession) { if (userSession.project_id === projectId) { deferred.resolve(); } else { deferred.reject(); } } }"," function userSession($cacheFactory, keystoneAPI) { get: get",60,3
openstack%2Fnova~master~I5fc4b55418f187817e81343e9224b731f8eea5e2,openstack/nova,master,I5fc4b55418f187817e81343e9224b731f8eea5e2,relocate os_compute_api:servers:discoverable,MERGED,2016-02-05 13:56:10.000000000,2016-02-15 23:31:47.000000000,2016-02-15 23:31:45.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-05 13:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c6fc12e404cee05a44762750c7dc865928f6148', 'message': 'relocate os_compute_api:servers:discoverable\n\nmove os_compute_api:servers:discoverable to other\npolicy defined position to make them easier\nto be recognized and used by end user.\n\nChange-Id: I5fc4b55418f187817e81343e9224b731f8eea5e2\n'}, {'number': 2, 'created': '2016-02-11 08:26:26.000000000', 'files': ['etc/nova/policy.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/69c9ed02297095b9adda12611e0070cb550b2581', 'message': 'relocate os_compute_api:servers:discoverable\n\nmove os_compute_api:servers:discoverable to other\npolicy defined position to make them easier\nto be recognized and used by end user.\n\nChange-Id: I5fc4b55418f187817e81343e9224b731f8eea5e2\n'}]",0,276740,69c9ed02297095b9adda12611e0070cb550b2581,36,12,2,6062,,,0,"relocate os_compute_api:servers:discoverable

move os_compute_api:servers:discoverable to other
policy defined position to make them easier
to be recognized and used by end user.

Change-Id: I5fc4b55418f187817e81343e9224b731f8eea5e2
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/276740/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/nova/policy.json'],1,4c6fc12e404cee05a44762750c7dc865928f6148,policy_repos," ""os_compute_api:servers:discoverable"": """","," ""os_compute_api:servers:discoverable"": """",",1,1
openstack%2Fglance~master~Id7800d22306c2e5dc4624cb28addee7fd9c8e344,openstack/glance,master,Id7800d22306c2e5dc4624cb28addee7fd9c8e344,grammar correction in basic architecture file,MERGED,2016-02-14 16:00:13.000000000,2016-02-15 23:30:55.000000000,2016-02-15 23:30:54.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 10068}]","[{'number': 1, 'created': '2016-02-14 16:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/373567d331aafc4b3ae00d263c406e596b916645', 'message': 'grammar correction in basic architecture file\n\nChange-Id: Id7800d22306c2e5dc4624cb28addee7fd9c8e344\n'}, {'number': 2, 'created': '2016-02-15 10:20:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9e9f1215065268e00b218cd921dc6d3327d8cdf4', 'message': 'grammar correction in basic architecture file\n\nChange-Id: Id7800d22306c2e5dc4624cb28addee7fd9c8e344\n'}, {'number': 3, 'created': '2016-02-15 18:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/082a337fa23a1aa850b74030a45483f120534229', 'message': 'grammar correction in basic architecture file\n\nChange-Id: Id7800d22306c2e5dc4624cb28addee7fd9c8e344\n'}, {'number': 4, 'created': '2016-02-15 19:21:43.000000000', 'files': ['doc/source/architecture.rst'], 'web_link': 'https://opendev.org/openstack/glance/commit/e05c58307c828133e8cbf7ef5b5c3094378d2112', 'message': 'grammar correction in basic architecture file\n\nChange-Id: Id7800d22306c2e5dc4624cb28addee7fd9c8e344\n'}]",7,279997,e05c58307c828133e8cbf7ef5b5c3094378d2112,20,4,4,20518,,,0,"grammar correction in basic architecture file

Change-Id: Id7800d22306c2e5dc4624cb28addee7fd9c8e344
",git fetch https://review.opendev.org/openstack/glance refs/changes/97/279997/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/architecture.rst~', 'doc/source/architecture.rst']",2,373567d331aafc4b3ae00d263c406e596b916645,documentation_edit,"OpenStack Glance has a client-server architecture that provides a REST API to the user through which requests to the server can be performed. A Glance Domain Controller manages the internal server operations that is divided into layers. A specific task is implemented by each layer. All the file (Image data) operations are performed using glance_store library, that is responsible for interaction with external storage back ends and (or) local filesystem(s). In turn, it provides a uniform interface to access the backend stores. Glance uses a central database (Glance DB) that is shared amongst all the components in the system and is sql-based by default. Other types of database backends are somewhat supported and used by operators but are not extensively tested upstream.Following components are present in the Glance architecture: * **A client** - any application that makes use of a Glance server. * **REST API** - Glance functionalities are exposed via REST. * **Database Abstraction Layer (DAL)** - an application programming interface(API) that unifies the communication between Glance and databases. * **Glance Domain Controller** - acts as a middleware used to implement the main Glance functionalities such as authorization, notifications, policies,database connections. * **Glance Store** - used to organize interactions between Glance and various data stores. * **Registry Layer** - optional layer that is used to organise secure communication between the domain and the DAL by using a separate service.","OpenStack Glance has a client-server architecture and provides a user REST API through which requests to the server are performed. Internal server operations are managed by a Glance Domain Controller divided into layers. Each layer implements its own task. All the files operations are performed using glance_store library which is responsible for interaction with external storage back ends or local filesystem, and provides a uniform interface to access. Glance uses an sql-based central database (Glance DB) that is shared with all the components in the system.The Glance architecture consists of several components: * **A client** - any application that uses Glance server. * **REST API** - exposes Glance functionality via REST. * **Database Abstraction Layer (DAL)** - an application programming interface which unifies the communication between Glance and databases. * **Glance Domain Controller** - middleware that implements the main Glance functionalities: authorization, notifications, policies, database connections. * **Glance Store** - organizes interactions between Glance and various data stores. * **Registry Layer** - optional layer organizing secure communication between the domain and the DAL by using a separate service.",71,21
openstack%2Fkeystone~master~I378974cc1707a888da7a0eef6117e5c4b6625d24,openstack/keystone,master,I378974cc1707a888da7a0eef6117e5c4b6625d24,Consolidate TestTrustRedelegation and TestTrustAuth tests,ABANDONED,2016-02-15 23:25:55.000000000,2016-02-15 23:26:50.000000000,,[],"[{'number': 1, 'created': '2016-02-15 23:25:55.000000000', 'files': ['keystone/tests/unit/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/331b1fdc0144e925256fb00f4bf13a1ef944bf11', 'message': 'Consolidate TestTrustRedelegation and TestTrustAuth tests\n\nPreviously, trust auth tests were seperated into different test\nclasses. This consolidates the trust tests to be contained within one\nclass that details the trust behavior, except for TestTrustChain\nwhich has an expensive setup. This makes it easier to run\ntrust tests against different keystone configurations.\n\nChange-Id: I378974cc1707a888da7a0eef6117e5c4b6625d24\n'}]",0,280442,331b1fdc0144e925256fb00f4bf13a1ef944bf11,2,0,1,13152,,,0,"Consolidate TestTrustRedelegation and TestTrustAuth tests

Previously, trust auth tests were seperated into different test
classes. This consolidates the trust tests to be contained within one
class that details the trust behavior, except for TestTrustChain
which has an expensive setup. This makes it easier to run
trust tests against different keystone configurations.

Change-Id: I378974cc1707a888da7a0eef6117e5c4b6625d24
",git fetch https://review.opendev.org/openstack/keystone refs/changes/42/280442/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_v3_auth.py'],1,331b1fdc0144e925256fb00f4bf13a1ef944bf11,bug/1538626,"class TrustAPIBehavior(test_v3.RestfulTestCase): super(TrustAPIBehavior, self).config_overrides() super(TrustAPIBehavior, self).setUp() def test_create_unscoped_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id']) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) self.assertValidTrustResponse(r, ref) def test_create_trust_no_roles(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id) self.post('/OS-TRUST/trusts', body={'trust': ref}, expected_status=http_client.FORBIDDEN) def _initialize_test_consume_trust(self, count): # Make sure remaining_uses is decremented as we consume the trust ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, remaining_uses=count, role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) # make sure the trust exists trust = self.assertValidTrustResponse(r, ref) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) # get a token for the trustee auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password']) r = self.v3_create_token(auth_data) token = r.headers.get('X-Subject-Token') # get a trust token, consume one use auth_data = self.build_authentication_request( token=token, trust_id=trust['id']) r = self.v3_create_token(auth_data) return trust def test_consume_trust_once(self): trust = self._initialize_test_consume_trust(2) # check decremented value r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) trust = r.result.get('trust') self.assertIsNotNone(trust) self.assertEqual(1, trust['remaining_uses']) # FIXME(lbragstad): Assert the role that is returned is the right role. def test_create_one_time_use_trust(self): trust = self._initialize_test_consume_trust(1) # No more uses, the trust is made unavailable self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}, expected_status=http_client.NOT_FOUND) # this time we can't get a trust token auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_create_unlimited_use_trust(self): # by default trusts are unlimited in terms of tokens that can be # generated from them, this test creates such a trust explicitly ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, remaining_uses=None, role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password']) r = self.v3_create_token(auth_data) token = r.headers.get('X-Subject-Token') auth_data = self.build_authentication_request( token=token, trust_id=trust['id']) r = self.v3_create_token(auth_data) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) trust = r.result.get('trust') self.assertIsNone(trust['remaining_uses']) def test_impersonation_token_cannot_create_new_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) trust_token = self.get_requested_token(auth_data) # Build second trust ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) self.post('/OS-TRUST/trusts', body={'trust': ref}, token=trust_token, expected_status=http_client.FORBIDDEN) def test_trust_deleted_grant(self): # create a new role role = unit.new_role_ref() self.role_api.create_role(role['id'], role) grant_url = ( '/projects/%(project_id)s/users/%(user_id)s/' 'roles/%(role_id)s' % { 'project_id': self.project_id, 'user_id': self.user_id, 'role_id': role['id']}) # assign a new role self.put(grant_url) # create a trust that delegates the new role ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[role['id']]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) # delete the grant self.delete(grant_url) # attempt to get a trust token with the deleted grant # and ensure it's unauthorized auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) r = self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def test_trust_chained(self): """"""Test that a trust token can't be used to execute another trust. To do this, we create an A->B->C hierarchy of trusts, then attempt to execute the trusts in series (C->B->A). """""" # create a sub-trustee user sub_trustee_user = unit.create_user( self.identity_api, domain_id=test_v3.DEFAULT_DOMAIN_ID) sub_trustee_user_id = sub_trustee_user['id'] # create a new role role = unit.new_role_ref() self.role_api.create_role(role['id'], role) # assign the new role to trustee self.put( '/projects/%(project_id)s/users/%(user_id)s/roles/%(role_id)s' % { 'project_id': self.project_id, 'user_id': self.trustee_user['id'], 'role_id': role['id']}) # create a trust from trustor -> trustee ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust1 = self.assertValidTrustResponse(r) # authenticate as trustee so we can create a second trust auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], project_id=self.project_id) token = self.get_requested_token(auth_data) # create a trust from trustee -> sub-trustee ref = unit.new_trust_ref( trustor_user_id=self.trustee_user['id'], trustee_user_id=sub_trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[role['id']]) r = self.post('/OS-TRUST/trusts', token=token, body={'trust': ref}) trust2 = self.assertValidTrustResponse(r) # authenticate as sub-trustee and get a trust token auth_data = self.build_authentication_request( user_id=sub_trustee_user['id'], password=sub_trustee_user['password'], trust_id=trust2['id']) trust_token = self.get_requested_token(auth_data) # attempt to get the second trust using a trust token auth_data = self.build_authentication_request( token=trust_token, trust_id=trust1['id']) r = self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def assertTrustTokensRevoked(self, trust_id): revocation_response = self.get('/OS-REVOKE/events') revocation_events = revocation_response.json_body['events'] found = False for event in revocation_events: if event.get('OS-TRUST:trust_id') == trust_id: found = True self.assertTrue(found, 'event with trust_id %s not found in list' % trust_id) def test_delete_trust_revokes_tokens(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) trust_id = trust['id'] auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust_id) r = self.v3_create_token(auth_data) self.assertValidProjectScopedTokenResponse( r, self.trustee_user) trust_token = r.headers['X-Subject-Token'] self.delete('/OS-TRUST/trusts/%(trust_id)s' % { 'trust_id': trust_id}) headers = {'X-Subject-Token': trust_token} self.head('/auth/tokens', headers=headers, expected_status=http_client.NOT_FOUND) self.assertTrustTokensRevoked(trust_id) def disable_user(self, user): user['enabled'] = False self.identity_api.update_user(user['id'], user) def test_trust_get_token_fails_if_trustor_disabled(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data) self.disable_user(self.user) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def test_trust_get_token_fails_if_trustee_disabled(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data) self.disable_user(self.trustee_user) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_delete_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) self.delete('/OS-TRUST/trusts/%(trust_id)s' % { 'trust_id': trust['id']}) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_change_password_invalidates_trust_tokens(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) r = self.v3_create_token(auth_data) self.assertValidProjectScopedTokenResponse(r, self.user) trust_token = r.headers.get('X-Subject-Token') self.get('/OS-TRUST/trusts?trustor_user_id=%s' % self.user_id, token=trust_token) self.assertValidUserResponse( self.patch('/users/%s' % self.trustee_user['id'], body={'user': {'password': uuid.uuid4().hex}})) self.get('/OS-TRUST/trusts?trustor_user_id=%s' % self.user_id, expected_status=http_client.UNAUTHORIZED, token=trust_token) def test_trustee_can_do_role_ops(self): resp = self.post('/OS-TRUST/trusts', body={'trust': self.redelegated_trust_ref}) trust = self.assertValidTrustResponse(resp) trust_token = self._get_trust_token(trust) resp = self.get( '/OS-TRUST/trusts/%(trust_id)s/roles' % { 'trust_id': trust['id']}, token=trust_token) self.assertValidRoleListResponse(resp, self.role) self.head( '/OS-TRUST/trusts/%(trust_id)s/roles/%(role_id)s' % { 'trust_id': trust['id'], 'role_id': self.role['id']}, token=trust_token, expected_status=http_client.OK) resp = self.get( '/OS-TRUST/trusts/%(trust_id)s/roles/%(role_id)s' % { 'trust_id': trust['id'], 'role_id': self.role['id']}, token=trust_token) self.assertValidRoleResponse(resp, self.role) def test_do_not_consume_remaining_uses_when_get_token_fails(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user['id'], project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id], remaining_uses=3) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) new_trust = r.result.get('trust') trust_id = new_trust.get('id') # Pass in another user's ID as the trustee, the result being a failed # token authenticate and the remaining_uses of the trust should not be # decremented. auth_data = self.build_authentication_request( user_id=self.default_domain_user['id'], password=self.default_domain_user['password'], trust_id=trust_id) self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) r = self.get('/OS-TRUST/trusts/%s' % trust_id) self.assertEqual(3, r.result.get('trust').get('remaining_uses')) # trustor->trustee redelegation without impersonation impersonation=False, # Set trustor and redelegated_trust_id for next trust in the chain next_trustor_id = trustee['id'] redelegated_trust_id = trust['id'] trustor_user_id=next_trustor_id, impersonation=False, allow_redelegation=True, redelegated_trust_id=redelegated_trust_id) next_trustor_id = next_trustee['id'] redelegated_trust_id = trust['id'] self.delete('/OS-TRUST/trusts/%(trust_id)s' % {class TestTrustAuthPKITokenProvider(TrustAPIBehavior, TestTrustChain): def config_overrides(self): super(TestTrustAuthPKITokenProvider, self).config_overrides() self.config_fixture.config(group='token', provider='pki', revoke_by_id=False) self.config_fixture.config(group='trust', enabled=True) class TestTrustAuthFernetTokenProvider(TrustAPIBehavior, TestTrustChain): def config_overrides(self): super(TestTrustAuthFernetTokenProvider, self).config_overrides() self.config_fixture.config(group='token', provider='fernet', revoke_by_id=False) self.config_fixture.config(group='trust', enabled=True) ","class TestTrustRedelegation(test_v3.RestfulTestCase): super(TestTrustRedelegation, self).config_overrides() super(TestTrustRedelegation, self).setUp() # trustor->trustee redelegation with impersonation impersonation=True, trustor_user_id=self.user_id, impersonation=True, allow_redelegation=True) # Assert chained trust have been deleted self.get('/OS-TRUST/trusts/%(trust_id)s' % {class TestTrustAuth(test_v3.RestfulTestCase): def config_overrides(self): super(TestTrustAuth, self).config_overrides() self.config_fixture.config( group='token', provider='pki', revoke_by_id=False) self.config_fixture.config(group='trust', enabled=True) def setUp(self): super(TestTrustAuth, self).setUp() # create a trustee to delegate stuff to self.trustee_user = unit.create_user(self.identity_api, domain_id=self.domain_id) self.trustee_user_id = self.trustee_user['id'] def test_create_unscoped_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) self.assertValidTrustResponse(r, ref) def test_create_trust_no_roles(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id) self.post('/OS-TRUST/trusts', body={'trust': ref}, expected_status=http_client.FORBIDDEN) def _initialize_test_consume_trust(self, count): # Make sure remaining_uses is decremented as we consume the trust ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, remaining_uses=count, role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) # make sure the trust exists trust = self.assertValidTrustResponse(r, ref) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) # get a token for the trustee auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password']) r = self.v3_create_token(auth_data) token = r.headers.get('X-Subject-Token') # get a trust token, consume one use auth_data = self.build_authentication_request( token=token, trust_id=trust['id']) r = self.v3_create_token(auth_data) return trust def test_consume_trust_once(self): trust = self._initialize_test_consume_trust(2) # check decremented value r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) trust = r.result.get('trust') self.assertIsNotNone(trust) self.assertEqual(1, trust['remaining_uses']) # FIXME(lbragstad): Assert the role that is returned is the right role. def test_create_one_time_use_trust(self): trust = self._initialize_test_consume_trust(1) # No more uses, the trust is made unavailable self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}, expected_status=http_client.NOT_FOUND) # this time we can't get a trust token auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_create_unlimited_use_trust(self): # by default trusts are unlimited in terms of tokens that can be # generated from them, this test creates such a trust explicitly ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, remaining_uses=None, role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password']) r = self.v3_create_token(auth_data) token = r.headers.get('X-Subject-Token') auth_data = self.build_authentication_request( token=token, trust_id=trust['id']) r = self.v3_create_token(auth_data) r = self.get( '/OS-TRUST/trusts/%(trust_id)s' % {'trust_id': trust['id']}) trust = r.result.get('trust') self.assertIsNone(trust['remaining_uses']) def test_impersonation_token_cannot_create_new_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) trust_token = self.get_requested_token(auth_data) # Build second trust ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) self.post('/OS-TRUST/trusts', body={'trust': ref}, token=trust_token, expected_status=http_client.FORBIDDEN) def test_trust_deleted_grant(self): # create a new role role = unit.new_role_ref() self.role_api.create_role(role['id'], role) grant_url = ( '/projects/%(project_id)s/users/%(user_id)s/' 'roles/%(role_id)s' % { 'project_id': self.project_id, 'user_id': self.user_id, 'role_id': role['id']}) # assign a new role self.put(grant_url) # create a trust that delegates the new role ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[role['id']]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) # delete the grant self.delete(grant_url) # attempt to get a trust token with the deleted grant # and ensure it's unauthorized auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) r = self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def test_trust_chained(self): """"""Test that a trust token can't be used to execute another trust. To do this, we create an A->B->C hierarchy of trusts, then attempt to execute the trusts in series (C->B->A). """""" # create a sub-trustee user sub_trustee_user = unit.create_user( self.identity_api, domain_id=test_v3.DEFAULT_DOMAIN_ID) sub_trustee_user_id = sub_trustee_user['id'] # create a new role role = unit.new_role_ref() self.role_api.create_role(role['id'], role) # assign the new role to trustee self.put( '/projects/%(project_id)s/users/%(user_id)s/roles/%(role_id)s' % { 'project_id': self.project_id, 'user_id': self.trustee_user_id, 'role_id': role['id']}) # create a trust from trustor -> trustee ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust1 = self.assertValidTrustResponse(r) # authenticate as trustee so we can create a second trust auth_data = self.build_authentication_request( user_id=self.trustee_user_id, password=self.trustee_user['password'], project_id=self.project_id) token = self.get_requested_token(auth_data) # create a trust from trustee -> sub-trustee ref = unit.new_trust_ref( trustor_user_id=self.trustee_user_id, trustee_user_id=sub_trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[role['id']]) r = self.post('/OS-TRUST/trusts', token=token, body={'trust': ref}) trust2 = self.assertValidTrustResponse(r) # authenticate as sub-trustee and get a trust token auth_data = self.build_authentication_request( user_id=sub_trustee_user['id'], password=sub_trustee_user['password'], trust_id=trust2['id']) trust_token = self.get_requested_token(auth_data) # attempt to get the second trust using a trust token auth_data = self.build_authentication_request( token=trust_token, trust_id=trust1['id']) r = self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def assertTrustTokensRevoked(self, trust_id): revocation_response = self.get('/OS-REVOKE/events') revocation_events = revocation_response.json_body['events'] found = False for event in revocation_events: if event.get('OS-TRUST:trust_id') == trust_id: found = True self.assertTrue(found, 'event with trust_id %s not found in list' % trust_id) def test_delete_trust_revokes_tokens(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) trust_id = trust['id'] auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust_id) r = self.v3_create_token(auth_data) self.assertValidProjectScopedTokenResponse( r, self.trustee_user) trust_token = r.headers['X-Subject-Token'] self.delete('/OS-TRUST/trusts/%(trust_id)s' % { 'trust_id': trust_id}) headers = {'X-Subject-Token': trust_token} self.head('/auth/tokens', headers=headers, expected_status=http_client.NOT_FOUND) self.assertTrustTokensRevoked(trust_id) def disable_user(self, user): user['enabled'] = False self.identity_api.update_user(user['id'], user) def test_trust_get_token_fails_if_trustor_disabled(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data) self.disable_user(self.user) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) def test_trust_get_token_fails_if_trustee_disabled(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data) self.disable_user(self.trustee_user) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_delete_trust(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r, ref) self.delete('/OS-TRUST/trusts/%(trust_id)s' % { 'trust_id': trust['id']}) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) self.v3_create_token(auth_data, expected_status=http_client.UNAUTHORIZED) def test_change_password_invalidates_trust_tokens(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=True, expires=dict(minutes=1), role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password'], trust_id=trust['id']) r = self.v3_create_token(auth_data) self.assertValidProjectScopedTokenResponse(r, self.user) trust_token = r.headers.get('X-Subject-Token') self.get('/OS-TRUST/trusts?trustor_user_id=%s' % self.user_id, token=trust_token) self.assertValidUserResponse( self.patch('/users/%s' % self.trustee_user['id'], body={'user': {'password': uuid.uuid4().hex}})) self.get('/OS-TRUST/trusts?trustor_user_id=%s' % self.user_id, expected_status=http_client.UNAUTHORIZED, token=trust_token) def test_trustee_can_do_role_ops(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=True, role_ids=[self.role_id]) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) trust = self.assertValidTrustResponse(r) auth_data = self.build_authentication_request( user_id=self.trustee_user['id'], password=self.trustee_user['password']) r = self.get( '/OS-TRUST/trusts/%(trust_id)s/roles' % { 'trust_id': trust['id']}, auth=auth_data) self.assertValidRoleListResponse(r, self.role) self.head( '/OS-TRUST/trusts/%(trust_id)s/roles/%(role_id)s' % { 'trust_id': trust['id'], 'role_id': self.role['id']}, auth=auth_data, expected_status=http_client.OK) r = self.get( '/OS-TRUST/trusts/%(trust_id)s/roles/%(role_id)s' % { 'trust_id': trust['id'], 'role_id': self.role['id']}, auth=auth_data) self.assertValidRoleResponse(r, self.role) def test_do_not_consume_remaining_uses_when_get_token_fails(self): ref = unit.new_trust_ref( trustor_user_id=self.user_id, trustee_user_id=self.trustee_user_id, project_id=self.project_id, impersonation=False, expires=dict(minutes=1), role_ids=[self.role_id], remaining_uses=3) r = self.post('/OS-TRUST/trusts', body={'trust': ref}) new_trust = r.result.get('trust') trust_id = new_trust.get('id') # Pass in another user's ID as the trustee, the result being a failed # token authenticate and the remaining_uses of the trust should not be # decremented. auth_data = self.build_authentication_request( user_id=self.default_domain_user['id'], password=self.default_domain_user['password'], trust_id=trust_id) self.v3_create_token(auth_data, expected_status=http_client.FORBIDDEN) r = self.get('/OS-TRUST/trusts/%s' % trust_id) self.assertEqual(3, r.result.get('trust').get('remaining_uses')) ",471,473
openstack%2Ftacker-horizon~master~I337846738d53488093d324ebfe1c8b21ce3681f6,openstack/tacker-horizon,master,I337846738d53488093d324ebfe1c8b21ce3681f6,Fix pep8 error and enable flake8 options,MERGED,2016-02-13 12:29:34.000000000,2016-02-15 23:19:53.000000000,2016-02-15 23:19:53.000000000,"[{'_account_id': 3}, {'_account_id': 13380}, {'_account_id': 16511}]","[{'number': 1, 'created': '2016-02-13 12:29:34.000000000', 'files': ['tacker_horizon/openstack_dashboard/dashboards/nfv/vnfmanager/forms.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/bf614900cd18e4e39b2509aa31ac0fca309241fe', 'message': 'Fix pep8 error and enable flake8 options\n\nThis Patch fixes flake8 error and enables this test\nfor all new patches to tacker-horizon.\n\nH701 Empty localization string\n\nsee\nhttps://github.com/openstack-dev/hacking/blob/master/\nhacking/checks/localization.py#L109\n\nsee OpenStack Style Guidelines\nhttp://docs.openstack.org/developer/hacking/\n\nThis Patch enables two flake8 options:\nshow-source\nmax-complexity\n\nshow-source adds output with source code for each error\n\nsee for max-complexity\nhttps://flake8.readthedocs.org/en/latest/\n\nChange-Id: I337846738d53488093d324ebfe1c8b21ce3681f6\nCloses-Bug: #1531680\n'}]",0,279882,bf614900cd18e4e39b2509aa31ac0fca309241fe,7,3,1,15755,,,0,"Fix pep8 error and enable flake8 options

This Patch fixes flake8 error and enables this test
for all new patches to tacker-horizon.

H701 Empty localization string

see
https://github.com/openstack-dev/hacking/blob/master/
hacking/checks/localization.py#L109

see OpenStack Style Guidelines
http://docs.openstack.org/developer/hacking/

This Patch enables two flake8 options:
show-source
max-complexity

show-source adds output with source code for each error

see for max-complexity
https://flake8.readthedocs.org/en/latest/

Change-Id: I337846738d53488093d324ebfe1c8b21ce3681f6
Closes-Bug: #1531680
",git fetch https://review.opendev.org/openstack/tacker-horizon refs/changes/82/279882/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker_horizon/openstack_dashboard/dashboards/nfv/vnfmanager/forms.py', 'tox.ini']",2,bf614900cd18e4e39b2509aa31ac0fca309241fe,bug/1531680,show-source = True max-complexity = 20,# H701 Empty localization string ignore = H701,4,3
openstack%2Fpuppet-neutron~master~If2fac987162ae1e980e93288525d35906437b403,openstack/puppet-neutron,master,If2fac987162ae1e980e93288525d35906437b403,Add desc fields for neutron_router_interface,MERGED,2016-02-15 20:21:41.000000000,2016-02-15 23:16:57.000000000,2016-02-15 23:05:05.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 8482}, {'_account_id': 9500}]","[{'number': 1, 'created': '2016-02-15 20:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/8ab762290d4f76ee5d26fce0e2f0b9e3ed9af06e', 'message': 'Add desc fields for neutron_router_interface\n\nI found this confusing and wasted some time with it, so hopefully this\nclears up the field meanings a bit for everyone else.\n\nChange-Id: If2fac987162ae1e980e93288525d35906437b403\n'}, {'number': 2, 'created': '2016-02-15 21:21:32.000000000', 'files': ['lib/puppet/type/neutron_router_interface.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/ec0877fca48c5651a3b2320ff239feebaba0262f', 'message': 'Add desc fields for neutron_router_interface\n\nI found this confusing and wasted some time with it, so hopefully this\nclears up the field meanings a bit for everyone else.\n\nChange-Id: If2fac987162ae1e980e93288525d35906437b403\n'}]",2,280386,ec0877fca48c5651a3b2320ff239feebaba0262f,13,4,2,9500,,,0,"Add desc fields for neutron_router_interface

I found this confusing and wasted some time with it, so hopefully this
clears up the field meanings a bit for everyone else.

Change-Id: If2fac987162ae1e980e93288525d35906437b403
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/86/280386/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/type/neutron_router_interface.rb'],1,8ab762290d4f76ee5d26fce0e2f0b9e3ed9af06e,," desc <<-EOT The name is used to derive the namees of the subnet and router, using the format RouterName:SubnetName, for example to attach Subnet1 to Router1 you should name this resource Router1:Subnet1 EOT desc 'interface id. Read Only.' desc 'router to which to attach this interface. Read Only. set with the name' desc 'subnet to which to attach this interface. Read Only. set with the name' desc 'An existing neutron port to which a router interface should be assigned'", desc 'An existing neutron port to which a rounter interface should be assigned',9,1
openstack%2Fnova~master~I9e8bd5f2ed064923ed04feb864b42e4b2948812d,openstack/nova,master,I9e8bd5f2ed064923ed04feb864b42e4b2948812d,Allocate UUID for compute node,MERGED,2016-02-08 20:32:35.000000000,2016-02-15 23:10:36.000000000,2016-02-15 20:46:11.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6508}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 11803}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-08 20:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d78cf4ffa0f727c93b30b22ea5c716046f65952', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nsave. Since we don't currently have them, save needs to handle this\ncase to migrate us to the point where we can add a uniqueness and\nnon-null-ness constraint on that column in the database.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 2, 'created': '2016-02-08 22:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6aa4990237ec2a73e874fc9704f5f824590ad668', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nsave. Since we don't currently have them, save needs to handle this\ncase to migrate us to the point where we can add a uniqueness and\nnon-null-ness constraint on that column in the database.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 3, 'created': '2016-02-09 15:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/33ebe7eede162a0e2ccdc0655112ca548847f4f9', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nsave. Since we don't currently have them, save needs to handle this\ncase to migrate us to the point where we can add a uniqueness and\nnon-null-ness constraint on that column in the database.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 4, 'created': '2016-02-09 16:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/60c661aa773ab713a92374e95206b1f5ea387dd4', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nsave. Since we don't currently have them, save needs to handle this\ncase to migrate us to the point where we can add a uniqueness and\nnon-null-ness constraint on that column in the database.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 5, 'created': '2016-02-09 18:17:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8e719942ec822c6c8353222ca28ec12d1f38eacc', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 6, 'created': '2016-02-09 18:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a10ba121177ca96c8c8026fc7d0c2223f63170b', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 7, 'created': '2016-02-10 11:33:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d6db5bf212936d6abc2dbd153ec5dd46b4ca1ade', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 8, 'created': '2016-02-10 22:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/219d69a92eb2f21573663cc2f41f2ec75f2430b3', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 9, 'created': '2016-02-11 23:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/159cce1040e028488baa820059b6209852c38d12', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}, {'number': 10, 'created': '2016-02-15 15:50:05.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/tests/unit/objects/test_compute_node.py', 'nova/objects/compute_node.py', 'nova/tests/unit/compute/test_resource_tracker.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/compute/test_multiple_nodes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4c05740b858a532467d6e01d5f80f0a39d0b43b8', 'message': ""Allocate UUID for compute node\n\nThis patch causes us to allocate a UUID for ComputeNode on create or\nwhen loaded from the database. Since we don't currently have them,\nquery needs to handle this case to migrate us to the point where we\ncan add a uniqueness and non-null-ness constraint on that column in\nthe database. We take a small hit every time we query a compute node\nthat doesn't have a uuid, by generating it and saving it back to the\ndatabase immediately, but this only happens once.\n\nRelated to blueprint compute-node-inventory\n\nChange-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d\n""}]",19,277554,4c05740b858a532467d6e01d5f80f0a39d0b43b8,126,21,10,4393,,,0,"Allocate UUID for compute node

This patch causes us to allocate a UUID for ComputeNode on create or
when loaded from the database. Since we don't currently have them,
query needs to handle this case to migrate us to the point where we
can add a uniqueness and non-null-ness constraint on that column in
the database. We take a small hit every time we query a compute node
that doesn't have a uuid, by generating it and saving it back to the
database immediately, but this only happens once.

Related to blueprint compute-node-inventory

Change-Id: I9e8bd5f2ed064923ed04feb864b42e4b2948812d
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/277554/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_objects.py', 'nova/objects/compute_node.py', 'nova/tests/unit/objects/test_compute_node.py', 'nova/tests/unit/db/test_db_api.py']",4,3d78cf4ffa0f727c93b30b22ea5c716046f65952,bp/resource-providers,"from nova.tests import uuidsentinel uuid=uuidsentinel.fake_compute_node,",,48,3
openstack%2Fmagnum~master~I12a5b2ff3e71be39aa84093fce8b1c2b1be9d473,openstack/magnum,master,I12a5b2ff3e71be39aa84093fce8b1c2b1be9d473,Turn selinux back on after cloud-init,MERGED,2016-02-09 15:22:21.000000000,2016-02-15 23:07:38.000000000,2016-02-15 23:07:38.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 10263}, {'_account_id': 12053}, {'_account_id': 12400}]","[{'number': 1, 'created': '2016-02-09 15:22:21.000000000', 'files': ['magnum/templates/swarm/fragments/disable-selinux.sh', 'magnum/templates/kubernetes/fragments/enable-services-minion.sh', 'magnum/templates/kubernetes/fragments/disable-selinux.sh', 'magnum/templates/kubernetes/fragments/enable-services-master.sh', 'magnum/templates/swarm/fragments/enable-services.sh'], 'web_link': 'https://opendev.org/openstack/magnum/commit/cf85c5ac03637a4e290ccc1eab404efb49e59a88', 'message': 'Turn selinux back on after cloud-init\n\nAfter cloud-init has run configuration steps, turn on selinux again\nfor security reasons.\n\nChange-Id: I12a5b2ff3e71be39aa84093fce8b1c2b1be9d473\nCloses-Bug: 1543308\n'}]",6,277883,cf85c5ac03637a4e290ccc1eab404efb49e59a88,17,5,1,18498,,,0,"Turn selinux back on after cloud-init

After cloud-init has run configuration steps, turn on selinux again
for security reasons.

Change-Id: I12a5b2ff3e71be39aa84093fce8b1c2b1be9d473
Closes-Bug: 1543308
",git fetch https://review.opendev.org/openstack/magnum refs/changes/83/277883/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/swarm/fragments/disable-selinux.sh', 'magnum/templates/kubernetes/fragments/enable-services-minion.sh', 'magnum/templates/kubernetes/fragments/disable-selinux.sh', 'magnum/templates/kubernetes/fragments/enable-services-master.sh', 'magnum/templates/swarm/fragments/enable-services.sh']",5,cf85c5ac03637a4e290ccc1eab404efb49e59a88,bug/1543308, setenforce 1,,6,8
openstack%2Fapi-site~master~Ic371f5e87eecd5c059633668285d1f75984e99ff,openstack/api-site,master,Ic371f5e87eecd5c059633668285d1f75984e99ff,Add firewall-policy insert_rule/remove_rule,MERGED,2016-02-13 23:02:55.000000000,2016-02-15 22:51:12.000000000,2016-02-15 22:51:12.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-13 23:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/7c144119625e7d0a9370557c2adbd8e61ac74a4d', 'message': 'Add firewall-policy insert_rule/remove_rule\n\nThis commit adds following firewall-policy API documents:\n\n  * v2.0/fw/firewall_policies/{firewall_policy_id}/insert_rule\n  * v2.0/fw/firewall_policies/{firewall_policy_id}/remove_rule\n\nChange-Id: Ic371f5e87eecd5c059633668285d1f75984e99ff\nCloses-bug:1544870\n'}, {'number': 2, 'created': '2016-02-15 08:25:52.000000000', 'files': ['api-ref/src/wadls/networking-api/src/wadl/firewalls.wadl', 'api-ref/src/wadls/networking-api/src/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/803e5a0ba470294b262e3995537097e05cd3d129', 'message': 'Add firewall-policy insert_rule/remove_rule\n\nThis commit adds following firewall-policy API documents:\n\n  * v2.0/fw/firewall_policies/{firewall_policy_id}/insert_rule\n  * v2.0/fw/firewall_policies/{firewall_policy_id}/remove_rule\n\nChange-Id: Ic371f5e87eecd5c059633668285d1f75984e99ff\nCloses-Bug: #1544870\n'}]",0,279899,803e5a0ba470294b262e3995537097e05cd3d129,9,3,2,13702,,,0,"Add firewall-policy insert_rule/remove_rule

This commit adds following firewall-policy API documents:

  * v2.0/fw/firewall_policies/{firewall_policy_id}/insert_rule
  * v2.0/fw/firewall_policies/{firewall_policy_id}/remove_rule

Change-Id: Ic371f5e87eecd5c059633668285d1f75984e99ff
Closes-Bug: #1544870
",git fetch https://review.opendev.org/openstack/api-site refs/changes/99/279899/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/networking-api/src/wadl/firewalls.wadl', 'api-ref/src/wadls/networking-api/src/common.ent']",2,7c144119625e7d0a9370557c2adbd8e61ac74a4d,bug/1544870,"<!ENTITY firewallPolicyInsertBeforeParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""false"" name=""insert_before"" style=""plain"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the firewall_rule. A new firewall_rule will be inserted before this firewall_rule. </para> </wadl:doc> </param>'> <!ENTITY firewallPolicyInsertAfterParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""false"" name=""insert_after"" style=""plain"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the firewall_rule. A new firewall_rule will be inserted after this firewall_rule. </para> </wadl:doc> </param>'><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> Indicates whether the policy has been audited. </para> <para> Each time that the firewall policy or its associated rules are changed, the API sets this attribute to <code>False</code>. To audit the policy, the policy owner must explicitly update the policy to set this attribute to <code>True</code>. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The human-readable description for the firewall policy. </para> </wadl:doc> </param>'> <!ENTITY firewall_policy-firewall_listResponseParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" name=""firewall_list"" style=""plain"" type=""xsd:list""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> A list of the UUIDs for firewall associated with the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" name=""firewall_rules"" style=""plain"" type=""xsd:list""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> A list of the UUIDs for firewall rule associated with the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID for the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> Human-readable name for the firewall policy. Does not have to be unique. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <para> Indicates whether the firewall policy is shared across all tenants.<param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the tenant who owns the firewall policy. </para> </wadl:doc><!ENTITY firewallRuleIdParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" name=""firewall_rule_id"" style=""plain"" type=""csapi:UUID""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID of the firewall rule. </para> </wadl:doc> </param>'>","<param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> Indicates whether the policy has been audited. </para> <para> Each time that the firewall policy or its associated rules are changed, the API sets this attribute to <code>False</code>. To audit the policy, the policy owner must explicitly update the policy to set this attribute to <code>True</code>. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The human-readable description for the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" name=""firewall_policy_id"" style=""plain"" type=""xsd:list""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> A list of rules that are associated with the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The UUID for the firewall policy. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> Human-readable name for the firewall policy. Does not have to be unique. </para> </wadl:doc><param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <para> Indicates whether the firewall policy is shared across all tenants.<param xmlns=""http://wadl.dev.java.net/2009/02"" required=""true"" <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The owner of the firewall policy. </para> </wadl:doc>",183,64
openstack%2Ftripleo-heat-templates~master~I67a7533469947355629b6cb54b79759e21e0ec55,openstack/tripleo-heat-templates,master,I67a7533469947355629b6cb54b79759e21e0ec55,Update Dell Storage Center api port setting,MERGED,2016-02-09 15:31:23.000000000,2016-02-15 22:47:19.000000000,2016-02-15 22:47:19.000000000,"[{'_account_id': 3}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7160}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10379}]","[{'number': 1, 'created': '2016-02-09 15:31:23.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9cfa91491dff6a5ce9630ee7402c051307765074', 'message': 'Update Dell Storage Center api port setting\n\nUpdated the setting for the dell storage center\napi port to the right variable name ::dell_sc_api_port\n\nChange-Id: I67a7533469947355629b6cb54b79759e21e0ec55\n'}]",0,277888,9cfa91491dff6a5ce9630ee7402c051307765074,18,7,1,10379,,,0,"Update Dell Storage Center api port setting

Updated the setting for the dell storage center
api port to the right variable name ::dell_sc_api_port

Change-Id: I67a7533469947355629b6cb54b79759e21e0ec55
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/88/277888/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",2,9cfa91491dff6a5ce9630ee7402c051307765074,dellsc_port," dell_sc_api_port => hiera('cinder::backend::dellsc_iscsi::dell_sc_api_port', undef),"," dell_sc_port => hiera('cinder::backend::dellsc_iscsi::dell_sc_port', undef),",2,2
openstack%2Fapi-site~master~I37bfbbfe50ed08585a2e3bb7e69d918af5403814,openstack/api-site,master,I37bfbbfe50ed08585a2e3bb7e69d918af5403814,Add 'routers' into response param for v2.0/routers,MERGED,2016-02-13 23:01:19.000000000,2016-02-15 22:47:01.000000000,2016-02-15 22:47:01.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 2448}, {'_account_id': 10497}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-02-13 23:01:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/0721dc9b1056613b2a9d87b192b0177a5ae9e20b', 'message': ""Add 'routers' into response param for v2.0/routers\n\nThis commit adds 'routers' into response parameter for GET v2.0/routers.\n\nChange-Id: I37bfbbfe50ed08585a2e3bb7e69d918af5403814\nCloses-bug:1544872\n""}, {'number': 2, 'created': '2016-02-15 08:26:24.000000000', 'files': ['api-ref/src/wadls/networking-api/src/wadl/layer3.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/8f56555f1f04bff44887f286c07e55c4d5cff38c', 'message': ""Add 'routers' into response param for v2.0/routers\n\nThis commit adds 'routers' into response parameter for GET v2.0/routers.\n\nChange-Id: I37bfbbfe50ed08585a2e3bb7e69d918af5403814\nCloses-Bug: #1544872\n""}]",0,279898,8f56555f1f04bff44887f286c07e55c4d5cff38c,10,5,2,13702,,,0,"Add 'routers' into response param for v2.0/routers

This commit adds 'routers' into response parameter for GET v2.0/routers.

Change-Id: I37bfbbfe50ed08585a2e3bb7e69d918af5403814
Closes-Bug: #1544872
",git fetch https://review.opendev.org/openstack/api-site refs/changes/98/279898/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/networking-api/src/wadl/layer3.wadl'],1,0721dc9b1056613b2a9d87b192b0177a5ae9e20b,bug/1544872, &routersObject;,,1,0
openstack%2Fapi-site~master~Iae2c006ccb27656ac83a1e8b0154cf8fcc32b2c0,openstack/api-site,master,Iae2c006ccb27656ac83a1e8b0154cf8fcc32b2c0,Replace from 'id' to 'xxxx_id' for Compute API,MERGED,2016-02-13 16:09:40.000000000,2016-02-15 22:41:49.000000000,2016-02-15 22:41:49.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 13702}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-02-13 16:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/d8dba5461e13e5cb1fc7c99315673874c8fb555e', 'message': ""Replace from 'id' to 'xxxx_id' for Compute API\n\nThis commit modifies following 'id':\n\n  * os-agents-v2.1: 'agent_build_id'\n  * os-fping-v2.1: 'instance_id'\n\nChange-Id: Iae2c006ccb27656ac83a1e8b0154cf8fcc32b2c0\nCloses-bug:1545225\n""}, {'number': 2, 'created': '2016-02-14 08:34:58.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-agents-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-fping-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/047f666fd9e59c4a5c3a06bfb030b6a613a3817d', 'message': ""Replace from 'id' to 'xxxx_id' for Compute API\n\nThis commit modifies following 'id':\n\n  * os-agents-v2.1: 'agent_build_id'\n  * os-fping-v2.1: 'instance_id'\n\nCloses-Bug: #1545225\nChange-Id: Iae2c006ccb27656ac83a1e8b0154cf8fcc32b2c0\n""}]",0,279886,047f666fd9e59c4a5c3a06bfb030b6a613a3817d,15,7,2,13702,,,0,"Replace from 'id' to 'xxxx_id' for Compute API

This commit modifies following 'id':

  * os-agents-v2.1: 'agent_build_id'
  * os-fping-v2.1: 'instance_id'

Closes-Bug: #1545225
Change-Id: Iae2c006ccb27656ac83a1e8b0154cf8fcc32b2c0
",git fetch https://review.opendev.org/openstack/api-site refs/changes/86/279886/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-agents-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/common.ent', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/os-fping-v2.1.wadl']",3,d8dba5461e13e5cb1fc7c99315673874c8fb555e,bug/1545225," <resource path=""{instance_id}"" id=""instance_id"">"," <resource path=""{id}"" id=""id"">",11,12
openstack%2Fnetworking-ovn~master~I2423fb56f4c04dfcc02c9103d025cafef7925f02,openstack/networking-ovn,master,I2423fb56f4c04dfcc02c9103d025cafef7925f02,Enabling qos support through Logical_Port.options,MERGED,2016-01-11 12:29:39.000000000,2016-02-15 22:36:05.000000000,2016-02-15 22:36:05.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 8298}, {'_account_id': 8788}, {'_account_id': 10237}, {'_account_id': 11604}, {'_account_id': 18051}]","[{'number': 1, 'created': '2016-01-11 12:29:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/91b809042d538cd99fa9d0f0324706c428058a84', 'message': 'Note: ** WIP **\nEnabling qos support through Logical_Port.options\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 2, 'created': '2016-01-13 11:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/504c70a6f9c631eda32cbb51aaad0c577db7e219', 'message': 'Note: ** WIP **\nEnabling qos support through Logical_Port.options\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 3, 'created': '2016-01-18 11:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/a96f49995d90526b90f0a841ccb6707a3e8999df', 'message': 'Note: ** WIP **\nEnabling qos support through Logical_Port.options\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 4, 'created': '2016-01-19 11:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/0344214bbb70780abdd1232222334a1ed5c6ba27', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 5, 'created': '2016-01-20 06:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/d0349259f1e302adeeb462c6d879d633e1234eb5', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 6, 'created': '2016-02-11 08:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c4ffa7b0db5241e2b4a3e470fddbec64dbc7ac5b', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 7, 'created': '2016-02-12 07:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9688e79ea60e9c8d3096d0dc710602d089c5d5d9', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 8, 'created': '2016-02-12 13:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f9df1e723e9bbad7a1181de89632eecacf51fe4f', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 9, 'created': '2016-02-12 20:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/b3de9f2b5687ee9eeaee5a8e9790bad6f3a65437', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nCloses-bug: #1457588\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 10, 'created': '2016-02-15 05:00:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f457405eb79d3835bdc6d406ea1a4456a9647f24', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nCloses-bug: #1457588\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}, {'number': 11, 'created': '2016-02-15 15:03:53.000000000', 'files': ['doc/source/install.rst', 'networking_ovn/tests/unit/test_ovn_plugin.py', 'devstack/plugin.sh', 'networking_ovn/plugin.py', 'doc/source/features.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f220cb04e049629c0aa0b66f5b8d5fb042b9d161', 'message': 'Enabling qos support through Logical_Port.options\n\nOne has to enable qos service_plugins to work with this feature\n\nCloses-bug: #1457588\nChange-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02\n'}]",7,265798,f220cb04e049629c0aa0b66f5b8d5fb042b9d161,48,8,11,8298,,,0,"Enabling qos support through Logical_Port.options

One has to enable qos service_plugins to work with this feature

Closes-bug: #1457588
Change-Id: I2423fb56f4c04dfcc02c9103d025cafef7925f02
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/98/265798/5 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/plugin.py'],1,91b809042d538cd99fa9d0f0324706c428058a84,265798,"from sqlalchemy.orm import exc from neutron.common import exceptions as n_exc from neutron.extensions import extra_dhcp_opt as edo_ext from neutron.extensions import portbindings from neutron.extensions import providernet as pnetfrom neutron.db import models_v2 from neutron.db.qos import models as qos_models if 'qos_policy_id' in net and net['qos_policy_id']: context.session.add( qos_models.QosNetworkPolicyBinding( policy_id=net['qos_policy_id'], network_id=result['id'])) def _qos_get_ovn_options(self, context, policy_id): try: bw_rule = self._model_query( context, qos_models.QosBandwidthLimitRule).filter( qos_models.QosBandwidthLimitRule.qos_policy_id == policy_id).one() to_ovn = lambda value: str(value if value is not None else 0) return {""policing_rate"": to_ovn(bw_rule.max_kbps), ""policing_burst"": to_ovn(bw_rule.max_burst_kbps)} except exc.NoResultFound: return {} def _qos_get_network_rule(self, context, network_id, qos_policy_id, force=False): bw_rule = {} if qos_policy_id: try: policy_binding = self._model_query( context, qos_models.QosNetworkPolicyBinding).filter( qos_models.QosNetworkPolicyBinding.network_id == network_id).one() if policy_binding.policy_id == qos_policy_id and not force: # This policy is already bound for this network. # Nothing to be done return # update the ORM to have the new id policy_binding.policy_id = qos_policy_id except exc.NoResultFound: context.session.add( qos_models.QosNetworkPolicyBinding( policy_id=qos_policy_id, network_id=network_id)) rule = self._qos_get_ovn_options(context, qos_policy_id) else: self._model_query( context, qos_models.QosNetworkPolicyBinding).filter( qos_models.QosNetworkPolicyBinding.network_id == network_id).delete() rule = {} return rule def _qos_get_network_ports(self, context, network_id): port_ids = self._model_query( context, models_v2.Port.id).filter( models_v2.Port.network_id == network_id, models_v2.Port.device_owner.like( const.DEVICE_OWNER_COMPUTE_PREFIX + ""%"")) policy_bound_ports = set([]) for item in self._model_query( context, qos_models.QosPortPolicyBinding.port_id): policy_bound_ports.add(item.port_id) return [item.id for item in port_ids if item.id not in policy_bound_ports] qos_rule_options = None port_ids = [] with context.session.begin(subtransactions=True): net_dict = network['network'] if 'qos_policy_id' in net_dict: qos_rule_options = \ self._qos_get_network_rule( context, network_id, net_dict['qos_policy_id']) port_ids = self._qos_get_network_ports(context, network_id) updated_port = super(OVNPlugin, self).update_network( context, network_id, network) if qos_rule_options is not None: with self._ovn.transaction(check_error=True) as txn: for port_id in port_ids: txn.add(self._ovn.set_lport( lport_name=port_id, options=qos_rule_options)) return updated_port pdict = port['port'] context, pdict) pdict, pdict, qos_options = None qos_policy_id = None if updated_port['device_owner'].startswith( const.DEVICE_OWNER_COMPUTE_PREFIX) or updated_port['device_owner'] == '': try: port_policy = self._model_query( context, qos_models.QosPortPolicyBinding).filter( qos_models.QosPortPolicyBinding.port_id == id).one() if 'qos_policy_id' in pdict: if pdict['qos_policy_id']: if port_policy.policy_id != \ pdict['qos_policy_id']: # update the binding entry port_policy.policy_id = pdict['qos_policy_id'] qos_policy_id = pdict['qos_policy_id'] else: # Port is no more bound to qos-policy, delete! context.session.delete(port_policy) qos_options = {} # check if there is a network policy for this port raise exc.NoResultFound() else: qos_policy_id = port_policy.policy_id except exc.NoResultFound: if pdict.get(""qos_policy_id"", None): context.session.add( qos_models.QosPortPolicyBinding( policy_id=pdict['qos_policy_id'], port_id=id)) qos_policy_id = pdict['qos_policy_id'] else: # check if the logical network has any policy try: nw_policy = self._model_query( context, qos_models.QosNetworkPolicyBinding).filter( qos_models.QosNetworkPolicyBinding.network_id == \ updated_port['network_id']).one() qos_policy_id = nw_policy.policy_id except exc.NoResultFound: pass else: if pdict.get(""qos_policy_id""): msg = ""Not a compute port"" raise n_exc.InvalidInput(error_msg=msg) if qos_policy_id: if updated_port['device_owner'].startswith( const.DEVICE_OWNER_COMPUTE_PREFIX): qos_options = self._qos_get_ovn_options(context, qos_policy_id) elif pdict['device_owner'] == '': # This port is detached from a VM qos_options = {} qos_options, pdict = port['port'] context, pdict) dhcp_opts = pdict.get(edo_ext.EXTRADHCPOPTS, []) pdict, if (ovn_const.OVN_PORT_BINDING_PROFILE in pdict and pdict[ovn_const.OVN_PORT_BINDING_PROFILE])): pdict[ovn_const.OVN_PORT_BINDING_PROFILE] qos_policy_id = None if pdict['device_owner'].startswith( const.DEVICE_OWNER_COMPUTE_PREFIX) or pdict['device_owner'] == '': if (""qos_policy_id"" in pdict and pdict[""qos_policy_id""]): qos_policy_id = pdict['qos_policy_id'] # Add a PortPolicy binding context.session.add(qos_models.QosPortPolicyBinding( policy_id=qos_policy_id, port_id=pdict['id'])) else: # check if there is a rule set for network try: nw_policy = self._model_query( context, qos_models.QosNetworkPolicyBinding).filter( qos_models.QosNetworkPolicyBinding.network_id == \ pdict['network_id']).one() qos_policy_id = nw_policy.policy_id except exc.NoResultFound: pass qos_options = None if qos_policy_id: if pdict['device_owner'] == '': qos_options = {} else: qos_options = self._qos_get_ovn_options( context, qos_policy_id) ovn_port_info = self._get_ovn_port_options( binding_profile, qos_options, db_port) def _get_ovn_port_options(self, binding_profile, qos_options, port): options = qos_options"," with context.session.begin(subtransactions=True): return super(OVNPlugin, self).update_network(context, network_id, network) context, port['port']) port['port'], port['port'], context, port['port']) dhcp_opts = port['port'].get(edo_ext.EXTRADHCPOPTS, []) port['port'], if (ovn_const.OVN_PORT_BINDING_PROFILE in port['port'] and port['port'][ovn_const.OVN_PORT_BINDING_PROFILE])): port['port'][ovn_const.OVN_PORT_BINDING_PROFILE] ovn_port_info = self._get_ovn_port_options(binding_profile, db_port) def _get_ovn_port_options(self, binding_profile, port):",192,14
openstack%2Fsecurity-doc~master~Ib5b063e14d0405984dd99e7d53d905b185830f65,openstack/security-doc,master,Ib5b063e14d0405984dd99e7d53d905b185830f65,Edited document for grammar and commas,MERGED,2016-02-14 17:59:32.000000000,2016-02-15 22:34:36.000000000,2016-02-15 22:34:36.000000000,"[{'_account_id': 3}, {'_account_id': 7244}, {'_account_id': 10497}, {'_account_id': 10670}, {'_account_id': 12325}, {'_account_id': 20376}]","[{'number': 1, 'created': '2016-02-14 17:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/2eb0e517b8d5890416d6fe4665b2533af041109a', 'message': 'Edited document for grammar and commas\n\nAdded/ommited commas as needed\n\nChange-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65\n'}, {'number': 2, 'created': '2016-02-14 18:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/9834a732882245dbb2784140ada60e318ea8563b', 'message': 'Edited document for grammar and commas\n\nAdded/ommited commas as needed\n\nChange-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65\n'}, {'number': 3, 'created': '2016-02-15 13:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/46cfa4e768d4764f694e54b67590c5f36405bceb', 'message': 'Edited document for grammar and commas\n\nAdded/ommited commas as needed\n\nChange-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65\n'}, {'number': 4, 'created': '2016-02-15 14:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/e40122f42720f60da18ed9fdb68ab0c0ce77a421', 'message': 'Edited document for grammar and commas\n\nAdded/ommited commas as needed\n\nChange-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65\n'}, {'number': 5, 'created': '2016-02-15 17:48:23.000000000', 'files': ['security-guide/source/introduction/security-boundaries-and-threats.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/3a73bbe51161c372ef36554200211b65c74257c5', 'message': 'Edited document for grammar and commas\n\nAdded/ommited commas as needed\n\nChange-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65\n'}]",10,280009,3a73bbe51161c372ef36554200211b65c74257c5,24,6,5,20376,,,0,"Edited document for grammar and commas

Added/ommited commas as needed

Change-Id: Ib5b063e14d0405984dd99e7d53d905b185830f65
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/09/280009/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/introduction/security-boundaries-and-threats.rst'],1,2eb0e517b8d5890416d6fe4665b2533af041109a,securitydoc_cherrypick3,"network as internal and *trusted* only if the proper controls are implemented to assert that the instances and all associated tenants are to be trusted.depending on the type of deployment, there may also be strong availabilitydomains. As such the compute node should be configured to meet the securitydifficult. Because core services will usually bridge at least two domains, special consideration must be given when applying security controls to them.threat actors we describe here. Those deploying an OpenStack cloud will have to decide where the balance lies for their deployment/usage. Network, a massive cyber-criminal enterprise, has demonstrated how cyberaccessing the cloud and will likely take part in regularly scheduled securitythis diagram.protected facilities and supply chains. In contrast, those standing up basic","network as internal and *trusted*, only if the proper controls are implemented to assert that the instances and all associated tenants are to be trusted.depending on the type of deployment there may also be strong availabilitydomains, as such the compute node should be configured to meet the securitydifficult - as core services will usually bridge at least two domains, special consideration must be given when applying security controls to them.threat actors we describe here. Those deploying an OpenStack cloud will have to decide where the balance lies for their deployment / usage. Network, a massive cyber-criminal enterprise has demonstrated how cyberaccessing the cloud and will likely take part in regular scheduled securitythis diagram but in general, this describes the sorts of attack that could be typical for each actor.protected facilities and supply chains. In contrast those standing up basic",13,13
openstack%2Fceilometer~master~Ie2250ae28e0ffaf97c92205d5e2f2da38c9afef1,openstack/ceilometer,master,Ie2250ae28e0ffaf97c92205d5e2f2da38c9afef1,Remove unused variable,MERGED,2016-02-12 15:08:36.000000000,2016-02-15 22:23:03.000000000,2016-02-15 22:23:03.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6924}, {'_account_id': 15843}]","[{'number': 1, 'created': '2016-02-12 15:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/144db92aa88077df506b9abf915ebe83363bba4b', 'message': 'Not used variable.\n\nI removed the unused variables in:\n- ceilometer/event/storage/impl_elasticsearch.py\n- ceilometer/event/storage/impl_hbase.py\n- ceilometer/storage/hbase/utils.py\n- ceilometer/storage/impl_hbase.py\n\nChange-Id: Ie2250ae28e0ffaf97c92205d5e2f2da38c9afef1\n'}, {'number': 2, 'created': '2016-02-15 08:26:27.000000000', 'files': ['ceilometer/storage/impl_hbase.py', 'ceilometer/storage/hbase/utils.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/35773a35937a9812764cdfd91e8fe0980be21927', 'message': 'Remove unused variable\n\nI removed the unused variables in code\n\nChange-Id: Ie2250ae28e0ffaf97c92205d5e2f2da38c9afef1\n'}]",3,279584,35773a35937a9812764cdfd91e8fe0980be21927,12,4,2,18603,,,0,"Remove unused variable

I removed the unused variables in code

Change-Id: Ie2250ae28e0ffaf97c92205d5e2f2da38c9afef1
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/84/279584/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/storage/impl_hbase.py', 'ceilometer/event/storage/impl_elasticsearch.py', 'ceilometer/storage/hbase/utils.py', 'ceilometer/event/storage/impl_hbase.py']",4,144db92aa88077df506b9abf915ebe83363bba4b,(detached," mess = event_id.split(':')[1] for data in gen: events_dict = hbase_utils.deserialize_entry(data[1])[0] for key in events_dict.items(): if not isinstance(key[0], tuple) and key[0].startswith('event_type'): for data in gen: events_dict = hbase_utils.deserialize_entry(data[1])[0] for key in events_dict.items(): if isinstance(key[0], tuple): trait_name, trait_type = key[0] for data in gen: events_dict = hbase_utils.deserialize_entry(data[1])[0]"," ts, mess = event_id.split(':') for event_id, data in gen: events_dict = hbase_utils.deserialize_entry(data)[0] for key, value in events_dict.items(): if not isinstance(key, tuple) and key.startswith('event_type'): for event_id, data in gen: events_dict = hbase_utils.deserialize_entry(data)[0] for key, value in events_dict.items(): if isinstance(key, tuple): trait_name, trait_type = key for event_id, data in gen: events_dict = hbase_utils.deserialize_entry(data)[0]",25,25
openstack%2Fpuppet-rally~master~Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2,openstack/puppet-rally,master,Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2,Add config file settings and tests for benchmarking,MERGED,2016-01-22 04:57:28.000000000,2016-02-15 22:18:39.000000000,2016-02-15 22:18:38.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 18418}]","[{'number': 1, 'created': '2016-01-22 04:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/1d835ce9eeb13aef19ee25f5fc1c5422dee97220', 'message': 'Add settings for rally benchmarking\n\nAs not to clutter up the init.pp, the benchmarking settings have\nbeen added to this new benchmark.pp manifest.\n\nThis will require a\n  include ::rally::benchmark\nline in the init.pp in a future commit.\n\nChange-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2\n'}, {'number': 2, 'created': '2016-02-11 02:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/fcf2f043f03237277907df7ee0c4f57e1a7c51c3', 'message': 'Add config file settings and tests for benchmarking\n\nDue to the large number of config options, the settings have been\nsplit up into their respective services\n\nThis will require a\n  include ::rally::settings\nline in the init.pp in a future commit.\n\nChange-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2\n'}, {'number': 3, 'created': '2016-02-13 03:25:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/e4d2f7337d8fb40546a193440254319e0cfd1510', 'message': 'Add config file settings and tests for benchmarking\n\nDue to the large number of config options, the settings have been\nsplit up into their respective services\n\nThis will require a\n  include ::rally::settings\nline in the init.pp in a future commit.\n\nChange-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2\n'}, {'number': 4, 'created': '2016-02-13 03:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/004e83eb9d5ec45b5415b86832592c6f50f6f091', 'message': 'Add config file settings and tests for benchmarking\n\nDue to the large number of config options, the settings have been\nsplit up into their respective services\n\nThis will require a\n  include ::rally::settings\nline in the init.pp in a future commit.\n\nChange-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2\n'}, {'number': 5, 'created': '2016-02-13 03:55:13.000000000', 'files': ['manifests/settings/ec2.pp', 'manifests/settings/glance.pp', 'manifests/settings/swift.pp', 'manifests/settings/cinder.pp', 'spec/classes/rally_settings_sahara_spec.rb', 'spec/classes/rally_settings_nova_spec.rb', 'manifests/settings/manila.pp', 'manifests/settings.pp', 'spec/classes/rally_settings_ec2_spec.rb', 'spec/classes/rally_settings_glance_spec.rb', 'spec/classes/rally_settings_ironic_spec.rb', 'manifests/settings/murano.pp', 'spec/classes/rally_settings_heat_spec.rb', 'spec/classes/rally_settings.rb', 'spec/classes/rally_settings_swift_spec.rb', 'manifests/settings/nova.pp', 'manifests/settings/sahara.pp', 'spec/classes/rally_settings_manila_spec.rb', 'manifests/settings/heat.pp', 'spec/classes/rally_settings_cinder_spec.rb', 'manifests/settings/ironic.pp', 'spec/classes/rally_settings_murano_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-rally/commit/f1309134747a20850ef3fc639fcf73fdd9fb3f8f', 'message': 'Add config file settings and tests for benchmarking\n\nDue to the large number of config options, the settings have been\nsplit up into their respective services\n\nThis will require a\n  include ::rally::settings\nline in the init.pp in a future commit.\n\nChange-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2\n'}]",13,271138,f1309134747a20850ef3fc639fcf73fdd9fb3f8f,19,4,5,18418,,,0,"Add config file settings and tests for benchmarking

Due to the large number of config options, the settings have been
split up into their respective services

This will require a
  include ::rally::settings
line in the init.pp in a future commit.

Change-Id: Ia59dadbcaa5c27aa371bd17cc20574f32021b7d2
",git fetch https://review.opendev.org/openstack/puppet-rally refs/changes/38/271138/5 && git format-patch -1 --stdout FETCH_HEAD,['manifests/benchmark.pp'],1,1d835ce9eeb13aef19ee25f5fc1c5422dee97220,,"# == Class: rally::benchmark # # Configure Rally benchmarking settings # # === Parameters # # [*cinder_volume_create_poll_interval*] # (Optional) Interval between checks when waiting for volume creation. # Defaults to $::os_service_default # # [*cinder_volume_create_prepoll_delay*] # (Optional) Time to sleep after creating a resource before polling for it # status # Defaults to $::os_service_default # # [*cinder_volume_create_timeout*] # (Optional) Time to wait for cinder volume to be created. # Defaults to $::os_service_default # # [*cinder_volume_delete_poll_interval*] # (Optional) Interval between checks when waiting for volume deletion. # Defaults to $::os_service_default # # [*cinder_volume_delete_timeout*] # (Optional) Time to wait for cinder volume to be deleted. # Defaults to $::os_service_default # # [*cirros_img_url*] # (Optional) CirrOS image URL # Defaults to $::os_service_default # # [*container_format*] # (Optional) Image container formate # Defaults to $::os_service_default # # [*disk_format*] # (Optional) Image disk format # Defaults to $::os_service_default # # [*ec2_server_boot_poll_interval*] # (Optional) Server boot poll interval # Defaults to $::os_service_default # # [*ec2_server_boot_prepoll_delay*] # (Optional) Time to sleep after boot before polling for status # Defaults to $::os_service_default # # [*ec2_server_boot_timeout*] # (Optional) Server boot timeout # Defaults to $::os_service_default # # [*glance_image_create_poll_interval*] # (Optional) Interval between checks when waiting for image creation. # Defaults to $::os_service_default # # [*glance_image_create_prepoll_delay*] # (Optional) Time to sleep after creating a resource before polling for it # status # Defaults to $::os_service_default # # [*glance_image_create_timeout*] # (Optional) Time to wait for glance image to be created. # Defaults to $::os_service_default # # [*glance_image_delete_poll_interval*] # (Optional) Interval between checks when waiting for image deletion. # Defaults to $::os_service_default # # [*glance_image_delete_timeout*] # (Optional) Time to wait for glance image to be deleted. # Defaults to $::os_service_default # # [*heat_stack_check_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # checking. # Defaults to $::os_service_default # # [*heat_stack_check_timeout*] # (Optional) Time (in sec) to wait for stack to be checked. # Defaults to $::os_service_default # # [*heat_stack_create_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # creation. # Defaults to $::os_service_default # # [*heat_stack_create_prepoll_delay*] # (Optional) Time (in sec) to sleep after creating a resource before polling # for it status. # Defaults to $::os_service_default # # [*heat_stack_create_timeout*] # (Optional) Time (in sec) to wait for heat stack to be created. # Defaults to $::os_service_default # # [*heat_stack_delete_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # deletion. # Defaults to $::os_service_default # # [*heat_stack_delete_timeout*] # (Optional) Time (in sec) to wait for heat stack to be deleted. # Defaults to $::os_service_default # # [*heat_stack_owner_role*] # (Optional) Role required for users to be able to manage Heat stacks # Defaults to $::os_service_default # # [*heat_stack_restore_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack to # be restored. # Defaults to $::os_service_default # # [*heat_stack_restore_timeout*] # (Optional) Time (in sec) to wait for stack to be restored from snapshot. # Defaults to $::os_service_default # # [*heat_stack_resume_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # resume. # Defaults to $::os_service_default # # [*heat_stack_resume_timeout*] # (Optional) Time (in sec) to wait for stack to be resumed. # Defaults to $::os_service_default # # [*heat_stack_scale_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for a stack # to scale up or down. # Defaults to $::os_service_default # # [*heat_stack_scale_timeout*] # (Optional) Time (in sec) to wait for stack to scale up or down. # Defaults to $::os_service_default # # [*heat_stack_snapshot_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # snapshot to be created. # Defaults to $::os_service_default # # [*heat_stack_snapshot_timeout*] # (Optional) Time (in sec) to wait for stack snapshot to be created. # Defaults to $::os_service_default # # [*heat_stack_suspend_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # suspend. # Defaults to $::os_service_default # # [*heat_stack_suspend_timeout*] # (Optional) Time (in sec) to wait for stack to be suspended. # Defaults to $::os_service_default # # [*heat_stack_update_poll_interval*] # (Optional) Time interval (in sec) between checks when waiting for stack # update. # Defaults to $::os_service_default # # [*heat_stack_update_prepoll_delay*] # (Optional) Time (in sec) to sleep after updating a resource before polling # for it status. # Defaults to $::os_service_default # # [*heat_stack_update_timeout*] # (Optional) Time (in sec) to wait for stack to be updated. # Defaults to $::os_service_default # # [*heat_stack_user_role*] # (Optional) Role for Heat template-defined users # Defaults to $::os_service_default # # [*ironic_node_create_poll_interval*] # (Optional) Interval(in sec) between checks when waiting for node creation. # Defaults to $::os_service_default # # [*manila_share_create_poll_interval*] # (Optional) Interval between checks when waiting for Manila share creation. # Defaults to $::os_service_default # # [*manila_share_create_prepoll_delay*] # (Optional) Delay between creating Manila share and polling for its status. # Defaults to $::os_service_default # # [*manila_share_create_timeout*] # (Optional) Timeout for Manila share creation. # Defaults to $::os_service_default # # [*manila_share_delete_poll_interval*] # (Optional) Interval between checks when waiting for Manila share deletion. # Defaults to $::os_service_default # # [*manila_share_delete_timeout*] # (Optional) Timeout for Manila share deletion. # Defaults to $::os_service_default # # [*murano_deploy_environment_check_interval*] # (Optional) Deploy environment check interval in seconds # Defaults to $::os_service_default # # [*murano_deploy_environment_timeout*] # (Optional) A timeout in seconds for an environment deploy # Defaults to $::os_service_default # # [*nova_detach_volume_poll_interval*] # (Optional) Nova volume detach poll interval # Defaults to $::os_service_default # # [*nova_detach_volume_timeout*] # (Optional) Nova volume detach timeout # Defaults to $::os_service_default # # [*nova_server_boot_poll_interval*] # (Optional) Server boot poll interval # Defaults to $::os_service_default # # [*nova_server_boot_prepoll_delay*] # (Optional) Time to sleep after boot before polling for status # Defaults to $::os_service_default # # [*nova_server_boot_timeout*] # (Optional) Server boot timeout # Defaults to $::os_service_default # # [*nova_server_delete_poll_interval*] # (Optional) Server delete poll interval # Defaults to $::os_service_default # # [*nova_server_delete_prepoll_delay*] # (Optional) Time to sleep after delete before polling for status # Defaults to $::os_service_default # # [*nova_server_delete_timeout*] # (Optional) Server delete timeout # Defaults to $::os_service_default # # [*nova_server_image_create_poll_interval*] # (Optional) Server image_create poll interval # Defaults to $::os_service_default # # [*nova_server_image_create_prepoll_delay*] # (Optional) Time to sleep after image_create before polling for status # Defaults to $::os_service_default # # [*nova_server_image_create_timeout*] # (Optional) Server image_create timeout # Defaults to $::os_service_default # # [*nova_server_image_delete_poll_interval*] # (Optional) Server image_delete poll interval # Defaults to $::os_service_default # # [*nova_server_image_delete_prepoll_delay*] # (Optional) Time to sleep after image_delete before polling for status # Defaults to $::os_service_default # # [*nova_server_image_delete_timeout*] # (Optional) Server image_delete timeout # Defaults to $::os_service_default # # [*nova_server_live_migrate_poll_interval*] # (Optional) Server live_migrate poll interval # Defaults to $::os_service_default # # [*nova_server_live_migrate_prepoll_delay*] # (Optional) Time to sleep after live_migrate before polling for status # Defaults to $::os_service_default # # [*nova_server_live_migrate_timeout*] # (Optional) Server live_migrate timeout # Defaults to $::os_service_default # # [*nova_server_migrate_poll_interval*] # (Optional) Server migrate poll interval # Defaults to $::os_service_default # # [*nova_server_migrate_prepoll_delay*] # (Optional) Time to sleep after migrate before polling for status # Defaults to $::os_service_default # # [*nova_server_migrate_timeout*] # (Optional) Server migrate timeout # Defaults to $::os_service_default # # [*nova_server_pause_poll_interval*] # (Optional) Server pause poll interval # Defaults to $::os_service_default # # [*nova_server_pause_prepoll_delay*] # (Optional) Time to sleep after pause before polling for status # Defaults to $::os_service_default # # [*nova_server_pause_timeout*] # (Optional) Server pause timeout # Defaults to $::os_service_default # # [*nova_server_reboot_poll_interval*] # (Optional) Server reboot poll interval # Defaults to $::os_service_default # # [*nova_server_reboot_prepoll_delay*] # (Optional) Time to sleep after reboot before polling for status # Defaults to $::os_service_default # # [*nova_server_reboot_timeout*] # (Optional) Server reboot timeout # Defaults to $::os_service_default # # [*nova_server_rebuild_poll_interval*] # (Optional) Server rebuild poll interval # Defaults to $::os_service_default # # [*nova_server_rebuild_prepoll_delay*] # (Optional) Time to sleep after rebuild before polling for status # Defaults to $::os_service_default # # [*nova_server_rebuild_timeout*] # (Optional) Server rebuild timeout # Defaults to $::os_service_default # # [*nova_server_rescue_poll_interval*] # (Optional) Server rescue poll interval # Defaults to $::os_service_default # # [*nova_server_rescue_prepoll_delay*] # (Optional) Time to sleep after rescue before polling for status # Defaults to $::os_service_default # # [*nova_server_rescue_timeout*] # (Optional) Server rescue timeout # Defaults to $::os_service_default # # [*nova_server_resize_confirm_poll_interval*] # (Optional) Server resize_confirm poll interval # Defaults to $::os_service_default # # [*nova_server_resize_confirm_prepoll_delay*] # (Optional) Time to sleep after resize_confirm before polling for status # Defaults to $::os_service_default # # [*nova_server_resize_confirm_timeout*] # (Optional) Server resize_confirm timeout # Defaults to $::os_service_default # # [*nova_server_resize_poll_interval*] # (Optional) Server resize poll interval # Defaults to $::os_service_default # # [*nova_server_resize_prepoll_delay*] # (Optional) Time to sleep after resize before polling for status # Defaults to $::os_service_default # # [*nova_server_resize_revert_poll_interval*] # (Optional) Server resize_revert poll interval # Defaults to $::os_service_default # # [*nova_server_resize_revert_prepoll_delay*] # (Optional) Time to sleep after resize_revert before polling for status # Defaults to $::os_service_default # # [*nova_server_resize_revert_timeout*] # (Optional) Server resize_revert timeout # Defaults to $::os_service_default # # [*nova_server_resize_timeout*] # (Optional) Server resize timeout # Defaults to $::os_service_default # # [*nova_server_resume_poll_interval*] # (Optional) Server resume poll interval # Defaults to $::os_service_default # # [*nova_server_resume_prepoll_delay*] # (Optional) Time to sleep after resume before polling for status # Defaults to $::os_service_default # # [*nova_server_resume_timeout*] # (Optional) Server resume timeout # Defaults to $::os_service_default # # [*nova_server_shelve_poll_interval*] # (Optional) Server shelve poll interval # Defaults to $::os_service_default # # [*nova_server_shelve_prepoll_delay*] # (Optional) Time to sleep after shelve before polling for status # Defaults to $::os_service_default # # [*nova_server_shelve_timeout*] # (Optional) Server shelve timeout # Defaults to $::os_service_default # # [*nova_server_start_poll_interval*] # (Optional) Server start poll interval # Defaults to $::os_service_default # # [*nova_server_start_prepoll_delay*] # (Optional) Time to sleep after start before polling for status # Defaults to $::os_service_default # # [*nova_server_start_timeout*] # (Optional) Server start timeout # Defaults to $::os_service_default # # [*nova_server_stop_poll_interval*] # (Optional) Server stop poll interval # Defaults to $::os_service_default # # [*nova_server_stop_prepoll_delay*] # (Optional) Time to sleep after stop before polling for status # Defaults to $::os_service_default # # [*nova_server_stop_timeout*] # (Optional) Server stop timeout # Defaults to $::os_service_default # # [*nova_server_suspend_poll_interval*] # (Optional) Server suspend poll interval # Defaults to $::os_service_default # # [*nova_server_suspend_prepoll_delay*] # (Optional) Time to sleep after suspend before polling for status # Defaults to $::os_service_default # # [*nova_server_suspend_timeout*] # (Optional) Server suspend timeout # Defaults to $::os_service_default # # [*nova_server_unpause_poll_interval*] # (Optional) Server unpause poll interval # Defaults to $::os_service_default # # [*nova_server_unpause_prepoll_delay*] # (Optional) Time to sleep after unpause before polling for status # Defaults to $::os_service_default # # [*nova_server_unpause_timeout*] # (Optional) Server unpause timeout # Defaults to $::os_service_default # # [*nova_server_unrescue_poll_interval*] # (Optional) Server unrescue poll interval # Defaults to $::os_service_default # # [*nova_server_unrescue_prepoll_delay*] # (Optional) Time to sleep after unrescue before polling for status # Defaults to $::os_service_default # # [*nova_server_unrescue_timeout*] # (Optional) Server unrescue timeout # Defaults to $::os_service_default # # [*nova_server_unshelve_poll_interval*] # (Optional) Server unshelve poll interval # Defaults to $::os_service_default # # [*nova_server_unshelve_prepoll_delay*] # (Optional) Time to sleep after unshelve before polling for status # Defaults to $::os_service_default # # [*nova_server_unshelve_timeout*] # (Optional) Server unshelve timeout # Defaults to $::os_service_default # # [*openstack_client_http_timeout*] # (Optional) HTTP timeout for any of OpenStack service in seconds # Defaults to $::os_service_default # # [*project_domain*] # (Optional) ID of domain in which projects will be created. # Defaults to $::os_service_default # # [*resource_deletion_timeout*] # (Optional) A timeout in seconds for deleting resources # Defaults to $::os_service_default # # [*resource_management_workers*] # (Optional) How many concurrent threads use for serving users context # Defaults to $::os_service_default # # [*sahara_cluster_check_interval*] # (Optional) Cluster status polling interval in seconds # Defaults to $::os_service_default # # [*sahara_cluster_create_timeout*] # (Optional) A timeout in seconds for a cluster create operation # Defaults to $::os_service_default # # [*sahara_cluster_delete_timeout*] # (Optional) A timeout in seconds for a cluster delete operation # Defaults to $::os_service_default # # [*sahara_job_check_interval*] # (Optional) Job Execution status polling interval in seconds # Defaults to $::os_service_default # # [*sahara_job_execution_timeout*] # (Optional) A timeout in seconds for a Job Execution to complete # Defaults to $::os_service_default # # [*sahara_workers_per_proxy*] # (Optional) Amount of workers one proxy should serve to. # Defaults to $::os_service_default # # [*swift_operator_role*] # (Optional) Role required for users to be able to create Swift containers # Defaults to $::os_service_default # # [*swift_reseller_admin_role*] # (Optional) User role that has reseller admin # Defaults to $::os_service_default # # [*user_domain*] # (Optional) ID of domain in which users will be created. # Defaults to $::os_service_default # # [*vm_ping_poll_interval*] # (Optional) Interval between checks when waiting for a VM to become pingable # Defaults to $::os_service_default # # [*vm_ping_timeout*] # (Optional) Time to wait for a VM to become pingable # Defaults to $::os_service_default class rally::benchmark ( $cinder_volume_create_poll_interval = $::os_service_default, $cinder_volume_create_prepoll_delay = $::os_service_default, $cinder_volume_create_timeout = $::os_service_default, $cinder_volume_delete_poll_interval = $::os_service_default, $cinder_volume_delete_timeout = $::os_service_default, $cirros_img_url = $::os_service_default, $container_format = $::os_service_default, $disk_format = $::os_service_default, $ec2_server_boot_poll_interval = $::os_service_default, $ec2_server_boot_prepoll_delay = $::os_service_default, $ec2_server_boot_timeout = $::os_service_default, $glance_image_create_poll_interval = $::os_service_default, $glance_image_create_prepoll_delay = $::os_service_default, $glance_image_create_timeout = $::os_service_default, $glance_image_delete_poll_interval = $::os_service_default, $glance_image_delete_timeout = $::os_service_default, $heat_stack_check_poll_interval = $::os_service_default, $heat_stack_check_timeout = $::os_service_default, $heat_stack_create_poll_interval = $::os_service_default, $heat_stack_create_prepoll_delay = $::os_service_default, $heat_stack_create_timeout = $::os_service_default, $heat_stack_delete_poll_interval = $::os_service_default, $heat_stack_delete_timeout = $::os_service_default, $heat_stack_owner_role = $::os_service_default, $heat_stack_restore_poll_interval = $::os_service_default, $heat_stack_restore_timeout = $::os_service_default, $heat_stack_resume_poll_interval = $::os_service_default, $heat_stack_resume_timeout = $::os_service_default, $heat_stack_scale_poll_interval = $::os_service_default, $heat_stack_scale_timeout = $::os_service_default, $heat_stack_snapshot_poll_interval = $::os_service_default, $heat_stack_snapshot_timeout = $::os_service_default, $heat_stack_suspend_poll_interval = $::os_service_default, $heat_stack_suspend_timeout = $::os_service_default, $heat_stack_update_poll_interval = $::os_service_default, $heat_stack_update_prepoll_delay = $::os_service_default, $heat_stack_update_timeout = $::os_service_default, $heat_stack_user_role = $::os_service_default, $ironic_node_create_poll_interval = $::os_service_default, $manila_share_create_poll_interval = $::os_service_default, $manila_share_create_prepoll_delay = $::os_service_default, $manila_share_create_timeout = $::os_service_default, $manila_share_delete_poll_interval = $::os_service_default, $manila_share_delete_timeout = $::os_service_default, $murano_deploy_environment_check_interval = $::os_service_default, $murano_deploy_environment_timeout = $::os_service_default, $nova_detach_volume_poll_interval = $::os_service_default, $nova_detach_volume_timeout = $::os_service_default, $nova_server_boot_poll_interval = $::os_service_default, $nova_server_boot_prepoll_delay = $::os_service_default, $nova_server_boot_timeout = $::os_service_default, $nova_server_delete_poll_interval = $::os_service_default, $nova_server_delete_prepoll_delay = $::os_service_default, $nova_server_delete_timeout = $::os_service_default, $nova_server_image_create_poll_interval = $::os_service_default, $nova_server_image_create_prepoll_delay = $::os_service_default, $nova_server_image_create_timeout = $::os_service_default, $nova_server_image_delete_poll_interval = $::os_service_default, $nova_server_image_delete_prepoll_delay = $::os_service_default, $nova_server_image_delete_timeout = $::os_service_default, $nova_server_live_migrate_poll_interval = $::os_service_default, $nova_server_live_migrate_prepoll_delay = $::os_service_default, $nova_server_live_migrate_timeout = $::os_service_default, $nova_server_migrate_poll_interval = $::os_service_default, $nova_server_migrate_prepoll_delay = $::os_service_default, $nova_server_migrate_timeout = $::os_service_default, $nova_server_pause_poll_interval = $::os_service_default, $nova_server_pause_prepoll_delay = $::os_service_default, $nova_server_pause_timeout = $::os_service_default, $nova_server_reboot_poll_interval = $::os_service_default, $nova_server_reboot_prepoll_delay = $::os_service_default, $nova_server_reboot_timeout = $::os_service_default, $nova_server_rebuild_poll_interval = $::os_service_default, $nova_server_rebuild_prepoll_delay = $::os_service_default, $nova_server_rebuild_timeout = $::os_service_default, $nova_server_rescue_poll_interval = $::os_service_default, $nova_server_rescue_prepoll_delay = $::os_service_default, $nova_server_rescue_timeout = $::os_service_default, $nova_server_resize_confirm_poll_interval = $::os_service_default, $nova_server_resize_confirm_prepoll_delay = $::os_service_default, $nova_server_resize_confirm_timeout = $::os_service_default, $nova_server_resize_poll_interval = $::os_service_default, $nova_server_resize_prepoll_delay = $::os_service_default, $nova_server_resize_revert_poll_interval = $::os_service_default, $nova_server_resize_revert_prepoll_delay = $::os_service_default, $nova_server_resize_revert_timeout = $::os_service_default, $nova_server_resize_timeout = $::os_service_default, $nova_server_resume_poll_interval = $::os_service_default, $nova_server_resume_prepoll_delay = $::os_service_default, $nova_server_resume_timeout = $::os_service_default, $nova_server_shelve_poll_interval = $::os_service_default, $nova_server_shelve_prepoll_delay = $::os_service_default, $nova_server_shelve_timeout = $::os_service_default, $nova_server_start_poll_interval = $::os_service_default, $nova_server_start_prepoll_delay = $::os_service_default, $nova_server_start_timeout = $::os_service_default, $nova_server_stop_poll_interval = $::os_service_default, $nova_server_stop_prepoll_delay = $::os_service_default, $nova_server_stop_timeout = $::os_service_default, $nova_server_suspend_poll_interval = $::os_service_default, $nova_server_suspend_prepoll_delay = $::os_service_default, $nova_server_suspend_timeout = $::os_service_default, $nova_server_unpause_poll_interval = $::os_service_default, $nova_server_unpause_prepoll_delay = $::os_service_default, $nova_server_unpause_timeout = $::os_service_default, $nova_server_unrescue_poll_interval = $::os_service_default, $nova_server_unrescue_prepoll_delay = $::os_service_default, $nova_server_unrescue_timeout = $::os_service_default, $nova_server_unshelve_poll_interval = $::os_service_default, $nova_server_unshelve_prepoll_delay = $::os_service_default, $nova_server_unshelve_timeout = $::os_service_default, $openstack_client_http_timeout = $::os_service_default, $project_domain = $::os_service_default, $resource_deletion_timeout = $::os_service_default, $resource_management_workers = $::os_service_default, $sahara_cluster_check_interval = $::os_service_default, $sahara_cluster_create_timeout = $::os_service_default, $sahara_cluster_delete_timeout = $::os_service_default, $sahara_job_check_interval = $::os_service_default, $sahara_job_execution_timeout = $::os_service_default, $sahara_workers_per_proxy = $::os_service_default, $swift_operator_role = $::os_service_default, $swift_reseller_admin_role = $::os_service_default, $user_domain = $::os_service_default, $vm_ping_poll_interval = $::os_service_default, $vm_ping_timeout = $::os_service_default, ) { rally_config { 'DEFAULT/openstack_client_http_timeout': value => $openstack_client_http_timeout; 'benchmark/cinder_volume_create_poll_interval': value => $cinder_volume_create_poll_interval; 'benchmark/cinder_volume_create_prepoll_delay': value => $cinder_volume_create_prepoll_delay; 'benchmark/cinder_volume_create_timeout': value => $cinder_volume_create_timeout; 'benchmark/cinder_volume_delete_poll_interval': value => $cinder_volume_delete_poll_interval; 'benchmark/cinder_volume_delete_timeout': value => $cinder_volume_delete_timeout; 'benchmark/ec2_server_boot_poll_interval': value => $ec2_server_boot_poll_interval; 'benchmark/ec2_server_boot_prepoll_delay': value => $ec2_server_boot_prepoll_delay; 'benchmark/ec2_server_boot_timeout': value => $ec2_server_boot_timeout; 'benchmark/glance_image_create_poll_interval': value => $glance_image_create_poll_interval; 'benchmark/glance_image_create_prepoll_delay': value => $glance_image_create_prepoll_delay; 'benchmark/glance_image_create_timeout': value => $glance_image_create_timeout; 'benchmark/glance_image_delete_poll_interval': value => $glance_image_delete_poll_interval; 'benchmark/glance_image_delete_timeout': value => $glance_image_delete_timeout; 'benchmark/heat_stack_check_poll_interval': value => $heat_stack_check_poll_interval; 'benchmark/heat_stack_check_timeout': value => $heat_stack_check_timeout; 'benchmark/heat_stack_create_poll_interval': value => $heat_stack_create_poll_interval; 'benchmark/heat_stack_create_prepoll_delay': value => $heat_stack_create_prepoll_delay; 'benchmark/heat_stack_create_timeout': value => $heat_stack_create_timeout; 'benchmark/heat_stack_delete_poll_interval': value => $heat_stack_delete_poll_interval; 'benchmark/heat_stack_delete_timeout': value => $heat_stack_delete_timeout; 'benchmark/heat_stack_restore_poll_interval': value => $heat_stack_restore_poll_interval; 'benchmark/heat_stack_restore_timeout': value => $heat_stack_restore_timeout; 'benchmark/heat_stack_resume_poll_interval': value => $heat_stack_resume_poll_interval; 'benchmark/heat_stack_resume_timeout': value => $heat_stack_resume_timeout; 'benchmark/heat_stack_scale_poll_interval': value => $heat_stack_scale_poll_interval; 'benchmark/heat_stack_scale_timeout': value => $heat_stack_scale_timeout; 'benchmark/heat_stack_snapshot_poll_interval': value => $heat_stack_snapshot_poll_interval; 'benchmark/heat_stack_snapshot_timeout': value => $heat_stack_snapshot_timeout; 'benchmark/heat_stack_suspend_poll_interval': value => $heat_stack_suspend_poll_interval; 'benchmark/heat_stack_suspend_timeout': value => $heat_stack_suspend_timeout; 'benchmark/heat_stack_update_poll_interval': value => $heat_stack_update_poll_interval; 'benchmark/heat_stack_update_prepoll_delay': value => $heat_stack_update_prepoll_delay; 'benchmark/heat_stack_update_timeout': value => $heat_stack_update_timeout; 'benchmark/ironic_node_create_poll_interval': value => $ironic_node_create_poll_interval; 'benchmark/manila_share_create_poll_interval': value => $manila_share_create_poll_interval; 'benchmark/manila_share_create_prepoll_delay': value => $manila_share_create_prepoll_delay; 'benchmark/manila_share_create_timeout': value => $manila_share_create_timeout; 'benchmark/manila_share_delete_poll_interval': value => $manila_share_delete_poll_interval; 'benchmark/manila_share_delete_timeout': value => $manila_share_delete_timeout; 'benchmark/murano_deploy_environment_check_interval': value => $murano_deploy_environment_check_interval; 'benchmark/murano_deploy_environment_timeout': value => $murano_deploy_environment_timeout; 'benchmark/nova_detach_volume_poll_interval': value => $nova_detach_volume_poll_interval; 'benchmark/nova_detach_volume_timeout': value => $nova_detach_volume_timeout; 'benchmark/nova_server_boot_poll_interval': value => $nova_server_boot_poll_interval; 'benchmark/nova_server_boot_prepoll_delay': value => $nova_server_boot_prepoll_delay; 'benchmark/nova_server_boot_timeout': value => $nova_server_boot_timeout; 'benchmark/nova_server_delete_poll_interval': value => $nova_server_delete_poll_interval; 'benchmark/nova_server_delete_prepoll_delay': value => $nova_server_delete_prepoll_delay; 'benchmark/nova_server_delete_timeout': value => $nova_server_delete_timeout; 'benchmark/nova_server_image_create_poll_interval': value => $nova_server_image_create_poll_interval; 'benchmark/nova_server_image_create_prepoll_delay': value => $nova_server_image_create_prepoll_delay; 'benchmark/nova_server_image_create_timeout': value => $nova_server_image_create_timeout; 'benchmark/nova_server_image_delete_poll_interval': value => $nova_server_image_delete_poll_interval; 'benchmark/nova_server_image_delete_prepoll_delay': value => $nova_server_image_delete_prepoll_delay; 'benchmark/nova_server_image_delete_timeout': value => $nova_server_image_delete_timeout; 'benchmark/nova_server_live_migrate_poll_interval': value => $nova_server_live_migrate_poll_interval; 'benchmark/nova_server_live_migrate_prepoll_delay': value => $nova_server_live_migrate_prepoll_delay; 'benchmark/nova_server_live_migrate_timeout': value => $nova_server_live_migrate_timeout; 'benchmark/nova_server_migrate_poll_interval': value => $nova_server_migrate_poll_interval; 'benchmark/nova_server_migrate_prepoll_delay': value => $nova_server_migrate_prepoll_delay; 'benchmark/nova_server_migrate_timeout': value => $nova_server_migrate_timeout; 'benchmark/nova_server_pause_poll_interval': value => $nova_server_pause_poll_interval; 'benchmark/nova_server_pause_prepoll_delay': value => $nova_server_pause_prepoll_delay; 'benchmark/nova_server_pause_timeout': value => $nova_server_pause_timeout; 'benchmark/nova_server_reboot_poll_interval': value => $nova_server_reboot_poll_interval; 'benchmark/nova_server_reboot_prepoll_delay': value => $nova_server_reboot_prepoll_delay; 'benchmark/nova_server_reboot_timeout': value => $nova_server_reboot_timeout; 'benchmark/nova_server_rebuild_poll_interval': value => $nova_server_rebuild_poll_interval; 'benchmark/nova_server_rebuild_prepoll_delay': value => $nova_server_rebuild_prepoll_delay; 'benchmark/nova_server_rebuild_timeout': value => $nova_server_rebuild_timeout; 'benchmark/nova_server_rescue_poll_interval': value => $nova_server_rescue_poll_interval; 'benchmark/nova_server_rescue_prepoll_delay': value => $nova_server_rescue_prepoll_delay; 'benchmark/nova_server_rescue_timeout': value => $nova_server_rescue_timeout; 'benchmark/nova_server_resize_confirm_poll_interval': value => $nova_server_resize_confirm_poll_interval; 'benchmark/nova_server_resize_confirm_prepoll_delay': value => $nova_server_resize_confirm_prepoll_delay; 'benchmark/nova_server_resize_confirm_timeout': value => $nova_server_resize_confirm_timeout; 'benchmark/nova_server_resize_poll_interval': value => $nova_server_resize_poll_interval; 'benchmark/nova_server_resize_prepoll_delay': value => $nova_server_resize_prepoll_delay; 'benchmark/nova_server_resize_revert_poll_interval': value => $nova_server_resize_revert_poll_interval; 'benchmark/nova_server_resize_revert_prepoll_delay': value => $nova_server_resize_revert_prepoll_delay; 'benchmark/nova_server_resize_revert_timeout': value => $nova_server_resize_revert_timeout; 'benchmark/nova_server_resize_timeout': value => $nova_server_resize_timeout; 'benchmark/nova_server_resume_poll_interval': value => $nova_server_resume_poll_interval; 'benchmark/nova_server_resume_prepoll_delay': value => $nova_server_resume_prepoll_delay; 'benchmark/nova_server_resume_timeout': value => $nova_server_resume_timeout; 'benchmark/nova_server_shelve_poll_interval': value => $nova_server_shelve_poll_interval; 'benchmark/nova_server_shelve_prepoll_delay': value => $nova_server_shelve_prepoll_delay; 'benchmark/nova_server_shelve_timeout': value => $nova_server_shelve_timeout; 'benchmark/nova_server_start_poll_interval': value => $nova_server_start_poll_interval; 'benchmark/nova_server_start_prepoll_delay': value => $nova_server_start_prepoll_delay; 'benchmark/nova_server_start_timeout': value => $nova_server_start_timeout; 'benchmark/nova_server_stop_poll_interval': value => $nova_server_stop_poll_interval; 'benchmark/nova_server_stop_prepoll_delay': value => $nova_server_stop_prepoll_delay; 'benchmark/nova_server_stop_timeout': value => $nova_server_stop_timeout; 'benchmark/nova_server_suspend_poll_interval': value => $nova_server_suspend_poll_interval; 'benchmark/nova_server_suspend_prepoll_delay': value => $nova_server_suspend_prepoll_delay; 'benchmark/nova_server_suspend_timeout': value => $nova_server_suspend_timeout; 'benchmark/nova_server_unpause_poll_interval': value => $nova_server_unpause_poll_interval; 'benchmark/nova_server_unpause_prepoll_delay': value => $nova_server_unpause_prepoll_delay; 'benchmark/nova_server_unpause_timeout': value => $nova_server_unpause_timeout; 'benchmark/nova_server_unrescue_poll_interval': value => $nova_server_unrescue_poll_interval; 'benchmark/nova_server_unrescue_prepoll_delay': value => $nova_server_unrescue_prepoll_delay; 'benchmark/nova_server_unrescue_timeout': value => $nova_server_unrescue_timeout; 'benchmark/nova_server_unshelve_poll_interval': value => $nova_server_unshelve_poll_interval; 'benchmark/nova_server_unshelve_prepoll_delay': value => $nova_server_unshelve_prepoll_delay; 'benchmark/nova_server_unshelve_timeout': value => $nova_server_unshelve_timeout; 'benchmark/sahara_cluster_check_interval': value => $sahara_cluster_check_interval; 'benchmark/sahara_cluster_create_timeout': value => $sahara_cluster_create_timeout; 'benchmark/sahara_cluster_delete_timeout': value => $sahara_cluster_delete_timeout; 'benchmark/sahara_job_check_interval': value => $sahara_job_check_interval; 'benchmark/sahara_job_execution_timeout': value => $sahara_job_execution_timeout; 'benchmark/sahara_workers_per_proxy': value => $sahara_workers_per_proxy; 'benchmark/vm_ping_poll_interval': value => $vm_ping_poll_interval; 'benchmark/vm_ping_timeout': value => $vm_ping_timeout; 'cleanup/resource_deletion_timeout': value => $resource_deletion_timeout; 'image/cirros_img_url': value => $cirros_img_url; 'image/container_format': value => $container_format; 'image/disk_format': value => $disk_format; 'role/heat_stack_owner_role': value => $heat_stack_owner_role; 'role/heat_stack_user_role': value => $heat_stack_user_role; 'role/swift_operator_role': value => $swift_operator_role; 'role/swift_reseller_admin_role': value => $swift_reseller_admin_role; 'users_context/project_domain': value => $project_domain; 'users_context/resource_management_workers': value => $resource_management_workers; 'users_context/user_domain': value => $user_domain; } } ",,785,0
openstack%2Fkuryr~master~I86c2071ee82113bb6cc74375b3357a10b8590a27,openstack/kuryr,master,I86c2071ee82113bb6cc74375b3357a10b8590a27,Passing the interaface name to unbind,ABANDONED,2015-12-07 22:30:44.000000000,2016-02-15 22:01:06.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 9820}, {'_account_id': 10151}, {'_account_id': 11343}, {'_account_id': 12069}, {'_account_id': 14352}]","[{'number': 1, 'created': '2015-12-07 22:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/9fab32cb798ee0cd824dc0a4f8fa1cc649abc77d', 'message': 'Passing the interaface name to unbind\n\nThe unbind code in binding.py cleans up the interface identified by\n""ifname"". However, in certain cases, e.g. the hybrid ovs case, this\ninterface may be connected to other network resources (a linux\nbridge). In order to clean up such resources properly the unbind\nbinary for this type of plug/unplug needs to remove the interface\nfirst.  Considering that the code for removing the interface in\nbinding.py, cleanup_veth(), does nothing if the interface does not\nexist, this should be safe to do in the binary. To do so, we need to\npass the name to the binary when called for unbinding.\n\nChange-Id: I86c2071ee82113bb6cc74375b3357a10b8590a27\n'}, {'number': 2, 'created': '2015-12-28 18:55:59.000000000', 'files': ['kuryr/binding.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/f0688045ff060a62e8549c18bb953fa3db571056', 'message': 'Passing the interaface name to unbind\n\nThe unbind code in binding.py cleans up the interface identified by\n""ifname"". However, in certain cases, e.g. the hybrid ovs case, this\ninterface may be connected to other network resources (a linux\nbridge). In order to clean up such resources properly the unbind\nbinary for this type of plug/unplug needs to remove the interface\nfirst. Hence, calling cleanup_veth() first.\n\nChange-Id: I86c2071ee82113bb6cc74375b3357a10b8590a27\n'}]",4,254417,f0688045ff060a62e8549c18bb953fa3db571056,15,8,2,1923,,,0,"Passing the interaface name to unbind

The unbind code in binding.py cleans up the interface identified by
""ifname"". However, in certain cases, e.g. the hybrid ovs case, this
interface may be connected to other network resources (a linux
bridge). In order to clean up such resources properly the unbind
binary for this type of plug/unplug needs to remove the interface
first. Hence, calling cleanup_veth() first.

Change-Id: I86c2071ee82113bb6cc74375b3357a10b8590a27
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/17/254417/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr/binding.py'],1,9fab32cb798ee0cd824dc0a4f8fa1cc649abc77d,ovs_hybrid," ifname = endpoint_id[:8] + VETH_POSTFIX unbinding_exec_path, UNBINDING_SUBCOMMAND, port_id, ifname, run_as_root=True)"," unbinding_exec_path, UNBINDING_SUBCOMMAND, port_id, run_as_root=True)",3,1
openstack%2Fnova~master~Id4b44dc4c3391563154a30406a5f1e7a2dc015b3,openstack/nova,master,Id4b44dc4c3391563154a30406a5f1e7a2dc015b3,Move Disk allocation ratio to ResourceTracker,MERGED,2015-11-16 02:50:56.000000000,2016-02-15 21:56:10.000000000,2016-02-15 21:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-11-16 02:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d41d6f8402ab017d5b501a2adcfb1173c661e506', 'message': ""Move disk allocation ratio to ResourceTracker\n\nAs mentioned in nova bp 'allocation-ratio-to-resource-tracker',\ncpu/mem allocation ratio have already been moved to resource tracker.\nAnd disk allocation ratio MUST be moved as same.\n\nChange-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3\nCloses-Bug: #1513335\n""}, {'number': 2, 'created': '2016-02-09 15:09:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3fcdc00a68587a21d093ad50fe2264fbcdeee20f', 'message': 'Move Disk allocation ratio to ResourceTracker\n\nWe already moved the CPU and RAM ratios to the compute nodes in Liberty\nbut we forgot to add the disk one. Adding it now.\n\nThat change specifically implies that nova.conf is consistent across the whole\ncloud since what was formerly defined on the scheduler side will have its\ndefinition by the compute nodes.\n\nUpgradeImpact\n\nChange-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3\nPartially-Implements: blueprint disk-allocation-ratio-to-rt\n'}, {'number': 3, 'created': '2016-02-09 16:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/97219567c78dccfd6df1bbbcb0683db83de24aa9', 'message': 'Move Disk allocation ratio to ResourceTracker\n\nWe already moved the CPU and RAM ratios to the compute nodes in Liberty\nbut we forgot to add the disk one. Adding it now.\n\nThat change specifically implies that nova.conf is consistent across the whole\ncloud since what was formerly defined on the scheduler side will have its\ndefinition by the compute nodes.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\nUpgradeImpact\n\nChange-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3\nPartially-Implements: blueprint disk-allocation-ratio-to-rt\n'}, {'number': 4, 'created': '2016-02-11 09:15:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3e1fa642ea44f8cdf6e2324e8a303fce0175d16', 'message': 'Move Disk allocation ratio to ResourceTracker\n\nWe already moved the CPU and RAM ratios to the compute nodes in Liberty\nbut we forgot to add the disk one. Adding it now.\n\nThat change specifically implies that nova.conf is consistent across the whole\ncloud since what was formerly defined on the scheduler side will have its\ndefinition by the compute nodes.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\nUpgradeImpact\n\nChange-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3\nPartially-Implements: blueprint disk-allocation-ratio-to-rt\n'}, {'number': 5, 'created': '2016-02-12 20:39:49.000000000', 'files': ['nova/conf/scheduler.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0ecc8701990edc811b29284c5aae6adc19ee48ea', 'message': 'Move Disk allocation ratio to ResourceTracker\n\nWe already moved the CPU and RAM ratios to the compute nodes in Liberty\nbut we forgot to add the disk one. Adding it now.\n\nThat change specifically implies that nova.conf is consistent across the whole\ncloud since what was formerly defined on the scheduler side will have its\ndefinition by the compute nodes.\n\nCo-Authored-By: Sylvain Bauza <sbauza@redhat.com>\nUpgradeImpact\n\nChange-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3\nPartially-Implements: blueprint disk-allocation-ratio-to-rt\n'}]",10,245619,0ecc8701990edc811b29284c5aae6adc19ee48ea,70,18,5,13248,,,0,"Move Disk allocation ratio to ResourceTracker

We already moved the CPU and RAM ratios to the compute nodes in Liberty
but we forgot to add the disk one. Adding it now.

That change specifically implies that nova.conf is consistent across the whole
cloud since what was formerly defined on the scheduler side will have its
definition by the compute nodes.

Co-Authored-By: Sylvain Bauza <sbauza@redhat.com>
UpgradeImpact

Change-Id: Id4b44dc4c3391563154a30406a5f1e7a2dc015b3
Partially-Implements: blueprint disk-allocation-ratio-to-rt
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/245619/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/opts.py', 'nova/scheduler/filters/disk_filter.py', 'nova/compute/resource_tracker.py']",3,d41d6f8402ab017d5b501a2adcfb1173c661e506,bp/disk-allocation-ratio-to-rt," cfg.FloatOpt( 'cpu_allocation_ratio', cfg.FloatOpt( 'ram_allocation_ratio', cfg.FloatOpt( ""disk_allocation_ratio"", default=1.0, help=""Virtual disk to physical disk allocation ratio""),"," cfg.FloatOpt('cpu_allocation_ratio', cfg.FloatOpt('ram_allocation_ratio',",11,13
openstack%2Ftripleo-heat-templates~master~If028c9d7764210363135c3e7cc16ae1fb897a77c,openstack/tripleo-heat-templates,master,If028c9d7764210363135c3e7cc16ae1fb897a77c,Switch to POLL_TEMP_URL for config transport,MERGED,2015-11-29 20:50:59.000000000,2016-02-15 21:53:05.000000000,2016-02-15 21:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 8449}]","[{'number': 1, 'created': '2015-11-29 20:50:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f1257121dd73f225663aed616d024a58470e5164', 'message': 'Switch to POLL_TEMP_URL for config transport\n\nThis will allow the following:\n- reduced load on heat for large overclouds\n- a shorter os-collect-config poll interval without increasing load on\n  the undercloud\n- the ability to add config deployments outside the stack, allowing\n  workflow tools like mistral, ansible or tripleoclient to directly\n  deploy custom scripts and config to overcloud nodes\n\nChange-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c\nDepends-On: I9c475f0c489c67db5895924050186228403f2773\n'}, {'number': 2, 'created': '2015-12-02 21:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/52d55ce779c9fee99afeb201baad44391cdad971', 'message': 'Switch to POLL_TEMP_URL for config transport\n\nThis will allow the following:\n- reduced load on heat for large overclouds\n- a shorter os-collect-config poll interval without increasing load on\n  the undercloud\n- the ability to add config deployments outside the stack, allowing\n  workflow tools like mistral, ansible or tripleoclient to directly\n  deploy custom scripts and config to overcloud nodes\n\nChange-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c\nDepends-On: I9c475f0c489c67db5895924050186228403f2773\n'}, {'number': 3, 'created': '2015-12-11 23:41:59.000000000', 'files': ['overcloud-resource-registry-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c26b541efb7c1cb16a7d7a2f2a12f52696c5146d', 'message': 'Switch to POLL_TEMP_URL for config transport\n\nThis will allow the following:\n- reduced load on heat for large overclouds\n- a shorter os-collect-config poll interval without increasing load on\n  the undercloud\n- the ability to add config deployments outside the stack, allowing\n  workflow tools like mistral, ansible or tripleoclient to directly\n  deploy custom scripts and config to overcloud nodes\n\nChange-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c\nDepends-On: I9c475f0c489c67db5895924050186228403f2773\n'}]",2,251157,c26b541efb7c1cb16a7d7a2f2a12f52696c5146d,36,5,3,4571,,,0,"Switch to POLL_TEMP_URL for config transport

This will allow the following:
- reduced load on heat for large overclouds
- a shorter os-collect-config poll interval without increasing load on
  the undercloud
- the ability to add config deployments outside the stack, allowing
  workflow tools like mistral, ansible or tripleoclient to directly
  deploy custom scripts and config to overcloud nodes

Change-Id: If028c9d7764210363135c3e7cc16ae1fb897a77c
Depends-On: I9c475f0c489c67db5895924050186228403f2773
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/57/251157/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-resource-registry-puppet.yaml'],1,f1257121dd73f225663aed616d024a58470e5164,temp_url_transport, SoftwareConfigTransport: POLL_TEMP_URL,,1,0
openstack%2Fheat~master~I20d2d9d4f317d726ccbb21275984f096ba300767,openstack/heat,master,I20d2d9d4f317d726ccbb21275984f096ba300767,Add support for launch_stack launchConfiguration type,MERGED,2016-02-12 20:07:40.000000000,2016-02-15 21:38:06.000000000,2016-02-15 21:38:06.000000000,"[{'_account_id': 3}, {'_account_id': 7253}, {'_account_id': 7256}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-12 20:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c627fe26872ddf5c968910e445140978824e9bf8', 'message': 'Add support for launch_stack launchConfiguration type\n\nRackspace AutoScale Groups now support a ""launch_stack""\nlaunchConfiguration type.  This adds support to the\nRackspace::AutoScale::Group resource.\n\nChange-Id: I20d2d9d4f317d726ccbb21275984f096ba300767\n'}, {'number': 2, 'created': '2016-02-15 17:44:17.000000000', 'files': ['contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/auto_scale.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/268e6a10d6c3d718406bcebf5f86936c8961d853', 'message': 'Add support for launch_stack launchConfiguration type\n\nRackspace AutoScale Groups now support a ""launch_stack""\nlaunchConfiguration type.  This adds support to the\nRackspace::AutoScale::Group resource.\n\nChange-Id: I20d2d9d4f317d726ccbb21275984f096ba300767\n'}]",6,279765,268e6a10d6c3d718406bcebf5f86936c8961d853,11,4,2,7253,,,0,"Add support for launch_stack launchConfiguration type

Rackspace AutoScale Groups now support a ""launch_stack""
launchConfiguration type.  This adds support to the
Rackspace::AutoScale::Group resource.

Change-Id: I20d2d9d4f317d726ccbb21275984f096ba300767
",git fetch https://review.opendev.org/openstack/heat refs/changes/65/279765/1 && git format-patch -1 --stdout FETCH_HEAD,"['contrib/rackspace/rackspace/tests/test_auto_scale.py', 'contrib/rackspace/rackspace/resources/auto_scale.py']",2,c627fe26872ddf5c968910e445140978824e9bf8,cloud-asg-launch-stack-config,"import sixfrom heat.engine import template as templatem LAUNCH_CONFIG_ARGS_STACK, 'stack', _LAUNCH_CONFIG_ARGS_STACK_KEYS = ( LAUNCH_CONFIG_ARGS_STACK_TEMPLATE, LAUNCH_CONFIG_ARGS_STACK_TEMPLATE_URL, LAUNCH_CONFIG_ARGS_STACK_DISABLE_ROLLBACK, LAUNCH_CONFIG_ARGS_STACK_ENVIRONMENT, LAUNCH_CONFIG_ARGS_STACK_FILES, LAUNCH_CONFIG_ARGS_STACK_PARAMETERS, LAUNCH_CONFIG_ARGS_STACK_TIMEOUT_MINS ) = ( 'template', 'template_url', 'disable_rollback', 'environment', 'files', 'parameters', 'timeout_mins' ) required=False, LAUNCH_CONFIG_ARGS_STACK: properties.Schema( properties.Schema.MAP, _('The attributes that Auto Scale uses to create a new stack. The ' 'attributes that you specify for the stack entity apply to all ' 'new stacks in the scaling group. Note the stack arguments are ' 'directly passed to Heat when creating a stack.'), schema={ LAUNCH_CONFIG_ARGS_STACK_TEMPLATE: properties.Schema( properties.Schema.MAP, _('The template that describes the stack. Either the ' 'template or template_url property must be specified.'), ), LAUNCH_CONFIG_ARGS_STACK_TEMPLATE_URL: properties.Schema( properties.Schema.STRING, _('A URI to a template. Either the template or ' 'template_url property must be specified.') ), LAUNCH_CONFIG_ARGS_STACK_DISABLE_ROLLBACK: properties.Schema( properties.Schema.BOOLEAN, _('Keep the resources that have been created if the stack ' 'fails to create. Defaults to True.'), default=True ), LAUNCH_CONFIG_ARGS_STACK_ENVIRONMENT: properties.Schema( properties.Schema.MAP, _('The environment for the stack.'), ), LAUNCH_CONFIG_ARGS_STACK_FILES: properties.Schema( properties.Schema.MAP, _('The contents of files that the template references.') ), LAUNCH_CONFIG_ARGS_STACK_PARAMETERS: properties.Schema( properties.Schema.MAP, _('Key/value pairs of the parameters and their values to ' 'pass to the parameters in the template.') ), LAUNCH_CONFIG_ARGS_STACK_TIMEOUT_MINS: properties.Schema( properties.Schema.INTEGER, _('The stack creation timeout in minutes.') ) } ) constraints.AllowedValues(['launch_server', 'launch_stack']), def _get_launch_config_server_args(self, launchconf): def _get_launch_config_stack_args(self, launchconf): lcargs = launchconf[self.LAUNCH_CONFIG_ARGS] stack_args = lcargs[self.LAUNCH_CONFIG_ARGS_STACK] return dict( launch_config_type=launchconf[self.LAUNCH_CONFIG_TYPE], template=stack_args[self.LAUNCH_CONFIG_ARGS_STACK_TEMPLATE], template_url=stack_args[ self.LAUNCH_CONFIG_ARGS_STACK_TEMPLATE_URL], disable_rollback=stack_args[ self.LAUNCH_CONFIG_ARGS_STACK_DISABLE_ROLLBACK], environment=stack_args[self.LAUNCH_CONFIG_ARGS_STACK_ENVIRONMENT], files=stack_args[self.LAUNCH_CONFIG_ARGS_STACK_FILES], parameters=stack_args[self.LAUNCH_CONFIG_ARGS_STACK_PARAMETERS], timeout_mins=stack_args[self.LAUNCH_CONFIG_ARGS_STACK_TIMEOUT_MINS] ) def _get_launch_config_args(self, launchconf): """"""Get the launchConfiguration-related pyrax arguments."""""" if launchconf[self.LAUNCH_CONFIG_ARGS][self.LAUNCH_CONFIG_ARGS_SERVER]: return self._get_launch_config_server_args(launchconf) else: return self._get_launch_config_stack_args(launchconf) server_args = lcargs.get(self.LAUNCH_CONFIG_ARGS_SERVER) st_args = lcargs.get(self.LAUNCH_CONFIG_ARGS_STACK) # launch_server and launch_stack are required and mutually exclusive. if ((not server_args and not st_args) or (server_args and st_args)): msg = (_('Must provide one of %(server)s or %(stack)s in %(conf)s') % {'server': self.LAUNCH_CONFIG_ARGS_SERVER, 'stack': self.LAUNCH_CONFIG_ARGS_STACK, 'conf': self.LAUNCH_CONFIGURATION}) raise exception.StackValidationFailed(msg) if st_args: st_tmpl = st_args.get(self.LAUNCH_CONFIG_ARGS_STACK_TEMPLATE) st_tmpl_url = st_args.get( self.LAUNCH_CONFIG_ARGS_STACK_TEMPLATE_URL) st_env = st_args.get(self.LAUNCH_CONFIG_ARGS_STACK_ENVIRONMENT) # template and template_url are required and mutually exclusive. if ((not st_tmpl and not st_tmpl_url) or (st_tmpl and st_tmpl_url)): msg = _('Must provide one of template or template_url.') raise exception.StackValidationFailed(msg) if st_tmpl: st_files = st_args.get(self.LAUNCH_CONFIG_ARGS_STACK_FILES) try: templatem.Template(st_tmpl, files=st_files, env=st_env) except Exception as exc: msg = (_('Encountered error while loading template: %s') % six.text_type(exc)) raise exception.StackValidationFailed(msg) "," required=True constraints.AllowedValues(['launch_server']), def _get_launch_config_args(self, launchconf): """"""Get the launchConfiguration-related pyrax arguments.""""""",563,12
openstack%2Fbarbican~master~I4c2a65247b6fb4a85417823187e98966162dd448,openstack/barbican,master,I4c2a65247b6fb4a85417823187e98966162dd448,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 13:39:50.000000000,2016-02-15 21:35:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-14 13:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/37d752ea5d9b6c71837a4245f39d5cbbd2df8669', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\n\nChange-Id: I4c2a65247b6fb4a85417823187e98966162dd448\n'}, {'number': 2, 'created': '2016-02-14 18:36:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/barbican/commit/87a32e98e6154845926b79630af75ddca4b83ee9', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\nDepends-On: Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535\nChange-Id: I4c2a65247b6fb4a85417823187e98966162dd448\n'}]",0,279977,87a32e98e6154845926b79630af75ddca4b83ee9,5,1,2,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Depends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
Depends-On: Ib0d6ed503eba0d02b0f60eec9c98734aa6fe4535
Change-Id: I4c2a65247b6fb4a85417823187e98966162dd448
",git fetch https://review.opendev.org/openstack/barbican refs/changes/77/279977/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,37d752ea5d9b6c71837a4245f39d5cbbd2df8669,,pycryptodome>=3.4 # Public Domain,pycrypto>=2.6 # Public Domain,1,1
openstack%2Frequirements~master~I82bb5d323f9b08f34f955ea61a81f64de811aa7d,openstack/requirements,master,I82bb5d323f9b08f34f955ea61a81f64de811aa7d,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 02:48:41.000000000,2016-02-15 21:35:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-14 02:48:41.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/637006e2c52c8889330e95ba0905b439936bc89c', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: If88beeb3983705621fe736995939ac20b2daf1f3\nChange-Id: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\n'}]",1,279912,637006e2c52c8889330e95ba0905b439936bc89c,7,3,1,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Depends-On: If88beeb3983705621fe736995939ac20b2daf1f3
Change-Id: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
",git fetch https://review.opendev.org/openstack/requirements refs/changes/12/279912/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,637006e2c52c8889330e95ba0905b439936bc89c,,pycryptodome===3.4,pycrypto===2.6.1,2,2
openstack%2Fneutron~master~I02d9e9edd6228238641a9a0a5e9c7089b548ae35,openstack/neutron,master,I02d9e9edd6228238641a9a0a5e9c7089b548ae35,[WIP] Trying py27/34 with oslo-master,ABANDONED,2016-02-09 01:25:37.000000000,2016-02-15 21:35:21.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-09 01:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e4179b75df4ff75bf944d8acda7bc3a1dd5fdeef', 'message': '[WIP] Trying py27/34 with oslo-master\n\nChange-Id: I02d9e9edd6228238641a9a0a5e9c7089b548ae35\n'}, {'number': 2, 'created': '2016-02-10 20:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1cdef27ec4628b262dfc2dcd125f27e93102b24d', 'message': '[WIP] Trying py27/34 with oslo-master\n\nChange-Id: I02d9e9edd6228238641a9a0a5e9c7089b548ae35\n'}, {'number': 3, 'created': '2016-02-11 14:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b69e268f0a2f983cad050beb77f3269809a4eed', 'message': '[WIP] Trying py27/34 with oslo-master\n\nDepends-On: I8880bf9caa269b9183dba8f269760af76461bca1\nChange-Id: I02d9e9edd6228238641a9a0a5e9c7089b548ae35\n'}, {'number': 4, 'created': '2016-02-14 21:54:49.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2d310fcc506baf95b7da8753098cb94116a345e4', 'message': '[WIP] Trying py27/34 with oslo-master\n\nDepends-On: I8880bf9caa269b9183dba8f269760af76461bca1\nChange-Id: I02d9e9edd6228238641a9a0a5e9c7089b548ae35\n'}]",0,277649,2d310fcc506baf95b7da8753098cb94116a345e4,59,13,4,5638,,,0,"[WIP] Trying py27/34 with oslo-master

Depends-On: I8880bf9caa269b9183dba8f269760af76461bca1
Change-Id: I02d9e9edd6228238641a9a0a5e9c7089b548ae35
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/277649/3 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e4179b75df4ff75bf944d8acda7bc3a1dd5fdeef,,,,1,0
openstack%2Fnova~master~I710399b9b9286884f3ed71522d2697680951c20e,openstack/nova,master,I710399b9b9286884f3ed71522d2697680951c20e,rpc.init() is being called twice per test,MERGED,2016-02-15 07:53:33.000000000,2016-02-15 21:29:28.000000000,2016-02-15 18:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-15 07:53:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ffa35e5faa49faa5700329f7dfe3f92ed6e36f74', 'message': ""rpc.init() is being called twice per test\n\nsetUp calls rpc.init() twice for each test, once in each of:\n\n    self.useFixture(conf_fixture.ConfFixture(CONF))\n    self.useFixture(nova_fixtures.RPCFixture('nova.test'))\n\nStop calling rpc.init() in ConfFixture, and defer to RPCFixture for\ninitialization.\n\nThe calls to rpc.init() in ConfFixture were taking 0.01 seconds each.\n\n    0.01 seconds * 14784 tests = 2.5 minutes\n\nChange-Id: I710399b9b9286884f3ed71522d2697680951c20e\n""}, {'number': 2, 'created': '2016-02-15 14:09:36.000000000', 'files': ['nova/tests/unit/test_fixtures.py', 'nova/tests/unit/conf_fixture.py', 'nova/config.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a82ed4fd35f5be06a4e587e8a2acc1552815f3b5', 'message': ""rpc.init() is being called twice per test\n\nsetUp calls rpc.init() twice for each test, once in each of:\n\n    self.useFixture(conf_fixture.ConfFixture(CONF))\n    self.useFixture(nova_fixtures.RPCFixture('nova.test'))\n\nStop calling rpc.init() in ConfFixture, and defer to RPCFixture for\ninitialization.\n\nThe calls to rpc.init() in ConfFixture were taking 0.01 seconds each.\n\n    0.01 seconds * 14784 tests = 2.5 minutes\n\nChange-Id: I710399b9b9286884f3ed71522d2697680951c20e\n""}]",0,280093,a82ed4fd35f5be06a4e587e8a2acc1552815f3b5,24,10,2,16907,,,0,"rpc.init() is being called twice per test

setUp calls rpc.init() twice for each test, once in each of:

    self.useFixture(conf_fixture.ConfFixture(CONF))
    self.useFixture(nova_fixtures.RPCFixture('nova.test'))

Stop calling rpc.init() in ConfFixture, and defer to RPCFixture for
initialization.

The calls to rpc.init() in ConfFixture were taking 0.01 seconds each.

    0.01 seconds * 14784 tests = 2.5 minutes

Change-Id: I710399b9b9286884f3ed71522d2697680951c20e
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/280093/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/test_fixtures.py', 'nova/tests/unit/conf_fixture.py', 'nova/config.py']",3,ffa35e5faa49faa5700329f7dfe3f92ed6e36f74,rpc_init_twice,"def parse_args(argv, default_config_files=None, configure_db=True, init_rpc=True): if init_rpc: rpc.init(CONF)","def parse_args(argv, default_config_files=None, configure_db=True): rpc.init(CONF)",9,3
openstack%2Fpython-zaqarclient~master~Iae5bffb296efd655a34584c7f2162adbe6d029e2,openstack/python-zaqarclient,master,Iae5bffb296efd655a34584c7f2162adbe6d029e2,Improve subscription listing,MERGED,2016-01-27 05:40:01.000000000,2016-02-15 21:27:29.000000000,2016-02-15 21:27:28.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 12321}, {'_account_id': 15054}, {'_account_id': 18683}]","[{'number': 1, 'created': '2016-01-27 05:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/8bb8e1aec992fa98a7c7f788c521a05ab6980619', 'message': ""Improve subscription listing\n\nThe way subscriptions are listed by Client.subscriptions method is not\nvery good. Besides doing nice work, this method modifies subscription\nlist response body from Zaqar by adding redundant 'queue_name' key to\neach subscription dictionary in the response body, while there is\nalready 'source' key containing queue name.\n\nBecause of that it's possible to write a unit test, where queue list\nresponse body from Zaqar does not represent real response that could\ncome from Zaqar. As example see\nzaqarclient.tests.queues.subscriptions.QueuesV2SubscriptionUnitTest.\ntest_subscription_list. This test is missing 'source' keys in response\nbody.\n\nThis patch makes subscription listing code stop modifying responses from\nZaqar. As expected, the example unit test fails after that. This patch\nfixes the test also and checks more subscription object's fields.\n\nAlso this patch improves subscription listing functional test to check\nall fields of subscription object that was deserialized from Zaqar\nresponse, i.e. checks zaqarclient.queues.v2.subscription.create_object\nmethod. It is also needed, because before this patch, subscription's\nqueue name field wasn't checked by any of the tests, making a recent bug\nlike https://bugs.launchpad.net/python-zaqarclient/+bug/1538367\npossible.\n\nChange-Id: Iae5bffb296efd655a34584c7f2162adbe6d029e2\nCloses-Bug: 1538366\n""}, {'number': 2, 'created': '2016-01-27 18:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/ac710af41e880dbed7a8b57f8deca447f4d7c36c', 'message': ""Improve subscription listing\n\nThe way subscriptions are listed by Client.subscriptions method is not\nvery good. Besides doing nice work, this method modifies subscription\nlist response body from Zaqar by adding redundant 'queue_name' key to\neach subscription dictionary in the response body, while there is\nalready 'source' key containing queue name.\n\nBecause of that it's possible to write a unit test, where queue list\nresponse body from Zaqar does not represent real response that could\ncome from Zaqar. As example see\nzaqarclient.tests.queues.subscriptions.QueuesV2SubscriptionUnitTest.\ntest_subscription_list. This test is missing 'source' keys in response\nbody.\n\nThis patch makes subscription listing code stop modifying responses from\nZaqar. As expected, the example unit test fails after that. This patch\nfixes the test also and checks more subscription object's fields.\n\nAlso this patch improves subscription listing functional test to check\nall fields of subscription object that was deserialized from Zaqar\nresponse, i.e. checks zaqarclient.queues.v2.subscription.create_object\nmethod. It is also needed, because before this patch, subscription's\nqueue name field wasn't checked by any of the tests, making a recent bug\nlike https://bugs.launchpad.net/python-zaqarclient/+bug/1538367\npossible.\n\nChange-Id: Iae5bffb296efd655a34584c7f2162adbe6d029e2\nCloses-Bug: 1538366\n""}, {'number': 3, 'created': '2016-01-27 18:33:35.000000000', 'files': ['zaqarclient/queues/v2/subscription.py', 'zaqarclient/tests/queues/subscriptions.py', 'zaqarclient/queues/v2/client.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/f24a7e9fa32feb4077883f7a10180d110ee6edc0', 'message': ""Improve subscription listing\n\nThe way subscriptions are listed by Client.subscriptions method is not\nvery good. Besides doing nice work, this method modifies subscription\nlist response body from Zaqar by adding redundant 'queue_name' key to\neach subscription dictionary in the response body, while there is\nalready 'source' key containing queue name.\n\nBecause of that it's possible to write a unit test, where queue list\nresponse body from Zaqar does not represent real response that could\ncome from Zaqar. As example see\nzaqarclient.tests.queues.subscriptions.QueuesV2SubscriptionUnitTest.\ntest_subscription_list. This test is missing 'source' keys in response\nbody.\n\nThis patch makes subscription listing code stop modifying responses from\nZaqar. As expected, the example unit test fails after that. This patch\nfixes the test also and checks more subscription object's fields.\n\nAlso this patch improves subscription listing functional test to check\nall fields of subscription object that was deserialized from Zaqar\nresponse, i.e. checks zaqarclient.queues.v2.subscription.create_object\nmethod. It is also needed, because before this patch, subscription's\nqueue name field wasn't checked by any of the tests, making a recent bug\nlike https://bugs.launchpad.net/python-zaqarclient/+bug/1538367\npossible.\n\nChange-Id: Iae5bffb296efd655a34584c7f2162adbe6d029e2\nCloses-Bug: 1538366\n""}]",2,272909,f24a7e9fa32feb4077883f7a10180d110ee6edc0,14,5,3,18683,,,0,"Improve subscription listing

The way subscriptions are listed by Client.subscriptions method is not
very good. Besides doing nice work, this method modifies subscription
list response body from Zaqar by adding redundant 'queue_name' key to
each subscription dictionary in the response body, while there is
already 'source' key containing queue name.

Because of that it's possible to write a unit test, where queue list
response body from Zaqar does not represent real response that could
come from Zaqar. As example see
zaqarclient.tests.queues.subscriptions.QueuesV2SubscriptionUnitTest.
test_subscription_list. This test is missing 'source' keys in response
body.

This patch makes subscription listing code stop modifying responses from
Zaqar. As expected, the example unit test fails after that. This patch
fixes the test also and checks more subscription object's fields.

Also this patch improves subscription listing functional test to check
all fields of subscription object that was deserialized from Zaqar
response, i.e. checks zaqarclient.queues.v2.subscription.create_object
method. It is also needed, because before this patch, subscription's
queue name field wasn't checked by any of the tests, making a recent bug
like https://bugs.launchpad.net/python-zaqarclient/+bug/1538367
possible.

Change-Id: Iae5bffb296efd655a34584c7f2162adbe6d029e2
Closes-Bug: 1538366
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/09/272909/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqarclient/queues/v2/subscription.py', 'zaqarclient/tests/queues/subscriptions.py', 'zaqarclient/queues/v2/client.py']",3,8bb8e1aec992fa98a7c7f788c521a05ab6980619,bug/1538366,, for s in subscription_list['subscriptions']: s['queue_name'] = queue_name,23,9
openstack%2Fdragonflow~master~I6102f630a8766880d8e8b101f9c26b88e5c77a91,openstack/dragonflow,master,I6102f630a8766880d8e8b101f9c26b88e5c77a91,Add support for DF built-in Pluggable pub/sub,MERGED,2016-01-04 16:12:59.000000000,2016-02-15 21:24:29.000000000,2016-02-15 21:24:29.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 8976}, {'_account_id': 11343}, {'_account_id': 11364}, {'_account_id': 13070}, {'_account_id': 15309}, {'_account_id': 16983}, {'_account_id': 18668}, {'_account_id': 18811}, {'_account_id': 18903}, {'_account_id': 19526}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-01-04 16:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/abc16cd9834794e036880301af504f0545065e15', 'message': 'Add support for DF built-in pub/sub\n\nAdd nanomsg as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 2, 'created': '2016-01-04 16:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/93d5e688e663459c774ba6ab93df528597fd4661', 'message': 'Add support for DF built-in pub/sub\n\nAdd nanomsg as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 3, 'created': '2016-01-06 05:51:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4b2fd70995d967203685651f0a01242f3f6d71ad', 'message': 'Add support for DF built-in pub/sub\n\nAdd nanomsg as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 4, 'created': '2016-01-06 06:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5c7403116f59803098c77b7099f7d172a54150bb', 'message': 'Add support for DF built-in pub/sub\n\nAdd nanomsg as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 5, 'created': '2016-01-07 15:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/45e6af03ccf224cd3926d6abb512f15fa047c57a', 'message': '[WIP] Add support for DF built-in pub/sub\n\nAdd nanomsg as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 6, 'created': '2016-01-07 22:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5168f530ac8808cc7b867b0f657bd0f5e779602c', 'message': '[WIP] Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 7, 'created': '2016-01-08 12:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/748d28b4cdbccd01a58b40fce409dbf58f64659c', 'message': '[WIP] Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 8, 'created': '2016-01-08 23:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d39493124d906414ff6c0f05b9a0afb32054af7b', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 9, 'created': '2016-01-09 09:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/b7e7ac7e5dd49ada21ad72d154f4c92f25fd3c94', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 10, 'created': '2016-01-13 06:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/180a18440d88ebcb58a99c811ebf4694c58f9e9a', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nimplements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 11, 'created': '2016-01-21 16:48:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3d75b48bf6fd5c0b93cef48abcacf3c41e467f21', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\nimplements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 12, 'created': '2016-01-24 06:20:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5cb5c16c3c0169572ad286cb2a3085f3c45883fd', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 13, 'created': '2016-01-24 06:42:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/599fb3c45a12e247fe8be366a0d0f3bedbd8f9b6', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 14, 'created': '2016-01-24 08:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/584810566ecd3dbccd6d4c65cc6fc9e789f70bec', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 15, 'created': '2016-01-24 09:26:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1f587d296bd011ad1194b05c06ea8cbc681c91ff', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 16, 'created': '2016-01-26 13:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5d393cc4168c9860be7fde0e273f0a20ca021f03', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 17, 'created': '2016-01-27 13:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0de3f58f205e94143b876dc69799c8fe7b751539', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 18, 'created': '2016-01-28 15:26:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/81e0b35952d440bd1a087fdd90759d36815da929', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 19, 'created': '2016-01-28 20:33:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f6a337b389c4c14142da53c3f608d75554c1a529', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 20, 'created': '2016-01-29 07:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3c2e10e3f8d383bb166b2dbb27845a046fcb101b', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 21, 'created': '2016-02-01 15:46:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/de57172add51a576bd5b321323407d54118f2c7e', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 22, 'created': '2016-02-01 19:55:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/8e1ede66a458dfeb4923a1fdcb00e09111110364', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 23, 'created': '2016-02-02 06:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a2ee0361ce092a5b1441563d43e22fb6c323b0aa', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 24, 'created': '2016-02-02 14:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9830c77f947b5f11e51435d03d47409cb18f28c4', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 25, 'created': '2016-02-02 14:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/88f9d5cfbfbb8fefda825f103f9848c21a9109f3', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 26, 'created': '2016-02-02 16:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/370ba301737845527cc93185fbca15b156ff7b11', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 27, 'created': '2016-02-04 13:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/45d7eb1a527cfa5041d1a73188f758b95fdb59a0', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 28, 'created': '2016-02-04 16:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/492e1d324cc162933355f6d2c01637f022dff827', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 29, 'created': '2016-02-07 11:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a22b4fc22226497266f6ae1a371d88b5805b3b7c', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 30, 'created': '2016-02-10 17:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2682c36a2cf68eeb0ee82b91bc20b0dc64e79d57', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 31, 'created': '2016-02-10 17:09:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f125fdf8a7055511c472dd7700dc1b103d06a201', 'message': 'Add support for DF built-in pub/sub\n\nAdd zmq as the built in pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True\nIf set to false will use the DB naitive Pub/Sub mechanisem\nif supported.\nThis is the first patch covering Pluggability the Zmq driver\nnext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 32, 'created': '2016-02-11 07:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/ec164005180b1b5f6e241c7bcd515407407717e0', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True If set to\nfalse will use the DB naitive Pub/Sub mechanisem if supported. This is\nthe first patch covering Pluggability the Zmq driver next patch will\ncover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com> Change-Id:\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 33, 'created': '2016-02-11 08:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9db69d1dea951d0dee76937850d96d1408ac684d', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True If set to\nfalse will use the DB naitive Pub/Sub mechanisem if supported. This is\nthe first patch covering Pluggability the Zmq driver next patch will\ncover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com> Change-Id:\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 34, 'created': '2016-02-12 08:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/d88a6c03ffba56810237ac23747e4578ef12c490', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True If set to\nfalse will use the DB naitive Pub/Sub mechanisem if supported. This is\nthe first patch covering Pluggability the Zmq driver next patch will\ncover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com> Change-Id:\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 35, 'created': '2016-02-14 06:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/0318cf2fc727c30de2b1ceb2e83726c5d855f2d0', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True If set to\nfalse will use the DB naitive Pub/Sub mechanisem if supported. This is\nthe first patch covering Pluggability the Zmq driver next patch will\ncover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com> Change-Id:\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 36, 'created': '2016-02-14 12:34:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/4824402f3293f52f1fa307eaefeacd1d69991cb3', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration use_df_pub_sub default to True If set to\nfalse will use the DB naitive Pub/Sub mechanisem if supported. This is\nthe first patch covering Pluggability the Zmq driver next patch will\ncover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com> Change-Id:\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 37, 'created': '2016-02-14 19:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/fc30a4b9b1f388afb73b23748d34bf0d87d8194d', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration enable_df_pub_sub default to False\nuntil we stabilised it and finalize the bp.\nIf set to false will use the DB naitive Pub/Sub mechanisem if supported.\nThis is the first patch covering Pluggability\nand the Zmq driver.\nNext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 38, 'created': '2016-02-15 06:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f864e1dbeb6516c636208991c56ddce5c6febbe9', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration enable_df_pub_sub default to False\nuntil we stabilised it and finalize the bp.\nIf set to false will use the DB naitive Pub/Sub mechanisem if supported.\nThis is the first patch covering Pluggability\nand the Zmq driver.\nNext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 39, 'created': '2016-02-15 12:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e6cd8851ec84037af6ce6e3b3fc68767415b880e', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration enable_df_pub_sub default to False\nuntil we stabilised it and finalize the bp.\nIf set to false will use the DB naitive Pub/Sub mechanisem if supported.\nThis is the first patch covering Pluggability\nand the Zmq driver.\nNext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}, {'number': 40, 'created': '2016-02-15 20:17:58.000000000', 'files': ['dragonflow/neutron/plugin.py', 'dragonflow/db/pubsub_drivers/__init__.py', 'dragonflow/db/pub_sub_api.py', 'dragonflow/tests/fullstack/test_pub_sub.py', 'dragonflow/db/pubsub_drivers/zmq_pubsub_driver.py', 'setup.cfg', 'dragonflow/controller/df_local_controller.py', 'dragonflow/db/api_nb.py', 'dragonflow/db/db_common.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/9cb724a87cb505bf4a99691df5b0901dd0464f7e', 'message': 'Add support for DF built-in Pluggable pub/sub\n\nAdd zmq as the first pub/sub mechanism.\nAdded configuration enable_df_pub_sub default to False\nuntil we stabilised it and finalize the bp.\nIf set to false will use the DB naitive Pub/Sub mechanisem if supported.\nThis is the first patch covering Pluggability\nand the Zmq driver.\nNext patch will cover the reliability issues\n\npartially implements blueprint: pubsub-module\n\nCo-Authored-By:Gal Sagie <gal.sagie@huawei.com>\n\nChange-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91\n'}]",97,263322,9cb724a87cb505bf4a99691df5b0901dd0464f7e,116,13,40,13070,,,0,"Add support for DF built-in Pluggable pub/sub

Add zmq as the first pub/sub mechanism.
Added configuration enable_df_pub_sub default to False
until we stabilised it and finalize the bp.
If set to false will use the DB naitive Pub/Sub mechanisem if supported.
This is the first patch covering Pluggability
and the Zmq driver.
Next patch will cover the reliability issues

partially implements blueprint: pubsub-module

Co-Authored-By:Gal Sagie <gal.sagie@huawei.com>

Change-Id: I6102f630a8766880d8e8b101f9c26b88e5c77a91
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/22/263322/12 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/neutron/plugin.py', 'dragonflow/common/common_params.py', 'dragonflow/db/db_subscriber.py', 'dragonflow/controller/df_local_controller.py', 'dragonflow/db/api_nb.py', 'dragonflow/db/db_publisher.py']",6,abc16cd9834794e036880301af504f0545065e15,pubsub,"# All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet import msgpack from nanomsg import Socket, PUB eventlet.monkey_patch(all=True) class PublisherAgent(object): def __init__(self, ip, db_driver, db_changes_callback, is_pub=False): super(PublisherAgent, self).__init__() self.db_driver = db_driver self.db_changes_callback = db_changes_callback self.ip = ip #TODO(gampel) move to configuration self.port = ""8861"" self.pub_socket = None self._queue = eventlet.queue.PriorityQueue() self.is_daemonize = False def daemonize(self): self.is_daemonize = True eventlet.spawn(self.run) self._queue.put('sync') eventlet.sleep(0) def run(self): self.pub_socket = Socket(PUB) self.endpoint = self.pub_socket.bind(""tcp://*:"" + self.port) self.pub_socket.send('sync') while True: event = None eventlet.sleep(0) try: event = self._queue.get(timeout=60) except eventlet.queue.Empty: self.pub_socket.send(""sync"") eventlet.sleep(1) else: data = msgpack.packb(event) self.pub_socket.send(data) self._queue.task_done() eventlet.sleep(0.2) def _send_event_ex(self, entry): self.pub_socket = Socket(PUB) #TODO(gampel) when the compute and server are on the same machine #this will not work as the port is allready bound self.pub_socket.bind(""tcp://*:"" + self.port) eventlet.sleep(0) self.pub_socket.send(entry) eventlet.sleep(1) self.pub_socket.close() def send_event(self, table, key, action, value): entry = table + ""@"" + key + ""@"" + action + ""@"" + value if self.is_daemonize: self._queue.put(entry) eventlet.sleep(0) else: self._send_event_ex(entry) def main(): pubsub = PublisherAgent('127.0.0.1', None, None) pubsub.daemonize() while True: pubsub.send_event(""t"", ""k"", ""a"", ""v"") if __name__ == ""__main__"": main() ",,234,12
openstack%2Fnova~master~I086b3880486f1607fce66b763afec031d5b96163,openstack/nova,master,I086b3880486f1607fce66b763afec031d5b96163,PCI stats will also include device_type in it's pools for PFs,ABANDONED,2015-11-24 05:41:26.000000000,2016-02-15 21:15:35.000000000,,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 8802}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}]","[{'number': 1, 'created': '2015-11-24 05:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dcaeca5ce4ba31dcce13eb9c4bf4bc0a62f15ac3', 'message': ""pci: adding support to specify a dev_type in pci requests\n\nPCI stats will also include dev_type in it's pools, in order\nto meet the request specs.\n\nSupporting a specification of a dev_type in pci requests\nwill allow the users to explicitly request pci devices by\nit's type, i.e. PF or a VF\nSome SR-IOV cards expose the same device_id for both PFs and VFs\nDue to this fact PFs will be filtered out for the available pools\nunless it has been explicitly requested.\n\nDocImpact\nPartially implements blueprint sriov-physical-function-passthrough\n\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n""}, {'number': 2, 'created': '2015-12-08 09:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/370316b2c07321ca853af8eceeed53c516e598b6', 'message': ""pci: adding support to specify a device_type in pci requests\n\nPCI stats will also include device_type in it's pools, in order\nto meet the request specs.\n\nSupporting a device_type in a pci requests specs\nwill allow the users to explicitly request pci devices by\nit's type, i.e. PF or a VF\nSome SR-IOV cards expose the same device_id for both PFs and VFs\nDue to this fact PFs will be filtered out for the available pools\nunless it has been explicitly requested.\n\nWhile keeping track of the number of available physical functions\nin the pci pools, this change will also update the dependent virtual\nfunctions count and remove it from the pools, when PF is allocated.\n\nPhysical function will be removed from the pools when one of it's\nVFs is allocated. It will become available again, when al of it's\nVFs are free.\n\nDocImpact\nPartially implements blueprint sriov-physical-function-passthrough\n\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n""}, {'number': 3, 'created': '2015-12-08 18:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b27a6ae3f7ce227a030bd34be8e50da703b6c7a', 'message': ""pci: adding support to specify a device_type in pci requests\n\nPCI stats will also include device_type in it's pools, in order\nto meet the request specs.\n\nSupporting a device_type in a pci requests specs\nwill allow the users to explicitly request pci devices by\nit's type, i.e. PF or a VF\nSome SR-IOV cards expose the same device_id for both PFs and VFs\nDue to this fact PFs will be filtered out for the available pools\nunless it has been explicitly requested.\n\nWhile keeping track of the number of available physical functions\nin the pci pools, this change will also update the dependent virtual\nfunctions count and remove it from the pools, when PF is allocated.\n\nPhysical function will be removed from the pools when one of it's\nVFs is allocated. It will become available again, when al of it's\nVFs are free.\n\nDocImpact\nPartially implements blueprint sriov-physical-function-passthrough\n\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n""}, {'number': 4, 'created': '2015-12-09 04:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d32ad3c3097ed118475f44597f045dcff2ac4446', 'message': ""pci: adding support to specify a device_type in pci requests\n\nPCI stats will also include device_type in it's pools, in order\nto meet the request specs.\n\nSupporting a device_type in a pci requests specs\nwill allow the users to explicitly request pci devices by\nit's type, i.e. PF or a VF\nSome SR-IOV cards expose the same device_id for both PFs and VFs\nDue to this fact PFs will be filtered out for the available pools\nunless it has been explicitly requested.\n\nWhile keeping track of the number of available physical functions\nin the pci pools, this change will also update the dependent virtual\nfunctions count and remove it from the pools, when PF is allocated.\n\nPhysical function will be removed from the pools when one of it's\nVFs is allocated. It will become available again, when al of it's\nVFs are free.\n\nDocImpact\nPartially implements blueprint sriov-physical-function-passthrough\n\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n""}, {'number': 5, 'created': '2015-12-17 17:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5b60b629fbc2597895ccb8257caa5cbb38fc7ed', 'message': 'PCI stats will also include device_type in it\'s pools for PFs\n\nWe want to expose device_type to device_pools, as once we actually start\ntracking SR-IOV physical functions, we\'d want a different alias for\nrequesting those than the one that was used for VFs. We also need to\nconsider backwards compatibility.\n\nCurrently, admin could specify an alias by specifying only product and\nvendor IDs. Anything else they wanted to specify that is a valid field\nof the pci_alias dict NEEDS to be matched by the same field in the\nwhitelist. So for example, a pci alias as such:\n\npci_alias = \'[{""name"": ""fastnic"",\n               ""vendor_id"": ""8086"",\n               ""product_id"": ""0443"",\n               ""device_type"": ""NIC""}]\'\n\nwould only match a device that was whitelisted with \'device_type\': \'NIC\'\nas part of the whitelist entry like so:\n\npci_passthrough_whitelist = {""address"":""00:0a:01.1"", ""device_type"": ""NIC""}\n\n(provided that the device at the given address has the requested vendor\nand product ids, of course).\n\nThe problem is that in case the given address is the\naddress of a Physical function, whitelisting it means that we want to\nmatch any of the VFs of the said PF. In order to keep backwards\ncompatibility, we can\'t remove that (miss?)feature so the question is: how\nwould we allow for requesting a PF by device_type in the alias (or\neventually based on a Neutron port) without needing for it\nto be specified in the whitelist, effectively breaking backwards\ncompatibility?\n\nThis patch allows the tags that are added to the pool based on the\nPciDeviceSpec (generated from the whitelist dict) to be extended\nbased on the actual pci_device that is being added to the pools. Although\nadded as a general update_devspec_tags() method on the object, currently\nit will only add a device_type tag for a PF device, effectively splitting the\npools by device_type into PFs and non PFs.\n\nCurrently we have a hard-coded filter that makes sure we never actually\nadd any PFs to pools, so this change is a no-op, but paves the way for\nbeing able to request a PF device in a backwards compatible way,\nprovided the administrators allow for it.\n\nDocImpact\n\nCo-authored-by: Vladik Romanovsky <vromanso@redhat.com>\nPartially implements blueprint: sriov-physical-function-passthrough\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n'}, {'number': 6, 'created': '2015-12-17 17:18:58.000000000', 'files': ['nova/objects/pci_device.py', 'nova/tests/unit/pci/test_stats.py', 'nova/pci/devspec.py', 'nova/tests/unit/objects/test_pci_device.py', 'nova/pci/request.py', 'nova/tests/unit/pci/test_devspec.py', 'nova/pci/stats.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/f8b1ebb98ca6a61bdd2b5bd7593ac97211f36f4a', 'message': 'PCI stats will also include device_type in it\'s pools for PFs\n\nWe want to expose device_type to device_pools, as once we actually start\ntracking SR-IOV physical functions, we\'d want a different alias for\nrequesting those than the one that was used for VFs. We also need to\nconsider backwards compatibility.\n\nCurrently, admin could specify an alias by specifying only product and\nvendor IDs. Anything else they wanted to specify that is a valid field\nof the pci_alias dict NEEDS to be matched by the same field in the\nwhitelist. So for example, a pci alias as such:\n\npci_alias = \'[{""name"": ""fastnic"",\n               ""vendor_id"": ""8086"",\n               ""product_id"": ""0443"",\n               ""device_type"": ""NIC""}]\'\n\nwould only match a device that was whitelisted with \'device_type\': \'NIC\'\nas part of the whitelist entry like so:\n\npci_passthrough_whitelist = {""address"":""00:0a:01.1"", ""device_type"": ""NIC""}\n\n(provided that the device at the given address has the requested vendor\nand product ids, of course).\n\nThe problem is that in case the given address is the\naddress of a Physical function, whitelisting it means that we want to\nmatch any of the VFs of the said PF. In order to keep backwards\ncompatibility, we can\'t remove that (miss?)feature so the question is: how\nwould we allow for requesting a PF by device_type in the alias (or\neventually based on a Neutron port) without needing for it\nto be specified in the whitelist, effectively breaking backwards\ncompatibility?\n\nThis patch allows the tags that are added to the pool based on the\nPciDeviceSpec (generated from the whitelist dict) to be extended\nbased on the actual pci_device that is being added to the pools. Although\nadded as a general update_devspec_tags() method on the object, currently\nit will only add a device_type tag for a PF device, effectively splitting the\npools by device_type into PFs and non PFs.\n\nCurrently we have a hard-coded filter that makes sure we never actually\nadd any PFs to pools, so this change is a no-op, but paves the way for\nbeing able to request a PF device in a backwards compatible way,\nprovided the administrators allow for it.\n\nDocImpact\n\nCo-authored-by: Vladik Romanovsky <vromanso@redhat.com>\nPartially implements blueprint: sriov-physical-function-passthrough\nChange-Id: I086b3880486f1607fce66b763afec031d5b96163\n'}]",9,249017,f8b1ebb98ca6a61bdd2b5bd7593ac97211f36f4a,65,13,6,8802,,,0,"PCI stats will also include device_type in it's pools for PFs

We want to expose device_type to device_pools, as once we actually start
tracking SR-IOV physical functions, we'd want a different alias for
requesting those than the one that was used for VFs. We also need to
consider backwards compatibility.

Currently, admin could specify an alias by specifying only product and
vendor IDs. Anything else they wanted to specify that is a valid field
of the pci_alias dict NEEDS to be matched by the same field in the
whitelist. So for example, a pci alias as such:

pci_alias = '[{""name"": ""fastnic"",
               ""vendor_id"": ""8086"",
               ""product_id"": ""0443"",
               ""device_type"": ""NIC""}]'

would only match a device that was whitelisted with 'device_type': 'NIC'
as part of the whitelist entry like so:

pci_passthrough_whitelist = {""address"":""00:0a:01.1"", ""device_type"": ""NIC""}

(provided that the device at the given address has the requested vendor
and product ids, of course).

The problem is that in case the given address is the
address of a Physical function, whitelisting it means that we want to
match any of the VFs of the said PF. In order to keep backwards
compatibility, we can't remove that (miss?)feature so the question is: how
would we allow for requesting a PF by device_type in the alias (or
eventually based on a Neutron port) without needing for it
to be specified in the whitelist, effectively breaking backwards
compatibility?

This patch allows the tags that are added to the pool based on the
PciDeviceSpec (generated from the whitelist dict) to be extended
based on the actual pci_device that is being added to the pools. Although
added as a general update_devspec_tags() method on the object, currently
it will only add a device_type tag for a PF device, effectively splitting the
pools by device_type into PFs and non PFs.

Currently we have a hard-coded filter that makes sure we never actually
add any PFs to pools, so this change is a no-op, but paves the way for
being able to request a PF device in a backwards compatible way,
provided the administrators allow for it.

DocImpact

Co-authored-by: Vladik Romanovsky <vromanso@redhat.com>
Partially implements blueprint: sriov-physical-function-passthrough
Change-Id: I086b3880486f1607fce66b763afec031d5b96163
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/249017/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/pci/request.py', 'nova/pci/stats.py']",2,dcaeca5ce4ba31dcce13eb9c4bf4bc0a62f15ac3,bp/sriov-physical-function-passthrough,"from nova.objects import fields pool_keys = ['product_id', 'vendor_id', 'numa_node', 'dev_type'] pools = self._filter_non_requested_pfs(request, pools) def _filter_non_requested_pfs(self, request, matching_pools) # Remove SRIOV_PFs from pools, unless it has been explicitly requested if all(spec.get('dev_type') != fields.PciDeviceType.SRIOV_PF for spec in request.spec): matching_pools = self._filter_pools_for_pfs(matching_pools) return matching_pools @staticmethod def _filter_pools_for_pfs(pools): return [pool for pool in pools if not pool.get('dev_type') == fields.PciDeviceType.SRIOV_PF] matching_pools = self._filter_non_requested_pfs(request, matching_pools)"," pool_keys = ['product_id', 'vendor_id', 'numa_node']",24,8
openstack%2Fopenstack-ansible-galera_server~master~I26560668325d45f670c8b946c978c48559f58419,openstack/openstack-ansible-galera_server,master,I26560668325d45f670c8b946c978c48559f58419,Added major version upgrade support,MERGED,2016-01-22 16:39:39.000000000,2016-02-15 21:14:52.000000000,2016-02-15 21:14:52.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7219}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 12807}, {'_account_id': 12892}, {'_account_id': 18784}]","[{'number': 1, 'created': '2016-01-22 16:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/107dd50ea39f90cbd843f7a97d4d94ac3c2bfd7d', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version missmatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2016-01-22 18:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/95611d3ca364d7d1e76f6d954457f210a413014f', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2016-01-22 18:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/9892f8819ad84af1c946fda32cd79e06dd030f7f', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2016-01-22 19:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/e71ff838af2bf2a9f28b315eba1acaf78118e2a6', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2016-01-22 19:40:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/6d8c4534fa9285f1bb769536575d22a35c6716e4', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2016-01-23 02:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/97a53a736a4e4d0bf49a4a458cdeeb6c317fe582', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2016-01-23 02:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/e65a39c6c96617fa39b279809b057a1db83478aa', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2016-01-25 21:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3a0c16157dbb13d72a6a8a79e89c1d88d5b220d0', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2016-01-25 22:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/5577402dde96baf59bc09f266a431393dfb36f9e', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2016-01-26 15:06:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/6ef91bd8828d45cae6e7da4c4a521fb4ad3766c3', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2016-02-12 12:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/41f70c34a0a4b5cf88e9d6779573a962e0f9da7d', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 12, 'created': '2016-02-12 12:36:55.000000000', 'files': ['tasks/galera_upgrade_check.yml', 'tasks/main.yml', 'tasks/galera_post_install.yml', 'handlers/main.yml', 'tests/test.yml', 'tasks/galera_upgrade_post.yml', 'defaults/main.yml', 'tasks/galera_bootstrap.yml', 'tasks/galera_cluster_state.yml', 'tests/test-prep.yml', 'tasks/galera_upgrade_pre.yml', 'tests/test-container-create.yml', 'tests/test-functional.yml', 'tasks/galera_running_check.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/b651fa3bd8603e34e2baf3924a123f8821b693fe', 'message': 'Added major version upgrade support\n\nThe change adds in the ability for the role to take care of a major upgrade\nin a version of an installed mariadb galera cluster.\n\nThe change adds a new task file that checks if the installed version of the\ngalera cluster matches that of the specified major version. The role will\nhard stop if there is a version mismatch and the option ""galera_upgrade=true""\nis not passed.\n\nChange-Id: I26560668325d45f670c8b946c978c48559f58419\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",16,271423,b651fa3bd8603e34e2baf3924a123f8821b693fe,48,9,12,7353,,,0,"Added major version upgrade support

The change adds in the ability for the role to take care of a major upgrade
in a version of an installed mariadb galera cluster.

The change adds a new task file that checks if the installed version of the
galera cluster matches that of the specified major version. The role will
hard stop if there is a version mismatch and the option ""galera_upgrade=true""
is not passed.

Change-Id: I26560668325d45f670c8b946c978c48559f58419
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/23/271423/3 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_upgrade_check.yml', 'tasks/main.yml', 'handlers/main.yml', 'defaults/main.yml']",4,107dd50ea39f90cbd843f7a97d4d94ac3c2bfd7d,galera-server-upgrade,galera_upgrade: false,,83,0
openstack%2Fmagnum~master~I62364f794a82b10c12403837c6bfb6a8c903acc6,openstack/magnum,master,I62364f794a82b10c12403837c6bfb6a8c903acc6,Updated from global requirements,MERGED,2016-02-10 21:54:20.000000000,2016-02-15 21:06:18.000000000,2016-02-13 03:10:48.000000000,"[{'_account_id': 3}, {'_account_id': 10263}, {'_account_id': 11536}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-10 21:54:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bb7787e6d63181056cdb2aebda8811ee8a7654c7', 'message': 'Updated from global requirements\n\nChange-Id: I62364f794a82b10c12403837c6bfb6a8c903acc6\n'}, {'number': 2, 'created': '2016-02-11 07:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ad134a84b12564d5102feb9cfd246d2cae810cdf', 'message': 'Updated from global requirements\n\nChange-Id: I62364f794a82b10c12403837c6bfb6a8c903acc6\n'}, {'number': 3, 'created': '2016-02-12 20:02:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/magnum/commit/0242aaa6c4497c10fbe8f0385100347f4b8bd1e7', 'message': 'Updated from global requirements\n\nChange-Id: I62364f794a82b10c12403837c6bfb6a8c903acc6\n'}]",0,278680,0242aaa6c4497c10fbe8f0385100347f4b8bd1e7,14,4,3,11131,,,0,"Updated from global requirements

Change-Id: I62364f794a82b10c12403837c6bfb6a8c903acc6
",git fetch https://review.opendev.org/openstack/magnum refs/changes/80/278680/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,bb7787e6d63181056cdb2aebda8811ee8a7654c7,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,5,5
openstack%2Fzaqar~master~I6f9805e20dc47307042842d4e472f8cb07421729,openstack/zaqar,master,I6f9805e20dc47307042842d4e472f8cb07421729,Updated from global requirements,MERGED,2016-02-10 22:01:13.000000000,2016-02-15 20:57:42.000000000,2016-02-15 20:57:42.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 12321}]","[{'number': 1, 'created': '2016-02-10 22:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ae88ccc5ec23dea57d1b0e8230742756a6c8991f', 'message': 'Updated from global requirements\n\nChange-Id: I6f9805e20dc47307042842d4e472f8cb07421729\n'}, {'number': 2, 'created': '2016-02-11 15:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/599e1ce01cd0f05f03e3e763b1268bf4aff8683e', 'message': 'Updated from global requirements\n\nChange-Id: I6f9805e20dc47307042842d4e472f8cb07421729\n'}, {'number': 3, 'created': '2016-02-14 23:13:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/37955f6941f3ca4281abceb8ff711abd54037fc5', 'message': 'Updated from global requirements\n\nChange-Id: I6f9805e20dc47307042842d4e472f8cb07421729\n'}]",0,278760,37955f6941f3ca4281abceb8ff711abd54037fc5,13,3,3,11131,,,0,"Updated from global requirements

Change-Id: I6f9805e20dc47307042842d4e472f8cb07421729
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/60/278760/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,ae88ccc5ec23dea57d1b0e8230742756a6c8991f,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,1,1
openstack%2Fzaqar~master~Ied5fa24fd973043eda643e09aac1d6c0f1500892,openstack/zaqar,master,Ied5fa24fd973043eda643e09aac1d6c0f1500892,Add queue name to notifications,MERGED,2016-02-02 06:30:29.000000000,2016-02-15 20:57:33.000000000,2016-02-15 20:57:32.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 8846}, {'_account_id': 12321}, {'_account_id': 13995}, {'_account_id': 18683}]","[{'number': 1, 'created': '2016-02-02 06:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d99d692f1c5c4cfbb17e8979a4fc8772d5398b57', 'message': ""Add queue name to notifications.\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 2, 'created': '2016-02-05 18:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/bc26579c14a044b04ba41dd447a2c0ab8fdd62e2', 'message': ""Add queue name to notifications.\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 3, 'created': '2016-02-05 23:16:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6d99f04a095d9bb7d5eb14605ef29fb93057b781', 'message': ""Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 4, 'created': '2016-02-06 00:33:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a6dd99284602b371dd4c707b6f2fcd14ff754765', 'message': 'DNM: Message IDs in notifications(proof of concept)\n\nTiny proof of concept that it\'s possible to also include message ID to\neach notification without refactoring Zaqar much.\n\nPossible alternatives to this solution that I can think of:\n1. Generate message IDs in the transport layer using uuid.\n2. Rename our current pipeline to ""input storage layer pipeline"" and add\nadditional ""output storage layer pipeline"" where we could move our\nNotifierDriver.\n\nPS: I haven\'t updated the tests for this proof of concept, so they fail.\n\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}, {'number': 5, 'created': '2016-02-06 00:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0238f62d610a47a20b271907f20ae1b8bc50a28d', 'message': ""Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 6, 'created': '2016-02-09 05:32:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/27f8f8cdfd3288af983edc0ef354836f33a3b96b', 'message': ""Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 7, 'created': '2016-02-10 00:04:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/a1f21632aa08a7cfd8f603ad19ad6edb449f43f0', 'message': ""Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise. Example:\n{'body': 'somemessage', 'ttl': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it's very\ninconvenient.\n\nThis patch adds queue name to each notification.\n\nSince we only add a new field to json dictionary, this patch is backward\ncompatible.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n""}, {'number': 8, 'created': '2016-02-10 00:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/17b33b4e1b915f6a0c0a3c7c3eca485a712bd6d5', 'message': 'Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise. Example:\n{\'body\': \'somemessage\', \'ttl\': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nBecause for now subscribers will need to listen on many ports awaiting\nfor notifications from different subscriptions created for each queue,\nto know from which queue each notification was sent, but it\'s very\ninconvenient.\n\nThis patch adds queue name to each notification to make notifications\nlook like this:\n{\'body\': \'somemessage\', \'ttl\': 60, \'queue_name\': \'somequeue\'}\n\nSince we only add a new key to JSON dictionary, this patch is backward\ncompatible.\n\nThis patch adds new test case ""test_proper_notification_data"".\nIt also modifies ""test_mailto"" and ""test_webhook"" test cases, so they\nconsider undeterministic behavior of ""json.dumps"" function, which\noften serializes dictionaries in different order, making test assertions\nsometimes fail.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}, {'number': 9, 'created': '2016-02-10 02:10:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/c73a90a91a8565c080d90d2e1599bd7fcf308d5f', 'message': 'Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise and simply represent\nmessages. Example:\n{\'body\': \'somemessage\', \'ttl\': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nThe only option for subscribers to know from which queue each\nnotification was sent is to listen on many ports, and make each port\ncorrespond to each particular queue, but it\'s very inconvenient.\n\nThis patch adds queue name to each notification to make notifications\nlook like this:\n{\'body\': \'somemessage\', \'ttl\': 60, \'queue_name\': \'somequeue\'}\n\nSince we only add a new key to JSON dictionary, this patch is backward\ncompatible.\n\nThis patch adds new test case ""test_proper_notification_data"".\nIt also modifies ""test_mailto"" and ""test_webhook"" test cases, so they\nconsider undeterministic behavior of ""json.dumps"" function, which\noften serializes dictionaries in different order, making test assertions\nsometimes fail.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}, {'number': 10, 'created': '2016-02-10 02:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6c57dec70f6e083794378a4625849133a10b9668', 'message': 'Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise and simply represent\nmessages. Example:\n{\'body\': \'somemessage\', \'ttl\': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nThe only option for subscribers to know from which queue each\nnotification was sent is to listen on many ports, and make each port\ncorrespond to each particular queue, but it\'s very inconvenient.\n\nThis patch adds queue name to each notification to make notifications\nlook like this:\n{\'body\': \'somemessage\', \'ttl\': 60, \'queue_name\': \'somequeue\'}\n\nSince we only add a new key to JSON dictionary, this patch is backward\ncompatible.\n\nThis patch adds new test case ""test_proper_notification_data"".\nIt also modifies ""test_mailto"" and ""test_webhook"" test cases, so they\nconsider undeterministic behavior of ""json.dumps"" function, which\noften serializes dictionaries in different order, making test assertions\nsometimes fail.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}, {'number': 11, 'created': '2016-02-10 02:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/aeeb0a51065000b7160d4ac69664619d7080a48b', 'message': 'Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise and simply represent\nmessages. Example:\n{\'body\': \'somemessage\', \'ttl\': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nThe only option for subscribers to know from which queue each\nnotification was sent is to listen on many ports, and make each port\ncorrespond to each particular queue, but it\'s very inconvenient.\n\nThis patch adds queue name to each notification to make notifications\nlook like this:\n{\'body\': \'somemessage\', \'ttl\': 60, \'queue_name\': \'somequeue\'}\n\nSince we only add a new key to JSON dictionary, this patch is backward\ncompatible.\n\nThis patch adds new test case ""test_proper_notification_data"".\nIt also modifies ""test_mailto"" and ""test_webhook"" test cases, so they\nconsider undeterministic behavior of ""json.dumps"" function, which\noften serializes dictionaries in different order, making test assertions\nsometimes fail.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}, {'number': 12, 'created': '2016-02-10 21:02:40.000000000', 'files': ['zaqar/tests/unit/notification/test_notifier.py', 'zaqar/notification/task/webhook.py', 'zaqar/notification/task/mailto.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1a0e8e719ad9948c4e7c60eabc980f36960e1446', 'message': 'Add queue name to notifications\n\nCurrently notifications from Zaqar are very consise and simply represent\nmessages. Example:\n{\'body\': \'somemessage\', \'ttl\': 60}\n\nBut subscribers are likely to want queue information inside\nnotifications, if they subscribe to multiple queues.\n\nThe only option for subscribers to know from which queue each\nnotification was sent is to listen on many ports, and make each port\ncorrespond to each particular queue, but it\'s very inconvenient.\n\nThis patch adds queue name to each notification to make notifications\nlook like this:\n{\'body\': \'somemessage\', \'ttl\': 60, \'queue_name\': \'somequeue\'}\n\nSince we only add a new key to JSON dictionary, this patch is backward\ncompatible.\n\nThis patch adds new test case ""test_proper_notification_data"".\nIt also modifies ""test_mailto"" and ""test_webhook"" test cases, so they\nconsider undeterministic behavior of ""json.dumps"" function, which\noften serializes dictionaries in different order, making test assertions\nsometimes fail.\n\nCloses-Bug: 1535811\nChange-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892\n'}]",6,275030,1a0e8e719ad9948c4e7c60eabc980f36960e1446,43,6,12,18683,,,0,"Add queue name to notifications

Currently notifications from Zaqar are very consise and simply represent
messages. Example:
{'body': 'somemessage', 'ttl': 60}

But subscribers are likely to want queue information inside
notifications, if they subscribe to multiple queues.

The only option for subscribers to know from which queue each
notification was sent is to listen on many ports, and make each port
correspond to each particular queue, but it's very inconvenient.

This patch adds queue name to each notification to make notifications
look like this:
{'body': 'somemessage', 'ttl': 60, 'queue_name': 'somequeue'}

Since we only add a new key to JSON dictionary, this patch is backward
compatible.

This patch adds new test case ""test_proper_notification_data"".
It also modifies ""test_mailto"" and ""test_webhook"" test cases, so they
consider undeterministic behavior of ""json.dumps"" function, which
often serializes dictionaries in different order, making test assertions
sometimes fail.

Closes-Bug: 1535811
Change-Id: Ied5fa24fd973043eda643e09aac1d6c0f1500892
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/30/275030/12 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/tests/unit/notification/test_notifier.py', 'zaqar/notification/notifier.py']",2,d99d692f1c5c4cfbb17e8979a4fc8772d5398b57,bug/1535811, for message in messages: message['queue_name'] = queue_name,,32,5
openstack%2Fdiskimage-builder~master~Id27f0166bfb09d67200f337a5ffff2f2037b7c1c,openstack/diskimage-builder,master,Id27f0166bfb09d67200f337a5ffff2f2037b7c1c,Fix dpkg element for Ubuntu Xenial,MERGED,2016-02-10 20:40:35.000000000,2016-02-15 20:57:20.000000000,2016-02-15 20:33:35.000000000,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 10035}]","[{'number': 1, 'created': '2016-02-10 20:40:35.000000000', 'files': ['elements/dpkg/root.d/60-block-apt-translations'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a9b38d0b6031db2636458d5c56609228e293ee4d', 'message': ""Fix dpkg element for Ubuntu Xenial\n\nThe Ubuntu Xenial cloud server images set the mode of\n/var/lib/apt/lists/partial to 700, so when mounted it's inaccessible to\nan unprivileged user, resulting in an error:\n\n  find: `/tmp/image.aDQKdkRi/mnt/var/lib/apt/lists/partial': Permission denied\n\nThere's no reason an image should come with anything already in\n/var/lib/apt/lists/partial, so just avoid trying to descend into that\ndirectory when fixing the apt translations packages.\n\nChange-Id: Id27f0166bfb09d67200f337a5ffff2f2037b7c1c\n""}]",0,278617,a9b38d0b6031db2636458d5c56609228e293ee4d,28,3,1,8482,,,0,"Fix dpkg element for Ubuntu Xenial

The Ubuntu Xenial cloud server images set the mode of
/var/lib/apt/lists/partial to 700, so when mounted it's inaccessible to
an unprivileged user, resulting in an error:

  find: `/tmp/image.aDQKdkRi/mnt/var/lib/apt/lists/partial': Permission denied

There's no reason an image should come with anything already in
/var/lib/apt/lists/partial, so just avoid trying to descend into that
directory when fixing the apt translations packages.

Change-Id: Id27f0166bfb09d67200f337a5ffff2f2037b7c1c
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/17/278617/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/dpkg/root.d/60-block-apt-translations'],1,a9b38d0b6031db2636458d5c56609228e293ee4d,xenial,find $TARGET_ROOT/var/lib/apt/lists/ -path $TARGET_ROOT/var/lib/apt/lists/partial -prune -o -type f -name '*_i18n_Translation-*' -print -exec sudo rm -f {} +,find $TARGET_ROOT/var/lib/apt/lists/ -type f -name '*_i18n_Translation-*' -exec sudo rm -f {} +,1,1
openstack%2Fpython-openstackclient~master~Ief6ab17775c6d7e3bef58d9fa025d9dd520b7370,openstack/python-openstackclient,master,Ief6ab17775c6d7e3bef58d9fa025d9dd520b7370,Refactor security group functional tests,MERGED,2016-02-05 15:55:26.000000000,2016-02-15 20:46:51.000000000,2016-02-15 20:46:50.000000000,"[{'_account_id': 3}, {'_account_id': 6482}]","[{'number': 1, 'created': '2016-02-05 15:55:26.000000000', 'files': ['functional/tests/network/v2/test_security_group.py', 'functional/tests/network/v2/test_security_group_rule.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a83602341121ccd252a8eaaa390f387b5230cd75', 'message': 'Refactor security group functional tests\n\nMoved the functional tests for ""os security group"" and\n""os security group rule"" from the compute to the network\ndirectory to align with the refactoring to the commands.\n\nChange-Id: Ief6ab17775c6d7e3bef58d9fa025d9dd520b7370\nPartial-Bug: #1519511\nPartial-Bug: #1519512\nRelated-to: blueprint neutron-client\n'}]",0,276800,a83602341121ccd252a8eaaa390f387b5230cd75,6,2,1,8410,,,0,"Refactor security group functional tests

Moved the functional tests for ""os security group"" and
""os security group rule"" from the compute to the network
directory to align with the refactoring to the commands.

Change-Id: Ief6ab17775c6d7e3bef58d9fa025d9dd520b7370
Partial-Bug: #1519511
Partial-Bug: #1519512
Related-to: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/00/276800/1 && git format-patch -1 --stdout FETCH_HEAD,"['functional/tests/network/v2/test_security_group.py', 'functional/tests/network/v2/test_security_group_rule.py']",2,a83602341121ccd252a8eaaa390f387b5230cd75,bug/1519511,,,0,0
openstack%2Fheat~master~I583a349ae09ff492f7b9d6b1999b06d607f9ad0b,openstack/heat,master,I583a349ae09ff492f7b9d6b1999b06d607f9ad0b,Add router_external property to OS::Neutron::ProviderNet,ABANDONED,2016-01-26 18:30:10.000000000,2016-02-15 20:45:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 8289}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-01-26 18:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/453154addc53c39f6eb52b5859c5f350e28b8ada', 'message': 'Add router_external property to OS::Neutron::ProviderNet\n\nChange-Id: I583a349ae09ff492f7b9d6b1999b06d607f9ad0b\n'}, {'number': 2, 'created': '2016-01-26 21:15:12.000000000', 'files': ['heat/engine/resources/openstack/neutron/provider_net.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2ef735357b8e7ccc763c150d16c70d400e8e71f7', 'message': 'Add router_external property to OS::Neutron::ProviderNet\n\nChange-Id: I583a349ae09ff492f7b9d6b1999b06d607f9ad0b\n'}]",4,272687,2ef735357b8e7ccc763c150d16c70d400e8e71f7,10,4,2,12321,,,0,"Add router_external property to OS::Neutron::ProviderNet

Change-Id: I583a349ae09ff492f7b9d6b1999b06d607f9ad0b
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/272687/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/neutron/provider_net.py'],1,453154addc53c39f6eb52b5859c5f350e28b8ada,272687," PROVIDER_SEGMENTATION_ID, ADMIN_STATE_UP, SHARED, ROUTER_EXTERNAL, 'segmentation_id', 'admin_state_up', 'shared', 'router_external', ROUTER_EXTERNAL: properties.Schema( properties.Schema.BOOLEAN, _('Allow external router'), default=False, update_allowed=True ), def prepare_custom_properties(props): ProviderNet.prepare_provider_properties(props) ProviderNet.prepare_external_properties(props) @staticmethod @staticmethod def prepare_external_properties(props): if ProviderNet.ROUTER_EXTERNAL in props: if props.get(ProviderNet.ROUTER_EXTERNAL, False): props['router:external'] = props.pop(ProviderNet.ROUTER_EXTERNAL) else: props.pop(ProviderNet.ROUTER_EXTERNAL) ProviderNet.prepare_custom_properties(props) ProviderNet.prepare_custom_properties(prop_diff)"," PROVIDER_SEGMENTATION_ID, ADMIN_STATE_UP, SHARED, 'segmentation_id', 'admin_state_up', 'shared', ProviderNet.prepare_provider_properties(props) ProviderNet.prepare_provider_properties(prop_diff)",23,4
openstack%2Fneutron~master~Ia4557473c7e362f98a564475527b97ee6d0178f9,openstack/neutron,master,Ia4557473c7e362f98a564475527b97ee6d0178f9,L3 agent: log traceback on floating ip setup failure,MERGED,2016-02-15 12:45:55.000000000,2016-02-15 20:45:44.000000000,2016-02-15 19:05:03.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14212}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-15 12:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b3c8a36ec0a2d8e4f1eebc9196b6f67b9e0743ef', 'message': ""L3 agent: log traceback on floating ip setup failure\n\nCurrently l3 agent suppresses exception traceback and just\nraises new FloatingIpSetupException so it's impossible to see\nactual issue from logs.\nThe patch adds LOG.exception() to the exception handler before\nreraising.\n\nCloses-Bug: #1545695\nChange-Id: Ia4557473c7e362f98a564475527b97ee6d0178f9\n""}, {'number': 2, 'created': '2016-02-15 13:09:20.000000000', 'files': ['neutron/agent/l3/router_info.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3188b458fd29bbd7711277bc337c0dacbaab4b9e', 'message': ""L3 agent: log traceback on floating ip setup failure\n\nCurrently l3 agent suppresses exception traceback and just\nraises new FloatingIpSetupException so it's impossible to see\nactual issue from logs.\nThe patch adds LOG.exception() to the exception handler before\nreraising.\n\nCloses-Bug: #1545695\nChange-Id: Ia4557473c7e362f98a564475527b97ee6d0178f9\n""}]",4,280194,3188b458fd29bbd7711277bc337c0dacbaab4b9e,24,11,2,5948,,,0,"L3 agent: log traceback on floating ip setup failure

Currently l3 agent suppresses exception traceback and just
raises new FloatingIpSetupException so it's impossible to see
actual issue from logs.
The patch adds LOG.exception() to the exception handler before
reraising.

Closes-Bug: #1545695
Change-Id: Ia4557473c7e362f98a564475527b97ee6d0178f9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/280194/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3/router_info.py'],1,b3c8a36ec0a2d8e4f1eebc9196b6f67b9e0743ef,bug/1545695, msg = 'L3 agent failure to setup NAT for floating IPs' LOG.exception(_LE(msg)) raise n_exc.FloatingIpSetupException(msg) msg = 'L3 agent failure to setup floating IPs' LOG.exception(_LE(msg)) raise n_exc.FloatingIpSetupException(msg), raise n_exc.FloatingIpSetupException( 'L3 agent failure to setup NAT for floating IPs') raise n_exc.FloatingIpSetupException('L3 agent failure to setup ' 'floating IPs'),6,4
openstack%2Ftripleo-common~master~I3a6aafc680637b2ec379f206a731796c24d5c7bb,openstack/tripleo-common,master,I3a6aafc680637b2ec379f206a731796c24d5c7bb,Convenience methods in base model class,MERGED,2016-01-17 23:36:56.000000000,2016-02-15 20:36:42.000000000,2016-02-15 17:30:25.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 6928}, {'_account_id': 9553}, {'_account_id': 9712}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-01-17 23:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1d6f293cc0c5d6ff11046dba434ab643abe02023', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}, {'number': 2, 'created': '2016-01-17 23:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e446b5ad3d9267d736ad7add84dbe63f1333abe8', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}, {'number': 3, 'created': '2016-01-18 00:07:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b0a03b049f2be83ec023717545dd88ffed95be8e', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}, {'number': 4, 'created': '2016-01-21 21:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d6c86c5b0da6ec4d7d5383ec9f2574bd6a7813d9', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}, {'number': 5, 'created': '2016-02-09 21:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5425ae856bab9c7bc14f4e9e4027ec842f3270a6', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}, {'number': 6, 'created': '2016-02-15 17:21:17.000000000', 'files': ['tripleo_common/core/models.py', 'tripleo_common/tests/core/test_models.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cd2dcd199a5c6b7c7f15d2fc5b93210c3ca3e5a4', 'message': 'Convenience methods in base model class\n\nThis change adds a BaseModel type which Plan inherits from along with\nimplementations of __eq__ and __repr__ to assist with testing and\ndebugging.\n\nThe __repr__ is a compact yaml representation which starts with the\nclass name.\n\nThe __eq__ asserts the other is of the same type, and then compares the\nclass __dict__ (which includes the class attributes)\n\nChange-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb\n'}]",1,268821,cd2dcd199a5c6b7c7f15d2fc5b93210c3ca3e5a4,28,6,6,4571,,,0,"Convenience methods in base model class

This change adds a BaseModel type which Plan inherits from along with
implementations of __eq__ and __repr__ to assist with testing and
debugging.

The __repr__ is a compact yaml representation which starts with the
class name.

The __eq__ asserts the other is of the same type, and then compares the
class __dict__ (which includes the class attributes)

Change-Id: I3a6aafc680637b2ec379f206a731796c24d5c7bb
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/21/268821/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/core/models.py', 'tripleo_common/tests/core/test_models.py']",2,1d6f293cc0c5d6ff11046dba434ab643abe02023,bp/tripleo-manage-software-deployments,"import yaml def test_eq(self): self.assertEqual(Plan('foo'), Plan('foo')) self.assertNotEqual(Plan('bar'), Plan('foo')) self.assertNotEqual(Plan('bar'), None) self.assertNotEqual(Plan('bar'), object()) def test_repr(self): plan = Plan('foo') plan_str = str(plan) self.assertEqual({'Plan': { 'files': {}, 'name': 'foo', 'metadata': {} }}, yaml.safe_load(plan_str))",,31,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ia334ea481e17c1d35aa67c33729cac6570f48199,openstack/tripleo-heat-templates,stable/liberty,Ia334ea481e17c1d35aa67c33729cac6570f48199,Increase default Cinder LVM backing file to 10G,MERGED,2016-02-12 13:42:53.000000000,2016-02-15 20:35:36.000000000,2016-02-15 20:35:35.000000000,"[{'_account_id': 3}, {'_account_id': 6928}]","[{'number': 1, 'created': '2016-02-12 13:42:53.000000000', 'files': ['puppet/controller.yaml', 'overcloud.yaml', 'puppet/cinder-storage.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/de29c2d081f7a0543bfedc5ca136206816a31422', 'message': 'Increase default Cinder LVM backing file to 10G\n\nWe get false negatives from Tempest when the Cinder LVM backing\nfile runs out space. This change increases its default size to 10G,\nmatching devstack [1]\n\n1. https://github.com/openstack-dev/devstack/blob/master/stackrc#L649\n\nChange-Id: Ia334ea481e17c1d35aa67c33729cac6570f48199\n(cherry picked from commit c7645f35a419f4af66fda5110f5b5b7a8d0137cf)\n'}]",0,279539,de29c2d081f7a0543bfedc5ca136206816a31422,14,2,1,6796,,,0,"Increase default Cinder LVM backing file to 10G

We get false negatives from Tempest when the Cinder LVM backing
file runs out space. This change increases its default size to 10G,
matching devstack [1]

1. https://github.com/openstack-dev/devstack/blob/master/stackrc#L649

Change-Id: Ia334ea481e17c1d35aa67c33729cac6570f48199
(cherry picked from commit c7645f35a419f4af66fda5110f5b5b7a8d0137cf)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/279539/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/controller.yaml', 'overcloud.yaml', 'puppet/cinder-storage.yaml']",3,de29c2d081f7a0543bfedc5ca136206816a31422,cinder_lvm_loopback, default: 10280, default: 5000,3,3
openstack%2Fshade~master~Ie16206349c59f780d786bffe5db1992cfa6a002e,openstack/shade,master,Ie16206349c59f780d786bffe5db1992cfa6a002e,Prepare functional test subunit stream for collection,MERGED,2016-02-11 20:12:32.000000000,2016-02-15 20:32:26.000000000,2016-02-15 20:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6488}]","[{'number': 1, 'created': '2016-02-11 20:12:32.000000000', 'files': ['shade/tests/functional/hooks/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/shade/commit/d052121d6dd66ffd2b0d6ed56c20ed1a1c55afd8', 'message': ""Prepare functional test subunit stream for collection\n\nThis commit fixes an issue with the functional test jobs where the\nsubunit stream from the test run isn't archived. This prevents both\nthe testr_results.html file from containing test results, and also\nthe eventual collection of the test results into the subunit2sql db\n(when it's actually enabled for non-tempest jobs)\n\nChange-Id: Ie16206349c59f780d786bffe5db1992cfa6a002e\n""}]",0,279246,d052121d6dd66ffd2b0d6ed56c20ed1a1c55afd8,11,3,1,5196,,,0,"Prepare functional test subunit stream for collection

This commit fixes an issue with the functional test jobs where the
subunit stream from the test run isn't archived. This prevents both
the testr_results.html file from containing test results, and also
the eventual collection of the test results into the subunit2sql db
(when it's actually enabled for non-tempest jobs)

Change-Id: Ie16206349c59f780d786bffe5db1992cfa6a002e
",git fetch https://review.opendev.org/openstack/shade refs/changes/46/279246/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/functional/hooks/post_test_hook.sh'],1,d052121d6dd66ffd2b0d6ed56c20ed1a1c55afd8,(HEAD,sudo testr last --subunit > $WORKSPACE/tempest.subunit,,1,0
openstack%2Fcongress~master~I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2,openstack/congress,master,I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2,Migrate datasource_manager and tests to DSE2,MERGED,2016-02-09 00:37:41.000000000,2016-02-15 20:00:40.000000000,2016-02-15 20:00:40.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 8878}, {'_account_id': 18591}]","[{'number': 1, 'created': '2016-02-09 00:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/83e7f5bb3fef6b87f51d20869b0c8f805c33e623', 'message': 'Migrate datasource_manager and tests to DSE2\n\nCopied and modified the datasource manager tests\nand put them into tests2/managers.\n\nFor the manager to actually work, dseNode needs to support the\nregistering and unregistering of services while node is running.\n\nTo run the new tests:\nnosetests congress/tests2/\nOR\npython3 -m ""nose"" congress/tests2/\n\nPartial-Bug: #1541663\n\nChange-Id: I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2\n'}, {'number': 2, 'created': '2016-02-09 01:50:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/3e08b1f655258e756667ec1cb040111c5b240048', 'message': 'Migrate datasource_manager and tests to DSE2\n\nCopied and modified the datasource manager tests\nand put them into tests2/managers.\n\nFor the manager to actually work, dseNode needs to support the\nregistering and unregistering of services while node is running.\n\nTo run the new tests:\nnosetests congress/tests2/\nOR\npython3 -m ""nose"" congress/tests2/\n\nPartial-Bug: #1541663\n\nChange-Id: I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2\n'}, {'number': 3, 'created': '2016-02-09 19:45:44.000000000', 'files': ['congress/managers/datasource.py', 'congress/tests2/managers/__init__.py', 'congress/dse2/dse_node.py', 'congress/tests2/managers/test_datasource.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/4bda3be2a1dd6852474b41406c2ffe6724da906a', 'message': 'Migrate datasource_manager and tests to DSE2\n\nCopied and modified the datasource manager tests\nand put them into tests2/managers.\n\nFor the manager to actually work, dseNode needs to support the\nregistering and unregistering of services while node is running.\n\nTo run the new tests:\nnosetests congress/tests2/\nOR\npython3 -m ""nose"" congress/tests2/\n\nPartial-Bug: #1541663\n\nChange-Id: I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2\n'}]",1,277635,4bda3be2a1dd6852474b41406c2ffe6724da906a,15,4,3,18591,,,0,"Migrate datasource_manager and tests to DSE2

Copied and modified the datasource manager tests
and put them into tests2/managers.

For the manager to actually work, dseNode needs to support the
registering and unregistering of services while node is running.

To run the new tests:
nosetests congress/tests2/
OR
python3 -m ""nose"" congress/tests2/

Partial-Bug: #1541663

Change-Id: I749af21c5f4ed507c4d036ea2fc42373f0a3e4a2
",git fetch https://review.opendev.org/openstack/congress refs/changes/35/277635/3 && git format-patch -1 --stdout FETCH_HEAD,"['congress/managers/datasource.py', 'congress/dse2/dse_node.py']",2,83e7f5bb3fef6b87f51d20869b0c8f805c33e623,dse2-datasource_manager," # TODO(dse2): implement registering service after node start # TODO(dse2): implement unregistering def unregister_service(self, service, index=None): raise NotImplementedError ",,95,12
openstack%2Fcinder~master~I64cc8a6e1cfc5fbae253d81d35b5edd1a03887ac,openstack/cinder,master,I64cc8a6e1cfc5fbae253d81d35b5edd1a03887ac,Tests: Set volume listen port to test_service_listen_port,MERGED,2016-02-10 20:13:54.000000000,2016-02-15 19:56:22.000000000,2016-02-15 19:56:22.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 2759}, {'_account_id': 7002}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 17405}]","[{'number': 1, 'created': '2016-02-10 20:13:54.000000000', 'files': ['cinder/tests/unit/test_service.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0168056eb32f4830bf031bde132304f3cb64a85f', 'message': 'Tests: Set volume listen port to test_service_listen_port\n\nThese tests can fail with an error binding to port 8776.\nUsing the same setting used by other tests allows these\nto work reliably.\n\nChange-Id: I64cc8a6e1cfc5fbae253d81d35b5edd1a03887ac\n'}]",0,278594,0168056eb32f4830bf031bde132304f3cb64a85f,40,9,1,4523,,,0,"Tests: Set volume listen port to test_service_listen_port

These tests can fail with an error binding to port 8776.
Using the same setting used by other tests allows these
to work reliably.

Change-Id: I64cc8a6e1cfc5fbae253d81d35b5edd1a03887ac
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/278594/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_service.py'],1,0168056eb32f4830bf031bde132304f3cb64a85f,," self.override_config('osapi_volume_listen_port', CONF.test_service_listen_port) self.override_config('osapi_volume_listen_port', CONF.test_service_listen_port) self.override_config('osapi_volume_listen_port', CONF.test_service_listen_port)",,6,0
openstack%2Fshade~master~I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0,openstack/shade,master,I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0,granting and revoking privs to users and groups,MERGED,2016-01-16 01:39:44.000000000,2016-02-15 19:49:01.000000000,2016-02-15 19:49:01.000000000,"[{'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 6488}, {'_account_id': 8016}]","[{'number': 1, 'created': '2016-01-16 01:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0608c26eaec0e93bb8883b7e6d2ce68b299f0d60', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 2, 'created': '2016-01-17 05:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/aa72e8afff3a6c42c26a986a37304a8c31511fcd', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 3, 'created': '2016-01-17 06:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/708a8488978c5f59d8d29f8bac9835bf62b7cad5', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 4, 'created': '2016-01-17 06:54:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/330496f3f847900a6168422230e11a1b72f15230', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 5, 'created': '2016-01-17 07:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/2a18722980b082bb3adab61497d9817aa5bee9f7', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 6, 'created': '2016-01-17 10:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/9d17cd69e2933446b827e5a10c017f3c7794b80e', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 7, 'created': '2016-01-17 10:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/cc9cd8cacedd171bd996383ca9a9618abfd28f5d', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 8, 'created': '2016-01-17 10:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/75b9e805e189ed2a67e723ebf0d5e0a5d8188668', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 9, 'created': '2016-01-17 10:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/33f21f144d9dae5b28e2ff858ff55637d67267fb', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 10, 'created': '2016-01-18 05:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4e41ca94e1d0895bcdf96b4308b012d7a6e0f168', 'message': 'granting and revoking privs to users and groups\n\nI also added, list_roles_for_users so that I could check for the\nexistance of the role assignments for keystone v2.0.\n\nThe domain and groups are dropped for keystone v2, and project is not\nrequired for keystone v2.\n\nThis also does the logic, to make sure that the correct keystone path is\nfollowed for each type.\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 11, 'created': '2016-01-25 22:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/b3b7cd605bb3a8521a3529702984b3f63cf171bd', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 12, 'created': '2016-01-25 22:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/0668eac6867807d935f65c592b44c8cc927a80dd', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 13, 'created': '2016-01-25 23:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/d8458e72f522c0daba9ea49ca55cf0073aede1d0', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 14, 'created': '2016-01-25 23:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/3484110092a7b1898cd6d711520e3ce18fe7bb50', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 15, 'created': '2016-01-27 22:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4ae6c655662e622cb80d1512d1608aab05265ee9', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 16, 'created': '2016-02-03 15:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/791fdaa37102e5283311aa68d53fdebadcb13ee0', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 17, 'created': '2016-02-03 19:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/28982fc5508a8c53aafef6e972e6e9d9afa0978f', 'message': 'granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n'}, {'number': 18, 'created': '2016-02-03 20:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4d165614f92ad154bea222a6c4dcea4644b78712', 'message': ""granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nadd a test that makes sure domains that don't exist raise an error\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n""}, {'number': 19, 'created': '2016-02-03 22:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/53ab3096670fe1587deec7e39219917090af6310', 'message': ""granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nadd a test that makes sure domains that don't exist raise an error\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n""}, {'number': 20, 'created': '2016-02-03 22:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/92f483369140e8a5c5c99f39bbbdf4eb43bf44ed', 'message': ""granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nadd a test that makes sure domains that don't exist raise an error\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n""}, {'number': 21, 'created': '2016-02-03 23:02:01.000000000', 'files': ['releasenotes/notes/grant-revoke-assignments-231d3f9596a1ae75.yaml', 'shade/_utils.py', 'shade/operatorcloud.py', 'shade/tests/unit/test_role_assignment.py', 'shade/tests/fakes.py', 'shade/tests/functional/test_identity.py', 'shade/_tasks.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/e38eea3d8cf8e440832893548c77f9feec1bf7d2', 'message': ""granting and revoking privs to users and groups\n\nThe domain and groups are dropped for keystone v2.\n\nproject is required for keystone v2\n\nadd a test that makes sure domains that don't exist raise an error\n\nChange-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0\n""}]",33,268404,e38eea3d8cf8e440832893548c77f9feec1bf7d2,55,4,21,8016,,,0,"granting and revoking privs to users and groups

The domain and groups are dropped for keystone v2.

project is required for keystone v2

add a test that makes sure domains that don't exist raise an error

Change-Id: I3313690c0f0bbf0fcd9fe1db2e46dcd3fb6dd3d0
",git fetch https://review.opendev.org/openstack/shade refs/changes/04/268404/16 && git format-patch -1 --stdout FETCH_HEAD,"['shade/_utils.py', 'shade/operatorcloud.py', 'shade/_tasks.py']",3,0608c26eaec0e93bb8883b7e6d2ce68b299f0d60,role_assignments_v2,"class RoleAddUser(task_manager.Task): def main(self, client): return client.keystone_client.roles.add_user_role(**self.args) class RoleGrantUser(task_manager.Task): def main(self, client): return client.keystone_client.roles.grant(**self.args) class RoleRemoveUser(task_manager.Task): def main(self, client): return client.keystone_client.roles.remove_user_role(**self.args) class RoleRevokeUser(task_manager.Task): def main(self, client): return client.keystone_client.roles.revoke(**self.args) class RoleForUser(task_manager.Task): def main(self, client): return client.keystone_client.roles.roles_for_user(**self.args) ",,184,0
openstack%2Fproject-config~master~I863de2c3d5847e9c1943bb25e28b86a68871693f,openstack/project-config,master,I863de2c3d5847e9c1943bb25e28b86a68871693f,Fix constraints for requirements repo,MERGED,2016-02-15 19:15:41.000000000,2016-02-15 19:48:54.000000000,2016-02-15 19:48:54.000000000,"[{'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2016-02-15 19:15:41.000000000', 'files': ['jenkins/jobs/macros.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/5f7bd189e4a33cfa7467df743d0772892afb8f36', 'message': 'Fix constraints for requirements repo\n\nFix zuul-git-prep-upper-constraints to not copy a non-existing file. If\nrequirements repo is to be checked out REQS_DIR is an empty directory,\nand thus we need to special case it.\n\nNote that if we check out requirements repo, we can use the\nupper-constraints file from that checkout, so no need to copy anything\naround.\n\nChange-Id: I863de2c3d5847e9c1943bb25e28b86a68871693f\n'}]",0,280368,5f7bd189e4a33cfa7467df743d0772892afb8f36,6,2,1,6547,,,0,"Fix constraints for requirements repo

Fix zuul-git-prep-upper-constraints to not copy a non-existing file. If
requirements repo is to be checked out REQS_DIR is an empty directory,
and thus we need to special case it.

Note that if we check out requirements repo, we can use the
upper-constraints file from that checkout, so no need to copy anything
around.

Change-Id: I863de2c3d5847e9c1943bb25e28b86a68871693f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/68/280368/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/macros.yaml'],1,5f7bd189e4a33cfa7467df743d0772892afb8f36,fix-requirements," # REQS_DIR is not set for openstack/requirements and there's also # no need to copy in this case. if [[ ""$ZUUL_PROJECT"" != ""openstack/requirements"" ]]; then cp $REQS_DIR/upper-constraints.txt ./ fi", cp $REQS_DIR/upper-constraints.txt ./,5,1
openstack%2Fproject-config~master~I4782f0d36965a0edf1733021be100f0a79ab5534,openstack/project-config,master,I4782f0d36965a0edf1733021be100f0a79ab5534,Rework devstack-jobs templating,MERGED,2016-02-09 18:57:56.000000000,2016-02-15 19:35:22.000000000,2016-02-15 19:35:22.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-09 18:57:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a90d03d392bcbe967d48c08814ba5b7f852fc33e', 'message': 'Rework devstack-jobs templating\n\nCurrently devstack-jobs template creates jobs\ngate-X\nperiodic-X-master\nperiodic-X-liberty\nperiodic-X-kilo\ngate-X-liberty-nv\ngate-X-kilo-nv\ngate-X-kilo\ngate-X-liberty\n\nBut only a few of the jobs are used in periodic pipelines or in stable\nbranches for branchless tempest.\n\nCreate new job groups devstack-periodic-master-jobs and\ndevstack-stable-jobs that can be used for the periodic and stable\nbranches.\n\nThis reduces the number of generated jobs from 8744 to 8382.\n\nChange-Id: I4782f0d36965a0edf1733021be100f0a79ab5534\n'}, {'number': 2, 'created': '2016-02-12 18:33:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/908af2bbc827a0d29d3e795529b0d93625c7fe31', 'message': 'Rework devstack-jobs templating\n\nCurrently devstack-jobs template creates jobs\ngate-X\nperiodic-X-master\nperiodic-X-liberty\nperiodic-X-kilo\ngate-X-liberty-nv\ngate-X-kilo-nv\ngate-X-kilo\ngate-X-liberty\n\nBut only a few of the jobs are used in periodic pipelines or in stable\nbranches for branchless tempest.\n\nCreate new job groups devstack-periodic-master-jobs and\ndevstack-stable-jobs that can be used for the periodic and stable\nbranches.\n\nThis reduces the number of generated jobs from 8744 to 8382.\n\nChange-Id: I4782f0d36965a0edf1733021be100f0a79ab5534\n'}, {'number': 3, 'created': '2016-02-12 18:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e2917928ec80675376f911f254b15ac80b8c5013', 'message': 'Rework devstack-jobs templating\n\nCurrently devstack-jobs template creates jobs\ngate-X\nperiodic-X-master\nperiodic-X-liberty\nperiodic-X-kilo\ngate-X-liberty-nv\ngate-X-kilo-nv\ngate-X-kilo\ngate-X-liberty\n\nBut only a few of the jobs are used in periodic pipelines or in stable\nbranches for branchless tempest.\n\nCreate new job groups devstack-periodic-master-jobs and\ndevstack-stable-jobs that can be used for the periodic and stable\nbranches.\n\nThis reduces the number of generated jobs from 8744 to 8382.\n\nChange-Id: I4782f0d36965a0edf1733021be100f0a79ab5534\n'}, {'number': 4, 'created': '2016-02-12 20:08:36.000000000', 'files': ['jenkins/jobs/projects.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/081eaf5114b63f5b77d33362726484c9ed250271', 'message': 'Rework devstack-jobs templating\n\nCurrently devstack-jobs template creates jobs\ngate-X\nperiodic-X-master\nperiodic-X-liberty\nperiodic-X-kilo\ngate-X-liberty-nv\ngate-X-kilo-nv\ngate-X-kilo\ngate-X-liberty\n\nBut only a few of the jobs are used in periodic pipelines or in stable\nbranches for branchless tempest.\n\nCreate new job groups devstack-periodic-master-jobs and\ndevstack-stable-jobs that can be used for the periodic and stable\nbranches.\n\nThis reduces the number of generated jobs from 8744 to 8382.\n\nChange-Id: I4782f0d36965a0edf1733021be100f0a79ab5534\n'}]",0,278034,081eaf5114b63f5b77d33362726484c9ed250271,17,5,4,6547,,,0,"Rework devstack-jobs templating

Currently devstack-jobs template creates jobs
gate-X
periodic-X-master
periodic-X-liberty
periodic-X-kilo
gate-X-liberty-nv
gate-X-kilo-nv
gate-X-kilo
gate-X-liberty

But only a few of the jobs are used in periodic pipelines or in stable
branches for branchless tempest.

Create new job groups devstack-periodic-master-jobs and
devstack-stable-jobs that can be used for the periodic and stable
branches.

This reduces the number of generated jobs from 8744 to 8382.

Change-Id: I4782f0d36965a0edf1733021be100f0a79ab5534
",git fetch https://review.opendev.org/openstack/project-config refs/changes/34/278034/4 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'jenkins/jobs/devstack-gate.yaml']",2,a90d03d392bcbe967d48c08814ba5b7f852fc33e,cleanup-devstack,"# Jobs will get defined for master branch in the periodic pipeline. - job-group: name: devstack-periodic-master-jobs jobs: - '{pipeline}-tempest-dsvm-all{job-suffix}' - '{pipeline}-tempest-dsvm-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-non-admin{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-identity-v3-only-full{job-suffix}' - '{pipeline}-tempest-dsvm-stress{job-suffix}' # Jobs will get defined for stable branches in the periodic pipeline, and # for stable branches gate jobs. - job-group: name: devstack-stable-jobs jobs: - '{pipeline}-tempest-dsvm-full{job-suffix}' - '{pipeline}-tempest-dsvm-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full{job-suffix}' - '{pipeline}-tempest-dsvm-postgres-full{job-suffix}' # Jobs will get defined for gate queue.",,30,7
openstack%2Fneutron~master~If2b7a9c703ae2fcfdcffedac0528437281bb23e5,openstack/neutron,master,If2b7a9c703ae2fcfdcffedac0528437281bb23e5,Add necessary executable permission,MERGED,2016-02-15 07:30:04.000000000,2016-02-15 19:35:05.000000000,2016-02-15 19:35:04.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9681}]","[{'number': 1, 'created': '2016-02-15 07:30:04.000000000', 'files': ['tools/coding-checks.sh', 'tools/misc-sanity-checks.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3ad46e1c40c0be25195580afe755732a095feaa5', 'message': ""Add necessary executable permission\n\nSome files should be marked as executable, and this patch\njust 'chmod +x' to them.\n\nChange-Id: If2b7a9c703ae2fcfdcffedac0528437281bb23e5\n""}]",0,280084,3ad46e1c40c0be25195580afe755732a095feaa5,21,5,1,9581,,,0,"Add necessary executable permission

Some files should be marked as executable, and this patch
just 'chmod +x' to them.

Change-Id: If2b7a9c703ae2fcfdcffedac0528437281bb23e5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/84/280084/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/coding-checks.sh', 'tools/misc-sanity-checks.sh']",2,3ad46e1c40c0be25195580afe755732a095feaa5,add-executable,,,0,0
openstack%2Ftripleo-heat-templates~master~I16cc96b7ecddeeda07de45f50ffc6a880dabbba6,openstack/tripleo-heat-templates,master,I16cc96b7ecddeeda07de45f50ffc6a880dabbba6,Minor fixes to allow local docker registry usage,MERGED,2016-01-08 17:29:04.000000000,2016-02-15 19:24:01.000000000,2016-02-15 19:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3098}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 10419}]","[{'number': 1, 'created': '2016-01-08 17:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b4bf46f42357bb0d0a5bb084a281bfb88608c38c', 'message': 'Minor fixes to allow local docker registry usage\n\nChanged the heat-docker-agents namespace to use the namespacing\nspecified in the environment file, which reduces modifications required\non the user when using a local registry.\n\nChanged the start agents script to handle using a local registry both\nwith a namespace and without.\n\nChange-Id: I16cc96b7ecddeeda07de45f50ffc6a880dabbba6\n'}, {'number': 2, 'created': '2016-02-04 23:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1f423a6c0e9acd5cc26a6dd6184f1198f3d78165', 'message': 'Minor fixes to allow local docker registry usage\n\nChanged the heat-docker-agents namespace to use the namespacing\nspecified in the environment file, which reduces modifications required\non the user when using a local registry.\n\nChanged the start agents script to handle using a local registry both\nwith a namespace and without.\n\nChange-Id: I16cc96b7ecddeeda07de45f50ffc6a880dabbba6\n'}, {'number': 3, 'created': '2016-02-12 20:57:22.000000000', 'files': ['docker/firstboot/install_docker_agents.yaml', 'environments/docker.yaml', 'docker/firstboot/start_docker_agents.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/255f4fd69e6bdf8247bc2861fa830859fffbef33', 'message': 'Minor fixes to allow local docker registry usage\n\nChanged the heat-docker-agents namespace to use the namespacing\nspecified in the environment file, which reduces modifications required\non the user when using a local registry.\n\nChanged the start agents script to handle using a local registry both\nwith a namespace and without.\n\nChange-Id: I16cc96b7ecddeeda07de45f50ffc6a880dabbba6\n'}]",5,265366,255f4fd69e6bdf8247bc2861fa830859fffbef33,45,6,3,3098,,,0,"Minor fixes to allow local docker registry usage

Changed the heat-docker-agents namespace to use the namespacing
specified in the environment file, which reduces modifications required
on the user when using a local registry.

Changed the start agents script to handle using a local registry both
with a namespace and without.

Change-Id: I16cc96b7ecddeeda07de45f50ffc6a880dabbba6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/66/265366/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/firstboot/install_docker_agents.yaml', 'environments/docker.yaml', 'docker/firstboot/start_docker_agents.sh']",3,b4bf46f42357bb0d0a5bb084a281bfb88608c38c,," # if namespace is used with local registry, trim all namespacing trim_var=$docker_registry registry_host=""${trim_var%%/*}"" /bin/sed -i ""s/# INSECURE_REGISTRY='--insecure-registry'/INSECURE_REGISTRY='--insecure-registry $registry_host'/g"" /etc/sysconfig/docker"," /bin/sed -i ""s/# INSECURE_REGISTRY='--insecure-registry '/INSECURE_REGISTRY='--insecure-registry $docker_registry'/g"" /etc/sysconfig/docker",9,3
openstack%2Fmanila~master~I9bc99776fdc98a58d3be5b33750fa72a9467e21d,openstack/manila,master,I9bc99776fdc98a58d3be5b33750fa72a9467e21d,Change the extra specs '=' operator behavior.,ABANDONED,2016-02-15 17:45:20.000000000,2016-02-15 19:10:54.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-15 17:45:20.000000000', 'files': ['manila/scheduler/filters/extra_specs_ops.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/81e73606eae6ffad5c212c2c8aaec0eef79fcfe4', 'message': ""Change the extra specs '=' operator behavior.\n\nChange-Id: I9bc99776fdc98a58d3be5b33750fa72a9467e21d\nCloses-Bug: #1538243\n""}]",0,280341,81e73606eae6ffad5c212c2c8aaec0eef79fcfe4,3,1,1,19678,,,0,"Change the extra specs '=' operator behavior.

Change-Id: I9bc99776fdc98a58d3be5b33750fa72a9467e21d
Closes-Bug: #1538243
",git fetch https://review.opendev.org/openstack/manila refs/changes/41/280341/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/scheduler/filters/extra_specs_ops.py'],1,81e73606eae6ffad5c212c2c8aaec0eef79fcfe4,bug/1538243,"_op_methods = {'=': lambda x, y: x = y,","_op_methods = {'=': lambda x, y: float(x) >= float(y),",1,1
openstack%2Fcinder~master~Ie88abfa5849ef315daf77b0f423dc44515f9e7d8,openstack/cinder,master,Ie88abfa5849ef315daf77b0f423dc44515f9e7d8,Updated from global requirements,MERGED,2016-02-08 02:38:06.000000000,2016-02-15 19:08:37.000000000,2016-02-11 19:35:11.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16272}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-02-08 02:38:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/991561d065a3c9593609408c242761edeb761416', 'message': 'Updated from global requirements\n\nChange-Id: Ie88abfa5849ef315daf77b0f423dc44515f9e7d8\n'}, {'number': 2, 'created': '2016-02-10 21:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ef35ce80f12b4448a96c958d10c4c0c54e0a77c', 'message': 'Updated from global requirements\n\nChange-Id: Ie88abfa5849ef315daf77b0f423dc44515f9e7d8\n'}, {'number': 3, 'created': '2016-02-11 07:38:37.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3b95bbe9e098024cbf48a53b253414f351d4b616', 'message': 'Updated from global requirements\n\nChange-Id: Ie88abfa5849ef315daf77b0f423dc44515f9e7d8\n'}]",0,277228,3b95bbe9e098024cbf48a53b253414f351d4b616,123,43,3,11131,,,0,"Updated from global requirements

Change-Id: Ie88abfa5849ef315daf77b0f423dc44515f9e7d8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/28/277228/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,991561d065a3c9593609408c242761edeb761416,openstack/requirements,tempest-lib>=0.14.0 # Apache-2.0,tempest-lib>=0.13.0 # Apache-2.0,1,1
openstack%2Fswift~feature%2Fhummingbird~I4fdc252b18ccfdb0f061088db017239cd1a239b1,openstack/swift,feature/hummingbird,I4fdc252b18ccfdb0f061088db017239cd1a239b1,go: fix requests with Range header for 0-bytes files,MERGED,2016-01-30 07:40:54.000000000,2016-02-15 19:07:45.000000000,2016-02-15 19:07:45.000000000,"[{'_account_id': 3}, {'_account_id': 995}, {'_account_id': 13052}, {'_account_id': 16218}]","[{'number': 1, 'created': '2016-01-30 07:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9b44989931d4f8a51b1928790c4dc1af20cf279e', 'message': 'go: fix requests with Range header for 0-bytes files (DLO or special objects like links for example)\n\nChange-Id: I4fdc252b18ccfdb0f061088db017239cd1a239b1\n'}, {'number': 2, 'created': '2016-02-12 18:53:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e6769ee7e8f7ed7b6f6d42698cfd749b59a6c5fa', 'message': 'go: fix requests with Range header for 0-bytes files (DLO or special objects like links for example)\n\nChange-Id: I4fdc252b18ccfdb0f061088db017239cd1a239b1\n'}, {'number': 3, 'created': '2016-02-13 02:35:37.000000000', 'files': ['go/hummingbird/utils.go', 'go/hummingbird/utils_test.go'], 'web_link': 'https://opendev.org/openstack/swift/commit/eede3896019c7e9fd42aa60f0ce5ca3cef577b57', 'message': 'go: fix requests with Range header for 0-bytes files\n\n(DLO or special objects like links for example)\n\nThis time I really ported over the range logic from swift instead of\nimplementing the RFC and then trying to special-case in everywhere swift is\nwrong.\n\nChange-Id: I4fdc252b18ccfdb0f061088db017239cd1a239b1\n'}]",0,274331,eede3896019c7e9fd42aa60f0ce5ca3cef577b57,16,4,3,19548,,,0,"go: fix requests with Range header for 0-bytes files

(DLO or special objects like links for example)

This time I really ported over the range logic from swift instead of
implementing the RFC and then trying to special-case in everywhere swift is
wrong.

Change-Id: I4fdc252b18ccfdb0f061088db017239cd1a239b1
",git fetch https://review.opendev.org/openstack/swift refs/changes/31/274331/2 && git format-patch -1 --stdout FETCH_HEAD,"['go/hummingbird/utils.go', 'go/hummingbird/utils_test.go']",2,9b44989931d4f8a51b1928790c4dc1af20cf279e,stupidranges," func TestRange0Bytes(t *testing.T) { tests := []struct { rangeHeader string exError string exRanges []httpRange }{ {""bytes=-0"", ""Zero end with no begin"", nil}, {""bytes=0-1"", ""Begin bigger than file"", nil}, {""bytes=0-"", ""Begin bigger than file"", nil}, } for _, test := range tests { result, err := ParseRange(test.rangeHeader, 0) if test.rangeHeader == "" "" { assert.Nil(t, result) assert.Nil(t, err) continue } if test.exError == """" { assert.Nil(t, err) } else { assert.Equal(t, err.Error(), test.exError) } assert.Equal(t, len(result), len(test.exRanges)) for i, _ := range result { assert.Equal(t, test.exRanges[i], result[i]) } } }",,33,0
openstack%2Fneutron~master~I63dc5199c7560329e8df55a0fbf7855e92e49c31,openstack/neutron,master,I63dc5199c7560329e8df55a0fbf7855e92e49c31,Remove deprecation warnings,MERGED,2016-02-15 08:50:35.000000000,2016-02-15 19:07:21.000000000,2016-02-15 19:07:19.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 14323}, {'_account_id': 14605}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-15 08:50:35.000000000', 'files': ['neutron/extensions/bgp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d596ceef3bce77ac3cc4821bae046509af69b996', 'message': 'Remove deprecation warnings\n\n    ../neutron/extensions/bgp.py:113: DeprecationWarning: Using\n    function/method \'instance.ugettext()\' is deprecated: Builtin\n    _ translation function is deprecated in OpenStack; use the\n    function from _i18n module for your project.\n\n      message = _(""BGP speaker %(id)s could not be found."")\n\nTrivialFix\n\nChange-Id: I63dc5199c7560329e8df55a0fbf7855e92e49c31\n'}]",0,280109,d596ceef3bce77ac3cc4821bae046509af69b996,33,9,1,1653,,,0,"Remove deprecation warnings

    ../neutron/extensions/bgp.py:113: DeprecationWarning: Using
    function/method 'instance.ugettext()' is deprecated: Builtin
    _ translation function is deprecated in OpenStack; use the
    function from _i18n module for your project.

      message = _(""BGP speaker %(id)s could not be found."")

TrivialFix

Change-Id: I63dc5199c7560329e8df55a0fbf7855e92e49c31
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/280109/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/bgp.py'],1,d596ceef3bce77ac3cc4821bae046509af69b996,deprecated-bgp,from neutron._i18n import _,,1,0
openstack%2Foslo.messaging~master~I365414c541d895dcd49ebcd32c3a456a92c392d6,openstack/oslo.messaging,master,I365414c541d895dcd49ebcd32c3a456a92c392d6,rabbit: improvements to QoS,MERGED,2016-02-13 01:22:17.000000000,2016-02-15 18:58:47.000000000,2016-02-15 10:27:37.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 8601}]","[{'number': 1, 'created': '2016-02-13 01:22:17.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5954d2ad640f126706ad0165e367a2ef57d32722', 'message': ""rabbit: improvements to QoS\n\n- Don't call _set_qos from both ensure_connection and on_reconnection,\n  instead consolidate and only call from _set_current_channel\n\n- Only set QoS on PURPOSE_LISTEN connections.  It's a waste of a\n  roundtrip to call it on PURPOSE_SEND connections and slows things\n  down unnecessarily\n\n- Guard against rabbit_qos_prefetch_count being set to a negative\n  value\n\n- Tests, because we love them\n\nChange-Id: I365414c541d895dcd49ebcd32c3a456a92c392d6\n""}]",0,279834,5954d2ad640f126706ad0165e367a2ef57d32722,9,4,1,9257,,,0,"rabbit: improvements to QoS

- Don't call _set_qos from both ensure_connection and on_reconnection,
  instead consolidate and only call from _set_current_channel

- Only set QoS on PURPOSE_LISTEN connections.  It's a waste of a
  roundtrip to call it on PURPOSE_SEND connections and slows things
  down unnecessarily

- Guard against rabbit_qos_prefetch_count being set to a negative
  value

- Tests, because we love them

Change-Id: I365414c541d895dcd49ebcd32c3a456a92c392d6
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/34/279834/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,5954d2ad640f126706ad0165e367a2ef57d32722,qos-fixup, self.purpose = purpose if new_channel == self.channel: return if self.channel is not None: if (new_channel is not None and self.purpose == rpc_common.PURPOSE_LISTEN): self._set_qos(new_channel) if self.rabbit_qos_prefetch_count > 0:, self._set_qos(self.channel) self._set_qos(new_channel) if self.channel is not None and new_channel != self.channel: if self.rabbit_qos_prefetch_count != 0:,36,4
openstack%2Fhorizon~master~I564b5e8b35fb2e84c27374bcac8a49cb6262b058,openstack/horizon,master,I564b5e8b35fb2e84c27374bcac8a49cb6262b058,Fix exceptions_captured manager in i9n tests,MERGED,2016-02-12 15:46:23.000000000,2016-02-15 18:56:35.000000000,2016-02-15 18:56:35.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 9576}, {'_account_id': 9981}, {'_account_id': 12071}, {'_account_id': 12826}]","[{'number': 1, 'created': '2016-02-12 15:46:23.000000000', 'files': ['openstack_dashboard/test/integration_tests/helpers.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1f08df329da7561142757ac292fd426782f0608', 'message': ""Fix exceptions_captured manager in i9n tests\n\nRecently introduced manager handled only 'bad' failure scenarios when\nSelenium became non responsive and caused again cryptic failures for\nfailures that were perfectly reported before exceptions_captured\nintroduction. Now both kind of (responsive and non responsive\nSelenium) failures are addressed inside it.\n\nChange-Id: I564b5e8b35fb2e84c27374bcac8a49cb6262b058\nCloses-Bug: #1545042\n""}]",0,279614,d1f08df329da7561142757ac292fd426782f0608,7,8,1,8040,,,0,"Fix exceptions_captured manager in i9n tests

Recently introduced manager handled only 'bad' failure scenarios when
Selenium became non responsive and caused again cryptic failures for
failures that were perfectly reported before exceptions_captured
introduction. Now both kind of (responsive and non responsive
Selenium) failures are addressed inside it.

Change-Id: I564b5e8b35fb2e84c27374bcac8a49cb6262b058
Closes-Bug: #1545042
",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/279614/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/integration_tests/helpers.py'],1,d1f08df329da7561142757ac292fd426782f0608,bug/1545042," contents = [] try: yield contents contents.append(testtools.content.text_content(exc_traceback)) finally: self.addDetail(label, contents[0]) with self.exceptions_captured(""BrowserLog.text"") as contents: contents.append(testtools.content.Content( lambda: self._unwrap_browser_log(log))) with self.exceptions_captured(""PageHTMLSource.html"") as contents: contents.append(testtools.content.Content( lambda: pg_source)) with self.exceptions_captured(""Screenshot"") as contents: contents.append(testtools.content.text_content(filename))"," content = None try: yield content content = testtools.content.text_content(exc_traceback) finally: self.addDetail(label, content) with self.exceptions_captured(""BrowserLog.text"") as content: content = testtools.content.Content( # noqa lambda: self._unwrap_browser_log(log)) with self.exceptions_captured(""PageHTMLSource.html"") as content: content = testtools.content.Content( # noqa lambda: pg_source) with self.exceptions_captured(""Screenshot"") as content: content = testtools.content.text_content(filename) # noqa",12,12
openstack%2Fneutron~master~I8880bf9caa269b9183dba8f269760af76461bca1,openstack/neutron,master,I8880bf9caa269b9183dba8f269760af76461bca1,"Switch ""dsvm-functional:"" into same pattern as constraints",MERGED,2016-02-11 14:52:09.000000000,2016-02-15 18:56:10.000000000,2016-02-15 18:56:09.000000000,"[{'_account_id': 3}, {'_account_id': 4190}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 12612}, {'_account_id': 13290}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 19999}]","[{'number': 1, 'created': '2016-02-11 14:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c9369e4225d1525ed6bd2643853729bb28e20cb9', 'message': '[WIP] remove ""dsvm-functional:"" from commands\n\nChange-Id: I8880bf9caa269b9183dba8f269760af76461bca1\n'}, {'number': 2, 'created': '2016-02-11 18:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5582a0db1744c67033db4f67fb7c547af18e10a1', 'message': 'Remove ""dsvm-functional:"" from commands\n\nIn Ibdfc03f27450a5392acc276f98bfb464f9a0f663, the oslo team is\nadding some periodic jobs to run oslo.* from master against\nneutron\'s py27 and py34, this is done by extending the\nexisting tox targets. The presence of ""dsvm-functional:"" in\ncommands breaks the jobs.\n\nChange-Id: I8880bf9caa269b9183dba8f269760af76461bca1\n'}, {'number': 3, 'created': '2016-02-11 21:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/22437baa9cc843b80a2021dba672e5091b2e90a6', 'message': 'Switch ""dsvm-functional:"" into same pattern as constraints\n\nIn Ibdfc03f27450a5392acc276f98bfb464f9a0f663, the oslo team is\nadding some periodic jobs to run oslo.* from master against\nneutron\'s py27 and py34, this is done by extending the\nexisting tox targets. The presence of ""dsvm-functional:"" in\ncommands breaks the jobs.\n\nSo let\'s move the definition of the dsvm-functional: command\nto the [testenv:dsvm-functional] section and reuse that\ndefinition in the other sections instead of defining\ndsvm-function in the base testenv. This follows the same\npattern as sitepackages and deps in the [testenv:dsvm-functional-constraints]\nand [testenv:dsvm-functional-py34] sections.\n\nChange-Id: I8880bf9caa269b9183dba8f269760af76461bca1\n'}, {'number': 4, 'created': '2016-02-11 23:22:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/bc44321778f10f8b51dc8f297df400af32977f28', 'message': 'Switch ""dsvm-functional:"" into same pattern as constraints\n\nIn Ibdfc03f27450a5392acc276f98bfb464f9a0f663, the oslo team is\nadding some periodic jobs to run oslo.* from master against\nneutron\'s py27 and py34, this is done by extending the\nexisting tox targets. The presence of ""dsvm-functional:"" in\ncommands breaks the jobs.\n\nThe right way to fix this is to follow the same pattern\nas the constraints by defining it once in\n[testenv:dsvm-functional] and reusing it. However this will\nnot work as there is a bug in tox with posargs that Sachi just fixed:\nhttps://bitbucket.org/hpk42/tox/pull-requests/189/fix-section-substitution-with-posargs/diff\n\nSo until we have a version of tox in our CI images with that\nfix, we need to live with duplicate definitions.\n\nChange-Id: I8880bf9caa269b9183dba8f269760af76461bca1\n'}]",2,279117,bc44321778f10f8b51dc8f297df400af32977f28,50,19,4,5638,,,0,"Switch ""dsvm-functional:"" into same pattern as constraints

In Ibdfc03f27450a5392acc276f98bfb464f9a0f663, the oslo team is
adding some periodic jobs to run oslo.* from master against
neutron's py27 and py34, this is done by extending the
existing tox targets. The presence of ""dsvm-functional:"" in
commands breaks the jobs.

The right way to fix this is to follow the same pattern
as the constraints by defining it once in
[testenv:dsvm-functional] and reusing it. However this will
not work as there is a bug in tox with posargs that Sachi just fixed:
https://bitbucket.org/hpk42/tox/pull-requests/189/fix-section-substitution-with-posargs/diff

So until we have a version of tox in our CI images with that
fix, we need to live with duplicate definitions.

Change-Id: I8880bf9caa269b9183dba8f269760af76461bca1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/279117/4 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c9369e4225d1525ed6bd2643853729bb28e20cb9,, {toxinidir}/tools/deploy_rootwrap.sh {toxinidir} {envdir}/etc {envdir}/bin, dsvm-functional: {toxinidir}/tools/deploy_rootwrap.sh {toxinidir} {envdir}/etc {envdir}/bin,1,1
openstack%2Fproject-config~master~I87cb93411cbd07b214c3744bdc96045a2abb9a71,openstack/project-config,master,I87cb93411cbd07b214c3744bdc96045a2abb9a71,Switch to dnf for fedora,MERGED,2016-02-04 16:40:42.000000000,2016-02-15 18:53:45.000000000,2016-02-15 18:53:44.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-04 16:40:42.000000000', 'files': ['jenkins/scripts/install-distro-packages.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/25e7764edf1e17d37b7b8801ef2d788e68fd007e', 'message': 'Switch to dnf for fedora\n\nThis logic came from install_puppet.sh in system-config.\n\nChange-Id: I87cb93411cbd07b214c3744bdc96045a2abb9a71\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",1,276339,25e7764edf1e17d37b7b8801ef2d788e68fd007e,9,3,1,4162,,,0,"Switch to dnf for fedora

This logic came from install_puppet.sh in system-config.

Change-Id: I87cb93411cbd07b214c3744bdc96045a2abb9a71
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/39/276339/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/install-distro-packages.sh'],1,25e7764edf1e17d37b7b8801ef2d788e68fd007e,temp/dnf,"function is_fedora { [ -f /usr/bin/yum ] && cat /etc/*release | grep -q -e ""Fedora"" } YUM=yum if is_fedora; then YUM=dnf fi sudo PATH=/usr/sbin:/sbin:$PATH $YUM install -y \", sudo PATH=/usr/sbin:/sbin:$PATH yum install -y \,10,1
openstack%2Ffuel-qa~stable%2F8.0~Ia9c1b86847d99b2aa20f50a6b0e98c58d0e3b297,openstack/fuel-qa,stable/8.0,Ia9c1b86847d99b2aa20f50a6b0e98c58d0e3b297,Remove unnecessary argument from call to sync func,MERGED,2016-02-15 15:52:20.000000000,2016-02-15 18:52:38.000000000,2016-02-15 18:52:38.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-02-15 15:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/beb04d9b4125f99e198e7858a6cca2b575b91484', 'message': 'Remove unnecessary argument from call to sync func\n\nSince a patch https://review.openstack.org/#/c/276143\nwas merged to the stable 8.0 branch\nthis patch https://review.openstack.org/#/c/272593\nshould be removed.\n\nChange-Id: Ia9c1b86847d99b2aa20f50a6b0e98c58d0e3b297\n'}, {'number': 2, 'created': '2016-02-15 15:53:37.000000000', 'files': ['system_test/tests/actions_base.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/96abf6edeb89f1a6074411ec98901aa3e46cd89d', 'message': 'Remove unnecessary argument from call to sync func\n\nSince a patch https://review.openstack.org/#/c/276143\nwas merged to the stable 8.0 branch\nthis patch https://review.openstack.org/#/c/272593\nshould be removed.\n\nCloses-Bug:1543125\nChange-Id: Ia9c1b86847d99b2aa20f50a6b0e98c58d0e3b297\n'}]",0,280298,96abf6edeb89f1a6074411ec98901aa3e46cd89d,15,8,2,14057,,,0,"Remove unnecessary argument from call to sync func

Since a patch https://review.openstack.org/#/c/276143
was merged to the stable 8.0 branch
this patch https://review.openstack.org/#/c/272593
should be removed.

Closes-Bug:1543125
Change-Id: Ia9c1b86847d99b2aa20f50a6b0e98c58d0e3b297
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/98/280298/2 && git format-patch -1 --stdout FETCH_HEAD,['system_test/tests/actions_base.py'],1,beb04d9b4125f99e198e7858a6cca2b575b91484,bug/1543125, self.env.sync_time(), self.env.sync_time( self.fuel_web.client.list_cluster_nodes(self.cluster_id)),1,2
openstack%2Fnova~stable%2Fliberty~I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1,openstack/nova,stable/liberty,I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1,XenAPI: Cope with more Cinder backends,MERGED,2016-01-26 18:49:16.000000000,2016-02-15 18:50:58.000000000,2016-02-15 18:50:56.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6735}, {'_account_id': 6873}, {'_account_id': 7244}, {'_account_id': 9008}, {'_account_id': 12898}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-01-26 18:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d7bcaa801f72ef60c24116f80d2290145090bbc', 'message': ""XenAPI: Cope with more Cinder backends\n\nSome Cinder backends (e.g. storwize 7000) expose multiple LUNs for a single\nSR connection from the XenServer host.  Since the SR UUID was based on the\n'volume' ID, which is unique per volume, multiple SRs would be connecting\nto the same array when multiple volumes are exposed.\n\nThis fixes the issue by making sure that we only connect to the array once\nfor each (host,port,IQN) tuple, and we can re-use the SR for as many LUNs\nare presented.\n\nChange-Id: I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1\nCloses-Bug: 1515672\n(cherry picked from commit 5bd222e8d854ca7f03ee6936454ee57e0d6e1a78)\n""}, {'number': 2, 'created': '2016-02-04 14:48:33.000000000', 'files': ['nova/tests/unit/virt/xenapi/test_volume_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/virt/xenapi/volume_utils.py', 'nova/tests/unit/virt/xenapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/deacf0efefcd9c0eaa99bf0b1836504d84c6800b', 'message': ""XenAPI: Cope with more Cinder backends\n\nSome Cinder backends (e.g. storwize 7000) expose multiple LUNs for a single\nSR connection from the XenServer host.  Since the SR UUID was based on the\n'volume' ID, which is unique per volume, multiple SRs would be connecting\nto the same array when multiple volumes are exposed.\n\nThis fixes the issue by making sure that we only connect to the array once\nfor each (host,port,IQN) tuple, and we can re-use the SR for as many LUNs\nare presented.\n\nChange-Id: I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1\nCloses-Bug: 1515672\n(cherry picked from commit 5bd222e8d854ca7f03ee6936454ee57e0d6e1a78)\n""}]",0,272695,deacf0efefcd9c0eaa99bf0b1836504d84c6800b,31,8,2,161,,,0,"XenAPI: Cope with more Cinder backends

Some Cinder backends (e.g. storwize 7000) expose multiple LUNs for a single
SR connection from the XenServer host.  Since the SR UUID was based on the
'volume' ID, which is unique per volume, multiple SRs would be connecting
to the same array when multiple volumes are exposed.

This fixes the issue by making sure that we only connect to the array once
for each (host,port,IQN) tuple, and we can re-use the SR for as many LUNs
are presented.

Change-Id: I6a1eb22fcfde8e3f5c069be54f5e7c91b0f2fec1
Closes-Bug: 1515672
(cherry picked from commit 5bd222e8d854ca7f03ee6936454ee57e0d6e1a78)
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/272695/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/xenapi/test_volume_utils.py', 'nova/virt/xenapi/vmops.py', 'nova/virt/xenapi/volume_utils.py', 'nova/tests/unit/virt/xenapi/test_vmops.py']",4,1d7bcaa801f72ef60c24116f80d2290145090bbc,bug/1515672,"import uuid def test_no_vm_orphaned_volume_old_sr(self, forget_sr, find_sr_by_uuid, @mock.patch.object(vm_utils, 'lookup', side_effect=[None, None]) @mock.patch.object(vm_utils, 'hard_shutdown_vm') @mock.patch.object(volume_utils, 'find_sr_by_uuid', side_effect=[None, 'sr_ref']) @mock.patch.object(volume_utils, 'forget_sr') @mock.patch.object(uuid, 'uuid5', return_value='fake-uuid') def test_no_vm_orphaned_volume(self, uuid5, forget_sr, find_sr_by_uuid, hard_shutdown_vm, lookup): fake_data = {'volume_id': 'fake-uuid', 'target_portal': 'host:port', 'target_iqn': 'iqn'} self.vmops.destroy(self.instance, 'network_info', {'block_device_mapping': [{'connection_info': {'data': fake_data}}]}) call1 = mock.call(self.vmops._session, 'FA15E-D15C-fake-uuid') call2 = mock.call(self.vmops._session, 'fake-uuid') uuid5.assert_called_once_with(volume_utils.SR_NAMESPACE, 'host/port/iqn') find_sr_by_uuid.assert_has_calls([call1, call2]) forget_sr.assert_called_once_with(self.vmops._session, 'sr_ref') self.assertEqual(0, hard_shutdown_vm.call_count) "," def test_no_vm_orphaned_volume(self, forget_sr, find_sr_by_uuid,",104,9
openstack%2Fproject-config~master~I2a82336ee89f203e5f6e51bdbffff0f988950531,openstack/project-config,master,I2a82336ee89f203e5f6e51bdbffff0f988950531,Enable windmill-jobs for all ansible-roles,MERGED,2016-02-11 23:17:07.000000000,2016-02-15 18:50:01.000000000,2016-02-15 18:50:01.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-11 23:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4ffe3624982577c642121fa8f63f1be68ea9b670', 'message': 'Enable windmill-jobs for all ansible-roles\n\nThese are currently non-voting jobs, but now can be run across all\nansible-roles projects and windmill includes all of them.\n\nChange-Id: I2a82336ee89f203e5f6e51bdbffff0f988950531\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}, {'number': 2, 'created': '2016-02-15 15:37:22.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/62d032f08b110749eb7c00929f05b57f00b81129', 'message': 'Enable windmill-jobs for all ansible-roles\n\nThese are currently non-voting jobs, but now can be run across all\nansible-roles projects and windmill includes all of them.\n\nChange-Id: I2a82336ee89f203e5f6e51bdbffff0f988950531\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,279308,62d032f08b110749eb7c00929f05b57f00b81129,12,3,2,4162,,,0,"Enable windmill-jobs for all ansible-roles

These are currently non-voting jobs, but now can be run across all
ansible-roles projects and windmill includes all of them.

Change-Id: I2a82336ee89f203e5f6e51bdbffff0f988950531
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/08/279308/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,4ffe3624982577c642121fa8f63f1be68ea9b670,temp/gate-windmill, - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv - name: windmill-jobs-centos7-nv - name: windmill-jobs-trusty-nv,,12,0
openstack%2Fproject-config~master~I5ee507ca5981917b3059cacca2234f5c81ce558e,openstack/project-config,master,I5ee507ca5981917b3059cacca2234f5c81ce558e,Import ansible-role-nginx,MERGED,2016-02-11 14:34:56.000000000,2016-02-15 18:49:53.000000000,2016-02-15 18:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 11809}]","[{'number': 1, 'created': '2016-02-11 14:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cd626596c131f49936dfac35c5d063c1844a0d52', 'message': ""Import ansible-role-nginx\n\nHere we'll be import a role to manage nginx.  We currently use nginx\nas the frontend webserver to jenkins.\n\nWe've enabled IRC notification for the windmill channel and gate\ntests.\n\nChange-Id: I5ee507ca5981917b3059cacca2234f5c81ce558e\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}, {'number': 2, 'created': '2016-02-15 15:36:36.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/ansible-role-nginx.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1e8249bd217c8484acfbe66ebb6834ad642a5be1', 'message': ""Import ansible-role-nginx\n\nHere we'll be import a role to manage nginx.  We currently use nginx\nas the frontend webserver to jenkins.\n\nWe've enabled IRC notification for the windmill channel and gate\ntests.\n\nChange-Id: I5ee507ca5981917b3059cacca2234f5c81ce558e\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,279101,1e8249bd217c8484acfbe66ebb6834ad642a5be1,17,4,2,4162,,,0,"Import ansible-role-nginx

Here we'll be import a role to manage nginx.  We currently use nginx
as the frontend webserver to jenkins.

We've enabled IRC notification for the windmill channel and gate
tests.

Change-Id: I5ee507ca5981917b3059cacca2234f5c81ce558e
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/01/279101/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack/ansible-role-nginx.config', 'zuul/layout.yaml']",5,cd626596c131f49936dfac35c5d063c1844a0d52,temp/ansible-role-nginx, - name: openstack/ansible-role-nginx template: - name: merge-check - name: ansible-role-jobs - name: ansible-role-functional-jobs-centos7-nv - name: ansible-role-functional-jobs-trusty-nv - name: docs-on-rtfd ,,35,0
openstack%2Fnova~master~Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6,openstack/nova,master,Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6,Use instance hostname for Neutron DNS unit tests,MERGED,2016-02-08 07:29:24.000000000,2016-02-15 18:33:38.000000000,2016-02-15 15:08:29.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 4694}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-08 07:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0a0b86e28c6b43573a4799726c2fddf127c30e4', 'message': 'Use instance hostname for Neutron DNS unit tests\n\nAdds  units tests for the changes made to the Neutron API to use the instance\nhostname for Neutron. Also some comments are fixed.\n\nChange-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6\nImplements: blueprint neutron-hostname-dns\n'}, {'number': 2, 'created': '2016-02-10 01:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b564586d766ed07b9f730b8112143875767e4e9e', 'message': 'Use instance hostname for Neutron DNS unit tests\n\nAdds  units tests for the changes made to the Neutron API to use the instance\nhostname for Neutron. Also some comments are fixed.\n\nChange-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6\nImplements: blueprint neutron-hostname-dns\n'}, {'number': 3, 'created': '2016-02-11 00:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b8ed33519449f30446b3d3cd8cdb4a07d0c0a3ca', 'message': 'Use instance hostname for Neutron DNS unit tests\n\nAdds  units tests for the changes made to the Neutron API to use the instance\nhostname for Neutron. Also, a release note is added and some comments are\nfixed.\n\nChange-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6\nImplements: blueprint neutron-hostname-dns\n'}, {'number': 4, 'created': '2016-02-11 00:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/169863b25fc7e1046a797719e1f07da5b341eae0', 'message': 'Use instance hostname for Neutron DNS unit tests\n\nAdds  units tests for the changes made to the Neutron API to use the instance\nhostname for Neutron. Also, a release note is added and some comments are\nfixed.\n\nChange-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6\nImplements: blueprint neutron-hostname-dns\n'}, {'number': 5, 'created': '2016-02-15 11:49:15.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'releasenotes/notes/instance-hostname-used-to-populate-ports-dns-name-08341ec73dc076c0.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/997d8f516cee99b4e16429d13ca5cf7fc05166aa', 'message': 'Use instance hostname for Neutron DNS unit tests\n\nAdds  units tests for the changes made to the Neutron API to use the instance\nhostname for Neutron. Also, a release note is added and some comments are\nfixed.\n\nChange-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6\nImplements: blueprint neutron-hostname-dns\n'}]",1,277302,997d8f516cee99b4e16429d13ca5cf7fc05166aa,60,15,5,4694,,,0,"Use instance hostname for Neutron DNS unit tests

Adds  units tests for the changes made to the Neutron API to use the instance
hostname for Neutron. Also, a release note is added and some comments are
fixed.

Change-Id: Ie74cb5ee71ea464d0863b14577c7dc2c9b534cf6
Implements: blueprint neutron-hostname-dns
",git fetch https://review.opendev.org/openstack/nova refs/changes/02/277302/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/tests/unit/network/test_neutronv2.py']",2,a0a0b86e28c6b43573a4799726c2fddf127c30e4,bp/neutron-hostname-dns," 'hostname': 'test-instance', has_dns_extension = False if kwargs.get('dns_extension'): has_dns_extension = True api.extensions[constants.DNS_INTEGRATION] = 1 elif has_dns_extension: self.mox.StubOutWithMock(api, '_refresh_neutron_extensions_cache') api._refresh_neutron_extensions_cache(mox.IgnoreArg(), neutron=self.moxed_client) '', 'dns_name': kwargs.get('_dns_name') or ''}}) if has_dns_extension: port_req_body['port']['dns_name'] = self.instance.hostname if not has_portbinding and not has_dns_extension: elif has_portbinding: else: api._refresh_neutron_extensions_cache(mox.IgnoreArg(), neutron=self.moxed_client) if has_portbinding and has_dns_extension: api._has_port_binding_extension(mox.IgnoreArg()).\ AndReturn(has_portbinding)class TestNeutronv2NeutronHostnameDNS(TestNeutronv2Base): def setUp(self): super(TestNeutronv2NeutronHostnameDNS, self).setUp() neutronapi.get_client(mox.IgnoreArg()).MultipleTimes().AndReturn( self.moxed_client) def test_allocate_for_instance_create_port(self): self._allocate_for_instance(1, dns_extension=True) def test_allocate_for_instance_with_requested_port(self): requested_networks = objects.NetworkRequestList( objects=[objects.NetworkRequest(port_id='my_portid1')]) self._allocate_for_instance(net_idx=1, dns_extension=True, requested_networks=requested_networks) def test_allocate_for_instance_port_dns_name_preset_equal_hostname(self): requested_networks = objects.NetworkRequestList( objects=[objects.NetworkRequest(port_id='my_portid1')]) self._allocate_for_instance(net_idx=1, dns_extension=True, requested_networks=requested_networks, _dns_name='test-instance') def test_allocate_for_instance_port_dns_name_preset_noteq_hostname(self): # If a pre-existing port has dns_name set, an exception should be # raised. requested_networks = objects.NetworkRequestList( objects=[objects.NetworkRequest(port_id='my_portid1')]) api = self._stub_allocate_for_instance( requested_networks=requested_networks, dns_extension=True, _break='pre_list_networks', _dns_name='my-instance') self.assertRaises(exception.PortNotUsableDNS, api.allocate_for_instance, self.context, self.instance, requested_networks=requested_networks) class TestNeutronv2NeutronHostnameDNSPortbinding(TestNeutronv2Base): def test_allocate_for_instance_portbinding(self): self._allocate_for_instance(1, portbinding=True, dns_extension=True, bind_host_id=self.instance.get('host')) ", ''}}) if not has_portbinding: else:,70,5
openstack%2Fhorizon~master~Id5a7063f62cde52050bdca01b99a8de13bcd8fd7,openstack/horizon,master,Id5a7063f62cde52050bdca01b99a8de13bcd8fd7,Renaming hzTable to hzTableHelper,ABANDONED,2016-02-10 19:43:06.000000000,2016-02-15 18:29:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12071}]","[{'number': 1, 'created': '2016-02-10 19:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/557cacbb60210bc97f5bfb766c86eb867a376779', 'message': 'Renaming hzTable to hzTableHelper\n\nOriginally the hzTable directive extended the Smart-Table module\nto provide support for checkboxes and sorting.\n\nWriting a table directive in another patch that will allow us to generate\nthe table HTML content given the data and column definition, so we want to use the\nhzTable namespace for that.\n\nChange-Id: Id5a7063f62cde52050bdca01b99a8de13bcd8fd7\nCloses-Bug: #1544248\n'}, {'number': 2, 'created': '2016-02-10 19:44:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/68f69802cd14d0c4feba3f2ba58734af9b695647', 'message': 'WIP Renaming hzTable to hzTableHelper\n\nOriginally the hzTable directive extended the Smart-Table module\nto provide support for checkboxes and sorting.\n\nWriting a table directive in another patch that will allow us to generate\nthe table HTML content given the data and column definition, so we want to use the\nhzTable namespace for that.\n\nChange-Id: Id5a7063f62cde52050bdca01b99a8de13bcd8fd7\nCloses-Bug: #1544248\n'}, {'number': 3, 'created': '2016-02-10 19:48:50.000000000', 'files': ['openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'horizon/static/framework/widgets/table/table.controller.js', 'horizon/static/framework/widgets/table/hz-select-all.directive.js', 'horizon/static/framework/widgets/table/hz-table-helper.directive.js', 'horizon/static/framework/widgets/table/hz-no-items.directive.js', 'openstack_dashboard/enabled/_3031_identity_users_panel.py', 'horizon/static/framework/widgets/table/hz-select.directive.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7c1e946dcd7cd78f7f8b28b504ba69627bdc7e01', 'message': 'Renaming hzTable to hzTableHelper\n\nOriginally the hzTable directive extended the Smart-Table module\nto provide support for checkboxes and sorting.\n\nWriting a table directive in another patch that will allow us to generate\nthe table HTML content given the data and column definition, so we want to use the\nhzTable namespace for that.\n\nChange-Id: Id5a7063f62cde52050bdca01b99a8de13bcd8fd7\nCloses-Bug: #1544248\n'}]",0,278581,7c1e946dcd7cd78f7f8b28b504ba69627bdc7e01,9,5,3,9622,,,0,"Renaming hzTable to hzTableHelper

Originally the hzTable directive extended the Smart-Table module
to provide support for checkboxes and sorting.

Writing a table directive in another patch that will allow us to generate
the table HTML content given the data and column definition, so we want to use the
hzTable namespace for that.

Change-Id: Id5a7063f62cde52050bdca01b99a8de13bcd8fd7
Closes-Bug: #1544248
",git fetch https://review.opendev.org/openstack/horizon refs/changes/81/278581/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/table/table.controller.js', 'openstack_dashboard/dashboards/project/static/dashboard/project/workflow/launch-instance/source/source.html', 'horizon/static/framework/widgets/table/hz-select-all.directive.js', 'horizon/static/framework/widgets/table/hz-table-helper.directive.js', 'horizon/static/framework/widgets/table/hz-no-items.directive.js', 'openstack_dashboard/enabled/_3031_identity_users_panel.py', 'horizon/static/framework/widgets/table/hz-select.directive.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/users/table/table.html']",8,557cacbb60210bc97f5bfb766c86eb867a376779,bug/1544248," hz-table-helper ng-cloak <span class=""fa fa-chevron-right"" duration=""200""></span>"," hz-table ng-cloak <span class=""fa fa-chevron-right"" hz-expand-detail duration=""200""></span>",17,17
openstack%2Fsecurity-doc~master~Ifcdae51e7aec2f68727d88bdfd8b46c42576f264,openstack/security-doc,master,Ifcdae51e7aec2f68727d88bdfd8b46c42576f264,Updated outdated link in Introduction,MERGED,2016-02-12 15:44:48.000000000,2016-02-15 18:17:06.000000000,2016-02-15 18:17:06.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 12325}, {'_account_id': 14926}]","[{'number': 1, 'created': '2016-02-12 15:44:48.000000000', 'files': ['security-guide/source/introduction/introduction-to-openstack.rst'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/51ff1aa0e0c3f278463c3e3185decd4cf2c5344b', 'message': 'Updated outdated link in Introduction\n\nCloses Bug: #1544691\n\nChange-Id: Ifcdae51e7aec2f68727d88bdfd8b46c42576f264\n'}]",0,279612,51ff1aa0e0c3f278463c3e3185decd4cf2c5344b,15,4,1,20376,,,0,"Updated outdated link in Introduction

Closes Bug: #1544691

Change-Id: Ifcdae51e7aec2f68727d88bdfd8b46c42576f264
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/12/279612/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/source/introduction/introduction-to-openstack.rst'],1,51ff1aa0e0c3f278463c3e3185decd4cf2c5344b,bug/1544691,<http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-145.pdf>`__ to introduce these different types of cloud as they apply to OpenStack.,<http://csrc.nist.gov/publications/nistpubs/800-145/SP800-145.pdf>`__ to introduce these different types of cloud as they apply to OpenStack.,2,2
openstack%2Fnetworking-ovn~master~Ideb30b96ecb3fad0dbe1df1d1bded1127825d196,openstack/networking-ovn,master,Ideb30b96ecb3fad0dbe1df1d1bded1127825d196,DevStack: Support disabling all OVN services,MERGED,2016-02-13 02:47:10.000000000,2016-02-15 18:12:55.000000000,2016-02-15 18:12:54.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}]","[{'number': 1, 'created': '2016-02-13 02:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/d5b495eec1ad86a5ff25f64c04c76acd71ed5cdb', 'message': 'DevStack: Support disabling all OVN services\n\n1) Support disabling all OVN services (ovn-controller and\n   ovn-northd) on nodes that do not require them.\n2) Build the OVN plug-in on nodes that run the neutron server\n   (q-svc) service.\n3) Set the OVN_NB_DB and OVN_SB_DB environment variables so\n   all nodes can run OVN commands.\n\nChange-Id: Ideb30b96ecb3fad0dbe1df1d1bded1127825d196\n'}, {'number': 2, 'created': '2016-02-13 05:52:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/87f9454cb2d028fc97d9f750b617191cbc4ec9ba', 'message': 'DevStack: Support disabling all OVN services\n\n1) Support disabling all OVN services (ovn-controller and\n   ovn-northd) on nodes that do not require them.\n2) Build the OVN plug-in on nodes that run the neutron server\n   (q-svc) service.\n3) Set the OVN_NB_DB and OVN_SB_DB environment variables so\n   all nodes can run OVN commands.\n\nChange-Id: Ideb30b96ecb3fad0dbe1df1d1bded1127825d196\n'}, {'number': 3, 'created': '2016-02-15 16:41:39.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/546d34aa68fc47f40169cb32b32116337060615f', 'message': 'DevStack: Support disabling all OVN services\n\n1) Support disabling all OVN services (ovn-controller and\n   ovn-northd) on nodes that do not require them.\n2) Build the OVN plug-in on nodes that run the neutron server\n   (q-svc) service.\n3) Set the OVN_NB_DB and OVN_SB_DB environment variables so\n   all nodes can run OVN commands.\n\nChange-Id: Ideb30b96ecb3fad0dbe1df1d1bded1127825d196\n'}]",3,279841,546d34aa68fc47f40169cb32b32116337060615f,15,3,3,9515,,,0,"DevStack: Support disabling all OVN services

1) Support disabling all OVN services (ovn-controller and
   ovn-northd) on nodes that do not require them.
2) Build the OVN plug-in on nodes that run the neutron server
   (q-svc) service.
3) Set the OVN_NB_DB and OVN_SB_DB environment variables so
   all nodes can run OVN commands.

Change-Id: Ideb30b96ecb3fad0dbe1df1d1bded1127825d196
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/41/279841/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,d5b495eec1ad86a5ff25f64c04c76acd71ed5cdb,devstack-fix1,"if is_service_enabled q-svc || is_ovn_service_enabled ovn-northd || is_ovn_service_enabled ovn-controller; then # Set the OVN_*_DB variables to enable OVN commands from any node. echo -e ""\n# Enable OVN commands from any node.\nexport OVN_NB_DB=$OVN_REMOTE\nexport OVN_SB_DB=$OVN_REMOTE"" >> ~/.bash_profile ",if is_ovn_service_enabled ovn-northd || is_ovn_service_enabled ovn-controller; then,5,1
openstack%2Fsolum~master~Idc94be9bb973b727e88805808877439d56f6cfe3,openstack/solum,master,Idc94be9bb973b727e88805808877439d56f6cfe3,Use prepare_service() in commands,MERGED,2016-01-28 20:26:05.000000000,2016-02-15 18:04:55.000000000,2016-02-15 18:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}]","[{'number': 1, 'created': '2016-01-28 20:26:05.000000000', 'files': ['solum/cmd/conductor.py', 'solum/cmd/deployer.py', 'solum/cmd/worker.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/382a84215bf369770c7fe9ddf88c9fecd43ff49f', 'message': 'Use prepare_service() in commands\n\nModify conductor, deployer and worker commands to use\nprepare_service().\n\nChange-Id: Idc94be9bb973b727e88805808877439d56f6cfe3\n'}]",3,273739,382a84215bf369770c7fe9ddf88c9fecd43ff49f,12,3,1,9107,,,0,"Use prepare_service() in commands

Modify conductor, deployer and worker commands to use
prepare_service().

Change-Id: Idc94be9bb973b727e88805808877439d56f6cfe3
",git fetch https://review.opendev.org/openstack/solum refs/changes/39/273739/1 && git format-patch -1 --stdout FETCH_HEAD,"['solum/cmd/conductor.py', 'solum/cmd/deployer.py', 'solum/cmd/worker.py']",3,382a84215bf369770c7fe9ddf88c9fecd43ff49f,oslo_utils,"from solum.common.rpc import service as rpc_service from solum.common import service service.prepare_service(sys.argv) server = rpc_service.Service(cfg.CONF.worker.topic, cfg.CONF.worker.host, endpoints)","from solum.common.rpc import service cfg.CONF(sys.argv[1:], project='solum') logging.setup('solum') server = service.Service(cfg.CONF.worker.topic, cfg.CONF.worker.host, endpoints)",15,15
openstack%2Fsolum~master~I0618c06605e235efd1cb98ce06e6c936cc335ee6,openstack/solum,master,I0618c06605e235efd1cb98ce06e6c936cc335ee6,Use oslo_serialization library,MERGED,2015-09-25 10:13:32.000000000,2016-02-15 17:53:15.000000000,2016-02-15 17:53:15.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}, {'_account_id': 9107}]","[{'number': 1, 'created': '2015-09-25 10:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/a99a44fb7165d7172ce35813885dededd86cf08b', 'message': 'Use oslo_serialization library\n\n* Add oslo.serialization dependency\n* Remove solum/openstack/common/jsonutils.py\n\nChange-Id: I0618c06605e235efd1cb98ce06e6c936cc335ee6\n'}, {'number': 2, 'created': '2016-01-28 20:35:25.000000000', 'files': ['solum/common/rpc/service.py', 'requirements.txt', 'solum/openstack/common/log.py', 'solum/uploaders/common.py', 'solum/openstack/common/jsonutils.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/e4a061b852bcfa6baba251d8fa3f11a566ee4f53', 'message': ""Use oslo_serialization library\n\n* Add oslo.serialization dependency\n* Remove solum/openstack/common/jsonutils.py\n\nThe patch changes solum/openstack/common/log.py. This file is copied\nfrom Oslo Incubator and so should not be modified, it's a compromise.\nAnyway, solum/openstack/common/ must be slowly removed.\n\nChange-Id: I0618c06605e235efd1cb98ce06e6c936cc335ee6\n""}]",0,227751,e4a061b852bcfa6baba251d8fa3f11a566ee4f53,18,4,2,9107,,,0,"Use oslo_serialization library

* Add oslo.serialization dependency
* Remove solum/openstack/common/jsonutils.py

The patch changes solum/openstack/common/log.py. This file is copied
from Oslo Incubator and so should not be modified, it's a compromise.
Anyway, solum/openstack/common/ must be slowly removed.

Change-Id: I0618c06605e235efd1cb98ce06e6c936cc335ee6
",git fetch https://review.opendev.org/openstack/solum refs/changes/51/227751/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/rpc/service.py', 'requirements.txt', 'solum/openstack/common/log.py', 'solum/uploaders/common.py', 'solum/openstack/common/jsonutils.py']",5,a99a44fb7165d7172ce35813885dededd86cf08b,oslo_serialization,,"# Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # Copyright 2011 Justin Santa Barbara # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ''' JSON related utilities. This module provides a few things: 1) A handy function for getting an object down to something that can be JSON serialized. See to_primitive(). 2) Wrappers around loads() and dumps(). The dumps() wrapper will automatically use to_primitive() for you if needed. 3) This sets up anyjson to use the loads() and dumps() wrappers if anyjson is available. ''' import codecs import datetime import functools import inspect import itertools import sys if sys.version_info < (2, 7): # On Python <= 2.6, json module is not C boosted, so try to use # simplejson module if available try: import simplejson as json except ImportError: import json else: import json import six import six.moves.xmlrpc_client as xmlrpclib from solum.openstack.common import gettextutils from solum.openstack.common import importutils from solum.openstack.common import strutils from solum.openstack.common import timeutils netaddr = importutils.try_import(""netaddr"") _nasty_type_tests = [inspect.ismodule, inspect.isclass, inspect.ismethod, inspect.isfunction, inspect.isgeneratorfunction, inspect.isgenerator, inspect.istraceback, inspect.isframe, inspect.iscode, inspect.isbuiltin, inspect.isroutine, inspect.isabstract] _simple_types = (six.string_types + six.integer_types + (type(None), bool, float)) def to_primitive(value, convert_instances=False, convert_datetime=True, level=0, max_depth=3): """"""Convert a complex object into primitives. Handy for JSON serialization. We can optionally handle instances, but since this is a recursive function, we could have cyclical data structures. To handle cyclical data structures we could track the actual objects visited in a set, but not all objects are hashable. Instead we just track the depth of the object inspections and don't go too deep. Therefore, convert_instances=True is lossy ... be aware. """""" # handle obvious types first - order of basic types determined by running # full tests on nova project, resulting in the following counts: # 572754 <type 'NoneType'> # 460353 <type 'int'> # 379632 <type 'unicode'> # 274610 <type 'str'> # 199918 <type 'dict'> # 114200 <type 'datetime.datetime'> # 51817 <type 'bool'> # 26164 <type 'list'> # 6491 <type 'float'> # 283 <type 'tuple'> # 19 <type 'long'> if isinstance(value, _simple_types): return value if isinstance(value, datetime.datetime): if convert_datetime: return timeutils.strtime(value) else: return value # value of itertools.count doesn't get caught by nasty_type_tests # and results in infinite loop when list(value) is called. if type(value) == itertools.count: return six.text_type(value) # FIXME(vish): Workaround for LP bug 852095. Without this workaround, # tests that raise an exception in a mocked method that # has a @wrap_exception with a notifier will fail. If # we up the dependency to 0.5.4 (when it is released) we # can remove this workaround. if getattr(value, '__module__', None) == 'mox': return 'mock' if level > max_depth: return '?' # The try block may not be necessary after the class check above, # but just in case ... try: recursive = functools.partial(to_primitive, convert_instances=convert_instances, convert_datetime=convert_datetime, level=level, max_depth=max_depth) if isinstance(value, dict): return dict((k, recursive(v)) for k, v in six.iteritems(value)) elif isinstance(value, (list, tuple)): return [recursive(lv) for lv in value] # It's not clear why xmlrpclib created their own DateTime type, but # for our purposes, make it a datetime type which is explicitly # handled if isinstance(value, xmlrpclib.DateTime): value = datetime.datetime(*tuple(value.timetuple())[:6]) if convert_datetime and isinstance(value, datetime.datetime): return timeutils.strtime(value) elif isinstance(value, gettextutils.Message): return value.data elif hasattr(value, 'iteritems'): return recursive(dict(value.iteritems()), level=level + 1) elif hasattr(value, '__iter__'): return recursive(list(value)) elif convert_instances and hasattr(value, '__dict__'): # Likely an instance of something. Watch for cycles. # Ignore class member vars. return recursive(value.__dict__, level=level + 1) elif netaddr and isinstance(value, netaddr.IPAddress): return six.text_type(value) else: if any(test(value) for test in _nasty_type_tests): return six.text_type(value) return value except TypeError: # Class objects are tricky since they may define something like # __iter__ defined but it isn't callable as list(). return six.text_type(value) def dumps(value, default=to_primitive, **kwargs): return json.dumps(value, default=default, **kwargs) def dump(obj, fp, *args, **kwargs): return json.dump(obj, fp, *args, **kwargs) def loads(s, encoding='utf-8', **kwargs): return json.loads(strutils.safe_decode(s, encoding), **kwargs) def load(fp, encoding='utf-8', **kwargs): return json.load(codecs.getreader(encoding)(fp), **kwargs) try: import anyjson except ImportError: pass else: anyjson._modules.append((__name__, 'dumps', TypeError, 'loads', ValueError, 'load')) anyjson.force_implementation(__name__) ",5,193
openstack%2Fdevstack~master~Icc55f9d12ee2c85ed39d2266a5fb4c337881b092,openstack/devstack,master,Icc55f9d12ee2c85ed39d2266a5fb4c337881b092,Set correct cloud for alt_demo user,ABANDONED,2016-02-05 13:22:51.000000000,2016-02-15 17:52:17.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4656}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14614}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-05 13:22:51.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3630a734113bee60a33a8384df079dad2f3df9f9', 'message': 'Set correct cloud for alt_demo user\n\nrecent patch Iaaf02469180563e2d8c413fee0ee66ada2296cfa added alt_demo\nuser to /etc/openstack/clouds.yaml,\nbut now it is overwriting the config for demo user.\n\nEasy fix.\n\nChange-Id: Icc55f9d12ee2c85ed39d2266a5fb4c337881b092\nCloses-Bug: #1542317\n'}]",0,276725,3630a734113bee60a33a8384df079dad2f3df9f9,9,7,1,9542,,,0,"Set correct cloud for alt_demo user

recent patch Iaaf02469180563e2d8c413fee0ee66ada2296cfa added alt_demo
user to /etc/openstack/clouds.yaml,
but now it is overwriting the config for demo user.

Easy fix.

Change-Id: Icc55f9d12ee2c85ed39d2266a5fb4c337881b092
Closes-Bug: #1542317
",git fetch https://review.opendev.org/openstack/devstack refs/changes/25/276725/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,3630a734113bee60a33a8384df079dad2f3df9f9,bug/1542317, --os-cloud devstack-alt \, --os-cloud devstack \,1,1
openstack%2Fneutron~master~I1e91aa22d093d50e5a9d318f24d09bb65e072246,openstack/neutron,master,I1e91aa22d093d50e5a9d318f24d09bb65e072246,Get rid of UnionModel for RBAC,MERGED,2016-02-11 12:45:30.000000000,2016-02-15 17:48:43.000000000,2016-02-15 17:48:43.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 18485}]","[{'number': 1, 'created': '2016-02-11 12:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f3e1e8ef85dc8f58b04201fc015c501fd440aa68', 'message': ""Get rid of UnionModel for RBAC\n\nThe union model approach was completely broken because it\ndidn't keep track of which model each result actually was.\n\nThis patch just strips it out and replaces get_rbac_policies\nwith queries to each model. This will mean pagination is broken\nonce multiple rbac types are in place, but everything else should\nwork fine.\n\nPartial-Bug: #1542815\nChange-Id: I1e91aa22d093d50e5a9d318f24d09bb65e072246\n""}, {'number': 2, 'created': '2016-02-11 12:56:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f20231a1899fa6fedbcf5832db8f07c3b4cfb914', 'message': ""Get rid of UnionModel for RBAC\n\nThe union model approach was completely broken because it\ndidn't keep track of which model each result actually was.\n\nThis patch just strips it out and replaces get_rbac_policies\nwith queries to each model. This will mean pagination is broken\nonce multiple rbac types are in place, but everything else should\nwork fine.\n\nPartial-Bug: #1542815\nChange-Id: I1e91aa22d093d50e5a9d318f24d09bb65e072246\n""}, {'number': 3, 'created': '2016-02-11 14:41:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9666d009288fc941e326b84786e3c9ed5da3e726', 'message': ""Get rid of UnionModel for RBAC\n\nThe union model approach was completely broken because it\ndidn't keep track of which model each result actually was.\n\nThis patch just strips it out and replaces get_rbac_policies\nwith queries to each model. This will mean pagination is broken\nonce multiple rbac types are in place, but everything else should\nwork fine.\n\nCo-Authored-By: Haim Daniel <hdaniel@redhat.com>\n\nCloses-Bug: #1542815\nChange-Id: I1e91aa22d093d50e5a9d318f24d09bb65e072246\n""}, {'number': 4, 'created': '2016-02-15 08:18:01.000000000', 'files': ['neutron/db/rbac_db_mixin.py', 'neutron/db/common_db_mixin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/957c21113fc5848925c13a3128a23243ee99fa30', 'message': ""Get rid of UnionModel for RBAC\n\nThe union model approach was completely broken because it\ndidn't keep track of which model each result actually was.\n\nThis patch just strips it out and replaces get_rbac_policies\nwith queries to each model. This will mean pagination is broken\nonce multiple rbac types are in place, but everything else should\nwork fine.\n\nCo-Authored-By: Haim Daniel <hdaniel@redhat.com>\n\nCloses-Bug: #1542815\nChange-Id: I1e91aa22d093d50e5a9d318f24d09bb65e072246\n""}]",1,279030,957c21113fc5848925c13a3128a23243ee99fa30,81,19,4,7787,,,0,"Get rid of UnionModel for RBAC

The union model approach was completely broken because it
didn't keep track of which model each result actually was.

This patch just strips it out and replaces get_rbac_policies
with queries to each model. This will mean pagination is broken
once multiple rbac types are in place, but everything else should
work fine.

Co-Authored-By: Haim Daniel <hdaniel@redhat.com>

Closes-Bug: #1542815
Change-Id: I1e91aa22d093d50e5a9d318f24d09bb65e072246
",git fetch https://review.opendev.org/openstack/neutron refs/changes/30/279030/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/rbac_db_mixin.py', 'neutron/db/common_db_mixin.py']",2,f3e1e8ef85dc8f58b04201fc015c501fd440aa68,bug/1542815,," if isinstance(model, UnionModel): return self._union_model_query(context, model) else: return self._single_model_query(context, model) def _union_model_query(self, context, model): # A union query is a query that combines multiple sets of data # together and represents them as one. So if a UnionModel was # passed in, we generate the query for each model with the # appropriate filters and then combine them together with the # .union operator. This allows any subsequent users of the query # to handle it like a normal query (e.g. add pagination/sorting/etc) first_query = None remaining_queries = [] for name, component_model in model.model_map.items(): query = self._single_model_query(context, component_model) if model.column_type_name: query.add_columns( sql.expression.column('""%s""' % name, is_literal=True). label(model.column_type_name) ) if first_query is None: first_query = query else: remaining_queries.append(query) return first_query.union(*remaining_queries) def _single_model_query(self, context, model): if isinstance(model, UnionModel): # NOTE(kevinbenton): a unionmodel is made up of multiple tables so # we apply the filter to each table for component_model in model.model_map.values(): query = self._apply_filters_to_query(query, component_model, filters, context) return query class UnionModel(object): """"""Collection of models that _model_query can query as a single table."""""" def __init__(self, model_map, column_type_name=None): # model_map is a dictionary of models keyed by an arbitrary name. # If column_type_name is specified, the resulting records will have a # column with that name which identifies the source of each record self.model_map = model_map self.column_type_name = column_type_name",16,51
openstack%2Foslo.privsep~master~I02a6b9bf70fb1f75c75f2dad052b3d0ad9e96967,openstack/oslo.privsep,master,I02a6b9bf70fb1f75c75f2dad052b3d0ad9e96967,Change name of privsep_helper to match code,MERGED,2016-02-09 16:49:33.000000000,2016-02-15 17:40:44.000000000,2016-02-10 04:28:15.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 11279}]","[{'number': 1, 'created': '2016-02-09 16:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/5313858085f6b1e461777baeae8b6d32dcba66ac', 'message': ""Change name of privsep_helper to match code\n\nThis patch updates the setup.cfg to be consistent with the\ndaemon's usage of the name 'privsep-helper', instead of the\nsetup.cfg's name of 'privesep_helper'\n\nCloses Bug: # 1543664\n\nChange-Id: I02a6b9bf70fb1f75c75f2dad052b3d0ad9e96967\n""}, {'number': 2, 'created': '2016-02-09 19:08:20.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/ce5b7c74cb3be80ddfa3412054d81f98ce3e2202', 'message': ""Change name of privsep_helper to match code\n\nThis patch updates the setup.cfg to be consistent with the\ndaemon's usage of the name 'privsep-helper', instead of the\nsetup.cfg's name of 'privesep_helper'\n\nCloses-Bug: #1543664\n\nChange-Id: I02a6b9bf70fb1f75c75f2dad052b3d0ad9e96967\n""}]",1,277957,ce5b7c74cb3be80ddfa3412054d81f98ce3e2202,17,5,2,5997,,,0,"Change name of privsep_helper to match code

This patch updates the setup.cfg to be consistent with the
daemon's usage of the name 'privsep-helper', instead of the
setup.cfg's name of 'privesep_helper'

Closes-Bug: #1543664

Change-Id: I02a6b9bf70fb1f75c75f2dad052b3d0ad9e96967
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/57/277957/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5313858085f6b1e461777baeae8b6d32dcba66ac,bug/1543664, privsep-helper = oslo_privsep.daemon:helper_main, privsep_helper = oslo_privsep.daemon:helper_main,1,1
openstack%2Foslo.messaging~master~I17d8d84592de3435ddbcba42361fc1258dd62b21,openstack/oslo.messaging,master,I17d8d84592de3435ddbcba42361fc1258dd62b21,Remove matchmaker_redis configs from [DEFAULT],MERGED,2016-02-08 22:06:00.000000000,2016-02-15 17:37:45.000000000,2016-02-10 03:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 13290}, {'_account_id': 15424}]","[{'number': 1, 'created': '2016-02-08 22:06:00.000000000', 'files': ['oslo_messaging/opts.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9c182eef67e303d3a5a0211538586f9ad91b4437', 'message': 'Remove matchmaker_redis configs from [DEFAULT]\n\nThe configuration options for matchmaker_redis appeared in two groups:\n[DEFAULT] and [match_redis]. This removes the configs from the incorrect\ngroup [DEFAULT].\n\nChange-Id: I17d8d84592de3435ddbcba42361fc1258dd62b21\nCloses-Bug: #1543305\n'}]",0,277585,9c182eef67e303d3a5a0211538586f9ad91b4437,9,5,1,6618,,,0,"Remove matchmaker_redis configs from [DEFAULT]

The configuration options for matchmaker_redis appeared in two groups:
[DEFAULT] and [match_redis]. This removes the configs from the incorrect
group [DEFAULT].

Change-Id: I17d8d84592de3435ddbcba42361fc1258dd62b21
Closes-Bug: #1543305
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/85/277585/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/opts.py'],1,9c182eef67e303d3a5a0211538586f9ad91b4437,bug/1543305,," matchmaker_redis.matchmaker_redis_opts,",0,1
openstack%2Fcongress~master~Iefceeb2779433aa55f36873c6f28cb5e09650a81,openstack/congress,master,Iefceeb2779433aa55f36873c6f28cb5e09650a81,Enable tests of action-model,MERGED,2016-02-15 05:07:00.000000000,2016-02-15 17:32:41.000000000,2016-02-15 17:32:41.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2016-02-15 05:07:00.000000000', 'files': ['congress/tests2/api/test_action_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/e55c6e46cb99343132442d6798a859b1df8ddf8d', 'message': 'Enable tests of action-model\n\nChange-Id: Iefceeb2779433aa55f36873c6f28cb5e09650a81\n'}]",0,280064,e55c6e46cb99343132442d6798a859b1df8ddf8d,6,2,1,11278,,,0,"Enable tests of action-model

Change-Id: Iefceeb2779433aa55f36873c6f28cb5e09650a81
",git fetch https://review.opendev.org/openstack/congress refs/changes/64/280064/1 && git format-patch -1 --stdout FETCH_HEAD,['congress/tests2/api/test_action_model.py'],1,e55c6e46cb99343132442d6798a859b1df8ddf8d,action-tests,"from congress.api import webservicefrom congress.tests2.api import base as api_base self.action_model = action_model.ActionsModel( services = api_base.setup_config([self.action_model]) self.datasource = services['data'] def test_get_invalid_datasource_action(self): context = {'ds_id': 'invalid_id'} self.assertRaises(webservice.DataModelException, self.action_model.get_items, {}, context=context)","from congress.dse2.dse_node import DseNode from congress.policy_engines.agnostic import Dse2Runtimefrom congress.tests.fake_datasource import FakeDataSource from congress.tests import helper # Here we load the fake driver cfg.CONF.set_override( 'drivers', ['congress.tests.fake_datasource.FakeDataSource']) services = self.create_services() self.action_model = services['action_model'] self.datasource = services['data'] def create_services(self): messaging_config = helper.generate_messaging_config() node = DseNode(messaging_config, ""testnode"", []) engine = Dse2Runtime('engine') fake = FakeDataSource('test1') action = action_model.ActionsModel( node.register_service(engine) # not strictly necessary node.register_service(fake) node.register_service(action) node.start() return {'node': node, 'engine': engine, 'action_model': action, 'data': fake} # TODO(dse2): enable once oslo-messaging returning proper error # codes # def test_get_invalid_datasource_action(self): # context = {'ds_id': 'invalid_id'} # self.assertRaises(webservice.DataModelException, # self.action_model.get_items, {}, context=context)",9,33
openstack%2Fcongress~master~I5bfe34930173910a93cd78d7bc319310a05b805d,openstack/congress,master,I5bfe34930173910a93cd78d7bc319310a05b805d,Enable tests-2 according to new arh,MERGED,2016-02-12 08:10:31.000000000,2016-02-15 17:32:35.000000000,2016-02-15 17:32:35.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2016-02-12 08:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/0aa92e4d3b7a35a4690dca7f198056cb90825147', 'message': 'Enable tests-2 according to new arh\n\nThis commit enables schema and status api model tests accoriding\nto new architecture.\n\nChange-Id: I5bfe34930173910a93cd78d7bc319310a05b805d\n'}, {'number': 2, 'created': '2016-02-12 08:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/9f432aef239d1f968a181b2dcbddf61f4c38a39c', 'message': 'Enable tests-2 according to new arh\n\nThis commit enables schema and status api model tests accoriding\nto new architecture.\n\nCloses-Bug:#1542540\nChange-Id: I5bfe34930173910a93cd78d7bc319310a05b805d\n'}, {'number': 3, 'created': '2016-02-15 04:49:59.000000000', 'files': ['congress/tests2/api/test_status_model.py', 'congress/tests2/api/test_schema_model.py', 'congress/api/schema_model.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/587b219cea618b7e35af9e8652457ae637b5b3b7', 'message': 'Enable tests-2 according to new arh\n\nThis commit enables schema and status api model tests accoriding\nto new architecture.\n\nCloses-Bug:#1542540\nChange-Id: I5bfe34930173910a93cd78d7bc319310a05b805d\n'}]",0,279415,587b219cea618b7e35af9e8652457ae637b5b3b7,11,2,3,11278,,,0,"Enable tests-2 according to new arh

This commit enables schema and status api model tests accoriding
to new architecture.

Closes-Bug:#1542540
Change-Id: I5bfe34930173910a93cd78d7bc319310a05b805d
",git fetch https://review.opendev.org/openstack/congress refs/changes/15/279415/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests2/api/test_status_model.py', 'congress/tests2/api/test_schema_model.py', 'congress/api/schema_model.py']",3,0aa92e4d3b7a35a4690dca7f198056cb90825147,schema-test-fix,from congress import exception except exception.CongressException as e:,"from congress.managers import datasource as datasource_manager except (datasource_manager.DatasourceNotFound, datasource_manager.DriverNotFound) as e:",48,90
openstack%2Fcongress~master~I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8,openstack/congress,master,I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8,Raise proper exceptions in new architecture,MERGED,2016-02-05 11:25:30.000000000,2016-02-15 17:31:50.000000000,2016-02-15 17:31:50.000000000,"[{'_account_id': 3}, {'_account_id': 8215}, {'_account_id': 8878}, {'_account_id': 11278}]","[{'number': 1, 'created': '2016-02-05 11:25:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4654011fb99ad917cddf706b825bfe12f2efe4a9', 'message': 'WIP: Raise exception on invalid service\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nTODO: If the exceptions are raised from endpoints, they are wrapped\ninto RemoteError and raised, so this needs to be handled\neither remove RemoteError and raise original exception or\nhandle remote exception on API for tests to pass\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\n'}, {'number': 2, 'created': '2016-02-08 04:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/67367a6ed560bfb4246b785863e98b9c83d62cd2', 'message': 'WIP: Raise exception on invalid service\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nTODO: If the exceptions are raised from endpoints, they are wrapped\ninto RemoteError and raised, so this needs to be handled\neither remove RemoteError and raise original exception or\nhandle remote exception on API for tests to pass\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}, {'number': 3, 'created': '2016-02-08 08:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/6681a1b89fde5e8574eff3f67dba3bd261a69fc1', 'message': 'Raise proper exceptions in new architecture\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nAdded congress.exception class to allowed_remote_exmods, to reraise\nthe exceptions from remote endpoint with same type instead of\nraising as RemoteError.\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}, {'number': 4, 'created': '2016-02-10 11:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/f2673863871835591386d89dde6b3b6592579867', 'message': 'Raise proper exceptions in new architecture\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nAdded congress.exception class to allowed_remote_exmods, to reraise\nthe exceptions from remote endpoint with same type instead of\nraising as RemoteError.\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}, {'number': 5, 'created': '2016-02-12 05:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d9be3a6ebd4010c1d1c0e7392c090cfbe3b3c27f', 'message': 'Raise proper exceptions in new architecture\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nAdded congress.exception class to allowed_remote_exmods, to reraise\nthe exceptions from remote endpoint with same type instead of\nraising as RemoteError.\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}, {'number': 6, 'created': '2016-02-15 03:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/282c15423ba61b8b1ec95b7c8a0dfdd434f6e406', 'message': 'Raise proper exceptions in new architecture\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nAdded congress.exception class to allowed_remote_exmods, to reraise\nthe exceptions from remote endpoint with same type instead of\nraising as RemoteError.\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}, {'number': 7, 'created': '2016-02-15 04:43:43.000000000', 'files': ['congress/api/table_model.py', 'congress/dse2/dse_node.py', 'congress/tests2/api/test_table_model.py', 'congress/tests2/dse2/test_dse2.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/00e88add11a91f299aec8035ecaa224bfdfe0a31', 'message': 'Raise proper exceptions in new architecture\n\nThis commit raises exception, if a call is invoked on invalid\nservice. This should enable the tests disabled as proper exception\nis not raised for invalid datasource.\n\nAdded congress.exception class to allowed_remote_exmods, to reraise\nthe exceptions from remote endpoint with same type instead of\nraising as RemoteError.\n\nChange-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8\nCloses-Bug:#1542540\n'}]",9,276691,00e88add11a91f299aec8035ecaa224bfdfe0a31,25,4,7,11278,,,0,"Raise proper exceptions in new architecture

This commit raises exception, if a call is invoked on invalid
service. This should enable the tests disabled as proper exception
is not raised for invalid datasource.

Added congress.exception class to allowed_remote_exmods, to reraise
the exceptions from remote endpoint with same type instead of
raising as RemoteError.

Change-Id: I1deb4d350e8be90c9c8a76e0b5c7c9e7051405a8
Closes-Bug:#1542540
",git fetch https://review.opendev.org/openstack/congress refs/changes/91/276691/7 && git format-patch -1 --stdout FETCH_HEAD,['congress/dse2/dse_node.py'],1,4654011fb99ad917cddf706b825bfe12f2efe4a9,exception-2,"from congress import exception Raises: MessagingTimeout, RemoteError, MessageDeliveryFailure, NotFound if not self.service_object(service_id): msg = ""service '%s' is not a registered service"" raise exception.NotFound(msg % service_id) if not self.service_object(service_id): msg = ""service '%s' is not a registered service"" raise exception.NotFound(msg % service_id) "," Raises: MessagingTimeout, RemoteError, MessageDeliveryFailure",10,1
openstack%2Ffuel-qa~master~I3b747e3fe8f5aae337b1ca81471a881280b148a0,openstack/fuel-qa,master,I3b747e3fe8f5aae337b1ca81471a881280b148a0,Add gates_tests to system_tests.__init__,MERGED,2016-02-15 16:25:08.000000000,2016-02-15 17:26:20.000000000,2016-02-15 17:26:20.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 14614}]","[{'number': 1, 'created': '2016-02-15 16:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a584ee1adcb57e83c8dffa7fc654f4435d213a44', 'message': 'Add gates_tests to system_tests.__init__\n\nWe miss to add out gates directory in tests_directory,\nso tests can be executed\n\nChange-Id: I3b747e3fe8f5aae337b1ca81471a881280b148a0\n'}, {'number': 2, 'created': '2016-02-15 16:37:45.000000000', 'files': ['system_test/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d2ce5b476d31abaca657388612dbb69ff056924b', 'message': 'Add gates_tests to system_tests.__init__\n\nWe miss to add our gates directory in tests_directory,\nso tests can not be executed\n\nChange-Id: I3b747e3fe8f5aae337b1ca81471a881280b148a0\n'}]",0,280311,d2ce5b476d31abaca657388612dbb69ff056924b,14,5,2,6719,,,0,"Add gates_tests to system_tests.__init__

We miss to add our gates directory in tests_directory,
so tests can not be executed

Change-Id: I3b747e3fe8f5aae337b1ca81471a881280b148a0
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/11/280311/2 && git format-patch -1 --stdout FETCH_HEAD,['system_test/__init__.py'],1,a584ee1adcb57e83c8dffa7fc654f4435d213a44,add_gate_dir," 'system_test/tests', 'gates_tests'", 'system_test/tests',2,1
openstack%2Fapi-site~master~Ie16cc25b371dedc775520ab0db79e14129ecbe2d,openstack/api-site,master,Ie16cc25b371dedc775520ab0db79e14129ecbe2d,Adjust the request param sequence,MERGED,2016-02-11 10:45:32.000000000,2016-02-15 17:22:48.000000000,2016-02-15 17:22:48.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-11 10:45:32.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/4d89b226aedea0a0be8f3a8f959feac3d90c5998', 'message': 'Adjust the request param sequence\n\nthe volumeAttachment contains volumeId and device\nso it should be on top of them as convention of whole book.\n\nChange-Id: Ie16cc25b371dedc775520ab0db79e14129ecbe2d\nPartial-Bug: #1515222\n'}]",0,278973,4d89b226aedea0a0be8f3a8f959feac3d90c5998,7,3,1,6062,,,0,"Adjust the request param sequence

the volumeAttachment contains volumeId and device
so it should be on top of them as convention of whole book.

Change-Id: Ie16cc25b371dedc775520ab0db79e14129ecbe2d
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/73/278973/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volume-attachments-v2.1.wadl'],1,4d89b226aedea0a0be8f3a8f959feac3d90c5998,nova-api-volume-adjust-order," <param name=""volumeAttachment"" style=""template"" type=""xsd:dict""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> A dictionary representation of a volume attachment. </para> </wadl:doc> </param>"," <param name=""volumeAttachment"" style=""template"" type=""xsd:dict""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN""> <para> A dictionary representation of a volume attachment. </para> </wadl:doc> </param>",10,10
openstack%2Finstack-undercloud~master~I780629059d7375df727cab28dfa219a7c9c20af7,openstack/instack-undercloud,master,I780629059d7375df727cab28dfa219a7c9c20af7,Explicitly decode to utf-8,MERGED,2016-01-21 19:01:00.000000000,2016-02-15 17:19:52.000000000,2016-02-15 17:19:52.000000000,"[{'_account_id': 3}, {'_account_id': 1926}, {'_account_id': 7144}, {'_account_id': 8532}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-21 19:01:00.000000000', 'files': ['instack_undercloud/undercloud.py'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/3fdd07eb644e94adb1a958229c524dc1a45fc67f', 'message': ""Explicitly decode to utf-8\n\nCI is currently failing on UnicodeDecodeErrors during the undercloud\ninstall.  I can't reproduce locally, but hopefully this will fix\nthe problem.\n\nChange-Id: I780629059d7375df727cab28dfa219a7c9c20af7\n""}]",0,270983,3fdd07eb644e94adb1a958229c524dc1a45fc67f,18,5,1,6928,,,0,"Explicitly decode to utf-8

CI is currently failing on UnicodeDecodeErrors during the undercloud
install.  I can't reproduce locally, but hopefully this will fix
the problem.

Change-Id: I780629059d7375df727cab28dfa219a7c9c20af7
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/83/270983/1 && git format-patch -1 --stdout FETCH_HEAD,['instack_undercloud/undercloud.py'],1,3fdd07eb644e94adb1a958229c524dc1a45fc67f,decode-utf8, env=env).decode('utf-8') line = process.stdout.readline().decode('utf-8'), env=env).decode() line = process.stdout.readline().decode(),2,2
openstack%2Fkeystonemiddleware~master~Ie050763a7e115bf7ea3d78e01de29e939334580e,openstack/keystonemiddleware,master,Ie050763a7e115bf7ea3d78e01de29e939334580e,Use load_from_options_getter for auth plugins,MERGED,2015-12-10 04:01:59.000000000,2016-02-15 17:18:42.000000000,2016-02-15 17:18:42.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 13478}]","[{'number': 1, 'created': '2015-12-10 04:01:59.000000000', 'files': ['keystonemiddleware/auth_token/__init__.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ee5e6ccd3d8b709415e571a2f86ba7da612d7338', 'message': ""Use load_from_options_getter for auth plugins\n\nWe can't simply use load_from_conf_options when loading auth plugins for\nkeystone middleware because we have to support the options being\noverriden from paste. We used to therefore load all these options\nmanually however load_from_options_getter will at least handle the auth\nplugin options and we can simply manage the conf loading bits manually.\n\nChange-Id: Ie050763a7e115bf7ea3d78e01de29e939334580e\n""}]",2,255661,ee5e6ccd3d8b709415e571a2f86ba7da612d7338,13,6,1,7191,,,0,"Use load_from_options_getter for auth plugins

We can't simply use load_from_conf_options when loading auth plugins for
keystone middleware because we have to support the options being
overriden from paste. We used to therefore load all these options
manually however load_from_options_getter will at least handle the auth
plugin options and we can simply manage the conf loading bits manually.

Change-Id: Ie050763a7e115bf7ea3d78e01de29e939334580e
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/61/255661/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token/__init__.py'],1,ee5e6ccd3d8b709415e571a2f86ba7da612d7338,getter," # NOTE(jamielennox): Ideally this would use load_from_conf_options # pattern we use in _conf_get. This function therefore does a manual # version of load_from_conf_options with the fallback plugin inline. # Plugin option registration is normally done as part of the load_from # function rather than the register function so copy here. plugin_opts = loading.get_auth_plugin_conf_options(plugin_loader) getter = lambda opt: self._conf_get(opt.dest, group=group) return plugin_loader.load_from_options_getter(getter)"," # NOTE(jamielennox): Ideally this would use get_from_conf_options # pattern we use in _conf_get. There is a somewhat replacement for this # in keystoneclient in load_from_options_getter which should be used # when available. Until then this is essentially a copy and paste of # the ksc load_from_conf_options code because we need to get a fix out # for this quickly. # FIXME(jamielennox): update to use load_from_options_getter when # https://review.openstack.org/162529 merges. # !!! - UNDER NO CIRCUMSTANCES COPY ANY OF THIS CODE - !!! plugin_opts = [o._to_oslo_opt() for o in plugin_loader.get_options()] plugin_kwargs = dict() for opt in plugin_opts: val = self._conf_get(opt.dest, group=group) if val is not None: val = opt.type(val) plugin_kwargs[opt.dest] = val return plugin_loader.load_from_options(**plugin_kwargs)",8,20
openstack%2Fpython-openstackclient~master~I1ec3beefbb878a207bca280b994ca176ef04ee2d,openstack/python-openstackclient,master,I1ec3beefbb878a207bca280b994ca176ef04ee2d,"Rename parameter ""identifier"" to ""network"" in network commands",MERGED,2016-02-14 11:05:33.000000000,2016-02-15 17:16:30.000000000,2016-02-15 17:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-14 11:05:33.000000000', 'files': ['openstackclient/network/v2/network.py', 'openstackclient/tests/network/v2/test_network.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/324e026f579041466a48ec4d93e41f05ca8314d2', 'message': 'Rename parameter ""identifier"" to ""network"" in network commands\n\nIn other commands, the name or ID of an object is just the name\nof the object. For example, name or ID of a server is ""server"",\nrouter is ""router"". So, do not use ""identifier"" in network commands.\n\nAlso, the parameter in doc file network.rst is not ""identifier"",\nbut ""network"".\n\nChange-Id: I1ec3beefbb878a207bca280b994ca176ef04ee2d\n'}]",0,279956,324e026f579041466a48ec4d93e41f05ca8314d2,9,5,1,14937,,,0,"Rename parameter ""identifier"" to ""network"" in network commands

In other commands, the name or ID of an object is just the name
of the object. For example, name or ID of a server is ""server"",
router is ""router"". So, do not use ""identifier"" in network commands.

Also, the parameter in doc file network.rst is not ""identifier"",
but ""network"".

Change-Id: I1ec3beefbb878a207bca280b994ca176ef04ee2d
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/56/279956/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/network.py', 'openstackclient/tests/network/v2/test_network.py']",2,324e026f579041466a48ec4d93e41f05ca8314d2,identifier-to-network-20160214," ('network', self._network.name), ('network', self._network.name), verifylist = [('network', self._network.name), ] ('network', self._network.name),"," ('identifier', self._network.name), ('identifier', self._network.name), verifylist = [('identifier', self._network.name), ] ('identifier', self._network.name),",8,8
openstack%2Fpython-openstackclient~master~I15c8e757dcab77fd6f895feb018184e1eb7e617b,openstack/python-openstackclient,master,I15c8e757dcab77fd6f895feb018184e1eb7e617b,Use assertRaises() to check if an exception is raised,MERGED,2016-02-14 10:52:34.000000000,2016-02-15 17:14:42.000000000,2016-02-15 17:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 17211}]","[{'number': 1, 'created': '2016-02-14 10:52:34.000000000', 'files': ['openstackclient/tests/compute/v2/test_server.py', 'openstackclient/tests/network/v2/test_network.py', 'openstackclient/tests/network/v2/test_router.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cfcb750a97af1ab82b425532437456c22dcebad9', 'message': 'Use assertRaises() to check if an exception is raised\n\nIn some test cases, try/except is used to check if an exception\nhas been raised. We should use assertRaises() instead.\n\nChange-Id: I15c8e757dcab77fd6f895feb018184e1eb7e617b\n'}]",0,279954,cfcb750a97af1ab82b425532437456c22dcebad9,10,6,1,14937,,,0,"Use assertRaises() to check if an exception is raised

In some test cases, try/except is used to check if an exception
has been raised. We should use assertRaises() instead.

Change-Id: I15c8e757dcab77fd6f895feb018184e1eb7e617b
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/54/279954/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/test_server.py', 'openstackclient/tests/network/v2/test_network.py', 'openstackclient/tests/network/v2/test_router.py']",3,cfcb750a97af1ab82b425532437456c22dcebad9,assert-raise-20160214," # Missing required args should bail here self.assertRaises(tests_utils.ParserException, self.check_parser, self.cmd, arglist, verifylist) # Missing required args should bail here self.assertRaises(tests_utils.ParserException, self.check_parser, self.cmd, arglist, verifylist) # Missing required args should bail here self.assertRaises(tests_utils.ParserException, self.check_parser, self.cmd, arglist, verifylist)"," try: self.check_parser(self.cmd, arglist, verifylist) except tests_utils.ParserException: pass try: # Argument parse failing should bail here self.check_parser(self.cmd, arglist, verifylist) except tests_utils.ParserException: pass try: # Missing required args should bail here self.check_parser(self.cmd, arglist, verifylist) except tests_utils.ParserException: pass",19,29
openstack%2Ffuel-qa~master~Ib3d61bc50127078ef4810838f2ac410cd5d4f090,openstack/fuel-qa,master,Ib3d61bc50127078ef4810838f2ac410cd5d4f090,Add neutron test for drop rabbit port,ABANDONED,2015-07-10 09:39:32.000000000,2016-02-15 17:07:43.000000000,,"[{'_account_id': 3}, {'_account_id': 7126}, {'_account_id': 8971}, {'_account_id': 15376}, {'_account_id': 17737}]","[{'number': 1, 'created': '2015-07-10 09:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/80edbf3790ddd4a970970e0194492b6128728cb4', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}, {'number': 2, 'created': '2015-07-10 16:05:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/20f80b8f18e0b756b15007504565f656b059cb0f', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}, {'number': 3, 'created': '2015-07-10 16:05:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/db812e599010725db8bc15d7b9f1aa0809ba2e5e', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}, {'number': 4, 'created': '2015-07-29 13:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/db3f3a0587f44cea5dc1b06cd2aaae99463f27f7', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}, {'number': 5, 'created': '2015-08-25 13:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6f8f91b18a461c228107e276630c111b1ad24d8e', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}, {'number': 6, 'created': '2015-10-28 12:16:06.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_neutron_base.py', 'fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/tests_strength/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1ddbefa0b3a75ec31b67dab75e145bbaad8bbfda', 'message': 'Add neutron test for drop rabbit port\n\nAdded neutron test for l3 migration after drop rabbit port.\n\nImplements blueprint neutron-automated-tests\n\nChange-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090\n'}]",0,200442,1ddbefa0b3a75ec31b67dab75e145bbaad8bbfda,39,5,6,7126,,,0,"Add neutron test for drop rabbit port

Added neutron test for l3 migration after drop rabbit port.

Implements blueprint neutron-automated-tests

Change-Id: Ib3d61bc50127078ef4810838f2ac410cd5d4f090
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/42/200442/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/tests_strength/test_neutron.py']",2,80edbf3790ddd4a970970e0194492b6128728cb4,bp/neutron-automated-tests," def neutron_l3_migration_after_drop_rabbit(self, segment_type): """""" Check l3 agent migration after some rabbit problems. Scenario: 1. Revert snapshot with neutron cluster 4. Launch instances in different private networks 5. Check ping on instances from each other by flips 6. Drop rabbit port on host with l3 agent for router 1 7. Check reschedule router 1 8. Repeat step 5 Duration 30m """""" self.env.revert_snapshot(""deploy_ha_neutron_{}"".format(segment_type)) cluster_id = self.fuel_web.get_last_created_cluster() os_conn = os_actions.OpenStackActions( self.fuel_web.get_public_vip(cluster_id)) network = os_conn.create_internal_network() instance_1 = os_conn.create_server_for_migration(neutron=True) float_ip_1 = os_conn.assign_floating_ip(instance_1) instance_2 = os_conn.create_server_for_migration(neutron=True, net_id=network['id']) float_ip_2 = os_conn.assign_floating_ip(instance_2) ",,91,4
openstack%2Fpython-tripleoclient~stable%2Fliberty~Ia0680e57c026836cfa31a685b2e26d6a94f3e49f,openstack/python-tripleoclient,stable/liberty,Ia0680e57c026836cfa31a685b2e26d6a94f3e49f,Remove ntp element from overcloud images,MERGED,2016-01-21 23:07:57.000000000,2016-02-15 17:05:05.000000000,2016-02-15 17:05:05.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-21 23:07:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/639b76866645329a0ee90e876eb4655782569b57', 'message': 'Remove ntp element from overcloud images\n\nNTP is now being configured via puppet, and the os-apply-config\ntemplate that gets installed by the ntp element actually overwrites\nthe puppet config, causing NTP to be configured incorrectly. We\njust need to stop including the element and let puppet handle\neverything.\n\nConflicts:\n\ttripleoclient/tests/v1/overcloud_image/test_overcloud_image.py\n\nChange-Id: Ia0680e57c026836cfa31a685b2e26d6a94f3e49f\n(cherry picked from commit e7117371f21c0d64193cf1228c9fdb3ed5000674)\n'}, {'number': 2, 'created': '2016-02-12 19:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9deb98c77c80e6d2872c395cc548af5a9498ef23', 'message': 'Remove ntp element from overcloud images\n\nNTP is now being configured via puppet, and the os-apply-config\ntemplate that gets installed by the ntp element actually overwrites\nthe puppet config, causing NTP to be configured incorrectly. We\njust need to stop including the element and let puppet handle\neverything.\n\nConflicts:\n\ttripleoclient/tests/v1/overcloud_image/test_overcloud_image.py\n\nChange-Id: Ia0680e57c026836cfa31a685b2e26d6a94f3e49f\n(cherry picked from commit e7117371f21c0d64193cf1228c9fdb3ed5000674)\n'}, {'number': 3, 'created': '2016-02-13 17:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/acc8d1a9cb463c4152559ea2c8de6d938e65d757', 'message': 'Remove ntp element from overcloud images\n\nNTP is now being configured via puppet, and the os-apply-config\ntemplate that gets installed by the ntp element actually overwrites\nthe puppet config, causing NTP to be configured incorrectly. We\njust need to stop including the element and let puppet handle\neverything.\n\nConflicts:\n\ttripleoclient/tests/v1/overcloud_image/test_overcloud_image.py\n\nDepends-On: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nChange-Id: Ia0680e57c026836cfa31a685b2e26d6a94f3e49f\n(cherry picked from commit e7117371f21c0d64193cf1228c9fdb3ed5000674)\n'}, {'number': 4, 'created': '2016-02-14 00:36:54.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0015a5d2fc84bb7aa84bcc279d88c1e43140bfe6', 'message': 'Remove ntp element from overcloud images\n\nNTP is now being configured via puppet, and the os-apply-config\ntemplate that gets installed by the ntp element actually overwrites\nthe puppet config, causing NTP to be configured incorrectly. We\njust need to stop including the element and let puppet handle\neverything.\n\nConflicts:\n\ttripleoclient/tests/v1/overcloud_image/test_overcloud_image.py\n\nDepends-On: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nDepends-On: I794fad76744d2a9a63122a3391c33830220b8ce6\nChange-Id: Ia0680e57c026836cfa31a685b2e26d6a94f3e49f\n(cherry picked from commit e7117371f21c0d64193cf1228c9fdb3ed5000674)\n'}]",0,271078,0015a5d2fc84bb7aa84bcc279d88c1e43140bfe6,58,5,4,6928,,,0,"Remove ntp element from overcloud images

NTP is now being configured via puppet, and the os-apply-config
template that gets installed by the ntp element actually overwrites
the puppet config, causing NTP to be configured incorrectly. We
just need to stop including the element and let puppet handle
everything.

Conflicts:
	tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py

Depends-On: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed
Depends-On: I794fad76744d2a9a63122a3391c33830220b8ce6
Change-Id: Ia0680e57c026836cfa31a685b2e26d6a94f3e49f
(cherry picked from commit e7117371f21c0d64193cf1228c9fdb3ed5000674)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/78/271078/4 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,639b76866645329a0ee90e876eb4655782569b57,stable-backports," ""overcloud-compute overcloud-ceph-storage sysctl hosts """," ""overcloud-compute overcloud-ceph-storage ntp sysctl hosts """,1,2
openstack%2Fpython-solumclient~master~I4badf572ded6327e49ed916a148a7bf7a0b62a57,openstack/python-solumclient,master,I4badf572ded6327e49ed916a148a7bf7a0b62a57,Adding app scale command,MERGED,2016-02-03 18:46:20.000000000,2016-02-15 17:03:53.000000000,2016-02-15 17:03:53.000000000,"[{'_account_id': 3}, {'_account_id': 7230}, {'_account_id': 9095}]","[{'number': 1, 'created': '2016-02-03 18:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/70d48e85e5896ae5090bb4b30befd78439b2322c', 'message': 'Adding app scale command\n\nThe command should be executed as:\nsolum app scale <app-name/app-id> <target>\n\nwhere target is the number of target instances\nfor the specified app.\n\nChange-Id: I4badf572ded6327e49ed916a148a7bf7a0b62a57\nDepends-On: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541520\n'}, {'number': 2, 'created': '2016-02-05 22:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/0ed4160adf34d0d92905c7c8cb3ff72e6475ce40', 'message': 'Adding app scale command\n\nThe command should be executed as:\nsolum app scale <app-name/app-id> <target>\n\nwhere target is the number of target instances\nfor the specified app.\n\nChange-Id: I4badf572ded6327e49ed916a148a7bf7a0b62a57\nDepends-On: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541520\n'}, {'number': 3, 'created': '2016-02-10 15:35:42.000000000', 'files': ['solumclient/solum.py'], 'web_link': 'https://opendev.org/openstack/python-solumclient/commit/56aa97fe82e5c69b933bd1c0e74e4b0c719b05f6', 'message': 'Adding app scale command\n\nThe command should be executed as:\nsolum app scale <app-name/app-id> <target>\n\nwhere target is the number of target instances\nfor the specified app.\n\nChange-Id: I4badf572ded6327e49ed916a148a7bf7a0b62a57\nDepends-On: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541520\n'}]",0,275882,56aa97fe82e5c69b933bd1c0e74e4b0c719b05f6,11,3,3,2506,,,0,"Adding app scale command

The command should be executed as:
solum app scale <app-name/app-id> <target>

where target is the number of target instances
for the specified app.

Change-Id: I4badf572ded6327e49ed916a148a7bf7a0b62a57
Depends-On: I3240b98650f0474340f0a451d655e65cc3ec5813
Closes-Bug: #1541520
",git fetch https://review.opendev.org/openstack/python-solumclient refs/changes/82/275882/3 && git format-patch -1 --stdout FETCH_HEAD,['solumclient/solum.py'],1,70d48e85e5896ae5090bb4b30befd78439b2322c,bug/1541520," solum app scale <NAME|ID> <scaling target> def _create_scaling_workflow(self, actions, app_name_id, tgt): app = self.client.apps.find(name_or_id=app_name_id) wf = (cli_wf.WorkflowManager(self.client, app_id=app.id).create(actions=actions, scale_target=tgt)) fields = ['wf_id', 'app_id', 'actions', 'config', 'source', 'id', 'created_at', 'updated_at'] self._print_dict(wf, fields, wrap=72) def scale(self): """"""Scale the app."""""" self.parser.add_argument('name') self.parser.add_argument('target') args = self.parser.parse_args() actions = ['deploy'] self._create_scaling_workflow(actions, args.name, args.target) ",,21,0
openstack%2Fpython-congressclient~master~I21f9037a7d069b4195655de138c534978962c908,openstack/python-congressclient,master,I21f9037a7d069b4195655de138c534978962c908,Updated from global requirements,MERGED,2016-02-10 21:58:41.000000000,2016-02-15 16:59:15.000000000,2016-02-15 16:59:15.000000000,"[{'_account_id': 3}, {'_account_id': 8215}]","[{'number': 1, 'created': '2016-02-10 21:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/396ddd39b060fccc9dce01b39ae9a153752793f4', 'message': 'Updated from global requirements\n\nChange-Id: I21f9037a7d069b4195655de138c534978962c908\n'}, {'number': 2, 'created': '2016-02-11 07:44:12.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-congressclient/commit/1e030f02acb6d5a7e3937cebfca16697cb2a5630', 'message': 'Updated from global requirements\n\nChange-Id: I21f9037a7d069b4195655de138c534978962c908\n'}]",0,278723,1e030f02acb6d5a7e3937cebfca16697cb2a5630,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: I21f9037a7d069b4195655de138c534978962c908
",git fetch https://review.opendev.org/openstack/python-congressclient refs/changes/23/278723/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,396ddd39b060fccc9dce01b39ae9a153752793f4,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,2,2
openstack%2Ffuel-web~master~If839ee66349e30ac5d7e8df043d3b3def3c14b89,openstack/fuel-web,master,If839ee66349e30ac5d7e8df043d3b3def3c14b89,Enabled task based deployment engine by default,MERGED,2016-01-28 18:08:01.000000000,2016-02-15 16:50:02.000000000,2016-02-15 16:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8776}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11090}, {'_account_id': 11898}, {'_account_id': 12559}, {'_account_id': 13505}, {'_account_id': 14543}, {'_account_id': 14985}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 19196}]","[{'number': 1, 'created': '2016-01-28 18:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f923870d61949cf9b192a0a809a50506bcd3dad9', 'message': 'Enabled task based deployment engine by default\n\nThe task based deployemnt engine is default engine for 9.0\n\nChange-Id: If839ee66349e30ac5d7e8df043d3b3def3c14b89\nImplements: blueprint enable-task-based-deployment\n'}, {'number': 2, 'created': '2016-02-01 10:29:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f2cf41f1a10edc7c12e92794fdf60711b1c92b3e', 'message': 'Enabled task based deployment engine by default\n\nThe task based deployment engine is default engine for 9.0\n\nChange-Id: If839ee66349e30ac5d7e8df043d3b3def3c14b89\nImplements: blueprint enable-task-based-deployment\n'}, {'number': 3, 'created': '2016-02-01 11:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b60bd3987036cd1213d106765441a6ea738744cb', 'message': 'Enabled task based deployment engine by default\n\nThe task based deployment engine is default engine for 9.0\n\nChange-Id: If839ee66349e30ac5d7e8df043d3b3def3c14b89\nImplements: blueprint enable-task-based-deployment\n'}, {'number': 4, 'created': '2016-02-01 14:41:55.000000000', 'files': ['nailgun/nailgun/test/integration/test_task_deploy.py', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/446148d7e281f6e9649f4f63e4357a8a6bbd761c', 'message': 'Enabled task based deployment engine by default\n\nThe task based deployment engine is default engine for 9.0\n\nChange-Id: If839ee66349e30ac5d7e8df043d3b3def3c14b89\nImplements: blueprint enable-task-based-deployment\n'}]",5,273693,446148d7e281f6e9649f4f63e4357a8a6bbd761c,59,18,4,18205,,,0,"Enabled task based deployment engine by default

The task based deployment engine is default engine for 9.0

Change-Id: If839ee66349e30ac5d7e8df043d3b3def3c14b89
Implements: blueprint enable-task-based-deployment
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/93/273693/3 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/test/integration/test_task_deploy.py', 'nailgun/nailgun/fixtures/openstack.yaml']",2,f923870d61949cf9b192a0a809a50506bcd3dad9,bp/enable-task-based-deployment," value: true description: ""The new deployment engine based on cross-node dependencies for deployment tasks."" - condition: ""true"""," value: false description: ""Enables new deployment engine based on cross-node dependencies for deployment tasks which allows to deploy all nodes simultaneously. Works only for deployment tasks with version >= 2.0.0."" - condition: ""not ('experimental' in version:feature_groups)""",7,11
openstack%2Fsolum~master~I3240b98650f0474340f0a451d655e65cc3ec5813,openstack/solum,master,I3240b98650f0474340f0a451d655e65cc3ec5813,Adding functionality to support scaling of an app,MERGED,2016-02-03 18:41:00.000000000,2016-02-15 16:49:32.000000000,2016-02-15 16:49:31.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 7230}, {'_account_id': 9095}]","[{'number': 1, 'created': '2016-02-03 18:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/16b2e7bae0dbeca096a859c5265541859764940e', 'message': 'Adding functionality to support scaling of an app\n\nChange-Id: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541545\n'}, {'number': 2, 'created': '2016-02-05 22:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/44da15169f760aa80ad757c5c1678f7d74eb810f', 'message': ""Adding functionality to support scaling of an app\n\nTowards scaling this patch adds the following:\n\n1) Method in workflow_handler which updates the app's\n   row in the app table with scale_config data.\n\n   We update scale_config in two situations.\n   First, when 'solum app deploy' is called. As part\n   of this call we store the default scaling target of '1'\n   in the scale_config column.\n   Second, when 'solum app scale' is called. As part of\n   this call we expect scale_target to be sent in and we\n   store that in the scale_config column.\n\n2) Method in heat deployer to save the du ref which can\n   be used during the scaling call.\n\n   We save the du's location in the scale_config column for\n   the app as part of the deploy method\n\n3) 'scale' method in the deployer's api.\n\n    Currently this method is empty, but the idea is to use\n    the scale_config column for the app to figure out the\n    'target' and the 'du' which have been saved earlier to\n    perform app scaling.\n\nChange-Id: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541545\n""}, {'number': 3, 'created': '2016-02-10 15:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/3520d4b9b3a2dfd4ad9f6c57b7a5eaea8c85e189', 'message': ""Adding functionality to support scaling of an app\n\nTowards scaling this patch adds the following:\n\n1) Method in workflow_handler which updates the app's\n   row in the app table with scale_config data.\n\n   We update scale_config in two situations.\n   First, when 'solum app deploy' is called. As part\n   of this call we store the default scaling target of '1'\n   in the scale_config column.\n   Second, when 'solum app scale' is called. As part of\n   this call we expect scale_target to be sent in and we\n   store that in the scale_config column.\n\n2) Method in heat deployer to save the du ref which can\n   be used during the scaling call.\n\n   We save the du's location in the scale_config column for\n   the app as part of the deploy method\n\n3) 'scale' method in the deployer's api.\n\n    Currently this method is empty, but the idea is to use\n    the scale_config column for the app to figure out the\n    'target' and the 'du' which have been saved earlier to\n    perform app scaling.\n\nChange-Id: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541545\n""}, {'number': 4, 'created': '2016-02-10 18:30:25.000000000', 'files': ['solum/deployer/api.py', 'solum/deployer/handlers/heat.py', 'solum/worker/handlers/shell.py', 'solum/api/handlers/workflow_handler.py', 'solum/tests/fakes.py', 'solum/api/controllers/v1/datamodel/workflow.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/b0a83ffce2afe259de48f01a4c09a1829e442b95', 'message': ""Adding functionality to support scaling of an app\n\nTowards scaling this patch adds the following:\n\n1) Method in workflow_handler which updates the app's\n   row in the app table with scale_config data.\n\n   We update scale_config in two situations.\n   First, when 'solum app deploy' is called. As part\n   of this call we store the default scaling target of '1'\n   in the scale_config column.\n   Second, when 'solum app scale' is called. As part of\n   this call we expect scale_target to be sent in and we\n   store that in the scale_config column.\n\n2) Method in heat deployer to save the du ref which can\n   be used during the scaling call.\n\n   We save the du's location in the scale_config column for\n   the app as part of the deploy method\n\n3) 'scale' method in the deployer's api.\n\n    Currently this method is empty, but the idea is to use\n    the scale_config column for the app to figure out the\n    'target' and the 'du' which have been saved earlier to\n    perform app scaling.\n\nChange-Id: I3240b98650f0474340f0a451d655e65cc3ec5813\nCloses-Bug: #1541545\n""}]",5,275878,b0a83ffce2afe259de48f01a4c09a1829e442b95,17,4,4,2506,,,0,"Adding functionality to support scaling of an app

Towards scaling this patch adds the following:

1) Method in workflow_handler which updates the app's
   row in the app table with scale_config data.

   We update scale_config in two situations.
   First, when 'solum app deploy' is called. As part
   of this call we store the default scaling target of '1'
   in the scale_config column.
   Second, when 'solum app scale' is called. As part of
   this call we expect scale_target to be sent in and we
   store that in the scale_config column.

2) Method in heat deployer to save the du ref which can
   be used during the scaling call.

   We save the du's location in the scale_config column for
   the app as part of the deploy method

3) 'scale' method in the deployer's api.

    Currently this method is empty, but the idea is to use
    the scale_config column for the app to figure out the
    'target' and the 'du' which have been saved earlier to
    perform app scaling.

Change-Id: I3240b98650f0474340f0a451d655e65cc3ec5813
Closes-Bug: #1541545
",git fetch https://review.opendev.org/openstack/solum refs/changes/78/275878/2 && git format-patch -1 --stdout FETCH_HEAD,['solum/api/controllers/v1/datamodel/workflow.py'],1,16b2e7bae0dbeca096a859c5265541859764940e,bug/1541545, scale_target = wtypes.text,,1,0
openstack%2Fkeystonemiddleware~master~I2aae5483c9309ab75985298c8de5b6f24cbc0f0d,openstack/keystonemiddleware,master,I2aae5483c9309ab75985298c8de5b6f24cbc0f0d,Split oslo_config and list all opts,MERGED,2016-01-14 02:39:13.000000000,2016-02-15 16:49:19.000000000,2016-02-15 16:49:19.000000000,"[{'_account_id': 3}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 8119}]","[{'number': 1, 'created': '2016-01-14 02:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/ea79c694cafa45b9d684dbe5bd65de28f9c0dce4', 'message': 'Split oslo_config and list all opts\n\nThe intent of providing the list_auth_token_opts function was to provide\nthe oslo_config sample config file generator a list of options to\ninclude in its sample files. However, services like zaqar have come to\nrely on the list_auth_token_opts to list all the options that may be\nconsumed by auth_token middleware so that they can register them against\na non-global oslo_config object.\n\nBy removing deprecated options from the list_auth_token_opts we remove\nthese options from the config objects that the services use, however by\nkeeping them we will forever have deprecated options in sample config\nfiles.\n\nTo split these two functionalities create a new function that lists the\noptions available for sample config files and update the entrypoint to\nreflect this. This function is currently private because it should only\nneed to be accessed via entrypoint. The old deprecated options are then\nadded back to the original list_auth_token_opts function.\n\nCloses-Bug: #1533932\nChange-Id: I2aae5483c9309ab75985298c8de5b6f24cbc0f0d\n'}, {'number': 2, 'created': '2016-01-14 06:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c764e084775b9a1706c294fb6494d2d3803a9c4c', 'message': 'Split oslo_config and list all opts\n\nThe intent of providing the list_auth_token_opts function was to provide\nthe oslo_config sample config file generator a list of options to\ninclude in its sample files. However, services like zaqar have come to\nrely on the list_auth_token_opts to list all the options that may be\nconsumed by auth_token middleware so that they can register them against\na non-global oslo_config object.\n\nBy removing deprecated options from the list_auth_token_opts we remove\nthese options from the config objects that the services use, however by\nkeeping them we will forever have deprecated options in sample config\nfiles.\n\nTo split these two functionalities create a new function that lists the\noptions available for sample config files and update the entrypoint to\nreflect this. This function is currently private because it should only\nneed to be accessed via entrypoint. The old deprecated options are then\nadded back to the original list_auth_token_opts function.\n\nCloses-Bug: #1533932\nChange-Id: I2aae5483c9309ab75985298c8de5b6f24cbc0f0d\n'}, {'number': 3, 'created': '2016-02-11 02:01:59.000000000', 'files': ['keystonemiddleware/auth_token/_opts.py', 'keystonemiddleware/opts.py', 'keystonemiddleware/tests/unit/test_opts.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/f0965c955dba16afaf350e65de2db68dc2c35c50', 'message': 'Split oslo_config and list all opts\n\nThe intent of providing the list_auth_token_opts function was to provide\nthe oslo_config sample config file generator a list of options to\ninclude in its sample files. However, services like zaqar have come to\nrely on the list_auth_token_opts to list all the options that may be\nconsumed by auth_token middleware so that they can register them against\na non-global oslo_config object.\n\nBy removing deprecated options from the list_auth_token_opts we remove\nthese options from the config objects that the services use, however by\nkeeping them we will forever have deprecated options in sample config\nfiles.\n\nTo split these two functionalities create a new function that lists the\noptions available for sample config files and update the entrypoint to\nreflect this. This function is currently private because it should only\nneed to be accessed via entrypoint. The old deprecated options are then\nadded back to the original list_auth_token_opts function.\n\nCloses-Bug: #1533932\nChange-Id: I2aae5483c9309ab75985298c8de5b6f24cbc0f0d\n'}]",6,267277,f0965c955dba16afaf350e65de2db68dc2c35c50,20,7,3,7191,,,0,"Split oslo_config and list all opts

The intent of providing the list_auth_token_opts function was to provide
the oslo_config sample config file generator a list of options to
include in its sample files. However, services like zaqar have come to
rely on the list_auth_token_opts to list all the options that may be
consumed by auth_token middleware so that they can register them against
a non-global oslo_config object.

By removing deprecated options from the list_auth_token_opts we remove
these options from the config objects that the services use, however by
keeping them we will forever have deprecated options in sample config
files.

To split these two functionalities create a new function that lists the
options available for sample config files and update the entrypoint to
reflect this. This function is currently private because it should only
need to be accessed via entrypoint. The old deprecated options are then
added back to the original list_auth_token_opts function.

Closes-Bug: #1533932
Change-Id: I2aae5483c9309ab75985298c8de5b6f24cbc0f0d
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/77/267277/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystonemiddleware/auth_token/_opts.py', 'keystonemiddleware/opts.py', 'keystonemiddleware/tests/unit/test_opts.py', 'setup.cfg']",4,ea79c694cafa45b9d684dbe5bd65de28f9c0dce4,bug/1533932, keystonemiddleware.auth_token = keystonemiddleware.auth_token._opts:list_opts, keystonemiddleware.auth_token = keystonemiddleware.opts:list_auth_token_opts,125,8
openstack%2Ffuel-mirror~master~I468dabf5fb02e5580dab3edd435daf7e61584de8,openstack/fuel-mirror,master,I468dabf5fb02e5580dab3edd435daf7e61584de8,Add hwloc to ubuntu mirror,MERGED,2016-02-15 13:22:01.000000000,2016-02-15 16:49:12.000000000,2016-02-15 16:49:12.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 10474}, {'_account_id': 11898}, {'_account_id': 16771}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-15 13:22:01.000000000', 'files': ['contrib/fuel_mirror/data/ubuntu.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-mirror/commit/95e7536f0de3b1f55a883f72f90597fab358d718', 'message': 'Add hwloc to ubuntu mirror\n\nhwloc package is needed for discovering\nNUMA topology\n\nChange-Id: I468dabf5fb02e5580dab3edd435daf7e61584de8\nImplements: blueprint support-numa-cpu-pinning\n'}]",0,280205,95e7536f0de3b1f55a883f72f90597fab358d718,9,6,1,10488,,,0,"Add hwloc to ubuntu mirror

hwloc package is needed for discovering
NUMA topology

Change-Id: I468dabf5fb02e5580dab3edd435daf7e61584de8
Implements: blueprint support-numa-cpu-pinning
",git fetch https://review.opendev.org/openstack/fuel-mirror refs/changes/05/280205/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/fuel_mirror/data/ubuntu.yaml'],1,95e7536f0de3b1f55a883f72f90597fab358d718,bp/support-numa-cpu-pinning," - ""hwloc""",,1,0
openstack%2Fdragonflow~master~I97907130dd7a122748fb01183fdc279160c7f7ef,openstack/dragonflow,master,I97907130dd7a122748fb01183fdc279160c7f7ef,"Fix all in-one deployment, Multi publisher configuration",MERGED,2016-02-15 12:11:46.000000000,2016-02-15 16:49:07.000000000,2016-02-15 16:49:06.000000000,"[{'_account_id': 3}, {'_account_id': 11343}]","[{'number': 1, 'created': '2016-02-15 12:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/58169173d59e5c87d2be76e018f093e06eec933b', 'message': 'Fix all in-one deployment, Multi publisher configuration\n\nInstall the publisher ip list for the q-svc\n\nChange-Id: I97907130dd7a122748fb01183fdc279160c7f7ef\n'}, {'number': 2, 'created': '2016-02-15 15:51:41.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/2914bab5128a4fac56d97d8e83faa4cc828928ab', 'message': 'Fix all in-one deployment, Multi publisher configuration\n\nInstall the publisher ip list for the q-svc\n\nChange-Id: I97907130dd7a122748fb01183fdc279160c7f7ef\n'}]",0,280182,2914bab5128a4fac56d97d8e83faa4cc828928ab,10,2,2,13070,,,0,"Fix all in-one deployment, Multi publisher configuration

Install the publisher ip list for the q-svc

Change-Id: I97907130dd7a122748fb01183fdc279160c7f7ef
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/82/280182/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,58169173d59e5c87d2be76e018f093e06eec933b,pubsub," iniset $NEUTRON_CONF df publishers_ips ""$PUBLISHERS_HOSTS""",,1,0
openstack%2Frequirements~master~I92cf48d55b83472bb8e5dbb189b4d4cd4807593c,openstack/requirements,master,I92cf48d55b83472bb8e5dbb189b4d4cd4807593c,"Add ""virtualbmc"" dependency",ABANDONED,2016-02-15 14:43:45.000000000,2016-02-15 16:48:04.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-15 14:43:45.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3af9a5818581e973d17a32c3dd8dae52b5f0c9dc', 'message': 'Add ""virtualbmc"" dependency\n\nThis patch is adding the ""virtualbmc"" project to the global-requirements\nfile.\n\nThe project is a small utility/library that allows users to create\nvirtual/fake BMCs that will convert IPMI commands to libvirt commands;\nthis does allow the Ironic project to test the same driver used with\nfor the physical hardware with VMs in gate.\n\nCurrently, Ironic uses a testing driver called ""ssh"" (pxe_ssh, agent_ssh)\nwhich is responsible for power controlling the VMs by SSH\'ing into the\nhost and issuing virsh commands. This approach is not ideal because we\nare not actually testing a driver that we recommend for production in\nthe gate.\n\nPartial-Bug: #1544642\nChange-Id: I92cf48d55b83472bb8e5dbb189b4d4cd4807593c\n'}]",0,280265,3af9a5818581e973d17a32c3dd8dae52b5f0c9dc,3,1,1,6773,,,0,"Add ""virtualbmc"" dependency

This patch is adding the ""virtualbmc"" project to the global-requirements
file.

The project is a small utility/library that allows users to create
virtual/fake BMCs that will convert IPMI commands to libvirt commands;
this does allow the Ironic project to test the same driver used with
for the physical hardware with VMs in gate.

Currently, Ironic uses a testing driver called ""ssh"" (pxe_ssh, agent_ssh)
which is responsible for power controlling the VMs by SSH'ing into the
host and issuing virsh commands. This approach is not ideal because we
are not actually testing a driver that we recommend for production in
the gate.

Partial-Bug: #1544642
Change-Id: I92cf48d55b83472bb8e5dbb189b4d4cd4807593c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/65/280265/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,3af9a5818581e973d17a32c3dd8dae52b5f0c9dc,bug/1544642,virtualbmc # Apache-2.0,,1,0
openstack%2Ffuel-qa~stable%2F8.0~I039582528d0bac93823d89a7357b1f74a10d0155,openstack/fuel-qa,stable/8.0,I039582528d0bac93823d89a7357b1f74a10d0155,Add new cli test from acceptance test plan,MERGED,2016-02-12 11:56:10.000000000,2016-02-15 16:45:47.000000000,2016-02-15 16:45:47.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}, {'_account_id': 15984}]","[{'number': 1, 'created': '2016-02-12 11:56:10.000000000', 'files': ['fuelweb_test/tests/tests_cli/test_cli_deploy_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/d8829138c83038b35f8780628bc6bb9dab047b40', 'message': 'Add new cli test from acceptance test plan\n\nDeployment using CLI with 3 controlelrs, NeutronVLAN, both Ceph\n\nCloses-Bug: #1524772\nChange-Id: I039582528d0bac93823d89a7357b1f74a10d0155\n(cherry picked from commit 49d6a23c99558ab8f042a2173a60eb524691d07b)\n'}]",0,279497,d8829138c83038b35f8780628bc6bb9dab047b40,15,5,1,15943,,,0,"Add new cli test from acceptance test plan

Deployment using CLI with 3 controlelrs, NeutronVLAN, both Ceph

Closes-Bug: #1524772
Change-Id: I039582528d0bac93823d89a7357b1f74a10d0155
(cherry picked from commit 49d6a23c99558ab8f042a2173a60eb524691d07b)
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/97/279497/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_cli/test_cli_deploy_ceph.py'],1,d8829138c83038b35f8780628bc6bb9dab047b40,I039582528d0bac93823d89a7357b1f74a10d0155," @test(depends_on=[SetupEnvironment.prepare_slaves_9], groups=[""cli_deploy_ceph_neutron_vlan""]) @log_snapshot_after_test def cli_deploy_ceph_neutron_vlan(self): """""" Deployment with 3 controlelrs, NeutronVLAN, both Ceph Scenario: 1. Create new environment 2. Choose Neutron, VLAN 3. Choose Ceph for volumes and Ceph for images 4. Add 3 controller, 2 compute, 3 ceph 5. Verify networks 6. Deploy the environment 7. Verify networks 8. Run OSTF tests Duration: 60 min """""" self.env.revert_snapshot(""ready_with_9_slaves"") node_ids = [self.fuel_web.get_nailgun_node_by_devops_node( self.env.d_env.nodes().slaves[slave_id])['id'] for slave_id in range(8)] release_id = self.fuel_web.get_releases_list_for_os( release_name=OPENSTACK_RELEASE)[0] admin_ip = self.ssh_manager.admin_ip self.show_step(1) self.show_step(2) cluster = self.ssh_manager.execute_on_remote( ip=admin_ip, cmd='fuel env create --name={0} --release={1} ' '--nst=vlan --json'.format(self.__class__.__name__, release_id), jsonify=True )['stdout_json'] self.show_step(3) with self.env.d_env.get_admin_remote() as remote: self.use_ceph_for_volumes(cluster['id'], remote) self.use_ceph_for_images(cluster['id'], remote) nodes = { 'controller': node_ids[0:3], 'compute': node_ids[3:5], 'ceph-osd': node_ids[5:8] } self.show_step(4) for role in nodes: self.ssh_manager.execute_on_remote( ip=admin_ip, cmd='fuel --env-id={0} node set ' '--node {1} --role={2}'.format( cluster['id'], ','.join(map(str, nodes[role])), role) ) self.show_step(5) self.fuel_web.verify_network(cluster['id']) self.show_step(6) task = self.ssh_manager.execute_on_remote( ip=admin_ip, cmd='fuel --env-id={0} ' 'deploy-changes --json'.format(cluster['id']), jsonify=True )['stdout_json'] with self.env.d_env.get_admin_remote() as remote: self.assert_cli_task_success(task, remote, timeout=130 * 60) self.show_step(7) self.fuel_web.verify_network(cluster['id']) self.show_step(8) self.fuel_web.run_ostf( cluster_id=cluster['id'], test_sets=['ha', 'smoke', 'sanity'] )",,82,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Icc2a45aa9514ce62497f91e6abe9261d1c1374ed,openstack/tripleo-heat-templates,stable/liberty,Icc2a45aa9514ce62497f91e6abe9261d1c1374ed,Fix tunnel_types hieradata on compute nodes,MERGED,2016-01-19 19:40:34.000000000,2016-02-15 16:41:53.000000000,2016-02-15 16:41:53.000000000,"[{'_account_id': 3}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-19 19:40:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a87557149d83c2b344a4b6a4ca9862d57e76d8c7', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}, {'number': 2, 'created': '2016-01-19 22:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/75180f3be22c06ba331e02dfe5638f8b2ec6656a', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}, {'number': 3, 'created': '2016-01-20 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9e79430d50a8a7b96adfcc4975fcfb0efe7afe44', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}, {'number': 4, 'created': '2016-02-11 18:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e61a0b142a485bbc9b12cede1c05576aedc61d2b', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}, {'number': 5, 'created': '2016-02-12 18:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f9cb1b8e2c4c3eeb048adcf09b67f029d94f419d', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}, {'number': 6, 'created': '2016-02-12 21:08:36.000000000', 'files': ['puppet/compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f87cb3f325d5a4b5dba34726874d77bf908f48e6', 'message': 'Fix tunnel_types hieradata on compute nodes\n\nThere was a missing : in the hieradata for the compute nodes that\ncaused tunnel_types to not be configured.  This also made it\nimpossible to boot instances on tunneled networks because the port\nbinding always failed.\n\nChange-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed\nCloses-Bug: 1534349\n(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)\n'}]",0,269829,f87cb3f325d5a4b5dba34726874d77bf908f48e6,45,5,6,6928,,,0,"Fix tunnel_types hieradata on compute nodes

There was a missing : in the hieradata for the compute nodes that
caused tunnel_types to not be configured.  This also made it
impossible to boot instances on tunneled networks because the port
binding always failed.

Change-Id: Icc2a45aa9514ce62497f91e6abe9261d1c1374ed
Closes-Bug: 1534349
(cherry picked from commit 11c5ab45017de16a06de7f4a7eed814dd5efcc25)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/29/269829/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/compute.yaml'],1,a87557149d83c2b344a4b6a4ca9862d57e76d8c7,bug/1519525, neutron::agents::ml2::ovs::tunnel_types: {get_input: neutron_tunnel_types}, neutron::agents::ml2::ovs:tunnel_types: {get_input: neutron_tunnel_types},1,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~If069686583b7988e871dde281df2453b33bf2c0f,openstack/tripleo-heat-templates,stable/liberty,If069686583b7988e871dde281df2453b33bf2c0f,Wire Neutron ML2 plugin and OVS agent settings as arrays,MERGED,2016-01-19 22:49:52.000000000,2016-02-15 16:41:46.000000000,2016-02-15 16:41:46.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6681}, {'_account_id': 6928}, {'_account_id': 7144}]","[{'number': 1, 'created': '2016-01-19 22:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a1265a4ac8ffe80b911bb2cc83e4561811893e67', 'message': ""Wire Neutron ML2 plugin and OVS agent settings as arrays\n\nThis is a revert of a revert, but I'm re-cherry-picking\nbecause the revert was combined with another revert that\nisn't ready to be un-reverted yet.\n\nThe main point is that there was a bug in this commit\nthat will be fixed in a follow-up commit, so we can put\nthis one back in.\n\nWires the following as arrays to the neutron module:\n - mechanism_drivers\n - flat_networks\n - tenant_network_types\n - tunnel_types\n - bridge_mappings\n\nAlso updates the template version to use a Liberty feature which\nallows serialization of comma_delimited_list into JSON.\n\nTidies up the manifests by removing the class declarations since\nconfig is passed by the puppet/controller+compute hiera mapped_data.\n\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\n(cherry picked from commit a2cb9e478d9a4cfaf064a2956bffe6d414bd47c0)\n\nChange-Id: If069686583b7988e871dde281df2453b33bf2c0f\n""}, {'number': 2, 'created': '2016-01-20 15:39:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f56191f2593834684157d487044c4fa719cdd323', 'message': ""Wire Neutron ML2 plugin and OVS agent settings as arrays\n\nThis was merged in a broken state, then got reverted in a patch\nthat removed two patches at once, and now a fix has merged to\nmaster that makes it work correctly.  I'm re-cherry-picking it\nfrom the original stable commit because disentangling it from\nthe other patch that got reverted would be a headache.\n\nWires the following as arrays to the neutron module:\n - mechanism_drivers\n - flat_networks\n - tenant_network_types\n - tunnel_types\n - bridge_mappings\n\nAlso updates the template version to use a Liberty feature which\nallows serialization of comma_delimited_list into JSON.\n\nTidies up the manifests by removing the class declarations since\nconfig is passed by the puppet/controller+compute hiera mapped_data.\n\nChange-Id: If069686583b7988e871dde281df2453b33bf2c0f\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\n(cherry picked from commit a2cb9e478d9a4cfaf064a2956bffe6d414bd47c0)\n(cherry picked from commit 39e8afe898c98815ff4e0292695110647bb44ddc)\n""}, {'number': 3, 'created': '2016-02-11 18:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e26080a3aa5488de8ba3a5a5a64e3c4f3834ece1', 'message': ""Wire Neutron ML2 plugin and OVS agent settings as arrays\n\nThis was merged in a broken state, then got reverted in a patch\nthat removed two patches at once, and now a fix has merged to\nmaster that makes it work correctly.  I'm re-cherry-picking it\nfrom the original stable commit because disentangling it from\nthe other patch that got reverted would be a headache.\n\nWires the following as arrays to the neutron module:\n - mechanism_drivers\n - flat_networks\n - tenant_network_types\n - tunnel_types\n - bridge_mappings\n\nAlso updates the template version to use a Liberty feature which\nallows serialization of comma_delimited_list into JSON.\n\nTidies up the manifests by removing the class declarations since\nconfig is passed by the puppet/controller+compute hiera mapped_data.\n\nChange-Id: If069686583b7988e871dde281df2453b33bf2c0f\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\n(cherry picked from commit a2cb9e478d9a4cfaf064a2956bffe6d414bd47c0)\n(cherry picked from commit 39e8afe898c98815ff4e0292695110647bb44ddc)\n""}, {'number': 4, 'created': '2016-02-12 18:04:51.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/controller.yaml', 'puppet/manifests/overcloud_compute.pp', 'overcloud.yaml', 'puppet/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0a29f07e51d86f1c7098ae2b0001d134ddc2078a', 'message': ""Wire Neutron ML2 plugin and OVS agent settings as arrays\n\nThis was merged in a broken state, then got reverted in a patch\nthat removed two patches at once, and now a fix has merged to\nmaster that makes it work correctly.  I'm re-cherry-picking it\nfrom the original stable commit because disentangling it from\nthe other patch that got reverted would be a headache.\n\nWires the following as arrays to the neutron module:\n - mechanism_drivers\n - flat_networks\n - tenant_network_types\n - tunnel_types\n - bridge_mappings\n\nAlso updates the template version to use a Liberty feature which\nallows serialization of comma_delimited_list into JSON.\n\nTidies up the manifests by removing the class declarations since\nconfig is passed by the puppet/controller+compute hiera mapped_data.\n\nChange-Id: If069686583b7988e871dde281df2453b33bf2c0f\nCo-Authored-By: Steven Hardy <shardy@redhat.com>\n(cherry picked from commit a2cb9e478d9a4cfaf064a2956bffe6d414bd47c0)\n(cherry picked from commit 39e8afe898c98815ff4e0292695110647bb44ddc)\n""}]",1,269898,0a29f07e51d86f1c7098ae2b0001d134ddc2078a,26,5,4,6928,,,0,"Wire Neutron ML2 plugin and OVS agent settings as arrays

This was merged in a broken state, then got reverted in a patch
that removed two patches at once, and now a fix has merged to
master that makes it work correctly.  I'm re-cherry-picking it
from the original stable commit because disentangling it from
the other patch that got reverted would be a headache.

Wires the following as arrays to the neutron module:
 - mechanism_drivers
 - flat_networks
 - tenant_network_types
 - tunnel_types
 - bridge_mappings

Also updates the template version to use a Liberty feature which
allows serialization of comma_delimited_list into JSON.

Tidies up the manifests by removing the class declarations since
config is passed by the puppet/controller+compute hiera mapped_data.

Change-Id: If069686583b7988e871dde281df2453b33bf2c0f
Co-Authored-By: Steven Hardy <shardy@redhat.com>
(cherry picked from commit a2cb9e478d9a4cfaf064a2956bffe6d414bd47c0)
(cherry picked from commit 39e8afe898c98815ff4e0292695110647bb44ddc)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/269898/4 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/controller.yaml', 'puppet/manifests/overcloud_compute.pp', 'overcloud.yaml', 'puppet/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp']",6,a1265a4ac8ffe80b911bb2cc83e4561811893e67,bug/1534349," include ::neutron::plugins::ml2 class { '::neutron::agents::ml2::ovs': manage_service => false, enabled => false, } if 'cisco_ucsm' in hiera('neutron::plugins::ml2::mechanism_drivers') { if 'cisco_nexus' in hiera('neutron::plugins::ml2::mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron::plugins::ml2::mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron::plugins::ml2::mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron::plugins::ml2::mechanism_drivers') {"," class { '::neutron::plugins::ml2': flat_networks => split(hiera('neutron_flat_networks'), ','), tenant_network_types => [hiera('neutron_tenant_network_type')], mechanism_drivers => [hiera('neutron_mechanism_drivers')], } class { '::neutron::agents::ml2::ovs': manage_service => false, enabled => false, bridge_mappings => split(hiera('neutron_bridge_mappings'), ','), tunnel_types => split(hiera('neutron_tunnel_types'), ','), } if 'cisco_ucsm' in hiera('neutron_mechanism_drivers') { if 'cisco_nexus' in hiera('neutron_mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron_mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron_mechanism_drivers') { if 'cisco_n1kv' in hiera('neutron_mechanism_drivers') {",130,144
openstack%2Fdesignate~stable%2Fliberty~Ia51e12d171512db4e9bc6fc1dd3eb66c951051e8,openstack/designate,stable/liberty,Ia51e12d171512db4e9bc6fc1dd3eb66c951051e8,Fix _assert_exception(),MERGED,2016-01-27 17:16:14.000000000,2016-02-15 16:32:32.000000000,2016-02-15 16:32:32.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 6662}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2016-01-27 17:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/aff5628d3f8f5d33d263b5821013faa8c0b3c718', 'message': 'Fix _assert_exception()\n\n_assert_exception() is expected to catch the case where an exception\nwith certain data must be thrown out. But it misses the case that no\nexception is thrown. This patch fixes the bug.\n\nChange-Id: Ia51e12d171512db4e9bc6fc1dd3eb66c951051e8\nCloses-bug: #1537892\n'}, {'number': 2, 'created': '2016-01-28 20:36:55.000000000', 'files': ['functionaltests/api/v2/base.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/f67e9ff1975f97ff21926cac635d67fd5476d182', 'message': 'Fix _assert_exception()\n\n_assert_exception() is expected to catch the case where an exception\nwith certain data must be thrown out. But it misses the case that no\nexception is thrown. This patch fixes the bug.\n\nChange-Id: Ia51e12d171512db4e9bc6fc1dd3eb66c951051e8\nCloses-bug: #1537892\n'}]",0,273161,f67e9ff1975f97ff21926cac635d67fd5476d182,12,5,2,741,,,0,"Fix _assert_exception()

_assert_exception() is expected to catch the case where an exception
with certain data must be thrown out. But it misses the case that no
exception is thrown. This patch fixes the bug.

Change-Id: Ia51e12d171512db4e9bc6fc1dd3eb66c951051e8
Closes-bug: #1537892
",git fetch https://review.opendev.org/openstack/designate refs/changes/61/273161/1 && git format-patch -1 --stdout FETCH_HEAD,['functionaltests/api/v2/base.py'],1,aff5628d3f8f5d33d263b5821013faa8c0b3c718,bug/1537892," else: raise self.failureException(""Test failed due to no exception."")",,2,0
openstack%2Fdesignate~stable%2Fliberty~I27395999b2002374a74bddad71333f508354f37b,openstack/designate,stable/liberty,I27395999b2002374a74bddad71333f508354f37b,Fixes wording of exceptions for delete,MERGED,2016-01-27 17:15:42.000000000,2016-02-15 16:32:25.000000000,2016-02-15 16:32:25.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 8174}, {'_account_id': 11752}]","[{'number': 1, 'created': '2016-01-27 17:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/30dc7cbd8adf8781c54ffa2470163584e663fde4', 'message': 'Fixes wording of exceptions for delete\n\nUpdated the wording of exceptions that prevent the deletion of\nmanaged records. Original message indicated that user was\nunable to update when the user actually requested a delete.\nNew message is ""Managed records may not be deleted""\nBoth exceptions in designate/central/service.py\n\nChange-Id: I27395999b2002374a74bddad71333f508354f37b\nCloses-Bug: #1511230\n'}, {'number': 2, 'created': '2016-01-28 20:36:39.000000000', 'files': ['designate/central/service.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/6b412e8647beae0e6e9215ab640ec50ff750d665', 'message': 'Fixes wording of exceptions for delete\n\nUpdated the wording of exceptions that prevent the deletion of\nmanaged records. Original message indicated that user was\nunable to update when the user actually requested a delete.\nNew message is ""Managed records may not be deleted""\nBoth exceptions in designate/central/service.py\n\nChange-Id: I27395999b2002374a74bddad71333f508354f37b\nCloses-Bug: #1511230\n'}]",0,273160,6b412e8647beae0e6e9215ab640ec50ff750d665,10,5,2,741,,,0,"Fixes wording of exceptions for delete

Updated the wording of exceptions that prevent the deletion of
managed records. Original message indicated that user was
unable to update when the user actually requested a delete.
New message is ""Managed records may not be deleted""
Both exceptions in designate/central/service.py

Change-Id: I27395999b2002374a74bddad71333f508354f37b
Closes-Bug: #1511230
",git fetch https://review.opendev.org/openstack/designate refs/changes/60/273160/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/central/service.py'],1,30dc7cbd8adf8781c54ffa2470163584e663fde4,bug/1511230, raise exceptions.BadRequest('Managed records may not be deleted') raise exceptions.BadRequest('Managed records may not be deleted'), raise exceptions.BadRequest('Managed records may not be updated') raise exceptions.BadRequest('Managed records may not be updated'),2,2
openstack%2Fdesignate~master~I6892433b5c112563901dbac2b477bf3d9e56217b,openstack/designate,master,I6892433b5c112563901dbac2b477bf3d9e56217b,Ensure ZoneManager emits valid objects,MERGED,2016-02-15 11:15:59.000000000,2016-02-15 16:31:34.000000000,2016-02-15 16:31:34.000000000,"[{'_account_id': 3}, {'_account_id': 8099}, {'_account_id': 8174}]","[{'number': 1, 'created': '2016-02-15 11:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/861935366715338826f6d208b9539b378085d932', 'message': 'Ensure ZoneManager emits valid objects\n\nZone Manager exists events have been sending Designate obj\nrepresentiations rather than plain dicts.\n\nChange-Id: I6892433b5c112563901dbac2b477bf3d9e56217b\nCloses-Bug: 1545658\n'}, {'number': 2, 'created': '2016-02-15 11:52:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/06ca431f58e982e4cf9608a9aff62385e8db2f87', 'message': 'Ensure ZoneManager emits valid objects\n\nZone Manager exists events have been sending Designate obj\nrepresentiations rather than plain dicts. Additionally,\nthe audit period values were not in the correct format\ndue to an explicit datetime -> str cast vs allowing the\nserializer to handle the conversion.\n\nChange-Id: I6892433b5c112563901dbac2b477bf3d9e56217b\nCloses-Bug: 1545658\n'}, {'number': 3, 'created': '2016-02-15 12:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/4ba56b3ed3be1d73e1c72c93458caf4060db05da', 'message': 'Ensure ZoneManager emits valid objects\n\nZone Manager exists events have been sending Designate obj\nrepresentiations rather than plain dicts. Additionally,\nthe audit period values were not in the correct format\ndue to an explicit datetime -> str cast vs allowing the\nserializer to handle the conversion.\n\nAdditionally, remove duplicated RoObject class and implement\nthe to_dict() method.\n\nChange-Id: I6892433b5c112563901dbac2b477bf3d9e56217b\nCloses-Bug: 1545658\n'}, {'number': 4, 'created': '2016-02-15 12:07:51.000000000', 'files': ['designate/zone_manager/tasks.py', 'designate/tests/unit/__init__.py', 'designate/tests/unit/test_zone_manager/test_tasks.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/0022fd85b6cc91425eb0d87f066c162c0074ca0d', 'message': 'Ensure ZoneManager emits valid objects\n\nZone Manager exists events have been sending Designate obj\nrepresentiations rather than plain dicts. Additionally,\nthe audit period values were not in the correct format\ndue to an explicit datetime -> str cast vs allowing the\nserializer to handle the conversion.\n\nAdditionally, remove duplicated RoObject class and implement\nthe to_dict() method.\n\nChange-Id: I6892433b5c112563901dbac2b477bf3d9e56217b\nCloses-Bug: 1545658\n'}]",0,280161,0022fd85b6cc91425eb0d87f066c162c0074ca0d,13,3,4,741,,,0,"Ensure ZoneManager emits valid objects

Zone Manager exists events have been sending Designate obj
representiations rather than plain dicts. Additionally,
the audit period values were not in the correct format
due to an explicit datetime -> str cast vs allowing the
serializer to handle the conversion.

Additionally, remove duplicated RoObject class and implement
the to_dict() method.

Change-Id: I6892433b5c112563901dbac2b477bf3d9e56217b
Closes-Bug: 1545658
",git fetch https://review.opendev.org/openstack/designate refs/changes/61/280161/1 && git format-patch -1 --stdout FETCH_HEAD,['designate/zone_manager/tasks.py'],1,861935366715338826f6d208b9539b378085d932,bug/1545658," msg = _LI(""Emitting zone exist events for shards %(start)s to %(end)s"") extra_data = { counter = 0 for zone in self._iter_zones(ctxt): counter += 1 zone_data = zone.to_dict() zone_data.update(extra_data) LOG.info(_LI(""Finished emitting %(counter)d events for shards "" ""%(start)s to %(end)s""), {""start"": pstart, ""end"": pend, ""counter"": counter})"," msg = _LI(""Emitting zone exist events for %(start)s to %(end)s"") data = { for zone in self._iter_zones(ctxt): zone_data = dict(zone) zone_data.update(data) LOG.info(_LI(""Finished emitting events.""))",13,5
openstack%2Fkolla~master~I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4,openstack/kolla,master,I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4,"Use uppercase 'S' in word ""OpenStack""",MERGED,2016-02-04 13:43:06.000000000,2016-02-15 16:23:37.000000000,2016-02-15 16:23:37.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 3098}, {'_account_id': 7488}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-04 13:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1bdce404f26137fe3afaaa6b8e66637925d76ffb', 'message': 'Use uppercase \'S\' in word ""OpenStack""\n\nChange-Id: I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4\n'}, {'number': 2, 'created': '2016-02-04 14:24:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fcda96fbdf1ef6d5ea51390f6291892b58fe554a', 'message': 'Use uppercase \'S\' in word ""OpenStack""\n\nChange-Id: I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4\n'}, {'number': 3, 'created': '2016-02-15 12:37:43.000000000', 'files': ['ansible/roles/mistral/defaults/main.yml', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/swift/defaults/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'etc/kolla/passwords.yml', 'ansible/roles/heat/defaults/main.yml', 'specs/ansible-multi.rst', 'kolla/common/config.py', 'ansible/roles/cinder/defaults/main.yml', 'ansible/group_vars/all.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/ironic/defaults/main.yml', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/magnum/defaults/main.yml', 'etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/70de590a11528105b56d5c549a8436c34b88426a', 'message': 'Use uppercase \'S\' in word ""OpenStack""\n\nChange-Id: I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4\n'}]",0,276230,70de590a11528105b56d5c549a8436c34b88426a,17,7,3,16237,,,0,"Use uppercase 'S' in word ""OpenStack""

Change-Id: I27ca0ea75f3d6a4371c91b3cb2c7a999ec90fbc4
",git fetch https://review.opendev.org/openstack/kolla refs/changes/30/276230/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ansible-multi.rst', 'kolla/common/config.py']",2,1bdce404f26137fe3afaaa6b8e66637925d76ffb,os-fix, help=('The method of the OpenStack install. The valid', help=('The method of the Openstack install. The valid',2,2
openstack%2Ffuel-qa~stable%2F7.0~Ia016dcac845d9b3dfa4179496fd9feff7ff6a4b8,openstack/fuel-qa,stable/7.0,Ia016dcac845d9b3dfa4179496fd9feff7ff6a4b8,Change logic for get job version,ABANDONED,2016-02-15 13:30:18.000000000,2016-02-15 16:15:01.000000000,,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2016-02-15 13:30:18.000000000', 'files': ['fuelweb_test/testrail/report.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/fab199067c58a1f2293e4cf33113ffb5cbfd8bdf', 'message': 'Change logic for get job version\n\nChanged logic for get job version to\ngenerate test_plan name in testrail reports.\nCloses-bug: #1545718\n\nChange-Id: Ia016dcac845d9b3dfa4179496fd9feff7ff6a4b8\n'}]",0,280215,fab199067c58a1f2293e4cf33113ffb5cbfd8bdf,9,5,1,7126,,,0,"Change logic for get job version

Changed logic for get job version to
generate test_plan name in testrail reports.
Closes-bug: #1545718

Change-Id: Ia016dcac845d9b3dfa4179496fd9feff7ff6a4b8
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/15/280215/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/testrail/report.py'],1,fab199067c58a1f2293e4cf33113ffb5cbfd8bdf,bug/1545718," custom_version = get_job_parameter(jenkins_build_data, 'CUSTOM_VERSION') if custom_version: swarm_timestamp = jenkins_build_data['timestamp'] / 1000 \ if 'timestamp' in jenkins_build_data else None return (TestRailSettings.milestone, time.strftime(""%D %H:%M"", time.localtime(swarm_timestamp)), custom_version) "," custom_version = get_job_parameter(jenkins_build_data, 'CUSTOM_VERSION') if custom_version: swarm_timestamp = jenkins_build_data['timestamp'] / 1000 \ if 'timestamp' in jenkins_build_data else None return (TestRailSettings.milestone, time.strftime(""%D %H:%M"", time.localtime(swarm_timestamp)), custom_version) ",8,8
openstack%2Ftosca-parser~master~Ibcbbf028a05faa56725048ac965839d3eeb2f271,openstack/tosca-parser,master,Ibcbbf028a05faa56725048ac965839d3eeb2f271,Add repositories section to ToscaTemplate,MERGED,2016-02-15 11:10:53.000000000,2016-02-15 16:07:39.000000000,2016-02-15 16:07:39.000000000,"[{'_account_id': 3}, {'_account_id': 6456}]","[{'number': 1, 'created': '2016-02-15 11:10:53.000000000', 'files': ['toscaparser/tests/test_toscatpl.py', 'toscaparser/tosca_template.py', 'toscaparser/tests/data/test_repositories_definition.yaml'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/139e7fd7d14dbe7736a6a1ddf08234532d6947ed', 'message': 'Add repositories section to ToscaTemplate\n\nChange-Id: Ibcbbf028a05faa56725048ac965839d3eeb2f271\nRelated-Bug: 1545641\n'}]",0,280159,139e7fd7d14dbe7736a6a1ddf08234532d6947ed,6,2,1,19724,,,0,"Add repositories section to ToscaTemplate

Change-Id: Ibcbbf028a05faa56725048ac965839d3eeb2f271
Related-Bug: 1545641
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/59/280159/1 && git format-patch -1 --stdout FETCH_HEAD,"['toscaparser/tests/test_toscatpl.py', 'toscaparser/tosca_template.py', 'toscaparser/tests/data/test_repositories_definition.yaml']",3,139e7fd7d14dbe7736a6a1ddf08234532d6947ed,bug/1545641,tosca_definitions_version: tosca_simple_yaml_1_0 repositories: some_repository: description: Some repo url: https://raw.githubusercontent.com/openstack/tosca-parser/master/toscaparser/tests/data/custom_types/ description: > TOSCA test for testing repositories definition node_templates: server: type: tosca.nodes.Compute ,,22,2
openstack%2Fneutron~master~I459dde6aa704cc2b160004bd33b51cab7096c550,openstack/neutron,master,I459dde6aa704cc2b160004bd33b51cab7096c550,Updated from global requirements,MERGED,2016-02-10 21:55:34.000000000,2016-02-15 16:07:17.000000000,2016-02-15 05:46:38.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17211}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-10 21:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1fd2bc319ddff51fc921582420e824e223d8b7f2', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 2, 'created': '2016-02-11 07:41:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d4d085dff9895f1e04e35e8188ac75e800221c5a', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 3, 'created': '2016-02-11 14:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6054251201cd134b2d1251895ce0217bd531d79', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 4, 'created': '2016-02-12 20:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/958b40c71876085e702089e29af3868eaa799d40', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 5, 'created': '2016-02-12 20:26:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a530f67ebd37f5ff4c278abe19e18fdbb0cd9283', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 6, 'created': '2016-02-13 05:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b319b2d50ae46e6dba6401cb2adb29760288dcb5', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 7, 'created': '2016-02-14 01:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/76fe1f79af5be12884f19de5b7e72fc2991236b2', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}, {'number': 8, 'created': '2016-02-14 23:09:07.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a953b53c65322f503f4ff2c4f447e78b13958c47', 'message': 'Updated from global requirements\n\nChange-Id: I459dde6aa704cc2b160004bd33b51cab7096c550\n'}]",2,278694,a953b53c65322f503f4ff2c4f447e78b13958c47,94,17,8,11131,,,0,"Updated from global requirements

Change-Id: I459dde6aa704cc2b160004bd33b51cab7096c550
",git fetch https://review.opendev.org/openstack/neutron refs/changes/94/278694/3 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,1fd2bc319ddff51fc921582420e824e223d8b7f2,openstack/requirements,"cliff!=1.16.0,>=1.15.0 # Apache-2.0mock>=1.2;python_version<'3.3' # BSD",cliff>=1.15.0 # Apache-2.0mock>=1.2 # BSD,4,4
openstack%2Fkeystone~master~Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2,openstack/keystone,master,Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2,disable admin_token by default,ABANDONED,2015-05-25 22:14:47.000000000,2016-02-15 15:53:50.000000000,,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 1955}, {'_account_id': 6482}, {'_account_id': 7725}, {'_account_id': 8119}, {'_account_id': 8871}, {'_account_id': 9751}, {'_account_id': 13055}, {'_account_id': 13063}, {'_account_id': 13478}, {'_account_id': 15825}, {'_account_id': 16523}]","[{'number': 1, 'created': '2015-05-25 22:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cc3b19c2b33e460b20d60b6d4f5ba223a63af1b4', 'message': 'disable admin_token by default\n\nadmin_token enabled by default is a security issue\nand suggesting users to edit paste.ini is bad[*] Instead,\nusers should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[*] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 2, 'created': '2015-06-03 00:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/1ef5a0c22df3a6e3c821ced360e2bd635135b34c', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommendeds to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 3, 'created': '2015-06-03 00:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2242743153cf4b6df01464862626515ac35f4c8f', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommends to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 4, 'created': '2015-06-29 16:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4434d961d0ccdb8fffc631621930dc90ee284647', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommends to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nSigned-off-by: Alberto Murillo <powerbsd@yahoo.com>\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 5, 'created': '2015-06-29 20:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/4fba2ec7b786410c7359f736ce6fd1058de71c81', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommends to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nSigned-off-by: Alberto Murillo <powerbsd@yahoo.com>\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 6, 'created': '2015-07-03 20:57:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8298070324b590006dd68d19c6cee087c0f01835', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommends to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nSigned-off-by: Alberto Murillo <powerbsd@yahoo.com>\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 7, 'created': '2015-08-03 22:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/333fb9c2e709fe399c2cdb87812a96bd2d035657', 'message': 'disable admin_token by default\n\nDocumentation[1] highly recommends to edit paste.ini but this is bad[2]\nInstead, users should be able to simply remove or comment out admin_token\nin keystone.conf\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 8, 'created': '2015-08-19 22:35:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/3dc12a03cb616975b42081377eb5cf4ea80ccc65', 'message': 'disable admin_token by default\n\n* Enhance security by having admin_token disabled by default[1]\n  (Users are updating this variable anyways as indicated in the installation guide)\n\n* Make it easier to disable AdminTokenAuthMiddleware to users\n  (remove the var from a file in /etc vs editing a file in /usr/share\n  wich could be potentially overwritten by software updates[2])\n\n* Go back to use a hardcoded ADMIN value for auth_token since there is no\n  default value anymore (commit 511e3)\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}, {'number': 9, 'created': '2015-11-11 18:17:22.000000000', 'files': ['keystone/tests/unit/test_v2.py', 'keystone/tests/unit/test_middleware.py', 'keystone/common/config.py', 'keystone/tests/unit/test_v3.py', 'keystone/tests/unit/test_v3_auth.py', 'keystone/middleware/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d6977ed870f76f6836e9fe74ecf883bd11668d52', 'message': 'disable admin_token by default\n\n* Enhance security by having admin_token disabled by default[1]\n  (Users are updating this variable anyways as indicated in the installation guide)\n\n* Make it easier to disable AdminTokenAuthMiddleware to users\n  (remove the var from a file in /etc vs editing a file in /usr/share\n  wich could be potentially overwritten by software updates[2])\n\n* Go back to use a hardcoded ADMIN value for auth_token since there is no\n  default value anymore (commit 511e3)\n\n[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token\n[2] paste.ini contains code paths so must be treated as ""code""\nwhich could change on upgrades vs configuration which must stay backward\ncompatible across releases\n\nDocImpact\nRelated-Bug: #1458720\nChange-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2\n'}]",17,185464,d6977ed870f76f6836e9fe74ecf883bd11668d52,54,13,9,1955,,,0,"disable admin_token by default

* Enhance security by having admin_token disabled by default[1]
  (Users are updating this variable anyways as indicated in the installation guide)

* Make it easier to disable AdminTokenAuthMiddleware to users
  (remove the var from a file in /etc vs editing a file in /usr/share
  wich could be potentially overwritten by software updates[2])

* Go back to use a hardcoded ADMIN value for auth_token since there is no
  default value anymore (commit 511e3)

[1] http://docs.openstack.org/developer/keystone/configuringservices.html#admin-token
[2] paste.ini contains code paths so must be treated as ""code""
which could change on upgrades vs configuration which must stay backward
compatible across releases

DocImpact
Related-Bug: #1458720
Change-Id: Ifcf99a6c20bce62b59e4f5f65b4dab8a3ec9d3d2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/64/185464/4 && git format-patch -1 --stdout FETCH_HEAD,"['etc/keystone.conf.sample', 'keystone/common/config.py', 'keystone/middleware/core.py']",3,cc3b19c2b33e460b20d60b6d4f5ba223a63af1b4,bug/1458720, context['is_admin'] = (CONF.admin_token is not None and token == CONF.admin_token) if (CONF.admin_token is not None and token_id == CONF.admin_token):, context['is_admin'] = (token == CONF.admin_token) if token_id == CONF.admin_token:,11,13
openstack%2Fapp-catalog~master~I74b18b721ce32af0d0d50b98e204b440d4829e4a,openstack/app-catalog,master,I74b18b721ce32af0d0d50b98e204b440d4829e4a,Change the archive name for SqlDatabase murano package,MERGED,2016-02-15 11:01:14.000000000,2016-02-15 15:50:25.000000000,2016-02-15 15:50:25.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 9788}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-15 11:01:14.000000000', 'files': ['openstack_catalog/web/static/assets.yaml'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/54efe1abd1be091e448e3a2079b016ef0d51d692', 'message': 'Change the archive name for SqlDatabase murano package\n\nThe previous name of archive was incorrect and it caused to\nerror in murano workflows. This patch renames the incorrect\narchive\n\n  url: https://www.dropbox.com/s/3d56zky2cxp9oxq/io.murano.databases.zip?dl=0\n  hash: 0d543e5ed464488118a946b32546696f\n\nCloses-Bug: #1497983\n\nChange-Id: I74b18b721ce32af0d0d50b98e204b440d4829e4a\n'}]",0,280155,54efe1abd1be091e448e3a2079b016ef0d51d692,12,5,1,13149,,,0,"Change the archive name for SqlDatabase murano package

The previous name of archive was incorrect and it caused to
error in murano workflows. This patch renames the incorrect
archive

  url: https://www.dropbox.com/s/3d56zky2cxp9oxq/io.murano.databases.zip?dl=0
  hash: 0d543e5ed464488118a946b32546696f

Closes-Bug: #1497983

Change-Id: I74b18b721ce32af0d0d50b98e204b440d4829e4a
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/55/280155/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/web/static/assets.yaml'],1,54efe1abd1be091e448e3a2079b016ef0d51d692,bug/1497983," name: Dmytro Dovbii package_name: io.murano.databases hash: 0d543e5ed464488118a946b32546696f attributes: ""Package URL"": ""http://storage.apps.openstack.org/apps/io.murano.databases.zip"""," name: Dmitry Dovbii package_name: io.murano.databases.SqlDatabase hash: bb263f544f74c4ba1a0d72143ea69e40 attributes: ""Package URL"": ""http://storage.apps.openstack.org/apps/io.murano.databases.SqlDatabase.zip""",4,4
openstack%2Fapi-site~master~I2ca2f836140727906e57ee0c1dabc58dbe88971a,openstack/api-site,master,I2ca2f836140727906e57ee0c1dabc58dbe88971a,Add description for Response parameters,MERGED,2016-01-26 17:04:15.000000000,2016-02-15 15:48:23.000000000,2016-02-15 15:48:23.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-01-26 17:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/b213b48de7f10d28317a886427d6541dd39914b5', 'message': 'Add description for Response parameters\n\nAdding the description for Response parameters to Create Server\nand Create Multiple Servers in compute api reference.\n\nChange-Id: I2ca2f836140727906e57ee0c1dabc58dbe88971a\nCloses-Bug: #1535721\n'}, {'number': 2, 'created': '2016-01-30 09:44:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/5d785f382cff752993b85244030816195bdc2a7e', 'message': 'Add description for Response parameters\n\nAdding the description for Response parameters to Create Server\nand Create Multiple Servers in compute api reference.\n\nChange-Id: I2ca2f836140727906e57ee0c1dabc58dbe88971a\nCloses-Bug: #1535721\n'}, {'number': 3, 'created': '2016-01-30 10:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/92ad824385772c87b4d30072ada98c732fa2cb9d', 'message': 'Add description for Response parameters\n\nAdding the description for Response parameters to Create Server\nand Create Multiple Servers in compute api reference.\n\nChange-Id: I2ca2f836140727906e57ee0c1dabc58dbe88971a\nCloses-Bug: #1535721\n'}, {'number': 4, 'created': '2016-02-04 04:35:59.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/servers-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/common.ent', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/servers-multiple-create-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/535d4ce1b70b3312d08df14965487f54f2aa884c', 'message': 'Add description for Response parameters\n\nAdding the description for Response parameters to Create Server\nand Create Multiple Servers in compute api reference.\n\nChange-Id: I2ca2f836140727906e57ee0c1dabc58dbe88971a\nCloses-Bug: #1535721\n'}]",2,272653,535d4ce1b70b3312d08df14965487f54f2aa884c,23,4,4,19840,,,0,"Add description for Response parameters

Adding the description for Response parameters to Create Server
and Create Multiple Servers in compute api reference.

Change-Id: I2ca2f836140727906e57ee0c1dabc58dbe88971a
Closes-Bug: #1535721
",git fetch https://review.opendev.org/openstack/api-site refs/changes/53/272653/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/compute-api/src/v2.1/wadl/servers-v2.1.wadl', 'api-ref/src/wadls/compute-api/src/v2.1/wadl/servers-multiple-create-v2.1.wadl']",2,b213b48de7f10d28317a886427d6541dd39914b5,bug/1535721, &serverCreateResponseParameters;,,2,1
openstack%2Fapi-site~master~I8cc613043981b0f2e834eaa65241998f87f0b543,openstack/api-site,master,I8cc613043981b0f2e834eaa65241998f87f0b543,Add missing hypervisor_idTemplateParameter,MERGED,2016-01-27 09:30:54.000000000,2016-02-15 15:47:55.000000000,2016-02-15 15:47:55.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 2750}, {'_account_id': 19840}]","[{'number': 1, 'created': '2016-01-27 09:30:54.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-hypervisors-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/a04f2352dde632912ec556dba5a905ed71400850', 'message': 'Add missing hypervisor_idTemplateParameter\n\nmissing this param so the request param is not complete\n\nChange-Id: I8cc613043981b0f2e834eaa65241998f87f0b543\nPartial-Bug: #1515222\n'}]",2,272955,a04f2352dde632912ec556dba5a905ed71400850,12,5,1,6062,,,0,"Add missing hypervisor_idTemplateParameter

missing this param so the request param is not complete

Change-Id: I8cc613043981b0f2e834eaa65241998f87f0b543
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/55/272955/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-hypervisors-v2.1.wadl'],1,a04f2352dde632912ec556dba5a905ed71400850,fix-compute-api-ref, &hypervisor_idTemplateParameter; </resource> </resources>, </resource> </resources>,3,2
openstack%2Fapp-catalog~master~I4aa82a139c21076aff21321565bf88ce934d0984,openstack/app-catalog,master,I4aa82a139c21076aff21321565bf88ce934d0984,Fix django INSTALLED_APPS configuration,MERGED,2016-02-01 16:51:43.000000000,2016-02-15 15:44:40.000000000,2016-02-15 15:44:40.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 8157}, {'_account_id': 9237}, {'_account_id': 9788}, {'_account_id': 10068}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-01 16:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/96ec64e579180d155a7772604d5185aa6662ebe4', 'message': 'Fix django INSTALLED_APPS configuration\n\nIn openstack_catalog/settings.py, fix INSTALLED_APPS\nby adding ""django.contrib.auth"".\n\nCloses-Bug: #1538440\nChange-Id: I4aa82a139c21076aff21321565bf88ce934d0984\n'}, {'number': 2, 'created': '2016-02-05 15:05:42.000000000', 'files': ['openstack_catalog/settings.py'], 'web_link': 'https://opendev.org/openstack/app-catalog/commit/0d45b00a7c8e9c8d70b04f7656a243434c361663', 'message': 'Fix django INSTALLED_APPS configuration\n\nIn openstack_catalog/settings.py, fix INSTALLED_APPS\nby adding ""django.contrib.auth"".\n\nThis patch allows app-catalog to be forward compatible\nwith django 1.9.\n\nCloses-Bug: #1538440\nChange-Id: I4aa82a139c21076aff21321565bf88ce934d0984\n'}]",1,274786,0d45b00a7c8e9c8d70b04f7656a243434c361663,17,7,2,10848,,,0,"Fix django INSTALLED_APPS configuration

In openstack_catalog/settings.py, fix INSTALLED_APPS
by adding ""django.contrib.auth"".

This patch allows app-catalog to be forward compatible
with django 1.9.

Closes-Bug: #1538440
Change-Id: I4aa82a139c21076aff21321565bf88ce934d0984
",git fetch https://review.opendev.org/openstack/app-catalog refs/changes/86/274786/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_catalog/settings.py'],1,96ec64e579180d155a7772604d5185aa6662ebe4,bug/1538440," 'django.contrib.auth',",,1,0
openstack%2Ffuel-main~stable%2F8.0~I8f32fb8105d0781938757fa13d5dcbbacbf9c845,openstack/fuel-main,stable/8.0,I8f32fb8105d0781938757fa13d5dcbbacbf9c845,VirtualBox network fixes and the dockerless mode support,MERGED,2016-02-15 14:22:55.000000000,2016-02-15 15:39:19.000000000,2016-02-15 15:39:19.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 13274}, {'_account_id': 14200}, {'_account_id': 19560}]","[{'number': 1, 'created': '2016-02-15 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/50218393813b7812fe08c80f3f0b724d5b3e54a7', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * using the VirtualBox scripts the Fuel master node now always\n   booted with kernel option 'wait_for_external_config=yes' to\n   provide the same deployment functionality as in the 'fuel-qa'.\n\n * settings for the kernel command line moved to the top config\n   file, because the settings wich could be edited should be placed\n   there.\n\n * because of configuration task moved to the correct place there\n   is no need to parse 'bootstrap_admin_node.log' and always follow\n   the changes in the 'fuel-library', so all parsing logic removed\n   from the scripts. This also simplifies networking changes and\n   there is no need to patch the files on the fly and restart\n   docker containers if they used.\n\n * variable 'vm_master_nat_gateway' removed from the 'config.sh'\n   and from the 'enable_outbound_network_for_product_vm' because\n   gateway should be set from the DHCP lease.\n\n * the sysconfig configuration files on the fuel master node now\n   configured the right way. the backup files for configuration\n   files are created. also added some comments for changes in the\n   scripts.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route. also\n   ZeroConf route creation and NetworkManager now switched off\n   to correct work of the network service.\n\n * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now\n   correctly modified and could contain up to three DNS nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n(cherry picked from commit 92a0e0b978cdcf60c593824a4c5ad7144fe401bb)\n""}, {'number': 2, 'created': '2016-02-15 14:49:02.000000000', 'files': ['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/config.sh', 'virtualbox/functions/product.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/643a1ef27c7dccc1c2a2ad26b85c09226b35a67d', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * using the VirtualBox scripts the Fuel master node now always\n   booted with kernel option 'wait_for_external_config=yes' to\n   provide the same deployment functionality as in the 'fuel-qa'.\n\n * settings for the kernel command line moved to the top config\n   file, because the settings wich could be edited should be placed\n   there.\n\n * because of configuration task moved to the correct place there\n   is no need to parse 'bootstrap_admin_node.log' and always follow\n   the changes in the 'fuel-library', so all parsing logic removed\n   from the scripts. This also simplifies networking changes and\n   there is no need to patch the files on the fly and restart\n   docker containers if they used.\n\n * variable 'vm_master_nat_gateway' removed from the 'config.sh'\n   and from the 'enable_outbound_network_for_product_vm' because\n   gateway should be set from the DHCP lease.\n\n * the sysconfig configuration files on the fuel master node now\n   configured the right way. the backup files for configuration\n   files are created. also added some comments for changes in the\n   scripts.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route. also\n   ZeroConf route creation and NetworkManager now switched off\n   to correct work of the network service.\n\n * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now\n   correctly modified and could contain up to three DNS nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n(cherry picked from commit 92a0e0b978cdcf60c593824a4c5ad7144fe401bb)\n""}]",6,280256,643a1ef27c7dccc1c2a2ad26b85c09226b35a67d,17,6,2,14200,,,0,"VirtualBox network fixes and the dockerless mode support

This commit include changes:

 * using the VirtualBox scripts the Fuel master node now always
   booted with kernel option 'wait_for_external_config=yes' to
   provide the same deployment functionality as in the 'fuel-qa'.

 * settings for the kernel command line moved to the top config
   file, because the settings wich could be edited should be placed
   there.

 * because of configuration task moved to the correct place there
   is no need to parse 'bootstrap_admin_node.log' and always follow
   the changes in the 'fuel-library', so all parsing logic removed
   from the scripts. This also simplifies networking changes and
   there is no need to patch the files on the fly and restart
   docker containers if they used.

 * variable 'vm_master_nat_gateway' removed from the 'config.sh'
   and from the 'enable_outbound_network_for_product_vm' because
   gateway should be set from the DHCP lease.

 * the sysconfig configuration files on the fuel master node now
   configured the right way. the backup files for configuration
   files are created. also added some comments for changes in the
   scripts.

 * now the default routing on the fuel master node correctly
   configured without creating the second default route. also
   ZeroConf route creation and NetworkManager now switched off
   to correct work of the network service.

 * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now
   correctly modified and could contain up to three DNS nameservers.

 * added support for the new dockerless 9.0 Fuel.

Implements blueprint: get-rid-docker-containers

Change-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845
Closes-Bug: #1544241
Partial-Bug: #1323365
(cherry picked from commit 92a0e0b978cdcf60c593824a4c5ad7144fe401bb)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/56/280256/1 && git format-patch -1 --stdout FETCH_HEAD,"['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/config.sh', 'virtualbox/functions/product.sh']",4,50218393813b7812fe08c80f3f0b724d5b3e54a7,bug/1544241,"wait_for_exec_in_bootstrap() { cmd=$5 # Log in into the VM, exec cmd and print exitcode send ""$cmd\r"" expect ""$prompt"" send ""echo \""rc=\$?\""\r"" echo ""$result"" | grep -q ""[r]c=0"" >&2 && return 0 echo -n ""Waiting for product VM to download files. Please do NOT abort the script... "" # Loop until master node booted and wait_for_external_config started while ! wait_for_exec_in_bootstrap $ip $username $password ""$prompt"" ""ps xa | grep '\[w\]ait_for_external_config'""; do echo ""Installation timed out! ($maxdelay seconds)"" 1>&2 exit 1 echo ""OK"" echo -n ""Waiting for product VM to install. Please do NOT abort the script... "" while wait_for_exec_in_bootstrap $ip $username $password ""$prompt"" ""ps xa | grep '\[b\]ootstrap_admin_node.sh'""; do echo ""Installation timed out! ($maxdelay seconds)"" 1>&2 exit 1 echo ""OK"" # Convert nameservers list into the one line separated by the comma dns_upstream=""$(echo -e $nameserver | cut -d ' ' -f2 | sed -e':a;N;$!ba;s/\n/,/g')"" # make backups, remove network manager options, disable defaults, enable boot and disable network manager send ""sed -i.orig '/^UUID=\\\|^NM_CONTROLLED=/d;s/^\\\(.*\\\)=yes/\\\1=no/g;s/^ONBOOT=.*/ONBOOT=yes/;/^ONBOOT=/iNM_CONTROLLED=no' /etc/sysconfig/network-scripts/ifcfg-eth{0,1,2}\r"" # eth1 should be static with private ip address and provided netmask send ""sed -i 's/^BOOTPROTO=.*/BOOTPROTO=static/;/^BOOTPROTO/aIPADDR=${master_ip_pub_net}\\\nNETMASK=${mask}' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" # eth2 should get ip address via dhcp and used default route send ""sed -i 's/^BOOTPROTO=.*/BOOTPROTO=dhcp/;s/^DEFROUTE=.*/DEFROUTE=yes/;/^BOOTPROTO/aPERSISTENT_DHCLIENT=yes' /etc/sysconfig/network-scripts/ifcfg-eth2\r"" # make backup and disable zeroconf at all because we should use only DHCP on eth2 send ""sed -i.orig '/NOZEROCONF/d;aNOZEROCONF=yes' /etc/sysconfig/network\r"" # remove default route from eth0 and system wide settings if exists send ""sed -i '/^GATEWAY=/d' /etc/sysconfig/network /etc/sysconfig/network-scripts/ifcfg-eth0\r"" # fix bug https://bugs.centos.org/view.php?id=7351 send ""sed -i.orig '/^DEVICE=lo/aTYPE=Loopback' /etc/sysconfig/network-scripts/ifcfg-lo\r"" # remove old settings from the resolv.conf and dnsmasq.upstream if exists send ""sed -i.orig '/^nameserver/d' /etc/resolv.conf /etc/dnsmasq.upstream &>/dev/null\r"" # update the resolv.conf and dnsmasq.upstream with the new settings send ""echo -e '$nameserver' | tee -a /etc/dnsmasq.upstream >>/etc/resolv.conf\r"" # update the astute.yaml with the new settings send ""sed -i.orig '/DNS_UPSTREAM/c\\""DNS_UPSTREAM\\"": \\""${dns_upstream}\\""' /etc/fuel/astute.yaml\r"" # enable NAT (MASQUERADE) and forwarding for the public network # disable NetworkManager and apply the network changes send ""nmcli networking off &>/dev/null ; service network restart &>/dev/null\r"" echo ""OK"" echo -n ""Waiting until the network services are restarted... "" result_inet=$( execute expect << ENDOFEXPECT spawn ssh $ssh_options $username@$ip expect ""connect to host"" exit expect ""*?assword:*"" send ""$password\r"" expect ""$prompt"" send ""for i in {1..5}; do ping -c 2 google.com || ping -c 2 wikipedia.com || sleep 2; done\r"" expect ""*icmp*"" expect ""$prompt"" send ""logout\r"" expect ""$prompt"" ) wait_for_exec_in_bootstrap $ip $username $password ""$prompt"" ""pkill -f ^wait_for_external_config"" return 0;","wait_for_line_in_puppet_bootstrap() { goodline=$5 badline=$6 # Log in into the VM, see if Puppet has completed its run send ""egrep --color=none -e '${goodline}' -e '${badline}' /var/log/puppet/bootstrap_admin_node.log\r"" echo ""$result"" | grep -v grep | egrep -q ""$badline"" >&2 && return 1 echo ""$result"" | grep -v grep | egrep -q ""$goodline"" >&2 && return 0is_product_vm_operational() { wait_for_line_in_puppet_bootstrap ""$@"" ""^Fuel.*complete"" ""^Fuel.*FAILED"" } echo ""Waiting for product VM to download files. Please do NOT abort the script..."" # Loop until master node gets successfully installed while ! wait_for_line_in_puppet_bootstrap $ip $username $password ""$prompt"" ""build docker containers finished.|^Fuel.*complete"" ""^Fuel.*FAILED""; do echo ""Installation timed out! ($maxdelay seconds)"" 1>&2 exit 1 echo ""Waiting for product VM to install. Please do NOT abort the script..."" while ! is_product_vm_operational $ip $username $password ""$prompt""; do echo ""Installation timed out! ($maxdelay seconds)"" 1>&2 exit 1 interface_id=$(($5-1)) # Subtract one to get ethX index (0-based) from the VirtualBox index (from 1 to 4) gateway_ip=$6 send ""file=/etc/sysconfig/network-scripts/ifcfg-eth$interface_id\r"" send ""hwaddr=\\\$(grep HWADDR \\\$file)\r"" send ""uuid=\\\$(grep UUID \\\$file)\r"" send ""echo -e \""\\\$hwaddr\\n\\\$uuid\\nDEVICE=eth$interface_id\\nTYPE=Ethernet\\nONBOOT=yes\\nNM_CONTROLLED=no\\nBOOTPROTO=dhcp\\nPEERDNS=no\"" > \\\$file\r"" send ""sed \""s/GATEWAY=.*/GATEWAY=\""$gateway_ip\""/g\"" -i /etc/sysconfig/network\r"" send ""echo -e \""$nameserver\"" > /etc/dnsmasq.upstream\r"" send ""sed \""s/DNS_UPSTREAM:.*/DNS_UPSTREAM: \\\$(grep \'^nameserver\' /etc/dnsmasq.upstream | cut -d \' \' -f2)/g\"" -i /etc/fuel/astute.yaml\r"" send ""sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" send ""sed -i 's/NM_CONTROLLED=yes/NM_CONTROLLED=no/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" send ""sed -i 's/BOOTPROTO=dhcp/BOOTPROTO=static/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send "" echo \""IPADDR=$master_ip_pub_net\"" >> /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send "" echo \""NETMASK=$mask\"" >> /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send ""dockerctl restart cobbler &>/dev/null\r"" set timeout 300 expect ""$prompt"" send ""service network restart &>/dev/null\r"" expect ""*OK*"" expect ""$prompt"" send ""dockerctl restart cobbler &>/dev/null\r"" set timeout 300 expect ""$prompt"" send ""dockerctl check cobbler &>/dev/null\r"" expect ""*ready*"" echo -e ""\nWaiting until the network services are restarted..."" result_inet=$( execute expect << ENDOFEXPECT spawn ssh $ssh_options $username@$ip expect ""connect to host"" exit expect ""*?assword:*"" send ""$password\r"" expect ""$prompt"" send ""for i in {1..5}; do ping -c 2 google.com || ping -c 2 wikipedia.com || sleep 2; done\r"" expect ""*icmp*"" expect ""$prompt"" send ""logout\r"" expect ""$prompt"" ) return 0;",75,71
openstack%2Ffuel-library~master~I54099eb37051af12b1108ebca398d42b5c63d1f6,openstack/fuel-library,master,I54099eb37051af12b1108ebca398d42b5c63d1f6,Fix race condition for nova and heat tasks,MERGED,2016-02-12 11:14:52.000000000,2016-02-15 15:31:38.000000000,2016-02-15 15:30:49.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 16518}, {'_account_id': 16771}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-12 11:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e0b8cfcfbeee93892dc14bb19c9c783d1d51fa5d', 'message': 'Fix race condition for nova and heat tasks\n\nThis fix splits execution of tasks on controller\nnodes to avoid race conditions as puppet providers\ncannot handle conflicts properly during parallel\napplication.\n\nChange-Id: I54099eb37051af12b1108ebca398d42b5c63d1f6\nCloses-bug: #1544927\n'}, {'number': 2, 'created': '2016-02-12 14:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a23b33999217fc2a4434afa88795ca5c7fc09b89', 'message': 'Fix race condition for nova and heat tasks\n\nThis fix splits execution of tasks on controller\nnodes to avoid race conditions as puppet providers\ncannot handle conflicts properly during parallel\napplication.\n\nChange-Id: I54099eb37051af12b1108ebca398d42b5c63d1f6\nCloses-bug: #1544927\n'}, {'number': 3, 'created': '2016-02-12 18:22:13.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/murano/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/glance/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ironic/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/horizon/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ceilometer/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/heat/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/keystone/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/rabbitmq/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/database/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/roles/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-controller/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/af747c3024e6ba5d6c52b476e64cbe7f06af930b', 'message': 'Fix race condition for nova and heat tasks\n\nThis fix splits execution of tasks on controller\nnodes to avoid race conditions as puppet providers\ncannot handle conflicts properly during parallel\napplication.\n\nChange-Id: I54099eb37051af12b1108ebca398d42b5c63d1f6\nCloses-bug: #1544927\n'}]",1,279481,af747c3024e6ba5d6c52b476e64cbe7f06af930b,46,12,3,8786,,,0,"Fix race condition for nova and heat tasks

This fix splits execution of tasks on controller
nodes to avoid race conditions as puppet providers
cannot handle conflicts properly during parallel
application.

Change-Id: I54099eb37051af12b1108ebca398d42b5c63d1f6
Closes-bug: #1544927
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/81/279481/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/heat/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-controller/tasks.yaml']",2,e0b8cfcfbeee93892dc14bb19c9c783d1d51fa5d,,"- id: primary-openstack-controller groups: [primary-controller]- id: openstack-controller type: puppet version: 2.0.0 groups: [controller] required_for: [deploy_end] requires: [openstack-haproxy] cross-depends: - name: primary-openstack-controller refresh_on: [nova_config, nova_paste_api_ini] parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/openstack-controller/openstack-controller.pp puppet_modules: /etc/puppet/modules timeout: 3600 ","- id: openstack-controller groups: [primary-controller, controller]",35,4
openstack%2Ftripleo-heat-templates~master~Ifd750e634812dae2b7945cbe2f35f98d8a82695e,openstack/tripleo-heat-templates,master,Ifd750e634812dae2b7945cbe2f35f98d8a82695e,Enable SSL middleware for cinder,MERGED,2016-01-16 11:41:24.000000000,2016-02-15 15:16:20.000000000,2016-02-15 15:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 8042}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-01-16 11:41:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/783fa4861b310c13a9ee7fb1456b67d2f2e22928', 'message': 'Enable SSL middleware for cinder\n\nChange-Id: Ifd750e634812dae2b7945cbe2f35f98d8a82695e\nDepends-On: If88dcdf9f4905e2a792b2fdc656eab51c85f637e\n'}, {'number': 2, 'created': '2016-01-21 11:38:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9b63f059700477aa51432126656da799f9cfb73c', 'message': 'Enable SSL middleware for cinder\n\nChange-Id: Ifd750e634812dae2b7945cbe2f35f98d8a82695e\nDepends-On: If88dcdf9f4905e2a792b2fdc656eab51c85f637e\n'}, {'number': 3, 'created': '2016-01-22 06:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c0013ba3b118d5ba1f36583fe6083a8d0dd3e484', 'message': 'Enable SSL middleware for cinder\n\nChange-Id: Ifd750e634812dae2b7945cbe2f35f98d8a82695e\nDepends-On: If88dcdf9f4905e2a792b2fdc656eab51c85f637e\n'}, {'number': 4, 'created': '2016-01-25 10:39:13.000000000', 'files': ['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6deccde41576341ae91e07b8ad837bfafdaa35e7', 'message': 'Enable SSL middleware for cinder\n\nChange-Id: Ifd750e634812dae2b7945cbe2f35f98d8a82695e\nDepends-On: If88dcdf9f4905e2a792b2fdc656eab51c85f637e\n'}]",0,268651,6deccde41576341ae91e07b8ad837bfafdaa35e7,33,7,4,10873,,,0,"Enable SSL middleware for cinder

Change-Id: Ifd750e634812dae2b7945cbe2f35f98d8a82695e
Depends-On: If88dcdf9f4905e2a792b2fdc656eab51c85f637e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/268651/4 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_controller_pacemaker.pp']",2,783fa4861b310c13a9ee7fb1456b67d2f2e22928,tls_enablement, include ::tripleo::ssl::cinder_config,,2,0
openstack%2Fsahara~master~I9b45e2806ee169e1b37dda0d06ca12da562fd67d,openstack/sahara,master,I9b45e2806ee169e1b37dda0d06ca12da562fd67d,Now updating cluster templates on update,MERGED,2015-12-08 15:03:29.000000000,2016-02-15 15:12:12.000000000,2016-02-15 15:12:12.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 9740}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-12-08 15:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bd28f8aab54479405594617a144790e9ced200c1', 'message': 'Now updating cluster templates on update\n\nWhen a node group template is updated that is\nreferenced by a cluster template, that cluster template\nis now updated so that the values shown to the user\nwill be correct.  Also adding a test for this scenario.\n\nChange-Id: I9b45e2806ee169e1b37dda0d06ca12da562fd67d\nCloses-Bug: #1519871\n'}, {'number': 2, 'created': '2015-12-09 17:09:53.000000000', 'files': ['sahara/db/sqlalchemy/api.py', 'sahara/tests/unit/conductor/manager/test_templates.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e7a130f1fde24866e4fa9e370e0e0026c5877acd', 'message': 'Now updating cluster templates on update\n\nWhen a node group template is updated that is\nreferenced by a cluster template, that cluster template\nis now updated so that the values shown to the user\nwill be correct.  Also adding a test for this scenario.\n\nChange-Id: I9b45e2806ee169e1b37dda0d06ca12da562fd67d\nCloses-Bug: #1519871\n'}]",2,254810,e7a130f1fde24866e4fa9e370e0e0026c5877acd,19,9,2,8090,,,0,"Now updating cluster templates on update

When a node group template is updated that is
referenced by a cluster template, that cluster template
is now updated so that the values shown to the user
will be correct.  Also adding a test for this scenario.

Change-Id: I9b45e2806ee169e1b37dda0d06ca12da562fd67d
Closes-Bug: #1519871
",git fetch https://review.opendev.org/openstack/sahara refs/changes/10/254810/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_templates.py', 'sahara/conductor/manager.py']",4,bd28f8aab54479405594617a144790e9ced200c1,bug/1519871," updated_ngt = self.db.node_group_template_update(context, values, ignore_default) ct_refs = self.db.node_group_template_get_relations(context, id) for ct in ct_refs: ct_update_values = {""node_groups"": [{ ""node_group_template_id"": id, ""count"": ct.count}] } self.cluster_template_update(context, ct.cluster_template_id, ct_update_values) return updated_ngt"," return self.db.node_group_template_update(context, values, ignore_default)",46,2
openstack%2Fopenstack-manuals~master~Id374b81726df3b7075b221b900ae95eeb0943f8c,openstack/openstack-manuals,master,Id374b81726df3b7075b221b900ae95eeb0943f8c,Add Japanese HA Guide to draft index,MERGED,2016-02-15 13:59:26.000000000,2016-02-15 15:11:20.000000000,2016-02-15 15:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 10497}, {'_account_id': 10607}]","[{'number': 1, 'created': '2016-02-15 13:59:26.000000000', 'files': ['www/draft/draft-index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a532c4025ffb53fd54b9e58d01021be3870d7bf0', 'message': 'Add Japanese HA Guide to draft index\n\nThe guide has first translations, link to it.\n\nChange-Id: Id374b81726df3b7075b221b900ae95eeb0943f8c\n'}]",0,280245,a532c4025ffb53fd54b9e58d01021be3870d7bf0,7,3,1,6547,,,0,"Add Japanese HA Guide to draft index

The guide has first translations, link to it.

Change-Id: Id374b81726df3b7075b221b900ae95eeb0943f8c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/280245/1 && git format-patch -1 --stdout FETCH_HEAD,['www/draft/draft-index.html'],1,a532c4025ffb53fd54b9e58d01021be3870d7bf0,draft-ja-ha-guide," <a href=""/draft/ja/ha-guide/"">High Availability Guide</a>",,1,0
openstack%2Fproject-config~master~Ib4167857695e5d06a81936b81bac1acc747a7e51,openstack/project-config,master,Ib4167857695e5d06a81936b81bac1acc747a7e51,Added new 'fuel-plugin-tacker' repository,ABANDONED,2016-02-15 14:56:35.000000000,2016-02-15 15:10:04.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6786}, {'_account_id': 13082}, {'_account_id': 14372}]","[{'number': 1, 'created': '2016-02-15 14:56:35.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/acls/openstack/fuel-plugin-tacker.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f7db5d390cd7b2ae4da53a478d31672453f07b78', 'message': ""Added new 'fuel-plugin-tacker' repository\n\nChange-Id: Ib4167857695e5d06a81936b81bac1acc747a7e51\nCloses-bug: #1544536\n""}]",0,280272,f7db5d390cd7b2ae4da53a478d31672453f07b78,3,6,1,12804,,,0,"Added new 'fuel-plugin-tacker' repository

Change-Id: Ib4167857695e5d06a81936b81bac1acc747a7e51
Closes-bug: #1544536
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/280272/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/openstack/fuel-plugin-tacker.config', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,f7db5d390cd7b2ae4da53a478d31672453f07b78,, - name: openstack/fuel-plugin-tacker template: - name: merge-check - name: noop-jobs ,,32,0
openstack%2Fpython-cinderclient~master~Ied336f051e094b6b7bed4cac0858941ec43e3b26,openstack/python-cinderclient,master,Ied336f051e094b6b7bed4cac0858941ec43e3b26,Removes MANIFEST.in as it is not needed explicitely by PBR,MERGED,2015-12-16 10:35:07.000000000,2016-02-15 15:06:50.000000000,2016-02-15 15:06:50.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 8556}, {'_account_id': 11689}, {'_account_id': 11904}, {'_account_id': 14305}, {'_account_id': 15699}]","[{'number': 1, 'created': '2015-12-16 10:35:07.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/afee25c0ab0c3174a7070305610576290d827f0d', 'message': 'Removes MANIFEST.in as it is not needed explicitely by PBR\n\nThis patch removes `MANIFEST.in` file as pbr generates a sensible\nmanifest from git files and some standard files and it removes\nthe need for an explicit `MANIFEST.in` file.\n\nChange-Id: Ied336f051e094b6b7bed4cac0858941ec43e3b26\n'}]",0,258408,afee25c0ab0c3174a7070305610576290d827f0d,11,7,1,15699,,,0,"Removes MANIFEST.in as it is not needed explicitely by PBR

This patch removes `MANIFEST.in` file as pbr generates a sensible
manifest from git files and some standard files and it removes
the need for an explicit `MANIFEST.in` file.

Change-Id: Ied336f051e094b6b7bed4cac0858941ec43e3b26
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/08/258408/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,afee25c0ab0c3174a7070305610576290d827f0d,drop_manifest,,include AUTHORS include ChangeLog exclude .gitignore exclude .gitreview ,0,4
openstack%2Fpython-cinderclient~master~I813d0da52490f4de4c8586c48fc9d09fd52f3b5a,openstack/python-cinderclient,master,I813d0da52490f4de4c8586c48fc9d09fd52f3b5a,Code is hosted on git.openstack.org,MERGED,2016-01-16 17:06:56.000000000,2016-02-15 15:06:44.000000000,2016-02-15 15:06:44.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 11904}, {'_account_id': 14305}, {'_account_id': 16237}, {'_account_id': 16308}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-01-16 17:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e5c22d039041facab75e44a2a6e753e367b4315c', 'message': ""Code is hosted on git.openstack.org\n\nWe're hosting on git.openstack.org, github is just a mirror. Update\ndescription in README.rst for this.\n\nChange-Id: I813d0da52490f4de4c8586c48fc9d09fd52f3b5a\n""}, {'number': 2, 'created': '2016-01-16 17:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/8c578124a40dc41be73d3df49ad33ffff7930c90', 'message': ""Code is hosted on git.openstack.org\n\nWe're hosting on git.openstack.org, github is just a mirror. Update\ndescription in README.rst for this.\n\nChange-Id: I813d0da52490f4de4c8586c48fc9d09fd52f3b5a\n""}, {'number': 3, 'created': '2016-01-16 18:33:23.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a0c8fcff4ffa8189936476affebef1fd4ebbc3b1', 'message': ""Code is hosted on git.openstack.org\n\nWe're hosting on git.openstack.org, github is just a mirror. Update\ndescription in README.rst for this.\n\nChange-Id: I813d0da52490f4de4c8586c48fc9d09fd52f3b5a\n""}]",1,268691,a0c8fcff4ffa8189936476affebef1fd4ebbc3b1,15,7,3,6547,,,0,"Code is hosted on git.openstack.org

We're hosting on git.openstack.org, github is just a mirror. Update
description in README.rst for this.

Change-Id: I813d0da52490f4de4c8586c48fc9d09fd52f3b5a
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/91/268691/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,e5c22d039041facab75e44a2a6e753e367b4315c,268690,hosted on `OpenStack`_. Patches must be submitted using `Gerrit`_. .. _OpenStack: https://git.openstack.org/cgit/openstack/python-cinderclient,"hosted on `Github`_. Patches must be submitted using `Gerrit`_, *not* Github pull requests. .. _Github: https://github.com/openstack/python-cinderclient",2,3
openstack%2Fnetworking-bgpvpn~stable%2Fliberty~Ibcebe75cd79280c5d74e6430bc3b644593693e90,openstack/networking-bgpvpn,stable/liberty,Ibcebe75cd79280c5d74e6430bc3b644593693e90,Fix usage of odl client,MERGED,2016-02-01 08:48:42.000000000,2016-02-15 15:06:37.000000000,2016-02-15 15:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2888}, {'_account_id': 9361}, {'_account_id': 9656}, {'_account_id': 12021}, {'_account_id': 13933}, {'_account_id': 18429}]","[{'number': 1, 'created': '2016-02-01 08:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/11bd6dfa04731d67ce7fbfa58f49bad912e68572', 'message': 'Fix usage of odl client\n\nodl_client.create_client method is not available in liberty. This fix is\nto modify ODL Driver code to initialize ODL client without calling\ncreate_client()\n\nChange-Id: Ibcebe75cd79280c5d74e6430bc3b644593693e90\nCloses-bug: 1540236\n'}, {'number': 2, 'created': '2016-02-03 15:25:42.000000000', 'files': ['networking_bgpvpn/neutron/services/service_drivers/opendaylight/odl.py', 'test-requirements.txt', 'networking_bgpvpn/tests/unit/services/odl/test_odl.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/ab3d1c796dfbc853146aec7c57136148c8b33836', 'message': 'Fix usage of odl client\n\nodl_client.create_client method is not available in liberty. This fix is\nto modify ODL Driver code to initialize ODL client without calling\ncreate_client()\n\nChange-Id: Ibcebe75cd79280c5d74e6430bc3b644593693e90\nCloses-bug: 1540236\n'}]",0,274552,ab3d1c796dfbc853146aec7c57136148c8b33836,21,8,2,18429,,,0,"Fix usage of odl client

odl_client.create_client method is not available in liberty. This fix is
to modify ODL Driver code to initialize ODL client without calling
create_client()

Change-Id: Ibcebe75cd79280c5d74e6430bc3b644593693e90
Closes-bug: 1540236
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/52/274552/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_bgpvpn/neutron/services/service_drivers/opendaylight/odl.py'],1,11bd6dfa04731d67ce7fbfa58f49bad912e68572,bug/1540236," self.client = odl_client.OpenDaylightRestClient( cfg.CONF.ml2_odl.url, cfg.CONF.ml2_odl.username, cfg.CONF.ml2_odl.password, cfg.CONF.ml2_odl.timeout )", self.client = odl_client.OpenDaylightRestClient.create_client(),6,2
openstack%2Fpython-cinderclient~master~I9ea25a538f2e75966f721f3c5b551d83487fb015,openstack/python-cinderclient,master,I9ea25a538f2e75966f721f3c5b551d83487fb015,Update HACKING with current information,MERGED,2016-01-09 23:59:36.000000000,2016-02-15 15:02:16.000000000,2016-02-15 15:02:16.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 10058}, {'_account_id': 14305}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-01-09 23:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/86eb926d468fbfd85a6ef3123fd860c78ace1538', 'message': 'Update HACKING with current information\n\nUpdates information about the current Reno release notes management.\nSome stale or incorrect information was also removed.\n\nChange-Id: I9ea25a538f2e75966f721f3c5b551d83487fb015\n'}, {'number': 2, 'created': '2016-01-15 14:28:01.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/f4b46766cbb18b0f1258c159f75f05ca353cb3f4', 'message': 'Update HACKING with current information\n\nUpdates information about the current Reno release notes management.\nSome stale or incorrect information was also removed.\n\nChange-Id: I9ea25a538f2e75966f721f3c5b551d83487fb015\n'}]",1,265594,f4b46766cbb18b0f1258c159f75f05ca353cb3f4,13,6,2,11904,,,0,"Update HACKING with current information

Updates information about the current Reno release notes management.
Some stale or incorrect information was also removed.

Change-Id: I9ea25a538f2e75966f721f3c5b551d83487fb015
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/94/265594/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,86eb926d468fbfd85a6ef3123fd860c78ace1538,fix_hacking,"- Any patch that makes a change significant to the end consumer or deployer of an OpenStack environment should include a release note (new features, upgrade impacts, deprecated functionality, etc.) - Cinder Client uses Reno for release notes management. See the `Reno Documentation`_ for more details on its usage. .. _Reno Documentation: http://docs.openstack.org/developer/reno/ - As a quick example, when adding a new shell command for Awesome Storage Feature, one could perform the following steps to include a release note for the new feature: $ tox -e venv -- reno new add-awesome-command $ vi releasenotes/notes/add-awesome-command-bb8bb8bb8bb8bb81.yaml Remove the extra template text from the release note and update the details so it looks something like: --- features: - Added shell command `cinder be-awesome` for Awesome Storage Feature. - Include the generated release notes file when submitting your patch for review.","Text encoding ------------- - All text within python code should be of type 'unicode'. WRONG: >>> s = 'foo' >>> s 'foo' >>> type(s) <type 'str'> RIGHT: >>> u = u'foo' >>> u u'foo' >>> type(u) <type 'unicode'> - Transitions between internal unicode and external strings should always be immediately and explicitly encoded or decoded. - All external text that is not explicitly encoded (database storage, commandline arguments, etc.) should be presumed to be encoded as utf-8. WRONG: mystring = infile.readline() myreturnstring = do_some_magic_with(mystring) outfile.write(myreturnstring) RIGHT: mystring = infile.readline() mytext = s.decode('utf-8') returntext = do_some_magic_with(mytext) returnstring = returntext.encode('utf-8') outfile.write(returnstring) - Each patch should add an entry in the doc/source/index.rst file under ""MASTER"". - On each new release, the entries under ""MASTER"" will become the release notes for that release, and ""MASTER"" will be cleared. - The format should match existing release notes. For example, a feature:: * Add support for function foo Or a bug fix:: .. _1241941: http://bugs.launchpad.net/python-cinderclient/+bug/1241941",18,48
openstack%2Ffuel-qa~master~Id8825a324deb3071794f3e82d3f15e571248125f,openstack/fuel-qa,master,Id8825a324deb3071794f3e82d3f15e571248125f,Fix nova partition preservation test,ABANDONED,2016-02-10 13:24:20.000000000,2016-02-15 14:55:57.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 12867}, {'_account_id': 15984}, {'_account_id': 16819}]","[{'number': 1, 'created': '2016-02-10 13:24:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/67e2c3238a8562401965a115d8157d3aa328f56f', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}, {'number': 2, 'created': '2016-02-10 17:09:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ea32bc6cf808d55f499bd0318b34d8d4bae4441e', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}, {'number': 3, 'created': '2016-02-10 20:57:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c4b10b4902ef90ebacf3d2cb305e297f64f37d6f', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}, {'number': 4, 'created': '2016-02-11 11:47:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/0c92baa43ba61e47b2ccece9b4b936fa34905d03', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}, {'number': 5, 'created': '2016-02-11 15:12:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/106bd25a37428758fce45d815dba5ef90f18e558', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}, {'number': 6, 'created': '2016-02-11 21:03:39.000000000', 'files': ['fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/test_node_reinstallation.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/94fdf7e14b1dba09c573203ffa024b8a67b8e5ee', 'message': 'Fix nova partition preservation test\n\nThe following preliminary and post-actions should be added\nfor operation of reinstalling a node with nova partition\npreserved:\n- disabling / enabling nova-compute service on the node\n- shutting down / starting back the OS instance under test\nThese actions are vital for making the test robust, otherwise\nthe test VMs sometimes loses network connectivity after the\nreinstalling the hosting node.\n\nChange-Id: Id8825a324deb3071794f3e82d3f15e571248125f\nCloses-Bug: #1543623\n'}]",0,278359,94fdf7e14b1dba09c573203ffa024b8a67b8e5ee,37,5,6,16819,,,0,"Fix nova partition preservation test

The following preliminary and post-actions should be added
for operation of reinstalling a node with nova partition
preserved:
- disabling / enabling nova-compute service on the node
- shutting down / starting back the OS instance under test
These actions are vital for making the test robust, otherwise
the test VMs sometimes loses network connectivity after the
reinstalling the hosting node.

Change-Id: Id8825a324deb3071794f3e82d3f15e571248125f
Closes-Bug: #1543623
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/59/278359/6 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/os_actions.py', 'fuelweb_test/tests/test_node_reinstallation.py']",2,67e2c3238a8562401965a115d8157d3aa328f56f,bug/1543623," 5. Disable nova-compute service on the node to be reinstalled 6. Shut down the test OS instance 7. Reinstall the compute node 8. Enable nova-compute service back 9. Start the test OS instance back 10. Run network verification 11. Run OSTF 12. Verify that the volume is present and has 'available' status 13. Verify that the VM is available and pingable # Disable nova-compute service on the node and shutoff # the test OS instance service = ""nova-compute"" service_status = os_conn.nova_disable_service( cmp_host.hypervisor_hostname, service) assert_equal(""disabled"", service_status, ""{0} service is not disabled on {0} host."".format( service, cmp_host)) vm.stop() devops_helpers.wait( lambda: os_conn.get_instance_detail(vm).status == ""SHUTOFF"", timeout=30) # Enable nova-compute service on the node and start # the test OS instance service_status = os_conn.nova_enable_service( cmp_host.hypervisor_hostname, service) assert_equal(""enabled"", service_status, ""{0} service is not enabled on {0} host."".format( service, cmp_host)) vm.start() devops_helpers.wait( lambda: os_conn.get_instance_detail(vm).status == ""ACTIVE"", timeout=30) ", 5. Reinstall the compute node 6. Run network verification 7. Run OSTF 8. Verify that the volume is present and has 'available' status 9. Verify that the VM is available and pingable,53,6
openstack%2Ffuel-library~master~I0c6e8c1356be231b76454d75db93d21038b88063,openstack/fuel-library,master,I0c6e8c1356be231b76454d75db93d21038b88063,Adapt ironic manifest,MERGED,2016-01-29 22:30:00.000000000,2016-02-15 14:51:39.000000000,2016-02-15 14:50:39.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13505}, {'_account_id': 13948}, {'_account_id': 14525}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-01-29 22:30:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9c44030d660adb8963a04b2b277bfa33be4df143', 'message': '[WIP]Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 2, 'created': '2016-02-08 20:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/50f2251dd6730ac8aa68ce20c16545669dd515ad', 'message': '[WIP]Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 3, 'created': '2016-02-08 21:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1dcdf4de6193c061f0da26f1dd1eba7046c22577', 'message': '[WIP]Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 4, 'created': '2016-02-08 22:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/07e2a2090a9494b309de7a2ff06834ece549eab0', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 5, 'created': '2016-02-08 23:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b8dd5701b546806cd7e2868aae53fce8f0e85fd4', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 6, 'created': '2016-02-09 10:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd2c8c23035f9e5e7e411c12ca91b44446ebadc3', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 7, 'created': '2016-02-09 15:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/36ede9acbe40a6168d09b3c22389db6e46b3b479', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 8, 'created': '2016-02-09 16:56:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/45a34e9084c9c0b5f6855be9525ee19fa770b587', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 9, 'created': '2016-02-10 09:45:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8e9a615979a3dc0a75ad620b66ec293396eda412', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}, {'number': 10, 'created': '2016-02-11 13:29:18.000000000', 'files': ['tests/noop/spec/hosts/ironic/ironic_spec.rb', 'deployment/puppet/osnailyfacter/modular/ironic/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/Puppetfile', 'deployment/puppet/osnailyfacter/modular/ironic/ironic.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2cb915170e47b5f5ec7b0098260edca770a8cd1b', 'message': 'Adapt ironic manifest\n\nAdapt ironic manifests to work with updated openstacklib/ironic modules\n\nPartial-blueprint: puppet-mitaka-modules\nChange-Id: I0c6e8c1356be231b76454d75db93d21038b88063\n'}]",20,274277,2cb915170e47b5f5ec7b0098260edca770a8cd1b,121,19,10,14525,,,0,"Adapt ironic manifest

Adapt ironic manifests to work with updated openstacklib/ironic modules

Partial-blueprint: puppet-mitaka-modules
Change-Id: I0c6e8c1356be231b76454d75db93d21038b88063
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/77/274277/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/noop/spec/hosts/ironic/ironic_spec.rb', 'deployment/puppet/osnailyfacter/modular/ironic/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/modular/ironic/ironic.pp']",5,9c44030d660adb8963a04b2b277bfa33be4df143,bp/puppet-mitaka-modules,"$ssl_hash = hiera_hash('use_ssl', {}) $internal_auth_protocol = get_ssl_property($ssl_hash, {}, 'keystone', 'internal', 'protocol', 'http') $internal_auth_address = get_ssl_property($ssl_hash, {}, 'keystone', 'internal', 'hostname', [$service_endpoint, $management_vip]) $internal_auth_url = ""${internal_auth_protocol}://${internal_auth_address}:5000"" auth_uri => $internal_auth_url,","# TODO (iberezovskiy): Move to globals (as it is done for sahara) # after new sync with upstream because of # https://github.com/openstack/puppet-ironic/blob/master/manifests/init.pp#L261 if $default_log_levels { ironic_config { 'DEFAULT/default_log_levels' : value => join(sort(join_keys_to_values($default_log_levels, '=')), ','); } } else { ironic_config { 'DEFAULT/default_log_levels' : ensure => absent; } } # auth_host => $keystone_endpoint,",21,25
openstack%2Ffuel-library~master~I5cd24feef53cbfc5940e51a64247987e35457f90,openstack/fuel-library,master,I5cd24feef53cbfc5940e51a64247987e35457f90,Set right order for ntp resources creation,MERGED,2016-02-08 13:13:42.000000000,2016-02-15 14:49:53.000000000,2016-02-15 14:49:07.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14200}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-02-08 13:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f7ce93decc9f23fe6a7027f2b5d1f48da1613fff', 'message': 'Set right order for ntp resources creation\n\nFor creating colocation with resource it must be created first,\nso set a dependency between a resource and colocation explicitly.\n\nChange-Id: I5cd24feef53cbfc5940e51a64247987e35457f90\nCloses-Bug: #1525779\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 2, 'created': '2016-02-09 17:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/72523c1dfd2b856ea992928b4f15b45f44f633ed', 'message': 'Set right order for ntp resources creation\n\nFor creating colocation with resource it must be created first,\nso set a dependency between a resource and colocation explicitly.\n\nChange-Id: I5cd24feef53cbfc5940e51a64247987e35457f90\nCloses-Bug: #1525779\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 3, 'created': '2016-02-09 17:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9ff6c79b5cad24290674e5b880ac70b5d39a41d2', 'message': 'Set right order for ntp resources creation\n\nFor creating colocation with resource it must be created first,\nso set a dependency between a resource and colocation explicitly.\n\nChange-Id: I5cd24feef53cbfc5940e51a64247987e35457f90\nCloses-Bug: #1525779\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 4, 'created': '2016-02-09 17:29:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/79220a76c76904d6a8c468a90e1bfb161d318a68', 'message': 'Set right order for ntp resources creation\n\nFor creating colocation with resource it must be created first,\nso set a dependency between a resource and colocation explicitly.\n\nChange-Id: I5cd24feef53cbfc5940e51a64247987e35457f90\nCloses-Bug: #1525779\nRelated-Blueprint: granular-task-idempotency\n'}, {'number': 5, 'created': '2016-02-10 08:39:33.000000000', 'files': ['deployment/puppet/cluster/manifests/ntp_ocf.pp', 'deployment/puppet/cluster/.fixtures.yml', 'deployment/puppet/cluster/spec/classes/cluster_ntp_ocf_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3c9cefd1e0f30443c7673635e3c1e97d5786fc77', 'message': 'Set right order for ntp resources creation\n\nFor creating colocation with resource it must be created first,\nso set a dependency between a resource and colocation explicitly.\n\nChange-Id: I5cd24feef53cbfc5940e51a64247987e35457f90\nCloses-Bug: #1525779\nRelated-Blueprint: granular-task-idempotency\n'}]",0,277380,3c9cefd1e0f30443c7673635e3c1e97d5786fc77,56,11,5,11827,,,0,"Set right order for ntp resources creation

For creating colocation with resource it must be created first,
so set a dependency between a resource and colocation explicitly.

Change-Id: I5cd24feef53cbfc5940e51a64247987e35457f90
Closes-Bug: #1525779
Related-Blueprint: granular-task-idempotency
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/80/277380/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/cluster/manifests/ntp_ocf.pp'],1,f7ce93decc9f23fe6a7027f2b5d1f48da1613fff,bp/granular-task-idempotency," cs_rsc_colocation { 'ntp-with-vrouter-ns' : ensure => 'present', score => 'INFINITY', primitives => [ ""clone_p_$service_name"", ""clone_p_vrouter"", ], } Cs_resource[""p_${service_name}""] -> Cs_rsc_colocation['ntp-with-vrouter-ns'] -> Service[$service_name]"," cs_rsc_colocation { 'ntp-with-vrouter-ns' : ensure => 'present', score => 'INFINITY', primitives => [ ""clone_p_$service_name"", ""clone_p_vrouter"", ], } Cs_rsc_colocation['ntp-with-vrouter-ns'] -> Service['ntp']",10,10
openstack%2Frally~master~I525583f1311763295fe64c6fa17a9a634a524cac,openstack/rally,master,I525583f1311763295fe64c6fa17a9a634a524cac,Make install_rally.sh --branch accept git tree-ish,MERGED,2016-02-11 02:36:42.000000000,2016-02-15 14:48:35.000000000,2016-02-15 14:48:35.000000000,"[{'_account_id': 3}, {'_account_id': 6835}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12637}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-11 02:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/88405e429c2569dee089e907806f40f68beb456b', 'message': ""Make install_rally.sh --branch accept git tree-ish\n\n'git clone ... -b ...' accepts branches or tags, but not commit\nhashes, refs, etc. This replaces 'git clone -b' with a separate 'git\nclone' and 'git checkout' so that 'install_rally.sh --branch ...' can\naccept any git tree-ish, not just branches and tags.\n\nChange-Id: I525583f1311763295fe64c6fa17a9a634a524cac\n""}, {'number': 2, 'created': '2016-02-12 14:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aef258eb770f920caa941459573143e61fc4aded', 'message': ""Make install_rally.sh --branch accept git tree-ish\n\n'git clone ... -b ...' accepts branches or tags, but not commit\nhashes, refs, etc. This replaces 'git clone -b' with a separate 'git\nclone' and 'git checkout' so that 'install_rally.sh --branch ...' can\naccept any git tree-ish, not just branches and tags.\n\nChange-Id: I525583f1311763295fe64c6fa17a9a634a524cac\n""}, {'number': 3, 'created': '2016-02-12 20:48:07.000000000', 'files': ['install_rally.sh'], 'web_link': 'https://opendev.org/openstack/rally/commit/437e6855e3a30c47e477c50e4d817ed809d31a31', 'message': ""Make install_rally.sh --branch accept git tree-ish\n\n'git clone ... -b ...' accepts branches or tags, but not commit\nhashes, refs, etc. This replaces 'git clone -b' with a separate 'git\nclone' and 'git checkout' so that 'install_rally.sh --branch ...' can\naccept any git tree-ish, not just branches and tags.\n\nChange-Id: I525583f1311763295fe64c6fa17a9a634a524cac\n""}]",2,278837,437e6855e3a30c47e477c50e4d817ed809d31a31,27,7,3,11748,,,0,"Make install_rally.sh --branch accept git tree-ish

'git clone ... -b ...' accepts branches or tags, but not commit
hashes, refs, etc. This replaces 'git clone -b' with a separate 'git
clone' and 'git checkout' so that 'install_rally.sh --branch ...' can
accept any git tree-ish, not just branches and tags.

Change-Id: I525583f1311763295fe64c6fa17a9a634a524cac
",git fetch https://review.opendev.org/openstack/rally refs/changes/37/278837/1 && git format-patch -1 --stdout FETCH_HEAD,['install_rally.sh'],1,88405e429c2569dee089e907806f40f68beb456b,278837," git clone ""$RALLY_GIT_URL"" ""$SOURCEDIR"" ( cd ""$SOURCEDIR"" git checkout ""$RALLY_GIT_BRANCH"" )"," git clone ""$RALLY_GIT_URL"" -b ""$RALLY_GIT_BRANCH"" ""$SOURCEDIR""",5,1
openstack%2Fdesignate~master~I3f3ee09df45ddbefda66591c1937d733eaaf5ef3,openstack/designate,master,I3f3ee09df45ddbefda66591c1937d733eaaf5ef3,"Functional tests for MX, TXT, SPF, SSHFP validation",MERGED,2016-02-10 18:07:34.000000000,2016-02-15 14:44:36.000000000,2016-02-15 14:44:36.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 11662}]","[{'number': 1, 'created': '2016-02-10 18:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/577028d3bf5db956dda4ee5dfc9e69328f3b6e54', 'message': 'Functional tests for trailing slashes on TXT/SPF records\n\nChange-Id: I3f3ee09df45ddbefda66591c1937d733eaaf5ef3\n'}, {'number': 2, 'created': '2016-02-10 20:40:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/ac91d1c60ba4df5140a3cb3d1792d6b64ed85a8c', 'message': 'Functional tests for MX, TXT, SPF, SSHFP validation\n\n* Test trailing slashes in SPF, TXT recordsets\n* Test negative values in MX, SSHFP records\n* Move recordset validation tests to a new module\n\nChange-Id: I3f3ee09df45ddbefda66591c1937d733eaaf5ef3\n'}, {'number': 3, 'created': '2016-02-10 23:55:22.000000000', 'files': ['functionaltests/api/v2/test_recordset.py', 'functionaltests/api/v2/base.py', 'functionaltests/api/v2/test_recordset_validation.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/47fc8f58c399cfbc3533aad7a4ed07f5c4170d70', 'message': 'Functional tests for MX, TXT, SPF, SSHFP validation\n\n* Test trailing slashes in SPF, TXT recordsets\n* Test negative values in MX, SSHFP records\n* Move recordset validation tests to a new module\n\nChange-Id: I3f3ee09df45ddbefda66591c1937d733eaaf5ef3\n'}]",0,278549,47fc8f58c399cfbc3533aad7a4ed07f5c4170d70,17,4,3,11662,,,0,"Functional tests for MX, TXT, SPF, SSHFP validation

* Test trailing slashes in SPF, TXT recordsets
* Test negative values in MX, SSHFP records
* Move recordset validation tests to a new module

Change-Id: I3f3ee09df45ddbefda66591c1937d733eaaf5ef3
",git fetch https://review.opendev.org/openstack/designate refs/changes/49/278549/2 && git format-patch -1 --stdout FETCH_HEAD,"['functionaltests/api/v2/test_recordset.py', 'functionaltests/api/v2/base.py']",2,577028d3bf5db956dda4ee5dfc9e69328f3b6e54,record-validation-tests, return e,,90,34
openstack%2Fpython-cinderclient~master~I45d00c06a8fe5929256260c1d56181db9ca2df48,openstack/python-cinderclient,master,I45d00c06a8fe5929256260c1d56181db9ca2df48,Fix link for OpenStack manual,MERGED,2016-01-16 17:06:56.000000000,2016-02-15 14:41:35.000000000,2016-02-15 14:41:35.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 14305}, {'_account_id': 16237}, {'_account_id': 16308}, {'_account_id': 16708}, {'_account_id': 16871}]","[{'number': 1, 'created': '2016-01-16 17:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/327927b1f26c737e3f22d13ec231e74d0016d713', 'message': 'Fix link for OpenStack manual\n\nThe OpenStack documentation team now has a CLI Reference, link to that\ninstead of the User Guide. The User Guide location is also broken due to\nreorganization of that guide.\n\nChange-Id: I45d00c06a8fe5929256260c1d56181db9ca2df48\n'}, {'number': 2, 'created': '2016-01-16 17:30:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/4a228c3c9f13cdf635170f067c4759d7ca21fa09', 'message': 'Fix link for OpenStack manual\n\nThe OpenStack documentation team now has a CLI Reference, link to that\ninstead of the User Guide. The User Guide location is also broken due to\nreorganization of that guide.\n\nChange-Id: I45d00c06a8fe5929256260c1d56181db9ca2df48\n'}, {'number': 3, 'created': '2016-01-16 18:33:23.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e02bfad204897e3dbd7cd1eb730665a1667a81ee', 'message': 'Fix link for OpenStack manual\n\nThe OpenStack documentation team now has a CLI Reference, link to that\ninstead of the User Guide. The User Guide location is also broken due to\nreorganization of that guide.\n\nChange-Id: I45d00c06a8fe5929256260c1d56181db9ca2df48\n'}]",3,268690,e02bfad204897e3dbd7cd1eb730665a1667a81ee,18,9,3,6547,,,0,"Fix link for OpenStack manual

The OpenStack documentation team now has a CLI Reference, link to that
instead of the User Guide. The User Guide location is also broken due to
reorganization of that guide.

Change-Id: I45d00c06a8fe5929256260c1d56181db9ca2df48
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/90/268690/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,327927b1f26c737e3f22d13ec231e74d0016d713,268690,.. _OpenStack CLI Reference: http://docs.openstack.org/cli-reference/,.. _OpenStack CLI Guide: http://docs.openstack.org/user-guide/content/ch_cli.html,1,1
openstack%2Fdjango_openstack_auth~master~I0f4d5afbcbb46d665edf9ad67ba61482e15d6035,openstack/django_openstack_auth,master,I0f4d5afbcbb46d665edf9ad67ba61482e15d6035,Drop supporting python3.3,MERGED,2016-01-28 12:50:24.000000000,2016-02-15 14:41:29.000000000,2016-02-15 14:41:29.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 4264}]","[{'number': 1, 'created': '2016-01-28 12:50:24.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/d2521170eb35f055dc806e84a694449e2c45dc44', 'message': 'Drop supporting python3.3\n\nChange supoort python3.3 to python3.4\nref:https://blueprints.launchpad.net/horizon/+spec/porting-python3\n\nChange-Id: I0f4d5afbcbb46d665edf9ad67ba61482e15d6035\n'}]",1,273511,d2521170eb35f055dc806e84a694449e2c45dc44,8,3,1,8686,,,0,"Drop supporting python3.3

Change supoort python3.3 to python3.4
ref:https://blueprints.launchpad.net/horizon/+spec/porting-python3

Change-Id: I0f4d5afbcbb46d665edf9ad67ba61482e15d6035
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/11/273511/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,d2521170eb35f055dc806e84a694449e2c45dc44,bp/s,"envlist = py27,py27dj18,pep8,py34","envlist = py27,py27dj18,pep8,py33,py34",2,2
openstack%2Fpython-designateclient~master~I41226aaa87f29802e408a2f69f58c4ba4a7d3233,openstack/python-designateclient,master,I41226aaa87f29802e408a2f69f58c4ba4a7d3233,Updated from global requirements,MERGED,2016-02-10 21:58:45.000000000,2016-02-15 14:41:16.000000000,2016-02-15 14:41:16.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 15699}]","[{'number': 1, 'created': '2016-02-10 21:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/008657cae5e10121772a721d51763bb6b9d01212', 'message': 'Updated from global requirements\n\nChange-Id: I41226aaa87f29802e408a2f69f58c4ba4a7d3233\n'}, {'number': 2, 'created': '2016-02-11 07:44:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-designateclient/commit/e9e6ab9e8997ddf70900375be4049ace7b5b395d', 'message': 'Updated from global requirements\n\nChange-Id: I41226aaa87f29802e408a2f69f58c4ba4a7d3233\n'}]",0,278724,e9e6ab9e8997ddf70900375be4049ace7b5b395d,10,4,2,11131,,,0,"Updated from global requirements

Change-Id: I41226aaa87f29802e408a2f69f58c4ba4a7d3233
",git fetch https://review.opendev.org/openstack/python-designateclient refs/changes/24/278724/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,008657cae5e10121772a721d51763bb6b9d01212,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,2,2
openstack%2Ffuel-library~master~Iaf977f3938c179ed4ffb912259b50b563e866314,openstack/fuel-library,master,Iaf977f3938c179ed4ffb912259b50b563e866314,Fix ring_replicas for swift,MERGED,2016-02-12 11:53:01.000000000,2016-02-15 14:18:38.000000000,2016-02-15 14:17:25.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11827}, {'_account_id': 13948}]","[{'number': 1, 'created': '2016-02-12 11:53:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9a7c0bdea11a4fe1d990d6885310a52db8421b7c', 'message': ""Fix ring_replicas for swift\n\nring_replicas should be set according to the number of controllers, as it's\nimpossible to use hard-coded value for 1 controller (3 replicas, 2 devices)\n\nChange-Id: Iaf977f3938c179ed4ffb912259b50b563e866314\nCloses-bug: #1541863\n""}, {'number': 2, 'created': '2016-02-12 12:57:43.000000000', 'files': ['tests/noop/spec/hosts/swift/swift_spec.rb', 'deployment/puppet/osnailyfacter/modular/swift/swift.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ea876004897e1364ae1fd72bdc789c99aedc58e6', 'message': ""Fix ring_replicas for swift\n\nring_replicas should be set according to the number of controllers, as it's\nimpossible to use hard-coded value for 1 controller (3 replicas, 2 devices)\n\nChange-Id: Iaf977f3938c179ed4ffb912259b50b563e866314\nCloses-bug: #1541863\n""}]",1,279496,ea876004897e1364ae1fd72bdc789c99aedc58e6,36,9,2,7604,,,0,"Fix ring_replicas for swift

ring_replicas should be set according to the number of controllers, as it's
impossible to use hard-coded value for 1 controller (3 replicas, 2 devices)

Change-Id: Iaf977f3938c179ed4ffb912259b50b563e866314
Closes-bug: #1541863
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/96/279496/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/noop/spec/hosts/swift/swift_spec.rb', 'deployment/puppet/osnailyfacter/modular/swift/swift.pp']",2,9a7c0bdea11a4fe1d990d6885310a52db8421b7c,bug/1541863,"$controllers_num = size(get_nodes_hash_by_roles(hiera_hash('network_metadata'), ['controller', 'primary-controller'])) if ($controllers_num < 2) { $ring_replicas = 2 } else { $ring_replicas = 3 } ring_replicas => $ring_replicas,",,23,0
openstack%2Fpuppet-openstacklib~master~I093dd5a4e6294e20761cb3d33373652eeadeac36,openstack/puppet-openstacklib,master,I093dd5a4e6294e20761cb3d33373652eeadeac36,Utility to handle IPv6 address brackets.,MERGED,2016-01-07 19:06:00.000000000,2016-02-15 14:14:05.000000000,2016-02-11 18:13:16.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 8297}, {'_account_id': 14985}]","[{'number': 1, 'created': '2016-01-07 19:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/772b18e830c7d80bdf079c895d55450e736ae597', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function ipv6_add_bracket_maybe to the parser.  With it you\ncan pass a array of string or a string, and if one is a ipv6 address,\nbracket are added.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}, {'number': 2, 'created': '2016-01-07 20:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/b74449b6ffc5ceb1e163b987a92581ed6db35868', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function ipv6_add_bracket_maybe to the parser.  With it you\ncan pass a array of string or a string, and if one is a ipv6 address,\nbracket are added.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}, {'number': 3, 'created': '2016-01-07 23:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/c379c9935b76690d623458cab7d9bd30b7113785', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function ipv6_add_bracket_maybe to the parser.  With it you\ncan pass a anything, and if it is a ipv6 address, it is enclosed inside\nbrackets.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}, {'number': 4, 'created': '2016-01-08 11:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/906e74024504923b2ee5e676e6fc0bd387a1f7ef', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function ipv6_add_bracket_maybe to the parser.  With it you\ncan pass a anything, and if it is a ipv6 address, it is enclosed inside\nbrackets.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}, {'number': 5, 'created': '2016-02-10 12:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/191ed5089c5e67792af8292c7a3717efa4dbf2ca', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function normalize_ip_for_uri to the parser.  It encloses\ninto brackets any valid IPv6 address thrown at it.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}, {'number': 6, 'created': '2016-02-11 12:41:29.000000000', 'files': ['spec/functions/normalize_ip_for_uri_spec.rb', 'lib/puppet/parser/functions/normalize_ip_for_uri.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstacklib/commit/af2aefbd7455e3b5840e51d81a2b7992acea1617', 'message': 'Utility to handle IPv6 address brackets.\n\nThis add the function normalize_ip_for_uri to the parser.  It encloses\ninto brackets any valid IPv6 address thrown at it.\n\nChange-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36\nCloses-bug: 1531960\n'}]",2,264927,af2aefbd7455e3b5840e51d81a2b7992acea1617,45,5,6,8297,,,0,"Utility to handle IPv6 address brackets.

This add the function normalize_ip_for_uri to the parser.  It encloses
into brackets any valid IPv6 address thrown at it.

Change-Id: I093dd5a4e6294e20761cb3d33373652eeadeac36
Closes-bug: 1531960
",git fetch https://review.opendev.org/openstack/puppet-openstacklib refs/changes/27/264927/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/functions/ipv6_add_bracket_maybe_spec.rb', 'lib/puppet/parser/functions/ipv6_add_bracket_maybe.rb']",2,772b18e830c7d80bdf079c895d55450e736ae597,bug/1531960,"require 'ipaddr' module Puppet::Parser::Functions newfunction(:ipv6_add_bracket_maybe, :type => :rvalue, :doc => 'Add brackets if the string (or array of string) is a IPv6 address. Returns the string (or array of string) untouched otherwise.') do |args| ips = args.dup.flatten results = args.dup.flatten ips.each_with_index do |ip, idx| begin if IPAddr.new(ip).ipv6? results[idx] = ""[#{ip}]"" end rescue IPAddr::Error => e # ignore it end end if results.length == 1 return results[0] else return results end end end ",,31,0
openstack%2Fironic~master~I12da2d1f29cc89d21c67aaf65f3a3ffc58cfce10,openstack/ironic,master,I12da2d1f29cc89d21c67aaf65f3a3ffc58cfce10,I don't see any reviewer assigned for this.,ABANDONED,2016-02-15 05:14:30.000000000,2016-02-15 14:05:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-15 05:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/80f03b8d529bb49945852a0c0dc70a551546e709', 'message': ""I don't see any reviewer assigned for this.\n\nChange-Id: I12da2d1f29cc89d21c67aaf65f3a3ffc58cfce10\n""}]",0,280066,80f03b8d529bb49945852a0c0dc70a551546e709,3,1,1,12028,,,0,"I don't see any reviewer assigned for this.

Change-Id: I12da2d1f29cc89d21c67aaf65f3a3ffc58cfce10
",git fetch https://review.opendev.org/openstack/ironic refs/changes/66/280066/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,80f03b8d529bb49945852a0c0dc70a551546e709,,,,0,0
openstack%2Fmanila~master~Ifde2dc5f0b337ab122591ac51384c70f8efa634a,openstack/manila,master,Ifde2dc5f0b337ab122591ac51384c70f8efa634a,Fix tempest test for export locations API,MERGED,2016-02-13 08:12:59.000000000,2016-02-15 14:02:45.000000000,2016-02-15 14:02:45.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14567}]","[{'number': 1, 'created': '2016-02-13 08:12:59.000000000', 'files': ['manila_tempest_tests/tests/api/admin/test_export_locations.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/e71b7a8887bd2930e4e375dd3962bcd192fea20e', 'message': 'Fix tempest test for export locations API\n\nDo not try to get admin export location using member client.\nThis bug appeares only when admin export locations exist.\nThis bug is blocker for implementation of admin export locations by\nshare drivers.\n\nChange-Id: Ifde2dc5f0b337ab122591ac51384c70f8efa634a\nCloses-Bug: #1545184\n'}]",2,279871,e71b7a8887bd2930e4e375dd3962bcd192fea20e,22,8,1,8851,,,0,"Fix tempest test for export locations API

Do not try to get admin export location using member client.
This bug appeares only when admin export locations exist.
This bug is blocker for implementation of admin export locations by
share drivers.

Change-Id: Ifde2dc5f0b337ab122591ac51384c70f8efa634a
Closes-Bug: #1545184
",git fetch https://review.opendev.org/openstack/manila refs/changes/71/279871/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_tempest_tests/tests/api/admin/test_export_locations.py'],1,e71b7a8887bd2930e4e375dd3962bcd192fea20e,bug/1545184, if export_location['is_admin_only']: continue,,2,0
openstack%2Fopenstack-doc-tools~master~I3a40ca5d7bb078fec20ad9fb7a5258f8fd1ae14c,openstack/openstack-doc-tools,master,I3a40ca5d7bb078fec20ad9fb7a5258f8fd1ae14c,Change Git message got cli reference update,MERGED,2016-02-13 13:01:46.000000000,2016-02-15 14:00:44.000000000,2016-02-15 14:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-13 13:01:46.000000000', 'files': ['bin/doc-tools-update-cli-reference'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/faaee70a62c13a8ef6220bb6c4076267cab054be', 'message': 'Change Git message got cli reference update\n\nShorten commit message to follow the git convention.\nChange Git topic branch to unify all related topic.\n\nChange-Id: I3a40ca5d7bb078fec20ad9fb7a5258f8fd1ae14c\n'}]",0,279884,faaee70a62c13a8ef6220bb6c4076267cab054be,10,4,1,10497,,,0,"Change Git message got cli reference update

Shorten commit message to follow the git convention.
Change Git topic branch to unify all related topic.

Change-Id: I3a40ca5d7bb078fec20ad9fb7a5258f8fd1ae14c
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/84/279884/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/doc-tools-update-cli-reference'],1,faaee70a62c13a8ef6220bb6c4076267cab054be,cli-reference,"branch=cli-referencegit commit -a -m ""[cli-ref] Update python-${project}client to ${version##* }""","branch=update_client_$projectgit commit -a -m ""[cli-ref] Update CLI reference for python-${project}client ${version##* }""",2,2
openstack%2Ffuel-main~master~I8f32fb8105d0781938757fa13d5dcbbacbf9c845,openstack/fuel-main,master,I8f32fb8105d0781938757fa13d5dcbbacbf9c845,VirtualBox network fixes and the dockerless mode support,MERGED,2016-02-11 17:31:59.000000000,2016-02-15 13:58:15.000000000,2016-02-15 13:58:14.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8967}, {'_account_id': 10474}, {'_account_id': 11587}, {'_account_id': 12817}, {'_account_id': 13194}, {'_account_id': 13274}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2016-02-11 17:31:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/185ba819e87661d78f704a1e8460ab8c90bfe80a', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * variable 'vm_master_nat_gateway' removed from the config.sh\n   and from the 'enable_outbound_network_for_product_vm'\n   because gateway should be set from the DHCP lease.\n\n * correct parsing of the 'bootstrap_admin_node.log' file for\n   the both 8.0 and 9.0 (with and without docker) Fuel.\n\n * the sysconfig configuration files on the fuel master\n   node now configured the right way. the backup files for\n   configuration files are created. also added some\n   comments for changes in the 'product.sh'.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route.\n\n * now the 'dnsmasq.upstream' and the 'astute.yaml' files\n   correctly modified and could contain up to three DNS\n   nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n""}, {'number': 2, 'created': '2016-02-11 19:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a3a4da82991f4a4afddd8c9b9b3ee9481b0ebd6f', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * variable 'vm_master_nat_gateway' removed from the config.sh\n   and from the 'enable_outbound_network_for_product_vm'\n   because gateway should be set from the DHCP lease.\n\n * correct parsing of the 'bootstrap_admin_node.log' file for\n   the both 8.0 and 9.0 (with and without docker) Fuel.\n\n * the sysconfig configuration files on the fuel master\n   node now configured the right way. the backup files for\n   configuration files are created. also added some\n   comments for changes in the 'product.sh'.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route.\n\n * now the 'dnsmasq.upstream' and the 'astute.yaml' files\n   correctly modified and could contain up to three DNS\n   nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n""}, {'number': 3, 'created': '2016-02-12 17:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c22e13affef74bcd5f34b31b8ca09f34cc4c5f4a', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * using the VirtualBox scripts the Fuel master node now always\n   booted with kernel option 'wait_for_external_config=yes' to\n   provide the same deployment functionality as in the 'fuel-qa'.\n\n * because of configuration task moved to the correct place there\n   is no need to parse 'bootstrap_admin_node.log' and always follow\n   the changes in the 'fuel-library', so all parsing logic removed\n   from the scripts. This also simplifies networking changes and\n   there is no need to patch the files on the fly and restart\n   docker containers if they used.\n\n * variable 'vm_master_nat_gateway' removed from the 'config.sh'\n   and from the 'enable_outbound_network_for_product_vm' because\n   gateway should be set from the DHCP lease.\n\n * the sysconfig configuration files on the fuel master node now\n   configured the right way. the backup files for configuration\n   files are created. also added some comments for changes in the\n   scripts.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route. also\n   ZeroConf route creation and NetworkManager now switched off\n   to correct work of the network service.\n\n * the 'astute.yaml' now correctly modified and could contain\n   up to three DNS nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n""}, {'number': 4, 'created': '2016-02-13 01:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/34a448a9c0e08f612ea1d750e74a588dfd9de082', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * using the VirtualBox scripts the Fuel master node now always\n   booted with kernel option 'wait_for_external_config=yes' to\n   provide the same deployment functionality as in the 'fuel-qa'.\n\n * because of configuration task moved to the correct place there\n   is no need to parse 'bootstrap_admin_node.log' and always follow\n   the changes in the 'fuel-library', so all parsing logic removed\n   from the scripts. This also simplifies networking changes and\n   there is no need to patch the files on the fly and restart\n   docker containers if they used.\n\n * variable 'vm_master_nat_gateway' removed from the 'config.sh'\n   and from the 'enable_outbound_network_for_product_vm' because\n   gateway should be set from the DHCP lease.\n\n * the sysconfig configuration files on the fuel master node now\n   configured the right way. the backup files for configuration\n   files are created. also added some comments for changes in the\n   scripts.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route. also\n   ZeroConf route creation and NetworkManager now switched off\n   to correct work of the network service.\n\n * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now\n   correctly modified and could contain up to three DNS nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n""}, {'number': 5, 'created': '2016-02-14 21:17:33.000000000', 'files': ['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/config.sh', 'virtualbox/functions/product.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/92a0e0b978cdcf60c593824a4c5ad7144fe401bb', 'message': ""VirtualBox network fixes and the dockerless mode support\n\nThis commit include changes:\n\n * using the VirtualBox scripts the Fuel master node now always\n   booted with kernel option 'wait_for_external_config=yes' to\n   provide the same deployment functionality as in the 'fuel-qa'.\n\n * settings for the kernel command line moved to the top config\n   file, because the settings wich could be edited should be placed\n   there.\n\n * because of configuration task moved to the correct place there\n   is no need to parse 'bootstrap_admin_node.log' and always follow\n   the changes in the 'fuel-library', so all parsing logic removed\n   from the scripts. This also simplifies networking changes and\n   there is no need to patch the files on the fly and restart\n   docker containers if they used.\n\n * variable 'vm_master_nat_gateway' removed from the 'config.sh'\n   and from the 'enable_outbound_network_for_product_vm' because\n   gateway should be set from the DHCP lease.\n\n * the sysconfig configuration files on the fuel master node now\n   configured the right way. the backup files for configuration\n   files are created. also added some comments for changes in the\n   scripts.\n\n * now the default routing on the fuel master node correctly\n   configured without creating the second default route. also\n   ZeroConf route creation and NetworkManager now switched off\n   to correct work of the network service.\n\n * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now\n   correctly modified and could contain up to three DNS nameservers.\n\n * added support for the new dockerless 9.0 Fuel.\n\nImplements blueprint: get-rid-docker-containers\n\nChange-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845\nCloses-Bug: #1544241\nPartial-Bug: #1323365\n""}]",0,279203,92a0e0b978cdcf60c593824a4c5ad7144fe401bb,26,12,5,14200,,,0,"VirtualBox network fixes and the dockerless mode support

This commit include changes:

 * using the VirtualBox scripts the Fuel master node now always
   booted with kernel option 'wait_for_external_config=yes' to
   provide the same deployment functionality as in the 'fuel-qa'.

 * settings for the kernel command line moved to the top config
   file, because the settings wich could be edited should be placed
   there.

 * because of configuration task moved to the correct place there
   is no need to parse 'bootstrap_admin_node.log' and always follow
   the changes in the 'fuel-library', so all parsing logic removed
   from the scripts. This also simplifies networking changes and
   there is no need to patch the files on the fly and restart
   docker containers if they used.

 * variable 'vm_master_nat_gateway' removed from the 'config.sh'
   and from the 'enable_outbound_network_for_product_vm' because
   gateway should be set from the DHCP lease.

 * the sysconfig configuration files on the fuel master node now
   configured the right way. the backup files for configuration
   files are created. also added some comments for changes in the
   scripts.

 * now the default routing on the fuel master node correctly
   configured without creating the second default route. also
   ZeroConf route creation and NetworkManager now switched off
   to correct work of the network service.

 * the 'resolv.conf', 'dnsmasq.upstream' and 'astute.yaml' now
   correctly modified and could contain up to three DNS nameservers.

 * added support for the new dockerless 9.0 Fuel.

Implements blueprint: get-rid-docker-containers

Change-Id: I8f32fb8105d0781938757fa13d5dcbbacbf9c845
Closes-Bug: #1544241
Partial-Bug: #1323365
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/03/279203/1 && git format-patch -1 --stdout FETCH_HEAD,"['virtualbox/actions/master-node-enable-internet.sh', 'virtualbox/actions/master-node-create-and-install.sh', 'virtualbox/config.sh', 'virtualbox/functions/product.sh']",4,185ba819e87661d78f704a1e8460ab8c90bfe80a,bp/get-rid-docker-containers," while ! wait_for_line_in_puppet_bootstrap $ip $username $password ""$prompt"" ""build docker containers finished.|Deployment task has succeeded: cobbler|^Fuel.*complete"" ""^Fuel.*FAILED""; do # Convert nameservers list into the one line separated by the comma dns_upstream=""$(echo -e $nameserver | cut -d ' ' -f2 | sed -e':a;N;$!ba;s/\n/,/g')"" # make backups, remove network manager options, disable defaults, enable boot and disable network manager send ""sed -i.orig '/^UUID=\\\|^NM_CONTROLLED=/d;s/^\\\(.*\\\)=yes/\\\1=no/g;s/^ONBOOT=.*/ONBOOT=yes/;/^ONBOOT=/iNM_CONTROLLED=no' /etc/sysconfig/network-scripts/ifcfg-eth{1,2}\r"" # eth1 should be static with private ip address and provided netmask send ""sed -i 's/^BOOTPROTO=.*/BOOTPROTO=static/;/^BOOTPROTO/aIPADDR=${master_ip_pub_net}\\\nNETMASK=${mask}' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" # eth2 should get ip addrees via dhcp and used default route send ""sed -i 's/^BOOTPROTO=.*/BOOTPROTO=dhcp/;s/^DEFROUTE=.*/DEFROUTE=yes/' /etc/sysconfig/network-scripts/ifcfg-eth2\r"" # make backups, remove default route from eth0 and system wide settings send ""sed -i.orig '/^GATEWAY=/d' /etc/sysconfig/network /etc/sysconfig/network-scripts/ifcfg-eth0\r"" # remove old settings from the dnsmasq.upstream if exists send ""sed -i.orig '/^nameserver/d' /etc/dnsmasq.upstream &>/dev/null\r"" # update the dnsmasq.upstream with the new settings send ""echo -e '$nameserver' >>/etc/dnsmasq.upstream\r"" # update the astute.yaml with the new settings send ""sed -i.orig '/DNS_UPSTREAM/c\\""DNS_UPSTREAM\\"": \\""${dns_upstream}\\""' /etc/fuel/astute.yaml\r"" # enable NAT (MASQUERADE) and forwarding for the public network # restart cobbler container in the docker mode, or dnsmasq serviece in the dockerless mode send ""dockerctl restart cobbler &>/dev/null ; service dnsmasq restart &>/dev/null\r"" # apply the network changes # restart again with new newtwork settings send ""dockerctl restart cobbler &>/dev/null ; service dnsmasq restart &>/dev/null\r"" result_inet=$( execute expect << ENDOFEXPECT spawn ssh $ssh_options $username@$ip expect ""connect to host"" exit expect ""*?assword:*"" send ""$password\r"" expect ""$prompt"" send ""for i in {1..5}; do ping -c 2 google.com || ping -c 2 wikipedia.com || sleep 2; done\r"" expect ""*icmp*"" expect ""$prompt"" send ""logout\r"" expect ""$prompt"" )"," while ! wait_for_line_in_puppet_bootstrap $ip $username $password ""$prompt"" ""build docker containers finished.|^Fuel.*complete"" ""^Fuel.*FAILED""; do interface_id=$(($5-1)) # Subtract one to get ethX index (0-based) from the VirtualBox index (from 1 to 4) gateway_ip=$6 send ""file=/etc/sysconfig/network-scripts/ifcfg-eth$interface_id\r"" send ""hwaddr=\\\$(grep HWADDR \\\$file)\r"" send ""uuid=\\\$(grep UUID \\\$file)\r"" send ""echo -e \""\\\$hwaddr\\n\\\$uuid\\nDEVICE=eth$interface_id\\nTYPE=Ethernet\\nONBOOT=yes\\nNM_CONTROLLED=no\\nBOOTPROTO=dhcp\\nPEERDNS=no\"" > \\\$file\r"" send ""sed \""s/GATEWAY=.*/GATEWAY=\""$gateway_ip\""/g\"" -i /etc/sysconfig/network\r"" send ""echo -e \""$nameserver\"" > /etc/dnsmasq.upstream\r"" send ""sed \""s/DNS_UPSTREAM:.*/DNS_UPSTREAM: \\\$(grep \'^nameserver\' /etc/dnsmasq.upstream | cut -d \' \' -f2)/g\"" -i /etc/fuel/astute.yaml\r"" send ""sed -i 's/ONBOOT=no/ONBOOT=yes/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send ""sed -i 's/NM_CONTROLLED=yes/NM_CONTROLLED=no/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send ""sed -i 's/BOOTPROTO=dhcp/BOOTPROTO=static/g' /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send "" echo \""IPADDR=$master_ip_pub_net\"" >> /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send "" echo \""NETMASK=$mask\"" >> /etc/sysconfig/network-scripts/ifcfg-eth1\r"" expect ""$prompt"" send ""dockerctl restart cobbler &>/dev/null\r"" expect ""*OK*"" send ""dockerctl restart cobbler &>/dev/null\r"" send ""dockerctl check cobbler &>/dev/null\r"" expect ""*ready*"" expect ""$prompt"" result_inet=$( execute expect << ENDOFEXPECT spawn ssh $ssh_options $username@$ip expect ""connect to host"" exit expect ""*?assword:*"" send ""$password\r"" expect ""$prompt"" send ""for i in {1..5}; do ping -c 2 google.com || ping -c 2 wikipedia.com || sleep 2; done\r"" expect ""*icmp*"" expect ""$prompt"" send ""logout\r"" expect ""$prompt"" )",39,43
openstack%2Fmurano-dashboard~master~I3756089e1e08b2a29a42336cb781becd01cf6be1,openstack/murano-dashboard,master,I3756089e1e08b2a29a42336cb781becd01cf6be1,fix for the test_add_delete_category_for_package,MERGED,2016-02-15 12:42:00.000000000,2016-02-15 13:57:29.000000000,2016-02-15 13:57:29.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-15 12:42:00.000000000', 'files': ['muranodashboard/tests/functional/sanity_check.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2350c6d2a0810ad4ea0fdd8d8aba9890d65c3823', 'message': ""fix for the test_add_delete_category_for_package\n\nFound that selenium kept focus on modal dialog window when action\ngo_to_submenu() was called. So the menu element wasn't clickable.\nThis is a timing issue. Just added wait.\n\nChange-Id: I3756089e1e08b2a29a42336cb781becd01cf6be1\nCloses-Bug: #1545540\n""}]",0,280190,2350c6d2a0810ad4ea0fdd8d8aba9890d65c3823,9,10,1,19282,,,0,"fix for the test_add_delete_category_for_package

Found that selenium kept focus on modal dialog window when action
go_to_submenu() was called. So the menu element wasn't clickable.
This is a timing issue. Just added wait.

Change-Id: I3756089e1e08b2a29a42336cb781becd01cf6be1
Closes-Bug: #1545540
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/90/280190/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/tests/functional/sanity_check.py'],1,2350c6d2a0810ad4ea0fdd8d8aba9890d65c3823,bug/1545540, # To wait till the focus is swithced # from modal dialog back to the window. self.wait_for_sidebar_is_loaded() ,,4,0
openstack%2Fnetworking-bgpvpn~backport%2Fkilo~Ibebbb306abafc8306601fcf5484fc97ee753fba9,openstack/networking-bgpvpn,backport/kilo,Ibebbb306abafc8306601fcf5484fc97ee753fba9,Initialize Heat plugin,ABANDONED,2016-01-29 14:45:08.000000000,2016-02-15 13:54:29.000000000,,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 9562}, {'_account_id': 12021}, {'_account_id': 13933}, {'_account_id': 16079}, {'_account_id': 16351}]","[{'number': 1, 'created': '2016-01-29 14:45:08.000000000', 'files': ['networking_bgpvpn_heat/bgpvpnservice.py', 'devstack/plugin.sh', 'networking_bgpvpn_heat/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/82dd3faf55eb7543a586168ff79886f210da1808', 'message': 'Initialize Heat plugin\n\nChange-Id: Ibebbb306abafc8306601fcf5484fc97ee753fba9\n'}]",8,274089,82dd3faf55eb7543a586168ff79886f210da1808,8,7,1,13933,,,0,"Initialize Heat plugin

Change-Id: Ibebbb306abafc8306601fcf5484fc97ee753fba9
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/89/274089/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bgpvpn_heat/bgpvpnservice.py', 'devstack/plugin.sh', 'networking_bgpvpn_heat/__init__.py']",3,82dd3faf55eb7543a586168ff79886f210da1808,add-heat-plugin,,,229,0
openstack%2Fnova~master~Icb2f58b005539fec18b49d629ecd568d1f897e51,openstack/nova,master,Icb2f58b005539fec18b49d629ecd568d1f897e51,Prevent access to image when filesystem resize is disabled,MERGED,2015-03-30 15:33:21.000000000,2016-02-15 13:47:29.000000000,2015-06-04 11:17:23.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 7166}, {'_account_id': 8213}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14594}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-03-30 15:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8a4024f7f29dcfce62b557566856fa6fd45c2efa', 'message': 'Prevent access to image when filesystem resize is disabled\n\nWhen resizing filesystems is disabled, the extend() function currently\naccesses an image of a spawning instance to determine if it is\nextendable. This check is not necessary as the image is not resized\nafterwards.\n\nWhen there is no method available to access the image (no libguestfs\nor nbd installed), the superfluous access causes delays in the spawn\nprocedure.\n\nWith this fix, extend() returns if the resize should not be performed\naccording to the configuration before trying to access the image\nin is_image_extendable().\n\nChange-Id: Icb2f58b005539fec18b49d629ecd568d1f897e51\nCloses-bug: #1438245\n'}, {'number': 2, 'created': '2015-04-02 08:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84303b99786a2159485e76489ab1aa38e87dd238', 'message': 'Prevent access to image when filesystem resize is disabled\n\nWhen resizing filesystems is disabled, the extend() function currently\naccesses an image of a spawning instance to determine if it is\nextendable. This check is not necessary as the image is not resized\nafterwards.\n\nWhen there is no method available to access the image (no libguestfs\nor nbd installed), the superfluous access causes delays in the spawn\nprocedure.\n\nWith this fix, extend() returns if the resize should not be performed\naccording to the configuration before trying to access the image\nin is_image_extendable().\n\nChange-Id: Icb2f58b005539fec18b49d629ecd568d1f897e51\nCloses-bug: #1438245\n'}, {'number': 3, 'created': '2015-04-02 12:13:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bd5836699ada47db5a5f4b0b41dde0a092e03d2f', 'message': 'Prevent access to image when filesystem resize is disabled\n\nWhen resizing filesystems is disabled, the extend() function currently\naccesses an image of a spawning instance to determine if it is\nextendable. This check is not necessary as the image is not resized\nafterwards.\n\nWhen there is no method available to access the image (no libguestfs\nor nbd installed), the superfluous access causes delays in the spawn\nprocedure.\n\nWith this fix, extend() returns if the resize should not be performed\naccording to the configuration before trying to access the image\nin is_image_extendable().\n\nChange-Id: Icb2f58b005539fec18b49d629ecd568d1f897e51\nCloses-bug: #1438245\n'}, {'number': 4, 'created': '2015-05-26 09:57:47.000000000', 'files': ['nova/tests/unit/virt/disk/test_api.py', 'nova/virt/disk/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/51800941533ea281ce352bba95304b3327a8848c', 'message': 'Prevent access to image when filesystem resize is disabled\n\nWhen resizing filesystems is disabled, the extend() function currently\naccesses an image of a spawning instance to determine if it is\nextendable. This check is not necessary as the image is not resized\nafterwards.\n\nWhen there is no method available to access the image (no libguestfs\nor nbd installed), the superfluous access causes delays in the spawn\nprocedure.\n\nWith this fix, extend() returns if the resize should not be performed\naccording to the configuration before trying to access the image\nin is_image_extendable().\n\nChange-Id: Icb2f58b005539fec18b49d629ecd568d1f897e51\nCloses-bug: #1438245\n'}]",8,168961,51800941533ea281ce352bba95304b3327a8848c,50,15,4,14594,,,0,"Prevent access to image when filesystem resize is disabled

When resizing filesystems is disabled, the extend() function currently
accesses an image of a spawning instance to determine if it is
extendable. This check is not necessary as the image is not resized
afterwards.

When there is no method available to access the image (no libguestfs
or nbd installed), the superfluous access causes delays in the spawn
procedure.

With this fix, extend() returns if the resize should not be performed
according to the configuration before trying to access the image
in is_image_extendable().

Change-Id: Icb2f58b005539fec18b49d629ecd568d1f897e51
Closes-bug: #1438245
",git fetch https://review.opendev.org/openstack/nova refs/changes/61/168961/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/disk/api.py'],1,8a4024f7f29dcfce62b557566856fa6fd45c2efa,(detached," if use_cow and not CONF.resize_fs_using_block_device: return # in case of non-raw disks we can't just resize the image, but # rather the mounted device instead mounter = mount.Mount.instance_for_format( image, None, None, 'qcow2') if mounter.get_dev(): safe_resize2fs(mounter.device, run_as_root=True, finally_call=mounter.unget_dev)"," if CONF.resize_fs_using_block_device: # in case of non-raw disks we can't just resize the image, but # rather the mounted device instead mounter = mount.Mount.instance_for_format( image, None, None, 'qcow2') if mounter.get_dev(): safe_resize2fs(mounter.device, run_as_root=True, finally_call=mounter.unget_dev)",11,9
openstack%2Fsenlin~master~Id12fb3c29b5b15a6684138c50d36a5dfdc565686,openstack/senlin,master,Id12fb3c29b5b15a6684138c50d36a5dfdc565686,Enable default_region_name config option,MERGED,2016-02-15 10:12:29.000000000,2016-02-15 13:45:02.000000000,2016-02-15 13:45:01.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-15 10:12:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/9d52012cf0bf1af462b5ac80858f316eb993916f', 'message': 'Enable region_name_for_services option\n\nThis patch makes region_name_for_services option take effect. It\nspecifies the default region name of backend openstack services\nthat senlin engine talks to.\n\nChange-Id: Id12fb3c29b5b15a6684138c50d36a5dfdc565686\n'}, {'number': 2, 'created': '2016-02-15 10:33:01.000000000', 'files': ['senlin/drivers/openstack/sdk.py', 'senlin/common/config.py', 'devstack/lib/senlin'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3e49089f7a6ddee585f4696db4b5274edbf0d47e', 'message': 'Enable default_region_name config option\n\nThis patch adds default_region_name config option. It specifies\nthe default region name of backend openstack services that senlin\nengine talks to.\n\nChange-Id: Id12fb3c29b5b15a6684138c50d36a5dfdc565686\n'}]",2,280132,3e49089f7a6ddee585f4696db4b5274edbf0d47e,12,4,2,11034,,,0,"Enable default_region_name config option

This patch adds default_region_name config option. It specifies
the default region name of backend openstack services that senlin
engine talks to.

Change-Id: Id12fb3c29b5b15a6684138c50d36a5dfdc565686
",git fetch https://review.opendev.org/openstack/senlin refs/changes/32/280132/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/drivers/openstack/sdk.py', 'senlin/common/config.py', 'devstack/lib/senlin']",3,9d52012cf0bf1af462b5ac80858f316eb993916f,add-default-region-name-option," iniset $SENLIN_CONF DEFAULT region_name_for_services ""$REGION_NAME""",,6,0
openstack%2Foslo.messaging~master~Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19,openstack/oslo.messaging,master,Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19,simulator.py improvements,MERGED,2016-02-09 11:35:54.000000000,2016-02-15 13:32:49.000000000,2016-02-15 13:32:48.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 7109}, {'_account_id': 7534}, {'_account_id': 13290}]","[{'number': 1, 'created': '2016-02-09 11:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/b276fb979c8bc7c8d09ff64b7c1daf456d4cd3ce', 'message': 'simulator.py improvements\n\nAdded fanout option to target\nFixed timeout option\n\nChange-Id: Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19\n'}, {'number': 2, 'created': '2016-02-11 12:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6a298346b739cb61ecd048a3a61bb26b4f14cb8b', 'message': 'simulator.py improvements\n\nAdded fanout option to target\nFixed timeout option\nRemoved setting config values as they are\nreverted to defaults on driver load\n\nChange-Id: Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19\n'}, {'number': 3, 'created': '2016-02-15 08:38:41.000000000', 'files': ['tools/simulator.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3c0a48aacea94e78a977a3edea919b741df19995', 'message': 'simulator.py improvements\n\nAdded fanout option to target\nFixed timeout option\nRemoved setting config values as they are\nreverted to defaults on driver load\n\nChange-Id: Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19\n'}]",4,277795,3c0a48aacea94e78a977a3edea919b741df19995,19,6,3,7534,,,0,"simulator.py improvements

Added fanout option to target
Fixed timeout option
Removed setting config values as they are
reverted to defaults on driver load

Change-Id: Ia2d8a7bbcb04706deb3d701c1a0f93a0dd835a19
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/95/277795/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/simulator.py'],1,b276fb979c8bc7c8d09ff64b7c1daf456d4cd3ce,(detached," client.add_argument('-tout', dest='timeout', type=int, default=3, client.add_argument('-tout', dest='timeout', type=int, default=3, client.add_argument('--is-fanout', dest='is_fanout', type=bool, default=False, help='Use `call` or `cast` RPC methods') targets = [messaging.Target( topic=topic, server=server_name, fanout=args.is_fanout) for topic, server_name in targets]"," client.add_argument('-t', dest='timeout', type=int, default=3, client.add_argument('-t', dest='timeout', type=int, default=3, targets = [messaging.Target(topic=topic, server=server_name) for topic, server_name in targets]",7,4
openstack%2Fgnocchi~master~I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac,openstack/gnocchi,master,I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac,Rework the handling of the resource ID,MERGED,2016-02-05 17:00:09.000000000,2016-02-15 13:31:38.000000000,2016-02-15 13:31:38.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}]","[{'number': 1, 'created': '2016-02-05 17:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/57d59c4c6b9fd2e1bbad2b54cb1b57747ca1717c', 'message': 'Rework the handling of the resource ID\n\nThis resource id should be validated only on POST.\nAnd we cannot use voluptuous.Schema inside a schema\nthat breaks our required=True/False in deserialize_and_validate()\n\nChange-Id: I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac\nCloses-bug: 1542402\nCloses-bug: 1542404\n'}, {'number': 2, 'created': '2016-02-05 17:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/0725ad305b1dd388fdaa92f6e4465cb72669e816', 'message': 'Rework the handling of the resource ID\n\nThis resource id should be validated only on POST.\nAnd we cannot use voluptuous.Schema inside a schema\nthat breaks our required=True/False in deserialize_and_validate()\n\nChange-Id: I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac\nCloses-bug: 1542402\nCloses-bug: 1542404\n'}, {'number': 3, 'created': '2016-02-08 07:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/51cd3977acf99594f6f31915a6187b0bfb0a030e', 'message': 'Rework the handling of the resource ID\n\nThis resource id should be validated only on POST.\nAnd we cannot use voluptuous.Schema inside a schema\nthat breaks our required=True/False in deserialize_and_validate()\n\nChange-Id: I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac\nCloses-bug: 1542402\nCloses-bug: 1542404\n'}, {'number': 4, 'created': '2016-02-15 11:10:51.000000000', 'files': ['gnocchi/rest/__init__.py', 'gnocchi/tests/gabbi/gabbits/resource.yaml'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7e48798514729e47ef4c78225faa6273d759a52b', 'message': 'Rework the handling of the resource ID\n\nThis resource id should be validated only on POST.\nAnd we cannot use voluptuous.Schema inside a schema\nthat breaks our required=True/False in deserialize_and_validate()\n\nChange-Id: I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac\nCloses-bug: 1542402\nCloses-bug: 1542404\n'}]",3,276830,7e48798514729e47ef4c78225faa6273d759a52b,13,3,4,2813,,,0,"Rework the handling of the resource ID

This resource id should be validated only on POST.
And we cannot use voluptuous.Schema inside a schema
that breaks our required=True/False in deserialize_and_validate()

Change-Id: I9d9e7e5a031bb341d4ece6b5b1a95f53ec41e3ac
Closes-bug: 1542402
Closes-bug: 1542404
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/30/276830/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/rest/__init__.py', 'gnocchi/tests/gabbi/gabbits/resource.yaml']",2,57d59c4c6b9fd2e1bbad2b54cb1b57747ca1717c,bug/1542402," - name: post instance resource with missing data url: /v1/resource/instance method: post request_headers: x-user-id: 0fbb231484614b1a80131fc22f6afc9c x-project-id: f3d41b770cc14f0bb94a1d5be9c0e3ea content-type: application/json data: id: 75C44741-CC60-4033-804E-2D3098C7D2E9 user_id: 0fbb231484614b1a80131fc22f6afc9c project_id: f3d41b770cc14f0bb94a1d5be9c0e3ea flavor_id: ""2"" image_ref: http://image host: compute1 status: 400 - name: patch instance resource with id url: /v1/resource/instance/75C44741-CC60-4033-804E-2D3098C7D2E9 method: patch request_headers: x-user-id: 0fbb231484614b1a80131fc22f6afc9c x-project-id: f3d41b770cc14f0bb94a1d5be9c0e3ea content-type: application/json data: id: foobar status: 400",,47,17
openstack%2Fnova-powervm~master~Ieb250d539e4adad8977d3a2716c2f1cf341c4137,openstack/nova-powervm,master,Ieb250d539e4adad8977d3a2716c2f1cf341c4137,Add vif driver framework,MERGED,2016-02-03 23:05:45.000000000,2016-02-15 13:31:27.000000000,2016-02-15 13:31:27.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 9623}, {'_account_id': 12947}, {'_account_id': 13883}, {'_account_id': 14070}, {'_account_id': 16128}, {'_account_id': 18549}, {'_account_id': 20137}, {'_account_id': 20138}]","[{'number': 1, 'created': '2016-02-03 23:05:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/e276b40d899d8e99c1b4d6bd695697078b2003cf', 'message': 'WIP: Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 2, 'created': '2016-02-04 14:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/57782bff8116542d1e8dca7ae5c95f939f550752', 'message': 'WIP: Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 3, 'created': '2016-02-04 15:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/1cd50a3172447af57c05566d02ecd29b5b8cdfdd', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 4, 'created': '2016-02-05 21:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/ccc402750fa818d52200ebf91e63805a260abbe5', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 5, 'created': '2016-02-08 14:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/765ace7ff95e28754af4ded2609cfab5183199ad', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 6, 'created': '2016-02-09 20:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/0f7c4e2b5e5c5ccbdb07d770c447c36d07fd28b8', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 7, 'created': '2016-02-10 16:13:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/f8ce701ca34284376576215e25d4fa44cc31aca0', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 8, 'created': '2016-02-10 16:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/6ebbf694fecaaa29e1b3e88914ac53c4c4ad9281', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}, {'number': 9, 'created': '2016-02-10 17:24:00.000000000', 'files': ['nova_powervm/tests/virt/powervm/test_vm.py', 'nova_powervm/virt/powervm/vif.py', 'nova_powervm/virt/powervm/tasks/network.py', 'nova_powervm/tests/virt/powervm/test_driver.py', 'nova_powervm/tests/virt/powervm/tasks/test_network.py', 'nova_powervm/tests/virt/powervm/test_vif.py', 'nova_powervm/virt/powervm/vm.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/01a452be03041c348ca854bba6db86fda91a4047', 'message': 'Add vif driver framework\n\nThis change set adds a new vif driver interface (as well as SEA\nimplementation) for the nova-powervm driver.  This is important as the\nplatform looks to new VIF types (ex. qbg or ovs).\n\nChange-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137\n'}]",47,275971,01a452be03041c348ca854bba6db86fda91a4047,40,11,9,8190,,,0,"Add vif driver framework

This change set adds a new vif driver interface (as well as SEA
implementation) for the nova-powervm driver.  This is important as the
platform looks to new VIF types (ex. qbg or ovs).

Change-Id: Ieb250d539e4adad8977d3a2716c2f1cf341c4137
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/71/275971/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/tests/virt/powervm/test_vm.py', 'nova_powervm/virt/powervm/tasks/network.py', 'nova_powervm/virt/powervm/vif.py', 'nova_powervm/tests/virt/powervm/test_driver.py', 'nova_powervm/tests/virt/powervm/tasks/test_network.py', 'nova_powervm/tests/virt/powervm/test_vif.py', 'nova_powervm/virt/powervm/vm.py']",7,e276b40d899d8e99c1b4d6bd695697078b2003cf,enable_multiple_vif_type,,"from pypowervm.tasks import cnadef crt_vif(adapter, instance, host_uuid, vif): """"""Will create a Client Network Adapter on the system. :param adapter: The pypowervm adapter API interface. :param instance: The nova instance to create the VIF against. :param host_uuid: The host system UUID. :param vif: The nova VIF that describes the ethernet interface. :return: The created network adapter wrapper. """""" lpar_uuid = get_pvm_uuid(instance) # CNA's require a VLAN. If the network doesn't provide, default to 1 vlan = vif['network']['meta'].get('vlan', 1) return cna.crt_cna(adapter, host_uuid, lpar_uuid, vlan, mac_addr=vif['address']) def crt_secure_rmc_vif(adapter, instance, host_uuid): """"""Creates the Secure RMC Network Adapter on the VM. :param adapter: The pypowervm adapter API interface. :param instance: The nova instance to create the VIF against. :param host_uuid: The host system UUID. :return: The created network adapter wrapper. """""" lpar_uuid = get_pvm_uuid(instance) return cna.crt_cna(adapter, host_uuid, lpar_uuid, SECURE_RMC_VLAN, vswitch=SECURE_RMC_VSWITCH, crt_vswitch=True) def get_secure_rmc_vswitch(adapter, host_uuid): """"""Returns the vSwitch that is used for secure RMC. :param adapter: The pypowervm adapter API interface. :param host_uuid: The host system UUID. :return: The wrapper for the secure RMC vSwitch. If it does not exist on the system, None is returned. """""" resp = adapter.read(pvm_ms.System.schema_type, root_id=host_uuid, child_type=pvm_net.VSwitch.schema_type) vswitches = pvm_net.VSwitch.wrap(resp) for vswitch in vswitches: if vswitch.name == SECURE_RMC_VSWITCH: return vswitch return None ",319,112
openstack%2Fbarbican~master~I5c892d1b09e6bc0cb155c5591b12f409d3c86419,openstack/barbican,master,I5c892d1b09e6bc0cb155c5591b12f409d3c86419,Document public secret type,MERGED,2015-04-08 22:59:22.000000000,2016-02-15 13:25:32.000000000,2016-02-15 13:25:32.000000000,"[{'_account_id': 3}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8623}, {'_account_id': 10873}, {'_account_id': 16046}, {'_account_id': 19673}]","[{'number': 1, 'created': '2015-04-08 22:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b59f776a5369a5b773276c1788eb4a2dbf9ae2bd', 'message': 'Document public secret type\n\nAdds documentation for public secret types.  Add two examples of storing\npublic secrets, one with a POST followed by PUT, and one with a single\nPOST.  The second example is incomplete until bug 1441866 is fixed.\n\nChange-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419\n'}, {'number': 2, 'created': '2015-04-09 03:22:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b889b0cf40736a85be4fb9e7af376735b2ff8899', 'message': 'Document public secret type\n\nAdds documentation for public secret types.  Add two examples of storing\npublic secrets, one with a POST followed by PUT, and one with a single\nPOST.  The second example is incomplete until bug 1441866 is fixed.\n\nChange-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419\n'}, {'number': 3, 'created': '2015-04-09 03:27:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c356cfc9102fd63ae03a96341da88305223924d5', 'message': 'Document public secret type\n\nAdds documentation for public secret types.  Add two examples of storing\npublic secrets, one with a POST followed by PUT, and one with a single\nPOST.  The second example is incomplete until bug 1441866 is fixed.\n\nChange-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419\n'}, {'number': 4, 'created': '2016-02-10 23:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/cab3efdab4dfbe350a8e675ebf351e9879e37f37', 'message': 'Document public secret type\n\nAdds documentation for public secret types.  Add two examples of storing\npublic secrets, one with a POST followed by PUT, and one with a single\nPOST.  The second example is incomplete until bug 1441866 is fixed.\n\nChange-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419\n'}, {'number': 5, 'created': '2016-02-11 22:21:45.000000000', 'files': ['doc/source/api/reference/secret_types.rst'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6dbc87dbde25cb6e86c06369e1c38b3ff0a236f3', 'message': 'Document public secret type\n\nAdds documentation for public secret types.  Add two examples of storing\npublic secrets, one with a POST followed by PUT, and one with a single\nPOST.  The second example is incomplete until bug 1441866 is fixed.\n\nChange-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419\n'}]",36,171859,6dbc87dbde25cb6e86c06369e1c38b3ff0a236f3,32,9,5,7973,,,0,"Document public secret type

Adds documentation for public secret types.  Add two examples of storing
public secrets, one with a POST followed by PUT, and one with a single
POST.  The second example is incomplete until bug 1441866 is fixed.

Change-Id: I5c892d1b09e6bc0cb155c5591b12f409d3c86419
",git fetch https://review.opendev.org/openstack/barbican refs/changes/59/171859/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/reference/secret_types.rst'],1,b59f776a5369a5b773276c1788eb4a2dbf9ae2bd,bug/1441866,"Symmetric #########with symmetric secrets is ``application/octet-stream``. When storing a symmetric secret with a single POST request, the data must be encoded so that it may be included inside the JSON body of the request. In this case, the content encoding of ``base64`` can be used. Example 1.1 ***********The ``retrieved_key`` file now contains the byte array we started with. Note Public ###### The ``public`` secret type is used to store the public key of an asymmetric keypair. For example, a public secret can be used to store the public key of an RSA keypair. Currently there is only one file format accepted for public secrets: A DER-encoded SubjectPublicKeyInfo structre as defined by X.509 RFC 5280 that has been Base64 encoded with a PEM header and footer. This is the type of public key that is generated by the ``openssl`` tool by default. The content type used with public secrets is ``application/octet-stream``. When storing a public secret with a single POST request, the contents of the file must be encoded, since JSON does not accept newline characters. In this case, the contents of the file must be Base64 encoded and the content encoding of ``base64`` can be used. Example 2.1 *********** Create an RSA keypair and store the public key in Barbican. For this example we will be using a metadata-only POST followed by a PUT. .. code-block:: bash # Create the RSA keypair openssl genrsa -out private.pem 2048 # Extract the public key openssl rsa -in private.pem -out public.pem -pubout # Submit a metadata-only POST curl -vv -H ""X-Auth-Token: $TOKEN"" \ -H 'Accept: application/json' \ -H 'Content-Type: application/json' \ -d '{""name"": ""RSA Public Key"", ""secret_type"": ""public"", ""algorithm"": ""RSA""}' \ http://localhost:9311/v1/secrets | python -m json.tool This should return a reference (URI) for the Secret that was created: .. code-block:: json 200 OK { ""secret_ref"": ""http://localhost:9311/v1/secrets/cd20d134-c229-417a-a753-86432ad13bad"" } We can use this reference to add the payload with a PUT request: .. code-block:: bash curl -vv -X PUT -H ""X-Auth-Token: $TOKEN"" \ -H 'Accept: application/json' \ -H 'Content-Type: application/octet-stream' \ --data-binary @public.pem \ http://localhost:9311/v1/secrets/cd20d134-c229-417a-a753-86432ad13bad The server shoudl respond with a 2xx response to indicate that the PUT request was processed successfully: .. code-block:: json 204 - No Content Now we should be able to request the metadata and see the new content type listed there: .. code-block:: bash curl -vv -H ""X-Auth-Token: $TOKEN"" \ -H 'Accept: application/json' \ http://localhost:9311/v1/secrets/cd20d134-c229-417a-a753-86432ad13bad | python -m json.tool .. code-block:: json { ""algorithm"": ""RSA"", ""bit_length"": null, ""content_types"": { ""default"": ""application/octet-stream"" }, ""created"": ""2015-04-08T21:45:59.239976"", ""creator_id"": ""3a7e3d2421384f56a8fb6cf082a8efab"", ""expiration"": null, ""mode"": null, ""name"": ""RSA Public Key"", ""secret_ref"": ""http://localhost:9311/v1/secrets/cd20d134-c229-417a-a753-86432ad13bad"", ""secret_type"": ""public"", ""status"": ""ACTIVE"", ""updated"": ""2015-04-08T21:52:57.523969"" } Finally we can use the default content type listed in ``content_types`` to retrieve the public key: .. code-block:: bash curl -vv -H ""X-Auth-Token: $TOKEN"" \ -H 'Accept: application/octet-stream' \ -o retrieved_public.pem \ http://localhost:9311/v1/secrets/cd20d134-c229-417a-a753-86432ad13bad/payload The ``retrieved_public.pem`` file now has the same contents as the public.pem file we started with. Example 2.2 *********** Create an RSA keypair and store the public key in Barbican. For this example we will be using a single POST request. .. code-block:: bash # Create the RSA keypair openssl genrsa -out private.pem 2048 # Extract the public key openssl rsa -in private.pem -out public.pem -pubout # Base64 encode the contents of the public key PUB_BASE64=$(base64 < public.pem) curl -vv -H ""X-Auth-Token: $TOKEN"" \ -H 'Accept: application/json' \ -H 'Content-Type: application/json' \ -d '{""name"": ""RSA Public Key"", ""secret_type"": ""public"", ""payload"": ""'""$PUB_BASE64""'"", ""payload_content_type"": ""application/octet-stream"", ""payload_content_encoding"": ""base64"", ""algorithm"": ""RSA""}' \ http://localhost:9311/v1/secrets | python -m json.tool This should return a reference (URI) for the Secret that was created. TODO(dmend): Finish this example after bug #1441866 is fixed.","Symmetric Keys ##############with symmetric keys is ``application/octet-stream``. When storing a symmetric secret with a single POST request, the data must be encoded so that it may be included inside the JSON body of the request. In this case, the content encoding of ``base64`` can be used Example *******The *retrieved_key* file now contains the byte array we started with. Note",148,9
openstack%2Ffuel-agent~master~I297c5a4d17606274d6f344c7dcbdcf44663984b2,openstack/fuel-agent,master,I297c5a4d17606274d6f344c7dcbdcf44663984b2,Increase all the grub_timeout defaults to 10sec,MERGED,2016-02-15 09:58:30.000000000,2016-02-15 13:23:56.000000000,2016-02-15 13:23:55.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 14188}, {'_account_id': 14200}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2016-02-15 09:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/61aeb2e30298400931be649da65a29e97395e06d', 'message': 'Increase all the grub_timeout defaults to 10sec\n\nChange-Id: I297c5a4d17606274d6f344c7dcbdcf44663984b2\nCloses-Bug: #1540638\n'}, {'number': 2, 'created': '2016-02-15 10:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/76ea9de7be24f23e73fb021994e4b0e09a1f94d0', 'message': 'Increase all the grub_timeout defaults to 10sec\n\nChange-Id: I297c5a4d17606274d6f344c7dcbdcf44663984b2\nCloses-Bug: #1540638\n'}, {'number': 3, 'created': '2016-02-15 12:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/a667b2f0616991fed4de35220494473f747ae9dd', 'message': 'Increase all the grub_timeout defaults to 10sec\n\nThis increase the timeout value and adds the ability in the\nIPMI session to catch the moment and press a key to see the\ngrub menu to choose a different kernel.\n\nChange-Id: I297c5a4d17606274d6f344c7dcbdcf44663984b2\nCloses-Bug: #1540638\n'}, {'number': 4, 'created': '2016-02-15 12:13:22.000000000', 'files': ['fuel_agent/tests/test_grub_utils.py', 'fuel_agent/tests/test_manager.py', 'etc/fuel-agent/fuel-agent.conf.sample', 'fuel_agent/manager.py', 'fuel_agent/utils/grub.py'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/7859dbd99cb7f398f1a89aace8865ade269cfa96', 'message': 'Increase all the grub_timeout defaults to 10sec\n\nThis increases the timeout value and adds the ability in the\nIPMI session to catch the moment and press a key to see the\ngrub menu to choose a different kernel.\n\nChange-Id: I297c5a4d17606274d6f344c7dcbdcf44663984b2\nCloses-Bug: #1540638\n'}]",1,280126,7859dbd99cb7f398f1a89aace8865ade269cfa96,32,9,4,14200,,,0,"Increase all the grub_timeout defaults to 10sec

This increases the timeout value and adds the ability in the
IPMI session to catch the moment and press a key to see the
grub menu to choose a different kernel.

Change-Id: I297c5a4d17606274d6f344c7dcbdcf44663984b2
Closes-Bug: #1540638
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/26/280126/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_agent/tests/test_manager.py', 'etc/fuel-agent/fuel-agent.conf.sample', 'fuel_agent/manager.py', 'fuel_agent/utils/grub.py']",4,61aeb2e30298400931be649da65a29e97395e06d,bug/1540638," kernel_params='', chroot='', grub_timeout=10):def grub2_cfg(kernel_params='', chroot='', grub_timeout=10):"," kernel_params='', chroot='', grub_timeout=5):def grub2_cfg(kernel_params='', chroot='', grub_timeout=5):",8,8
openstack%2Fnetworking-powervm~master~Icbc781b10076adb1e2d8ee1f298ddf70b73c3635,openstack/networking-powervm,master,Icbc781b10076adb1e2d8ee1f298ddf70b73c3635,Port over pretty_tox.sh from neutron,MERGED,2016-02-11 19:09:50.000000000,2016-02-15 13:22:53.000000000,2016-02-15 13:22:53.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 9623}, {'_account_id': 12947}, {'_account_id': 13883}]","[{'number': 1, 'created': '2016-02-11 19:09:50.000000000', 'files': ['test-requirements.txt', 'tox.ini', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/networking-powervm/commit/f17e5ebf5eccb8d76439900702a57a5d381326f5', 'message': ""Port over pretty_tox.sh from neutron\n\nneutron has a bash script that uses the ostestr package to\nformat the output from tox in a 'pretty' format. It makes it\nmuch more readable. pretty_tox.sh is pulled from neutron\nas-is and enabled in tox.ini.\n\nChange-Id: Icbc781b10076adb1e2d8ee1f298ddf70b73c3635\n""}]",0,279235,f17e5ebf5eccb8d76439900702a57a5d381326f5,9,5,1,18549,,,0,"Port over pretty_tox.sh from neutron

neutron has a bash script that uses the ostestr package to
format the output from tox in a 'pretty' format. It makes it
much more readable. pretty_tox.sh is pulled from neutron
as-is and enabled in tox.ini.

Change-Id: Icbc781b10076adb1e2d8ee1f298ddf70b73c3635
",git fetch https://review.opendev.org/openstack/networking-powervm refs/changes/35/279235/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'tox.ini', 'tools/pretty_tox.sh']",3,f17e5ebf5eccb8d76439900702a57a5d381326f5,pretty_tox,"#!/usr/bin/env bash set -o pipefail TESTRARGS=$1 # --until-failure is not compatible with --subunit see: # # https://bugs.launchpad.net/testrepository/+bug/1411804 # # this work around exists until that is addressed if [[ ""$TESTARGS"" =~ ""until-failure"" ]]; then python setup.py testr --slowest --testr-args=""$TESTRARGS"" else python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS"" | subunit-trace -f fi ",,19,1
openstack%2Fpython-gnocchiclient~master~I9f2a3aeef715f168de1ac215f87f19b43c7c7e95,openstack/python-gnocchiclient,master,I9f2a3aeef715f168de1ac215f87f19b43c7c7e95,Quote query string when POST is used,MERGED,2016-02-10 14:13:48.000000000,2016-02-15 13:19:06.000000000,2016-02-15 13:19:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2016-02-10 14:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-gnocchiclient/commit/66f5d6a0502bfc76027d5125a85e94207f1cd9f8', 'message': 'Quote query string when POST is used\n\nChange-Id: I9f2a3aeef715f168de1ac215f87f19b43c7c7e95\n'}, {'number': 2, 'created': '2016-02-12 10:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-gnocchiclient/commit/ea5bdcd3df93677f1c6c5af3e7f57513cd055039', 'message': 'Quote query string when POST is used\n\nChange-Id: I9f2a3aeef715f168de1ac215f87f19b43c7c7e95\n'}, {'number': 3, 'created': '2016-02-15 09:35:15.000000000', 'files': ['gnocchiclient/utils.py', 'gnocchiclient/tests/unit/test_utils.py', 'gnocchiclient/tests/functional/test_metric.py'], 'web_link': 'https://opendev.org/openstack/python-gnocchiclient/commit/21c54eda219b3ae45392ec189241d7d911891bbf', 'message': 'Quote query string when POST is used\n\nChange-Id: I9f2a3aeef715f168de1ac215f87f19b43c7c7e95\n'}]",0,278389,21c54eda219b3ae45392ec189241d7d911891bbf,13,3,3,2813,,,0,"Quote query string when POST is used

Change-Id: I9f2a3aeef715f168de1ac215f87f19b43c7c7e95
",git fetch https://review.opendev.org/openstack/python-gnocchiclient refs/changes/89/278389/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchiclient/utils.py', 'gnocchiclient/tests/unit/test_utils.py']",2,66f5d6a0502bfc76027d5125a85e94207f1cd9f8,sileht/timestamp," def test_dict_to_querystring(self): self.assertEqual(""start=2016-02-10T13%3A54%3A53%2B00%3A00"" ""&stop=2016-02-10T13%3A56%3A42%2B02%3A00"", utils.dict_to_querystring( {""start"": ""2016-02-10T13:54:53+00:00"", ""stop"": ""2016-02-10T13:56:42+02:00""}))",,9,1
openstack%2Ffuel-nailgun-agent~master~I9441a4a4c24e7908d49e0b63f1f2d92e434c2f8e,openstack/fuel-nailgun-agent,master,I9441a4a4c24e7908d49e0b63f1f2d92e434c2f8e,Fail if we can't find main MAC and IP,ABANDONED,2016-02-12 16:00:36.000000000,2016-02-15 13:16:23.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7468}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11898}]","[{'number': 1, 'created': '2016-02-12 16:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-agent/commit/f76116cd63f46180f89a9e1a3e94201150b9a861', 'message': ""Fail if we can't find main MAC and IP\n\nInstead of sending random MAC and IP to nailgun as nodes new main\nMAC/IP it's better to fail. Agent will collect and send correct\ninfo when needed IP is back up.\n\nChange-Id: I9441a4a4c24e7908d49e0b63f1f2d92e434c2f8e\nCloses-bug: #1532823\n""}, {'number': 2, 'created': '2016-02-15 12:52:02.000000000', 'files': ['agent'], 'web_link': 'https://opendev.org/openstack/fuel-nailgun-agent/commit/7917f290dd96d96bfbb98db8458f9d7aa465ce4f', 'message': ""Fail if we can't find main MAC and IP\n\nInstead of sending random MAC and IP to nailgun as nodes new main\nMAC/IP it's better to fail. Agent will collect and send correct\ninfo when needed IP is back up.\n\nChange-Id: I9441a4a4c24e7908d49e0b63f1f2d92e434c2f8e\nCloses-bug: #1532823\n""}]",2,279620,7917f290dd96d96bfbb98db8458f9d7aa465ce4f,17,10,2,9387,,,0,"Fail if we can't find main MAC and IP

Instead of sending random MAC and IP to nailgun as nodes new main
MAC/IP it's better to fail. Agent will collect and send correct
info when needed IP is back up.

Change-Id: I9441a4a4c24e7908d49e0b63f1f2d92e434c2f8e
Closes-bug: #1532823
",git fetch https://review.opendev.org/openstack/fuel-nailgun-agent refs/changes/20/279620/2 && git format-patch -1 --stdout FETCH_HEAD,['agent'],1,f76116cd63f46180f89a9e1a3e94201150b9a861,bug/1532823," master_data = _master_ip_and_mac unless master_data[:mac] and master_data[:ip] @logger.error(""Unable to determine admin MAC and IP. Exiting."") exit 1 end", master_data=_master_ip_and_mac,5,1
openstack%2Fglance~master~I1442b6743e77e2aa47a708ae1c38d7c4a54b8cd1,openstack/glance,master,I1442b6743e77e2aa47a708ae1c38d7c4a54b8cd1,Promote log message to exception level on artifact load failure,MERGED,2016-02-08 13:01:55.000000000,2016-02-15 13:13:53.000000000,2016-02-15 13:13:53.000000000,"[{'_account_id': 3}, {'_account_id': 7575}, {'_account_id': 14676}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-08 13:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c5a149a62b135d76cc16d0bc93b4cd17ef848bd2', 'message': 'Promote log message to exception level on artifact load failure\n\nBefore this patch exact place of where the error happened during\nartifact load was hard to pinpoint, because it was not shown in the\nstacktrace. With this change exception is no longer just converted to\nstring and printed, but also a stacktrace of exact location of the error\nis printed\n\nChange-Id: I1442b6743e77e2aa47a708ae1c38d7c4a54b8cd1\nCloses-Bug: #1543105\n'}, {'number': 2, 'created': '2016-02-12 13:15:10.000000000', 'files': ['glance/common/glare/loader.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/a3e19a0abe1e68daaf90cfcd6db9e6056cf10db2', 'message': 'Promote log message to exception level on artifact load failure\n\nBefore this patch exact place of where the error happened during\nartifact load was hard to pinpoint, because it was not shown in the\nstacktrace. With this change exception is no longer just converted to\nstring and printed, but also a stacktrace of exact location of the error\nis printed\n\nChange-Id: I1442b6743e77e2aa47a708ae1c38d7c4a54b8cd1\nCloses-Bug: #1543105\n'}]",0,277378,a3e19a0abe1e68daaf90cfcd6db9e6056cf10db2,18,4,2,15168,,,0,"Promote log message to exception level on artifact load failure

Before this patch exact place of where the error happened during
artifact load was hard to pinpoint, because it was not shown in the
stacktrace. With this change exception is no longer just converted to
string and printed, but also a stacktrace of exact location of the error
is printed

Change-Id: I1442b6743e77e2aa47a708ae1c38d7c4a54b8cd1
Closes-Bug: #1543105
",git fetch https://review.opendev.org/openstack/glance refs/changes/78/277378/2 && git format-patch -1 --stdout FETCH_HEAD,['glance/common/artifacts/loader.py'],1,c5a149a62b135d76cc16d0bc93b4cd17ef848bd2,bug/1543105," msg = (_LE(""Could not load plugin from %(module)s"") % {""module"": ep.module_name}) LOG.exception(msg)"," msg = (_LE(""Could not load plugin from %(module)s: %(msg)s"") % {""module"": ep.module_name, ""msg"": exc}) LOG.error(msg)",3,3
openstack%2Fnova~master~I44283f19823bf39159633fa93f575e306bcf1970,openstack/nova,master,I44283f19823bf39159633fa93f575e306bcf1970,Fix reported ppc64le bug on video selection,MERGED,2016-02-11 18:40:16.000000000,2016-02-15 13:13:10.000000000,2016-02-15 13:13:09.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-11 18:40:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b80c53e0b432fb3189ef385e39d980d0447e3b49', 'message': ""Fix reported ppc64le bug on video selection\n\nppc64le apparently is the same as other ppc plaforms in it's video\nselection. This one line fix was put into a reported bug and addresses\nthis for people.\n\nChange-Id: I44283f19823bf39159633fa93f575e306bcf1970\nCloses-Bug: #1523742\n""}, {'number': 2, 'created': '2016-02-11 19:02:48.000000000', 'files': ['nova/virt/libvirt/driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/87069e7bf788ec4e80bd340bcb97d57117cbc4d2', 'message': ""Fix reported ppc64le bug on video selection\n\nppc64le apparently is the same as other ppc plaforms in it's video\nselection. This one line fix was put into a reported bug and addresses\nthis for people.\n\nCo-Authored-By: xiaojinwei001@163.com\n\nChange-Id: I44283f19823bf39159633fa93f575e306bcf1970\nCloses-Bug: #1523742\n""}]",0,279227,87069e7bf788ec4e80bd340bcb97d57117cbc4d2,26,7,2,2750,,,0,"Fix reported ppc64le bug on video selection

ppc64le apparently is the same as other ppc plaforms in it's video
selection. This one line fix was put into a reported bug and addresses
this for people.

Co-Authored-By: xiaojinwei001@163.com

Change-Id: I44283f19823bf39159633fa93f575e306bcf1970
Closes-Bug: #1523742
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/279227/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/driver.py'],1,b80c53e0b432fb3189ef385e39d980d0447e3b49,bug1523742," elif guestarch in (arch.PPC, arch.PPC64, arch.PPC64LE):"," elif guestarch in (arch.PPC, arch.PPC64):",1,1
openstack%2Fkarbor~master~I043492dc0ca999b339c2a85b976ea2283737fdc7,openstack/karbor,master,I043492dc0ca999b339c2a85b976ea2283737fdc7,Make ProtectionPlugin abstract,MERGED,2016-02-14 13:12:49.000000000,2016-02-15 13:12:34.000000000,2016-02-15 13:12:34.000000000,"[{'_account_id': 3}, {'_account_id': 11904}, {'_account_id': 13070}, {'_account_id': 15069}, {'_account_id': 16203}, {'_account_id': 19346}, {'_account_id': 19720}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-14 13:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d6e57479f10f57056729a0cdcbc8e6321857a1e1', 'message': 'Make ProtectionPlugin abstract\n\nChange-Id: I043492dc0ca999b339c2a85b976ea2283737fdc7\n'}, {'number': 2, 'created': '2016-02-14 14:21:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/d8437ebf104281140ddc234f40300ece0bb0381e', 'message': 'Make ProtectionPlugin abstract\n\nChange-Id: I043492dc0ca999b339c2a85b976ea2283737fdc7\n'}, {'number': 3, 'created': '2016-02-15 12:47:14.000000000', 'files': ['smaug/services/protection/protection_plugin.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/505941c061f960dfbb7a15f6379ac0d99ade769f', 'message': 'Make ProtectionPlugin abstract\n\nChange-Id: I043492dc0ca999b339c2a85b976ea2283737fdc7\n'}]",1,279971,505941c061f960dfbb7a15f6379ac0d99ade769f,13,8,3,2023,,,0,"Make ProtectionPlugin abstract

Change-Id: I043492dc0ca999b339c2a85b976ea2283737fdc7
",git fetch https://review.opendev.org/openstack/karbor refs/changes/71/279971/2 && git format-patch -1 --stdout FETCH_HEAD,['smaug/services/protection/protection_plugin.py'],1,d6e57479f10f57056729a0cdcbc8e6321857a1e1,service_move,import abc import six@six.add_metaclass(abc.ABCMeta) class ProtectionPlugin(object): @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod @abc.abstractmethod,"class ProtectionPlugin(object): def __init__(self): super(ProtectionPlugin, self).__init__() self.protectable_type = None self.schema = None # TODO(wangliuan) ",12,6
openstack%2Fnetworking-hyperv~master~If1b6c0af4de2d35ed970aff4200dca22f818c9c4,openstack/networking-hyperv,master,If1b6c0af4de2d35ed970aff4200dca22f818c9c4,Updates HyperVSecurityGroupsDriver icmpv6 protocol,MERGED,2016-02-11 22:22:21.000000000,2016-02-15 13:11:20.000000000,2016-02-15 13:11:20.000000000,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 8543}]","[{'number': 1, 'created': '2016-02-11 22:22:21.000000000', 'files': ['hyperv/neutron/security_groups_driver.py', 'hyperv/tests/unit/neutron/test_security_groups_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/f2e9cac91136fa0d4e87eb37c5fecdb63c0ff3ca', 'message': ""Updates HyperVSecurityGroupsDriver icmpv6 protocol\n\nOne of the changes to the Neutron Security Groups API is the\nrename of the security groups rules' 'icmpv6' protocol to\n'ipv6-icmp', leading to the creation of ACLs having unrecognised\nprotocols. This finally leads to failing to bind the security group\nrules to ports.\n\nChange-Id: If1b6c0af4de2d35ed970aff4200dca22f818c9c4\nCloses-Bug: #1544753\n""}]",0,279292,f2e9cac91136fa0d4e87eb37c5fecdb63c0ff3ca,8,3,1,8213,,,0,"Updates HyperVSecurityGroupsDriver icmpv6 protocol

One of the changes to the Neutron Security Groups API is the
rename of the security groups rules' 'icmpv6' protocol to
'ipv6-icmp', leading to the creation of ACLs having unrecognised
protocols. This finally leads to failing to bind the security group
rules to ports.

Change-Id: If1b6c0af4de2d35ed970aff4200dca22f818c9c4
Closes-Bug: #1544753
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/92/279292/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/neutron/security_groups_driver.py', 'hyperv/tests/unit/neutron/test_security_groups_driver.py']",2,f2e9cac91136fa0d4e87eb37c5fecdb63c0ff3ca,bug/1544753," sg_rule4 = self._create_sg_rule(self._acl('protocol', 'ipv6-icmp')) def test_stateful_ipv6_icmp(self): sg_rule = self._create_sg_rule(self._acl('protocol', 'ipv6-icmp'))"," sg_rule4 = self._create_sg_rule(self._acl('protocol', 'icmpv6')) def test_stateful_icmpv6(self): sg_rule = self._create_sg_rule(self._acl('protocol', 'icmpv6'))",5,5
openstack%2Fdragonflow~master~If23d0e68db47e494ae5c71106c2a3fa595d1a0c9,openstack/dragonflow,master,If23d0e68db47e494ae5c71106c2a3fa595d1a0c9,Add Neutron publisher configuration,MERGED,2016-02-10 17:05:49.000000000,2016-02-15 13:10:54.000000000,2016-02-15 13:10:54.000000000,"[{'_account_id': 3}, {'_account_id': 11343}, {'_account_id': 11364}, {'_account_id': 13070}, {'_account_id': 18668}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-10 17:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c4575b06c10cbd31e4de1b4fe2d58254d4eeec4e', 'message': 'Add Neutron publisher configuration\n\nFirst phase this will the publishers ip address to the Local controller configuration file\nIn the second phase we will add publisher  list to the dragonflow distributed database\n\nChange-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9\n'}, {'number': 2, 'created': '2016-02-11 08:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/3fe1077287715d091860dba16fce5ca521459e9d', 'message': 'Add Neutron publisher configuration\n\nFirst phase this will the publishers ip address to the Local controller configuration file\nIn the second phase we will add publisher  list to the dragonflow distributed database\n\nChange-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9\n'}, {'number': 3, 'created': '2016-02-12 08:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1537be0b1c8e1426f4c773733be7fb66d6197f82', 'message': 'Add Neutron publisher configuration\n\nFirst phase this will the publishers ip address to the Local controller configuration file\nIn the second phase we will add publisher  list to the dragonflow distributed database\n\nChange-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9\n'}, {'number': 4, 'created': '2016-02-14 19:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/5caba4ea55535cbaa3001587032db2c23748711c', 'message': 'Add Neutron publisher configuration\n\nFirst phase this will the publishers ip address to the Local controller configuration file\nIn the second phase we will add publisher  list to the dragonflow distributed database\n\nChange-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9\n'}, {'number': 5, 'created': '2016-02-15 12:13:56.000000000', 'files': ['devstack/plugin.sh', 'dragonflow/common/common_params.py', 'dragonflow/db/drivers/zookeeper_db_driver.py', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/66ba8f1870abfb5b48dfb034ea69dd8db90c5f46', 'message': 'Add Neutron publisher configuration\n\nFirst phase this will the publishers ip address to the Local controller configuration file\nIn the second phase we will add publisher  list to the dragonflow distributed database\n\nChange-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9\n'}]",10,278524,66ba8f1870abfb5b48dfb034ea69dd8db90c5f46,31,6,5,13070,,,0,"Add Neutron publisher configuration

First phase this will the publishers ip address to the Local controller configuration file
In the second phase we will add publisher  list to the dragonflow distributed database

Change-Id: If23d0e68db47e494ae5c71106c2a3fa595d1a0c9
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/24/278524/3 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/plugin.sh', 'dragonflow/common/common_params.py']",2,c4575b06c10cbd31e4de1b4fe2d58254d4eeec4e,pubsub," help=_(""Enable IPv6 DHCP by using DHCP agent"")), cfg.BoolOpt('use_df_pub_sub', default=True, help=_(""Enable use of Dragonflow built-in pub/sub"")), cfg.StrOpt('pub_sub_driver', default='zmq_pubsub_driver', help=_('Drivers to use for the Dragonflow pub/sub')), cfg.ListOpt('publishers_ips', default=['$local_ip'], help=_('List of the Neutron Server Publisher IPs.')), cfg.PortOpt('publisher_port', default=8866, help=_('Neutron Server Publishers Port'))"," help=_(""Enable IPv6 DHCP by using DHCP agent""))",18,2
openstack%2Fxstatic-angular-gettext~master~Ib6e42f616ecf79d5f701a08e433d5c0f638369dd,openstack/xstatic-angular-gettext,master,Ib6e42f616ecf79d5f701a08e433d5c0f638369dd,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:47:52.000000000,2016-02-15 13:09:31.000000000,2016-02-15 13:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:47:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-gettext/commit/23d2ce00f06fd0d6f3ae711a7c802639c5cf548f', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ib6e42f616ecf79d5f701a08e433d5c0f638369dd\n'}]",1,256854,23d2ce00f06fd0d6f3ae711a7c802639c5cf548f,10,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ib6e42f616ecf79d5f701a08e433d5c0f638369dd
",git fetch https://review.opendev.org/openstack/xstatic-angular-gettext refs/changes/54/256854/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,23d2ce00f06fd0d6f3ae711a7c802639c5cf548f,,,[tox:jenkins] downloadcache = ~/cache/pip,0,2
openstack%2Fxstatic-magic-search~master~Ia083124afaca6b4e5170ed63587fdf2ca9f99802,openstack/xstatic-magic-search,master,Ia083124afaca6b4e5170ed63587fdf2ca9f99802,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:49:30.000000000,2016-02-15 13:09:21.000000000,2016-02-15 13:09:21.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}, {'_account_id': 16352}]","[{'number': 1, 'created': '2015-12-11 22:49:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-magic-search/commit/080d3686964d720bad42c0be4c0c9d60bf8d50fa', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ia083124afaca6b4e5170ed63587fdf2ca9f99802\n'}]",0,256864,080d3686964d720bad42c0be4c0c9d60bf8d50fa,10,6,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ia083124afaca6b4e5170ed63587fdf2ca9f99802
",git fetch https://review.opendev.org/openstack/xstatic-magic-search refs/changes/64/256864/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,080d3686964d720bad42c0be4c0c9d60bf8d50fa,,,[tox:jenkins] downloadcache = ~/cache/pip,0,2
openstack%2Fxstatic-bootswatch~master~Ie79171825cec9c9a0b21bd9182380719dcebf405,openstack/xstatic-bootswatch,master,Ie79171825cec9c9a0b21bd9182380719dcebf405,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:48:42.000000000,2016-02-15 13:09:03.000000000,2016-02-15 13:09:03.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:48:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-bootswatch/commit/2c0a7a18f619b6da9d91b51c687bc8df15f625ac', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ie79171825cec9c9a0b21bd9182380719dcebf405\n'}]",0,256859,2c0a7a18f619b6da9d91b51c687bc8df15f625ac,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ie79171825cec9c9a0b21bd9182380719dcebf405
",git fetch https://review.opendev.org/openstack/xstatic-bootswatch refs/changes/59/256859/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2c0a7a18f619b6da9d91b51c687bc8df15f625ac,,,[tox:jenkins] downloadcache = ~/cache/pip,0,2
openstack%2Fxstatic-d3~master~I719051f9242d956cf47762e430fc9d8b0e16b573,openstack/xstatic-d3,master,I719051f9242d956cf47762e430fc9d8b0e16b573,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:48:48.000000000,2016-02-15 13:08:53.000000000,2016-02-15 13:08:53.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:48:48.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-d3/commit/de2298a4c445344ee98db5f0ecb7394922a0f19b', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I719051f9242d956cf47762e430fc9d8b0e16b573\n'}]",0,256860,de2298a4c445344ee98db5f0ecb7394922a0f19b,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I719051f9242d956cf47762e430fc9d8b0e16b573
",git fetch https://review.opendev.org/openstack/xstatic-d3 refs/changes/60/256860/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,de2298a4c445344ee98db5f0ecb7394922a0f19b,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-jsencrypt~master~I38b3b8f55d8af32e891da15ba755156a32cd7084,openstack/xstatic-jsencrypt,master,I38b3b8f55d8af32e891da15ba755156a32cd7084,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:49:23.000000000,2016-02-15 13:08:45.000000000,2016-02-15 13:08:45.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:49:23.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-jsencrypt/commit/633011365a69602aada5f419fc40fd50279e8884', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I38b3b8f55d8af32e891da15ba755156a32cd7084\n'}]",0,256863,633011365a69602aada5f419fc40fd50279e8884,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I38b3b8f55d8af32e891da15ba755156a32cd7084
",git fetch https://review.opendev.org/openstack/xstatic-jsencrypt refs/changes/63/256863/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,633011365a69602aada5f419fc40fd50279e8884,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-bootstrap-datepicker~master~I5e2190f0fa8393c65fad087093cde8bae22090ee,openstack/xstatic-bootstrap-datepicker,master,I5e2190f0fa8393c65fad087093cde8bae22090ee,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:48:19.000000000,2016-02-15 13:08:39.000000000,2016-02-15 13:08:39.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:48:19.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-bootstrap-datepicker/commit/afdafbbb4f1c34548754b19d71a8a124121857b7', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I5e2190f0fa8393c65fad087093cde8bae22090ee\n'}]",0,256856,afdafbbb4f1c34548754b19d71a8a124121857b7,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I5e2190f0fa8393c65fad087093cde8bae22090ee
",git fetch https://review.opendev.org/openstack/xstatic-bootstrap-datepicker refs/changes/56/256856/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,afdafbbb4f1c34548754b19d71a8a124121857b7,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-angular-fileupload~master~I1f39c6a7824dfafb5b4d1a03fe8415fa3534bdc1,openstack/xstatic-angular-fileupload,master,I1f39c6a7824dfafb5b4d1a03fe8415fa3534bdc1,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:47:39.000000000,2016-02-15 13:08:27.000000000,2016-02-15 13:08:27.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:47:39.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-fileupload/commit/8bd3bd19efc1df31fdb0d35379891ea93e3353f8', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I1f39c6a7824dfafb5b4d1a03fe8415fa3534bdc1\n'}]",0,256853,8bd3bd19efc1df31fdb0d35379891ea93e3353f8,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I1f39c6a7824dfafb5b4d1a03fe8415fa3534bdc1
",git fetch https://review.opendev.org/openstack/xstatic-angular-fileupload refs/changes/53/256853/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8bd3bd19efc1df31fdb0d35379891ea93e3353f8,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-angular-lrdragndrop~master~Iaa90867307001a2cc01c338428b088f113e33313,openstack/xstatic-angular-lrdragndrop,master,Iaa90867307001a2cc01c338428b088f113e33313,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:48:05.000000000,2016-02-15 13:08:18.000000000,2016-02-15 13:08:18.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:48:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-lrdragndrop/commit/880d542062d570e5074e78ffa2e371a7ea2d629c', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Iaa90867307001a2cc01c338428b088f113e33313\n'}]",0,256855,880d542062d570e5074e78ffa2e371a7ea2d629c,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Iaa90867307001a2cc01c338428b088f113e33313
",git fetch https://review.opendev.org/openstack/xstatic-angular-lrdragndrop refs/changes/55/256855/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,880d542062d570e5074e78ffa2e371a7ea2d629c,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-angular-bootstrap~master~I1252e0d79f2d71367a23f72e0d859005300af716,openstack/xstatic-angular-bootstrap,master,I1252e0d79f2d71367a23f72e0d859005300af716,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:47:26.000000000,2016-02-15 13:08:12.000000000,2016-02-15 13:08:12.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:47:26.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-angular-bootstrap/commit/8648295573aa0fd887a36684fde84c9c504a4b1e', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I1252e0d79f2d71367a23f72e0d859005300af716\n'}]",0,256852,8648295573aa0fd887a36684fde84c9c504a4b1e,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I1252e0d79f2d71367a23f72e0d859005300af716
",git fetch https://review.opendev.org/openstack/xstatic-angular-bootstrap refs/changes/52/256852/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8648295573aa0fd887a36684fde84c9c504a4b1e,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-bootstrap-scss~master~I014bd6059d87181d60be453d666b5bea82ca3439,openstack/xstatic-bootstrap-scss,master,I014bd6059d87181d60be453d666b5bea82ca3439,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:48:27.000000000,2016-02-15 13:07:58.000000000,2016-02-15 13:07:58.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:48:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-bootstrap-scss/commit/8f92bdebbc1e24903a98e0f1cf9921c9eda1a24f', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I014bd6059d87181d60be453d666b5bea82ca3439\n'}]",0,256857,8f92bdebbc1e24903a98e0f1cf9921c9eda1a24f,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I014bd6059d87181d60be453d666b5bea82ca3439
",git fetch https://review.opendev.org/openstack/xstatic-bootstrap-scss refs/changes/57/256857/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8f92bdebbc1e24903a98e0f1cf9921c9eda1a24f,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-jasmine~master~I1cf1fceee5ae891d560cb5f345a1cbdfa7646c8d,openstack/xstatic-jasmine,master,I1cf1fceee5ae891d560cb5f345a1cbdfa7646c8d,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:49:10.000000000,2016-02-15 13:07:48.000000000,2016-02-15 13:07:48.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:49:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-jasmine/commit/f24999b19017e55d2740fbb046908c3154c06ea8', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I1cf1fceee5ae891d560cb5f345a1cbdfa7646c8d\n'}]",0,256862,f24999b19017e55d2740fbb046908c3154c06ea8,8,4,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I1cf1fceee5ae891d560cb5f345a1cbdfa7646c8d
",git fetch https://review.opendev.org/openstack/xstatic-jasmine refs/changes/62/256862/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f24999b19017e55d2740fbb046908c3154c06ea8,,,[tox:jenkins] downloadcache = ~/cache/pip,0,2
openstack%2Fxstatic-font-awesome~master~I61d45342736d9607aac033340536e4ecec384d6a,openstack/xstatic-font-awesome,master,I61d45342736d9607aac033340536e4ecec384d6a,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:49:04.000000000,2016-02-15 13:07:41.000000000,2016-02-15 13:07:41.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:49:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-font-awesome/commit/40f071220b6b4c13d2f4c6fd2d264799d5b1a58f', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I61d45342736d9607aac033340536e4ecec384d6a\n'}]",0,256861,40f071220b6b4c13d2f4c6fd2d264799d5b1a58f,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I61d45342736d9607aac033340536e4ecec384d6a
",git fetch https://review.opendev.org/openstack/xstatic-font-awesome refs/changes/61/256861/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,40f071220b6b4c13d2f4c6fd2d264799d5b1a58f,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-rickshaw~master~I67fa6e487e185294876d56b67ade892cd4e49590,openstack/xstatic-rickshaw,master,I67fa6e487e185294876d56b67ade892cd4e49590,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:49:40.000000000,2016-02-15 13:07:34.000000000,2016-02-15 13:07:34.000000000,"[{'_account_id': 3}, {'_account_id': 8648}, {'_account_id': 12826}, {'_account_id': 14867}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:49:40.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-rickshaw/commit/ef5a81446bb639d3e95dfc62d37eb55f4c341d6b', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I67fa6e487e185294876d56b67ade892cd4e49590\n'}]",0,256866,ef5a81446bb639d3e95dfc62d37eb55f4c341d6b,9,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I67fa6e487e185294876d56b67ade892cd4e49590
",git fetch https://review.opendev.org/openstack/xstatic-rickshaw refs/changes/66/256866/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ef5a81446bb639d3e95dfc62d37eb55f4c341d6b,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fxstatic-angular~master~I321fdc7c3b1786f5d3e108404e31fa9a54c0b914,openstack/xstatic-angular,master,I321fdc7c3b1786f5d3e108404e31fa9a54c0b914,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:47:02.000000000,2016-02-15 13:07:17.000000000,2016-02-15 13:07:17.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 8648}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:47:02.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/xstatic-angular/commit/5a9e413162cdbdacbe7dce0705f83a7c644c21eb', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I321fdc7c3b1786f5d3e108404e31fa9a54c0b914\n'}]",0,256849,5a9e413162cdbdacbe7dce0705f83a7c644c21eb,8,4,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I321fdc7c3b1786f5d3e108404e31fa9a54c0b914
",git fetch https://review.opendev.org/openstack/xstatic-angular refs/changes/49/256849/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,5a9e413162cdbdacbe7dce0705f83a7c644c21eb,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Ftripleo-ci~master~I794fad76744d2a9a63122a3391c33830220b8ce6,openstack/tripleo-ci,master,I794fad76744d2a9a63122a3391c33830220b8ce6,Wait for pacemaker cluster to settle,MERGED,2016-02-13 19:42:02.000000000,2016-02-15 13:03:57.000000000,2016-02-15 13:03:48.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 6796}, {'_account_id': 8449}, {'_account_id': 10873}, {'_account_id': 12715}]","[{'number': 1, 'created': '2016-02-13 19:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/dc697634207bfcfe7bad77483fc7a294a0248a15', 'message': 'Wait for pacemaker cluster to settle\n\nWhen using pacemaker in the HA job, there is no guarantee that all the\nresources are started and running and the cluster is settled before we\nrun the overcloud ping test. This can lead to various errors, a common\none being 503 Service Unavailable when we try to create the tenant-stack\nin Heat during the pingtest, since often Heat is one of the last\nresources to start in the cluster.\n\nChange-Id: I794fad76744d2a9a63122a3391c33830220b8ce6\nPartial-Bug: #1545318\n'}, {'number': 2, 'created': '2016-02-13 19:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f0f1a105ba773ccbbb15b27ecf1362a784fc12cb', 'message': 'Wait for pacemaker cluster to settle\n\nWhen using pacemaker in the HA job, there is no guarantee that all the\nresources are started and running and the cluster is settled before we\nrun the overcloud ping test. This can lead to various errors, a common\none being 503 Service Unavailable when we try to create the tenant-stack\nin Heat during the pingtest, since often Heat is one of the last\nresources to start in the cluster.\n\nChange-Id: I794fad76744d2a9a63122a3391c33830220b8ce6\nPartial-Bug: #1545318\n'}, {'number': 3, 'created': '2016-02-13 22:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fcc4fce3dc153437c2e186eb51df08c38f9b8a89', 'message': 'Wait for pacemaker cluster to settle\n\nWhen using pacemaker in the HA job, there is no guarantee that all the\nresources are started and running and the cluster is settled before we\nrun the overcloud ping test. This can lead to various errors, a common\none being 503 Service Unavailable when we try to create the tenant-stack\nin Heat during the pingtest, since often Heat is one of the last\nresources to start in the cluster.\n\nChange-Id: I794fad76744d2a9a63122a3391c33830220b8ce6\nPartial-Bug: #1545318\n'}, {'number': 4, 'created': '2016-02-14 13:43:15.000000000', 'files': ['toci_instack.sh', 'toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7d5091d581b68d4c73a7628c8173504ce94cd97d', 'message': 'Wait for pacemaker cluster to settle\n\nWhen using pacemaker in the HA job, there is no guarantee that all the\nresources are started and running and the cluster is settled before we\nrun the overcloud ping test. This can lead to various errors, a common\none being 503 Service Unavailable when we try to create the tenant-stack\nin Heat during the pingtest, since often Heat is one of the last\nresources to start in the cluster.\n\nChange-Id: I794fad76744d2a9a63122a3391c33830220b8ce6\nPartial-Bug: #1545318\n'}]",1,279894,7d5091d581b68d4c73a7628c8173504ce94cd97d,19,6,4,7144,,,0,"Wait for pacemaker cluster to settle

When using pacemaker in the HA job, there is no guarantee that all the
resources are started and running and the cluster is settled before we
run the overcloud ping test. This can lead to various errors, a common
one being 503 Service Unavailable when we try to create the tenant-stack
in Heat during the pingtest, since often Heat is one of the last
resources to start in the cluster.

Change-Id: I794fad76744d2a9a63122a3391c33830220b8ce6
Partial-Bug: #1545318
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/94/279894/2 && git format-patch -1 --stdout FETCH_HEAD,"['toci_instack.sh', 'toci_gate_test.sh']",2,dc697634207bfcfe7bad77483fc7a294a0248a15,bug/1545318, PACEMAKER=1,,10,0
openstack%2Fopenstacksdk~master~Ia2f65f566e6b5a03e865ce26122cd567712a08f1,openstack/openstacksdk,master,Ia2f65f566e6b5a03e865ce26122cd567712a08f1,Basic resource.prop for ID attributes (image),MERGED,2016-02-12 15:03:42.000000000,2016-02-15 12:54:56.000000000,2016-02-15 12:54:56.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2016-02-12 15:03:42.000000000', 'files': ['openstack/image/v1/_proxy.py', 'openstack/image/v2/image.py', 'openstack/tests/unit/image/v1/test_image.py', 'openstack/image/v2/_proxy.py', 'openstack/image/v1/image.py', 'openstack/tests/unit/image/v2/test_image.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e201e460dfa3fbc9a3f0b8b17d11a98ff754f68e', 'message': 'Basic resource.prop for ID attributes (image)\n\nThis patch set updates all image resource objects to use basic\nproperties for ID attributes. In particular, the following changes\nwere made:\n  - Use basic *_id resource.prop for ID attributes\n  - Clarify documentation for ID attributes\n\nChange-Id: Ia2f65f566e6b5a03e865ce26122cd567712a08f1\nPartial-Bug: #1461200\n'}]",0,279581,e201e460dfa3fbc9a3f0b8b17d11a98ff754f68e,11,2,1,8410,,,0,"Basic resource.prop for ID attributes (image)

This patch set updates all image resource objects to use basic
properties for ID attributes. In particular, the following changes
were made:
  - Use basic *_id resource.prop for ID attributes
  - Clarify documentation for ID attributes

Change-Id: Ia2f65f566e6b5a03e865ce26122cd567712a08f1
Partial-Bug: #1461200
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/81/279581/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/image/v1/_proxy.py', 'openstack/image/v2/image.py', 'openstack/tests/unit/image/v1/test_image.py', 'openstack/image/v2/_proxy.py', 'openstack/image/v1/image.py', 'openstack/tests/unit/image/v2/test_image.py']",6,e201e460dfa3fbc9a3f0b8b17d11a98ff754f68e,bug/1461200," self.assertEqual(EXAMPLE['owner'], sot.owner_id)"," self.assertEqual(EXAMPLE['owner'], sot.owner)",9,9
openstack%2Fsahara~master~Icb0e88b2aadf278eb621f4b5075223dfe099f2a1,openstack/sahara,master,Icb0e88b2aadf278eb621f4b5075223dfe099f2a1,Distributed periodic tasks implementation,MERGED,2016-01-20 15:35:33.000000000,2016-02-15 12:46:58.000000000,2016-02-15 12:46:58.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2016-01-20 15:35:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ffd4082a653f9d255aa887c2b3a661bed225389a', 'message': 'Distributed periodic tasks implementation\n\nPartially-implements bp: distributed-periodics\n\nChange-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1\n'}, {'number': 2, 'created': '2016-02-04 14:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/459f6569968c910db3e9f8b7a1a0d8ec04749fa1', 'message': 'Distributed periodic tasks implementation\n\nPartially-implements bp: distributed-periodics\n\nChange-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1\n'}, {'number': 3, 'created': '2016-02-04 15:01:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8a3e8262be67815de4bbf7816d732ad735bd0079', 'message': 'Distributed periodic tasks implementation\n\nPartially-implements bp: distributed-periodics\n\nChange-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1\n'}, {'number': 4, 'created': '2016-02-04 19:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a2353ae0778fc065309a685ae6dcf2e62a02bbe0', 'message': 'Distributed periodic tasks implementation\n\nPeriodic tasks now can be launched in\ndistributed mode if coordination backend\nis provided.\n\nPartially-implements bp: distributed-periodics\n\nChange-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1\n'}, {'number': 5, 'created': '2016-02-08 16:41:01.000000000', 'files': ['sahara/service/periodic.py', 'sahara/service/coordinator.py', 'requirements.txt', 'sahara/service/edp/job_manager.py', 'sahara/tests/unit/service/test_periodic.py', 'sahara/config.py', 'sahara/tests/unit/service/test_coordinator.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/6610c256dc3f01eb91e19ff57e9986113f2a04e6', 'message': 'Distributed periodic tasks implementation\n\nPeriodic tasks now can be launched in\ndistributed mode if coordination backend\nis provided.\n\nPartially-implements bp: distributed-periodics\n\nChange-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1\n'}]",14,270255,6610c256dc3f01eb91e19ff57e9986113f2a04e6,27,7,5,12039,,,0,"Distributed periodic tasks implementation

Periodic tasks now can be launched in
distributed mode if coordination backend
is provided.

Partially-implements bp: distributed-periodics

Change-Id: Icb0e88b2aadf278eb621f4b5075223dfe099f2a1
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/270255/5 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/coordinator.py', 'sahara/service/periodic.py', 'requirements.txt', 'sahara/service/edp/job_manager.py']",4,ffd4082a653f9d255aa887c2b3a661bed225389a,bp/distributed-periodics,"def update_job_status(job_execution_id): try: get_job_status(job_execution_id) except Exception as e: LOG.error(_LE(""Error during update job execution {job}: {error}"") .format(job=job_execution_id, error=e)) update_job_status(je.id)"," try: get_job_status(je.id) except Exception as e: LOG.error(_LE(""Error during update job execution {job}: {error}"") .format(job=je.id, error=e))",136,8
openstack%2Ftripleo-common~master~Iad012b0f1e48b9375484d1087e26bfb47d0affbc,openstack/tripleo-common,master,Iad012b0f1e48b9375484d1087e26bfb47d0affbc,Create basic API layout,ABANDONED,2015-12-10 11:15:03.000000000,2016-02-15 12:46:26.000000000,,"[{'_account_id': 3}, {'_account_id': 7065}, {'_account_id': 7386}, {'_account_id': 9712}]","[{'number': 1, 'created': '2015-12-10 11:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/cce9e472e05764052d53f3f3f430bfc2f42c9888', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 2, 'created': '2015-12-10 12:32:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7a512ce9d8f33c6255adc5c002af04ae3a6fe520', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 3, 'created': '2015-12-10 13:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8a26baaf7349d34b51b1e3962b08b93e0e9378fd', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 4, 'created': '2015-12-10 16:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/af07c703ba17e6ffff0c92b46f32b2a1491ca461', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 5, 'created': '2015-12-10 16:24:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5ac7103e723f82de50ba44a14f4ce5fb32db68e5', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 6, 'created': '2015-12-10 18:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/dca9ce0cdcf37a150d2992c7e65f3320b4d8b3d4', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 7, 'created': '2015-12-11 20:39:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/78aff5f032e3d2ff7d80d3f6e5eabe779952f9c9', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 8, 'created': '2015-12-17 09:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/af1085b5f84038f95bc7baa9dda89777d20d0e16', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 9, 'created': '2015-12-17 12:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8be62de07e5cc03acda1c722d5f5c8a7586b9d96', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 10, 'created': '2015-12-18 08:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2ace12f2506475ab07fd08e5cdb88682cb00f9e3', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 11, 'created': '2015-12-18 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7298b80b6002569d327a324f25582f9273e16305', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 12, 'created': '2015-12-18 17:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d1c20d14c01995db7b8909678ee747be51106d4e', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 13, 'created': '2015-12-21 08:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/baf449920401a0d225a230e2b97f9009048d6363', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 14, 'created': '2015-12-21 09:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f7858f8879935fa837a501f86937b4ba51be6947', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 15, 'created': '2015-12-22 12:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1a9835c925a316ddc37272cdd7a7511025fb38f8', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 16, 'created': '2016-01-06 15:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f917dab72f8d52a3b50cfcc8644bf8a2392c7c55', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}, {'number': 17, 'created': '2016-01-08 09:15:24.000000000', 'files': ['tripleo_common/conf.py', 'tripleo_common/utils/clients.py', 'tripleo_common/tests/api/__init__.py', 'tripleo_common/api/__init__.py', 'README.rst', 'etc/tripleo/tripleo.conf.sample', 'tripleo_common/tests/api/test_main.py', 'tripleo_common/core/exception.py', 'tripleo_common/api/utils.py', 'requirements.txt', 'tripleo_common/api/main.py', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5c081bb0aab23799a74d26d6564c319eb88c7fe4', 'message': ""Create basic API layout\n\nThis patch add's the boilerplate required for a Flask API with\nCORS support. Following patches will implement V1 of the API.\n\nCo-Authored-By: Ryan Brady <rbrady@redhat.com>\nCo-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>\nChange-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc\n""}]",0,255798,5c081bb0aab23799a74d26d6564c319eb88c7fe4,54,4,17,9712,,,0,"Create basic API layout

This patch add's the boilerplate required for a Flask API with
CORS support. Following patches will implement V1 of the API.

Co-Authored-By: Ryan Brady <rbrady@redhat.com>
Co-Authored-By: Tzu-Mainn Chen <tzumainn@redhat.com>
Change-Id: Iad012b0f1e48b9375484d1087e26bfb47d0affbc
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/98/255798/9 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/api/utils.py', 'requirements.txt', 'tripleo_common/utils/clients.py', 'tripleo_common/api/__init__.py', 'README.rst', 'tripleo_common/api/main.py', 'etc/tripleo/tripleo.conf.sample', 'setup.cfg', 'tox.ini']",9,cce9e472e05764052d53f3f3f430bfc2f42c9888,add-initial-swift-patch35, [testenv:genconfig] commands = oslo-config-generator --output-file etc/tripleo/tripleo.conf.sample \ --namespace tripleo_common.conf \ --namespace tripleo_common.clients \ --namespace keystonemiddleware.auth_token \ --namespace oslo.concurrency \ --namespace oslo.db \ --namespace oslo.log \ --namespace oslo.messaging \ --namespace oslo.middleware.cors \ --namespace oslo.policy \ --namespace oslo.service.periodic_task \ --namespace oslo.service.service,,921,0
openstack%2Ftripleo-common~master~I93e779bde0d54ffc3c29932866889a50e8917bea,openstack/tripleo-common,master,I93e779bde0d54ffc3c29932866889a50e8917bea,[WIP] Add the Plan deploy endpoint to start a Heat deploy,ABANDONED,2015-12-11 12:21:22.000000000,2016-02-15 12:46:23.000000000,,"[{'_account_id': 3}, {'_account_id': 9712}]","[{'number': 1, 'created': '2015-12-11 12:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6158eb8b7138be669446a2d7ed956bafdc6381fe', 'message': '[WIP] Add the /plans/<name>/deploy endpoint to start a Heat deploy\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 2, 'created': '2015-12-11 15:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e0c330b9f86da98fb517dde6e76c810dfbd5f0b8', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 3, 'created': '2015-12-14 08:55:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5ea00e1d387e37eab1279654fda1a7170f566cda', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 4, 'created': '2015-12-15 11:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fdd122aafc7dec3bb00ddb64804ba2704d43304e', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 5, 'created': '2015-12-17 09:47:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a2fa9632c3440bddeb995b92b4b4c55dce661478', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 6, 'created': '2015-12-17 12:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1c91d4d275d8ea44dd07e70fd9d3a1595ae874e0', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 7, 'created': '2015-12-17 14:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/93bcbb0307b7f3786b994a76e70285b01bacbbbd', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 8, 'created': '2015-12-17 14:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3bbfbc778f5aca333b7435a9a3808b1a99145788', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 9, 'created': '2015-12-18 08:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d7f88e6868175e58eee62411995975864ce8ece8', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 10, 'created': '2015-12-18 10:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b7a3a2fceb3f3cac32e4158b1beafc317d119793', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 11, 'created': '2015-12-18 12:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4dacebe68ec5b8a88db9675e27a1e8c85050ae2d', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 12, 'created': '2015-12-18 12:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/92112bf12c5541180c3b0c4f75ece410d3e0c4a4', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 13, 'created': '2015-12-18 17:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0d04927184149294c2c1a551004199ff8cdacef6', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 14, 'created': '2015-12-21 08:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/54e7551145e01fff90693c2edf546f434f674b1c', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 15, 'created': '2015-12-21 09:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/442d85caab2ce175f49fd1877349d24f5258a617', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 16, 'created': '2015-12-22 12:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c03f1e6f736397497650194400bad908d53babd5', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 17, 'created': '2015-12-22 12:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b8a3edf77f071d0210d9625a6e7898f2474dda03', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 18, 'created': '2016-01-06 15:05:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e4aa1556c5c9289d34961e03b2b692564b90bd55', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}, {'number': 19, 'created': '2016-01-08 09:15:24.000000000', 'files': ['tripleo_common/api/utils.py', 'tripleo_common/utils/templates.py', 'tripleo_common/deploy.py', 'tripleo_common/core/plan_storage.py', 'tripleo_common/core/plan.py', 'tripleo_common/api/v1.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2a5c08c950ab82af5c3b78ad1d4d261c0b1810f1', 'message': '[WIP] Add the Plan deploy endpoint to start a Heat deploy\n\nThis code is the worst. It is aiming to be a proof of concept,\nafter we have some success it will need re-factoring.\n\nChange-Id: I93e779bde0d54ffc3c29932866889a50e8917bea\n'}]",0,256384,2a5c08c950ab82af5c3b78ad1d4d261c0b1810f1,50,2,19,9712,,,0,"[WIP] Add the Plan deploy endpoint to start a Heat deploy

This code is the worst. It is aiming to be a proof of concept,
after we have some success it will need re-factoring.

Change-Id: I93e779bde0d54ffc3c29932866889a50e8917bea
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/84/256384/17 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/api/v1.py'],1,6158eb8b7138be669446a2d7ed956bafdc6381fe,add-initial-swift-patch35,"from tripleo_common import deployfrom tripleo_common.core import templates @v1.route('/plans/<name>/deploy', methods=[""PUT""]) def api_play_deploy(name): utils.check_auth(flask.request) plan_manager = _plan_manager() plan = plan_manager.get_plan(name) dm = deploy.DeployManager(clients.heatclient(), name) template, environment, files = templates.process_plan_data(plan.files) dm.deploy(template, environment, files) return '', 202",,18,0
openstack%2Fpython-tripleoclient~master~Ibede5b9a2afb790a61558014689bbba6581eca58,openstack/python-tripleoclient,master,Ibede5b9a2afb790a61558014689bbba6581eca58,Update tripleoclient to use the common deploy logic,ABANDONED,2015-10-21 07:59:49.000000000,2016-02-15 12:46:20.000000000,,"[{'_account_id': 3}, {'_account_id': 9712}]","[{'number': 1, 'created': '2015-10-21 07:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/206d4a66f26b025aaad73ab98d1513676418ba9c', 'message': '[WIP] Update tripleoclient to use the common deploy logic\n\nChange-Id: Ibede5b9a2afb790a61558014689bbba6581eca58\nDepends-On: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 2, 'created': '2015-11-09 15:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/88e6fddd94c5fb6dcae0109ec81e18a90049db2f', 'message': '[WIP] Update tripleoclient to use the common deploy logic\n\nChange-Id: Ibede5b9a2afb790a61558014689bbba6581eca58\nDepends-On: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}, {'number': 3, 'created': '2015-11-16 16:59:10.000000000', 'files': ['tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/33609bb31e5a1b7f196de9da32cec11a01b7a5a0', 'message': 'Update tripleoclient to use the common deploy logic\n\nChange-Id: Ibede5b9a2afb790a61558014689bbba6581eca58\nDepends-On: Idadb05d01a7e2353dd812e8461c5641e4dafdae5\n'}]",0,237920,33609bb31e5a1b7f196de9da32cec11a01b7a5a0,13,2,3,9712,,,0,"Update tripleoclient to use the common deploy logic

Change-Id: Ibede5b9a2afb790a61558014689bbba6581eca58
Depends-On: Idadb05d01a7e2353dd812e8461c5641e4dafdae5
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/20/237920/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/overcloud_deploy.py'],1,206d4a66f26b025aaad73ab98d1513676418ba9c,237920,"from tripleo_common import deploy def _heat_deploy(self, stack_name, template_path, environments, timeout): deploy_manager = deploy.FileDeployManager(self.heatclient, stack_name) deploy_args = { 'template_path': template_path, 'environment_files': environments, deploy_args['timeout_mins'] = timeout return deploy_manager.deploy(**deploy_args) self._heat_deploy(parsed_args.stack, overcloud_yaml,","from heatclient.common import template_utilsfrom tripleo_common import update def _heat_deploy(self, stack, stack_name, template_path, parameters, environments, timeout): self.log.debug(""Processing environment files"") env_files, env = ( template_utils.process_multiple_environments_and_files( environments)) if stack: update.add_breakpoints_cleanup_into_env(env) self.log.debug(""Getting template contents"") template_files, template = template_utils.get_template_contents( template_path) files = dict(list(template_files.items()) + list(env_files.items())) clients = self.app.client_manager orchestration_client = clients.tripleoclient.orchestration() self.log.debug(""Deploying stack: %s"", stack_name) self.log.debug(""Deploying template: %s"", template) self.log.debug(""Deploying parameters: %s"", parameters) self.log.debug(""Deploying environment: %s"", env) self.log.debug(""Deploying files: %s"", files) stack_args = { 'stack_name': stack_name, 'template': template, 'environment': env, 'files': files stack_args['timeout_mins'] = timeout if stack is None: self.log.info(""Performing Heat stack create"") orchestration_client.stacks.create(**stack_args) else: self.log.info(""Performing Heat stack update"") # Make sure existing parameters for stack are reused stack_args['existing'] = 'true' orchestration_client.stacks.update(stack.id, **stack_args) create_result = utils.wait_for_stack_ready( orchestration_client, stack_name) if not create_result: if stack is None: raise Exception(""Heat Stack create failed."") else: raise Exception(""Heat Stack update failed."") self._heat_deploy(stack, parsed_args.stack, overcloud_yaml, parameters,",9,48
openstack%2Fdiskimage-builder~master~I09664d7c33c3d08c3d93166ad83f86e0751622bc,openstack/diskimage-builder,master,I09664d7c33c3d08c3d93166ad83f86e0751622bc,Install additional packages in debian-minimal,ABANDONED,2016-02-08 15:26:07.000000000,2016-02-15 12:32:16.000000000,,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6476}, {'_account_id': 6488}, {'_account_id': 7118}, {'_account_id': 10035}, {'_account_id': 13505}]","[{'number': 1, 'created': '2016-02-08 15:26:07.000000000', 'files': ['elements/debian-minimal/element-deps', 'elements/debian-minimal/package-installs.yaml', 'elements/debian/package-installs.yaml'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/cd36699352014376b7bc287603c288c53af7c587', 'message': 'Install additional packages in debian-minimal\n\n* Move curl and openssh-server from debian to debian-minimal\n* Add ifupdown package to debian-minimal\nopenssh-server and ifupdown make debian-minimal compatible with\nsimple-init element.\ncurl is required for I851cb47e844a72a430b578dd63d8b230ee6e3ed9\n\nChange-Id: I09664d7c33c3d08c3d93166ad83f86e0751622bc\n'}]",0,277445,cd36699352014376b7bc287603c288c53af7c587,9,11,1,13505,,,0,"Install additional packages in debian-minimal

* Move curl and openssh-server from debian to debian-minimal
* Add ifupdown package to debian-minimal
openssh-server and ifupdown make debian-minimal compatible with
simple-init element.
curl is required for I851cb47e844a72a430b578dd63d8b230ee6e3ed9

Change-Id: I09664d7c33c3d08c3d93166ad83f86e0751622bc
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/45/277445/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/debian-minimal/element-deps', 'elements/debian-minimal/package-installs.yaml', 'elements/debian/package-installs.yaml']",3,cd36699352014376b7bc287603c288c53af7c587,,,openssh-server:curl:,4,2
openstack%2Fdesignate-dashboard~master~I80f07a4aab5466025e729bf50cebde79c46511b9,openstack/designate-dashboard,master,I80f07a4aab5466025e729bf50cebde79c46511b9,Imported Translations from Zanata,MERGED,2016-02-11 07:34:01.000000000,2016-02-15 12:28:58.000000000,2016-02-15 12:28:58.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}]","[{'number': 1, 'created': '2016-02-11 07:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/e9224ba5affe3f8b8ae2049657d5aefbe22359cb', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I80f07a4aab5466025e729bf50cebde79c46511b9\n'}, {'number': 2, 'created': '2016-02-13 06:16:49.000000000', 'files': ['designatedashboard/locale/ja/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/designate-dashboard/commit/e5eba221a985bd9459d3604fef8c61b34eefbcbb', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I80f07a4aab5466025e729bf50cebde79c46511b9\n'}]",0,278891,e5eba221a985bd9459d3604fef8c61b34eefbcbb,9,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I80f07a4aab5466025e729bf50cebde79c46511b9
",git fetch https://review.opendev.org/openstack/designate-dashboard refs/changes/91/278891/2 && git format-patch -1 --stdout FETCH_HEAD,['designatedashboard/locale/ja/LC_MESSAGES/django.po'],1,e9224ba5affe3f8b8ae2049657d5aefbe22359cb,zanata/translations,"# KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>, 2016. #zanata""Project-Id-Version: designate-dashboard 1.0.0.dev38\n""""POT-Creation-Date: 2015-07-29 06:41+0000\n""""PO-Revision-Date: 2016-02-08 02:40+0000\n"" ""Last-Translator: KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>\n""msgstr ""ドメイン %(name)s が作成されました。""msgstr ""ドメイン %(name)s が更新されました。""msgstr ""ドメインレコード %(name)s が作成されました。""msgstr ""ドメインレコード %(name)s が更新されました。""""有効なホスト名を入力してください。ホスト名は、文字と数字で 63 文字以内で設定"" ""してください。""msgstr ""選択可能な現在使用中の Floating IP がありません。""","# Shu Muto <shu-mutou@rf.jp.nec.com>, 2015. #zanata""Project-Id-Version: designate-dashboard 2.0.0.0b2.dev12\n""""POT-Creation-Date: 2016-01-08 20:53+0000\n""""PO-Revision-Date: 2015-11-02 08:39+0000\n"" ""Last-Translator: Shu Muto <shu-mutou@rf.jp.nec.com>\n""msgstr ""ドメイン %(name)s は作成されました。""msgstr ""ドメイン %(name)s は更新されました。""msgstr ""ドメインレコード %(name)s は作成されました。""msgstr ""ドメインレコード %(name)s は更新されました。""""有効なホスト名を入力してください。ホスト名は、文字と数字で63文字以内で設定し"" ""てください。""msgstr ""選択可能な現在使用中のフローティングIPはありません。""",12,12
openstack%2Fvitrage~master~Ie6c5a91a016fabe84ee78104e49f120929e98860,openstack/vitrage,master,Ie6c5a91a016fabe84ee78104e49f120929e98860,fix get topology parameters,MERGED,2016-02-15 12:19:49.000000000,2016-02-15 12:28:52.000000000,2016-02-15 12:28:52.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-02-15 12:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/7628ed7c310aaabc4177f55d8251aaf0288e9da3', 'message': 'fix get topology parameters\n\nChange-Id: Ie6c5a91a016fabe84ee78104e49f120929e98860\n'}, {'number': 2, 'created': '2016-02-15 12:24:44.000000000', 'files': ['vitrage/entity_graph/api_handler/service.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/9ad9385b27e8c6bf456030fd128951dd16328cdc', 'message': 'fix get topology parameters\n\nfix stop add parameter\n\nChange-Id: Ie6c5a91a016fabe84ee78104e49f120929e98860\n'}]",0,280186,9ad9385b27e8c6bf456030fd128951dd16328cdc,7,2,2,19134,,,0,"fix get topology parameters

fix stop add parameter

Change-Id: Ie6c5a91a016fabe84ee78104e49f120929e98860
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/86/280186/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/api_handler/service.py'],1,7628ed7c310aaabc4177f55d8251aaf0288e9da3,bp/topology-api," def get_topology(self, ctx, graph_type, depth, query, root):"," def get_topology(self, ctx, arg):",1,1
openstack%2Fha-guide~master~Ifc366945fb32afdf2e90cff4aacc25a295eeece0,openstack/ha-guide,master,Ifc366945fb32afdf2e90cff4aacc25a295eeece0,Build Japanese HA Guide as draft,MERGED,2016-02-15 06:15:54.000000000,2016-02-15 12:24:44.000000000,2016-02-15 12:24:44.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-15 06:15:54.000000000', 'files': ['doc-tools-check-languages.conf'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/0505c1db660c47967292a95070044a14c6f819bc', 'message': 'Build Japanese HA Guide as draft\n\nChange-Id: Ifc366945fb32afdf2e90cff4aacc25a295eeece0\n'}]",0,280076,0505c1db660c47967292a95070044a14c6f819bc,8,3,1,10497,,,0,"Build Japanese HA Guide as draft

Change-Id: Ifc366945fb32afdf2e90cff4aacc25a295eeece0
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/76/280076/1 && git format-patch -1 --stdout FETCH_HEAD,['doc-tools-check-languages.conf'],1,0505c1db660c47967292a95070044a14c6f819bc,i18n," [""ja""]=""ha-guide"" [""ja""]=""ha-guide"""," # No translations currently # Example how to enable: #[""ja""]=""ha-guide"" # No translations currently # Example how to enable: #[""ja""]=""ha-guide""",2,6
openstack%2Fpython-fuelclient~master~Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9,openstack/python-fuelclient,master,Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9,Basic VIP management commands added to Nailgun CLI v2,MERGED,2016-02-09 00:39:54.000000000,2016-02-15 12:23:23.000000000,2016-02-15 11:20:06.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}, {'_account_id': 19158}]","[{'number': 1, 'created': '2016-02-09 00:39:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/90b7d3c9220b82ed9bc5cc2d17d4897dab51a979', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip download --env 1 --ip 1 --file firstvip.yaml\nfuel vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 2, 'created': '2016-02-09 13:55:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/87e6d5f985b4c1cd8d493f68bd517815cff30a3d', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 3, 'created': '2016-02-09 17:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/a94701986744b456f1952b17e755a7685c13a173', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 4, 'created': '2016-02-09 17:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/17b8537b11f55a501900db15dd8931c46e8e3ce7', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 5, 'created': '2016-02-09 23:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/3fd3ef6d939a7cfad0f661157ef1a546326bb795', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 6, 'created': '2016-02-09 23:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/f13a1528987c63fdbc7dec069ff4bd2f3c2369a2', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 7, 'created': '2016-02-09 23:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/2e144ef3bb4916728271a52907932cf626f04b9c', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 8, 'created': '2016-02-10 10:30:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/90785c81f1014f6f53bc9f405da2fd22c0023cf7', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 9, 'created': '2016-02-10 10:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/1da389e57a1919ff77ca3cb0cc6e34e0ba34462a', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}, {'number': 10, 'created': '2016-02-15 11:01:42.000000000', 'files': ['fuelclient/commands/vip.py', 'fuelclient/v1/__init__.py', 'fuelclient/v1/vip.py', 'fuelclient/tests/unit/v2/cli/test_vip.py', 'fuelclient/cli/actions/vip.py', 'setup.cfg', 'fuelclient/__init__.py', 'fuelclient/tests/unit/v2/lib/test_vip.py'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/c45bd4ebb96b7fff91a00e6e8336bcf2053d3386', 'message': 'Basic VIP management commands added to Nailgun CLI v2\n\nNow Naigun CLI v2 supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml\nfuel2 vip upload --env 1 --file ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9\n'}]",24,277636,c45bd4ebb96b7fff91a00e6e8336bcf2053d3386,72,10,10,19158,,,0,"Basic VIP management commands added to Nailgun CLI v2

Now Naigun CLI v2 supports VIP configuration management commands
that allow to download and upload VIP configuration:

fuel2 vip download --env 1 --ip-address-id 1 --file firstvip.yaml
fuel2 vip upload --env 1 --file ip_address.yaml

Partial-Bug: #1482399
Implements Blueprint: allow-any-vip

Change-Id: Ib9b15bfdb7d4514919efbac2dab4416d088aa1e9
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/36/277636/9 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/commands/vip.py', 'fuelclient/v1/__init__.py', 'fuelclient/v1/vip.py', 'fuelclient/tests/unit/v2/cli/test_vip.py', 'fuelclient/cli/actions/vip.py', 'setup.cfg', 'fuelclient/__init__.py', 'fuelclient/tests/unit/v2/lib/test_vip.py']",8,90b7d3c9220b82ed9bc5cc2d17d4897dab51a979,bug/1482399,"# -*- coding: utf-8 -*- # # Copyright 2016 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import yaml import fuelclient from fuelclient.tests.unit.v1.test_vip_action import MANY_VIPS_YAML from fuelclient.tests.unit.v2.lib import test_api class TestVipFacade(test_api.BaseLibTest): def setUp(self): super(TestVipFacade, self).setUp() self.version = 'v1' self.env_id = 42 self.res_uri = ( '/api/{version}/clusters/{env_id}' '/network_configuration/ips/vips/'.format( version=self.version, env_id=self.env_id)) self.client = fuelclient.get_client('vip', self.version) def test_vip_upload(self): expected_body = yaml.load(MANY_VIPS_YAML) matcher = self.m_request.put(self.res_uri, json=expected_body) m_open = mock.mock_open(read_data=MANY_VIPS_YAML) with mock.patch('fuelclient.cli.serializers.open', m_open, create=True): with mock.patch('fuelclient.objects.environment.os') as env_os: env_os.path.exists.return_value = True self.client.upload(self.env_id, 'vips_1.yaml') self.assertTrue(matcher.called) self.assertEqual(expected_body, matcher.last_request.json()) def test_vip_download(self): expected_body = yaml.load(MANY_VIPS_YAML) matcher = self.m_request.get(self.res_uri, json=expected_body) m_open = mock.mock_open() with mock.patch('fuelclient.cli.serializers.open', m_open, create=True): self.client.download(self.env_id) self.assertTrue(matcher.called) written_yaml = yaml.safe_load(m_open().write.mock_calls[0][1][0]) expected_yaml = yaml.safe_load(MANY_VIPS_YAML) self.assertEqual(written_yaml, expected_yaml) ",,334,2
openstack%2Ffuel-octane~stable%2F8.0~I066750e8deb292fa8a34656d2bce06ef13719360,openstack/fuel-octane,stable/8.0,I066750e8deb292fa8a34656d2bce06ef13719360,Remove version hardcode from puppet module path,MERGED,2016-02-15 11:59:13.000000000,2016-02-15 12:21:22.000000000,2016-02-15 12:21:22.000000000,"[{'_account_id': 3}, {'_account_id': 6677}]","[{'number': 1, 'created': '2016-02-15 11:59:13.000000000', 'files': ['octane/magic_consts.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/be95fb7597448d4ec4932a22b45451efb6978b99', 'message': 'Remove version hardcode from puppet module path\n\nNow module path constant has hardcoded version 2015.1.0-7.0.\nReplace it with /etc/puppet/modules path which is a symlink\nto the current version of modules.\n\nChange-Id: I066750e8deb292fa8a34656d2bce06ef13719360\nCloses-bug: 1544967\n'}]",0,280177,be95fb7597448d4ec4932a22b45451efb6978b99,6,2,1,6677,,,0,"Remove version hardcode from puppet module path

Now module path constant has hardcoded version 2015.1.0-7.0.
Replace it with /etc/puppet/modules path which is a symlink
to the current version of modules.

Change-Id: I066750e8deb292fa8a34656d2bce06ef13719360
Closes-bug: 1544967
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/77/280177/1 && git format-patch -1 --stdout FETCH_HEAD,['octane/magic_consts.py'],1,be95fb7597448d4ec4932a22b45451efb6978b99,bug/1544967,"PUPPET_DIR = ""/etc/puppet/modules""","PUPPET_DIR = ""/etc/puppet/2015.1.0-7.0/modules""",1,1
openstack%2Fironic~master~I8159fd64d1c074bd539817a40900e34f8fae30d4,openstack/ironic,master,I8159fd64d1c074bd539817a40900e34f8fae30d4,Augmenting the hashing strategy,MERGED,2016-02-08 14:13:36.000000000,2016-02-15 12:20:15.000000000,2016-02-15 12:20:14.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6618}, {'_account_id': 6637}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10202}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 16635}, {'_account_id': 18781}, {'_account_id': 18893}]","[{'number': 1, 'created': '2016-02-08 14:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5a28d86245c9ef427bcd6646c135d2bc52c934e3', 'message': 'Augmenting the hashing strategy\n\nIt was only ``sha1`` algorithm being used till now to create\nhash of the file contents. Now included the ``md5`` hashing.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n'}, {'number': 2, 'created': '2016-02-09 08:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f0d2ea1b39222a481ce1a690777a23d9a7d60907', 'message': 'Augmenting the hashing strategy\n\nIt was only ``sha1`` algorithm being used till now to create\nhash of the file contents. Now included the ``md5`` hashing,\ndefault being `md5`.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n'}, {'number': 3, 'created': '2016-02-09 10:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fbd87b0160806b14f24484d7078526333fb01276', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Now added 'md5'\nhashing as well. As this method wasn't being used at all,\ntherefore changing the default algorithm to 'md5'.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}, {'number': 4, 'created': '2016-02-10 06:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1f1283b749f5453f4e756ebc82c87164180d2319', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Now added 'md5'\nhashing as well. As this method wasn't being used at all,\ntherefore changing the default algorithm to 'md5'.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}, {'number': 5, 'created': '2016-02-10 13:05:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c8bebd0306f67e5dcebc1f22a866b62c6a222200', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Need to add 'md5'\nto keep the consistency with that of IPA code base. As this\nmethod wasn't being used at all, therefore changing the default\nalgorithm to 'md5'. Will be used in oob firmware update (manual\nclean step) to verify the checksum of the images.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}, {'number': 6, 'created': '2016-02-11 03:33:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ad2d5790966a4f9b138e47d27a5b1280cd40e0da', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Need to add 'md5'\nto keep the consistency with that of IPA code base. As this\nmethod wasn't being used at all, therefore changing the default\nalgorithm to 'md5'. Will be used in oob firmware update (manual\nclean step) to verify the checksum of the images.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}, {'number': 7, 'created': '2016-02-12 04:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/dbba4ce6b8e645943af100b72059e61bf62168b7', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Need to add 'md5'\nto keep the consistency with that of IPA code base. As this\nmethod wasn't being used at all, therefore changing the default\nalgorithm to 'md5'. Will be used in oob firmware update (manual\nclean step) to verify the checksum of the images.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}, {'number': 8, 'created': '2016-02-12 10:57:02.000000000', 'files': ['ironic/tests/unit/common/test_utils.py', 'ironic/common/utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/1de89030a7218279a5dd225069fee1556abdcc7c', 'message': ""Augmenting the hashing strategy\n\nIt was only 'sha1' algorithm being used till now in ``hash_file``\nmethod to create hash of the file contents. Need to add 'md5'\nto keep the consistency with that of IPA code base. Also, this\nmethod now supports all the algorithms hashlib does. As this\nmethod wasn't being used at all, therefore making the default\nalgorithm to 'md5'. Will be used in oob firmware update (manual\nclean step) to verify the checksum of the images.\n\nChange-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4\n""}]",29,277408,1de89030a7218279a5dd225069fee1556abdcc7c,53,19,8,16635,,,0,"Augmenting the hashing strategy

It was only 'sha1' algorithm being used till now in ``hash_file``
method to create hash of the file contents. Need to add 'md5'
to keep the consistency with that of IPA code base. Also, this
method now supports all the algorithms hashlib does. As this
method wasn't being used at all, therefore making the default
algorithm to 'md5'. Will be used in oob firmware update (manual
clean step) to verify the checksum of the images.

Change-Id: I8159fd64d1c074bd539817a40900e34f8fae30d4
",git fetch https://review.opendev.org/openstack/ironic refs/changes/08/277408/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/common/test_utils.py', 'ironic/common/utils.py']",2,5a28d86245c9ef427bcd6646c135d2bc52c934e3,augment_hashing_strategy,"def _get_hash_object(hash_algo_name='md5'): """"""Create a hash object by the name of the algorithm. :param hash_algo_name: name of the hashing algorithm, default 'md5' :returns: a hash object based on the algorithm """""" hash_obj = None if hash_algo_name == 'md5': hash_obj = hashlib.md5() elif hash_algo_name == 'sha1': hash_obj = hashlib.sha1() return hash_obj def hash_file(file_like_object, hash_algo='md5'): """"""Generate a hash for the contents of a file. :param file_like_object: file like object whose hash to be calculated :param hash_algo: name of the hashing strategy, default 'md5' :returns: a condensed digest of the bytes of contents """""" checksum = _get_hash_object(hash_algo)","def hash_file(file_like_object): """"""Generate a hash for the contents of a file."""""" checksum = hashlib.sha1()",32,5
openstack%2Ffuel-menu~master~I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353,openstack/fuel-menu,master,I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353,Save root password to settings file,MERGED,2016-02-05 12:19:42.000000000,2016-02-15 12:17:54.000000000,2016-02-15 12:17:54.000000000,"[{'_account_id': 3}, {'_account_id': 6571}, {'_account_id': 7195}, {'_account_id': 10068}, {'_account_id': 10391}, {'_account_id': 10443}, {'_account_id': 10488}, {'_account_id': 11898}, {'_account_id': 14200}, {'_account_id': 14495}, {'_account_id': 20384}]","[{'number': 1, 'created': '2016-02-05 12:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/1abd25bc4f8c349d682695a0e610f0705325bc47', 'message': 'Save root password to settings file\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 2, 'created': '2016-02-05 12:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/7d12be8996f2da85f9abf1d548048f5259b2289d', 'message': 'Save root password to settings file\n\nFrom fuel menu root password changes only in master node, to make\npossible to change it on slave nodes I put it in settings file.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 3, 'created': '2016-02-05 13:14:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/163d09b5c0b6637963e4ad48ed97c4d70b211abe', 'message': 'Save root password to settings file\n\nFrom fuel menu root password changes only in master node, to make\npossible to change it on slave nodes I put it encrypted version in\nsettings file.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 4, 'created': '2016-02-05 13:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/f51b5152f5b759632642bed2ae732510fa4eb6af', 'message': 'Save root password to settings file\n\nFrom fuel menu root password changes only in master node, to make\npossible to change it on slave nodes I put it hashed version in\nsettings file.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 5, 'created': '2016-02-05 16:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/3b2d38c9a243df4fa091f66cc53c5870c12c598e', 'message': 'Save root password to settings file\n\nFuel-menu changes root password only in master node, to make\npossible to change it on slave nodes I put it hashed version in\nsettings file, BOOTSTRAP section.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 6, 'created': '2016-02-09 15:26:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/83d821eac980f5297a91134daf2624ba30226f10', 'message': 'Save root password to settings file\n\nFuel-menu changes root password only on master node, to make\npossible to change it on slave nodes this commit put it hashed version in\nsettings file, BOOTSTRAP section.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 7, 'created': '2016-02-09 15:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/48a60080ab8fcb5f7fb1920fad67938b71acc1e8', 'message': 'Save root password to settings file\n\nFuel-menu changes root password only on master node, to make\npossible to change it on slave nodes this commit put it hashed version in\nsettings file, BOOTSTRAP section.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 8, 'created': '2016-02-12 08:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/fa4721c119e985bf50d6ca3f169a9cabc9795096', 'message': 'Save root password to settings file\n\nThis patch fixes save method of rootpw module to make possible to change\nroot password not only on master node but on slaves. Save method puts\nhashed version of root password into the BOOTSTRAP section of the\nsettings file.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}, {'number': 9, 'created': '2016-02-12 09:12:12.000000000', 'files': ['fuelmenu/modules/rootpw.py', 'fuelmenu/common/utils.py'], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/a179d0e03eac35ea1ece158b457e96c6a7ac5d63', 'message': 'Save root password to settings file\n\nThis patch fixes save method of rootpw module to make possible to change\nroot password not only on master node but on slaves. Save method puts\nhashed version of root password into the BOOTSTRAP section of the\nsettings file.\n\nChange-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353\nPartial-Bug: #1537496\n'}]",14,276700,a179d0e03eac35ea1ece158b457e96c6a7ac5d63,45,11,9,20384,,,0,"Save root password to settings file

This patch fixes save method of rootpw module to make possible to change
root password not only on master node but on slaves. Save method puts
hashed version of root password into the BOOTSTRAP section of the
settings file.

Change-Id: I2092bfca78fb721a8df3c8c6e4e6fd18e64ba353
Partial-Bug: #1537496
",git fetch https://review.opendev.org/openstack/fuel-menu refs/changes/00/276700/3 && git format-patch -1 --stdout FETCH_HEAD,['fuelmenu/modules/rootpw.py'],1,1abd25bc4f8c349d682695a0e610f0705325bc47,bug/1537496,"from fuelmenu.settings import Settings self.save(responses) def save(self, responses): Settings().write({'ROOT_PASSWORD': responses['PASSWORD']}, defaultsfile=self.parent.defaultsettingsfile, outfn=self.parent.settingsfile) ",,9,0
openstack%2Fsenlin~master~Icaa9d1f0d4d5d2070a20fce06dcabe850a5cba5c,openstack/senlin,master,Icaa9d1f0d4d5d2070a20fce06dcabe850a5cba5c,Remove useless encrypt/decrypt methods,MERGED,2016-02-14 13:55:30.000000000,2016-02-15 12:16:41.000000000,2016-02-15 12:16:41.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-14 13:55:30.000000000', 'files': ['senlin/common/utils.py', 'senlin/tests/unit/test_common_utils.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/f0de867480f58ad374d719dcfa4e6d75c808a8e7', 'message': ""Remove useless encrypt/decrypt methods\n\nThe encrypt/decrypt util functions were used to encrypt/decrypt webhook\ncredentials. We don't have use case for them now. This patch proposes a\nremoval of both.\n\nChange-Id: Icaa9d1f0d4d5d2070a20fce06dcabe850a5cba5c\n""}]",0,279986,f0de867480f58ad374d719dcfa4e6d75c808a8e7,7,3,1,8246,,,0,"Remove useless encrypt/decrypt methods

The encrypt/decrypt util functions were used to encrypt/decrypt webhook
credentials. We don't have use case for them now. This patch proposes a
removal of both.

Change-Id: Icaa9d1f0d4d5d2070a20fce06dcabe850a5cba5c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/86/279986/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/common/utils.py', 'senlin/tests/unit/test_common_utils.py']",2,f0de867480f58ad374d719dcfa4e6d75c808a8e7,rm-crypt,,"from cryptography import fernetclass TestEncrypt(base.SenlinTestCase): def test_encrypt(self): msg = 'test-string' msg_encrypted, key = utils.encrypt(msg) self.assertIsInstance(msg_encrypted, six.string_types) self.assertIsInstance(key, six.string_types) def test_decrypt(self): msg = 'test-string' msg_encrypted, key = utils.encrypt(msg) msg_decrypted = utils.decrypt(msg_encrypted, key) self.assertEqual(msg, msg_decrypted) def test_decrypt_invalid_key_msg(self): msg = 'test-string' msg_encrypted, key = utils.encrypt(msg) invalid_key = 'fake-key' self.assertRaises(fernet.InvalidToken, utils.decrypt, msg_encrypted, invalid_key) invalid_msg = 'fake-msg' self.assertRaises(ValueError, utils.decrypt, invalid_msg, key) invalid_msg = fernet.Fernet.generate_key() self.assertRaises(fernet.InvalidToken, utils.decrypt, invalid_msg, key) ",0,60
openstack%2Fmonasca-agent~master~I7222aaa1b7032e789c77e9aacc8bbbc5aa390f94,openstack/monasca-agent,master,I7222aaa1b7032e789c77e9aacc8bbbc5aa390f94,Sample outputs and implementation description in https://drive.google.com/file/d/0B1oK2fO_NmsTaGtlaDVPOTR4Q1U/view?usp=sharing,ABANDONED,2016-02-15 12:13:42.000000000,2016-02-15 12:14:02.000000000,,[],"[{'number': 1, 'created': '2016-02-15 12:13:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/251a5abe13f02597634669ac2ab71ce5f4e33682', 'message': 'Sample outputs and implementation description in https://drive.google.com/file/d/0B1oK2fO_NmsTaGtlaDVPOTR4Q1U/view?usp=sharing\n\nChange-Id: I7222aaa1b7032e789c77e9aacc8bbbc5aa390f94\n'}]",0,280183,251a5abe13f02597634669ac2ab71ce5f4e33682,2,0,1,11730,,,0,"Sample outputs and implementation description in https://drive.google.com/file/d/0B1oK2fO_NmsTaGtlaDVPOTR4Q1U/view?usp=sharing

Change-Id: I7222aaa1b7032e789c77e9aacc8bbbc5aa390f94
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/83/280183/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,251a5abe13f02597634669ac2ab71ce5f4e33682,,,,0,0
openstack%2Ffuel-web~master~I3add184f0032cc321cf3feebbe823fc17351321c,openstack/fuel-web,master,I3add184f0032cc321cf3feebbe823fc17351321c,Add attributes field to Node model,MERGED,2016-02-05 10:14:08.000000000,2016-02-15 12:02:56.000000000,2016-02-15 11:31:51.000000000,"[{'_account_id': 3}, {'_account_id': 6571}, {'_account_id': 6677}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9377}, {'_account_id': 10391}, {'_account_id': 10443}, {'_account_id': 10488}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 12559}, {'_account_id': 14543}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-02-05 10:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/61f262f02a0b1d6a05b51ea5667ea1a6fc210e9b', 'message': ""Add node attributes columns\n\nAdd 'editable' and 'generated' columns to\n'node_attributes' database table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 2, 'created': '2016-02-05 11:33:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ffb62e27e32a53c006c49258a78c912be58ddfa0', 'message': ""Add node attributes columns\n\nAdd 'editable' and 'generated' columns to\n'node_attributes' database table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 3, 'created': '2016-02-05 12:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6772aa626dcfa2b1b3b53ac17166e540344e50c1', 'message': ""Add node attributes columns\n\nAdd 'attributes_metadata' column to 'nodes'\ndatabase table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 4, 'created': '2016-02-05 12:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/06baa99db29ebad5cda8c9b37f966364dd11e24f', 'message': ""Add node attributes column\n\nAdd 'attributes_metadata' column to 'nodes'\ndatabase table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 5, 'created': '2016-02-10 09:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f671e0f1a59567db77ffdba4551a92f1d0af5ebd', 'message': ""Add node attributes column\n\nAdd 'attributes' column to 'nodes' database table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 6, 'created': '2016-02-10 10:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b9aaf18216baeb85ea7cc4ccc443e3f2e775bf99', 'message': ""Add node attributes column\n\nAdd 'attributes' column to 'nodes' database table.\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n""}, {'number': 7, 'created': '2016-02-11 07:23:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aa18bca157826f0c1d57559d213b7be36c3b6694', 'message': 'Add attributes field to Node model\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n'}, {'number': 8, 'created': '2016-02-12 16:07:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/89dc7a2db5e90c212e3d41022022ba8740c2fd77', 'message': 'Add attributes field to Node model\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n'}, {'number': 9, 'created': '2016-02-15 10:59:47.000000000', 'files': ['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/73f1df05f766184d532ac054b20caca8f7df967c', 'message': 'Add attributes field to Node model\n\nChange-Id: I3add184f0032cc321cf3feebbe823fc17351321c\nImplements: blueprint support-numa-cpu-pinning\n'}]",15,276666,73f1df05f766184d532ac054b20caca8f7df967c,118,18,9,11898,,,0,"Add attributes field to Node model

Change-Id: I3add184f0032cc321cf3feebbe823fc17351321c
Implements: blueprint support-numa-cpu-pinning
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/276666/8 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/db/migration/alembic_migrations/versions/fuel_9_0.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/db/sqlalchemy/models/node.py', 'nailgun/nailgun/test/unit/test_migration_fuel_9_0.py']",4,61f262f02a0b1d6a05b51ea5667ea1a6fc210e9b,bp/support-numa-cpu-pinning,"import datetime cluster_id = base.insert_table_row( meta.tables['clusters'], { } ) node_id = base.insert_table_row( meta.tables['nodes'], { 'uuid': '26b508d0-0d76-4159-bce9-f67ec2765480', 'cluster_id': cluster_id, 'group_id': None, 'status': 'discover', 'meta': '{}', 'mac': 'aa:aa:aa:aa:aa:aa', 'timestamp': datetime.datetime.utcnow(), } ) base.insert_table_row( meta.tables['node_attributes'], { 'node_id': node_id, } ) class TestNodeAttributesMigration(base.BaseAlembicMigrationTest): def test_attributes_fields_exist(self): columns = [ self.meta.tables['node_attributes'].c.editable, self.meta.tables['node_attributes'].c.generated ] db_values = db.execute(sa.select(columns)).fetchone() for db_value in db_values: self.assertEqual(db_value, '{}')"," db.execute( meta.tables['clusters'].insert(), [{ }])",83,4
openstack%2Fsahara~master~If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0,openstack/sahara,master,If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0,Add test cases for versionhandler,MERGED,2015-12-23 07:49:39.000000000,2016-02-15 12:02:23.000000000,2016-02-15 12:02:23.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8932}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 17130}, {'_account_id': 18399}]","[{'number': 1, 'created': '2015-12-23 07:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/215057994190ce4650949f483bfc28721622e130', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 2, 'created': '2016-01-13 07:27:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c18bbaa5387840c45634cb9fb569719a61db1b2c', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 3, 'created': '2016-01-13 09:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e27ddfb05503d125c47e2e591916f6c22c3b0e02', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 4, 'created': '2016-01-19 07:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b53487cac5067de6eb887ddc12c30f914f45b00e', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 5, 'created': '2016-02-03 02:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/176d0827ab32aa4cebb53d169916f998a8be3c1e', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 6, 'created': '2016-02-04 07:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8eefcc7ae8d8a3ab02c516ee2b1b45a4104d9301', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 7, 'created': '2016-02-14 11:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/38b4cc2cd92b326a1cbfc26936c9f37e8b3cbdcc', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}, {'number': 8, 'created': '2016-02-14 12:24:01.000000000', 'files': ['sahara/tests/unit/plugins/cdh/v5/test_versionhandler.py', 'sahara/tests/unit/plugins/cdh/v5_4_0/test_versionhandler.py', 'sahara/tests/unit/plugins/cdh/v5_3_0/test_versionhandler.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5db99107d6617bdb1c9eb2cdeedce92b87108f84', 'message': 'Add test cases for versionhandler\n\nAdd version handler unit tests for each version, which is a necessary\nwork need to be done before versionhandler refactoring.\n\nPartially Implements: blueprint cdh-plugin-refactoring\n\nChange-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0\n'}]",6,260907,5db99107d6617bdb1c9eb2cdeedce92b87108f84,58,11,8,18399,,,0,"Add test cases for versionhandler

Add version handler unit tests for each version, which is a necessary
work need to be done before versionhandler refactoring.

Partially Implements: blueprint cdh-plugin-refactoring

Change-Id: If4763491d3a5a2a44c8c7f65d56ee423b0f5bad0
",git fetch https://review.opendev.org/openstack/sahara refs/changes/07/260907/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/unit/plugins/cdh/v5/test_versionhandler.py', 'sahara/tests/unit/plugins/cdh/v5_4_0/test_versionhandler.py', 'sahara/tests/unit/plugins/cdh/v5_3_0/test_versionhandler.py']",3,215057994190ce4650949f483bfc28721622e130,bp/cdh-plugin-refactoring,"# Copyright (c) 2015 Intel Corporation. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import mock import six from sahara.plugins.cdh.v5_3_0.edp_engine import EdpOozieEngine from sahara.plugins.cdh.v5_3_0.edp_engine import EdpSparkEngine from sahara.plugins.cdh.v5_3_0 import versionhandler from sahara.tests.unit import base class VersionHandlerTestCase(base.SaharaTestCase): plugin_path = ""sahara.plugins.cdh.v5_3_0."" cloudera_utils_path = plugin_path + ""cloudera_utils.ClouderaUtilsV530."" plugin_utils_path = plugin_path + ""plugin_utils.PluginUtilsV530."" def setUp(self): super(VersionHandlerTestCase, self).setUp() self.vh = versionhandler.VersionHandler() @mock.patch(plugin_path + ""config_helper.get_plugin_configs"") def test_get_plugin_configs(self, get_plugin_configs): self.vh.get_plugin_configs() get_plugin_configs.assert_called_once_with() def test_get_node_processes(self): processes = self.vh.get_node_processes() for k, v in six.iteritems(processes): for p in v: self.assertIsInstance(p, str) @mock.patch(plugin_path + ""validation.validate_cluster_creating"") def test_validate(self, validate_cluster_creating): cluster = mock.Mock() self.vh.validate(cluster) validate_cluster_creating.assert_called_once_with(cluster) @mock.patch(""sahara.conductor.API.cluster_update"") @mock.patch(""sahara.context.ctx"") @mock.patch(plugin_path + ""deploy.configure_cluster"") @mock.patch(cloudera_utils_path + ""get_cloudera_manager_info"", return_value={""fake_cm_info"": ""fake""}) def test_config_cluster(self, get_cm_info, configure_cluster, ctx, cluster_update): cluster = mock.Mock() self.vh.configure_cluster(cluster) configure_cluster.assert_called_once_with(cluster) cluster_update.assert_called_once_with( ctx(), cluster, {'info': {""fake_cm_info"": ""fake""}}) @mock.patch(plugin_path + ""deploy.start_cluster"") def test_start_cluster(self, start_cluster): cluster = mock.Mock() self.vh._set_cluster_info = mock.Mock() self.vh.start_cluster(cluster) start_cluster.assert_called_once_with(cluster) self.vh._set_cluster_info.assert_called_once_with(cluster) @mock.patch(plugin_path + ""deploy.decommission_cluster"") def test_decommmission_nodes(self, decommission_cluster): cluster = mock.Mock() instances = mock.Mock() self.vh.decommission_nodes(cluster, instances) decommission_cluster.assert_called_once_with(cluster, instances) @mock.patch(plugin_path + ""validation.validate_existing_ng_scaling"") @mock.patch(plugin_path + ""validation.validate_additional_ng_scaling"") def test_validate_scaling(self, additional_validate, existing_validate): cluster = mock.Mock() existing = mock.Mock() additional = mock.Mock() self.vh.validate_scaling(cluster, existing, additional) existing_validate.assert_called_once_with(cluster, existing) additional_validate.assert_called_once_with(cluster, additional) @mock.patch(plugin_path + ""deploy.scale_cluster"") def test_scale_cluster(self, scale_cluster): cluster = mock.Mock() instances = mock.Mock() self.vh.scale_cluster(cluster, instances) scale_cluster.assert_called_once_with(cluster, instances) @mock.patch(""sahara.conductor.API.cluster_update"") @mock.patch(""sahara.context.ctx"") @mock.patch(cloudera_utils_path + ""get_cloudera_manager_info"", return_value={}) @mock.patch(plugin_utils_path + ""get_hue"") def test_set_cluster_info(self, get_hue, get_cloudera_manager_info, ctx, cluster_update): get_hue.return_value.management_ip = ""1.2.3.4"" cluster = mock.Mock() self.vh._set_cluster_info(cluster) info = {'info': {'Hue Dashboard': {'Web UI': 'http://1.2.3.4:8888'}}} cluster_update.assert_called_once_with(ctx(), cluster, info) @mock.patch(""sahara.plugins.utils.get_instance"") @mock.patch(""sahara.plugins.utils.get_config_value_or_default"") @mock.patch(""sahara.service.edp.job_utils.get_plugin"") def test_get_edp_engine(self, get_plugin, get_config_value_or_default, get_instance): cluster = mock.Mock() job_type = 'Java' ret = self.vh.get_edp_engine(cluster, job_type) self.assertIsInstance(ret, EdpOozieEngine) job_type = 'Spark' ret = self.vh.get_edp_engine(cluster, job_type) self.assertIsInstance(ret, EdpSparkEngine) job_type = 'unsupported' ret = self.vh.get_edp_engine(cluster, job_type) self.assertIsNone(ret) def test_get_edp_job_types(self): ret = self.vh.get_edp_job_types() expect = EdpOozieEngine.get_supported_job_types() + \ EdpSparkEngine.get_supported_job_types() self.assertEqual(expect, ret) @mock.patch(plugin_path + ""edp_engine.EdpOozieEngine.get_possible_job_config"", return_value={'job_config': {}}) def test_edp_config_hints(self, get_possible_job_config): job_type = mock.Mock() ret = self.vh.get_edp_config_hints(job_type) get_possible_job_config.assert_called_once_with(job_type) self.assertEqual(ret, {'job_config': {}}) @mock.patch(plugin_path + ""deploy.get_open_ports"", return_value=[1234]) def test_get_open_ports(self, get_open_ports): node_group = mock.Mock() ret = self.vh.get_open_ports(node_group) get_open_ports.assert_called_once_with(node_group) self.assertEqual(ret, [1234]) @mock.patch(plugin_utils_path + ""recommend_configs"") def test_recommend_configs(self, recommend_configs): cluster = mock.Mock() scaling = mock.Mock() self.vh.get_plugin_configs = mock.Mock() self.vh.recommend_configs(cluster, scaling) recommend_configs.assert_called_once_with(cluster, self.vh.get_plugin_configs(), scaling) ",,470,0
openstack%2Fha-guide~master~I145c1cb3f6a7ae6b44c7e926193b3dd958852719,openstack/ha-guide,master,I145c1cb3f6a7ae6b44c7e926193b3dd958852719,Updated from openstack-manuals,MERGED,2016-02-14 18:27:17.000000000,2016-02-15 11:59:14.000000000,2016-02-15 11:59:14.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-14 18:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/23617baf5a96e1a228b17b9dd89cbed4fffc80d4', 'message': 'Updated from openstack-manuals\n\nChange-Id: I145c1cb3f6a7ae6b44c7e926193b3dd958852719\n'}, {'number': 2, 'created': '2016-02-15 11:49:04.000000000', 'files': ['doc/common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/3866c99c817cd0748b6b8fd32cc985ce343bdab8', 'message': 'Updated from openstack-manuals\n\nChange-Id: I145c1cb3f6a7ae6b44c7e926193b3dd958852719\n'}]",0,280011,3866c99c817cd0748b6b8fd32cc985ce343bdab8,9,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: I145c1cb3f6a7ae6b44c7e926193b3dd958852719
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/11/280011/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common-rst/conventions.rst', 'doc/common-rst/app_support.rst', 'doc/common-rst/glossary.rst']",3,23617baf5a96e1a228b17b9dd89cbed4fffc80d4,openstack/openstack-manuals,"======== Glossary ======== .. comments This file is automatically generated, edit the master doc/glossary/glossary-terms.xml to update it. This glossary offers a list of terms and definitions to define a vocabulary for OpenStack-related concepts. To add to OpenStack glossary, clone the `openstack/openstack-manuals repository <https://git.openstack.org/cgit/openstack/openstack-manuals>`__ and update the source file ``doc/glossary/glossary-terms.xml`` through the OpenStack contribution process. .. glossary:: 6to4 A mechanism that allows IPv6 packets to be transmitted over an IPv4 network, providing a strategy for migrating to IPv6. absolute limit Impassable limits for guest VMs. Settings include total RAM size, maximum number of vCPUs, and maximum disk size. access control list A list of permissions attached to an object. An ACL specifies which users or system processes have access to objects. It also defines which operations can be performed on specified objects. Each entry in a typical ACL specifies a subject and an operation. For instance, the ACL entry ``(Alice, delete)`` for a file gives Alice permission to delete the file. access key Alternative term for an Amazon EC2 access key. See EC2 access key. account The Object Storage context of an account. Do not confuse with a user account from an authentication service, such as Active Directory, /etc/passwd, OpenLDAP, OpenStack Identity, and so on. account auditor Checks for missing replicas and incorrect or corrupted objects in a specified Object Storage account by running queries against the back-end SQLite database. account database A SQLite database that contains Object Storage accounts and related metadata and that the accounts server accesses. account reaper An Object Storage worker that scans for and deletes account databases and that the account server has marked for deletion. account server Lists containers in Object Storage and stores container information in the account database. account service An Object Storage component that provides account services such as list, create, modify, and audit. Do not confuse with OpenStack Identity service, OpenLDAP, or similar user-account services. accounting The Compute service provides accounting information through the event notification and system usage data facilities. ACL See access control list. active/active configuration In a high-availability setup with an active/active configuration, several systems share the load together and if one fails, the load is distributed to the remaining systems. Active Directory Authentication and identity service by Microsoft, based on LDAP. Supported in OpenStack. active/passive configuration In a high-availability setup with an active/passive configuration, systems are set up to bring additional resources online to replace those that have failed. address pool A group of fixed and/or floating IP addresses that are assigned to a project and can be used by or assigned to the VM instances in a project. admin API A subset of API calls that are accessible to authorized administrators and are generally not accessible to end users or the public Internet. They can exist as a separate service (keystone) or can be a subset of another API (nova). admin server In the context of the Identity service, the worker process that provides access to the admin API. Advanced Message Queuing Protocol (AMQP) The open standard messaging protocol used by OpenStack components for intra-service communications, provided by RabbitMQ, Qpid, or ZeroMQ. Advanced RISC Machine (ARM) Lower power consumption CPU often found in mobile and embedded devices. Supported by OpenStack. alert The Compute service can send alerts through its notification system, which includes a facility to create custom notification drivers. Alerts can be sent to and displayed on the horizon dashboard. allocate The process of taking a floating IP address from the address pool so it can be associated with a fixed IP on a guest VM instance. Amazon Kernel Image (AKI) Both a VM container format and disk format. Supported by Image service. Amazon Machine Image (AMI) Both a VM container format and disk format. Supported by Image service. Amazon Ramdisk Image (ARI) Both a VM container format and disk format. Supported by Image service. Anvil A project that ports the shell script-based project named DevStack to Python. Apache The Apache Software Foundation supports the Apache community of open-source software projects. These projects provide software products for the public good. Apache License 2.0 All OpenStack core projects are provided under the terms of the Apache License 2.0 license. Apache Web Server The most common web server software currently used on the Internet. API endpoint The daemon, worker, or service that a client communicates with to access an API. API endpoints can provide any number of services, such as authentication, sales data, performance meters, Compute VM commands, census data, and so on. API extension Custom modules that extend some OpenStack core APIs. API extension plug-in Alternative term for a Networking plug-in or Networking API extension. API key Alternative term for an API token. API server Any node running a daemon or worker that provides an API endpoint. API token Passed to API requests and used by OpenStack to verify that the client is authorized to run the requested operation. API version In OpenStack, the API version for a project is part of the URL. For example, ``example.com/nova/v1/foobar``. applet A Java program that can be embedded into a web page. Application Programming Interface (API) A collection of specifications used to access a service, application, or program. Includes service calls, required parameters for each call, and the expected return values. Application catalog OpenStack project that provides an application catalog service so that users can compose and deploy composite environments on an application abstraction level while managing the application lifecycle. The code name of the project is murano. application server A piece of software that makes available another piece of software over a network. Application Service Provider (ASP) Companies that rent specialized applications that help businesses and organizations provide additional services with lower cost. Address Resolution Protocol (ARP) The protocol by which layer-3 IP addresses are resolved into layer-2 link local addresses. arptables Tool used for maintaining Address Resolution Protocol packet filter rules in the Linux kernel firewall modules. Used along with iptables, ebtables, and ip6tables in Compute to provide firewall services for VMs. associate The process associating a Compute floating IP address with a fixed IP address. Asynchronous JavaScript and XML (AJAX) A group of interrelated web development techniques used on the client-side to create asynchronous web applications. Used extensively in horizon. ATA over Ethernet (AoE) A disk storage protocol tunneled within Ethernet. attach The process of connecting a VIF or vNIC to a L2 network in Networking. In the context of Compute, this process connects a storage volume to an instance. attachment (network) Association of an interface ID to a logical port. Plugs an interface into a port. auditing Provided in Compute through the system usage data facility. auditor A worker process that verifies the integrity of Object Storage objects, containers, and accounts. Auditors is the collective term for the Object Storage account auditor, container auditor, and object auditor. Austin The code name for the initial release of OpenStack. The first design summit took place in Austin, Texas, US. auth node Alternative term for an Object Storage authorization node. authentication The process that confirms that the user, process, or client is really who they say they are through private key, secret token, password, fingerprint, or similar method. authentication token A string of text provided to the client after authentication. Must be provided by the user or process in subsequent requests to the API endpoint. AuthN The Identity service component that provides authentication services. authorization The act of verifying that a user, process, or client is authorized to perform an action. authorization node An Object Storage node that provides authorization services. AuthZ The Identity component that provides high-level authorization services. Auto ACK Configuration setting within RabbitMQ that enables or disables message acknowledgment. Enabled by default. auto declare A Compute RabbitMQ setting that determines whether a message exchange is automatically created when the program starts. availability zone An Amazon EC2 concept of an isolated area that is used for fault tolerance. Do not confuse with an OpenStack Compute zone or cell. AWS Amazon Web Services. AWS CloudFormation template AWS CloudFormation allows AWS users to create and manage a collection of related resources. The Orchestration service supports a CloudFormation-compatible format (CFN). back end Interactions and processes that are obfuscated from the user, such as Compute volume mount, data transmission to an iSCSI target by a daemon, or Object Storage object integrity checks. back-end catalog The storage method used by the Identity service catalog service to store and retrieve information about API endpoints that are available to the client. Examples include an SQL database, LDAP database, or KVS back end. back-end store The persistent data store used to save and retrieve information for a service, such as lists of Object Storage objects, current state of guest VMs, lists of user names, and so on. Also, the method that the Image service uses to get and store VM images. Options include Object Storage, local file system, S3, and HTTP. backup restore and disaster recovery as a service The OpenStack project that provides integrated tooling for backing up, restoring, and recovering file systems, instances, or database backups. The project name is freezer. bandwidth The amount of available data used by communication resources, such as the Internet. Represents the amount of data that is used to download things or the amount of data available to download. barbican Code name of the key management service for OpenStack. bare An Image service container format that indicates that no container exists for the VM image. Bare metal service OpenStack project that provisions bare metal, as opposed to virtual, machines. The code name for the project is ironic. base image An OpenStack-provided image. Bell-LaPadula model A security model that focuses on data confidentiality and controlled access to classified information. This model divide the entities into subjects and objects. The clearance of a subject is compared to the classification of the object to determine if the subject is authorized for the specific access mode. The clearance or classification scheme is expressed in terms of a lattice. Benchmark service OpenStack project that provides a framework for performance analysis and benchmarking of individual OpenStack components as well as full production OpenStack cloud deployments. The code name of the project is rally. Bexar A grouped release of projects related to OpenStack that came out in February of 2011. It included only Compute (nova) and Object Storage (swift). Bexar is the code name for the second release of OpenStack. The design summit took place in San Antonio, Texas, US, which is the county seat for Bexar county. binary Information that consists solely of ones and zeroes, which is the language of computers. bit A bit is a single digit number that is in base of 2 (either a zero or one). Bandwidth usage is measured in bits per second. bits per second (BPS) The universal measurement of how quickly data is transferred from place to place. block device A device that moves data in the form of blocks. These device nodes interface the devices, such as hard disks, CD-ROM drives, flash drives, and other addressable regions of memory. block migration A method of VM live migration used by KVM to evacuate instances from one host to another with very little downtime during a user-initiated switchover. Does not require shared storage. Supported by Compute. Block Storage The OpenStack core project that enables management of volumes, volume snapshots, and volume types. The project name of Block Storage is cinder. Block Storage API An API on a separate endpoint for attaching, detaching, and creating block storage for compute VMs. BMC Baseboard Management Controller. The intelligence in the IPMI architecture, which is a specialized micro-controller that is embedded on the motherboard of a computer and acts as a server. Manages the interface between system management software and platform hardware. bootable disk image A type of VM image that exists as a single, bootable file. Bootstrap Protocol (BOOTP) A network protocol used by a network client to obtain an IP address from a configuration server. Provided in Compute through the dnsmasq daemon when using either the FlatDHCP manager or VLAN manager network manager. Border Gateway Protocol (BGP) The Border Gateway Protocol is a dynamic routing protocol that connects autonomous systems. Considered the backbone of the Internet, this protocol connects disparate networks to form a larger network. browser Any client software that enables a computer or device to access the Internet. builder file Contains configuration information that Object Storage uses to reconfigure a ring or to re-create it from scratch after a serious failure. bursting The practice of utilizing a secondary environment to elastically build instances on-demand when the primary environment is resource constrained. button class A group of related button types within horizon. Buttons to start, stop, and suspend VMs are in one class. Buttons to associate and disassociate floating IP addresses are in another class, and so on. byte Set of bits that make up a single character; there are usually 8 bits to a byte. CA Certificate Authority or Certification Authority. In cryptography, an entity that issues digital certificates. The digital certificate certifies the ownership of a public key by the named subject of the certificate. This enables others (relying parties) to rely upon signatures or assertions made by the private key that corresponds to the certified public key. In this model of trust relationships, a CA is a trusted third party for both the subject (owner) of the certificate and the party relying upon the certificate. CAs are characteristic of many public key infrastructure (PKI) schemes. cache pruner A program that keeps the Image service VM image cache at or below its configured maximum size. Cactus An OpenStack grouped release of projects that came out in the spring of 2011. It included Compute (nova), Object Storage (swift), and the Image service (glance). Cactus is a city in Texas, US and is the code name for the third release of OpenStack. When OpenStack releases went from three to six months long, the code name of the release changed to match a geography nearest the previous summit. CADF Cloud Auditing Data Federation (CADF) is a specification for audit event data. CADF is supported by OpenStack Identity. CALL One of the RPC primitives used by the OpenStack message queue software. Sends a message and waits for a response. capability Defines resources for a cell, including CPU, storage, and networking. Can apply to the specific services within a cell or a whole cell. capacity cache A Compute back-end database table that contains the current workload, amount of free RAM, and number of VMs running on each host. Used to determine on which host a VM starts. capacity updater A notification driver that monitors VM instances and updates the capacity cache as needed. CAST One of the RPC primitives used by the OpenStack message queue software. Sends a message and does not wait for a response. catalog A list of API endpoints that are available to a user after authentication with the Identity service. catalog service An Identity service that lists API endpoints that are available to a user after authentication with the Identity service. ceilometer The project name for the Telemetry service, which is an integrated project that provides metering and measuring facilities for OpenStack. cell Provides logical partitioning of Compute resources in a child and parent relationship. Requests are passed from parent cells to child cells if the parent cannot provide the requested resource. cell forwarding A Compute option that enables parent cells to pass resource requests to child cells if the parent cannot provide the requested resource. cell manager The Compute component that contains a list of the current capabilities of each host within the cell and routes requests as appropriate. CentOS A Linux distribution that is compatible with OpenStack. Ceph Massively scalable distributed storage system that consists of an object store, block store, and POSIX-compatible distributed file system. Compatible with OpenStack. CephFS The POSIX-compliant file system provided by Ceph. certificate authority A simple certificate authority provided by Compute for cloudpipe VPNs and VM image decryption. Challenge-Handshake Authentication Protocol (CHAP) An iSCSI authentication method supported by Compute. chance scheduler A scheduling method used by Compute that randomly chooses an available host from the pool. changes since A Compute API parameter that downloads changes to the requested item since your last request, instead of downloading a new, fresh set of data and comparing it against the old data. Chef An operating system configuration management tool supporting OpenStack deployments. child cell If a requested resource such as CPU time, disk storage, or memory is not available in the parent cell, the request is forwarded to its associated child cells. If the child cell can fulfill the request, it does. Otherwise, it attempts to pass the request to any of its children. cinder A core OpenStack project that provides block storage services for VMs. CirrOS A minimal Linux distribution designed for use as a test image on clouds such as OpenStack. Cisco neutron plug-in A Networking plug-in for Cisco devices and technologies, including UCS and Nexus. cloud architect A person who plans, designs, and oversees the creation of clouds. cloud computing A model that enables access to a shared pool of configurable computing resources, such as networks, servers, storage, applications, and services, that can be rapidly provisioned and released with minimal management effort or service provider interaction. cloud controller Collection of Compute components that represent the global state of the cloud; talks to services, such as Identity authentication, Object Storage, and node/storage workers through a queue. cloud controller node A node that runs network, volume, API, scheduler, and image services. Each service may be broken out into separate nodes for scalability or availability. Cloud Data Management Interface (CDMI) SINA standard that defines a RESTful API for managing objects in the cloud, currently unsupported in OpenStack. Cloud Infrastructure Management Interface (CIMI) An in-progress specification for cloud management. Currently unsupported in OpenStack. cloud-init A package commonly installed in VM images that performs initialization of an instance after boot using information that it retrieves from the metadata service, such as the SSH public key and user data. cloudadmin One of the default roles in the Compute RBAC system. Grants complete system access. Cloudbase-Init A Windows project providing guest initialization features, similar to cloud-init. cloudpipe A compute service that creates VPNs on a per-project basis. cloudpipe image A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN running on Linux. Clustering The OpenStack project that OpenStack project that implements clustering services and libraries for the management of groups of homogeneous objects exposed by other OpenStack services. The project name of Clustering service is senlin. CMDB Configuration Management Database. congress OpenStack project that provides the Governance service. command filter Lists allowed commands within the Compute rootwrap facility. Common Internet File System (CIFS) A file sharing protocol. It is a public or open variation of the original Server Message Block (SMB) protocol developed and used by Microsoft. Like the SMB protocol, CIFS runs at a higher level and uses the TCP/IP protocol. community project A project that is not officially endorsed by the OpenStack Foundation. If the project is successful enough, it might be elevated to an incubated project and then to a core project, or it might be merged with the main code trunk. compression Reducing the size of files by special encoding, the file can be decompressed again to its original content. OpenStack supports compression at the Linux file system level but does not support compression for things such as Object Storage objects or Image service VM images. Compute The OpenStack core project that provides compute services. The project name of Compute service is nova. Compute API The nova-api daemon provides access to nova services. Can communicate with other APIs, such as the Amazon EC2 API. compute controller The Compute component that chooses suitable hosts on which to start VM instances. compute host Physical host dedicated to running compute nodes. compute node A node that runs the nova-compute daemon that manages VM instances that provide a wide range of services, such as web applications and analytics. Compute service Name for the Compute component that manages VMs. compute worker The Compute component that runs on each compute node and manages the VM instance lifecycle, including run, reboot, terminate, attach/detach volumes, and so on. Provided by the nova-compute daemon. concatenated object A set of segment objects that Object Storage combines and sends to the client. conductor In Compute, conductor is the process that proxies database requests from the compute process. Using conductor improves security because compute nodes do not need direct access to the database. consistency window The amount of time it takes for a new Object Storage object to become accessible to all clients. console log Contains the output from a Linux VM console in Compute. container Organizes and stores objects in Object Storage. Similar to the concept of a Linux directory but cannot be nested. Alternative term for an Image service container format. container auditor Checks for missing replicas or incorrect objects in specified Object Storage containers through queries to the SQLite back-end database. container database A SQLite database that stores Object Storage containers and container metadata. The container server accesses this database. container format A wrapper used by the Image service that contains a VM image and its associated metadata, such as machine state, OS disk size, and so on. container server An Object Storage server that manages containers. Containers service OpenStack project that provides a set of services for management of application containers in a multi-tenant cloud environment. The code name of the project name is magnum. container service The Object Storage component that provides container services, such as create, delete, list, and so on. content delivery network (CDN) A content delivery network is a specialized network that is used to distribute content to clients, typically located close to the client for increased performance. controller node Alternative term for a cloud controller node. core API Depending on context, the core API is either the OpenStack API or the main API of a specific core project, such as Compute, Networking, Image service, and so on. core project An official OpenStack project. Currently consists of Compute (nova), Object Storage (swift), Image service (glance), Identity (keystone), Dashboard (horizon), Networking (neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration (heat), Database service (trove), Bare Metal service (ironic), Data processing service (sahara). However, this definition is changing based on community discussions about the ""Big Tent"". cost Under the Compute distributed scheduler, this is calculated by looking at the capabilities of each host relative to the flavor of the VM instance being requested. credentials Data that is only known to or accessible by a user and used to verify that the user is who he says he is. Credentials are presented to the server during authentication. Examples include a password, secret key, digital certificate, and fingerprint. Cross-Origin Resource Sharing (CORS) A mechanism that allows many resources (for example, fonts, JavaScript) on a web page to be requested from another domain outside the domain from which the resource originated. In particular, JavaScript's AJAX calls can use the XMLHttpRequest mechanism. Crowbar An open source community project by Dell that aims to provide all necessary services to quickly deploy clouds. current workload An element of the Compute capacity cache that is calculated based on the number of build, snapshot, migrate, and resize operations currently in progress on a given host. customer Alternative term for tenant. customization module A user-created Python module that is loaded by horizon to change the look and feel of the dashboard. daemon A process that runs in the background and waits for requests. May or may not listen on a TCP or UDP port. Do not confuse with a worker. DAC Discretionary access control. Governs the ability of subjects to access objects, while enabling users to make policy decisions and assign security attributes. The traditional UNIX system of users, groups, and read-write-execute permissions is an example of DAC. dashboard The web-based management interface for OpenStack. An alternative name for horizon. data encryption Both Image service and Compute support encrypted virtual machine (VM) images (but not instances). In-transit data encryption is supported in OpenStack using technologies such as HTTPS, SSL, TLS, and SSH. Object Storage does not support object encryption at the application level but may support storage that uses disk encryption. database ID A unique ID given to each replica of an Object Storage database. database replicator An Object Storage component that copies changes in the account, container, and object databases to other nodes. Database service An integrated project that provide scalable and reliable Cloud Database-as-a-Service functionality for both relational and non-relational database engines. The project name of Database service is trove. Data processing service OpenStack project that provides a scalable data-processing stack and associated management interfaces. The code name for the project is sahara. data store A database engine supported by the Database service. deallocate The process of removing the association between a floating IP address and a fixed IP address. Once this association is removed, the floating IP returns to the address pool. Debian A Linux distribution that is compatible with OpenStack. deduplication The process of finding duplicate data at the disk block, file, and/or object level to minimize storage use—currently unsupported within OpenStack. default panel The default panel that is displayed when a user accesses the horizon dashboard. default tenant New users are assigned to this tenant if no tenant is specified when a user is created. default token An Identity service token that is not associated with a specific tenant and is exchanged for a scoped token. delayed delete An option within Image service so that an image is deleted after a predefined number of seconds instead of immediately. delivery mode Setting for the Compute RabbitMQ message delivery mode; can be set to either transient or persistent. denial of service (DoS) Denial of service (DoS) is a short form for denial-of-service attack. This is a malicious attempt to prevent legitimate users from using a service. deprecated auth An option within Compute that enables administrators to create and manage users through the ``nova-manage`` command as opposed to using the Identity service. Designate Code name for the DNS service project for OpenStack. Desktop-as-a-Service A platform that provides a suite of desktop environments that users access to receive a desktop experience from any location. This may provide general use, development, or even homogeneous testing environments. developer One of the default roles in the Compute RBAC system and the default role assigned to a new user. device ID Maps Object Storage partitions to physical storage devices. device weight Distributes partitions proportionately across Object Storage devices based on the storage capacity of each device. DevStack Community project that uses shell scripts to quickly build complete OpenStack development environments. DHCP Dynamic Host Configuration Protocol. A network protocol that configures devices that are connected to a network so that they can communicate on that network by using the Internet Protocol (IP). The protocol is implemented in a client-server model where DHCP clients request configuration data, such as an IP address, a default route, and one or more DNS server addresses from a DHCP server. DHCP agent OpenStack Networking agent that provides DHCP services for virtual networks. Diablo A grouped release of projects related to OpenStack that came out in the fall of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), Object Storage (swift 1.4.3), and the Image service (glance). Diablo is the code name for the fourth release of OpenStack. The design summit took place in in the Bay Area near Santa Clara, California, US and Diablo is a nearby city. direct consumer An element of the Compute RabbitMQ that comes to life when a RPC call is executed. It connects to a direct exchange through a unique exclusive queue, sends the message, and terminates. direct exchange A routing table that is created within the Compute RabbitMQ during RPC calls; one is created for each RPC call that is invoked. direct publisher Element of RabbitMQ that provides a response to an incoming MQ message. disassociate The process of removing the association between a floating IP address and fixed IP and thus returning the floating IP address to the address pool. disk encryption The ability to encrypt data at the file system, disk partition, or whole-disk level. Supported within Compute VMs. disk format The underlying format that a disk image for a VM is stored as within the Image service back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on. dispersion In Object Storage, tools to test and ensure dispersion of objects and containers to ensure fault tolerance. distributed virtual router (DVR) Mechanism for highly-available multi-host routing when using OpenStack Networking (neutron). Django A web framework used extensively in horizon. DNS Domain Name System. A hierarchical and distributed naming system for computers, services, and resources connected to the Internet or a private network. Associates a human-friendly names to IP addresses. DNS record A record that specifies information about a particular domain and belongs to the domain. DNS service OpenStack project that provides scalable, on demand, self service access to authoritative DNS services, in a technology-agnostic manner. The code name for the project is designate. dnsmasq Daemon that provides DNS, DHCP, BOOTP, and TFTP services for virtual networks. domain An Identity API v3 entity. Represents a collection of projects, groups and users that defines administrative boundaries for managing OpenStack Identity entities. On the Internet, separates a website from other sites. Often, the domain name has two or more parts that are separated by dots. For example, yahoo.com, usa.gov, harvard.edu, or mail.yahoo.com. Also, a domain is an entity or container of all DNS-related information containing one or more records. Domain Name System (DNS) A system by which Internet domain name-to-address and address-to-name resolutions are determined. DNS helps navigate the Internet by translating the IP address into an address that is easier to remember. For example, translating 111.111.111.1 into www.yahoo.com. All domains and their components, such as mail servers, utilize DNS to resolve to the appropriate locations. DNS servers are usually set up in a master-slave relationship such that failure of the master invokes the slave. DNS servers might also be clustered or replicated such that changes made to one DNS server are automatically propagated to other active servers. In Compute, the support that enables associating DNS entries with floating IP addresses, nodes, or cells so that hostnames are consistent across reboots. download The transfer of data, usually in the form of files, from one computer to another. DRTM Dynamic root of trust measurement. durable exchange The Compute RabbitMQ message exchange that remains active when the server restarts. durable queue A Compute RabbitMQ message queue that remains active when the server restarts. Dynamic Host Configuration Protocol (DHCP) A method to automatically configure networking for a host at boot time. Provided by both Networking and Compute. Dynamic HyperText Markup Language (DHTML) Pages that use HTML, JavaScript, and Cascading Style Sheets to enable users to interact with a web page or show simple animation. east-west traffic Network traffic between servers in the same cloud or data center. See also north-south traffic. EBS boot volume An Amazon EBS storage volume that contains a bootable VM image, currently unsupported in OpenStack. ebtables Filtering tool for a Linux bridging firewall, enabling filtering of network traffic passing through a Linux bridge. Used in Compute along with arptables, iptables, and ip6tables to ensure isolation of network communications. EC2 The Amazon commercial compute product, similar to Compute. EC2 access key Used along with an EC2 secret key to access the Compute EC2 API. EC2 API OpenStack supports accessing the Amazon EC2 API through Compute. EC2 Compatibility API A Compute component that enables OpenStack to communicate with Amazon EC2. EC2 secret key Used along with an EC2 access key when communicating with the Compute EC2 API; used to digitally sign each request. Elastic Block Storage (EBS) The Amazon commercial block storage product. encryption OpenStack supports encryption technologies such as HTTPS, SSH, SSL, TLS, digital certificates, and data encryption. endpoint See API endpoint. endpoint registry Alternative term for an Identity service catalog. encapsulation The practice of placing one packet type within another for the purposes of abstracting or securing data. Examples include GRE, MPLS, or IPsec. endpoint template A list of URL and port number endpoints that indicate where a service, such as Object Storage, Compute, Identity, and so on, can be accessed. entity Any piece of hardware or software that wants to connect to the network services provided by Networking, the network connectivity service. An entity can make use of Networking by implementing a VIF. ephemeral image A VM image that does not save changes made to its volumes and reverts them to their original state after the instance is terminated. ephemeral volume Volume that does not save the changes made to it and reverts to its original state when the current user relinquishes control. Essex A grouped release of projects related to OpenStack that came out in April 2012, the fifth release of OpenStack. It included Compute (nova 2012.1), Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and Dashboard (horizon). Essex is the code name for the fifth release of OpenStack. The design summit took place in Boston, Massachusetts, US and Essex is a nearby city. ESXi An OpenStack-supported hypervisor. ETag MD5 hash of an object within Object Storage, used to ensure data integrity. euca2ools A collection of command-line tools for administering VMs; most are compatible with OpenStack. Eucalyptus Kernel Image (EKI) Used along with an ERI to create an EMI. Eucalyptus Machine Image (EMI) VM image container format supported by Image service. Eucalyptus Ramdisk Image (ERI) Used along with an EKI to create an EMI. evacuate The process of migrating one or all virtual machine (VM) instances from one host to another, compatible with both shared storage live migration and block migration. exchange Alternative term for a RabbitMQ message exchange. exchange type A routing algorithm in the Compute RabbitMQ. exclusive queue Connected to by a direct consumer in RabbitMQ—Compute, the message can be consumed only by the current connection. extended attributes (xattr) File system option that enables storage of additional information beyond owner, group, permissions, modification time, and so on. The underlying Object Storage file system must support extended attributes. extension Alternative term for an API extension or plug-in. In the context of Identity service, this is a call that is specific to the implementation, such as adding support for OpenID. external network A network segment typically used for instance Internet access. extra specs Specifies additional requirements when Compute determines where to start a new instance. Examples include a minimum amount of network bandwidth or a GPU. FakeLDAP An easy method to create a local LDAP directory for testing Identity and Compute. Requires Redis. fan-out exchange Within RabbitMQ and Compute, it is the messaging interface that is used by the scheduler service to receive capability messages from the compute, volume, and network nodes. federated identity A method to establish trusts between identity providers and the OpenStack cloud. Fedora A Linux distribution compatible with OpenStack. Fibre Channel Storage protocol similar in concept to TCP/IP; encapsulates SCSI commands and data. Fibre Channel over Ethernet (FCoE) The fibre channel protocol tunneled within Ethernet. fill-first scheduler The Compute scheduling method that attempts to fill a host with VMs rather than starting new VMs on a variety of hosts. filter The step in the Compute scheduling process when hosts that cannot run VMs are eliminated and not chosen. firewall Used to restrict communications between hosts and/or nodes, implemented in Compute using iptables, arptables, ip6tables, and ebtables. FWaaS A Networking extension that provides perimeter firewall functionality. fixed IP address An IP address that is associated with the same instance each time that instance boots, is generally not accessible to end users or the public Internet, and is used for management of the instance. Flat Manager The Compute component that gives IP addresses to authorized nodes and assumes DHCP, DNS, and routing configuration and services are provided by something else. flat mode injection A Compute networking method where the OS network configuration information is injected into the VM image before the instance starts. flat network Virtual network type that uses neither VLANs nor tunnels to segregate tenant traffic. Each flat network typically requires a separate underlying physical interface defined by bridge mappings. However, a flat network can contain multiple subnets. FlatDHCP Manager The Compute component that provides dnsmasq (DHCP, DNS, BOOTP, TFTP) and radvd (routing) services. flavor Alternative term for a VM instance type. flavor ID UUID for each Compute or Image service VM flavor or instance type. floating IP address An IP address that a project can associate with a VM so that the instance has the same public IP address each time that it boots. You create a pool of floating IP addresses and assign them to instances as they are launched to maintain a consistent IP address for maintaining DNS assignment. Folsom A grouped release of projects related to OpenStack that came out in the fall of 2012, the sixth release of OpenStack. It includes Compute (nova), Object Storage (swift), Identity (keystone), Networking (neutron), Image service (glance), and Volumes or Block Storage (cinder). Folsom is the code name for the sixth release of OpenStack. The design summit took place in San Francisco, California, US and Folsom is a nearby city. FormPost Object Storage middleware that uploads (posts) an image through a form on a web page. freezer OpenStack project that provides backup restore and disaster recovery as a service. front end The point where a user interacts with a service; can be an API endpoint, the horizon dashboard, or a command-line tool. gateway An IP address, typically assigned to a router, that passes network traffic between different networks. generic receive offload (GRO) Feature of certain network interface drivers that combines many smaller received packets into a large packet before delivery to the kernel IP stack. generic routing encapsulation (GRE) Protocol that encapsulates a wide variety of network layer protocols inside virtual point-to-point links. glance A core project that provides the OpenStack Image service. glance API server Processes client requests for VMs, updates Image service metadata on the registry server, and communicates with the store adapter to upload VM images from the back-end store. glance registry Alternative term for the Image service image registry. global endpoint template The Identity service endpoint template that contains services available to all tenants. GlusterFS A file system designed to aggregate NAS hosts, compatible with OpenStack. golden image A method of operating system installation where a finalized disk image is created and then used by all nodes without modification. Governance service OpenStack project to provide Governance-as-a-Service across any collection of cloud services in order to monitor, enforce, and audit policy over dynamic infrastructure. The code name for the project is congress. Graphic Interchange Format (GIF) A type of image file that is commonly used for animated images on web pages. Graphics Processing Unit (GPU) Choosing a host based on the existence of a GPU is currently unsupported in OpenStack. Green Threads The cooperative threading model used by Python; reduces race conditions and only context switches when specific library calls are made. Each OpenStack service is its own thread. Grizzly The code name for the seventh release of OpenStack. The design summit took place in San Diego, California, US and Grizzly is an element of the state flag of California. Group An Identity v3 API entity. Represents a collection of users that is owned by a specific domain. guest OS An operating system instance running under the control of a hypervisor. Hadoop Apache Hadoop is an open source software framework that supports data-intensive distributed applications. Hadoop Distributed File System (HDFS) A distributed, highly fault-tolerant file system designed to run on low-cost commodity hardware. handover An object state in Object Storage where a new replica of the object is automatically created due to a drive failure. hard reboot A type of reboot where a physical or virtual power button is pressed as opposed to a graceful, proper shutdown of the operating system. Havana The code name for the eighth release of OpenStack. The design summit took place in Portland, Oregon, US and Havana is an unincorporated community in Oregon. heat An integrated project that aims to orchestrate multiple cloud applications for OpenStack. Heat Orchestration Template (HOT) Heat input in the format native to OpenStack. health monitor Determines whether back-end members of a VIP pool can process a request. A pool can have several health monitors associated with it. When a pool has several monitors associated with it, all monitors check each member of the pool. All monitors must declare a member to be healthy for it to stay active. high availability (HA) A high availability system design approach and associated service implementation ensures that a prearranged level of operational performance will be met during a contractual measurement period. High availability systems seeks to minimize system downtime and data loss. horizon OpenStack project that provides a dashboard, which is a web interface. horizon plug-in A plug-in for the OpenStack dashboard (horizon). host A physical computer, not a VM instance (node). host aggregate A method to further subdivide availability zones into hypervisor pools, a collection of common hosts. Host Bus Adapter (HBA) Device plugged into a PCI slot, such as a fibre channel or network card. hybrid cloud A hybrid cloud is a composition of two or more clouds (private, community or public) that remain distinct entities but are bound together, offering the benefits of multiple deployment models. Hybrid cloud can also mean the ability to connect colocation, managed and/or dedicated services with cloud resources. Hyper-V One of the hypervisors supported by OpenStack. hyperlink Any kind of text that contains a link to some other site, commonly found in documents where clicking on a word or words opens up a different website. Hypertext Transfer Protocol (HTTP) An application protocol for distributed, collaborative, hypermedia information systems. It is the foundation of data communication for the World Wide Web. Hypertext is structured text that uses logical links (hyperlinks) between nodes containing text. HTTP is the protocol to exchange or transfer hypertext. Hypertext Transfer Protocol Secure (HTTPS) An encrypted communications protocol for secure communication over a computer network, with especially wide deployment on the Internet. Technically, it is not a protocol in and of itself; rather, it is the result of simply layering the Hypertext Transfer Protocol (HTTP) on top of the TLS or SSL protocol, thus adding the security capabilities of TLS or SSL to standard HTTP communications. most OpenStack API endpoints and many inter-component communications support HTTPS communication. hypervisor Software that arbitrates and controls VM access to the actual underlying hardware. hypervisor pool A collection of hypervisors grouped together through host aggregates. IaaS Infrastructure-as-a-Service. IaaS is a provisioning model in which an organization outsources physical components of a data center, such as storage, hardware, servers, and networking components. A service provider owns the equipment and is responsible for housing, operating and maintaining it. The client typically pays on a per-use basis. IaaS is a model for providing cloud services. Icehouse The code name for the ninth release of OpenStack. The design summit took place in Hong Kong and Ice House is a street in that city. ICMP Internet Control Message Protocol, used by network devices for control messages. For example, :command:`ping` uses ICMP to test connectivity. ID number Unique numeric ID associated with each user in Identity, conceptually similar to a Linux or LDAP UID. Identity API Alternative term for the Identity service API. Identity back end The source used by Identity service to retrieve user information; an OpenLDAP server, for example. identity provider A directory service, which allows users to login with a user name and password. It is a typical source of authentication tokens. Identity The OpenStack core project that provides a central directory of users mapped to the OpenStack services they can access. It also registers endpoints for OpenStack services. It acts as a common authentication system. The project name of Identity is keystone. Identity service API The API used to access the OpenStack Identity service provided through keystone. IDS Intrusion Detection System. image A collection of files for a specific operating system (OS) that you use to create or rebuild a server. OpenStack provides pre-built images. You can also create custom images, or snapshots, from servers that you have launched. Custom images can be used for data backups or as ""gold"" images for additional servers. Image API The Image service API endpoint for management of VM images. image cache Used by Image service to obtain images on the local host rather than re-downloading them from the image server each time one is requested. image ID Combination of a URI and UUID used to access Image service VM images through the image API. image membership A list of tenants that can access a given VM image within Image service. image owner The tenant who owns an Image service virtual machine image. image registry A list of VM images that are available through Image service. Image service An OpenStack core project that provides discovery, registration, and delivery services for disk and server images. The project name of the Image service is glance. Image service API Alternative name for the glance image API. image status The current status of a VM image in Image service, not to be confused with the status of a running instance. image store The back-end store used by Image service to store VM images, options include Object Storage, local file system, S3, or HTTP. image UUID UUID used by Image service to uniquely identify each VM image. incubated project A community project may be elevated to this status and is then promoted to a core project. ingress filtering The process of filtering incoming network traffic. Supported by Compute. INI The OpenStack configuration files use an INI format to describe options and their values. It consists of sections and key value pairs. injection The process of putting a file into a virtual machine image before the instance is started. instance A running VM, or a VM in a known state such as suspended, that can be used like a hardware server. instance ID Alternative term for instance UUID. instance state The current state of a guest VM image. instance tunnels network A network segment used for instance traffic tunnels between compute nodes and the network node. instance type Describes the parameters of the various virtual machine images that are available to users; includes parameters such as CPU, storage, and memory. Alternative term for flavor. instance type ID Alternative term for a flavor ID. instance UUID Unique ID assigned to each guest VM instance. interface A physical or virtual device that provides connectivity to another device or medium. interface ID Unique ID for a Networking VIF or vNIC in the form of a UUID. Internet protocol (IP) Principal communications protocol in the internet protocol suite for relaying datagrams across network boundaries. Internet Service Provider (ISP) Any business that provides Internet access to individuals or businesses. Internet Small Computer System Interface (iSCSI) Storage protocol that encapsulates SCSI frames for transport over IP networks. ironic OpenStack project that provisions bare metal, as opposed to virtual, machines. IOPS IOPS (Input/Output Operations Per Second) are a common performance measurement used to benchmark computer storage devices like hard disk drives, solid state drives, and storage area networks. IP address Number that is unique to every computer system on the Internet. Two versions of the Internet Protocol (IP) are in use for addresses: IPv4 and IPv6. IP Address Management (IPAM) The process of automating IP address allocation, deallocation, and management. Currently provided by Compute, melange, and Networking. IPL Initial Program Loader. IPMI Intelligent Platform Management Interface. IPMI is a standardized computer system interface used by system administrators for out-of-band management of computer systems and monitoring of their operation. In layman's terms, it is a way to manage a computer using a direct network connection, whether it is turned on or not; connecting to the hardware rather than an operating system or login shell. ip6tables Tool used to set up, maintain, and inspect the tables of IPv6 packet filter rules in the Linux kernel. In OpenStack Compute, ip6tables is used along with arptables, ebtables, and iptables to create firewalls for both nodes and VMs. ipset Extension to iptables that allows creation of firewall rules that match entire ""sets"" of IP addresses simultaneously. These sets reside in indexed data structures to increase efficiency, particularly on systems with a large quantity of rules. iptables Used along with arptables and ebtables, iptables create firewalls in Compute. iptables are the tables provided by the Linux kernel firewall (implemented as different Netfilter modules) and the chains and rules it stores. Different kernel modules and programs are currently used for different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables to ARP, and ebtables to Ethernet frames. Requires root privilege to manipulate. IQN iSCSI Qualified Name (IQN) is the format most commonly used for iSCSI names, which uniquely identify nodes in an iSCSI network. All IQNs follow the pattern iqn.yyyy-mm.domain:identifier, where 'yyyy-mm' is the year and month in which the domain was registered, 'domain' is the reversed domain name of the issuing organization, and 'identifier' is an optional string which makes each IQN under the same domain unique. For example, 'iqn.2015-10.org.openstack.408ae959bce1'. iSCSI The SCSI disk protocol tunneled within Ethernet, supported by Compute, Object Storage, and Image service. ISO9660 One of the VM image disk formats supported by Image service. itsec A default role in the Compute RBAC system that can quarantine an instance in any project. Java A programming language that is used to create systems that involve more than one computer by way of a network. JavaScript A scripting language that is used to build web pages. JavaScript Object Notation (JSON) One of the supported response formats in OpenStack. Jenkins Tool used to run jobs automatically for OpenStack development. jumbo frame Feature in modern Ethernet networks that supports frames up to approximately 9000 bytes. Juno The code name for the tenth release of OpenStack. The design summit took place in Atlanta, Georgia, US and Juno is an unincorporated community in Georgia. Kerberos A network authentication protocol which works on the basis of tickets. Kerberos allows nodes communication over a non-secure network, and allows nodes to prove their identity to one another in a secure manner. kernel-based VM (KVM) An OpenStack-supported hypervisor. KVM is a full virtualization solution for Linux on x86 hardware containing virtualization extensions (Intel VT or AMD-V), ARM, IBM Power, and IBM zSeries. It consists of a loadable kernel module, that provides the core virtualization infrastructure and a processor specific module. Key management service OpenStack project that produces a secret storage and generation system capable of providing key management for services wishing to enable encryption features. The code name of the project is barbican. keystone The project that provides OpenStack Identity services. Kickstart A tool to automate system configuration and installation on Red Hat, Fedora, and CentOS-based Linux distributions. Kilo The code name for the eleventh release of OpenStack. The design summit took place in Paris, France. Due to delays in the name selection, the release was known only as K. Because ``k`` is the unit symbol for kilo and the reference artifact is stored near Paris in the Pavillon de Breteuil in Sèvres, the community chose Kilo as the release name. large object An object within Object Storage that is larger than 5 GB. Launchpad The collaboration site for OpenStack. Layer-2 network Term used in the OSI network architecture for the data link layer. The data link layer is responsible for media access control, flow control and detecting and possibly correcting errors that may occur in the physical layer. Layer-3 network Term used in the OSI network architecture for the network layer. The network layer is responsible for packet forwarding including routing from one node to another. Layer-2 (L2) agent OpenStack Networking agent that provides layer-2 connectivity for virtual networks. Layer-3 (L3) agent OpenStack Networking agent that provides layer-3 (routing) services for virtual networks. Liberty The code name for the twelfth release of OpenStack. The design summit took place in Vancouver, Canada and Liberty is the name of a village in the Canadian province of Saskatchewan. libvirt Virtualization API library used by OpenStack to interact with many of its supported hypervisors. Lightweight Directory Access Protocol (LDAP) An application protocol for accessing and maintaining distributed directory information services over an IP network. Linux bridge Software that enables multiple VMs to share a single physical NIC within Compute. Linux Bridge neutron plug-in Enables a Linux bridge to understand a Networking port, interface attachment, and other abstractions. Linux containers (LXC) An OpenStack-supported hypervisor. live migration The ability within Compute to move running virtual machine instances from one host to another with only a small service interruption during switchover. load balancer A load balancer is a logical device that belongs to a cloud account. It is used to distribute workloads between multiple back-end systems or services, based on the criteria defined as part of its configuration. load balancing The process of spreading client requests between two or more nodes to improve performance and availability. LBaaS Enables Networking to distribute incoming requests evenly between designated instances. Logical Volume Manager (LVM) Provides a method of allocating space on mass-storage devices that is more flexible than conventional partitioning schemes. magnum Code name for the OpenStack project that provides the Containers Service. management API Alternative term for an admin API. management network A network segment used for administration, not accessible to the public Internet. manager Logical groupings of related code, such as the Block Storage volume manager or network manager. manifest Used to track segments of a large object within Object Storage. manifest object A special Object Storage object that contains the manifest for a large object. manila OpenStack project that provides shared file systems as service to applications. maximum transmission unit (MTU) Maximum frame or packet size for a particular network medium. Typically 1500 bytes for Ethernet networks. mechanism driver A driver for the Modular Layer 2 (ML2) neutron plug-in that provides layer-2 connectivity for virtual instances. A single OpenStack installation can use multiple mechanism drivers. melange Project name for OpenStack Network Information Service. To be merged with Networking. membership The association between an Image service VM image and a tenant. Enables images to be shared with specified tenants. membership list A list of tenants that can access a given VM image within Image service. memcached A distributed memory object caching system that is used by Object Storage for caching. memory overcommit The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as RAM overcommit. message broker The software package used to provide AMQP messaging capabilities within Compute. Default package is RabbitMQ. message bus The main virtual communication line used by all AMQP messages for inter-cloud communications within Compute. message queue Passes requests from clients to the appropriate workers and returns the output to the client after the job completes. Message service OpenStack project that aims to produce an OpenStack messaging service that affords a variety of distributed application patterns in an efficient, scalable and highly-available manner, and to create and maintain associated Python libraries and documentation. The code name for the project is zaqar. Metadata agent OpenStack Networking agent that provides metadata services for instances. Meta-Data Server (MDS) Stores CephFS metadata. migration The process of moving a VM instance from one host to another. mistral OpenStack project that provides the Workflow service. Mitaka The code name for the thirteenth release of OpenStack. The design summit took place in Tokyo, Japan. Mitaka is a city in Tokyo. monasca OpenStack project that provides a Monitoring service. multi-host High-availability mode for legacy (nova) networking. Each compute node handles NAT and DHCP and acts as a gateway for all of the VMs on it. A networking failure on one compute node doesn't affect VMs on other compute nodes. multinic Facility in Compute that allows each virtual machine instance to have more than one VIF connected to it. murano OpenStack project that provides an Application catalog. Modular Layer 2 (ML2) neutron plug-in Can concurrently use multiple layer-2 networking technologies, such as 802.1Q and VXLAN, in Networking. Monitor (LBaaS) LBaaS feature that provides availability monitoring using the ``ping`` command, TCP, and HTTP/HTTPS GET. Monitor (Mon) A Ceph component that communicates with external clients, checks data state and consistency, and performs quorum functions. Monitoring The OpenStack project that provides a multi-tenant, highly scalable, performant, fault-tolerant Monitoring-as-a-Service solution for metrics, complex event processing, and logging. It builds an extensible platform for advanced monitoring services that can be used by both operators and tenants to gain operational insight and visibility, ensuring availability and stability. The project name is monasca. multi-factor authentication Authentication method that uses two or more credentials, such as a password and a private key. Currently not supported in Identity. MultiNic Facility in Compute that enables a virtual machine instance to have more than one VIF connected to it. Nebula Released as open source by NASA in 2010 and is the basis for Compute. netadmin One of the default roles in the Compute RBAC system. Enables the user to allocate publicly accessible IP addresses to instances and change firewall rules. NetApp volume driver Enables Compute to communicate with NetApp storage devices through the NetApp OnCommand Provisioning Manager. network A virtual network that provides connectivity between entities. For example, a collection of virtual ports that share network connectivity. In Networking terminology, a network is always a layer-2 network. NAT Network Address Translation; Process of modifying IP address information while in transit. Supported by Compute and Networking. network controller A Compute daemon that orchestrates the network configuration of nodes, including IP addresses, VLANs, and bridging. Also manages routing for both public and private networks. Network File System (NFS) A method for making file systems available over the network. Supported by OpenStack. network ID Unique ID assigned to each network segment within Networking. Same as network UUID. network manager The Compute component that manages various network components, such as firewall rules, IP address allocation, and so on. network namespace Linux kernel feature that provides independent virtual networking instances on a single host with separate routing tables and interfaces. Similar to virtual routing and forwarding (VRF) services on physical network equipment. network node Any compute node that runs the network worker daemon. network segment Represents a virtual, isolated OSI layer-2 subnet in Networking. Newton The code name for the fourteenth release of OpenStack. The design summit will take place in Austin, Texas, US. The release is named after ""Newton House"" which is located at 1013 E. Ninth St., Austin, TX. which is listed on the National Register of Historic Places. NTP Network Time Protocol; Method of keeping a clock for a host or node correct via communication with a trusted, accurate time source. network UUID Unique ID for a Networking network segment. network worker The ``nova-network`` worker daemon; provides services such as giving an IP address to a booting nova instance. Networking A core OpenStack project that provides a network connectivity abstraction layer to OpenStack Compute. The project name of Networking is neutron. Networking API API used to access OpenStack Networking. Provides an extensible architecture to enable custom plug-in creation. neutron A core OpenStack project that provides a network connectivity abstraction layer to OpenStack Compute. neutron API An alternative name for Networking API. neutron manager Enables Compute and Networking integration, which enables Networking to perform network management for guest VMs. neutron plug-in Interface within Networking that enables organizations to create custom plug-ins for advanced features, such as QoS, ACLs, or IDS. Nexenta volume driver Provides support for NexentaStor devices in Compute. No ACK Disables server-side message acknowledgment in the Compute RabbitMQ. Increases performance but decreases reliability. node A VM instance that runs on a host. non-durable exchange Message exchange that is cleared when the service restarts. Its data is not written to persistent storage. non-durable queue Message queue that is cleared when the service restarts. Its data is not written to persistent storage. non-persistent volume Alternative term for an ephemeral volume. north-south traffic Network traffic between a user or client (north) and a server (south), or traffic into the cloud (south) and out of the cloud (north). See also east-west traffic. nova OpenStack project that provides compute services. Nova API Alternative term for the Compute API. nova-network A Compute component that manages IP address allocation, firewalls, and other network-related tasks. This is the legacy networking option and an alternative to Networking. object A BLOB of data held by Object Storage; can be in any format. object auditor Opens all objects for an object server and verifies the MD5 hash, size, and metadata for each object. object expiration A configurable option within Object Storage to automatically delete objects after a specified amount of time has passed or a certain date is reached. object hash Uniquely ID for an Object Storage object. object path hash Used by Object Storage to determine the location of an object in the ring. Maps objects to partitions. object replicator An Object Storage component that copies an object to remote partitions for fault tolerance. object server An Object Storage component that is responsible for managing objects. Object Storage The OpenStack core project that provides eventually consistent and redundant storage and retrieval of fixed digital content. The project name of OpenStack Object Storage is swift. Object Storage API API used to access OpenStack Object Storage. Object Storage Device (OSD) The Ceph storage daemon. object versioning Allows a user to set a flag on an Object Storage container so that all objects within the container are versioned. Ocata The code name for the fifteenth release of OpenStack. The design summit will take place in Barcelona, Spain. Ocata is a beach north of Barcelona. Oldie Term for an Object Storage process that runs for a long time. Can indicate a hung process. Open Cloud Computing Interface (OCCI) A standardized interface for managing compute, data, and network resources, currently unsupported in OpenStack. Open Virtualization Format (OVF) Standard for packaging VM images. Supported in OpenStack. Open vSwitch Open vSwitch is a production quality, multilayer virtual switch licensed under the open source Apache 2.0 license. It is designed to enable massive network automation through programmatic extension, while still supporting standard management interfaces and protocols (for example NetFlow, sFlow, SPAN, RSPAN, CLI, LACP, 802.1ag). Open vSwitch (OVS) agent Provides an interface to the underlying Open vSwitch service for the Networking plug-in. Open vSwitch neutron plug-in Provides support for Open vSwitch in Networking. OpenLDAP An open source LDAP server. Supported by both Compute and Identity. OpenStack OpenStack is a cloud operating system that controls large pools of compute, storage, and networking resources throughout a data center, all managed through a dashboard that gives administrators control while empowering their users to provision resources through a web interface. OpenStack is an open source project licensed under the Apache License 2.0. OpenStack code name Each OpenStack release has a code name. Code names ascend in alphabetical order: Austin, Bexar, Cactus, Diablo, Essex, Folsom, Grizzly, Havana, Icehouse, Juno, Kilo, Liberty, and Mitaka. Code names are cities or counties near where the corresponding OpenStack design summit took place. An exception, called the Waldon exception, is granted to elements of the state flag that sound especially cool. Code names are chosen by popular vote. openSUSE A Linux distribution that is compatible with OpenStack. operator The person responsible for planning and maintaining an OpenStack installation. Orchestration An integrated project that orchestrates multiple cloud applications for OpenStack. The project name of Orchestration is heat. orphan In the context of Object Storage, this is a process that is not terminated after an upgrade, restart, or reload of the service. Oslo OpenStack project that produces a set of Python libraries containing code shared by OpenStack projects. parent cell If a requested resource, such as CPU time, disk storage, or memory, is not available in the parent cell, the request is forwarded to associated child cells. partition A unit of storage within Object Storage used to store objects. It exists on top of devices and is replicated for fault tolerance. partition index Contains the locations of all Object Storage partitions within the ring. partition shift value Used by Object Storage to determine which partition data should reside on. path MTU discovery (PMTUD) Mechanism in IP networks to detect end-to-end MTU and adjust packet size accordingly. pause A VM state where no changes occur (no changes in memory, network communications stop, etc); the VM is frozen but not shut down. PCI passthrough Gives guest VMs exclusive access to a PCI device. Currently supported in OpenStack Havana and later releases. persistent message A message that is stored both in memory and on disk. The message is not lost after a failure or restart. persistent volume Changes to these types of disk volumes are saved. personality file A file used to customize a Compute instance. It can be used to inject SSH keys or a specific network configuration. Platform-as-a-Service (PaaS) Provides to the consumer the ability to deploy applications through a programming language or tools supported by the cloud platform provider. An example of Platform-as-a-Service is an Eclipse/Java programming platform provided with no downloads required. plug-in Software component providing the actual implementation for Networking APIs, or for Compute APIs, depending on the context. policy service Component of Identity that provides a rule-management interface and a rule-based authorization engine. pool A logical set of devices, such as web servers, that you group together to receive and process traffic. The load balancing function chooses which member of the pool handles the new requests or connections received on the VIP address. Each VIP has one pool. pool member An application that runs on the back-end server in a load-balancing system. port A virtual network port within Networking; VIFs / vNICs are connected to a port. port UUID Unique ID for a Networking port. preseed A tool to automate system configuration and installation on Debian-based Linux distributions. private image An Image service VM image that is only available to specified tenants. private IP address An IP address used for management and administration, not available to the public Internet. private network The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. A private network interface can be a flat or VLAN network interface. A flat network interface is controlled by the flat_interface with flat managers. A VLAN network interface is controlled by the ``vlan_interface`` option with VLAN managers. project Projects represent the base unit of “ownership” in OpenStack, in that all resources in OpenStack should be owned by a specific project. In OpenStack Identity, a project must be owned by a specific domain. project ID User-defined alphanumeric string in Compute; the name of a project. project VPN Alternative term for a cloudpipe. promiscuous mode Causes the network interface to pass all traffic it receives to the host rather than passing only the frames addressed to it. protected property Generally, extra properties on an Image service image to which only cloud administrators have access. Limits which user roles can perform CRUD operations on that property. The cloud administrator can configure any image property as protected. provider An administrator who has access to all hosts and instances. proxy node A node that provides the Object Storage proxy service. proxy server Users of Object Storage interact with the service through the proxy server, which in turn looks up the location of the requested data within the ring and returns the results to the user. public API An API endpoint used for both service-to-service communication and end-user interactions. public image An Image service VM image that is available to all tenants. public IP address An IP address that is accessible to end-users. public key authentication Authentication method that uses keys rather than passwords. public network The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. The public network interface is controlled by the ``public_interface`` option. Puppet An operating system configuration-management tool supported by OpenStack. Python Programming language used extensively in OpenStack. QEMU Copy On Write 2 (QCOW2) One of the VM image disk formats supported by Image service. Qpid Message queue software supported by OpenStack; an alternative to RabbitMQ. quarantine If Object Storage finds objects, containers, or accounts that are corrupt, they are placed in this state, are not replicated, cannot be read by clients, and a correct copy is re-replicated. Quick EMUlator (QEMU) QEMU is a generic and open source machine emulator and virtualizer. One of the hypervisors supported by OpenStack, generally used for development purposes. quota In Compute and Block Storage, the ability to set resource limits on a per-project basis. RabbitMQ The default message queue software used by OpenStack. Rackspace Cloud Files Released as open source by Rackspace in 2010; the basis for Object Storage. RADOS Block Device (RBD) Ceph component that enables a Linux block device to be striped over multiple distributed data stores. radvd The router advertisement daemon, used by the Compute VLAN manager and FlatDHCP manager to provide routing services for VM instances. rally OpenStack project that provides the Benchmark service. RAM filter The Compute setting that enables or disables RAM overcommitment. RAM overcommit The ability to start new VM instances based on the actual memory usage of a host, as opposed to basing the decision on the amount of RAM each running instance thinks it has available. Also known as memory overcommit. rate limit Configurable option within Object Storage to limit database writes on a per-account and/or per-container basis. raw One of the VM image disk formats supported by Image service; an unstructured disk image. rebalance The process of distributing Object Storage partitions across all drives in the ring; used during initial ring creation and after ring reconfiguration. reboot Either a soft or hard reboot of a server. With a soft reboot, the operating system is signaled to restart, which enables a graceful shutdown of all processes. A hard reboot is the equivalent of power cycling the server. The virtualization platform should ensure that the reboot action has completed successfully, even in cases in which the underlying domain/VM is paused or halted/stopped. rebuild Removes all data on the server and replaces it with the specified image. Server ID and IP addresses remain the same. Recon An Object Storage component that collects meters. record Belongs to a particular domain and is used to specify information about the domain. There are several types of DNS records. Each record type contains particular information used to describe the purpose of that record. Examples include mail exchange (MX) records, which specify the mail server for a particular domain; and name server (NS) records, which specify the authoritative name servers for a domain. record ID A number within a database that is incremented each time a change is made. Used by Object Storage when replicating. Red Hat Enterprise Linux (RHEL) A Linux distribution that is compatible with OpenStack. reference architecture A recommended architecture for an OpenStack cloud. region A discrete OpenStack environment with dedicated API endpoints that typically shares only the Identity (keystone) with other regions. registry Alternative term for the Image service registry. registry server An Image service that provides VM image metadata information to clients. Reliable, Autonomic Distributed Object Store (RADOS) A collection of components that provides object storage within Ceph. Similar to OpenStack Object Storage. Remote Procedure Call (RPC) The method used by the Compute RabbitMQ for intra-service communications. replica Provides data redundancy and fault tolerance by creating copies of Object Storage objects, accounts, and containers so that they are not lost when the underlying storage fails. replica count The number of replicas of the data in an Object Storage ring. replication The process of copying data to a separate physical device for fault tolerance and performance. replicator The Object Storage back-end process that creates and manages object replicas. request ID Unique ID assigned to each request sent to Compute. rescue image A special type of VM image that is booted when an instance is placed into rescue mode. Allows an administrator to mount the file systems for an instance to correct the problem. resize Converts an existing server to a different flavor, which scales the server up or down. The original server is saved to enable rollback if a problem occurs. All resizes must be tested and explicitly confirmed, at which time the original server is removed. RESTful A kind of web service API that uses REST, or Representational State Transfer. REST is the style of architecture for hypermedia systems that is used for the World Wide Web. ring An entity that maps Object Storage data to partitions. A separate ring exists for each service, such as account, object, and container. ring builder Builds and manages rings within Object Storage, assigns partitions to devices, and pushes the configuration to other storage nodes. Role Based Access Control (RBAC) Provides a predefined list of actions that the user can perform, such as start or stop VMs, reset passwords, and so on. Supported in both Identity and Compute and can be configured using the horizon dashboard. role A personality that a user assumes to perform a specific set of operations. A role includes a set of rights and privileges. A user assuming that role inherits those rights and privileges. role ID Alphanumeric ID assigned to each Identity service role. rootwrap A feature of Compute that allows the unprivileged ""nova"" user to run a specified list of commands as the Linux root user. round-robin scheduler Type of Compute scheduler that evenly distributes instances among available hosts. router A physical or virtual network device that passes network traffic between different networks. routing key The Compute direct exchanges, fanout exchanges, and topic exchanges use this key to determine how to process a message; processing varies depending on exchange type. RPC driver Modular system that allows the underlying message queue software of Compute to be changed. For example, from RabbitMQ to ZeroMQ or Qpid. rsync Used by Object Storage to push object replicas. RXTX cap Absolute limit on the amount of network traffic a Compute VM instance can send and receive. RXTX quota Soft limit on the amount of network traffic a Compute VM instance can send and receive. S3 Object storage service by Amazon; similar in function to Object Storage, it can act as a back-end store for Image service VM images. sahara OpenStack project that provides a scalable data-processing stack and associated management interfaces. SAML assertion Contains information about a user as provided by the identity provider. It is an indication that a user has been authenticated. scheduler manager A Compute component that determines where VM instances should start. Uses modular design to support a variety of scheduler types. scoped token An Identity service API access token that is associated with a specific tenant. scrubber Checks for and deletes unused VMs; the component of Image service that implements delayed delete. secret key String of text known only by the user; used along with an access key to make requests to the Compute API. secure shell (SSH) Open source tool used to access remote hosts through an encrypted communications channel, SSH key injection is supported by Compute. security group A set of network traffic filtering rules that are applied to a Compute instance. segmented object An Object Storage large object that has been broken up into pieces. The re-assembled object is called a concatenated object. self-service For IaaS, ability for a regular (non-privileged) account to manage a virtual infrastructure component such as networks without involving an administrator. SELinux Linux kernel security module that provides the mechanism for supporting access control policies. senlin OpenStack project that provides a Clustering service. server Computer that provides explicit services to the client software running on that system, often managing a variety of computer operations. A server is a VM instance in the Compute system. Flavor and image are requisite elements when creating a server. server image Alternative term for a VM image. server UUID Unique ID assigned to each guest VM instance. service An OpenStack service, such as Compute, Object Storage, or Image service. Provides one or more endpoints through which users can access resources and perform operations. service catalog Alternative term for the Identity service catalog. service ID Unique ID assigned to each service that is available in the Identity service catalog. service provider A system that provides services to other system entities. In case of federated identity, OpenStack Identity is the service provider. service registration An Identity service feature that enables services, such as Compute, to automatically register with the catalog. service tenant Special tenant that contains all services that are listed in the catalog. service token An administrator-defined token used by Compute to communicate securely with the Identity service. session back end The method of storage used by horizon to track client sessions, such as local memory, cookies, a database, or memcached. session persistence A feature of the load-balancing service. It attempts to force subsequent connections to a service to be redirected to the same node as long as it is online. session storage A horizon component that stores and tracks client session information. Implemented through the Django sessions framework. share A remote, mountable file system in the context of the Shared File Systems. You can mount a share to, and access a share from, several hosts by several users at a time. share network An entity in the context of the Shared File Systems that encapsulates interaction with the Networking service. If the driver you selected runs in the mode requiring such kind of interaction, you need to specify the share network to create a share. Shared File Systems API A Shared File Systems service that provides a stable RESTful API. The service authenticates and routes requests throughout the Shared File Systems service. There is python-manilaclient to interact with the API. Shared File Systems service An OpenStack service that provides a set of services for management of shared file systems in a multi-tenant cloud environment. The service is similar to how OpenStack provides block-based storage management through the OpenStack Block Storage service project. With the Shared File Systems service, you can create a remote file system and mount the file system on your instances. You can also read and write data from your instances to and from your file system. The project name of the Shared File Systems service is manila. shared IP address An IP address that can be assigned to a VM instance within the shared IP group. Public IP addresses can be shared across multiple servers for use in various high-availability scenarios. When an IP address is shared to another server, the cloud network restrictions are modified to enable each server to listen to and respond on that IP address. You can optionally specify that the target server network configuration be modified. Shared IP addresses can be used with many standard heartbeat facilities, such as keepalive, that monitor for failure and manage IP failover. shared IP group A collection of servers that can share IPs with other members of the group. Any server in a group can share one or more public IPs with any other server in the group. With the exception of the first server in a shared IP group, servers must be launched into shared IP groups. A server may be a member of only one shared IP group. shared storage Block storage that is simultaneously accessible by multiple clients, for example, NFS. Sheepdog Distributed block storage system for QEMU, supported by OpenStack. Simple Cloud Identity Management (SCIM) Specification for managing identity in the cloud, currently unsupported by OpenStack. Single-root I/O Virtualization (SR-IOV) A specification that, when implemented by a physical PCIe device, enables it to appear as multiple separate PCIe devices. This enables multiple virtualized guests to share direct access to the physical device, offering improved performance over an equivalent virtual device. Currently supported in OpenStack Havana and later releases. Service Level Agreement (SLA) Contractual obligations that ensure the availability of a service. SmokeStack Runs automated tests against the core OpenStack API; written in Rails. snapshot A point-in-time copy of an OpenStack storage volume or image. Use storage volume snapshots to back up volumes. Use image snapshots to back up data, or as ""gold"" images for additional servers. soft reboot A controlled reboot where a VM instance is properly restarted through operating system commands. Software Development Lifecycle Automation service OpenStack project that aims to make cloud services easier to consume and integrate with application development process by automating the source-to-image process, and simplifying app-centric deployment. The project name is solum. SolidFire Volume Driver The Block Storage driver for the SolidFire iSCSI storage appliance. solum OpenStack project that provides a Software Development Lifecycle Automation service. SPICE The Simple Protocol for Independent Computing Environments (SPICE) provides remote desktop access to guest virtual machines. It is an alternative to VNC. SPICE is supported by OpenStack. spread-first scheduler The Compute VM scheduling algorithm that attempts to start a new VM on the host with the least amount of load. SQL-Alchemy An open source SQL toolkit for Python, used in OpenStack. SQLite A lightweight SQL database, used as the default persistent storage method in many OpenStack services. stack A set of OpenStack resources created and managed by the Orchestration service according to a given template (either an AWS CloudFormation template or a Heat Orchestration Template (HOT)). StackTach Community project that captures Compute AMQP communications; useful for debugging. static IP address Alternative term for a fixed IP address. StaticWeb WSGI middleware component of Object Storage that serves container data as a static web page. storage back end The method that a service uses for persistent storage, such as iSCSI, NFS, or local disk. storage node An Object Storage node that provides container services, account services, and object services; controls the account databases, container databases, and object storage. storage manager A XenAPI component that provides a pluggable interface to support a wide variety of persistent storage back ends. storage manager back end A persistent storage method supported by XenAPI, such as iSCSI or NFS. storage services Collective name for the Object Storage object services, container services, and account services. strategy Specifies the authentication source used by Image service or Identity. In the Database service, it refers to the extensions implemented for a data store. subdomain A domain within a parent domain. Subdomains cannot be registered. Subdomains enable you to delegate domains. Subdomains can themselves have subdomains, so third-level, fourth-level, fifth-level, and deeper levels of nesting are possible. subnet Logical subdivision of an IP network. SUSE Linux Enterprise Server (SLES) A Linux distribution that is compatible with OpenStack. suspend Alternative term for a paused VM instance. swap Disk-based virtual memory used by operating systems to provide more memory than is actually available on the system. swauth An authentication and authorization service for Object Storage, implemented through WSGI middleware; uses Object Storage itself as the persistent backing store. swift An OpenStack core project that provides object storage services. swift All in One (SAIO) Creates a full Object Storage development environment within a single VM. swift middleware Collective term for Object Storage components that provide additional functionality. swift proxy server Acts as the gatekeeper to Object Storage and is responsible for authenticating the user. swift storage node A node that runs Object Storage account, container, and object services. sync point Point in time since the last container and accounts database sync among nodes within Object Storage. sysadmin One of the default roles in the Compute RBAC system. Enables a user to add other users to a project, interact with VM images that are associated with the project, and start and stop VM instances. system usage A Compute component that, along with the notification system, collects meters and usage information. This information can be used for billing. Telemetry An integrated project that provides metering and measuring facilities for OpenStack. The project name of Telemetry is ceilometer. TempAuth An authentication facility within Object Storage that enables Object Storage itself to perform authentication and authorization. Frequently used in testing and development. Tempest Automated software test suite designed to run against the trunk of the OpenStack core project. TempURL An Object Storage middleware component that enables creation of URLs for temporary object access. tenant A group of users; used to isolate access to Compute resources. An alternative term for a project. Tenant API An API that is accessible to tenants. tenant endpoint An Identity service API endpoint that is associated with one or more tenants. tenant ID Unique ID assigned to each tenant within the Identity service. The project IDs map to the tenant IDs. token An alpha-numeric string of text used to access OpenStack APIs and resources. token services An Identity service component that manages and validates tokens after a user or tenant has been authenticated. tombstone Used to mark Object Storage objects that have been deleted; ensures that the object is not updated on another node after it has been deleted. topic publisher A process that is created when a RPC call is executed; used to push the message to the topic exchange. Torpedo Community project used to run automated tests against the OpenStack API. transaction ID Unique ID assigned to each Object Storage request; used for debugging and tracing. transient Alternative term for non-durable. transient exchange Alternative term for a non-durable exchange. transient message A message that is stored in memory and is lost after the server is restarted. transient queue Alternative term for a non-durable queue. TripleO OpenStack-on-OpenStack program. The code name for the OpenStack Deployment program. trove OpenStack project that provides database services to applications. Ubuntu A Debian-based Linux distribution. unscoped token Alternative term for an Identity service default token. updater Collective term for a group of Object Storage components that processes queued and failed updates for containers and objects. user In OpenStack Identity, entities represent individual API consumers and are owned by a specific domain. In OpenStack Compute, a user can be associated with roles, projects, or both. user data A blob of data that the user can specify when they launch an instance. The instance can access this data through the metadata service or config drive. Commonly used to pass a shell script that the instance runs on boot. User Mode Linux (UML) An OpenStack-supported hypervisor. VIF UUID Unique ID assigned to each Networking VIF. VIP The primary load balancing configuration object. Specifies the virtual IP address and port where client traffic is received. Also defines other details such as the load balancing method to be used, protocol, and so on. This entity is sometimes known in load-balancing products as a virtual server, vserver, or listener. Virtual Central Processing Unit (vCPU) Subdivides physical CPUs. Instances can then use those divisions. Virtual Disk Image (VDI) One of the VM image disk formats supported by Image service. VXLAN A network virtualization technology that attempts to reduce the scalability problems associated with large cloud computing deployments. It uses a VLAN-like encapsulation technique to encapsulate Ethernet frames within UDP packets. Virtual Hard Disk (VHD) One of the VM image disk formats supported by Image service. virtual IP An Internet Protocol (IP) address configured on the load balancer for use by clients connecting to a service that is load balanced. Incoming connections are distributed to back-end nodes based on the configuration of the load balancer. virtual machine (VM) An operating system instance that runs on top of a hypervisor. Multiple VMs can run at the same time on the same physical host. virtual network An L2 network segment within Networking. virtual networking A generic term for virtualization of network functions such as switching, routing, load balancing, and security using a combination of VMs and overlays on physical network infrastructure. Virtual Network Computing (VNC) Open source GUI and CLI tools used for remote console access to VMs. Supported by Compute. Virtual Network InterFace (VIF) An interface that is plugged into a port in a Networking network. Typically a virtual network interface belonging to a VM. virtual port Attachment point where a virtual interface connects to a virtual network. virtual private network (VPN) Provided by Compute in the form of cloudpipes, specialized instances that are used to create VPNs on a per-project basis. virtual server Alternative term for a VM or guest. virtual switch (vSwitch) Software that runs on a host or node and provides the features and functions of a hardware-based network switch. virtual VLAN Alternative term for a virtual network. VirtualBox An OpenStack-supported hypervisor. VLAN manager A Compute component that provides dnsmasq and radvd and sets up forwarding to and from cloudpipe instances. VLAN network The Network Controller provides virtual networks to enable compute servers to interact with each other and with the public network. All machines must have a public and private network interface. A VLAN network is a private network interface, which is controlled by the ``vlan_interface`` option with VLAN managers. VM disk (VMDK) One of the VM image disk formats supported by Image service. VM image Alternative term for an image. VM Remote Control (VMRC) Method to access VM instance consoles using a web browser. Supported by Compute. VMware API Supports interaction with VMware products in Compute. VMware NSX Neutron plug-in Provides support for VMware NSX in Neutron. VNC proxy A Compute component that provides users access to the consoles of their VM instances through VNC or VMRC. volume Disk-based data storage generally represented as an iSCSI target with a file system that supports extended attributes; can be persistent or ephemeral. Volume API Alternative name for the Block Storage API. volume controller A Block Storage component that oversees and coordinates storage volume actions. volume driver Alternative term for a volume plug-in. volume ID Unique ID applied to each storage volume under the Block Storage control. volume manager A Block Storage component that creates, attaches, and detaches persistent storage volumes. volume node A Block Storage node that runs the cinder-volume daemon. volume plug-in Provides support for new and specialized types of back-end storage for the Block Storage volume manager. volume worker A cinder component that interacts with back-end storage to manage the creation and deletion of volumes and the creation of compute volumes, provided by the cinder-volume daemon. vSphere An OpenStack-supported hypervisor. weighting A Compute process that determines the suitability of the VM instances for a job for a particular host. For example, not enough RAM on the host, too many CPUs on the host, and so on. weight Used by Object Storage devices to determine which storage devices are suitable for the job. Devices are weighted by size. weighted cost The sum of each cost used when deciding where to start a new VM instance in Compute. worker A daemon that listens to a queue and carries out tasks in response to messages. For example, the cinder-volume worker manages volume creation and deletion on storage arrays. Workflow service OpenStack project that provides a simple YAML-based language to write workflows, tasks and transition rules, and a service that allows to upload them, modify, run them at scale and in a highly available manner, manage and monitor workflow execution state and state of individual tasks. The code name of the project is mistral. Xen Xen is a hypervisor using a microkernel design, providing services that allow multiple computer operating systems to execute on the same computer hardware concurrently. Xen API The Xen administrative API, which is supported by Compute. Xen Cloud Platform (XCP) An OpenStack-supported hypervisor. Xen Storage Manager Volume Driver A Block Storage volume plug-in that enables communication with the Xen Storage Manager API. XenServer An OpenStack-supported hypervisor. XFS High-performance 64-bit file system created by Silicon Graphics. Excels in parallel I/O operations and data consistency. zaqar OpenStack project that provides a message service to applications. ZeroMQ Message queue software supported by OpenStack. An alternative to RabbitMQ. Also spelled 0MQ. Zuul Tool used in OpenStack development to ensure correctly ordered testing of changes in parallel. ",,4253,0
openstack%2Fnova~master~I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9,openstack/nova,master,I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9,Replace except Exception with specific exception,MERGED,2015-08-26 10:02:30.000000000,2016-02-15 11:56:37.000000000,2016-02-15 11:56:36.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10618}, {'_account_id': 11564}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-08-26 10:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/58fd9640d5862ae561e1a0e668cd9c245d746695', 'message': 'Replace except Exception with specific exception\n\nWe should use specific exception instead of except\nException\n\nPartial-Bug: #1223605\n\nChange-Id: I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9\n'}, {'number': 2, 'created': '2015-08-28 08:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ecaa76f0ce37076ba6dd8372d453a7deed7a0cd0', 'message': 'Replace except Exception with specific exception\n\nWe should use specific exception instead of except\nException\n\nPartial-Bug: #1223605\n\nChange-Id: I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9\n'}, {'number': 3, 'created': '2015-12-31 04:23:50.000000000', 'files': ['nova/cmd/manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6b16177f907a5c41402e0a7617b500d98669b324', 'message': 'Replace except Exception with specific exception\n\nWe should use specific exception instead of except\nException\n\nCo-Author: rushiagr (Rushi Agrawal)\n\nPartial-Bug: #1223605\n\nChange-Id: I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9\n'}]",2,217067,6b16177f907a5c41402e0a7617b500d98669b324,43,15,3,15705,,,0,"Replace except Exception with specific exception

We should use specific exception instead of except
Exception

Co-Author: rushiagr (Rushi Agrawal)

Partial-Bug: #1223605

Change-Id: I95cb7ca0a7d920adbe65ba11493af6c5b32cd4d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/217067/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/cmd/manage.py'],1,58fd9640d5862ae561e1a0e668cd9c245d746695,bug/1223605, except os.error:, except Exception:,1,1
openstack%2Fvitrage~master~I97ec6042ad43af93bb44c327354298205ffd8459,openstack/vitrage,master,I97ec6042ad43af93bb44c327354298205ffd8459,nagios transformer - bug fixed,MERGED,2016-02-15 11:32:34.000000000,2016-02-15 11:53:40.000000000,2016-02-15 11:53:40.000000000,"[{'_account_id': 3}, {'_account_id': 19122}]","[{'number': 1, 'created': '2016-02-15 11:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/13f5c2fb6c650851eee99c01ce2c3a9ce9c72ac7', 'message': 'nagios transformer - bug fixed\n\nChange-Id: I97ec6042ad43af93bb44c327354298205ffd8459\n'}, {'number': 2, 'created': '2016-02-15 11:37:55.000000000', 'files': ['vitrage/synchronizer/plugins/nagios/transformer.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/210926886ac9deba434b5a6720395a6605669e03', 'message': 'nagios transformer - bug fixed\n\nChange-Id: I97ec6042ad43af93bb44c327354298205ffd8459\n'}]",0,280168,210926886ac9deba434b5a6720395a6605669e03,7,2,2,19209,,,0,"nagios transformer - bug fixed

Change-Id: I97ec6042ad43af93bb44c327354298205ffd8459
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/68/280168/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/synchronizer/plugins/nagios/transformer.py'],1,13f5c2fb6c650851eee99c01ce2c3a9ce9c72ac7,bp/nagios-synchronizer," entity_event[NagiosProperties.LAST_CHECKq],"," entity_event[self.TIMESTAMP],",1,1
openstack%2Ffuel-qa~stable%2F8.0~I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8,openstack/fuel-qa,stable/8.0,I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8,Adjust ntp and dns check to use list of values,MERGED,2016-02-15 10:28:56.000000000,2016-02-15 11:53:34.000000000,2016-02-15 11:53:34.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11587}]","[{'number': 1, 'created': '2016-02-15 10:28:56.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e2865641ab04cdab21fe16d3d527d2a9c356eb59', 'message': 'Adjust ntp and dns check to use list of values\n\n- Change external_dns_check to use list of dns\n- Change external_ntp_check to use list of ntp\n- Fix wait condition in external_ntp_check\n\nCloses-Bug: #1543549\nChange-Id: I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8\n'}]",0,280141,e2865641ab04cdab21fe16d3d527d2a9c356eb59,11,6,1,10136,,,0,"Adjust ntp and dns check to use list of values

- Change external_dns_check to use list of dns
- Change external_ntp_check to use list of ntp
- Fix wait condition in external_ntp_check

Closes-Bug: #1543549
Change-Id: I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/41/280141/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,e2865641ab04cdab21fe16d3d527d2a9c356eb59,fixNtpDnscheck," provided_dns = EXTERNAL_DNS.split(', ') logger.debug(""provided to test dns is {}"".format(provided_dns)) cluster_dns = [] for dns in provided_dns: ext_dns_ip = ''.join( remote_slave.execute(""grep {0} /etc/resolv.dnsmasq.conf | "" ""awk {{'print $2'}}"". format(dns))[""stdout""]).rstrip() cluster_dns.append(ext_dns_ip) logger.debug(""external dns in conf is {}"".format(cluster_dns)) assert_equal(set(provided_dns), set(cluster_dns), provided_ntp = EXTERNAL_NTP.split(', ') logger.debug(""provided to test ntp is {}"".format(provided_ntp)) cluster_ntp = [] for ntp in provided_ntp: ext_ntp_ip = ''.join( remote_slave.execute(""awk '/^server +{0}/{{print $2}}' "" ""/etc/ntp.conf"". format(ntp))[""stdout""]).rstrip() cluster_ntp.append(ext_ntp_ip) logger.debug(""external ntp in conf is {}"".format(cluster_ntp)) assert_equal(set(provided_ntp), set(cluster_ntp), lambda: is_ntpd_active(remote_slave, vrouter_vip), timeout=120)"," ext_dns_ip = ''.join( remote_slave.execute(""grep {0} /etc/resolv.dnsmasq.conf | "" ""awk {{'print $2'}}"". format(EXTERNAL_DNS))[""stdout""]).rstrip() assert_equal(ext_dns_ip, EXTERNAL_DNS, ext_ntp_ip = ''.join( remote_slave.execute(""awk '/^server +{0}/{{print $2}}' "" ""/etc/ntp.conf"". format(EXTERNAL_NTP))[""stdout""]).rstrip() assert_equal(ext_ntp_ip, EXTERNAL_NTP, lambda: not is_ntpd_active(remote_slave, vrouter_vip), timeout=120)",23,11
openstack%2Fopenstack-manuals~master~I26a0fab481f7b518d42a80e4f4e83bf9df5d6b5b,openstack/openstack-manuals,master,I26a0fab481f7b518d42a80e4f4e83bf9df5d6b5b,Sync common files to ha-guide repo,MERGED,2016-02-15 06:18:31.000000000,2016-02-15 11:46:32.000000000,2016-02-15 11:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 14947}]","[{'number': 1, 'created': '2016-02-15 06:18:31.000000000', 'files': ['tools/sync-projects.sh'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ebcde1859daaa5a87d960197472520b22146a55', 'message': 'Sync common files to ha-guide repo\n\nChange-Id: I26a0fab481f7b518d42a80e4f4e83bf9df5d6b5b\n'}]",0,280078,3ebcde1859daaa5a87d960197472520b22146a55,8,3,1,10497,,,0,"Sync common files to ha-guide repo

Change-Id: I26a0fab481f7b518d42a80e4f4e83bf9df5d6b5b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/78/280078/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/sync-projects.sh'],1,3ebcde1859daaa5a87d960197472520b22146a55,i18n, copy_rst_trans doc/common, # TODO(jaegerandi): Copy over once translations are ready #copy_rst_trans doc/common-rst,1,2
openstack%2Ffuel-qa~master~I746a67e6491d37ed8dff9a29d732009ede0b04f1,openstack/fuel-qa,master,I746a67e6491d37ed8dff9a29d732009ede0b04f1,Remove bootstrap.rsa key,MERGED,2016-01-23 16:17:33.000000000,2016-02-15 11:46:26.000000000,2016-02-15 11:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11587}, {'_account_id': 12817}, {'_account_id': 12867}, {'_account_id': 15984}, {'_account_id': 16414}]","[{'number': 1, 'created': '2016-01-23 16:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f039c7c39cb440a74f8fc1d461f17df7a1397d9c', 'message': '[WIP] test\n\nChange-Id: I746a67e6491d37ed8dff9a29d732009ede0b04f1\n'}, {'number': 2, 'created': '2016-02-08 16:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/75ba1c772664021b5c0dfd150cc622efef24230b', 'message': 'Remove bootstrap.rsa key\n\nbootstrap.rsa key-file comes with fuel-bootstrap-image package\nfrom fuel-main. Since this package is going to be removed and\nCentOS bootstrap image as well, we need to align fuel-devops code\n\nImplements-bp: #remove-centos-bootstrap-from-fuel\n\nChange-Id: I746a67e6491d37ed8dff9a29d732009ede0b04f1\n'}, {'number': 3, 'created': '2016-02-09 09:52:29.000000000', 'files': ['fuelweb_test/helpers/ssh_manager.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6f0c9164534790c4aa1b3cb55d0538a23df1f296', 'message': 'Remove bootstrap.rsa key\n\nbootstrap.rsa key-file comes with fuel-bootstrap-image package\nfrom fuel-main. Since this package is going to be removed and\nCentOS bootstrap image as well, we need to align fuel-devops code\n\nImplements-bp: #remove-centos-bootstrap-from-fuel\n\nChange-Id: I746a67e6491d37ed8dff9a29d732009ede0b04f1\n'}]",0,271706,6f0c9164534790c4aa1b3cb55d0538a23df1f296,27,12,3,12817,,,0,"Remove bootstrap.rsa key

bootstrap.rsa key-file comes with fuel-bootstrap-image package
from fuel-main. Since this package is going to be removed and
CentOS bootstrap image as well, we need to align fuel-devops code

Implements-bp: #remove-centos-bootstrap-from-fuel

Change-Id: I746a67e6491d37ed8dff9a29d732009ede0b04f1
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/06/271706/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/ssh_manager.py'],1,f039c7c39cb440a74f8fc1d461f17df7a1397d9c,bp/remove-centos-bootstrap-from-fuel, for key_string in ['/root/.ssh/id_rsa']:," for key_string in ['/root/.ssh/id_rsa', '/root/.ssh/bootstrap.rsa']:",1,1
openstack%2Ffuel-ostf~master~Ia894071966c906e44580829179a5d362619f9191,openstack/fuel-ostf,master,Ia894071966c906e44580829179a5d362619f9191,Add version of plugin for sahara OSTF test,MERGED,2016-02-11 08:50:36.000000000,2016-02-15 11:46:20.000000000,2016-02-15 11:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 10136}, {'_account_id': 11587}, {'_account_id': 15984}, {'_account_id': 16414}, {'_account_id': 19119}]","[{'number': 1, 'created': '2016-02-11 08:50:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/77233951763e41dd2d5882e97fdbe4e1d0bb0592', 'message': 'Add version of plugin for sahara OSTF test\n\nAdd version of vanilla plugin for MOS 9.0\ncloses-bug: #1544460\n\nChange-Id: Ia894071966c906e44580829179a5d362619f9191\n'}, {'number': 2, 'created': '2016-02-11 10:16:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/75ff006acea39dd4739c2b08c87a02280138fdd3', 'message': 'Add version of plugin for sahara OSTF test\n\nAdd version of vanilla plugin for MOS 9.0\ncloses-bug: #1544460\n\nChange-Id: Ia894071966c906e44580829179a5d362619f9191\n'}, {'number': 3, 'created': '2016-02-11 10:17:34.000000000', 'files': ['fuel_health/tests/sanity/test_sanity_sahara.py', 'fuel_health/tests/tests_platform/test_sahara.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/ef4d78f9ccce8b87f1a484663b4c83784ad334e0', 'message': 'Add version of plugin for sahara OSTF test\n\nAdd version of vanilla plugin for MOS 9.0\ncloses-bug: #1544460\n\nChange-Id: Ia894071966c906e44580829179a5d362619f9191\n'}]",1,278935,ef4d78f9ccce8b87f1a484663b4c83784ad334e0,16,8,3,13919,,,0,"Add version of plugin for sahara OSTF test

Add version of vanilla plugin for MOS 9.0
closes-bug: #1544460

Change-Id: Ia894071966c906e44580829179a5d362619f9191
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/35/278935/2 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/sanity/test_sanity_sahara.py'],1,77233951763e41dd2d5882e97fdbe4e1d0bb0592,bug/1544460," ""8.0"": ""2.7.1"", ""9.0"": ""2.7.1"" }"," ""8.0"": ""2.7.1""}",3,1
openstack%2Fnova~master~I5851bbae2fa198a4e9be149a5836bea813848d89,openstack/nova,master,I5851bbae2fa198a4e9be149a5836bea813848d89,Remove unused CONF imports,MERGED,2016-02-15 05:46:15.000000000,2016-02-15 11:45:44.000000000,2016-02-15 11:45:43.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 5754}, {'_account_id': 8119}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-15 05:46:15.000000000', 'files': ['nova/tests/unit/api/openstack/compute/test_console_auth_tokens.py', 'nova/tests/unit/api/openstack/compute/test_security_group_default_rules.py', 'nova/tests/unit/test_notifications.py', 'nova/scheduler/filters/compute_filter.py', 'nova/network/security_group/neutron_driver.py', 'nova/tests/functional/libvirt/test_rt_servers.py', 'nova/virt/hyperv/snapshotops.py', 'nova/network/security_group/security_group_base.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/tests/unit/virt/vmwareapi/test_read_write_util.py', 'nova/image/download/__init__.py', 'nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/console/test_websocketproxy.py', 'nova/tests/unit/virt/vmwareapi/test_vif.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/functional/db/api/test_migrations.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py', 'nova/api/openstack/compute/legacy_v2/contrib/rescue.py', 'nova/tests/unit/api/openstack/compute/test_plugin_framework.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/50a9550999ccf746141bed0d2d6bf4c0801dba72', 'message': ""Remove unused CONF imports\n\nWhile reviewing config centralization patches I realized that\nwe have a fair few files where we import cfg or setup CONF, but\nnever actually use config variables.\n\nThis patch cleans those up, but I am sure we'll add more as we\nmove more flags around.\n\nChange-Id: I5851bbae2fa198a4e9be149a5836bea813848d89\n""}]",0,280068,50a9550999ccf746141bed0d2d6bf4c0801dba72,16,6,1,2271,,,0,"Remove unused CONF imports

While reviewing config centralization patches I realized that
we have a fair few files where we import cfg or setup CONF, but
never actually use config variables.

This patch cleans those up, but I am sure we'll add more as we
move more flags around.

Change-Id: I5851bbae2fa198a4e9be149a5836bea813848d89
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/280068/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/api/openstack/compute/test_console_auth_tokens.py', 'nova/tests/unit/api/openstack/compute/test_security_group_default_rules.py', 'nova/tests/unit/test_notifications.py', 'nova/scheduler/filters/compute_filter.py', 'nova/network/security_group/neutron_driver.py', 'nova/tests/functional/libvirt/test_rt_servers.py', 'nova/virt/hyperv/snapshotops.py', 'nova/network/security_group/security_group_base.py', 'nova/tests/unit/virt/disk/vfs/test_localfs.py', 'nova/tests/unit/virt/vmwareapi/test_read_write_util.py', 'nova/image/download/__init__.py', 'nova/tests/unit/api/openstack/compute/test_microversions.py', 'nova/tests/unit/console/test_websocketproxy.py', 'nova/tests/unit/virt/vmwareapi/test_vif.py', 'nova/tests/unit/api/openstack/compute/test_attach_interfaces.py', 'nova/tests/functional/db/api/test_migrations.py', 'nova/tests/unit/scheduler/test_scheduler_utils.py', 'nova/api/openstack/compute/legacy_v2/contrib/rescue.py', 'nova/tests/unit/api/openstack/compute/test_plugin_framework.py']",19,50a9550999ccf746141bed0d2d6bf4c0801dba72,conf_unused,,from oslo_config import cfgCONF = cfg.CONF ,0,54
openstack%2Foslo.config~master~I6eb366261143155d88da5c1ef69bee423c81b88d,openstack/oslo.config,master,I6eb366261143155d88da5c1ef69bee423c81b88d,remove specially attribute handling from _Namespace,MERGED,2016-02-04 18:57:11.000000000,2016-02-15 11:34:41.000000000,2016-02-10 03:30:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8688}]","[{'number': 1, 'created': '2016-02-04 18:57:11.000000000', 'files': ['oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/1e5956abde185f26c390685efb6f657e4d437735', 'message': ""remove specially attribute handling from _Namespace\n\nWith the most recent change to allow __setattr__, __getattr__, and\n__delattr__ to fall back to the base class implementation when there is\nno value in the local _cli dictionary, we're effectively re-implementing\nthe attribute management API in our own dictionary instead of just using\nthe one in the base class. So, remove our overrides and just use the\nbase class.\n\nChange-Id: I6eb366261143155d88da5c1ef69bee423c81b88d\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,276396,1e5956abde185f26c390685efb6f657e4d437735,10,5,1,2472,,,0,"remove specially attribute handling from _Namespace

With the most recent change to allow __setattr__, __getattr__, and
__delattr__ to fall back to the base class implementation when there is
no value in the local _cli dictionary, we're effectively re-implementing
the attribute management API in our own dictionary instead of just using
the one in the base class. So, remove our overrides and just use the
base class.

Change-Id: I6eb366261143155d88da5c1ef69bee423c81b88d
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/96/276396/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/tests/test_cfg.py', 'oslo_config/cfg.py']",2,1e5956abde185f26c390685efb6f657e4d437735,remove-attr-management,," # Do this last self._cli = {} def __setattr__(self, name, value): if '_cli' not in self.__dict__: super(_Namespace, self).__setattr__(name, value) return self._cli[name] = value def __getattr__(self, name): try: return self._cli[name] except KeyError: return super(_Namespace, self).__getattr__(name) def __delattr__(self, name): try: del self._cli[name] except KeyError: return super(_Namespace, self).__delattr__(name)",0,34
openstack%2Fvitrage-specs~master~Ic354dc0f96996e0bb17c47541a7a21bc7bc9256f,openstack/vitrage-specs,master,Ic354dc0f96996e0bb17c47541a7a21bc7bc9256f,fix typos,MERGED,2016-02-15 10:25:13.000000000,2016-02-15 11:11:24.000000000,2016-02-15 11:11:24.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-02-15 10:25:13.000000000', 'files': ['specs/mitaka/vitrage-synchronizer.rst', 'specs/mitaka/ui-system-health-visualization.rst', 'specs/mitaka/vitrage-evaluator-engine.rst', 'specs/mitaka/vitrage-template-validator.rst'], 'web_link': 'https://opendev.org/openstack/vitrage-specs/commit/96cacf6c37deee47bea2c543c065616c71a93f80', 'message': 'fix typos\n\nChange-Id: Ic354dc0f96996e0bb17c47541a7a21bc7bc9256f\n'}]",0,280138,96cacf6c37deee47bea2c543c065616c71a93f80,6,2,1,19134,,,0,"fix typos

Change-Id: Ic354dc0f96996e0bb17c47541a7a21bc7bc9256f
",git fetch https://review.opendev.org/openstack/vitrage-specs refs/changes/38/280138/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/mitaka/vitrage-synchronizer.rst', 'specs/mitaka/ui-system-health-visualization.rst', 'specs/mitaka/vitrage-evaluator-engine.rst', 'specs/mitaka/vitrage-template-validator.rst']",4,96cacf6c37deee47bea2c543c065616c71a93f80,typo,"===================Template validator is a part of Vitrage Evaluator. It receives a template, runs over it and checks its correctness.","====================Tamplate validator is a part of Vitrage Evaluator. It receives a template, runs over it and checks its correctness.",14,8
openstack%2Fdjango_openstack_auth~master~I8ea690923010674351d45ef5122bb046ee5e46b5,openstack/django_openstack_auth,master,I8ea690923010674351d45ef5122bb046ee5e46b5,Change log.error to log.warning,MERGED,2016-02-08 08:49:48.000000000,2016-02-15 11:08:22.000000000,2016-02-15 11:08:22.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5623}, {'_account_id': 6162}, {'_account_id': 17172}]","[{'number': 1, 'created': '2016-02-08 08:49:48.000000000', 'files': ['openstack_auth/policy.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/0be06b415792935a7c9012298d3b68092bf2fb7c', 'message': 'Change log.error to log.warning\n\nLooks like the actual repercussion from this ""error"" is\nnothing at all, so the log should be changed to a warning\nas _domain_to_credentials returns even if an exception is\nraised.\n\nSo when a function like this works even if an exception is\nraised, the log level should be a warning at best, as the rest\nof the code depending on this still seems to work no matter\nwhat is returned.\n\nChange-Id: I8ea690923010674351d45ef5122bb046ee5e46b5\nCloses-Bug: #1527575\n'}]",0,277320,0be06b415792935a7c9012298d3b68092bf2fb7c,9,5,1,12281,,,0,"Change log.error to log.warning

Looks like the actual repercussion from this ""error"" is
nothing at all, so the log should be changed to a warning
as _domain_to_credentials returns even if an exception is
raised.

So when a function like this works even if an exception is
raised, the log level should be a warning at best, as the rest
of the code depending on this still seems to work no matter
what is returned.

Change-Id: I8ea690923010674351d45ef5122bb046ee5e46b5
Closes-Bug: #1527575
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/20/277320/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/policy.py'],1,0be06b415792935a7c9012298d3b68092bf2fb7c,bug/1527575," LOG.warning(""Failed to create user from domain scoped token."")"," LOG.error(""Failed to create user from domain scoped token."")",1,1
openstack%2Ffuel-web~master~I971bbd5691422e046ce7dd0acf9deb447f1bae90,openstack/fuel-web,master,I971bbd5691422e046ce7dd0acf9deb447f1bae90,"Removing unclean and wrong document ""third_party.rst"" from the docs tree",MERGED,2016-02-11 06:43:41.000000000,2016-02-15 11:07:19.000000000,2016-02-15 10:34:12.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}]","[{'number': 1, 'created': '2016-02-11 06:43:41.000000000', 'files': ['docs/index.rst', 'docs/infra/third_party.rst'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c4e9301be9b1e3b5e836d7458f19d71608a26404', 'message': 'Removing unclean and wrong document ""third_party.rst"" from the docs tree\n\nChange-Id: I971bbd5691422e046ce7dd0acf9deb447f1bae90\nSigned-off-by: Igor Shishkin <me@teran.ru>\n'}]",0,278876,c4e9301be9b1e3b5e836d7458f19d71608a26404,16,4,1,8965,,,0,"Removing unclean and wrong document ""third_party.rst"" from the docs tree

Change-Id: I971bbd5691422e046ce7dd0acf9deb447f1bae90
Signed-off-by: Igor Shishkin <me@teran.ru>
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/76/278876/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/index.rst', 'docs/infra/third_party.rst']",2,c4e9301be9b1e3b5e836d7458f19d71608a26404,,,".. _third-party-testing: Third Party Testing =================== Overview -------- Gerrit has an event stream which can be subscribed to, using this it is possible to test commits against testing systems beyond those supplied by Fuel's Jenkins setup. It is also possible for these systems to feed information back into Gerrit. What's more, they can leave non-gating votes on Gerrit review requests. There are several examples of systems that read the Gerrit event stream and run their own tests on the commits `on this page <https://wiki.openstack.org/wiki/ThirdPartySystems>`_. For each patch set the third party system tests, the system adds a comment in Gerrit with a summary of the test result and links to the test artifacts. Requirements ------------ * Until a third party testing system operates in a stable fashion, third party tests can comment on patches but not vote on them. * A system can also be set up to only do '+1' reviews and leave all the '-1's to be manually confirmed. * A third-party system may only leave one comment per patch set (unless it is retriggered). * The maintainers are responsible for re-triggering tests when their third party testing system breaks. * Support recheck to request re-running a test. * Support the following syntaxes: ``recheck``. * Recheck means recheck everything. A single recheck comment should re-trigger all testing systems. * Publish contact information for the maintainers. * All accounts must be previously set by posting launchpad bug to add your system. * Maintainers are encouraged to be in IRC regularly to make it faster to contact them. * Include a public link to all test artifacts to make debugging failed tests easier (using a dns name over a hardcoded ip is recommended). This should include: * Environment details * This must include a utc timestamp of the test run * Test configuration * Skipped tests * logs should include a trace of the commands used * OpenStack logs * Tempest logs (including ``testr_results.html.gz``) * logs must be browsable; logs requiring download, installation or login to access are not acceptable .. note:: All test artifacts must be retained for one month. Reading the Event Stream ------------------------ It is possible to use ssh to connect to ``review.fuel-infra.org`` on port 29418 with your ssh key if you have a normal reviewer account in Gerrit. This will give you a real-time JSON stream of events happening inside Gerrit. For example: .. code-block:: bash $ ssh -p 29418 USERNAME@review.fuel-infra.org gerrit stream-events Will give a stream with an output like this (line breaks and indentation added in this document for readability, the real JSON will be all one line per event): .. code-block:: javascript {""type"":""comment-added"",""change"": {""project"":""openstack/keystone"",""branch"":""stable/essex"",""topic"":""bug/969088"",""id"":""I18ae38af62b4c2b2423e20e436611fc30f844ae1"",""number"":""7385"",""subject"":""Make import_nova_auth only create roles which don\u0027t already exist"",""owner"": {""name"":""Chuck Short"",""email"":""chuck.short@canonical.com"",""username"":""zulcss""},""url"":""https://review.fuel-infra.org/7385""}, ""patchSet"": {""number"":""1"",""revision"":""aff45d69a73033241531f5e3542a8d1782ddd859"",""ref"":""refs/changes/85/7385/1"",""uploader"": {""name"":""Chuck Short"",""email"":""chuck.short@canonical.com"",""username"":""zulcss""}, ""createdOn"":1337002189}, ""author"": {""name"":""Mark McLoughlin"",""email"":""markmc@redhat.com"",""username"":""markmc""}, ""approvals"": [{""type"":""CRVW"",""description"":""Code Review"",""value"":""2""},{""type"":""APRV"",""description"":""Approved"",""value"":""0""}], ""comment"":""Hmm, I actually thought this was in Essex already.\n\nIt\u0027s a pretty annoying little issue for folks migrating for nova auth. Fix is small and pretty safe. Good choice for backporting""} For most purposes you will want to trigger on ``patchset-created`` for when a new patchset has been uploaded. Further documentation on how to use the events stream can be found in `Gerrit's stream event documentation page <http://gerrit-documentation.googlecode.com/svn/Documentation/2.3/cmd-stream-events.html>`_. Posting Result To Gerrit ------------------------ External testing systems can give non-gating votes to Gerrit by means of a -1/+1 verify vote. Comments should also be provided to explain what kind of test failed. We do also ask that the comments contain public links to the failure so that the developer can see what caused the failure. An example of how to post this is as follows: .. code-block:: bash $ ssh -p 29418 USERNAME@review.fuel-infra.org gerrit review -m '""Test failed on MegaTestSystem <http://megatestsystem.org/tests/1234>""' --verified=-1 c0ff33 In this example ``c0ff33`` is the commit ID for the review. You can set the verified to either `-1` or `+1` depending on whether or not it passed the tests. Further documentation on the `review` command in Gerrit can be found in the `Gerrit review documentation page <http://gerrit-documentation.googlecode.com/svn/Documentation/2.3/cmd-review.html>`_. We do suggest cautious testing of these systems and have a development Gerrit setup to test on if required. In SmokeStack's case all failures are manually reviewed before getting pushed to OpenStack, while this may not scale it is advisable during the initial testing of the setup. There are several triggers that gerrit will match to alter the formatting of comments. The raw regular expressions can be seen in `gerrit.pp <https://git.openstack.org/cgit/openstack-infra/system-config/tree/modules/openstack_project/manifests/gerrit.pp>`_. For example, to have your test results formatted in the same manner as the upstream Jenkins results, use a template for each result matching:: * test-name-no-spaces http://link.to/result : [SUCCESS|FAILURE] some comment about the test .. _request-account-label: Creating a Service Account -------------------------- In order to post comments as a Third Party CI System and eventually verify your build status on Gerrit patches, you will need a dedicated Gerrit CI account. You will need to create this account in our OpenID provider `Launchpad <https://launchpad.net>`_. You may already have an existing personal account in Launchpad, but you should create a new and entirely separate account for this purpose. Once you have created this account with the OpenID provider you can log into Gerrit with that new account as you would with your normal user account. Once logged in you will need to do several things: 1. Set an SSH username at https://review.fuel-infra.org/#/settings/ if it isn't already set. This is the username your CI system will use to SSH to Gerrit in order to read the event stream. 2. Set the account's fullname at https://review.fuel-infra.org/#/settings/contact This name should follow a few rules in order to make it clear in Gerrit comments what this CI system exists to test. The name should have three pieces ``Organization`` ``Product/technology`` ``CI designator``. The organization value should be your company name or other organization affiliation. Product/technology should describe the product or technology you are testing in conjunction with OpenStack. This should be the name of a component which cannot be tested in the official OpenStack infrastructure (requires particular physical hardware, proprietary software, some hypervisor feature not available in public clouds, et cetera). Note this should not be the name of an OpenStack project but rather the thing you are testing with OpenStack projects. And finally the CI designator is used to denote this is a CI system so that automatic Gerrit comment parsers can filter these comments out. This value should be ``CI`` for most CI systems but can be ``Bot`` if you are not performing continuous integration. An example of a proper name would be something like ``IBM DB2 CI``. 3. Add the SSH public key you will be using to the Gerrit account at https://review.fuel-infra.org/#/settings/ssh-keys You can generate an ssh key using ``ssh-keygen``. You want to give Gerrit the contents of the generated id_rsa.pub file. Once you have done this you will have everything you need to comment on Gerrit changes from our CI system but you will not be able to vote +/-1 Verified on changes. To get voting rights you will need to get the release group of the project you are testing to add you to their project specific <project>-ci group. Please contact the project in question when you are ready to start voting and they can add you to this group. The Jenkins Gerrit Trigger Plugin Way ------------------------------------- There is a Gerrit Trigger plugin for Jenkins which automates all of the processes described in this document. So if your testing system is Jenkins based you can use it to simplify things. You will still need an account to do this as described in the :ref:`request-account-label` section above. The Gerrit Trigger plugin for Jenkins can be found on `the Jenkins repository`_. You can install it using the Advanced tab in the Jenkins Plugin Manager. .. _the Jenkins repository: http://repo.jenkins-ci.org/repo/com/sonyericsson/hudson/plugins/gerrit/gerrit-trigger/ Once installed Jenkins will have a new `Gerrit Trigger` option in the `Manage Jenkins` menu. This should be given the following options:: Hostname: review.fuel-infra.org Frontend URL: https://review.fuel-infra.org/ SSH Port: 29418 Username: (the Gerrit user) SSH Key File: (path to the user SSH key) Verify ------ Started: 0 Successful: 1 Failed: -1 Unstable: 0 Code Review ----------- Started: 0 Successful: 0 Failed: 0 Unstable: 0 (under Advanced Button): Stated: (blank) Successful: gerrit approve <CHANGE>,<PATCHSET> --message 'Build Successful <BUILDS_STATS>' --verified <VERIFIED> --code-review <CODE_REVIEW> Failed: gerrit approve <CHANGE>,<PATCHSET> --message 'Build Failed <BUILDS_STATS>' --verified <VERIFIED> --code-review <CODE_REVIEW> Unstable: gerrit approve <CHANGE>,<PATCHSET> --message 'Build Unstable <BUILDS_STATS>' --verified <VERIFIED> --code-review <CODE_REVIEW> Note that it is useful to include something in the messages about what testing system is supplying these messages. When creating jobs in Jenkins you will have the option to add triggers. You should configure as follows:: Trigger on Patchset Uploaded: ticked (the rest unticked) Type: Plain Pattern: openstack/project-name (where project-name is the name of the project) Branches: Type: Path Pattern: ** This job will now automatically trigger when a new patchset is uploaded and will report the results to Gerrit automatically. Testing your CI setup --------------------- You can use the ``fuel-external/test`` project to test your external CI infrastructure with OpenStack's Gerrit. By using the sandbox project you can test your CI system without affecting regular OpenStack reviews. Once you confirm your CI system works as you expect, change your configuration of the gerrit trigger plugin or zuul to subscribe to gerrit events from your target project. Permissions on your Third Party System -------------------------------------- When you create your CI account it will have no special permissions. This means it can comment on changes but generally not vote +/-1 Verified on any changes. The exception to this is on the ``fuel-external/test`` project. Any account is able to vote +/-1 Verified on that account and it provides a way to test your CI's voting abilities before you vote on other projects. .. _openstack-dev/ci-sandbox: https://review.fuel-infra.org/[ADDME] The Fuel Infrastructure team disables mis-behaving third-party ci accounts at its discretion. This documentation endeavours to outline specific circumstances that may lead to an account being disabled. There have been times when third-party ci systems behave in ways we didn't envision and therefore were unable to document prior to the event. If your third-party ci system has been disabled, please don't hesitate to contact devops team. In order to get your Third Pary CI account to have voting permissions on repos in gerrit in addition to ``fuel-external/test`` you have a greater chance of success if you follow these steps: * Set up your system and test it according to ""Testing your CI setup"" outlined above (this will create a history of activity associated with your account which will be evaluated when you apply for voting permissions). * Post comments, that adhere to the ""Requirements"" listed above, that demonstrate the format for your system communication to the repos you want your system to test. * Once your Third Party Account has a history on gerrit so that others can evaluate your format for comments, and the stability of your voting pattern (in the sandbox repo): * send an email to the fuel-devops mailing list nominating your system for voting permissions * fuel-devops@mirantis.com * present your account history * address any questions and concerns with your system * If the members of the program you want voting permissions from agree your system should be able to vote, the release group for that program or project can add you to the <project>-ci group specific to that program/project. ",0,311
openstack%2Frally~master~I380df1030495cb9cbcb0eb157ffd5079c6d2910f,openstack/rally,master,I380df1030495cb9cbcb0eb157ffd5079c6d2910f,Remove unnecessary second argument from get method,MERGED,2016-02-12 15:31:50.000000000,2016-02-15 11:06:51.000000000,2016-02-15 11:06:51.000000000,"[{'_account_id': 3}, {'_account_id': 8491}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-12 15:31:50.000000000', 'files': ['rally/plugins/openstack/context/sahara/sahara_cluster.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/cc8414f28e3f66ad6884a5dfa3f5d5a7daaad602', 'message': ""Remove unnecessary second argument from get method\n\ndict.get() returns 'None' by default if a key wasn't found.\nRemove 'None' as second argument to avoid redundancy.\n\nChange-Id: I380df1030495cb9cbcb0eb157ffd5079c6d2910f\nCloses-Bug: #1541414\n""}]",0,279607,cc8414f28e3f66ad6884a5dfa3f5d5a7daaad602,12,4,1,17589,,,0,"Remove unnecessary second argument from get method

dict.get() returns 'None' by default if a key wasn't found.
Remove 'None' as second argument to avoid redundancy.

Change-Id: I380df1030495cb9cbcb0eb157ffd5079c6d2910f
Closes-Bug: #1541414
",git fetch https://review.opendev.org/openstack/rally refs/changes/07/279607/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/context/sahara/sahara_cluster.py'],1,cc8414f28e3f66ad6884a5dfa3f5d5a7daaad602,," flavor_id=self.config.get(""flavor_id""),"," flavor_id=self.config.get(""flavor_id"", None),",1,1
openstack%2Ffuel-ostf~master~Ie52d9f6014201be9d8d4221b1611465c840793c1,openstack/fuel-ostf,master,Ie52d9f6014201be9d8d4221b1611465c840793c1,Fix for test with nova services checking,MERGED,2016-02-12 13:42:13.000000000,2016-02-15 11:03:36.000000000,2016-02-15 11:03:36.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7126}, {'_account_id': 7732}, {'_account_id': 8882}, {'_account_id': 14614}, {'_account_id': 16414}, {'_account_id': 16437}]","[{'number': 1, 'created': '2016-02-12 13:42:13.000000000', 'files': ['fuel_health/tests/sanity/test_sanity_infrastructure.py'], 'web_link': 'https://opendev.org/openstack/fuel-ostf/commit/8f005134bed3d475c23ae0fa0b82a4ae86cf0a86', 'message': ""Fix for test with nova services checking\n\nCurrently OSTF tests use deprecated nova-manage command to check\nnova-service status. Result of nova-manage command is incorrect:\nit contains services which aren't enabled. We should switch on\nnova service-list usage.\n\nChange-Id: Ie52d9f6014201be9d8d4221b1611465c840793c1\nCloses-bug: #1544981\n""}]",0,279537,8f005134bed3d475c23ae0fa0b82a4ae86cf0a86,13,8,1,14691,,,0,"Fix for test with nova services checking

Currently OSTF tests use deprecated nova-manage command to check
nova-service status. Result of nova-manage command is incorrect:
it contains services which aren't enabled. We should switch on
nova service-list usage.

Change-Id: Ie52d9f6014201be9d8d4221b1611465c840793c1
Closes-bug: #1544981
",git fetch https://review.opendev.org/openstack/fuel-ostf refs/changes/37/279537/1 && git format-patch -1 --stdout FETCH_HEAD,['fuel_health/tests/sanity/test_sanity_infrastructure.py'],1,8f005134bed3d475c23ae0fa0b82a4ae86cf0a86,," 1. Execute nova service-list command on a controller node. 2. Check there are no failed services (with down state). downstate = u'down' cmd = 'source /root/openrc; nova service-list' output = self.verify(50, ssh_client.exec_command, 1, ""'nova service-list' command execution failed. "", ""'nova service-list' command execution"", downstate not in output, 'Step 2 failed: Some nova services ' downstate not in output, 'Step 2 failed: Some nova services '"," 1. Execute nova-manage service list command on a controller node. 2. Check there are no failed services (with XXX state). output = u'XXX' cmd = 'nova-manage service list' output = self.verify(50, ssh_client.exec_command, 1, ""'nova-manage' command execution failed. "", ""nova-manage command execution"", u'XXX' not in output, 'Step 2 failed: Some nova services ' u'XXX' not in output, 'Step 2 failed: Some nova services '",9,9
openstack%2Fkeystone~master~Iadcedaec184c7ca14ecd6ad5035265a310e2d5d2,openstack/keystone,master,Iadcedaec184c7ca14ecd6ad5035265a310e2d5d2,Expand implied roles in trust tokens,MERGED,2016-02-13 01:47:51.000000000,2016-02-15 10:56:21.000000000,2016-02-15 10:56:21.000000000,"[{'_account_id': 3}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 19985}]","[{'number': 1, 'created': '2016-02-13 01:47:51.000000000', 'files': ['keystone/tests/unit/test_v3_assignment.py', 'keystone/token/providers/common.py', 'keystone/assignment/core.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/790b8c22bea9336abe2ce301fda5962021974ded', 'message': 'Expand implied roles in trust tokens\n\nCloses-Bug: 1543318\n\nChange-Id: Iadcedaec184c7ca14ecd6ad5035265a310e2d5d2\n'}]",0,279835,790b8c22bea9336abe2ce301fda5962021974ded,8,4,1,2218,,,0,"Expand implied roles in trust tokens

Closes-Bug: 1543318

Change-Id: Iadcedaec184c7ca14ecd6ad5035265a310e2d5d2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/279835/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/test_v3_assignment.py', 'keystone/token/providers/common.py', 'keystone/assignment/core.py']",3,790b8c22bea9336abe2ce301fda5962021974ded,bug/1539240," def add_implied_roles(self, role_refs): refs = self.add_implied_roles(refs)"," def _add_implied_roles(self, role_refs): refs = self._add_implied_roles(refs)",12,10
openstack%2Ffuel-library~master~If14fcfc915d76c9580be0a097b250d79cf953b9e,openstack/fuel-library,master,If14fcfc915d76c9580be0a097b250d79cf953b9e,Do not check cluster health if master is not elected,MERGED,2016-02-08 16:22:15.000000000,2016-02-15 10:54:54.000000000,2016-02-15 10:54:04.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7109}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 13948}, {'_account_id': 14985}, {'_account_id': 18805}]","[{'number': 1, 'created': '2016-02-08 16:22:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/87d1c03a74ad786192945de32ab2304e2a90651c', 'message': 'Do not check cluster health if master is not elected\n\nDoing otherwise causes node to restart when get_monitor is called\nwithin action_promote - it does not find a master and assumes that\nit is running out of cluster.\n\nAlso, code is refactored a little bit - a new function returning\ncurrent master is created and is used in the changed code.\n\nCloses-Bug: #1543154\nChange-Id: If14fcfc915d76c9580be0a097b250d79cf953b9e\n'}, {'number': 2, 'created': '2016-02-09 17:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f824525ce875006ae6117d3f5c4dfe4da07d4225', 'message': 'Do not check cluster health if master is not elected\n\nDoing otherwise causes node to restart when get_monitor is called\nwithin action_promote - it does not find a master and assumes that\nit is running out of cluster.\n\nAlso, code is refactored a little bit - a new function returning\ncurrent master is created and is used in the changed code.\n\nCloses-Bug: #1543154\nChange-Id: If14fcfc915d76c9580be0a097b250d79cf953b9e\n'}, {'number': 3, 'created': '2016-02-10 09:01:06.000000000', 'files': ['files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3dac123119ee5456db177f71631f14d6fc217776', 'message': 'Do not check cluster health if master is not elected\n\nDoing otherwise causes node to restart when get_monitor is called\nwithin action_promote - it does not find a master and assumes that\nit is running out of cluster.\n\nAlso, code is refactored a little bit - a new function returning\ncurrent master is created and is used in the changed code.\n\nCloses-Bug: #1543154\nChange-Id: If14fcfc915d76c9580be0a097b250d79cf953b9e\n'}]",8,277483,3dac123119ee5456db177f71631f14d6fc217776,46,10,3,7109,,,0,"Do not check cluster health if master is not elected

Doing otherwise causes node to restart when get_monitor is called
within action_promote - it does not find a master and assumes that
it is running out of cluster.

Also, code is refactored a little bit - a new function returning
current master is created and is used in the changed code.

Closes-Bug: #1543154
Change-Id: If14fcfc915d76c9580be0a097b250d79cf953b9e
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/277483/2 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,87d1c03a74ad786192945de32ab2304e2a90651c,bug/1543154,"# Get current master. If a parameter is provided, # do not check node with that name get_master_name_but() { for node in $(get_alive_pacemaker_nodes_but ""@$"") do ocf_log info ""${LH} looking if $node is master"" if is_master $node; then ocf_log info ""${LH} master is $node"" echo $node break fi done } ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" else local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -z ""$master_name"" ]; then ocf_log info ""${LH} no master is elected currently. Skipping cluster health check."" elif get_running_nodes | grep -q $(rabbit_node_name $master_name); then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" # Rabbit is running but is not connected to master # Failing to avoid split brain ocf_log err ""${LH} rabbit node is running out of the cluster"" rc=$OCF_ERR_GENERIC fi if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then local master_name=$(get_master_name_but $THIS_PCMK_NODE) if [ -n ""$master_name"" ]; then ocf_log info ""${LH} master exists and rabbit app is not running. Exiting to be restarted by pacemaker"" rc=$OCF_ERR_GENERIC fi fi if [ $rc -eq $OCF_ERR_GENERIC ]; then"," local rc_check=$OCF_SUCCESS ocf_log info ""${LH} rabbit app is running. checking if we are the part of healthy cluster"" if [ $rc -eq $OCF_RUNNING_MASTER ] ; then # The master is always running inside of its cluster ocf_log info ""${LH} rabbit app is running and is master of cluster"" rc_check=$OCF_SUCCESS rc_check=$OCF_ERR_GENERIC nodelist=$(get_alive_pacemaker_nodes_but) for node in $nodelist do ocf_log info ""${LH} rabbit app is running. looking for master on $node"" is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then ocf_log info ""${LH} rabbit app is running. master is $node"" if get_running_nodes | grep -q $(rabbit_node_name $node) then ocf_log info ""${LH} rabbit app is running and is member of healthy cluster"" rc_check=$OCF_SUCCESS break fi fi done [ $rc_check -eq $OCF_ERR_GENERIC ] && ocf_log err ""${LH} rabbit node is running out of the cluster"" if [ ""$OCF_CHECK_LEVEL"" -gt 20 ]; then nodelist=$(get_alive_pacemaker_nodes_but $THIS_PCMK_NODE) rc_check=$OCF_SUCCESS for node in $nodelist do is_master $node status_master=$? ocf_log info ""${LH} fetched master attribute for $node. attr value is ${status_master}"" if [ $status_master -eq 0 ] ; then rc_check=$OCF_ERR_GENERIC ocf_log info ""${LH} rabbit app is not running. master is $node. exiting to be restarted by pacemaker"" break fi done fi if [ $rc -eq $OCF_ERR_GENERIC -o $rc_check -eq $OCF_ERR_GENERIC ]; then",46,41
openstack%2Ffuel-agent~master~Id91c479f74d4e4945a6a1340e3f73a8789961b66,openstack/fuel-agent,master,Id91c479f74d4e4945a6a1340e3f73a8789961b66,Add hwloc to default bootstrap packages,MERGED,2016-02-12 07:52:00.000000000,2016-02-15 10:54:49.000000000,2016-02-15 10:54:49.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 8971}, {'_account_id': 10288}, {'_account_id': 10443}]","[{'number': 1, 'created': '2016-02-12 07:52:00.000000000', 'files': ['contrib/fuel_bootstrap/fuel_bootstrap_cli/fuel_bootstrap/settings.yaml.sample'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/566c8f5850aa230f779a968d2efa1bff438fdd0c', 'message': 'Add hwloc to default bootstrap packages\n\nhwloc package is needed for discovering\nNUMA topology\n\nChange-Id: Id91c479f74d4e4945a6a1340e3f73a8789961b66\nImplements: blueprint support-numa-cpu-pinning\n'}]",0,279407,566c8f5850aa230f779a968d2efa1bff438fdd0c,11,6,1,10488,,,0,"Add hwloc to default bootstrap packages

hwloc package is needed for discovering
NUMA topology

Change-Id: Id91c479f74d4e4945a6a1340e3f73a8789961b66
Implements: blueprint support-numa-cpu-pinning
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/07/279407/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/fuel_bootstrap/fuel_bootstrap_cli/fuel_bootstrap/settings.yaml.sample'],1,566c8f5850aa230f779a968d2efa1bff438fdd0c,bp/support-numa-cpu-pinning, - hwloc,,1,0
openstack%2Fneutron~stable%2Fliberty~Ic951c1b91c5a10462f548544a5e8d482c52ad665,openstack/neutron,stable/liberty,Ic951c1b91c5a10462f548544a5e8d482c52ad665,Wait for the watch process in test case,MERGED,2016-02-08 11:31:10.000000000,2016-02-15 10:54:35.000000000,2016-02-15 10:25:56.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 10153}, {'_account_id': 11159}, {'_account_id': 12444}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}]","[{'number': 1, 'created': '2016-02-08 11:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8fa9f6f1c789b7b5abc7f1f86042a3210be485d', 'message': 'Wait for the watch process in test case\n\nBecause the _watch_process and the failing_process are asynchronous,\nthere might be a chance that failing_process exit and _watch_process\nis not executed.\n\nIf the _watch_process is blocked, the method that will be asserted\nwill not be called. This will fail the UT, but it is intermittent.\n\nChange-Id: Ic951c1b91c5a10462f548544a5e8d482c52ad665\nCloses-Bug: #1519160\n(cherry picked from commit dcd0498c17ae860c55a92f9f31b3e3fa0460b78e)\n'}, {'number': 2, 'created': '2016-02-08 11:33:51.000000000', 'files': ['neutron/tests/unit/agent/linux/test_async_process.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/306636e64dc884484aad772dd6994299d30c2a06', 'message': 'Wait for the watch process in test case\n\nBecause the _watch_process and the failing_process are asynchronous,\nthere might be a chance that failing_process exit and _watch_process\nis not executed.\n\nIf the _watch_process is blocked, the method that will be asserted\nwill not be called. This will fail the UT, but it is intermittent.\n\nChange-Id: Ic951c1b91c5a10462f548544a5e8d482c52ad665\nCloses-Bug: #1519160\nRelated-Bug: #1543040\nRelated Bug: #1506021\n(cherry picked from commit dcd0498c17ae860c55a92f9f31b3e3fa0460b78e)\n'}]",0,277347,306636e64dc884484aad772dd6994299d30c2a06,39,11,2,6579,,,0,"Wait for the watch process in test case

Because the _watch_process and the failing_process are asynchronous,
there might be a chance that failing_process exit and _watch_process
is not executed.

If the _watch_process is blocked, the method that will be asserted
will not be called. This will fail the UT, but it is intermittent.

Change-Id: Ic951c1b91c5a10462f548544a5e8d482c52ad665
Closes-Bug: #1519160
Related-Bug: #1543040
Related Bug: #1506021
(cherry picked from commit dcd0498c17ae860c55a92f9f31b3e3fa0460b78e)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/47/277347/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/agent/linux/test_async_process.py'],1,b8fa9f6f1c789b7b5abc7f1f86042a3210be485d,bug/1519160, # Wait for the monitor process to complete for thread in self.process._watchers: thread.wait(),,3,0
openstack%2Fdjango_openstack_auth~master~I35d4150c1571af1a0c90c4e9a2ab3b077d709e13,openstack/django_openstack_auth,master,I35d4150c1571af1a0c90c4e9a2ab3b077d709e13,Updated from global requirements,ABANDONED,2016-02-10 21:52:40.000000000,2016-02-15 10:45:35.000000000,,"[{'_account_id': 3}, {'_account_id': 841}]","[{'number': 1, 'created': '2016-02-10 21:52:40.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/940cef786a41b5867c6ceadf0a31fcef73f0bc7d', 'message': 'Updated from global requirements\n\nChange-Id: I35d4150c1571af1a0c90c4e9a2ab3b077d709e13\n'}]",0,278665,940cef786a41b5867c6ceadf0a31fcef73f0bc7d,5,2,1,11131,,,0,"Updated from global requirements

Change-Id: I35d4150c1571af1a0c90c4e9a2ab3b077d709e13
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/65/278665/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,940cef786a41b5867c6ceadf0a31fcef73f0bc7d,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,1,1
openstack%2Fpython-fuelclient~master~Ifd186f0d703a840635f6f111c379338e93fde0a3,openstack/python-fuelclient,master,Ifd186f0d703a840635f6f111c379338e93fde0a3,Use OS command line parameters for credentials,MERGED,2016-01-27 10:13:19.000000000,2016-02-15 10:33:05.000000000,2016-02-12 17:37:27.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11898}, {'_account_id': 18205}]","[{'number': 1, 'created': '2016-01-27 10:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/4f72d7de44144b1a6d1daf4f5b9c1e3f4400162b', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\nCloses-bug: #1535417\n""}, {'number': 2, 'created': '2016-02-05 16:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/f14484fdaea2167351c117094c19f3378bd462ee', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}, {'number': 3, 'created': '2016-02-05 16:39:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/074ca72ea4b9fa6da0ca8fbe113536e163c50cf8', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}, {'number': 4, 'created': '2016-02-08 15:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/a238271f5dcedcbc966246749d71a6eb68afbe01', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}, {'number': 5, 'created': '2016-02-10 11:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/7a896684cde568920a3a79142fdc521b7776350a', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}, {'number': 6, 'created': '2016-02-10 18:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/51398ca21f8e831474e25129fb1c18f277081090', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}, {'number': 7, 'created': '2016-02-12 15:02:04.000000000', 'files': ['fuelclient/cli/actions/base.py', 'fuelclient/tests/unit/v2/cli/test_engine.py', 'fuelclient/fuelclient_settings.py', 'fuelclient/main.py', 'fuelclient/tests/unit/common/test_config.py', 'fuelclient/client.py', 'tools/prepare_nailgun.sh', 'fuelclient/fuel_client.yaml', 'fuelclient/cli/parser.py', 'fuelclient/tests/unit/v1/test_authentication.py', 'fuelclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/1566c52f3dd1d4538fe08d01db0adb5a5a5d47bc', 'message': ""Use OS command line parameters for credentials\n\nIn order to comply with OpenStack de-facto standards\nuser's credentials must be supplied via appropriate\n--os parameters.\n\nCloses-bug: #1535417\nChange-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3\n""}]",19,272975,1566c52f3dd1d4538fe08d01db0adb5a5a5d47bc,69,8,7,6623,,,0,"Use OS command line parameters for credentials

In order to comply with OpenStack de-facto standards
user's credentials must be supplied via appropriate
--os parameters.

Closes-bug: #1535417
Change-Id: Ifd186f0d703a840635f6f111c379338e93fde0a3
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/75/272975/5 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/fuelclient_settings.py', 'fuelclient/main.py', 'fuelclient/utils.py']",3,4f72d7de44144b1a6d1daf4f5b9c1e3f4400162b,bug/1535417," def add_os_cli_parameters(parser): parser.add_argument( '--os-auth-url', metavar='<auth-url>', help='Authentication URL, defaults to env[OS_AUTH_URL].') project_name_group = parser.add_mutually_exclusive_group() project_name_group.add_argument( '--os-tenant-name', metavar='<auth-tenant-name>', help='Authentication tenant name, defaults to ' 'env[OS_TENANT_NAME].') project_name_group.add_argument( '--os-project-name', metavar='<auth-project-name>', help='Another way to specify tenant name. ' 'This option is mutually exclusive with ' ' --os-tenant-name. ' 'Defaults to env[OS_PROJECT_NAME].') parser.add_argument( '--os-username', metavar='<auth-username>', help='Authentication username, defaults to env[OS_USERNAME].') parser.add_argument( '--os-password', metavar='<auth-password>', help='Authentication password, defaults to env[OS_PASSWORD].')",,44,0
openstack%2Ffuel-qa~master~I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8,openstack/fuel-qa,master,I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8,Adjust ntp and dns check to use list of values,MERGED,2016-02-12 15:22:13.000000000,2016-02-15 10:29:59.000000000,2016-02-15 10:29:59.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2016-02-12 15:22:13.000000000', 'files': ['fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/114f68b7a7956ec75c401d5df955bedb1fe8be0f', 'message': 'Adjust ntp and dns check to use list of values\n\n- Change external_dns_check to use list of dns\n- Change external_ntp_check to use list of ntp\n- Fix wait condition in external_ntp_check\n\nCloses-Bug: #1543549\nChange-Id: I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8\n'}]",0,279598,114f68b7a7956ec75c401d5df955bedb1fe8be0f,12,6,1,10136,,,0,"Adjust ntp and dns check to use list of values

- Change external_dns_check to use list of dns
- Change external_ntp_check to use list of ntp
- Fix wait condition in external_ntp_check

Closes-Bug: #1543549
Change-Id: I92ec6e67c8aa1106e9c5ee7ea95b67d63b0151a8
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/98/279598/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/helpers/checkers.py'],1,114f68b7a7956ec75c401d5df955bedb1fe8be0f,fixNtpDnscheck," provided_dns = EXTERNAL_DNS.split(', ') logger.debug(""provided to test dns is {}"".format(provided_dns)) cluster_dns = [] for dns in provided_dns: ext_dns_ip = ''.join( remote_slave.execute(""grep {0} /etc/resolv.dnsmasq.conf | "" ""awk {{'print $2'}}"". format(dns))[""stdout""]).rstrip() cluster_dns.append(ext_dns_ip) logger.debug(""external dns in conf is {}"".format(cluster_dns)) assert_equal(set(provided_dns), set(cluster_dns), provided_ntp = EXTERNAL_NTP.split(', ') logger.debug(""provided to test ntp is {}"".format(provided_ntp)) cluster_ntp = [] for ntp in provided_ntp: ext_ntp_ip = ''.join( remote_slave.execute(""awk '/^server +{0}/{{print $2}}' "" ""/etc/ntp.conf"". format(ntp))[""stdout""]).rstrip() cluster_ntp.append(ext_ntp_ip) logger.debug(""external ntp in conf is {}"".format(cluster_ntp)) assert_equal(set(provided_ntp), set(cluster_ntp), lambda: is_ntpd_active(remote_slave, vrouter_vip), timeout=120)"," ext_dns_ip = ''.join( remote_slave.execute(""grep {0} /etc/resolv.dnsmasq.conf | "" ""awk {{'print $2'}}"". format(EXTERNAL_DNS))[""stdout""]).rstrip() assert_equal(ext_dns_ip, EXTERNAL_DNS, ext_ntp_ip = ''.join( remote_slave.execute(""awk '/^server +{0}/{{print $2}}' "" ""/etc/ntp.conf"". format(EXTERNAL_NTP))[""stdout""]).rstrip() assert_equal(ext_ntp_ip, EXTERNAL_NTP, lambda: not is_ntpd_active(remote_slave, vrouter_vip), timeout=120)",23,11
openstack%2Fsenlin~master~I1674d5da0b0fab9f3d0621616be372a347a5cd9c,openstack/senlin,master,I1674d5da0b0fab9f3d0621616be372a347a5cd9c,Remove some dead options in engine config,MERGED,2016-02-15 08:13:43.000000000,2016-02-15 10:27:49.000000000,2016-02-15 10:27:49.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-15 08:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5a1f6fc7ef24a0cbfeea38f44cc96263c4cc78dc', 'message': ""Remove some dead options in engine config\n\nWe are never using the 'region_name_for_services' option and the\n'error_wait_time' option. This patch proposes a removal of both.\n\nChange-Id: I1674d5da0b0fab9f3d0621616be372a347a5cd9c\n""}, {'number': 2, 'created': '2016-02-15 10:12:29.000000000', 'files': ['senlin/tests/unit/common/base.py', 'senlin/common/config.py', 'devstack/lib/senlin'], 'web_link': 'https://opendev.org/openstack/senlin/commit/1f1184763b21081c51dc6511973cf93f931f4e83', 'message': ""Remove some dead options in engine config\n\nWe are never using the 'region_name_for_services' option and the\n'error_wait_time' option. This patch proposes a removal of both.\n\nChange-Id: I1674d5da0b0fab9f3d0621616be372a347a5cd9c\n""}]",0,280098,1f1184763b21081c51dc6511973cf93f931f4e83,13,4,2,8246,,,0,"Remove some dead options in engine config

We are never using the 'region_name_for_services' option and the
'error_wait_time' option. This patch proposes a removal of both.

Change-Id: I1674d5da0b0fab9f3d0621616be372a347a5cd9c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/98/280098/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/common/base.py', 'senlin/common/config.py', 'devstack/lib/senlin']",3,5a1f6fc7ef24a0cbfeea38f44cc96263c4cc78dc,enable-region-name-for-services-option,," iniset $SENLIN_CONF DEFAULT region_name_for_services ""$REGION_NAME""",0,9
openstack%2Fpython-fuelclient~master~Id5f22228b007d5881d8d1db4725772ef0ca3f9ce,openstack/python-fuelclient,master,Id5f22228b007d5881d8d1db4725772ef0ca3f9ce,Basic VIP management commands added to Nailgun CLI v1,MERGED,2015-12-29 15:38:58.000000000,2016-02-15 10:26:34.000000000,2016-02-15 10:26:21.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11898}, {'_account_id': 13124}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18205}, {'_account_id': 19158}]","[{'number': 1, 'created': '2015-12-29 15:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/74436a51fd4423d869fedb451793eaed8bc173e8', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 2, 'created': '2015-12-29 15:46:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/2d1985d09987b37878e81a63aa984f74afa5865d', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 3, 'created': '2016-01-12 10:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/3093f6bf76ec223d17219dfb088da55001a28289', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 4, 'created': '2016-01-12 10:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/6a8afc1fa33a0cc7c8611f17f7fa33042064866d', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 5, 'created': '2016-01-13 17:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/befc9cea39ee20ad9d4933c6b19c282b9893c2d5', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 6, 'created': '2016-01-27 12:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/57b5b8fffd6ce20af786d199c41cdbfc33c704fb', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 7, 'created': '2016-02-03 14:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/6067e6445b1b98cc6d4aef89f4fe325a6cc4cb3e', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --ip 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 8, 'created': '2016-02-05 12:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/ec4cc3290a70cd671ff80cf777007f5a639238a9', 'message': 'Basic VIP management commands added to Nailgun CLI\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 9, 'created': '2016-02-05 15:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/911b6d63d05cc1284c6d0bec12feb96daf95789a', 'message': 'Basic VIP management commands added to Nailgun CLI v1\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 10, 'created': '2016-02-09 17:26:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/ff1eed924524e7fc9051e30fad20e0e9805185df', 'message': 'Basic VIP management commands added to Nailgun CLI v1\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 11, 'created': '2016-02-09 23:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/a0a11ac6e803b9cd7f13fdfed87601b65fc6d149', 'message': 'Basic VIP management commands added to Nailgun CLI v1\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 12, 'created': '2016-02-09 23:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/5bdefd2cc1e27ac243ae867a0f6801f768ab32c9', 'message': 'Basic VIP management commands added to Nailgun CLI v1\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip-address-id 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}, {'number': 13, 'created': '2016-02-10 10:29:57.000000000', 'files': ['fuelclient/objects/environment.py', 'fuelclient/tests/functional/v1/test_client.py', 'fuelclient/cli/actions/vip.py', 'fuelclient/tests/unit/v1/test_vip_action.py', 'fuelclient/cli/actions/__init__.py', 'fuelclient/cli/arguments.py'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/31190a8d38d493eb525c23b1254816c818fa9947', 'message': 'Basic VIP management commands added to Nailgun CLI v1\n\nNow Naigun CLI supports VIP configuration management commands\nthat allow to download and upload VIP configuration:\n\nfuel vip --env 1 --ip-address-id 1 --download\nfuel vip --env 1 --upload ip_address.yaml\n\nPartial-Bug: #1482399\nImplements Blueprint: allow-any-vip\n\nChange-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce\n'}]",51,262245,31190a8d38d493eb525c23b1254816c818fa9947,181,11,13,19158,,,0,"Basic VIP management commands added to Nailgun CLI v1

Now Naigun CLI supports VIP configuration management commands
that allow to download and upload VIP configuration:

fuel vip --env 1 --ip-address-id 1 --download
fuel vip --env 1 --upload ip_address.yaml

Partial-Bug: #1482399
Implements Blueprint: allow-any-vip

Change-Id: Id5f22228b007d5881d8d1db4725772ef0ca3f9ce
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/45/262245/12 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/objects/environment.py', 'fuelclient/tests/functional/v1/test_client.py', 'fuelclient/cli/actions/vip.py', 'fuelclient/tests/unit/v1/test_vip_action.py', 'fuelclient/cli/actions/__init__.py', 'fuelclient/cli/arguments.py']",6,74436a51fd4423d869fedb451793eaed8bc173e8,bug/1482399," def get_vip_arg(help_msg): return get_boolean_arg( ""vip"", flags=(""--vip"",), help=help_msg ) def get_ip_arg(help_msg): return get_int_arg( ""ip"", flags=(""--ip"",), help=help_msg ) def get_network_id_arg(help_msg): return get_int_arg(""network"", flags=(""--network"",), help=help_msg) def get_network_role_arg(help_msg): return get_str_arg( ""network-role"", flags=(""--network-role"",), help=help_msg ) def get_upload_file_arg(help_msg): return get_str_arg(""upload"", flags=(""-u"",), help=help_msg)",,395,29
openstack%2Fdevstack~master~I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e,openstack/devstack,master,I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e,Add sanity check for enough free space,ABANDONED,2015-05-25 17:14:23.000000000,2016-02-15 10:23:56.000000000,,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 6579}, {'_account_id': 6854}, {'_account_id': 7118}, {'_account_id': 7715}, {'_account_id': 8655}, {'_account_id': 11343}, {'_account_id': 12444}, {'_account_id': 13252}, {'_account_id': 16051}, {'_account_id': 16788}]","[{'number': 1, 'created': '2015-05-25 17:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/197c120be70f86ce54612c9d60e5d3bdcc6492f3', 'message': ""Add sanity check for enough free space.\n\nRunning ./stack.sh on a machine that lacks enough free space can lead\nvarious errors that are hard to track down, such as the messaging queue\nstops handling messages, sql server stops answering, etc. There really\nshould be an error to let the user know what he's doing wrong here.\n\n2GB is used as an arbitrary lower limit.\n\nChange-Id: I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e\n""}, {'number': 2, 'created': '2015-05-25 17:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ec8adc4e986732d9cd0f1aa3a1a19a3a5f3670d7', 'message': ""Add sanity check for enough free space\n\nRunning ./stack.sh on a machine that lacks enough free space can lead\nvarious errors that are hard to track down, such as the messaging queue\nstops handling messages, sql server stops answering, etc. There really\nshould be an error to let the user know what he's doing wrong here.\n\n2GB is used as an arbitrary lower limit.\n\nChange-Id: I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e\n""}, {'number': 3, 'created': '2015-05-27 07:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d8129de6c761b05a5558ce7028b1edb8a01d58e8', 'message': ""Add sanity check for enough free space\n\nRunning ./stack.sh on a machine that lacks enough free space can lead\nvarious errors that are hard to track down, such as the messaging queue\nstops handling messages, sql server stops answering, etc. There really\nshould be an error to let the user know what he's doing wrong here.\n\n2GB is used as a lower limit, since rabbitmq for example starts logging\nwarnings at the 1GB mark.\n\nChange-Id: I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e\n""}, {'number': 4, 'created': '2015-05-27 07:46:49.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3a48e748d4f6c6780314ad142d6257b0e8d12f0a', 'message': ""Add sanity check for enough free space\n\nRunning ./stack.sh on a machine that lacks enough free space can lead\nvarious errors that are hard to track down, such as the messaging queue\nstops handling messages, sql server stops answering, etc. There really\nshould be an error to let the user know what he's doing wrong here.\n\n2GB is used as a lower limit, since rabbitmq for example starts logging\nwarnings at the 1GB mark.\n\nChange-Id: I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e\n""}]",9,185432,3a48e748d4f6c6780314ad142d6257b0e8d12f0a,29,12,4,12444,,,0,"Add sanity check for enough free space

Running ./stack.sh on a machine that lacks enough free space can lead
various errors that are hard to track down, such as the messaging queue
stops handling messages, sql server stops answering, etc. There really
should be an error to let the user know what he's doing wrong here.

2GB is used as a lower limit, since rabbitmq for example starts logging
warnings at the 1GB mark.

Change-Id: I3f44cb8cfe3cbc8bc8940a52a2c0b81c1890383e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/185432/4 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,197c120be70f86ce54612c9d60e5d3bdcc6492f3,check_free_space,"for fs in ""/"" ""/var"" ""/opt""; do if [ $(df -k $fs | tail -n 1 | awk '{ print $4 }') -lt 2097152 ]; then echo ""You don't have enough free space on $fs."" echo ""You need at least 2GB of free space."" exit 1 fi done",,7,0
openstack%2Fsenlin~master~I067196aa64215706ff1ff437a3f6c500683181e4,openstack/senlin,master,I067196aa64215706ff1ff437a3f6c500683181e4,Refactor controllers in API layer,MERGED,2016-02-15 07:43:23.000000000,2016-02-15 10:21:52.000000000,2016-02-15 10:21:52.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-15 07:43:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6a463282e8f7d007bc8e0befd6fafb32f54aa385', 'message': 'Refactor controllers in API layer\n\nWe have quite some duplicated logics in the resource controllers at API\nlayer. This patch abstracts the duplicated code into a base class.\n\nChange-Id: I067196aa64215706ff1ff437a3f6c500683181e4\n'}, {'number': 2, 'created': '2016-02-15 09:09:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a517fc1079fa5023d0172dc14375d61edc942252', 'message': 'Refactor controllers in API layer\n\nWe have quite some duplicated logics in the resource controllers at API\nlayer. This patch abstracts the duplicated code into a base class.\n\nChange-Id: I067196aa64215706ff1ff437a3f6c500683181e4\n'}, {'number': 3, 'created': '2016-02-15 09:57:04.000000000', 'files': ['senlin/api/openstack/v1/events.py', 'senlin/api/openstack/v1/actions.py', 'senlin/api/openstack/v1/cluster_policies.py', 'senlin/tests/unit/apiv1/test_events.py', 'senlin/tests/unit/apiv1/test_clusters.py', 'senlin/api/openstack/v1/policies.py', 'senlin/api/openstack/v1/clusters.py', 'senlin/api/openstack/v1/webhooks.py', 'senlin/tests/unit/apiv1/test_policy_types.py', 'senlin/api/openstack/v1/policy_types.py', 'senlin/tests/unit/apiv1/test_nodes.py', 'senlin/tests/unit/apiv1/test_receivers.py', 'senlin/tests/unit/apiv1/test_profile_types.py', 'senlin/api/openstack/v1/build_info.py', 'senlin/tests/unit/apiv1/test_policies.py', 'senlin/tests/unit/apiv1/test_profiles.py', 'senlin/api/openstack/v1/profile_types.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/api/openstack/v1/receivers.py', 'senlin/api/openstack/v1/profiles.py', 'senlin/tests/unit/apicommon/test_wsgi.py', 'senlin/tests/unit/apiv1/test_cluster_policies.py', 'senlin/api/common/wsgi.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8171f824a35cd4b9c9ce7530b0e4999e797136cc', 'message': 'Refactor controllers in API layer\n\nWe have quite some duplicated logics in the resource controllers at API\nlayer. This patch abstracts the duplicated code into a base class.\n\nChange-Id: I067196aa64215706ff1ff437a3f6c500683181e4\n'}]",1,280090,8171f824a35cd4b9c9ce7530b0e4999e797136cc,12,3,3,8246,,,0,"Refactor controllers in API layer

We have quite some duplicated logics in the resource controllers at API
layer. This patch abstracts the duplicated code into a base class.

Change-Id: I067196aa64215706ff1ff437a3f6c500683181e4
",git fetch https://review.opendev.org/openstack/senlin refs/changes/90/280090/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/api/openstack/v1/events.py', 'senlin/api/openstack/v1/actions.py', 'senlin/api/openstack/v1/cluster_policies.py', 'senlin/tests/unit/apiv1/test_events.py', 'senlin/tests/unit/apiv1/test_clusters.py', 'senlin/api/openstack/v1/policies.py', 'senlin/api/openstack/v1/clusters.py', 'senlin/api/openstack/v1/webhooks.py', 'senlin/tests/unit/apiv1/test_policy_types.py', 'senlin/api/openstack/v1/policy_types.py', 'senlin/tests/unit/apiv1/test_nodes.py', 'senlin/tests/unit/apiv1/test_receivers.py', 'senlin/tests/unit/apiv1/test_profile_types.py', 'senlin/api/openstack/v1/build_info.py', 'senlin/tests/unit/apiv1/test_policies.py', 'senlin/tests/unit/apiv1/test_profiles.py', 'senlin/api/openstack/v1/profile_types.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/api/openstack/v1/receivers.py', 'senlin/api/openstack/v1/profiles.py', 'senlin/tests/unit/apicommon/test_wsgi.py', 'senlin/tests/unit/apiv1/test_cluster_policies.py', 'senlin/api/common/wsgi.py']",23,6a463282e8f7d007bc8e0befd6fafb32f54aa385,refactor-api-controllers,"from webob import excfrom senlin.rpc import client as rpc_client return exc.HTTPNotFound() err = exc.HTTPBadRequest(msg) except exc.HTTPException as err: if not isinstance(err, exc.HTTPError): if isinstance(err, exc.HTTPServerError):class Controller(object): """"""Generic WSGI controller for resources."""""" def __init__(self, options): self.options = options self.rpc_client = rpc_client.EngineClient() def default(self, req, **args): raise exc.HTTPNotFound() def translate_exception(ex, locale): if isinstance(ex, exception.SenlinException): ex.message = oslo_i18n.translate(ex.message, locale) else: ex.message = oslo_i18n.translate(six.text_type(ex), locale) if isinstance(ex, exc.HTTPError): ex.explanation = oslo_i18n.translate(ex.explanation, locale) ex.detail = oslo_i18n.translate(getattr(ex, 'detail', ''), locale) return ex","import webob.excclass DefaultMethodController(object): """"""A default controller for handling requests. This controller handles the OPTIONS request method and any of the HTTP methods that are not explicitly implemented by the application. """""" def options(self, req, allowed_methods, *args, **kwargs): """"""Handler of the OPTIONS request method. Return a response that includes the 'Allow' header listing the methods that are implemented. A 204 status code is used for this response. """""" raise webob.exc.HTTPNoContent(headers=[('Allow', allowed_methods)]) def reject(self, req, allowed_methods, *args, **kwargs): """"""Return a 405 method not allowed error. As a convenience, the 'Allow' header with the list of implemented methods is included in the response as well. """""" raise webob.exc.HTTPMethodNotAllowed( headers=[('Allow', allowed_methods)]) return webob.exc.HTTPNotFound() err = webob.exc.HTTPBadRequest(msg) except webob.exc.HTTPException as err: if not isinstance(err, webob.exc.HTTPError): if isinstance(err, webob.exc.HTTPServerError):def translate_exception(exc, locale): if isinstance(exc, exception.SenlinException): exc.message = oslo_i18n.translate(exc.message, locale) else: exc.message = oslo_i18n.translate(six.text_type(exc), locale) if isinstance(exc, webob.exc.HTTPError): exc.explanation = oslo_i18n.translate(exc.explanation, locale) exc.detail = oslo_i18n.translate(getattr(exc, 'detail', ''), locale) return exc",88,197
openstack%2Ffuel-library~stable%2F8.0~I179d7e6b41ae84529f35975fbd98298380d49e47,openstack/fuel-library,stable/8.0,I179d7e6b41ae84529f35975fbd98298380d49e47,Configure correct gateway for cinder-vmware and compute-vmware nodes,MERGED,2016-02-12 16:11:44.000000000,2016-02-15 10:21:06.000000000,2016-02-15 10:20:19.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9977}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 11827}, {'_account_id': 12199}, {'_account_id': 13505}, {'_account_id': 14985}, {'_account_id': 15660}, {'_account_id': 15921}, {'_account_id': 16044}, {'_account_id': 17747}]","[{'number': 1, 'created': '2016-02-12 16:11:44.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/astute/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c2a335b5b725f1b994f78d4c78723d29fa44685a', 'message': 'Configure correct gateway for cinder-vmware and compute-vmware nodes\n\n- Add cinder-vmware and compute-vmware roles to task configure_default_route\n  like compute and cinder nodes.\n\nChange-Id: I179d7e6b41ae84529f35975fbd98298380d49e47\nCloses-bug: #1544067\n'}]",0,279631,c2a335b5b725f1b994f78d4c78723d29fa44685a,25,16,1,14946,,,0,"Configure correct gateway for cinder-vmware and compute-vmware nodes

- Add cinder-vmware and compute-vmware roles to task configure_default_route
  like compute and cinder nodes.

Change-Id: I179d7e6b41ae84529f35975fbd98298380d49e47
Closes-bug: #1544067
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/31/279631/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/astute/tasks.yaml'],1,c2a335b5b725f1b994f78d4c78723d29fa44685a,bug/1544067_9," role: [primary-mongo, mongo, compute, compute-vmware, ceph-osd, cinder, cinder-vmware]"," role: [primary-mongo, mongo, compute, ceph-osd, cinder]",1,1
openstack%2Fpython-heatclient~master~I3f9d64e4d76616e201374522f06a4e8938f00d4d,openstack/python-heatclient,master,I3f9d64e4d76616e201374522f06a4e8938f00d4d,OSC plugin for stack resource show and list,MERGED,2015-11-13 00:05:25.000000000,2016-02-15 10:18:54.000000000,2016-02-15 10:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 13009}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-13 00:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/74e92aefeacc77332533d5ccd20825082315e4a4', 'message': 'WIP: OSC plugin for stack resource show and list\n\nThis change implements ""openstack stack resource show"" and\n""openstack stack resource list"" command\n\nBlueprint: partially heat-support-python-openstackclient\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n'}, {'number': 2, 'created': '2015-11-17 23:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/550e3c87a6c46c0e1b56a585c2765ce17a7509d9', 'message': 'WIP: OSC plugin for stack resource show and list\n\nThis change implements ""openstack stack resource show"" and\n""openstack stack resource list"" command\n\nBlueprint: partially heat-support-python-openstackclient\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n'}, {'number': 3, 'created': '2016-02-01 22:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/b02ca335a579fae0cc0aa0062b23e90ad06c0c5a', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 4, 'created': '2016-02-02 19:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/34a9216943e709cb1aa0e9bb72e214701bb5bebb', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 5, 'created': '2016-02-03 22:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/34d3f9801bce45e5b39d25ff71701339c24c0c91', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 6, 'created': '2016-02-04 22:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6600d9b84bf22d6898cf8b1cb9782ba5a7b4cb1d', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 7, 'created': '2016-02-05 16:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ec51bd534a743ef2184215563abc880105262d84', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 8, 'created': '2016-02-09 15:00:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/86435097638cd386d0254365c861fb806b2e8cb0', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 9, 'created': '2016-02-09 20:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/13147fa6261a077e711a083181759f9e139cd672', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 10, 'created': '2016-02-10 14:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dabc78efdd7104484718b046b8d378731b86a823', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 11, 'created': '2016-02-10 22:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d9549988e82164d3e5f1d583281c85e48bc6328a', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}, {'number': 12, 'created': '2016-02-12 15:24:19.000000000', 'files': ['heatclient/osc/v1/resources.py', 'heatclient/osc/v1/stack.py', 'heatclient/tests/unit/osc/v1/test_resources.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/1d302a93bbad93127665d078dffcc049f03d7996', 'message': ""OSC plugin for stack resource show and list\n\nThis change implements the 'openstack stack resource show' and\n'openstack stack resource list' commands.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d\n""}]",16,244927,1d302a93bbad93127665d078dffcc049f03d7996,50,7,12,13664,,,0,"OSC plugin for stack resource show and list

This change implements the 'openstack stack resource show' and
'openstack stack resource list' commands.

Blueprint: heat-support-python-openstackclient

Change-Id: I3f9d64e4d76616e201374522f06a4e8938f00d4d
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/27/244927/9 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/resources.py', 'heatclient/tests/unit/osc/v1/test_resources.py', 'setup.cfg']",3,74e92aefeacc77332533d5ccd20825082315e4a4,bp/heat-support-python-openstackclient, stack_resource_show = heatclient.osc.v1.resources:ShowResource stack_resource_list = heatclient.osc.v1.resources:ListResources,,154,0
openstack%2Fpython-heatclient~master~I052be7ab510c40dac26a1fb7662016241976a2f7,openstack/python-heatclient,master,I052be7ab510c40dac26a1fb7662016241976a2f7,OpenstackClient plugin for event list,MERGED,2015-11-13 19:30:31.000000000,2016-02-15 10:18:49.000000000,2016-02-15 10:18:49.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 13664}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-13 19:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/38a7375c522acc985a7d1fbcb72c00285d881891', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 2, 'created': '2015-11-13 22:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/bb75c17cb1921a0648dba47e21d1369759783585', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 3, 'created': '2015-11-13 22:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/221282d9f2ee64bfff7eb3ffec55b1253d99028c', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 4, 'created': '2015-11-16 19:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/09fa33e7972822d80eb419d8f3ad0a3475661eed', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 5, 'created': '2015-11-23 17:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/24dc48a2eafa6db618e84db0f3f79ae45aaa3736', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 6, 'created': '2015-11-23 21:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7126ddd2c9193467d1411281043eb6b12a55eb32', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 7, 'created': '2015-12-07 21:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/c742eccfb7d8d2f7a9d520bf12064b3c326d555b', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 8, 'created': '2016-01-04 22:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/be7e4c6c0555a0a9c627d910cf02e2738aeeaaf8', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 9, 'created': '2016-01-11 21:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d6a6c35dac246b50a753c9e2637d23e88e23716f', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 10, 'created': '2016-01-15 14:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/4d7d43d2037609247ba9397b6ed3d72a43003e6e', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 11, 'created': '2016-02-03 20:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dcaa0e25a47e976db6189f20268d08f7437ef309', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 12, 'created': '2016-02-08 17:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/53235820cad04877751a2a2bac67ae9c86865729', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 13, 'created': '2016-02-09 14:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/2a07b4f16a29ee7313e25abb5f265f2e9120837e', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 14, 'created': '2016-02-09 21:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/e1723ce727d776932f22c5e5696e37e95466bb2b', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 15, 'created': '2016-02-10 21:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/9128a1699c4d7a2f306080af5109cee6e0c12012', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}, {'number': 16, 'created': '2016-02-12 15:24:19.000000000', 'files': ['heatclient/tests/unit/osc/v1/test_event.py', 'heatclient/osc/v1/event.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/efec30e2904a9b5a5f2bbdedd2972e21601cb87a', 'message': 'OpenstackClient plugin for event list\n\nThis change implements the ""openstack event list"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I052be7ab510c40dac26a1fb7662016241976a2f7\n'}]",33,245308,efec30e2904a9b5a5f2bbdedd2972e21601cb87a,70,8,16,11832,,,0,"OpenstackClient plugin for event list

This change implements the ""openstack event list"" command.

Blueprint: heat-support-python-openstackclient

Change-Id: I052be7ab510c40dac26a1fb7662016241976a2f7
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/08/245308/16 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/osc/v1/test_event.py', 'heatclient/osc/v1/event.py']",2,38a7375c522acc985a7d1fbcb72c00285d881891,bp/heat-support-python-openstackclient,"from cliff import listerfrom heatclient.common import event_utils class ListEvent(lister.Lister): '''List Events.''' log = logging.getLogger(__name__ + '.ListEvent') def get_parser(self, prog_name): parser = super(ListEvent, self).get_parser(prog_name) parser.add_argument( 'stack', metavar='<NAME or ID>', help=_('Name or ID of stack to show events for') ) parser.add_argument( '--resource', metavar='<RESOURCE>', help=_('Name of resource to filter events by') ) parser.add_argument( '--filter', metavar='<KEY=VALUE>', action='append', help=_('Filter parameters to apply on returned events') ) parser.add_argument( '--limit', metavar='<LIMIT>', type=int, help=_('Limit the number of events returned') ) parser.add_argument( '--marker', metavar='<ID>', help=_('Only return events that appear after the given ID') ) parser.add_argument( '--nested-depth', metavar='<DEPTH>', type=int, help=_('Depth of nested stacks from which to display events. ' 'Note: this cannot be specified with --resource') ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)', parsed_args) client = self.app.client_manager.orchestration columns = ['id', 'resource_status', 'resource_status_reason', 'event_time'] kwargs = { 'resource_name': parsed_args.resource, 'limit': parsed_args.limit, 'marker': parsed_args.marker, 'filters': utils.format_parameters(parsed_args.filter), 'sort_dir': 'asc' } if parsed_args.resource and parsed_args.nested_depth: msg = _('--nested-depth cannot be specified with --resource') raise exc.CommandError(msg) if parsed_args.nested_depth: # Until the API supports recursive event listing we'll have to do # the marker/limit filtering client-side del kwargs['marker'] del kwargs['limit'] columns.append('stack_name') nested_depth = parsed_args.nested_depth else: nested_depth = 0 events = event_utils.get_events( client, stack_id=parsed_args.stack, event_args=kwargs, nested_depth=nested_depth, marker=parsed_args.marker, limit=parsed_args.limit) if len(events) > 0: if hasattr(events[0], 'resource_name'): columns.insert(0, 'resource_name') else: columns.insert(0, 'logical_resource_id') return ( columns, (utils.get_dict_properties(s, columns) for s in events) )",,173,0
openstack%2Fpython-heatclient~master~Ie9614626969612e954270b1d2eb00ccd0034d274,openstack/python-heatclient,master,Ie9614626969612e954270b1d2eb00ccd0034d274,OpenstackClient plugin for event show,MERGED,2015-11-13 19:30:31.000000000,2016-02-15 10:18:43.000000000,2016-02-15 10:18:43.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 13664}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-13 19:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/207c6f1b8b82a2df6e7edbb21366fc4e6d8b69de', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 2, 'created': '2015-11-13 22:15:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/7fb35d7beaeeac8b17588dc12225530ebfd689ab', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 3, 'created': '2015-11-23 17:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/179afe1ba2e039588067b18c1cb9203211bd09c5', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 4, 'created': '2015-12-07 21:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/37cfb47c94e9b6a493ad5de757421cb1b899ae26', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 5, 'created': '2016-01-04 22:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/4a73935f82a7fc6a0ab07f1f569d8f0896ce44b2', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 6, 'created': '2016-01-11 21:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/1b259f90772735222b44e154a29252abd950a3f1', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 7, 'created': '2016-01-15 14:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/ea58e25c31da64277a8a36d277ddc01ff25b56f2', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 8, 'created': '2016-02-03 20:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d8f1e87ae5a3d9fc4c5b1743cae488e66a7a769c', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 9, 'created': '2016-02-08 17:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/1b67cf4ea68a993a0d7ae7e764c4660a5642a41b', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 10, 'created': '2016-02-09 14:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/8f208e72626aa9716cc44a7a8c75ae600d284e92', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 11, 'created': '2016-02-09 21:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/d0ab865c240261e206701ff52b60ed96b945bcb3', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 12, 'created': '2016-02-10 21:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a0e0c16c0174dfc6e2d5255f94a19bc953be76e6', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}, {'number': 13, 'created': '2016-02-12 15:24:19.000000000', 'files': ['heatclient/tests/unit/osc/v1/test_event.py', 'heatclient/osc/v1/event.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/55417bb44fd83b5265456ec02902f539132e830b', 'message': 'OpenstackClient plugin for event show\n\nThis change implements the ""openstack event show"" command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: Ie9614626969612e954270b1d2eb00ccd0034d274\n'}]",12,245307,55417bb44fd83b5265456ec02902f539132e830b,59,8,13,11832,,,0,"OpenstackClient plugin for event show

This change implements the ""openstack event show"" command.

Blueprint: heat-support-python-openstackclient

Change-Id: Ie9614626969612e954270b1d2eb00ccd0034d274
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/07/245307/11 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/osc/v1/test_event.py', 'heatclient/osc/v1/event.py']",2,207c6f1b8b82a2df6e7edbb21366fc4e6d8b69de,bp/heat-support-python-openstackclient,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # # Copyright 2015 IBM Corp. import logging from cliff import show from heatclient.common import utils from heatclient import exc from heatclient.openstack.common._i18n import _ class ShowEvent(show.ShowOne): log = logging.getLogger(__name__ + '.ShowEvent') def get_parser(self, prog_name): parser = super(ShowEvent, self).get_parser(prog_name) parser.add_argument( 'stack', metavar='<NAME or ID>', help=_('Name or ID of stack to show events for') ) parser.add_argument( 'resource', metavar='<RESOURCE>', help=_('Name of the resource event belongs to') ) parser.add_argument( 'event', metavar='<EVENT>', help=_('ID of event to display details for') ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)', parsed_args) client = self.app.client_manager.orchestration fields = { 'stack_id': parsed_args.stack, 'resource_name': parsed_args.resource, 'event_id': parsed_args.event } try: event = client.events.get(**fields) except exc.HTTPNotFound as ex: raise exc.CommandError(str(ex)) formatters = { 'links': utils.link_formatter, 'resource_properties': utils.json_formatter } utils.print_dict(event.to_dict(), formatters=formatters) ",,138,0
openstack%2Fpython-heatclient~master~I95df1390a9daee7115ccda68b261e0a76530ade4,openstack/python-heatclient,master,I95df1390a9daee7115ccda68b261e0a76530ade4,OpenstackClient plugin for stack delete,MERGED,2015-11-06 01:57:26.000000000,2016-02-15 10:14:25.000000000,2016-02-15 10:14:25.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 7404}, {'_account_id': 8399}, {'_account_id': 10487}, {'_account_id': 11832}, {'_account_id': 14033}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-06 01:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6972e36adb0675bd4534849b6cc4f80a98fe7878', 'message': '[WIP]: openstack stack delete\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n'}, {'number': 2, 'created': '2016-01-21 00:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/09e1f2a401f681e2ecd1dde560f4fc9b0fbee5ce', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 3, 'created': '2016-01-21 15:16:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/16bdc2cdfd87eed6d6dba346a48f76c0f423e6ac', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 4, 'created': '2016-01-25 16:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/50946c73b31144cef6e34c279a7a8003a573bee3', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 5, 'created': '2016-01-26 22:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/3e0f04df5692bbc416f1f30b43709d422032c0cf', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 6, 'created': '2016-01-29 14:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/030f958c62fe333dabcfc72efb114fb6178a4e45', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 7, 'created': '2016-02-03 19:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0904a6f1c13fc8fba2f7c67f2f0bf5b9cd940535', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 8, 'created': '2016-02-08 17:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/41705f86133c204c73a9f8388fad9c61e56bcaac', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 9, 'created': '2016-02-09 14:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/bc128dd2fdf824510d1a79e3812945a31f011caa', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 10, 'created': '2016-02-09 21:49:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/140d6c4467b7b8866487c81e01ae3607c2176874', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 11, 'created': '2016-02-10 20:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/72f6445cadf02a05920e578e3bbc736038e4e69d', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 12, 'created': '2016-02-10 21:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/794e080f76c812563179c194be70876cf9f6166d', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}, {'number': 13, 'created': '2016-02-12 15:24:19.000000000', 'files': ['heatclient/osc/v1/stack.py', 'heatclient/tests/unit/test_utils.py', 'heatclient/common/utils.py', 'setup.cfg', 'heatclient/tests/unit/osc/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/b696c52554b54cbe4cb74c7c45195718fb56014e', 'message': ""OpenstackClient plugin for stack delete\n\nThis change implements the 'openstack stack delete' command.\n\nBlueprint: heat-support-python-openstackclient\n\nChange-Id: I95df1390a9daee7115ccda68b261e0a76530ade4\n""}]",29,242302,b696c52554b54cbe4cb74c7c45195718fb56014e,71,9,13,13664,,,0,"OpenstackClient plugin for stack delete

This change implements the 'openstack stack delete' command.

Blueprint: heat-support-python-openstackclient

Change-Id: I95df1390a9daee7115ccda68b261e0a76530ade4
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/02/242302/4 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/stack.py', 'setup.cfg']",2,6972e36adb0675bd4534849b6cc4f80a98fe7878,bp/heat-support-python-openstackclient, stack_delete = heatclient.osc.v1.stack:DeleteStack,,23,0
openstack%2Fheat~master~I1af303bd51f6d3cbd3b03069145a47336186fc35,openstack/heat,master,I1af303bd51f6d3cbd3b03069145a47336186fc35,Do not convert resource_id to string,MERGED,2016-02-11 11:37:05.000000000,2016-02-15 10:10:41.000000000,2016-02-15 10:10:41.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8399}, {'_account_id': 8833}, {'_account_id': 11424}, {'_account_id': 12363}, {'_account_id': 13009}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-11 11:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/97ebfebee3cd1d5008bf6c23263010d338e76df9', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}, {'number': 2, 'created': '2016-02-11 13:02:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c1b93a8b1b9ed3e5becd517d48a4c4cc67a00091', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}, {'number': 3, 'created': '2016-02-12 04:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/2aacdb7d5ca48826a0df53dd9f2f56c7f2d3e612', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}, {'number': 4, 'created': '2016-02-14 03:50:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fb0d7e2a5f0b61162cd4fd50e834608dc175b4b4', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}, {'number': 5, 'created': '2016-02-14 05:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/536837b8094344af2525d91a5a0b76538b8419c0', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}, {'number': 6, 'created': '2016-02-15 02:45:35.000000000', 'files': ['heat/engine/resources/openstack/neutron/neutron.py', 'heat/engine/resources/openstack/neutron/floatingip.py', 'heat/tests/openstack/neutron/test_neutron_metering.py', 'heat/tests/openstack/neutron/test_neutron_net.py', 'heat/tests/openstack/neutron/test_neutron_subnet.py', 'heat/tests/openstack/neutron/test_neutron_floating_ip.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/7de870eb26d8ea9fa307e4b5dff44e9b6c60a1b0', 'message': ""Do not convert resource_id to string\n\nWe seem to be converting `resource_id` to string for neutron\nresources and as a result None(singleton) gets converted to 'None'.\nThis patch changes it and fixes the unit tests.\n\nChange-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35\nPartial-Bug: #1544227\n""}]",0,278997,7de870eb26d8ea9fa307e4b5dff44e9b6c60a1b0,27,9,6,8833,,,0,"Do not convert resource_id to string

We seem to be converting `resource_id` to string for neutron
resources and as a result None(singleton) gets converted to 'None'.
This patch changes it and fixes the unit tests.

Change-Id: I1af303bd51f6d3cbd3b03069145a47336186fc35
Partial-Bug: #1544227
",git fetch https://review.opendev.org/openstack/heat refs/changes/97/278997/6 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/neutron/neutron.py', 'heat/tests/openstack/neutron/test_neutron_metering.py', 'heat/tests/openstack/neutron/test_neutron_net.py', 'heat/tests/openstack/neutron/test_neutron_subnet.py', 'heat/tests/openstack/neutron/test_neutron_floating_ip.py']",5,97ebfebee3cd1d5008bf6c23263010d338e76df9,bug/1514680,," neutronV20.find_resourceid_by_name_or_id( mox.IsA(neutronclient.Client), 'router', 'None', cmd_resource=None, ).MultipleTimes().AndReturn('None')",59,42
openstack%2Fvitrage~master~Idd2928bb839a9740f14ea0023bcf93f1cf569e37,openstack/vitrage,master,Idd2928bb839a9740f14ea0023bcf93f1cf569e37,run_vitrage & stop_vitrage & get_topology,MERGED,2016-02-10 13:15:50.000000000,2016-02-15 10:05:20.000000000,2016-02-15 10:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 19122}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-02-10 13:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/4433cac509073adb2d968b95b46e78c056b4e5ce', 'message': 'pre_run_vitrage\n\nChange-Id: Idd2928bb839a9740f14ea0023bcf93f1cf569e37\n'}, {'number': 2, 'created': '2016-02-15 09:51:32.000000000', 'files': ['vitrage_tempest_tests/tests/api/__init__.py', 'requirements.txt', 'vitrage_tempest_tests/tests/stop_vitrage_env.py', 'vitrage_tempest_tests/tests/__init__.py', 'etc/vitrage/graph.sample.json', 'vitrage_tempest_tests/tests/api/base.py', 'vitrage_tempest_tests/tests/api/topology/__init__.py', 'vitrage_tempest_tests/tests/api/topology/topology.py', 'vitrage_tempest_tests/tests/run_vitrage_env.py', 'run_vitrage.sh', 'vitrage_tempest_tests/tests/base_mock.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/190e4a308739deebeef6a561531845b2583746d9', 'message': 'run_vitrage & stop_vitrage & get_topology\n\nChange-Id: Idd2928bb839a9740f14ea0023bcf93f1cf569e37\n'}]",5,278357,190e4a308739deebeef6a561531845b2583746d9,10,3,2,19765,,,0,"run_vitrage & stop_vitrage & get_topology

Change-Id: Idd2928bb839a9740f14ea0023bcf93f1cf569e37
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/57/278357/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage_tempest_tests/tests/api/__init__.py', 'vitrage_tempest_tests/tests/api/pre_run_vitrage.py', 'requirements.txt', 'etc/vitrage/graph.sample.json']",4,4433cac509073adb2d968b95b46e78c056b4e5ce,tempest_tests,"{ ""directed"": true, ""graph"": {}, ""nodes"": [ { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-8"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:20d12a8a-ea9a-89c6-5947-83bea959362e"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-2"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:dc35fa2f-4515-1653-ef6b-03b471bb395b"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-13"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:9879cf5a-bdcf-3651-3017-961ed887ec86"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-10"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:fe124f4b-9ed7-4591-fcd1-803cf5c33cb1"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-11"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:f2e48a97-7350-061e-12d3-84c6dc3e67c0"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""host-2"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.host"", ""id"": ""RESOURCE:nova.host:host-2"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""host-3"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.host"", ""id"": ""RESOURCE:nova.host:host-3"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""host-0"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.host"", ""id"": ""RESOURCE:nova.host:host-0"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""host-1"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.host"", ""id"": ""RESOURCE:nova.host:host-1"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-9"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:275097cf-954e-8e24-b185-9514e24b8591"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-1"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:a0f0805f-c804-cffe-c25a-1b38f555ed68"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-14"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:56af57d2-34a4-19b1-5106-b613637a11a7"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""zone-1"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.zone"", ""id"": ""RESOURCE:nova.zone:zone-1"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-3"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:16e14c58-d254-2bec-53e4-c766e48810aa"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-7"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:f35a1e10-74ff-7332-8edf-83cd6ffcb2de"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-4"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:ea8a450e-cab1-2272-f431-494b40c5c378"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-6"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:6e42bdc3-b776-1b2c-2c7d-b7a8bb98f721"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-5"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:8c951613-c660-87c0-c18b-0fa3293ce8d8"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""zone-0"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""available"", ""type"": ""nova.zone"", ""id"": ""RESOURCE:nova.zone:zone-0"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-0"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:78353ce4-2710-49b5-1341-b8cbb6000ebc"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""vm-12"", ""update_timestamp"": ""2015-12-01T12:46:41Z"", ""state"": ""ACTIVE"", ""project_id"": ""0683517e1e354d2ba25cba6937f44e79"", ""type"": ""nova.instance"", ""id"": ""RESOURCE:nova.instance:35bf479a-75d9-80a9-874e-d3b50fb2dd2e"" }, { ""category"": ""RESOURCE"", ""is_placeholder"": false, ""is_deleted"": false, ""name"": ""node"", ""type"": ""node"", ""id"": ""RESOURCE:node"" } ], ""links"": [ { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 3, ""key"": ""contains"", ""source"": 5 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 1, ""key"": ""contains"", ""source"": 5 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 16, ""key"": ""contains"", ""source"": 5 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 11, ""key"": ""contains"", ""source"": 5 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 13, ""key"": ""contains"", ""source"": 6 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 4, ""key"": ""contains"", ""source"": 6 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 14, ""key"": ""contains"", ""source"": 6 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 20, ""key"": ""contains"", ""source"": 7 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 0, ""key"": ""contains"", ""source"": 7 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 19, ""key"": ""contains"", ""source"": 7 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 15, ""key"": ""contains"", ""source"": 7 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 9, ""key"": ""contains"", ""source"": 8 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 10, ""key"": ""contains"", ""source"": 8 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 2, ""key"": ""contains"", ""source"": 8 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 17, ""key"": ""contains"", ""source"": 8 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 6, ""key"": ""contains"", ""source"": 12 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 8, ""key"": ""contains"", ""source"": 12 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 5, ""key"": ""contains"", ""source"": 18 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 7, ""key"": ""contains"", ""source"": 18 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 18, ""key"": ""contains"", ""source"": 21 }, { ""relationship_name"": ""contains"", ""is_deleted"": false, ""target"": 12, ""key"": ""contains"", ""source"": 21 } ], ""multigraph"": true }",,456,0
openstack%2Foslo.utils~master~Ie635370474f5e86d0d6188a52b581f04b14bd484,openstack/oslo.utils,master,Ie635370474f5e86d0d6188a52b581f04b14bd484,Remove bandit.yaml in favor of defaults,MERGED,2016-02-04 23:54:28.000000000,2016-02-15 10:05:14.000000000,2016-02-15 10:05:14.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2016-02-04 23:54:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/bc7ce7986208be3e9287dc6e9840928070c98d64', 'message': 'Remove bandit.yaml in favor of defaults\n\nWith latest bandit version, The bandit.yaml is only necessary\nfor advanced tweaking. We can just use the defaults.\n\nChange-Id: Ie635370474f5e86d0d6188a52b581f04b14bd484\n'}, {'number': 2, 'created': '2016-02-05 00:16:55.000000000', 'files': ['bandit.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.utils/commit/cf3de7d5f7878503b074cb42f7487119a1a50476', 'message': 'Remove bandit.yaml in favor of defaults\n\nWith latest bandit version, The bandit.yaml is only necessary\nfor advanced tweaking. We can just use the defaults.\n\nChange-Id: Ie635370474f5e86d0d6188a52b581f04b14bd484\n'}]",0,276510,cf3de7d5f7878503b074cb42f7487119a1a50476,13,6,2,5638,,,0,"Remove bandit.yaml in favor of defaults

With latest bandit version, The bandit.yaml is only necessary
for advanced tweaking. We can just use the defaults.

Change-Id: Ie635370474f5e86d0d6188a52b581f04b14bd484
",git fetch https://review.opendev.org/openstack/oslo.utils refs/changes/10/276510/2 && git format-patch -1 --stdout FETCH_HEAD,"['bandit.yaml', 'tox.ini']",2,bc7ce7986208be3e9287dc6e9840928070c98d64,,commands = bandit -r oslo_utils -n5 -p gate,commands = bandit -c bandit.yaml -r oslo_utils -n5 -p gate,1,360
openstack%2Fmanila~master~Iaa6269e66f387353c37d3209b1e773b172998592,openstack/manila,master,Iaa6269e66f387353c37d3209b1e773b172998592,Incomplete parameter validation of qos in Huawei Driver,ABANDONED,2016-02-15 05:09:13.000000000,2016-02-15 10:04:54.000000000,,"[{'_account_id': 3}, {'_account_id': 12017}, {'_account_id': 14384}, {'_account_id': 15942}, {'_account_id': 16643}, {'_account_id': 17623}, {'_account_id': 17742}, {'_account_id': 18752}]","[{'number': 1, 'created': '2016-02-15 05:09:13.000000000', 'files': ['manila/share/drivers/huawei/v3/connection.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/share/drivers/huawei/v3/smartx.py', 'manila/share/drivers/huawei/constants.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/24c63cf234cfe3e3fbbe6c918b5ef9df0c39adfe', 'message': 'Incomplete parameter validation of qos in Huawei Driver\n\nWhen creating a qos share, incomplete parameter validation will\ncause shares been added into improper qos group.\nWhile some of Huawei array do not support qos, compatibility will\nbe a problem, so we will take array version into account.\n\nChange-Id: Iaa6269e66f387353c37d3209b1e773b172998592\nCloses-Bug: #1545559\n'}]",16,280065,24c63cf234cfe3e3fbbe6c918b5ef9df0c39adfe,11,8,1,17742,,,0,"Incomplete parameter validation of qos in Huawei Driver

When creating a qos share, incomplete parameter validation will
cause shares been added into improper qos group.
While some of Huawei array do not support qos, compatibility will
be a problem, so we will take array version into account.

Change-Id: Iaa6269e66f387353c37d3209b1e773b172998592
Closes-Bug: #1545559
",git fetch https://review.opendev.org/openstack/manila refs/changes/65/280065/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/huawei/v3/connection.py', 'manila/share/drivers/huawei/v3/helper.py', 'manila/share/drivers/huawei/v3/smartx.py', 'manila/share/drivers/huawei/constants.py', 'manila/tests/share/drivers/huawei/test_huawei_nas.py']",5,24c63cf234cfe3e3fbbe6c918b5ef9df0c39adfe,bug/1545559," ""qos:maxBandWidth"": ""50"", ""qos:IOType"": ""0""}, ""fake_qos_info"": {""MAXIOPS"": ""100"", ""MAXBANDWIDTH"": ""50"", ""IOType"": ""0"", ""qos:IOType"": ""1""}, ""fake_qos_info"": {""NAME"": ""fake_qos"", ""MAXIOPS"": ""100"", ""IOTYPE"": ""1""}})"," ""qos:minIOPS"": ""50""}, ""fake_qos_info"": {""MAXIOPS"": ""100"", ""MINIOPS"": ""50"", ""qos:minIOPS"": ""50""}, ""fake_qos_info"": {""NAME"": ""fake_qos"", ""MAXIOPS"": ""100""}})",65,35
openstack%2Fmurano~master~I495c7630f7564e477c3b68a7a818ec3671ea885c,openstack/murano,master,I495c7630f7564e477c3b68a7a818ec3671ea885c,Exclude releasenotes while run flake8 tests,ABANDONED,2015-12-30 09:28:56.000000000,2016-02-15 10:02:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-30 09:28:56.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/58feefec103d37dee3754ea0c65876cf6bb5d3ce', 'message': 'Exclude releasenotes while run flake8 tests\n\nChange-Id: I495c7630f7564e477c3b68a7a818ec3671ea885c\n'}]",0,262422,58feefec103d37dee3754ea0c65876cf6bb5d3ce,12,5,1,6763,,,0,"Exclude releasenotes while run flake8 tests

Change-Id: I495c7630f7564e477c3b68a7a818ec3671ea885c
",git fetch https://review.opendev.org/openstack/murano refs/changes/22/262422/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,58feefec103d37dee3754ea0c65876cf6bb5d3ce,exclude_ro,"exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,tools,releasenotes","exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,tools",1,1
openstack%2Fmurano-dashboard~master~I3bfe72c215bc370b8551e691d8b5c5d0a9d9266a,openstack/murano-dashboard,master,I3bfe72c215bc370b8551e691d8b5c5d0a9d9266a,Exclude releasenotes while run flake8 tests,ABANDONED,2015-12-30 09:20:56.000000000,2016-02-15 10:01:50.000000000,,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-30 09:20:56.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ccac29c615e4897f7459f500f5ddd273deff5a02', 'message': 'Exclude releasenotes while run flake8 tests\n\nChange-Id: I3bfe72c215bc370b8551e691d8b5c5d0a9d9266a\n'}]",0,262419,ccac29c615e4897f7459f500f5ddd273deff5a02,9,6,1,6763,,,0,"Exclude releasenotes while run flake8 tests

Change-Id: I3bfe72c215bc370b8551e691d8b5c5d0a9d9266a
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/19/262419/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ccac29c615e4897f7459f500f5ddd273deff5a02,exclude_releasenotes,"exclude=.build,.venv,.git,.tox,dist,doc,*lib/python*,*egg,tools,horizon,settings.py,*/local/*,releasenotes","exclude=.build,.venv,.git,.tox,dist,doc,*lib/python*,*egg,tools,horizon,settings.py,*/local/*",1,1
openstack%2Frpm-packaging~master~I63622f025ddb28825d64cf7c3259aae9aeb89439,openstack/rpm-packaging,master,I63622f025ddb28825d64cf7c3259aae9aeb89439,Add initial spec for keystoneauth1,MERGED,2016-02-09 17:08:41.000000000,2016-02-15 09:55:35.000000000,2016-02-15 09:55:35.000000000,"[{'_account_id': 3}, {'_account_id': 1955}, {'_account_id': 6593}, {'_account_id': 6717}, {'_account_id': 6835}, {'_account_id': 7102}, {'_account_id': 7613}, {'_account_id': 10384}, {'_account_id': 19648}]","[{'number': 1, 'created': '2016-02-09 17:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/f5758cd337f0ee7f4be68be7e09ff45c34bb44c5', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 2, 'created': '2016-02-09 17:25:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/04328919b47c858b36708af2d0cf3f9b7548fec5', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 3, 'created': '2016-02-11 14:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/a8ddd2c29db2680f8cd66ff3178b7b87cc02c87a', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 4, 'created': '2016-02-12 19:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ba044545aab86cbeaa1531acac249693bf0e7185', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 5, 'created': '2016-02-13 09:44:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0e2d3352b92cdf0811ef2e2eac3ff83da62306bb', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 6, 'created': '2016-02-13 10:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/0e0e96a93a6a1e04594895cdac5f4af3442888cb', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 7, 'created': '2016-02-13 12:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/86244781d1bb80d1036edc40f05b064abc221208', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 8, 'created': '2016-02-13 21:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/6cb2d46105aa62c33f5af5c3e080232dc1cb8012', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}, {'number': 9, 'created': '2016-02-14 10:11:32.000000000', 'files': ['openstack/keystoneauth1/keystoneauth1.spec.j2'], 'web_link': 'https://opendev.org/openstack/rpm-packaging/commit/ece8b9001a75a59c271595bfbc30aeffc3330ecf', 'message': 'Add initial spec for keystoneauth1\n\nChange-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439\n'}]",12,277966,ece8b9001a75a59c271595bfbc30aeffc3330ecf,44,9,9,7102,,,0,"Add initial spec for keystoneauth1

Change-Id: I63622f025ddb28825d64cf7c3259aae9aeb89439
",git fetch https://review.opendev.org/openstack/rpm-packaging refs/changes/66/277966/7 && git format-patch -1 --stdout FETCH_HEAD,['openstack/keystoneauth1/keystoneauth1.spec.j2'],1,f5758cd337f0ee7f4be68be7e09ff45c34bb44c5,277966,"%global sname keystoneauth1 Name: {{ 'keystoneauth1' | py2pkg }} Version: 2.2.0 Release: 0 Summary: OpenStack authenticating tools License: {{ 'Apache-2.0' | license }} Url: https://launchpad.net/%{sname} Source0: https://pypi.python.org/packages/source/k/%{sname}/%{sname}-%{version}.tar.gz BuildRequires: openstack-macros BuildRequires: {{ 'pbr' | py2pkg }} BuildRequires: {{ 'fixtures' | py2pkg }} BuildRequires: {{ 'mock' | py2pkg }} BuildRequires: {{ 'oauthlib' | py2pkg }} BuildRequires: {{ 'oslo.config' | py2pkg }} BuildRequires: {{ 'oslotest' | py2pkg }} BuildRequires: {{ 'os-testr' | py2pkg }} BuildRequires: {{ 'pycrypto' | py2pkg }} BuildRequires: {{ 'requests-mock' | py2pkg }} BuildRequires: {{ 'tempest-lib' | py2pkg }} BuildRequires: {{ 'testrepository' | py2pkg }} BuildRequires: {{ 'testresources' | py2pkg }} BuildRequires: {{ 'testtools' | py2pkg }} BuildRequires: {{ 'WebOb' | py2pkg }} BuildRequires: {{ 'lxml' | py2pkg }} BuildRequires: {{ 'requests-kerberos' | py2pkg }} BuildRequires: {{ 'betamax' | py2pkg }} Requires: {{ 'argparse' | py2pkg }} Requires: {{ 'iso8601' | py2pkg }} >= 0.1.9 Requires: {{ 'requests' | py2pkg }} >= 2.8.1 Requires: {{ 'six' | py2pkg }} >= 1.9.0 Requires: {{ 'stevedore' | py2pkg }} >= 1.5.0 Requires: {{ 'lxml' | py2pkg }} >= 2.3 Requires: {{ 'requests-kerberos' | py2pkg }} >= 0.6 BuildArch: noarch %description Tools for authenticating to an OpenStack-based cloud. These tools include: * Authentication plugins (password, token, and federation based) * Discovery mechanisms to determine API version support * A session that is used to maintain client settings across requests (based on the requests Python library) %package doc Summary: Documentation for OpenStack authenticating tools BuildRequires: {{ 'Sphinx' | py2pkg }} BuildRequires: {{ 'oslosphinx' | py2pkg }} %description doc Documentation for OpenStack authenticating tools. %prep %setup -q -n %{sname}-%{version} %build %{__python2} setup.py build %install %{__python2} setup.py install --skip-build --root %{buildroot} # generate html docs %{__python2} setup.py build_sphinx # remove the sphinx-build leftovers rm -rf doc/build/html/.{doctrees,buildinfo} %check %{__python2} setup.py test %files %if 0%{?suse_version} %doc LICENSE %else %license LICENSE %endif %doc AUTHORS ChangeLog README.rst %{python2_sitelib}/keystoneauth1 %{python2_sitelib}/*.egg-info %files doc %doc doc/build/html %doc LICENSE %changelog ",,83,0
openstack%2Ffuel-qa~master~Ic4086dde60ca8a94dcd2ee079376c97ce719ff03,openstack/fuel-qa,master,Ic4086dde60ca8a94dcd2ee079376c97ce719ff03,Add new runner for system test,MERGED,2015-10-28 18:37:09.000000000,2016-02-15 09:55:05.000000000,2016-02-15 09:55:05.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11587}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 19119}]","[{'number': 1, 'created': '2015-10-28 18:37:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ede4d65254164931cf341bed31017404fe9817b2', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 2, 'created': '2015-10-29 16:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9bad0dc9197284adf8d4165567d86ccddab86e11', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 3, 'created': '2015-10-29 16:49:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2b00f5ba0da7ef052f083f5425cea68f598594de', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 4, 'created': '2015-11-02 13:45:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/4bbade2f22cebf73a90548371728f757fd450866', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 5, 'created': '2015-11-02 17:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f70751f61c5b379aeebe8bb8cea80a0c4d9722f9', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 6, 'created': '2015-11-02 17:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/fdf98ac575ff4e513ae699039214b28b27d1a041', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 7, 'created': '2015-11-02 17:13:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/03ff9f07b12c41840d9f62d189592cfd6e5f038a', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 8, 'created': '2015-11-06 15:34:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/86789b754343fdd07853fa3a991774e8772d1c02', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 9, 'created': '2015-11-20 12:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/02601c035467f0f399a3071bc4513be2d7043fb1', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 10, 'created': '2015-11-23 14:13:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1964911fec701604e06ea88683ca22339995feff', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 11, 'created': '2015-11-24 10:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/561095fcdea43e353e69eae4520f6189957fe096', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 12, 'created': '2015-11-27 15:18:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/482e09ef9b31291ccf42b2f3673206418f5fe967', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 13, 'created': '2015-11-27 16:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/626e2049b9601c376953e0d44003aea4961b60c7', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 14, 'created': '2015-11-27 16:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/3b3635b87a96b532c65ca9d7aeedd80473854960', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 15, 'created': '2016-01-14 14:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1641ca758ec20625922af7285f93fec20213abf1', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 16, 'created': '2016-01-29 17:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e1626a15efd993c494e25217de43e79c451c75ea', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 17, 'created': '2016-01-29 17:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9d5198f137ec76a8b01f8fff412e2bfdbe7728be', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 18, 'created': '2016-01-29 17:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/61a9ec398671317b0d6b56790f260c4d23f707ff', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 19, 'created': '2016-01-29 18:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/3d25d523888164fadb57ff1fa17db1187d136817', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 20, 'created': '2016-01-29 18:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c5c7be187f84452f4522d1b346bb50d76f536d57', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 21, 'created': '2016-01-29 18:04:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/22be78c358dae67a7cc9379310bfc88f52b9551a', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 22, 'created': '2016-01-29 18:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/26179a1d68ad9c56a6838b706f565b01b9baa38e', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 23, 'created': '2016-02-01 16:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a381e3f6dc5cbcbb871be30c2ebff9a77a8cfa4b', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 24, 'created': '2016-02-02 13:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/2949ed0e28dc2e804a3483cfd61f56746ad37205', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 25, 'created': '2016-02-02 13:56:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9639750ee526827217d59863978bba83aaa51876', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 26, 'created': '2016-02-11 10:32:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/3f46996134cfc047596071f9d6fe3f3aca8c2956', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}, {'number': 27, 'created': '2016-02-11 14:58:50.000000000', 'files': ['fuelweb_test/tests/tests_security/test_run_nessus.py', 'system_test/helpers/decorators.py', 'system_test/tests/strength/test_destroy_controllers.py', 'system_test/core/discover.py', 'system_test/tests/test_create_deploy_ostf.py', 'fuelweb_test/run_tests.py', 'system_test/tests/plugins/plugin_example/test_plugin_example.py', 'system_test/tests/plugins/plugin_example/test_plugin_example_v3.py', 'system_test/tests/test_redeploy_after_stop.py', 'fuelweb_test/testrail/upload_cases_description.py', 'system_test/core/repository.py', 'system_test/helpers/utils.py', 'system_test/tests/test_fuel_migration.py', 'system_test/core/__init__.py', 'system_test/tests/vcenter/test_vcenter_dvs.py', 'system_test/tests/strength/test_filling_root.py', 'system_test/tests/test_redeploy_after_reset.py', 'system_test/__init__.py', 'system_test/tests/test_deploy_check_rados.py', 'utils/jenkins/system_tests.sh', 'system_test/tests/base_actions_factory.py', 'run_system_test.py', 'system_test/tests/test_delete_after_deploy.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c106f6be549f68df3e42e11db8e7423d0e8c08bc', 'message': 'Add new runner for system test\n\nFor run the tests from both test suites (fuelweb_test, system_test) we\n    may use new runner - run_system_test.py.\n\nChanges in framework:\n    - add @testcase decorator use instead of @factory\n\nFeatures of new runner:\n    - auto discovering all test in both test suites\n    - show the groups from the test suites\n    - explain content of groups\n    - run the several groups at the same time\n    - combine configuration with the test groups from new suite\n    - run old groups\n    - use runner in utils/jenkins/system_tests.sh\n\nChanges in tests:\n    - remove @factory function\n    - add @testcase to each test class\n\nChange-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03\nImplemets blueprint template-based-testcases\n'}]",44,240016,c106f6be549f68df3e42e11db8e7423d0e8c08bc,172,16,27,12867,,,0,"Add new runner for system test

For run the tests from both test suites (fuelweb_test, system_test) we
    may use new runner - run_system_test.py.

Changes in framework:
    - add @testcase decorator use instead of @factory

Features of new runner:
    - auto discovering all test in both test suites
    - show the groups from the test suites
    - explain content of groups
    - run the several groups at the same time
    - combine configuration with the test groups from new suite
    - run old groups
    - use runner in utils/jenkins/system_tests.sh

Changes in tests:
    - remove @factory function
    - add @testcase to each test class

Change-Id: Ic4086dde60ca8a94dcd2ee079376c97ce719ff03
Implemets blueprint template-based-testcases
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/16/240016/12 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/testrail/upload_tempest_test_suite.py', 'fuelweb_test/tests/tests_security/test_run_nessus.py', 'fuelweb_test/testrail/report_tempest_results.py', 'fuelweb_test/testrail/builds.py', 'system_test/tests/strength/test_destroy_controllers.py', 'fuelweb_test/testrail/upload_cases_description.py', 'system_test/helpers/utils.py', 'fuelweb_test/testrail/report_pi.py', 'fuelweb_test/testrail/__init__.py', 'system_test/tests/base_actions_factory.py', 'run_system_test.py', 'fuelweb_test/testrail/testrail_client.py', 'fuelweb_test/testrail/report.py']",13,ede4d65254164931cf341bed31017404fe9817b2,bp/template-based-testcases,from fuelweb_test.settings import JENKINS from fuelweb_test.settings import GROUPS_TO_EXPAND from fuelweb_test.settings import LaunchpadSettings from fuelweb_test.settings import LOGS_DIR from fuelweb_test.settings import logger from fuelweb_test.settings import TestRailSettings,from settings import JENKINS from settings import GROUPS_TO_EXPAND from settings import LaunchpadSettings from settings import LOGS_DIR from settings import logger from settings import TestRailSettings,279,43
openstack%2Fpython-aodhclient~master~I2da7689b552dfbae51e7a5d8d091afef9f44f5d2,openstack/python-aodhclient,master,I2da7689b552dfbae51e7a5d8d091afef9f44f5d2,check the alarm type when list alarm,MERGED,2016-02-01 02:08:25.000000000,2016-02-15 09:54:06.000000000,2016-02-15 09:54:06.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 7478}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-02-01 02:08:25.000000000', 'files': ['aodhclient/v2/alarm_cli.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/072801bca5780e7d563b55a2bd7b9424d7190742', 'message': 'check the alarm type when list alarm\n\nwhen list alarm with type, the type can be anything, this patch add\nchoice parameter in the parser.\n\nChange-Id: I2da7689b552dfbae51e7a5d8d091afef9f44f5d2\n'}]",0,274488,072801bca5780e7d563b55a2bd7b9424d7190742,7,5,1,18137,,,0,"check the alarm type when list alarm

when list alarm with type, the type can be anything, this patch add
choice parameter in the parser.

Change-Id: I2da7689b552dfbae51e7a5d8d091afef9f44f5d2
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/88/274488/1 && git format-patch -1 --stdout FETCH_HEAD,['aodhclient/v2/alarm_cli.py'],1,072801bca5780e7d563b55a2bd7b9424d7190742,," choices=ALARM_TYPES, help='Type of alarm')", help='Type of alarm'),1,1
openstack%2Ftempest~master~Iae79feb63a8bee82020a634089a3fba111fecec6,openstack/tempest,master,Iae79feb63a8bee82020a634089a3fba111fecec6,Create new test for incremental backup in cinder,ABANDONED,2015-12-03 14:03:38.000000000,2016-02-15 09:53:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1736}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7227}, {'_account_id': 7350}, {'_account_id': 7872}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 13420}, {'_account_id': 14614}, {'_account_id': 16437}, {'_account_id': 18785}]","[{'number': 1, 'created': '2015-12-03 14:03:38.000000000', 'files': ['tempest/api/volume/admin/test_volumes_backup.py', 'tempest/services/volume/base/base_backups_client.py', 'tempest/config.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/9e9dededa5a7bcb36625626db0aa26a8e3afc262', 'message': 'Create new test for incremental backup in cinder\n\nAdd new test: test_incremental_backup.\nCode refactoring for old tests.\n\nChange-Id: Iae79feb63a8bee82020a634089a3fba111fecec6\nCloses-Bug: #1506394\n'}]",0,252964,9e9dededa5a7bcb36625626db0aa26a8e3afc262,12,19,1,14510,,,0,"Create new test for incremental backup in cinder

Add new test: test_incremental_backup.
Code refactoring for old tests.

Change-Id: Iae79feb63a8bee82020a634089a3fba111fecec6
Closes-Bug: #1506394
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/252964/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/volume/admin/test_volumes_backup.py', 'tempest/services/volume/base/base_backups_client.py', 'tempest/config.py']",3,9e9dededa5a7bcb36625626db0aa26a8e3afc262,bug/1506394," 'Not implemented on icehouse '), cfg.BoolOpt('incremental_backup_force', default=False, help='Force create and delete backup not ' 'implemented on Juno and Kilo.')", 'Not implemented on icehouse '),83,13
openstack%2Fheat~stable%2Fkilo~I0090d11219e2e8b2220477376048030e657c0a62,openstack/heat,stable/kilo,I0090d11219e2e8b2220477376048030e657c0a62,Fix a grammatical mistake of the example online.,ABANDONED,2016-02-15 09:20:47.000000000,2016-02-15 09:49:12.000000000,,[{'_account_id': 6577}],"[{'number': 1, 'created': '2016-02-15 09:20:47.000000000', 'files': ['doc/source/template_guide/hot_spec.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/59e6317cee57ea2b85a4f627c0d47ffdb2084354', 'message': "" Fix a grammatical mistake of the example online.\n\n Yaml don't support a value define like %value%.\n For this reason,the example online can't run successfully.\n\n Closes-Bug: #1542591\n\nChange-Id: I0090d11219e2e8b2220477376048030e657c0a62\n""}]",0,280117,59e6317cee57ea2b85a4f627c0d47ffdb2084354,3,1,1,19963,,,0," Fix a grammatical mistake of the example online.

 Yaml don't support a value define like %value%.
 For this reason,the example online can't run successfully.

 Closes-Bug: #1542591

Change-Id: I0090d11219e2e8b2220477376048030e657c0a62
",git fetch https://review.opendev.org/openstack/heat refs/changes/17/280117/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/template_guide/hot_spec.rst'],1,59e6317cee57ea2b85a4f627c0d47ffdb2084354,bug/1542591, <%port%>: { get_param: ports } port_range_min: <%port%> port_range_max: <%port%> <%port%>: { get_param: ports } <%protocol%>: { get_param: protocols } template: protocol: <%protocol%> port_range_min: <%port%>, %port%: { get_param: ports } port_range_min: %port% port_range_max: %port% %port%: { get_param: ports } %protocol%: { get_param: protocols } template: protocol: %protocol% port_range_min: %port%,7,7
openstack%2Fneutron~master~Id944b27dcd84a92bf15242f5797408bf83b0d317,openstack/neutron,master,Id944b27dcd84a92bf15242f5797408bf83b0d317,Pecan: Fix association of plugins with resources,MERGED,2016-02-05 12:39:26.000000000,2016-02-15 09:47:02.000000000,2016-02-15 09:47:02.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 14323}]","[{'number': 1, 'created': '2016-02-05 12:39:26.000000000', 'files': ['neutron/api/extensions.py', 'neutron/pecan_wsgi/startup.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/517aa03da35fb4cfb3b16a5abbcc8115727b4a77', 'message': 'Pecan: Fix association of plugins with resources\n\nThe process was leveraing the supported_extension_aliases\nattribute, which might not provide a complete list of extension\naliases.\n\nWith this patch now Pecan leverages helper methods available\nin the extension manager, which have been slightly refactored in\norder to allow for retrieving aliases for a single plugin.\n\nCloses-Bug: #1542277\n\nChange-Id: Id944b27dcd84a92bf15242f5797408bf83b0d317\n'}]",1,276707,517aa03da35fb4cfb3b16a5abbcc8115727b4a77,18,9,1,261,,,0,"Pecan: Fix association of plugins with resources

The process was leveraing the supported_extension_aliases
attribute, which might not provide a complete list of extension
aliases.

With this patch now Pecan leverages helper methods available
in the extension manager, which have been slightly refactored in
order to allow for retrieving aliases for a single plugin.

Closes-Bug: #1542277

Change-Id: Id944b27dcd84a92bf15242f5797408bf83b0d317
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/276707/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/api/extensions.py', 'neutron/pecan_wsgi/startup.py']",2,517aa03da35fb4cfb3b16a5abbcc8115727b4a77,bug/1542277, ext_aliases = ext_mgr.get_plugin_supported_extension_aliases(plugin)," ext_aliases = getattr(plugin, 'supported_extension_aliases', [])",17,11
openstack%2Fproject-config~master~I150640990fb900318878563544af91e0a6043882,openstack/project-config,master,I150640990fb900318878563544af91e0a6043882,always make upper-constraints available to python jobs,MERGED,2016-02-10 12:36:50.000000000,2016-02-15 09:45:54.000000000,2016-02-15 09:45:53.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-10 12:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/92e38eb3fe4b82733d2b90e982caeb1112270fb6', 'message': 'always make upper-constraints available to python jobs\n\nFor all the python jobs, always make the constraints available. This\nallows projects to have py27 target use constraints without having a\nparallel set of jobs.\n\nChange-Id: I150640990fb900318878563544af91e0a6043882\n'}, {'number': 2, 'created': '2016-02-10 12:40:19.000000000', 'files': ['jenkins/jobs/python-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/6cada96ba1de08b4282dccd302037e0e943456f2', 'message': 'always make upper-constraints available to python jobs\n\nFor all the python jobs, always make the constraints available. This\nallows projects to have py27 target use constraints without having a\nparallel set of jobs.\n\nChange-Id: I150640990fb900318878563544af91e0a6043882\n'}]",1,278335,6cada96ba1de08b4282dccd302037e0e943456f2,12,4,2,2750,,,0,"always make upper-constraints available to python jobs

For all the python jobs, always make the constraints available. This
allows projects to have py27 target use constraints without having a
parallel set of jobs.

Change-Id: I150640990fb900318878563544af91e0a6043882
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/278335/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/python-jobs.yaml'],1,92e38eb3fe4b82733d2b90e982caeb1112270fb6,constraints-patch1, - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints - zuul-git-prep-upper-constraints, - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep - gerrit-git-prep,7,7
openstack%2Ftrove~master~I3671a737d3e71305982d8f4965215a73e785ea2d,openstack/trove,master,I3671a737d3e71305982d8f4965215a73e785ea2d,Add backup & restore for Cassandra,MERGED,2015-07-28 22:37:34.000000000,2016-02-15 09:32:19.000000000,2016-02-15 09:32:19.000000000,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 9746}, {'_account_id': 10215}, {'_account_id': 10295}, {'_account_id': 14576}]","[{'number': 1, 'created': '2015-07-28 22:37:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/8b355c4d9e6f506014e22db5e85f23134ab20213', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 2, 'created': '2015-07-31 22:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6bc6916efac5dd7aef498bc2c0de214ce351cb2e', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 3, 'created': '2015-08-01 03:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/2c587c0009bb4b381075f1a69588c50b82195c3d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 4, 'created': '2015-08-02 01:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/fa23525ee8a76751c26275d4d575609908c13eb1', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 5, 'created': '2015-08-02 02:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/680800af36ff1101d0ad4093c0905eb6eec7b747', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 6, 'created': '2015-08-02 16:15:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4a060b14a7d217de42a85efa483ac2ed9801c9c2', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 7, 'created': '2015-08-14 21:26:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/bf0b448ebeb4a785f5dd991691b3f65411f89a5a', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 8, 'created': '2015-08-15 23:45:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/aa03e80c73db2a18b312eeb53252ef8f43d03256', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 9, 'created': '2015-08-17 15:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5832e8de4edbd1859fb24356edc9c3bed678c457', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 10, 'created': '2015-08-17 22:15:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/cb6cf940f2e9575bb6bcca38c4739e1a5601a60d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 11, 'created': '2015-09-05 05:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ebe407c83bd039967d5dc510dd1b36a3a44b08bd', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 12, 'created': '2015-09-24 17:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/71b7a75a66f9749d66c6040d453c521e3bc1a3d8', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 13, 'created': '2015-10-09 15:25:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7dbdf9f01350b37c5903c0cf7bb74a3de28e3bda', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 14, 'created': '2015-11-05 13:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/e83286d952f8c438a093d803ac081375ac1d73e3', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 15, 'created': '2015-11-05 20:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ee2f663c4d8974479630c96cffc071557d0d6af7', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 16, 'created': '2015-11-08 14:29:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/d1ab5a48fef1cd75d473b2089aef660ead5f88fd', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 17, 'created': '2015-11-09 14:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/0803ab8067d46519a0bfd756f4a18533581d39f7', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 18, 'created': '2015-11-12 00:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/1250c2862e093ad3e6ad78dc8f866cd95b241b0d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d""}, {'number': 19, 'created': '2015-12-07 19:57:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/421f40a22034895b76933a6119355dfab760ad0e', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d""}, {'number': 20, 'created': '2015-12-07 21:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/294a4b2ae8eb51ca1dc3d1c9ea4798fca21215a7', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 21, 'created': '2015-12-07 21:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/65d0dd165c04ca84b37e52bd63df4073980d2f3c', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 22, 'created': '2015-12-09 23:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/918e0f579038b72245b38ff6a6ae1d7139cb25db', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 23, 'created': '2015-12-11 16:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/291f192e66526a7d818bb04e63bf7e08eeac898a', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 24, 'created': '2015-12-17 16:42:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/5406bf07792f71e64676cbd6ded413c3c7029221', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 25, 'created': '2015-12-18 21:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/87d1ffccc0f37f2f04244beec0f7fedbf688c27e', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 26, 'created': '2016-01-07 21:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/02c8efe86a6b92feaf707129d381edcac33b239d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 27, 'created': '2016-01-07 23:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/114e6625c23a90f64f1dc131937c1d27cf7c641b', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 28, 'created': '2016-01-08 01:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ed8249408f2605f4553b0017be50ddd57b4f7b75', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 29, 'created': '2016-01-20 22:12:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9c3bf1f81a95f2af592000d3766b808ff8c9c0c1', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 30, 'created': '2016-01-25 18:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/85836d98b7d338cf47bb474968e2b48a30e6a52e', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 31, 'created': '2016-01-26 22:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/23412a1071a709f273bd7b1d715f08216dff397b', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 32, 'created': '2016-01-27 02:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/c61d5927aacd9c56ba9385484670f336d435cb83', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 33, 'created': '2016-02-02 18:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/85c4504a153c3caccc70e1073f9e4db057150eb0', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 34, 'created': '2016-02-03 20:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/9e1fbd75d48027fb231efafc59c929b71638161d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 35, 'created': '2016-02-05 18:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4382a4ffa2f76a94f16e7edc4dd7a6bbd2eae9fe', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 36, 'created': '2016-02-05 19:53:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3b3ea78777a1dd3b67d5250f5f415b5089d1f84b', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 37, 'created': '2016-02-09 16:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/3df372ca488df570ab2ba93e9cced46749d9fa4d', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 38, 'created': '2016-02-10 15:26:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/a2f769de62393cd7504aee54cf931186fb8b37df', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 39, 'created': '2016-02-10 17:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/320971e5d0bf88efb748651c852a160a8c3fc05f', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 40, 'created': '2016-02-10 20:45:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/7885c54acf367a59173a2f5948071a1c9908cd14', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}, {'number': 41, 'created': '2016-02-13 03:29:28.000000000', 'files': ['etc/trove/trove-guestagent.conf.sample', 'trove/common/cfg.py', 'trove/guestagent/strategies/restore/experimental/cassandra_impl.py', 'trove/guestagent/strategies/backup/experimental/cassandra_impl.py', 'trove/taskmanager/models.py', 'trove/guestagent/datastore/experimental/cassandra/manager.py', 'trove/guestagent/datastore/experimental/cassandra/service.py', 'trove/tests/unittests/backup/test_backupagent.py', 'trove/tests/scenario/helpers/cassandra_helper.py', 'trove/tests/unittests/guestagent/test_backups.py', 'trove/tests/unittests/guestagent/test_cassandra_manager.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/e722342ce7a94a1b8fa3f43ae82cf3ef69013389', 'message': ""Add backup & restore for Cassandra\n\nImplement backup and restore functionality for Cassandra datastore.\n\nWe implement full backup strategy using the Nodetool\n(http://goo.gl/QtXVsM) utility.\n\nSnapshots:\n\nNodetool can take a snapshot of one or more keyspace(s).\nSnapshot(s) will be stored in the data directory tree:\n'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'\n\nA snapshot can be restored by moving all *.db files from a snapshot\ndirectory to the respective keyspace overwriting any existing files.\n\nNOTE: It is recommended to include the system keyspace in the backup.\n      Keeping the system keyspace will reduce the restore time\n      by avoiding need to rebuilding indexes.\n\nThe Backup Procedure:\n\n1. Clear existing snapshots.\n\n2. Take a snapshot of all keyspaces.\n\n3. Collect all *.db files from the snapshot directories package them\ninto a single TAR archive.\n\nTransform the paths such that the backup can be restored simply by\nextracting the archive right to an existing data directory\n(i.e. place the root into the <data dir> and\nremove the 'snapshots/<snapshot name>' portion of the path).\nThe data directory itself is not included in the backup archive\n(i.e. the archive is rooted inside the data directory).\nThis is to make sure we can always restore an old backup\neven if the standard guest agent data directory changes.\n\nAttempt to preserve access modifiers on the archived files.\n\nAssert the backup is not empty as there should always be\nat least the system keyspace. Fail if there is nothing to backup.\n\n4. Compress and/or encrypt the archive as required.\n\n5. This archive is streamed to the storage location.\n\nThe Restore Procedure:\n\n1. Create a new data directory as it does not exist.\n\n2. Unpack the backup to that directory.\n\n3. Update ownership of the restored files to the Cassandra user.\n\nNotes on 'cluster_name' property:\n\nCassandra has a concept of clusters. Clusters are composed of\nnodes - instances. All nodes belonging to one cluster must all have the\nsame 'cluster_name' property. This prevents nodes from different logical\nclusters from accidentally talking to each other.\n\nThe cluster name can be changed in the configuration file.\nIt is also stored in the system keyspace.\nWhen the Cassandra service boots up it verifies that the cluster name\nstored in the database matches the name in the configuration file and\nfails if not. This is to prevent the operator from accidentally\nlaunching a node with data from another cluster.\nThe operator has to update the configuration file.\n\nSimilarly, when a backup is restored it carries the original cluster\nname with it. We have to update the configuration file to use the old\nname.\nWhen a node gets restored it will still belong to the original cluster.\n\nNotes on superuser password reset:\n\nDatabase is no longer wide open and requires password authentication.\nThe 'root' password stored in the system keyspace\nneeds to be reset before we can start up with restored data.\n\nA general password reset procedure is:\n- disable user authentication and remote access\n- restart the service\n- update the password in the 'system_auth.credentials' table\n- re-enable authentication and make the host reachable\n- restart the service\n\nNote: The superuser-password-reset and related methods that\n      potentially expose the database contents are intentionally\n      decorated with '_' and '__' to discourage a caller from\n      using them unless absolutely necessary.\n\nAdditional changes:\n\n- Adds backup/restore namespaces to the sample config\n  file 'trove-guestagent.conf.sample'.\n  We include the other datastores too\n  for the sake of consistency.\n  (Auston McReynolds, Jul 6, 2014)\n\nImplements: blueprint cassandra-backup-restore\nCo-Authored-By: Denis Makogon <dmakogon@mirantis.com>\nChange-Id: I3671a737d3e71305982d8f4965215a73e785ea2d\n""}]",2,206751,e722342ce7a94a1b8fa3f43ae82cf3ef69013389,159,7,41,14576,,,0,"Add backup & restore for Cassandra

Implement backup and restore functionality for Cassandra datastore.

We implement full backup strategy using the Nodetool
(http://goo.gl/QtXVsM) utility.

Snapshots:

Nodetool can take a snapshot of one or more keyspace(s).
Snapshot(s) will be stored in the data directory tree:
'<data dir>/<keyspace>/<table>/snapshots/<snapshot name>'

A snapshot can be restored by moving all *.db files from a snapshot
directory to the respective keyspace overwriting any existing files.

NOTE: It is recommended to include the system keyspace in the backup.
      Keeping the system keyspace will reduce the restore time
      by avoiding need to rebuilding indexes.

The Backup Procedure:

1. Clear existing snapshots.

2. Take a snapshot of all keyspaces.

3. Collect all *.db files from the snapshot directories package them
into a single TAR archive.

Transform the paths such that the backup can be restored simply by
extracting the archive right to an existing data directory
(i.e. place the root into the <data dir> and
remove the 'snapshots/<snapshot name>' portion of the path).
The data directory itself is not included in the backup archive
(i.e. the archive is rooted inside the data directory).
This is to make sure we can always restore an old backup
even if the standard guest agent data directory changes.

Attempt to preserve access modifiers on the archived files.

Assert the backup is not empty as there should always be
at least the system keyspace. Fail if there is nothing to backup.

4. Compress and/or encrypt the archive as required.

5. This archive is streamed to the storage location.

The Restore Procedure:

1. Create a new data directory as it does not exist.

2. Unpack the backup to that directory.

3. Update ownership of the restored files to the Cassandra user.

Notes on 'cluster_name' property:

Cassandra has a concept of clusters. Clusters are composed of
nodes - instances. All nodes belonging to one cluster must all have the
same 'cluster_name' property. This prevents nodes from different logical
clusters from accidentally talking to each other.

The cluster name can be changed in the configuration file.
It is also stored in the system keyspace.
When the Cassandra service boots up it verifies that the cluster name
stored in the database matches the name in the configuration file and
fails if not. This is to prevent the operator from accidentally
launching a node with data from another cluster.
The operator has to update the configuration file.

Similarly, when a backup is restored it carries the original cluster
name with it. We have to update the configuration file to use the old
name.
When a node gets restored it will still belong to the original cluster.

Notes on superuser password reset:

Database is no longer wide open and requires password authentication.
The 'root' password stored in the system keyspace
needs to be reset before we can start up with restored data.

A general password reset procedure is:
- disable user authentication and remote access
- restart the service
- update the password in the 'system_auth.credentials' table
- re-enable authentication and make the host reachable
- restart the service

Note: The superuser-password-reset and related methods that
      potentially expose the database contents are intentionally
      decorated with '_' and '__' to discourage a caller from
      using them unless absolutely necessary.

Additional changes:

- Adds backup/restore namespaces to the sample config
  file 'trove-guestagent.conf.sample'.
  We include the other datastores too
  for the sake of consistency.
  (Auston McReynolds, Jul 6, 2014)

Implements: blueprint cassandra-backup-restore
Co-Authored-By: Denis Makogon <dmakogon@mirantis.com>
Change-Id: I3671a737d3e71305982d8f4965215a73e785ea2d
",git fetch https://review.opendev.org/openstack/trove refs/changes/51/206751/6 && git format-patch -1 --stdout FETCH_HEAD,"['trove/guestagent/strategies/backup/experimental/cassandra_impl.py', 'trove/guestagent/datastore/experimental/cassandra/service.py', 'trove/tests/unittests/backup/test_backupagent.py', 'etc/trove/trove-guestagent.conf.sample', 'trove/tests/unittests/guestagent/test_dbaas.py', 'trove/common/cfg.py', 'trove/guestagent/strategies/restore/experimental/cassandra_impl.py', 'trove/taskmanager/models.py', 'trove/guestagent/datastore/experimental/cassandra/manager.py', 'trove/guestagent/datastore/experimental/cassandra/system.py', 'trove/tests/unittests/guestagent/test_backups.py', 'trove/tests/unittests/guestagent/test_cassandra_manager.py']",12,8b355c4d9e6f506014e22db5e85f23134ab20213,cassandra-backup-restore,"from mock import ANY, call, DEFAULT, MagicMock, patch, NonCallableMagicMockfrom trove.guestagent import backup __MOUNT_POINT = '/var/lib/cassandra' self.manager.app.status = mock_status @patch.object(backup, 'restore') def test_prepare_db_restore(self, restore): backup_info = {'id': 'backup_id', 'instance_id': 'fake-instance-id', 'location': 'fake-location', 'type': 'InnoBackupEx', 'checksum': 'fake-checksum'} self._prepare_dynamic(['cassandra'], is_db_installed=False, backup_info=backup_info) restore.assert_called_once_with( self.context, backup_info, self.__MOUNT_POINT) def test_superuser_password_reset(self): fake_status = MagicMock() fake_status.is_running = False test_app = cass_service.CassandraApp() test_app.status = fake_status with patch.multiple( test_app, start_db=DEFAULT, stop_db=DEFAULT, restart=DEFAULT, _disable_db_on_boot=DEFAULT, _enable_db_on_boot=DEFAULT, _CassandraApp__disable_remote_access=DEFAULT, _CassandraApp__enable_remote_access=DEFAULT, _CassandraApp__disable_authentication=DEFAULT, _CassandraApp__enable_authentication=DEFAULT, _CassandraApp__reset_superuser_password=DEFAULT, configure_superuser_access=DEFAULT) as calls: test_app._reset_superuser_password() calls['_disable_db_on_boot'].assert_called_once_with() calls[ '_CassandraApp__disable_remote_access' ].assert_called_once_with() calls[ '_CassandraApp__disable_authentication' ].assert_called_once_with() calls['start_db'].assert_called_once_with(update_db=False), calls[ '_CassandraApp__enable_authentication' ].assert_called_once_with() calls[ '_CassandraApp__reset_superuser_password' ].assert_called_once_with() calls['configure_superuser_access'].assert_called_once_with() self.assertEqual(2, calls['restart'].call_count) calls['stop_db'].assert_called_once_with() calls[ '_CassandraApp__enable_remote_access' ].assert_called_once_with() calls['_enable_db_on_boot'].assert_called_once_with() def test_change_cluster_name(self): fake_status = MagicMock() fake_status.is_running = True test_app = cass_service.CassandraApp() test_app.status = fake_status with patch.multiple( test_app, start_db=DEFAULT, stop_db=DEFAULT, restart=DEFAULT, _update_cluster_name_property=DEFAULT, _CassandraApp__reset_cluster_name=DEFAULT) as calls: sample_name = NonCallableMagicMock() test_app.change_cluster_name(sample_name) calls['_CassandraApp__reset_cluster_name'].assert_called_once_with( sample_name) calls['_update_cluster_name_property'].assert_called_once_with( sample_name) calls['restart'].assert_called_once_with() @patch.object(cass_service, 'CONF', DEFAULT) def test_apply_post_restore_updates(self, conf_mock): fake_status = MagicMock() fake_status.is_running = False test_app = cass_service.CassandraApp() test_app.status = fake_status with patch.multiple( test_app, start_db=DEFAULT, stop_db=DEFAULT, _update_cluster_name_property=DEFAULT, _reset_superuser_password=DEFAULT, change_cluster_name=DEFAULT) as calls: backup_info = {'instance_id': 'old_id'} conf_mock.guest_id = 'new_id' test_app._apply_post_restore_updates(backup_info) calls['_update_cluster_name_property'].assert_called_once_with( 'old_id') calls['_reset_superuser_password'].assert_called_once_with() calls['start_db'].assert_called_once_with(update_db=False) calls['change_cluster_name'].assert_called_once_with('new_id') calls['stop_db'].assert_called_once_with() is_db_installed=True, backup_info=None, mock_app.status = mock_status mock_app._remove_system_tables = MagicMock(return_value=None) mount_point=self.__MOUNT_POINT, mock_app._remove_system_tables.assert_any_call() if backup_info: mock_app._apply_post_restore_updates.assert_called_once_with( backup_info)","from mock import ANY, call, MagicMock, patch, NonCallableMagicMock self.manager.appStatus = mock_status is_db_installed=True, backup_id=None, # covering all outcomes is starting to cause trouble here if not backup_id: backup_info = {'id': backup_id, 'location': 'fake-location', 'type': 'InnoBackupEx', 'checksum': 'fake-checksum', } self.manager.appStatus = mock_status mount_point=""/var/lib/cassandra"",",726,54
openstack%2Fwatcher~master~I139775f467fe7778c7354b0cfacf796fc27ffcb2,openstack/watcher,master,I139775f467fe7778c7354b0cfacf796fc27ffcb2,Add Voluptuous to validate the action parameters,MERGED,2016-01-21 07:42:26.000000000,2016-02-15 09:31:16.000000000,2016-02-15 09:31:16.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2016-01-21 07:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/34d21c41780c19b07a187e8b3586842216a7a48c', 'message': 'WiP Add Schema validator\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 2, 'created': '2016-01-26 14:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8dc2bb9f862f5a7b5317d52cdc2bf98b61cf91b7', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters\nof an Action through a schema.\n\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 3, 'created': '2016-01-26 14:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5bb189912e913a93e84aba2520975e0ca91c1716', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an Action through a schema.\n\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 4, 'created': '2016-01-26 14:36:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3cece764f5829e720982db7dc8243705becac19c', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an Action through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 5, 'created': '2016-01-26 14:36:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/388083df25a22239c7493d99cd0bded2ffcd2327', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an Action\nthrough a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 6, 'created': '2016-01-26 14:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/61226e49682c2775b1af93b7a773ce88d9d2841d', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an Action through a schema.\n\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 7, 'created': '2016-01-26 14:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/97517765df267199e97eecd4abadc3c25f5d3e65', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 8, 'created': '2016-01-26 16:14:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/edc885c33c28d542e4e7c5eb0bcb3df463067c78', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an Action through a schema.\n\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 9, 'created': '2016-01-26 16:15:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/724d6dabd23a0c07f05920b6ef2080bc275391d2', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 10, 'created': '2016-01-27 13:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/690beb12af8f5118e6ed8e3caf0127c4ac4a072a', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 11, 'created': '2016-02-03 00:01:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/28c60deb5de019e29ecd67a689432fac0faf6ed3', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 12, 'created': '2016-02-03 18:22:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/555ae4b01ac0730de25f50ee9ea3ee131ccefd83', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 13, 'created': '2016-02-03 18:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3a55ad331e6364f3fadf36f3c324bc54673b337e', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 14, 'created': '2016-02-03 18:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/7a9d3a974f0bc62fafcdb7525c8bf979b16453e0', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 15, 'created': '2016-02-03 18:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/5c3cfda70d10bd42c95f6b573d7913dcce68a9cc', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 16, 'created': '2016-02-03 22:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0aa52485f83f5c74b7de0c45ba901bbb345eeeca', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 17, 'created': '2016-02-04 18:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/496a438f9d34c498915f7b56b2192a31cbe3dd8c', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 18, 'created': '2016-02-08 14:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6857945b5e9b0b8243614938419b7b2f356ff4d0', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 19, 'created': '2016-02-09 08:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/4023e83a61c63a7216cc2f39c715e3bd6bb7d467', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 20, 'created': '2016-02-09 10:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/3b4544d9789d4570ffef68e309229a86c6970ca7', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 21, 'created': '2016-02-10 08:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/034e8c93b870868a4cc612d8694ffeb10d1c00fb', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 22, 'created': '2016-02-12 15:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/922d7dcb43569b27cf637d3bddbea76c2ff1b5fb', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}, {'number': 23, 'created': '2016-02-12 16:48:17.000000000', 'files': ['watcher/applier/actions/base.py', 'watcher/decision_engine/planner/default.py', 'watcher/tests/decision_engine/planner/test_default_planner.py', 'watcher/tests/applier/actions/test_change_nova_service_state.py', 'watcher/tests/applier/workflow_engine/test_default_workflow_engine.py', 'watcher/tests/decision_engine/strategy/strategies/test_outlet_temp_control.py', 'watcher/common/exception.py', 'watcher/applier/actions/factory.py', 'watcher/decision_engine/strategy/strategies/dummy_strategy.py', 'requirements.txt', 'watcher/tests/decision_engine/strategy/strategies/test_basic_consolidation.py', 'watcher/tests/db/utils.py', 'watcher/locale/fr/LC_MESSAGES/watcher.po', 'watcher/tests/applier/actions/test_sleep.py', 'watcher/tests/decision_engine/strategy/strategies/faker_cluster_state.py', 'watcher/objects/action.py', 'watcher/api/controllers/v1/action.py', 'watcher/applier/actions/nop.py', 'watcher/decision_engine/solution/default.py', 'watcher/decision_engine/strategy/strategies/outlet_temp_control.py', 'watcher/applier/actions/migration.py', 'watcher/tests/decision_engine/strategy/strategies/test_dummy_strategy.py', 'watcher/applier/actions/change_nova_service_state.py', 'watcher/tests/decision_engine/model/test_mapping.py', 'watcher/tests/applier/actions/test_migration.py', 'watcher/decision_engine/strategy/strategies/basic_consolidation.py', 'watcher/locale/watcher.pot', 'watcher/applier/actions/sleep.py', 'watcher/db/sqlalchemy/models.py', 'watcher/tests/decision_engine/solution/test_default_solution.py', 'watcher/decision_engine/solution/base.py', 'watcher/metrics_engine/cluster_model_collector/nova.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/e3198d25a571b36a3715f5df1bc54718f3ad79ce', 'message': 'Add Voluptuous to validate the action parameters\n\nWe want a simplest way to validate the input parameters of an\nAction through a schema.\n\nAPIImpact\nDocImpact\nPartially implements: blueprint watcher-add-actions-via-conf\n\nChange-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2\n'}]",28,270642,e3198d25a571b36a3715f5df1bc54718f3ad79ce,74,6,23,16495,,,0,"Add Voluptuous to validate the action parameters

We want a simplest way to validate the input parameters of an
Action through a schema.

APIImpact
DocImpact
Partially implements: blueprint watcher-add-actions-via-conf

Change-Id: I139775f467fe7778c7354b0cfacf796fc27ffcb2
",git fetch https://review.opendev.org/openstack/watcher refs/changes/42/270642/7 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/applier/actions/test_migration.py', 'watcher/applier/actions/base.py', 'requirements.txt', 'watcher/applier/actions/migration.py', 'watcher/common/utils.py', 'watcher/applier/actions/factory.py']",6,34d21c41780c19b07a187e8b3586842216a7a48c,bug/1536218, loaded_action.check_parameters(),,74,2
openstack%2Fpython-watcherclient~master~I014e4b0d5e734ea9ef869c3ad33908a2c0d2aa40,openstack/python-watcherclient,master,I014e4b0d5e734ea9ef869c3ad33908a2c0d2aa40,Removed host_aggregate filter for Audit Template,MERGED,2016-02-12 14:18:34.000000000,2016-02-15 09:29:58.000000000,2016-02-15 09:29:58.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}]","[{'number': 1, 'created': '2016-02-12 14:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/9ad4c310d49f9982d509bd8e23b8244358f8d1f7', 'message': ""Removed host_aggregate filter for Audit Template\n\nAlthough it was proposed via python-watcherclient, the feature was not\nimplemented on the Watcher API. As the notion of host aggregate is\ncurrently unused in Watcher, decision was made to only implement the\nfiltering of goal within the Watcher API whilst removing the\nhost_aggregate filter from the Watcher client.\nThus, this patchset removes the 'host_aggregate' parameter from the\nclient.\n\nChange-Id: I014e4b0d5e734ea9ef869c3ad33908a2c0d2aa40\nRelated-Bug: #bug/1510189\n""}, {'number': 2, 'created': '2016-02-12 15:49:30.000000000', 'files': ['watcherclient/v1/audit_template.py', 'watcherclient/tests/v1/test_audit_template.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/9699fc5f70f71d430b09948c473a62a8c3450053', 'message': ""Removed host_aggregate filter for Audit Template\n\nAlthough it was proposed via python-watcherclient, the feature was not\nimplemented on the Watcher API. As the notion of host aggregate is\ncurrently unused in Watcher, decision was made to only implement the\nfiltering of goal within the Watcher API whilst removing the\nhost_aggregate filter from the Watcher client.\nThus, this patchset removes the 'host_aggregate' parameter from the\nclient.\n\nChange-Id: I014e4b0d5e734ea9ef869c3ad33908a2c0d2aa40\nRelated-Bug: #1510189\n""}]",0,279555,9699fc5f70f71d430b09948c473a62a8c3450053,9,5,2,18971,,,0,"Removed host_aggregate filter for Audit Template

Although it was proposed via python-watcherclient, the feature was not
implemented on the Watcher API. As the notion of host aggregate is
currently unused in Watcher, decision was made to only implement the
filtering of goal within the Watcher API whilst removing the
host_aggregate filter from the Watcher client.
Thus, this patchset removes the 'host_aggregate' parameter from the
client.

Change-Id: I014e4b0d5e734ea9ef869c3ad33908a2c0d2aa40
Related-Bug: #1510189
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/55/279555/2 && git format-patch -1 --stdout FETCH_HEAD,"['watcherclient/v1/audit_template.py', 'watcherclient/tests/v1/test_audit_template.py']",2,9ad4c310d49f9982d509bd8e23b8244358f8d1f7,bug/1510189,"from testtools import matchers 'goal': 'BASIC_CONSOLIDATION'fake_responses_filter_by_goal = { '/v1/audit_templates/?goal=BASIC_CONSOLIDATION': { 'GET': ( {}, {""audit_templates"": [AUDIT_TMPL2]} ), }, } def test_audit_templates_list_by_goal(self): self.api = utils.FakeAPI(fake_responses_filter_by_goal) self.mgr = watcherclient.v1.audit_template.AuditTemplateManager( self.api) audit_templates = self.mgr.list(goal=""BASIC_CONSOLIDATION"") expect = [ ('GET', '/v1/audit_templates/?goal=%s' % AUDIT_TMPL2['goal'], {}, None), ] self.assertEqual(expect, self.api.calls) self.assertEqual(1, len(audit_templates)) self.assertThat(audit_templates, matchers.HasLength(1)) self.assertThat(audit_templates, matchers.HasLength(2))","from testtools.matchers import HasLength 'goal': 'SERVERS_CONSOLIDATION' self.assertThat(audit_templates, HasLength(1)) self.assertThat(audit_templates, HasLength(2))",29,5
openstack%2Fpython-watcherclient~master~I57bb0c88bcf373304e59109cd7557052ef7a980b,openstack/python-watcherclient,master,I57bb0c88bcf373304e59109cd7557052ef7a980b,Removed useless '--name' in audit-template-list,MERGED,2016-02-11 14:25:06.000000000,2016-02-15 09:27:58.000000000,2016-02-15 09:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 11235}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}]","[{'number': 1, 'created': '2016-02-11 14:25:06.000000000', 'files': ['watcherclient/v1/audit_template_shell.py'], 'web_link': 'https://opendev.org/openstack/python-watcherclient/commit/51a3b3fe3f3b4bde5a0f8edf40fb435c89fe73e2', 'message': ""Removed useless '--name' in audit-template-list\n\nThis bug outlined that a --name option of the audit-template-list\nsubcommand was not working properly. But the goal of this command\nwould have been equivalent to using 'audit-template-show'. That's\nwhy I simply removed it from our client.\n\nChange-Id: I57bb0c88bcf373304e59109cd7557052ef7a980b\nCloses-Bug: #1510190\n""}]",0,279094,51a3b3fe3f3b4bde5a0f8edf40fb435c89fe73e2,8,5,1,18971,,,0,"Removed useless '--name' in audit-template-list

This bug outlined that a --name option of the audit-template-list
subcommand was not working properly. But the goal of this command
would have been equivalent to using 'audit-template-show'. That's
why I simply removed it from our client.

Change-Id: I57bb0c88bcf373304e59109cd7557052ef7a980b
Closes-Bug: #1510190
",git fetch https://review.opendev.org/openstack/python-watcherclient refs/changes/94/279094/1 && git format-patch -1 --stdout FETCH_HEAD,['watcherclient/v1/audit_template_shell.py'],1,51a3b3fe3f3b4bde5a0f8edf40fb435c89fe73e2,bug/1510190,," '--name', metavar='<name>', help='Only show information for the audit template with this name.') @cliutils.arg( if args.name is not None: params['name'] = args.name",0,6
openstack%2Ffuel-menu~master~Ia3b0d141eac41310911ea3abdf2a7de69138279e,openstack/fuel-menu,master,Ia3b0d141eac41310911ea3abdf2a7de69138279e,Allow to apply DNS settings manually,MERGED,2016-02-06 03:25:24.000000000,2016-02-15 09:27:52.000000000,2016-02-15 09:27:52.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 10391}, {'_account_id': 10443}]","[{'number': 1, 'created': '2016-02-06 03:25:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/481738a7cfad03e9c5508ee39f1906ae8876e4ed', 'message': 'Enable to apply DNS settings\n\nThis allow to properly check repositories for bootstrap images in an\ninteractive mode in some cases when the network is restricted and only\ninternal DNS services are available.\n\nChange-Id: Ia3b0d141eac41310911ea3abdf2a7de69138279e\nCloses-Bug: #1542570\n'}, {'number': 2, 'created': '2016-02-08 03:44:43.000000000', 'files': ['fuelmenu/modules/dnsandhostname.py'], 'web_link': 'https://opendev.org/openstack/fuel-menu/commit/37c74c28e182b4fc080de938480cdef01f500196', 'message': 'Allow to apply DNS settings manually\n\nThis allow to properly check repositories for bootstrap images in an\ninteractive mode in some cases when the network is restricted and only\ninternal DNS services are available.\n\nChange-Id: Ia3b0d141eac41310911ea3abdf2a7de69138279e\nCloses-Bug: #1542570\n'}]",0,276989,37c74c28e182b4fc080de938480cdef01f500196,11,4,2,1531,,,0,"Allow to apply DNS settings manually

This allow to properly check repositories for bootstrap images in an
interactive mode in some cases when the network is restricted and only
internal DNS services are available.

Change-Id: Ia3b0d141eac41310911ea3abdf2a7de69138279e
Closes-Bug: #1542570
",git fetch https://review.opendev.org/openstack/fuel-menu refs/changes/89/276989/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelmenu/modules/dnsandhostname.py'],1,481738a7cfad03e9c5508ee39f1906ae8876e4ed,bug/1542570," self.defaults, showallbuttons=True)", self.defaults),1,1
openstack%2Fsenlin~master~Id40465397e6f3a31aaf97d0d568f588fd46b11e8,openstack/senlin,master,Id40465397e6f3a31aaf97d0d568f588fd46b11e8,Add node_count_by_cluster DB API,MERGED,2016-02-15 08:24:09.000000000,2016-02-15 09:23:57.000000000,2016-02-15 09:23:57.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 11034}]","[{'number': 1, 'created': '2016-02-15 08:24:09.000000000', 'files': ['senlin/db/api.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/68a6bdf40b698862d45a791a04ee1319afc87d46', 'message': ""Add node_count_by_cluster DB API\n\nThis patch adds a 'node_count_by_cluter' API so that we can later enforce\na quota settings regarding maximum nodes per cluster.\n\nChange-Id: Id40465397e6f3a31aaf97d0d568f588fd46b11e8\n""}]",0,280101,68a6bdf40b698862d45a791a04ee1319afc87d46,7,3,1,8246,,,0,"Add node_count_by_cluster DB API

This patch adds a 'node_count_by_cluter' API so that we can later enforce
a quota settings regarding maximum nodes per cluster.

Change-Id: Id40465397e6f3a31aaf97d0d568f588fd46b11e8
",git fetch https://review.opendev.org/openstack/senlin refs/changes/01/280101/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/db/api.py', 'senlin/tests/unit/db/test_node_api.py', 'senlin/db/sqlalchemy/api.py']",3,68a6bdf40b698862d45a791a04ee1319afc87d46,nodes-count,"def node_count_by_cluster(context, cluster_id, project_safe=True): return _query_node_get_all(context, cluster_id=cluster_id, project_safe=project_safe).count() ",,33,0
openstack%2Fstorlets~master~Ib70f94df0e5920c4780ab5f7bbb3f0e92604117b,openstack/storlets,master,Ib70f94df0e5920c4780ab5f7bbb3f0e92604117b,Fix redundant call of get_vaco in storlet_handler,ABANDONED,2016-02-08 05:36:12.000000000,2016-02-15 09:22:43.000000000,,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 9816}]","[{'number': 1, 'created': '2016-02-08 05:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/3ff4033b1a74dbee6503845820c8d8c7e0ae494b', 'message': 'Fix redundant call of get_vaco in storlet_handler\n\nChange-Id: Ib70f94df0e5920c4780ab5f7bbb3f0e92604117b\n'}, {'number': 2, 'created': '2016-02-15 04:36:35.000000000', 'files': ['Engine/swift/storlet_middleware/storlet_handler.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/6b6ac30f7f028d9f27fe85dff1631604d4b0f32f', 'message': 'Fix redundant call of get_vaco in storlet_handler\n\nChange-Id: Ib70f94df0e5920c4780ab5f7bbb3f0e92604117b\n'}]",0,277285,6b6ac30f7f028d9f27fe85dff1631604d4b0f32f,8,3,2,9816,,,0,"Fix redundant call of get_vaco in storlet_handler

Change-Id: Ib70f94df0e5920c4780ab5f7bbb3f0e92604117b
",git fetch https://review.opendev.org/openstack/storlets refs/changes/85/277285/1 && git format-patch -1 --stdout FETCH_HEAD,['Engine/swift/storlet_middleware/storlet_handler.py'],1,3ff4033b1a74dbee6503845820c8d8c7e0ae494b,vaco," try: self.version, self.acc, self.cont, self.obj = \ self._get_vaco(self.request) except ValueError: raise NotStorletRequest() def _setup_gateway(self): self.conf, self.logger, self.app, self.version, self.acc, self.cont, self.obj) def _get_vaco(self, req): self.acc, self.cont, self.obj)) 'object'.format(self.acc, self.cont, self.obj)) format(self.acc, self.cont, self.obj)) def _get_vaco(self, req): return req.split_path(4, 4, rest_with_last=True) return (self.cont in self.storlet_containers and self.obj self.request, self.cont, self.obj, resp) self.gateway.gatewayProxyPutFlow(self.request, self.cont, self.obj) def _get_vaco(self, req): _, _, acc, cont, obj = req.split_path( self.request, self.cont, self.obj, resp) (self.acc, self.cont, self.obj, (self.acc, self.cont, self.obj, self.logger.debug('storlet_handler call in %s: with %s' % (self.exec_server, req.path)) except NotStorletRequest: return req.get_response(self.app)"," def _setup_gateway(self): ver, acc, cont, obj = self.get_vaco() self.conf, self.logger, self.app, ver, acc, cont, obj) def get_vaco(self): _, account, container, obj = self.get_vaco() account, container, obj)) 'object'.format(account, container, obj)) format(account, container, obj)) def get_vaco(self): return self.request.split_path(4, 4, rest_with_last=True) _, _, container, obj = self.get_vaco() return (container in self.storlet_containers and obj _, _, container, obj = self.get_vaco() self.request, container, obj, resp) _, _, container, obj = self.get_vaco() self.gateway.gatewayProxyPutFlow(self.request, container, obj) def get_vaco(self): _, _, acc, cont, obj = self.request.split_path( _, _, container, obj = self.get_vaco() self.request, container, obj, resp) _, account, container, obj = self.get_vaco() (account, container, obj, (account, container, obj, _, account, container, obj = request_handler.get_vaco() self.logger.debug('storlet_handler call in %s: with %s/%s/%s' % (self.exec_server, account, container, obj)) except HTTPException: raise except (ValueError, NotStorletRequest): return req.get_response(self.app) try:",26,32
openstack%2Ffuel-qa~master~I62651ad8e881d04144614842d286c31a0d9c5eef,openstack/fuel-qa,master,I62651ad8e881d04144614842d286c31a0d9c5eef,Add helpers for plugins install,MERGED,2016-01-14 08:42:45.000000000,2016-02-15 09:03:35.000000000,2016-01-15 08:43:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7935}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9588}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11587}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 16414}, {'_account_id': 19119}, {'_account_id': 19120}]","[{'number': 1, 'created': '2016-01-14 08:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/9f1440c5d0835a2ee85e8fa59b348183d494bb06', 'message': 'Add helpers for ssh manager\n\n1. Implement helpers push metaclasses (normal and bound with singleton).\n2. SingletonMeta -> modified to allow handling multiple classes and moved to metaclasses too.\n\nChange-Id: I62651ad8e881d04144614842d286c31a0d9c5eef\n'}, {'number': 2, 'created': '2016-01-14 09:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/dd416116fea57b8058ffac032b62d2dd9d99a43a', 'message': 'Add helpers for ssh manager\n\n1. Implement helpers push metaclasses (normal and bound with singleton).\n2. SingletonMeta -> modified to allow handling multiple classes and moved to metaclasses too.\n\nChange-Id: I62651ad8e881d04144614842d286c31a0d9c5eef\n'}, {'number': 3, 'created': '2016-01-14 10:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/6633d0c9d184c12f147e0dba9ad19596c9dd84a6', 'message': 'Add helpers for ssh manager\n\n1. Implement helpers push metaclasses (normal and bound with singleton).\n2. SingletonMeta -> modified to allow handling multiple classes and moved to metaclasses too.\n\nChange-Id: I62651ad8e881d04144614842d286c31a0d9c5eef\n'}, {'number': 4, 'created': '2016-01-14 12:23:33.000000000', 'files': ['fuelweb_test/helpers/fuel_actions.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/926159a2b9ba579c0a29cac29e1415bd864f1531', 'message': 'Add helpers for plugins install\n\nAdded upload_plugin and install_plugin to AdminActions\n\nChange-Id: I62651ad8e881d04144614842d286c31a0d9c5eef\n'}]",8,267390,926159a2b9ba579c0a29cac29e1415bd864f1531,40,18,4,19119,,,0,"Add helpers for plugins install

Added upload_plugin and install_plugin to AdminActions

Change-Id: I62651ad8e881d04144614842d286c31a0d9c5eef
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/90/267390/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/__init__.py', 'fuelweb_test/helpers/metaclasses.py', 'doc/helpers.rst', 'fuelweb_test/models/environment.py', 'fuelweb_test/helpers/ssh_manager.py', 'fuelweb_test/helpers/ssh_manager_helpers/plugin_helpers.py', 'fuelweb_test/helpers/ssh_manager_helpers/__init__.py']",7,9f1440c5d0835a2ee85e8fa59b348183d494bb06,plugin_helpers,"# Copyright 2016 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import types import sys import pkgutil import inspect # By default we have empty list to use as ""import *"" and load as helpers __all__ = [] def __get_arg_names(func): """"""Get list of function arguments names :param func: func :return: list """""" if sys.version_info.major < 3: return [arg for arg in inspect.getargspec(func=func).args] else: return list(inspect.signature(obj=func).parameters.keys()) # Now load all modules and packages here and add methods to __all__, # if API is correct (self presents, method is not marked as protected/private). # Also method added to globals() (mandatory). for loader, name, is_pkg in pkgutil.walk_packages(__path__): module = loader.find_module(name).load_module(name) for key, value in inspect.getmembers(module): if key.startswith('_') or not isinstance(value, types.FunctionType): continue if 'self' not in __get_arg_names(value): continue globals()[key] = value __all__.append(key) ",,236,30
openstack%2Fproject-config~master~I0c0802746ddf078e46ac7eb7d129a18f2e3a2bf2,openstack/project-config,master,I0c0802746ddf078e46ac7eb7d129a18f2e3a2bf2,Create ansible-role-shade project,MERGED,2016-02-10 21:24:40.000000000,2016-02-15 09:02:10.000000000,2016-02-15 09:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-10 21:24:40.000000000', 'files': ['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/ansible-role-shade.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e5178398c1209556b5819bb80e0ad86b29a21794', 'message': ""Create ansible-role-shade project\n\nLike ansible-role-diskimage-builder, we'll need better control over\nshade.  This is the reason for creating the project.\n\nWe'll be adding IRC notification into windmill and like to start with\nan empty project.\n\nChange-Id: I0c0802746ddf078e46ac7eb7d129a18f2e3a2bf2\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n""}]",0,278643,e5178398c1209556b5819bb80e0ad86b29a21794,7,3,1,4162,,,0,"Create ansible-role-shade project

Like ansible-role-diskimage-builder, we'll need better control over
shade.  This is the reason for creating the project.

We'll be adding IRC notification into windmill and like to start with
an empty project.

Change-Id: I0c0802746ddf078e46ac7eb7d129a18f2e3a2bf2
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/278643/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/ansible-role-shade.config']",5,e5178398c1209556b5819bb80e0ad86b29a21794,temp/ansible-role-shade,"[access ""refs/heads/*""] abandon = group ansible-role-shade-core label-Code-Review = -2..+2 group ansible-role-shade-core label-Workflow = -1..+1 group ansible-role-shade-core [access ""refs/tags/*""] pushSignedTag = group ansible-role-shade-release [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",,36,0
openstack%2Fpython-openstackclient~master~I3306b4129b006ee2540b160b6d8fbd7ca1deb4d5,openstack/python-openstackclient,master,I3306b4129b006ee2540b160b6d8fbd7ca1deb4d5,Avoid using `required=True` for non optional arguments.,ABANDONED,2015-08-22 08:24:30.000000000,2016-02-15 09:01:34.000000000,,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8736}, {'_account_id': 13063}]","[{'number': 1, 'created': '2015-08-22 08:24:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2c718f8020b6b54bd9d73ae376999638342475a2', 'message': 'Avoid using `required=True` for non optional arguments.\n\nRequired options are generally considered bad form because users\nexpect options to be optional, and thus they should be avoided\nwhen possible [1].\n\nDefault help group headings for these arguements are `optional arguments`,\nthis misleading to many people, there are already an issue opened for this\nusage [2].\n\nThe patch address these occurrences for keystone service to make these\narguments as positional arguments.\n\n[1] https://docs.python.org/3/library/argparse.html#required\n[2] https://bugs.python.org/issue9694\n\nChange-Id: I3306b4129b006ee2540b160b6d8fbd7ca1deb4d5\n'}, {'number': 2, 'created': '2015-08-22 08:26:59.000000000', 'files': ['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/endpoint.py', 'openstackclient/identity/v3/token.py', 'openstackclient/identity/v3/federation_protocol.py', 'openstackclient/identity/v3/service_provider.py', 'openstackclient/identity/v3/trust.py', 'openstackclient/identity/v3/mapping.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/51d74b83090df01a353aa7669e5a414602ce3539', 'message': 'Avoid using `required=True` for non optional arguments.\n\nRequired options are generally considered bad form because users\nexpect options to be optional, and thus they should be avoided\nwhen possible [1].\n\nDefault help group headings for these arguements are `optional arguments`,\nthis misleading to many people, there are already an issue opened for this\nusage [2].\n\nThe patch address these occurrences for identity service to make these\narguments as positional arguments.\n\n[1] https://docs.python.org/3/library/argparse.html#required\n[2] https://bugs.python.org/issue9694\n\nChange-Id: I3306b4129b006ee2540b160b6d8fbd7ca1deb4d5\n'}]",0,215892,51d74b83090df01a353aa7669e5a414602ce3539,10,4,2,13063,,,0,"Avoid using `required=True` for non optional arguments.

Required options are generally considered bad form because users
expect options to be optional, and thus they should be avoided
when possible [1].

Default help group headings for these arguements are `optional arguments`,
this misleading to many people, there are already an issue opened for this
usage [2].

The patch address these occurrences for identity service to make these
arguments as positional arguments.

[1] https://docs.python.org/3/library/argparse.html#required
[2] https://bugs.python.org/issue9694

Change-Id: I3306b4129b006ee2540b160b6d8fbd7ca1deb4d5
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/92/215892/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/identity/v2_0/role.py', 'openstackclient/identity/v2_0/endpoint.py', 'openstackclient/identity/v3/token.py', 'openstackclient/identity/v3/federation_protocol.py', 'openstackclient/identity/v3/service_provider.py', 'openstackclient/identity/v3/trust.py', 'openstackclient/identity/v3/mapping.py']",7,2c718f8020b6b54bd9d73ae376999638342475a2,replace_optional," 'rules', metavar='<filename>', help='Filename that contains a set of mapping rules',"," '--rules', metavar='<filename>', required=True, help='Filename that contains a set of mapping rules (required)',",48,76
openstack%2Fproject-config~master~I562c4e7d22d8c76ea5ddd1da834dea8c76c87c1f,openstack/project-config,master,I562c4e7d22d8c76ea5ddd1da834dea8c76c87c1f,Move bindep-fallback to non-voting,MERGED,2016-02-11 16:25:03.000000000,2016-02-15 09:01:24.000000000,2016-02-15 09:01:24.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-11 16:25:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/df1579fe1f51f431b563921caf33c2b7dd521dfc', 'message': 'Move bindep-fallback to non-voting for trusty\n\nWe ready to start out as non-voting for ubuntu trusty. We should move\nto voting pretty fast. Just want to ensure the job passes at a good\nrate.\n\nChange-Id: I562c4e7d22d8c76ea5ddd1da834dea8c76c87c1f\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}, {'number': 2, 'created': '2016-02-12 13:48:25.000000000', 'files': ['jenkins/jobs/infra.yaml', 'jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/13b3deccdb51d24e09b4a12bbbbcf0f1d504a808', 'message': 'Move bindep-fallback to non-voting\n\nWe do this to move trusty into the check queue, as we want more\nregular runs.  Both Centos and Fedora should also be non-voting\nbecause they are currently not functional.\n\nChange-Id: I562c4e7d22d8c76ea5ddd1da834dea8c76c87c1f\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",2,279161,13b3deccdb51d24e09b4a12bbbbcf0f1d504a808,11,3,2,4162,,,0,"Move bindep-fallback to non-voting

We do this to move trusty into the check queue, as we want more
regular runs.  Both Centos and Fedora should also be non-voting
because they are currently not functional.

Change-Id: I562c4e7d22d8c76ea5ddd1da834dea8c76c87c1f
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/279161/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,df1579fe1f51f431b563921caf33c2b7dd521dfc,temp/bindep-voting, - name: bindep-fallback-nv check: - gate-bindep-fallback-ubuntu-trusty - name: bindep-fallback-nv - name: bindep-fallback-nv, - name: bindep-fallback - gate-bindep-fallback-ubuntu-trusty - name: bindep-fallback - name: bindep-fallback,5,4
openstack%2Fproject-config~master~I329926e69202a2e1f37e5e0bc9e5891db5589484,openstack/project-config,master,I329926e69202a2e1f37e5e0bc9e5891db5589484,Add openstack/broadview-lib project,MERGED,2016-02-03 18:09:46.000000000,2016-02-15 08:59:49.000000000,2016-02-15 08:59:49.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10980}, {'_account_id': 11515}, {'_account_id': 11809}]","[{'number': 1, 'created': '2016-02-03 18:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/aba7b481f8d74f3a69690c488ded615b8f13f669', 'message': 'Adding broadview-lib project and jobs.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 2, 'created': '2016-02-03 18:30:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f0ad05c58cb551fc17bb8a7fe6b98d164aa3e175', 'message': 'Adding broadview-lib project and jobs.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 3, 'created': '2016-02-04 16:34:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6c99f8872a54ff080214dc81041206ebdd8671bf', 'message': 'Adding broadview-lib project and jobs.\n\nbroadview-lib provides a Python interface to BroadView, which provides physical network switch metrics.\nThis project is the first of an overall contribution that will supply metrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 4, 'created': '2016-02-08 21:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2565b2b3e0228e8150cc2c823cc236d3bbd9e300', 'message': 'Adding broadview-lib project and jobs.\n\nbroadview-lib provides a Python interface to BroadView, which provides physical network switch metrics.\nThis project is the first of an overall contribution that will supply metrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 5, 'created': '2016-02-09 22:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/400be1b8cea55760a5f9180e262d72f00c335ace', 'message': 'Add openstack/broadview-lib project\n\nbroadview-lib provides a Python interface to BroadView, which\nprovides physical network switch (underlay) metrics. broadview-lib\nsupports the configuration of BroadView agents, and supports parsing of\nmonitoring messages published by agents to a collector or application\nthat receives them. Received messages are converted to an object model\nthat can be used to get at metrics data.\n\nThis project is the first of an overall contribution that will supply\nmetrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 6, 'created': '2016-02-11 19:57:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/9c855439ad53c948f8c59f7285e5e0ea1b612c37', 'message': 'Add openstack/broadview-lib project\n\nbroadview-lib provides a Python interface to BroadView, which\nprovides physical network switch (underlay) metrics. broadview-lib\nsupports the configuration of BroadView agents, and supports parsing of\nmonitoring messages published by agents to a collector or application\nthat receives them. Received messages are converted to an object model\nthat can be used to get at metrics data.\n\nThis project is the first of an overall contribution that will supply\nmetrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 7, 'created': '2016-02-12 09:56:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7bd7df67dfc0e22137ea6f30f1790fff098dd860', 'message': 'Add openstack/broadview-lib project\n\nbroadview-lib provides a Python interface to BroadView, which\nprovides physical network switch (underlay) metrics. broadview-lib\nsupports the configuration of BroadView agents, and supports parsing of\nmonitoring messages published by agents to a collector or application\nthat receives them. Received messages are converted to an object model\nthat can be used to get at metrics data.\n\nThis project is the first of an overall contribution that will supply\nmetrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}, {'number': 8, 'created': '2016-02-12 13:39:57.000000000', 'files': ['gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/broadview-lib.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b160d207e8dc3fb60be097409f9da0aa3363b53b', 'message': 'Add openstack/broadview-lib project\n\nbroadview-lib provides a Python interface to BroadView, which\nprovides physical network switch (underlay) metrics. broadview-lib\nsupports the configuration of BroadView agents, and supports parsing of\nmonitoring messages published by agents to a collector or application\nthat receives them. Received messages are converted to an object model\nthat can be used to get at metrics data.\n\nThis project is the first of an overall contribution that will supply\nmetrics data to monitoring projects like Monasca.\n\nChange-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484\n'}]",12,275873,b160d207e8dc3fb60be097409f9da0aa3363b53b,44,7,8,20260,,,0,"Add openstack/broadview-lib project

broadview-lib provides a Python interface to BroadView, which
provides physical network switch (underlay) metrics. broadview-lib
supports the configuration of BroadView agents, and supports parsing of
monitoring messages published by agents to a collector or application
that receives them. Received messages are converted to an object model
that can be used to get at metrics data.

This project is the first of an overall contribution that will supply
metrics data to monitoring projects like Monasca.

Change-Id: I329926e69202a2e1f37e5e0bc9e5891db5589484
",git fetch https://review.opendev.org/openstack/project-config refs/changes/73/275873/8 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml', 'gerrit/acls/openstack/broadview-lib.config']",4,aba7b481f8d74f3a69690c488ded615b8f13f669,master,"[access ""refs/heads/*""] abandon = group broadview-lib-core label-Code-Review = -2..+2 group broadview-lib-core label-Workflow = -1..+1 group broadview-lib-core [receive] requireChangeId = true requireContributorAgreement = true [submit] mergeContent = true ",,33,0
openstack%2Fheat~master~I0b6d55a9ee29aed4eaed63f9ad8958e9e2768b50,openstack/heat,master,I0b6d55a9ee29aed4eaed63f9ad8958e9e2768b50,Add length validation to _validate_stack_name(),MERGED,2016-02-07 23:28:08.000000000,2016-02-15 08:59:40.000000000,2016-02-15 08:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 7385}, {'_account_id': 12363}, {'_account_id': 13009}]","[{'number': 1, 'created': '2016-02-07 23:28:08.000000000', 'files': ['heat/tests/test_stack.py', 'heat/engine/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/6fca28005ed5e030eb9283e9c1944724a995ae82', 'message': 'Add length validation to _validate_stack_name()\n\nCheck that length of stack name is 255 characters\nor less so that it can fail with a BadRequest Error\ninstead of making it to the database to fail and\ngiving the user an Internal Server Error.\n\nChange-Id: I0b6d55a9ee29aed4eaed63f9ad8958e9e2768b50\nCloses-Bug: 1542955\n'}]",0,277214,6fca28005ed5e030eb9283e9c1944724a995ae82,9,4,1,7221,,,0,"Add length validation to _validate_stack_name()

Check that length of stack name is 255 characters
or less so that it can fail with a BadRequest Error
instead of making it to the database to fail and
giving the user an Internal Server Error.

Change-Id: I0b6d55a9ee29aed4eaed63f9ad8958e9e2768b50
Closes-Bug: 1542955
",git fetch https://review.opendev.org/openstack/heat refs/changes/14/277214/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_stack.py', 'heat/engine/stack.py']",2,6fca28005ed5e030eb9283e9c1944724a995ae82,bug/1542955," if not re.match(""[a-zA-Z][a-zA-Z0-9_.-]{0,254}$"", name): 'must start with alpha and must be 255 ' 'characters or less.') % name"," if not re.match(""[a-zA-Z][a-zA-Z0-9_.-]*$"", name): 'must start with alpha') % name",9,3
openstack%2Fheat~master~If5a7514131f4a51c211237238bd11b79becec419,openstack/heat,master,If5a7514131f4a51c211237238bd11b79becec419,Replace ex.message with exception_to_unicode(ex),MERGED,2016-02-08 15:18:36.000000000,2016-02-15 08:58:21.000000000,2016-02-15 08:58:20.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 9107}, {'_account_id': 9542}]","[{'number': 1, 'created': '2016-02-08 15:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/aba3a1fa05023ceb8f570fd85382b3c15a157a66', 'message': 'Replace ex.message with exception_to_unicode(ex)\n\nThe message attribute of exceptions has been removed in Python 3. Use\nexception_to_unicode(exc) of oslo_utils.encodeutils instead to get\nthe error message.\n\ntranslate_exception(exc) of heat.common.wsgi tries to translate the\nerror message and store the translated message into exc.message.\nBecause of that, exc.message is kept for HeatException and\nsubclasses.\n\nChange-Id: If5a7514131f4a51c211237238bd11b79becec419\nRelated-Bug: 1542961\n'}, {'number': 2, 'created': '2016-02-08 17:05:16.000000000', 'files': ['heat/tests/openstack/sahara/test_templates.py', 'heat/common/wsgi.py', 'heat/tests/db/test_sqlalchemy_api.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/openstack/manila/share.py', 'heat/engine/resources/openstack/sahara/templates.py', 'heat/tests/clients/test_nova_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/aa0ce433258b63e95f086db797b7c8cd51320730', 'message': 'Replace ex.message with exception_to_unicode(ex)\n\nThe message attribute of exceptions has been removed in Python 3. Use\nexception_to_unicode(exc) of oslo_utils.encodeutils instead to get\nthe error message.\n\ntranslate_exception(exc) of heat.common.wsgi tries to translate the\nerror message and store the translated message into exc.message.\nBecause of that, exc.message is kept for HeatException and\nsubclasses.\n\nCo-Authored-By: Roman Podoliaka <rpodolyaka@mirantis.com>\n\nRelated-Bug: 1542961\n\nChange-Id: If5a7514131f4a51c211237238bd11b79becec419\n'}]",0,277441,aa0ce433258b63e95f086db797b7c8cd51320730,13,5,2,9107,,,0,"Replace ex.message with exception_to_unicode(ex)

The message attribute of exceptions has been removed in Python 3. Use
exception_to_unicode(exc) of oslo_utils.encodeutils instead to get
the error message.

translate_exception(exc) of heat.common.wsgi tries to translate the
error message and store the translated message into exc.message.
Because of that, exc.message is kept for HeatException and
subclasses.

Co-Authored-By: Roman Podoliaka <rpodolyaka@mirantis.com>

Related-Bug: 1542961

Change-Id: If5a7514131f4a51c211237238bd11b79becec419
",git fetch https://review.opendev.org/openstack/heat refs/changes/41/277441/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/common/wsgi.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/resources/openstack/manila/share.py', 'heat/engine/resources/openstack/sahara/templates.py', 'heat/tests/clients/test_nova_client.py']",5,aba3a1fa05023ceb8f570fd85382b3c15a157a66,bug/1542961,"from oslo_utils import encodeutils self.assertIn('spam', encodeutils.exception_to_unicode(e))"," self.assertIn('spam', e.message)",18,9
openstack%2Fproject-config~master~I5df8289bdb44f8b23402c8f11f474bcfad65fd46,openstack/project-config,master,I5df8289bdb44f8b23402c8f11f474bcfad65fd46,Add job with functional tests for refstack,MERGED,2016-02-12 13:41:51.000000000,2016-02-15 08:56:29.000000000,2016-02-15 08:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-12 13:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/53f0b49dc54409a625e58a9072b6b0e308487a00', 'message': 'Add job with functional tests for refstack\n\nAs mentioned in bug Refstack needs additional job with\nfunctional tests in pipeline.\nI suggest to add it only to check pipeline now and see how it\nwill work. And I suggest to make it non-voting now.\n\nChange-Id: I5df8289bdb44f8b23402c8f11f474bcfad65fd46\nCloses-Bug: #1502398\n'}, {'number': 2, 'created': '2016-02-12 14:13:23.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4f893380cd8b3d86edf05446ec5141671a2fa632', 'message': 'Add job with functional tests for refstack\n\nAs mentioned in bug Refstack needs additional job with\nfunctional tests in pipeline.\nI suggest to add it only to check pipeline now and see how it\nwill work. And I suggest to make it non-voting now.\n\nChange-Id: I5df8289bdb44f8b23402c8f11f474bcfad65fd46\nCloses-Bug: #1502398\n'}]",0,279536,4f893380cd8b3d86edf05446ec5141671a2fa632,9,3,2,10234,,,0,"Add job with functional tests for refstack

As mentioned in bug Refstack needs additional job with
functional tests in pipeline.
I suggest to add it only to check pipeline now and see how it
will work. And I suggest to make it non-voting now.

Change-Id: I5df8289bdb44f8b23402c8f11f474bcfad65fd46
Closes-Bug: #1502398
",git fetch https://review.opendev.org/openstack/project-config refs/changes/36/279536/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,53f0b49dc54409a625e58a9072b6b0e308487a00,bug/1502398, - name: gate-refstack-functional voting: false - gate-refstack-tox-py27-func-mysql,,6,0
openstack%2Fproject-config~master~Ie14fae7fbf70c37ce0b53fe54ba54884b1af16da,openstack/project-config,master,Ie14fae7fbf70c37ce0b53fe54ba54884b1af16da,Add javascript jobs to stackviz,MERGED,2016-02-11 20:20:25.000000000,2016-02-15 08:52:42.000000000,2016-02-15 08:52:41.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 17001}]","[{'number': 1, 'created': '2016-02-11 20:20:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b7ab9216cf0e5af667ee66487eb670675dd1f7f5', 'message': 'Add javascript jobs to stackviz\n\nStackviz is a tempest runtime visualization tool that serves up a\nstatic website with test results. While most of the data processing is\ndone via a python module, a large amount of the codebase is written in\nAngularJS. Javascript jobs will be necessary to ensure the codebase is\nclean and maintainable as work progresses and features are added.\n\nChange-Id: Ie14fae7fbf70c37ce0b53fe54ba54884b1af16da\n'}, {'number': 2, 'created': '2016-02-11 20:28:06.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/32a8de9d5d27e163a923d83203d2eeb88d5ba681', 'message': 'Add javascript jobs to stackviz\n\nStackviz is a tempest runtime visualization tool that serves up a\nstatic website with test results. While most of the data processing is\ndone via a python module, a large amount of the codebase is written in\nAngularJS. Javascript jobs will be necessary to ensure the codebase is\nclean and maintainable as work progresses and features are added.\n\nChange-Id: Ie14fae7fbf70c37ce0b53fe54ba54884b1af16da\n'}]",0,279254,32a8de9d5d27e163a923d83203d2eeb88d5ba681,11,5,2,17005,,,0,"Add javascript jobs to stackviz

Stackviz is a tempest runtime visualization tool that serves up a
static website with test results. While most of the data processing is
done via a python module, a large amount of the codebase is written in
AngularJS. Javascript jobs will be necessary to ensure the codebase is
clean and maintainable as work progresses and features are added.

Change-Id: Ie14fae7fbf70c37ce0b53fe54ba54884b1af16da
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/279254/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b7ab9216cf0e5af667ee66487eb670675dd1f7f5,stackviz-jobs, - name: javascript-jobs,,1,0
openstack%2Fproject-config~master~I94b8fcb1eee8ceeeb0cd55b9a83d11ecaa730fcc,openstack/project-config,master,I94b8fcb1eee8ceeeb0cd55b9a83d11ecaa730fcc,Add neutron tempest run using neutron-lib master to neutron exp,MERGED,2016-02-11 01:48:25.000000000,2016-02-15 08:52:34.000000000,2016-02-15 08:52:33.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-11 01:48:25.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ee338fc95f67f0daf73ffe0ae20f958219dd8be1', 'message': ""Add neutron tempest run using neutron-lib master to neutron exp\n\nThis adds a job for running the neutron tempest tests against\nthe master branch of neutron-lib, as opposed to pypi, in the\nneutron experimental queue. This is used to check changes\nto neutron to use new library routines, before they have been\nreleased to pypi. Why not wait until the routines are released?\nBecause it's much less error-prone to make the changes to the\nlib and neutron at the same time.\n\nThis job is temporary until the code migration across M/N\nis complete.\n\nI can hack something gross to use the in-tree api test as\na stand-in for this, if we don't want to use this job for\nthis purpose, but this seems like it might be cleaner.\n\nChange-Id: I94b8fcb1eee8ceeeb0cd55b9a83d11ecaa730fcc\n""}]",0,278825,ee338fc95f67f0daf73ffe0ae20f958219dd8be1,7,3,1,10980,,,0,"Add neutron tempest run using neutron-lib master to neutron exp

This adds a job for running the neutron tempest tests against
the master branch of neutron-lib, as opposed to pypi, in the
neutron experimental queue. This is used to check changes
to neutron to use new library routines, before they have been
released to pypi. Why not wait until the routines are released?
Because it's much less error-prone to make the changes to the
lib and neutron at the same time.

This job is temporary until the code migration across M/N
is complete.

I can hack something gross to use the in-tree api test as
a stand-in for this, if we don't want to use this job for
this purpose, but this seems like it might be cleaner.

Change-Id: I94b8fcb1eee8ceeeb0cd55b9a83d11ecaa730fcc
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/278825/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,ee338fc95f67f0daf73ffe0ae20f958219dd8be1,add-n-l-to-n-exp, - gate-tempest-dsvm-neutron-src-neutron-lib,,1,0
openstack%2Fsenlin~master~I0a7f3fc2e4e46dd4470d91a8cffd74d232fb04b7,openstack/senlin,master,I0a7f3fc2e4e46dd4470d91a8cffd74d232fb04b7,Make do_join/leave in profile base return True,MERGED,2016-02-15 08:21:37.000000000,2016-02-15 08:51:54.000000000,2016-02-15 08:51:54.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 08:21:37.000000000', 'files': ['senlin/profiles/os/heat/stack.py', 'senlin/profiles/os/nova/server.py', 'senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9e0192a2abf59a0d37424d02dca2db288fb6e064', 'message': 'Make do_join/leave in profile base return True\n\nThis patch makes do_join and do_leave methods in profile base\nmodule return True by default. Subclass can override these two\nmethods to perform extra operations if needed.\n\nChange-Id: I0a7f3fc2e4e46dd4470d91a8cffd74d232fb04b7\nCloses-Bug: #1545604\n'}]",0,280100,9e0192a2abf59a0d37424d02dca2db288fb6e064,7,3,1,11034,,,0,"Make do_join/leave in profile base return True

This patch makes do_join and do_leave methods in profile base
module return True by default. Subclass can override these two
methods to perform extra operations if needed.

Change-Id: I0a7f3fc2e4e46dd4470d91a8cffd74d232fb04b7
Closes-Bug: #1545604
",git fetch https://review.opendev.org/openstack/senlin refs/changes/00/280100/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/heat/stack.py', 'senlin/profiles/os/nova/server.py', 'senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py']",4,9e0192a2abf59a0d37424d02dca2db288fb6e064,bug/1545604," self.assertEqual(True, self.assertEqual(True, profile.do_leave(mock.Mock()))"," self.assertEqual(NotImplemented, self.assertEqual(NotImplemented, profile.do_leave(mock.Mock()))",8,16
openstack%2Fproject-config~master~I75f7066dca7b26204fa7a0196fd019c1b33aa3a3,openstack/project-config,master,I75f7066dca7b26204fa7a0196fd019c1b33aa3a3,create openstack/service-types-authority,MERGED,2016-02-10 20:33:45.000000000,2016-02-15 08:49:03.000000000,2016-02-15 08:49:02.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 2750}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10670}, {'_account_id': 11564}]","[{'number': 1, 'created': '2016-02-10 20:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b5245542860be4f44e138c3f70cc0a9f637db0dd', 'message': 'create openstack/service-registry\n\nThis creates the openstack service registry project, as the output of\nthe following mailing list discussion:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-February/086269.html\n\nThe purpose of this will be a dedicated registry location for service\ntypes in OpenStack under the watchful eye of the API working group.\n\nChange-Id: I75f7066dca7b26204fa7a0196fd019c1b33aa3a3\n'}, {'number': 2, 'created': '2016-02-11 10:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/06eb87a45eae465a901a2ddedb203e0eff577ae6', 'message': 'create openstack/service-registry\n\nThis creates the openstack service registry project, as the output of\nthe following mailing list discussion:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-February/086269.html\n\nThe purpose of this will be a dedicated registry location for service\ntypes in OpenStack under the watchful eye of the API working group.\n\nChange-Id: I75f7066dca7b26204fa7a0196fd019c1b33aa3a3\n'}, {'number': 3, 'created': '2016-02-12 13:31:59.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/acls/openstack/service-types-authority.config', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/fc549f106059aa119d1d6c4bdb3925268c9f3c8b', 'message': 'create openstack/service-types-authority\n\nThis creates the openstack service types authority (think IANA), as\nthe output of the following mailing list discussion:\n\nhttp://lists.openstack.org/pipermail/openstack-dev/2016-February/086269.html\n\nThe purpose of this will be a dedicated registry location for service\ntypes in OpenStack under the watchful eye of the API working group.\n\nChange-Id: I75f7066dca7b26204fa7a0196fd019c1b33aa3a3\n'}]",0,278612,fc549f106059aa119d1d6c4bdb3925268c9f3c8b,19,7,3,2750,,,0,"create openstack/service-types-authority

This creates the openstack service types authority (think IANA), as
the output of the following mailing list discussion:

http://lists.openstack.org/pipermail/openstack-dev/2016-February/086269.html

The purpose of this will be a dedicated registry location for service
types in OpenStack under the watchful eye of the API working group.

Change-Id: I75f7066dca7b26204fa7a0196fd019c1b33aa3a3
",git fetch https://review.opendev.org/openstack/project-config refs/changes/12/278612/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/service-registry.config', 'gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,b5245542860be4f44e138c3f70cc0a9f637db0dd,service-registry, - name: openstack/service-registry template: - name: merge-check - name: noop-jobs ,,22,0
openstack%2Fsenlin~master~Ie0b063d8a0fe6c57515b6ae9ae440ae468118807,openstack/senlin,master,Ie0b063d8a0fe6c57515b6ae9ae440ae468118807,Improve param checking for event-list,MERGED,2016-02-14 08:17:22.000000000,2016-02-15 08:43:22.000000000,2016-02-15 08:43:22.000000000,"[{'_account_id': 3}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-14 08:17:22.000000000', 'files': ['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_events.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4876cbad03c25df41b3bcd89c69a88e9e6b67253', 'message': ""Improve param checking for event-list\n\nThis patch adds checking for 'limit' and 'project_safe' parameters when\nlisting events.\n\nChange-Id: Ie0b063d8a0fe6c57515b6ae9ae440ae468118807\n""}]",0,279933,4876cbad03c25df41b3bcd89c69a88e9e6b67253,7,2,1,8246,,,0,"Improve param checking for event-list

This patch adds checking for 'limit' and 'project_safe' parameters when
listing events.

Change-Id: Ie0b063d8a0fe6c57515b6ae9ae440ae468118807
",git fetch https://review.opendev.org/openstack/senlin refs/changes/33/279933/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_events.py']",2,4876cbad03c25df41b3bcd89c69a88e9e6b67253,event-list-cond," def test_event_list_bad_limit(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.event_list, self.ctx, limit='MANY') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'MANY' specified for 'limit'"", six.text_type(ex.exc_info[1])) def test_event_list_bad_project_safe(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.event_list, self.ctx, project_safe='yes') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'yes' specified for 'project_safe'"", six.text_type(ex.exc_info[1])) ",,20,0
openstack%2Fproject-config~master~Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c,openstack/project-config,master,Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c,Adds new project Python-namosclient,MERGED,2016-02-12 07:18:14.000000000,2016-02-15 08:41:04.000000000,2016-02-15 08:41:04.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10487}, {'_account_id': 11809}]","[{'number': 1, 'created': '2016-02-12 07:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8509102c636157832f89fb285d1722f90641c91d', 'message': 'Python-namosclient\n\nAdds the python client for the namos service.\n\nChange-Id: Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c\n'}, {'number': 2, 'created': '2016-02-12 09:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5cba74f822321db1e8342e3a009039c1e32cd749', 'message': 'Adds new project Python-namosclient\n\nAdds new project for python client to OpenStack service namos,\nwhich is available at https://github.com/openstack/namos\n\nChange-Id: Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c\n'}, {'number': 3, 'created': '2016-02-12 13:20:25.000000000', 'files': ['gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e6334ba99ff2782902527fdffef42e8523d58be5', 'message': 'Adds new project Python-namosclient\n\nAdds new project for python client to OpenStack service namos,\nwhich is available at https://git.openstack.org/openstack/namos\n\nChange-Id: Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c\n'}]",7,279399,e6334ba99ff2782902527fdffef42e8523d58be5,15,5,3,10487,,,0,"Adds new project Python-namosclient

Adds new project for python client to OpenStack service namos,
which is available at https://git.openstack.org/openstack/namos

Change-Id: Ic58bdd61899fb796c3b09e7eaef893b9cc4e4d7c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/99/279399/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/python-namosclient.config', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",4,8509102c636157832f89fb285d1722f90641c91d,new-project, - name: openstack/python-namosclient template: - name: merge-check - name: noop-jobs ,,33,0
openstack%2Fproject-config~master~Iea35bf890a85eda80595b249e578976e8e74260f,openstack/project-config,master,Iea35bf890a85eda80595b249e578976e8e74260f,Import puppet-pacemaker from github/redhat-openstack,MERGED,2016-02-12 17:42:31.000000000,2016-02-15 08:39:20.000000000,2016-02-15 08:39:20.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6796}, {'_account_id': 6928}, {'_account_id': 7144}, {'_account_id': 7984}, {'_account_id': 10873}]","[{'number': 1, 'created': '2016-02-12 17:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7e64ed42b6c51eb4b2faf6ae96078633607642c3', 'message': 'Import puppet-pacemaker from github/redhat-openstack\n\npuppet-pacemaker is a Puppet modules started by Red Hat folks a few\nyears ago and is now highly used in TripleO project.\n\nBecause we want to improve TripleO CI coverage, moving this module to\nOpenStack will help us to:\n\n* run TripleO HA jobs for each patch in puppet-pacemaker and improve its\n  stability.\n* allow anyone to send patches with Gerrit\n* use OpenStack Infra to benefit existing Puppet CI jobs\n\nThe module would not be under any tent now, just like puppet-ceph.\nIt would be a community module, without PTL, just some core reviewers,\nmainly people actually working on it.\n\nChange-Id: Iea35bf890a85eda80595b249e578976e8e74260f\n'}, {'number': 2, 'created': '2016-02-12 17:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/47f878527cf764d5a8ad317a920e67e95291aae5', 'message': 'Import puppet-pacemaker from github/redhat-openstack\n\npuppet-pacemaker is a Puppet modules started by Red Hat folks a few\nyears ago and is now highly used in TripleO project.\n\nBecause we want to improve TripleO CI coverage, moving this module to\nOpenStack will help us to:\n\n* run TripleO HA jobs for each patch in puppet-pacemaker and improve its\n  stability.\n* allow anyone to send patches with Gerrit\n* use OpenStack Infra to benefit existing Puppet CI jobs\n\nThe module would not be under any tent now, just like puppet-ceph.\nIt would be a community module, without PTL, just some core reviewers,\nmainly people actually working on it.\n\nChange-Id: Iea35bf890a85eda80595b249e578976e8e74260f\n'}, {'number': 3, 'created': '2016-02-12 21:20:58.000000000', 'files': ['gerrit/acls/openstack/puppet-pacemaker.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c7b965abec38f685d1dc8299a876933a37565080', 'message': 'Import puppet-pacemaker from github/redhat-openstack\n\npuppet-pacemaker is a Puppet modules started by Red Hat folks a few\nyears ago and is now highly used in TripleO project.\n\nBecause we want to improve TripleO CI coverage, moving this module to\nOpenStack will help us to:\n\n* run TripleO HA jobs for each patch in puppet-pacemaker and improve its\n  stability.\n* allow anyone to send patches with Gerrit\n* use OpenStack Infra to benefit existing Puppet CI jobs\n\nThe module would not be under any tent now, just like puppet-ceph.\nIt would be a community module, without PTL, just some core reviewers,\nmainly people actually working on it.\n\nChange-Id: Iea35bf890a85eda80595b249e578976e8e74260f\n'}]",5,279698,c7b965abec38f685d1dc8299a876933a37565080,19,11,3,3153,,,0,"Import puppet-pacemaker from github/redhat-openstack

puppet-pacemaker is a Puppet modules started by Red Hat folks a few
years ago and is now highly used in TripleO project.

Because we want to improve TripleO CI coverage, moving this module to
OpenStack will help us to:

* run TripleO HA jobs for each patch in puppet-pacemaker and improve its
  stability.
* allow anyone to send patches with Gerrit
* use OpenStack Infra to benefit existing Puppet CI jobs

The module would not be under any tent now, just like puppet-ceph.
It would be a community module, without PTL, just some core reviewers,
mainly people actually working on it.

Change-Id: Iea35bf890a85eda80595b249e578976e8e74260f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/98/279698/3 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/puppet-pacemaker.config', 'gerritbot/channels.yaml', 'jenkins/jobs/projects.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml']",5,7e64ed42b6c51eb4b2faf6ae96078633607642c3,puppet/pacemaker, - name: openstack/puppet-pacemaker template: - name: merge-check - name: puppet-check-jobs - name: puppet-module-unit-jobs - name: puppet-beaker-jobs check-tripleo: - gate-tripleo-ci-f22-nonha ,,41,0
openstack%2Fkarbor~master~I60874d40f9e260aee7185b3cf6689cfa85db331d,openstack/karbor,master,I60874d40f9e260aee7185b3cf6689cfa85db331d,Implement the GET and DELETE RESTAPI of resource plans,ABANDONED,2016-02-15 03:32:18.000000000,2016-02-15 08:35:08.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-15 03:32:18.000000000', 'files': ['smaug/api/v1/plans.py', 'smaug/db/api.py', 'smaug/db/sqlalchemy/api.py', 'smaug/utils.py', 'smaug/tests/unit/api/v1/test_router.py', 'smaug/objects/plan.py', 'smaug/tests/unit/api/v1/test_plans.py', 'smaug/exception.py', 'smaug/api/v1/router.py', 'etc/policy.json'], 'web_link': 'https://opendev.org/openstack/karbor/commit/ecfabb8cf48faed651cf6012a42e466691fe8210', 'message': 'Implement the GET and DELETE RESTAPI of resource plans\n\nChange-Id: I60874d40f9e260aee7185b3cf6689cfa85db331d\nCloses-Bug: #1541729\n'}]",0,280054,ecfabb8cf48faed651cf6012a42e466691fe8210,3,1,1,17151,,,0,"Implement the GET and DELETE RESTAPI of resource plans

Change-Id: I60874d40f9e260aee7185b3cf6689cfa85db331d
Closes-Bug: #1541729
",git fetch https://review.opendev.org/openstack/karbor refs/changes/54/280054/1 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/api/v1/plans.py', 'smaug/db/api.py', 'smaug/db/sqlalchemy/api.py', 'smaug/utils.py', 'smaug/tests/unit/api/v1/test_router.py', 'smaug/objects/plan.py', 'smaug/tests/unit/api/v1/test_plans.py', 'smaug/api/v1/router.py', 'smaug/exception.py', 'etc/policy.json']",10,ecfabb8cf48faed651cf6012a42e466691fe8210,bug/1541729," ""plan:get"": ""rule:admin_or_owner"", ""plan:get_all"": ""rule:admin_or_owner"""," ""plan:get"": ""rule:admin_or_owner""",529,30
openstack%2Fproject-config~master~Ifa8b55e8cf9d26792a5e969998850ea9dbf094ca,openstack/project-config,master,Ifa8b55e8cf9d26792a5e969998850ea9dbf094ca,Sort devstack-jobs list,MERGED,2016-02-09 20:42:20.000000000,2016-02-15 08:29:25.000000000,2016-02-15 08:29:24.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-09 20:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2dcc219c383cf38f127299a0a7b80169236cdd79', 'message': 'Sort devstack-jobs list\n\nJust sort the entries alphabetically so that related entries can\nbe found more easily.\n\nChange-Id: Ifa8b55e8cf9d26792a5e969998850ea9dbf094ca\n'}, {'number': 2, 'created': '2016-02-12 17:25:19.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0cd45c07f7135bba0e1adc96555d7450d932f34e', 'message': 'Sort devstack-jobs list\n\nJust sort the entries alphabetically so that related entries can\nbe found more easily.\n\nChange-Id: Ifa8b55e8cf9d26792a5e969998850ea9dbf094ca\n'}]",0,278084,0cd45c07f7135bba0e1adc96555d7450d932f34e,10,3,2,6547,,,0,"Sort devstack-jobs list

Just sort the entries alphabetically so that related entries can
be found more easily.

Change-Id: Ifa8b55e8cf9d26792a5e969998850ea9dbf094ca
",git fetch https://review.opendev.org/openstack/project-config refs/changes/84/278084/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,2dcc219c383cf38f127299a0a7b80169236cdd79,cleanup-devstack, - '{pipeline}-grenade-dsvm-forward{job-suffix}' - '{pipeline}-grenade-dsvm-ironic{job-suffix}' - '{pipeline}-grenade-dsvm-neutron-forward{job-suffix}' - '{pipeline}-grenade-dsvm-neutron{job-suffix}' - '{pipeline}-grenade-dsvm-partial-ironic{job-suffix}' - '{pipeline}-grenade-dsvm-partial-ncpu{job-suffix}' - '{pipeline}-grenade-dsvm-sahara{job-suffix}' - '{pipeline}-grenade-dsvm-trove{job-suffix}' - '{pipeline}-grenade-dsvm{job-suffix}' - '{pipeline}-tempest-dsvm-cells{job-suffix}' - '{pipeline}-tempest-dsvm-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-full{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-agent_ssh-src{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-agent_ssh{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-parallel{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa-ipxe{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa-src{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ssh-postgres{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ssh{job-suffix}' - '{pipeline}-tempest-dsvm-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-lxc{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-dvr-ovs-native{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-dvr{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-non-admin{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-ssh{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-identity-v3-only-full{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-ovs-native{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-pg-full{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-plus{job-suffix}' - '{pipeline}-tempest-dsvm-neutron{job-suffix}' - '{pipeline}-tempest-dsvm-nova-v20-api-legacy{job-suffix}' - '{pipeline}-tempest-dsvm-nova-v20-api{job-suffix}' - '{pipeline}-tempest-dsvm-nova-wsgi-full{job-suffix}' - '{pipeline}-tempest-dsvm-postgres-full{job-suffix}' - '{pipeline}-tempest-dsvm-stress-keystonev3{job-suffix}' - '{pipeline}-tempest-dsvm-stress{job-suffix}' - '{pipeline}-tempest-dsvm-trove{job-suffix}', - '{pipeline}-tempest-dsvm-full{job-suffix}' - '{pipeline}-tempest-dsvm-neutron{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-ovs-native{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-dvr{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-dvr-ovs-native{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-ssh{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-plus{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-pg-full{job-suffix}' - '{pipeline}-tempest-dsvm-cells{job-suffix}' - '{pipeline}-tempest-dsvm-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-lxc{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-large-ops{job-suffix}' - '{pipeline}-tempest-dsvm-postgres-full{job-suffix}' - '{pipeline}-grenade-dsvm{job-suffix}' - '{pipeline}-grenade-dsvm-forward{job-suffix}' - '{pipeline}-grenade-dsvm-neutron{job-suffix}' - '{pipeline}-grenade-dsvm-neutron-forward{job-suffix}' - '{pipeline}-grenade-dsvm-partial-ncpu{job-suffix}' - '{pipeline}-grenade-dsvm-ironic{job-suffix}' - '{pipeline}-grenade-dsvm-partial-ironic{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ssh{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ssh-postgres{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-agent_ssh{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-agent_ssh-src{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa-src{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-pxe_ipa-ipxe{job-suffix}' - '{pipeline}-tempest-dsvm-ironic-parallel{job-suffix}' - '{pipeline}-tempest-dsvm-stress{job-suffix}' - '{pipeline}-tempest-dsvm-stress-keystonev3{job-suffix}' - '{pipeline}-tempest-dsvm-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-test-accounts{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-full-non-admin{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-identity-v3-only-full{job-suffix}' - '{pipeline}-tempest-dsvm-nova-v20-api{job-suffix}' - '{pipeline}-tempest-dsvm-nova-v20-api-legacy{job-suffix}' - '{pipeline}-tempest-dsvm-nova-wsgi-full{job-suffix}' - '{pipeline}-tempest-dsvm-trove{job-suffix}' - '{pipeline}-grenade-dsvm-trove{job-suffix}' - '{pipeline}-grenade-dsvm-sahara{job-suffix}',41,41
openstack%2Fproject-config~master~I541466c96426f511393195e3fc6e4df46f3ea572,openstack/project-config,master,I541466c96426f511393195e3fc6e4df46f3ea572,Remove unused templates from devstack-gate.yaml,MERGED,2016-02-09 19:40:32.000000000,2016-02-15 08:29:05.000000000,2016-02-15 08:29:05.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}, {'_account_id': 10980}, {'_account_id': 11515}]","[{'number': 1, 'created': '2016-02-09 19:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/7e501c10f3f5703c8a24f5d3161f7afbe5f88584', 'message': 'Remove unused templates from devstack-gate.yaml\n\nRemove job templates that are not used anywhere currently.\n\n{pipeline}-tempest-dsvm-large-ops-testing{job-suffix} and\n{pipeline}-tempest-dsvm-neutron-large-ops-testing{job-suffix}:\n  Both removed in I7ed7e6eb8225a29c06245b8056ad4495b3136679\n{pipeline}-tempest-dsvm-postgres-zeromq-full{job-suffix}:\n  Already unused in import from openstack-infra/config repo\n{pipeline}-tempest-dsvm-coverage{job-suffix}:\n  Already unused in import from openstack-infra/config repo\n{pipeline}-tempest-dsvm-src-{name}{job-suffix}:\n  Removed in I1dcd8558b98443ffa9a3a01c2e877bd64bb96296\n\nChange-Id: I541466c96426f511393195e3fc6e4df46f3ea572\n'}, {'number': 2, 'created': '2016-02-12 17:25:19.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b7dc3f81184fcee59ac12a53eda1827a6d4c2eaa', 'message': 'Remove unused templates from devstack-gate.yaml\n\nRemove job templates that are not used anywhere currently.\n\n{pipeline}-tempest-dsvm-postgres-zeromq-full{job-suffix}:\n  Already unused in import from openstack-infra/config repo\n{pipeline}-tempest-dsvm-coverage{job-suffix}:\n  Already unused in import from openstack-infra/config repo\n{pipeline}-tempest-dsvm-src-{name}{job-suffix}:\n  Removed in I1dcd8558b98443ffa9a3a01c2e877bd64bb96296\n\nChange-Id: I541466c96426f511393195e3fc6e4df46f3ea572\n'}]",0,278061,b7dc3f81184fcee59ac12a53eda1827a6d4c2eaa,14,5,2,6547,,,0,"Remove unused templates from devstack-gate.yaml

Remove job templates that are not used anywhere currently.

{pipeline}-tempest-dsvm-postgres-zeromq-full{job-suffix}:
  Already unused in import from openstack-infra/config repo
{pipeline}-tempest-dsvm-coverage{job-suffix}:
  Already unused in import from openstack-infra/config repo
{pipeline}-tempest-dsvm-src-{name}{job-suffix}:
  Removed in I1dcd8558b98443ffa9a3a01c2e877bd64bb96296

Change-Id: I541466c96426f511393195e3fc6e4df46f3ea572
",git fetch https://review.opendev.org/openstack/project-config refs/changes/61/278061/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,7e501c10f3f5703c8a24f5d3161f7afbe5f88584,cleanup-devstack,,"# tempest-dsvm-src-{name} - run a devstack tempest job, but use the # zuul git ref for name instead of the released library version. # # Purpose: this allows libraries to test their proposed commits to # ensure they don't break OpenStack on their next release. It is # expected to eventually be part of all library jobs in OpenStack, as # the main tempest-dsvm jobs will be using only released versions of # libraries. - job-template: name: '{pipeline}-tempest-dsvm-src-{name}{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 130 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PROJECTS=""openstack/{name} $PROJECTS"" export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_FULL=1 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_PROJECT_FROM_GIT={name} cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log name: '{pipeline}-tempest-dsvm-large-ops-testing{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 100 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_NO_SERVICES=1 ENABLED_SERVICES=n-api,n-crt,n-cpu,n-sch,n-cond,g-api,g-reg,key,n-net # n-obj has been removed from mitaka if [[ ""stable/kilo stable/liberty"" =~ $ZUUL_BRANCH ]]; then ENABLED_SERVICES+=,n-obj, fi export ENABLED_SERVICES export DEVSTACK_GATE_TEMPEST_LARGE_OPS=100 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-neutron-large-ops-testing{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 100 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_NO_SERVICES=1 ENABLED_SERVICES=n-api,n-crt,n-cpu,n-sch,n-cond,g-api,g-reg,key # n-obj has been removed from mitaka if [[ ""stable/kilo stable/liberty"" =~ $ZUUL_BRANCH ]]; then ENABLED_SERVICES+=,n-obj, fi export ENABLED_SERVICES export DEVSTACK_GATE_TEMPEST_LARGE_OPS=100 export DEVSTACK_GATE_NEUTRON=1 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-postgres-zeromq-full{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 130 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_FULL=1 export DEVSTACK_GATE_POSTGRES=1 export DEVSTACK_GATE_MQ_DRIVER=""zeromq"" export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-coverage{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 130 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - shell: | #!/bin/bash -xe export PYTHONUNBUFFERED=true export DEVSTACK_GATE_TEMPEST=1 export DEVSTACK_GATE_TEMPEST_COVERAGE=1 export BRANCH_OVERRIDE={branch-override} if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh publishers: - devstack-logs - console-log - job-template: - '{pipeline}-tempest-dsvm-src-{name}{job-suffix}' - '{pipeline}-tempest-dsvm-large-ops-testing{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-large-ops-testing{job-suffix}' - '{pipeline}-tempest-dsvm-postgres-zeromq-full{job-suffix}' - '{pipeline}-tempest-dsvm-coverage{job-suffix}'",0,188
openstack%2Fproject-config~master~I55a29a280a66ffe4eb187249f58f24f3a722f294,openstack/project-config,master,I55a29a280a66ffe4eb187249f58f24f3a722f294,Remove {name} jobs from devstack-jobs,MERGED,2016-02-09 20:27:41.000000000,2016-02-15 08:28:41.000000000,2016-02-15 08:28:40.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-09 20:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/742d3d0313a3a97388bea5711eb63bf649783804', 'message': 'Remove {name} jobs from devstack-jobs\n\nThe job group devstack-jobs is only used with the name devstack-jobs in\nprojects.yaml - but it should be with repository names. So, all the\njobs here are also setup separately.\n\nSo, remove these jobs from devstack-jobs, they are totally wrong here\nand will not work as expected.\n\nChange-Id: I55a29a280a66ffe4eb187249f58f24f3a722f294\n'}, {'number': 2, 'created': '2016-02-12 17:25:19.000000000', 'files': ['jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ee2eeb87108ed62fb6a44fbf69d5fa1c566a44c6', 'message': 'Remove {name} jobs from devstack-jobs\n\nThe job group devstack-jobs is only used with the name devstack-jobs in\nprojects.yaml - but it should be with repository names. So, all the\njobs here are also setup separately.\n\nSo, remove these jobs from devstack-jobs, they are totally wrong here\nand will not work as expected.\n\nChange-Id: I55a29a280a66ffe4eb187249f58f24f3a722f294\n'}]",0,278073,ee2eeb87108ed62fb6a44fbf69d5fa1c566a44c6,11,3,2,6547,,,0,"Remove {name} jobs from devstack-jobs

The job group devstack-jobs is only used with the name devstack-jobs in
projects.yaml - but it should be with repository names. So, all the
jobs here are also setup separately.

So, remove these jobs from devstack-jobs, they are totally wrong here
and will not work as expected.

Change-Id: I55a29a280a66ffe4eb187249f58f24f3a722f294
",git fetch https://review.opendev.org/openstack/project-config refs/changes/73/278073/2 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/devstack-gate.yaml'],1,742d3d0313a3a97388bea5711eb63bf649783804,cleanup-devstack,, - '{pipeline}-tempest-dsvm-test-accounts-src-{name}{job-suffix}' - '{pipeline}-tempest-dsvm-neutron-src-{name}{job-suffix}' - '{pipeline}-tempest-dsvm-largeops-src-{name}{job-suffix}' - '{pipeline}-tempest-dsvm-full-ceph-src-{name}{job-suffix}' - '{pipeline}-{name}-src-grenade-dsvm{job-suffix}',0,5
openstack%2Fproject-config~master~I95626cf9a316d680adcec149aad6a58190b5fcd4,openstack/project-config,master,I95626cf9a316d680adcec149aad6a58190b5fcd4,Remove linters from jenkins/jobs/python-jobs,MERGED,2016-02-12 20:45:04.000000000,2016-02-15 08:27:04.000000000,2016-02-15 08:27:04.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-12 20:45:04.000000000', 'files': ['jenkins/jobs/python-jobs.yaml', 'jenkins/jobs/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/8a4f347f2384b259f8cfbf8023b54a1258ca210f', 'message': 'Remove linters from jenkins/jobs/python-jobs\n\nRemove the linters template from the jenkins python-jobs template, add\nit to those few repositories that still need it.\n\nChange-Id: I95626cf9a316d680adcec149aad6a58190b5fcd4\n'}]",0,279781,8a4f347f2384b259f8cfbf8023b54a1258ca210f,7,3,1,6547,,,0,"Remove linters from jenkins/jobs/python-jobs

Remove the linters template from the jenkins python-jobs template, add
it to those few repositories that still need it.

Change-Id: I95626cf9a316d680adcec149aad6a58190b5fcd4
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/279781/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/python-jobs.yaml', 'jenkins/jobs/projects.yaml']",2,8a4f347f2384b259f8cfbf8023b54a1258ca210f,pti-pep8-linters, - gate-{name}-linters - gate-{name}-linters - gate-{name}-linters - gate-{name}-linters,,4,1
openstack%2Fproject-config~master~Ica69d5ba3e37cd6258bd1d68baef2e63635f4ec1,openstack/project-config,master,Ica69d5ba3e37cd6258bd1d68baef2e63635f4ec1,Move gate-networking-midonet-v2-dsvm-rally-nv out of experimental,MERGED,2016-02-12 03:53:32.000000000,2016-02-15 08:25:07.000000000,2016-02-15 08:25:07.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-02-12 03:53:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ebf30962c08172408c6525375aa4cdf556a51aca', 'message': 'Move gate-networking-midonet-v2-dsvm-rally-nv out of experimental\n\nMake it an non-voting job as it seems working well.\n\nChange-Id: Ica69d5ba3e37cd6258bd1d68baef2e63635f4ec1\n'}, {'number': 2, 'created': '2016-02-12 03:54:34.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/dd218e6c7f55c52eb53f9001562f982e75900bfb', 'message': 'Move gate-networking-midonet-v2-dsvm-rally-nv out of experimental\n\nMake it a non-voting job as it seems working well.\n\nChange-Id: Ica69d5ba3e37cd6258bd1d68baef2e63635f4ec1\n'}]",0,279373,dd218e6c7f55c52eb53f9001562f982e75900bfb,10,4,2,6854,,,0,"Move gate-networking-midonet-v2-dsvm-rally-nv out of experimental

Make it a non-voting job as it seems working well.

Change-Id: Ica69d5ba3e37cd6258bd1d68baef2e63635f4ec1
",git fetch https://review.opendev.org/openstack/project-config refs/changes/73/279373/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,ebf30962c08172408c6525375aa4cdf556a51aca,midonet-rally-nv, - gate-networking-midonet-v2-dsvm-rally-nv, experimental: - gate-networking-midonet-v2-dsvm-rally-nv,1,2
openstack%2Fsenlin~master~I297221df75efa535005b1b7292bdb80483f83e7b,openstack/senlin,master,I297221df75efa535005b1b7292bdb80483f83e7b,Check nova server status after rebuilding it,MERGED,2016-02-15 07:16:57.000000000,2016-02-15 08:05:18.000000000,2016-02-15 08:05:18.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 07:16:57.000000000', 'files': ['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/0d64a7c42586a9c8276d179a07d56faa227e389c', 'message': 'Check nova server status after rebuilding it\n\nThis patch revises some methods in os.nova.server profile to add\nwaiting logic after rebuilding a server.\n\nChange-Id: I297221df75efa535005b1b7292bdb80483f83e7b\n'}]",0,280083,0d64a7c42586a9c8276d179a07d56faa227e389c,7,3,1,11034,,,0,"Check nova server status after rebuilding it

This patch revises some methods in os.nova.server profile to add
waiting logic after rebuilding a server.

Change-Id: I297221df75efa535005b1b7292bdb80483f83e7b
",git fetch https://review.opendev.org/openstack/senlin refs/changes/83/280083/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/profiles/os/nova/server.py', 'senlin/tests/unit/profiles/test_nova_server.py']",2,0d64a7c42586a9c8276d179a07d56faa227e389c,check-nova-server-status-after-rebuild," novaclient.wait_for_server.assert_called_once_with('FAKE_ID', 'ACTIVE') novaclient.wait_for_server.assert_called_once_with('FAKE_ID', 'ACTIVE') nc.wait_for_server.assert_called_once_with('FAKE_ID', 'ACTIVE')",,7,0
openstack%2Fproject-config~master~I8d83c049165cfffd165b2e83b2ed37c1407849e3,openstack/project-config,master,I8d83c049165cfffd165b2e83b2ed37c1407849e3,Use pep8 instead of linters for terracotta,MERGED,2016-02-10 21:28:01.000000000,2016-02-15 07:58:03.000000000,2016-02-15 07:58:03.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 8290}]","[{'number': 1, 'created': '2016-02-10 21:28:01.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/355c798102de1c1db8414818a8bb30c49fe0b1c6', 'message': 'Use pep8 instead of linters for terracotta\n\nUse standard python-jobs template to get pep8 instead of linters to\nfollow PTI.\n\nChange-Id: I8d83c049165cfffd165b2e83b2ed37c1407849e3\nDepends-On: Iab513d7f3a087ff7042be5cf00be4a4d2677e2cd\n'}]",0,278645,355c798102de1c1db8414818a8bb30c49fe0b1c6,10,5,1,6547,,,0,"Use pep8 instead of linters for terracotta

Use standard python-jobs template to get pep8 instead of linters to
follow PTI.

Change-Id: I8d83c049165cfffd165b2e83b2ed37c1407849e3
Depends-On: Iab513d7f3a087ff7042be5cf00be4a4d2677e2cd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/278645/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,355c798102de1c1db8414818a8bb30c49fe0b1c6,pti-pep8-linters, - name: python-jobs, - name: python-jobs-linters,1,1
openstack%2Fneutron~master~I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5,openstack/neutron,master,I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5,ML2: delete_port on deadlock during binding,MERGED,2016-02-10 20:30:25.000000000,2016-02-15 07:52:42.000000000,2016-02-11 11:14:21.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 7787}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 12692}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-10 20:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9128ee9174738df2bf37c151a56e668da0f5e6ae', 'message': 'ML2: delete_port on any exception during binding\n\nThe previous logic was only catching mechanism driver exceptions so\nit would leave behind a partially built port if any other exception\ntype was encountered.\n\nThe bug this closes was caused by a DBDeadlock being encountered which\nwould not be caught so the API would retry the whole operation with\nthe original created port left behind. This resulted in two ports\nassigned to the same instance.\n\nCloses-Bug: #1543880\nChange-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5\n'}, {'number': 2, 'created': '2016-02-10 20:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f485345da4ed7462c5385045a253bd607c7a4ca7', 'message': 'ML2: delete_port on any exception during binding\n\nThe previous logic was only catching mechanism driver exceptions so\nit would leave behind a partially built port if a deadlock was\nencountered during port binding.\n\nThe bug this closes was caused by a DBDeadlock being encountered when\na lock was attempted on the port binding record\n(get_locked_port_and_binding). This would not be caught so the API\nwould retry the whole operation with the original created port\nleft behind. This resulted in two ports assigned to the same instance.\n\nCloses-Bug: #1543880\nChange-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5\n'}, {'number': 3, 'created': '2016-02-11 04:51:21.000000000', 'files': ['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb8141051abe64de7ad9398fb2adaf9a0a79d62d', 'message': 'ML2: delete_port on deadlock during binding\n\nThe previous logic was only catching mechanism driver exceptions so\nit would leave behind a partially built port if a deadlock was\nencountered during port binding.\n\nThe bug this closes was caused by a DBDeadlock being encountered when\na lock was attempted on the port binding record\n(get_locked_port_and_binding). This would not be caught so the API\nwould retry the whole operation with the original created port\nleft behind. This resulted in two ports assigned to the same instance.\n\nCloses-Bug: #1543880\nChange-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5\n'}]",1,278609,eb8141051abe64de7ad9398fb2adaf9a0a79d62d,49,18,3,7787,,,0,"ML2: delete_port on deadlock during binding

The previous logic was only catching mechanism driver exceptions so
it would leave behind a partially built port if a deadlock was
encountered during port binding.

The bug this closes was caused by a DBDeadlock being encountered when
a lock was attempted on the port binding record
(get_locked_port_and_binding). This would not be caught so the API
would retry the whole operation with the original created port
left behind. This resulted in two ports assigned to the same instance.

Closes-Bug: #1543880
Change-Id: I694a9d58002d72636225f99a5fb2b1ccc1cfb6e5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/278609/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/plugins/ml2/test_plugin.py', 'neutron/plugins/ml2/plugin.py']",2,9128ee9174738df2bf37c151a56e668da0f5e6ae,bug/1543880, except Exception: # we have a broad catch here because we shouldn't leave behind a # port in the event of any exception, except ml2_exc.MechanismDriverError:,25,9
openstack%2Fpython-neutronclient~master~Ia7804ab6baac674830c6834f67cfd411ebf4d14f,openstack/python-neutronclient,master,Ia7804ab6baac674830c6834f67cfd411ebf4d14f,Add code for load balancer status tree,MERGED,2016-01-07 01:15:03.000000000,2016-02-15 07:47:48.000000000,2016-01-22 19:27:34.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6951}, {'_account_id': 7448}, {'_account_id': 8410}, {'_account_id': 9526}, {'_account_id': 10477}, {'_account_id': 10980}, {'_account_id': 11628}, {'_account_id': 12999}, {'_account_id': 14605}, {'_account_id': 15226}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-01-07 01:15:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/63a0a1809e2e5c06c0b3d2cd615125ee0b8f2cf1', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nWIP.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 2, 'created': '2016-01-08 01:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a6f4f4ba15bade77e72c329db749196346afdcc6', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 3, 'created': '2016-01-11 22:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1cbbd1263fc7f68ce377c3642da0febc7e6a89f2', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 4, 'created': '2016-01-11 23:14:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4b9fe506386f4397ed4730eae27522d8ac2a130a', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 5, 'created': '2016-01-12 03:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/3563223794e5e13cc11215b99942d6469159de94', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 6, 'created': '2016-01-13 00:56:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ca8aa1623fe09f57cb97d860403277054ad477d3', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 7, 'created': '2016-01-13 00:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/eb2318906d7a91995b0b79757b8ae2e914f3bb14', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 8, 'created': '2016-01-13 01:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/fa2d37ce7f5fc51069b16ff2954e8e3877b4161c', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 9, 'created': '2016-01-13 01:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/381720fa6aae484ea8fb9c67fa824f1303b63481', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieve a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 10, 'created': '2016-01-13 22:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f1688be255125ccba436e05778da667be8e81c41', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieving a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 11, 'created': '2016-01-15 17:12:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ef81b3cbb02a0da036859676293d9c51f2445356', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieving a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 12, 'created': '2016-01-15 17:13:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/eef3720377a9f23b7f983c2c8cf6085b3aee38c1', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieving a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\n1. DocImpact Flag. IMO, this is required as we are adding a new CLI.\n2. Release notes\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 13, 'created': '2016-01-15 18:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ea3c6e57c9e1c75ef9dcee3990ac773e7a7aac0f', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieving a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nDocImpact\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}, {'number': 14, 'created': '2016-01-19 18:03:24.000000000', 'files': ['neutronclient/neutron/v2_0/lb/v2/loadbalancer.py', 'neutronclient/v2_0/client.py', 'neutronclient/shell.py', 'releasenotes/notes/add-lb-status-tree-723f23c09617de3b.yaml', 'releasenotes/source/old_relnotes.rst', 'neutronclient/tests/unit/lb/v2/test_cli20_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/a97f28f18729a55f3cdc0c7c21d6a183d6b01a1c', 'message': ""Add code for load balancer status tree\n\nSo far the feature of retrieving a specific Load Balancer's Status Tree\nis not implemented in the neutronclient code, we need to add feature\ncode and related tests.\n\nDocImpact Add loadbalancer-status-tree feature in CLI\n\nChange-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f\n""}]",69,264499,a97f28f18729a55f3cdc0c7c21d6a183d6b01a1c,57,13,14,10477,,,0,"Add code for load balancer status tree

So far the feature of retrieving a specific Load Balancer's Status Tree
is not implemented in the neutronclient code, we need to add feature
code and related tests.

DocImpact Add loadbalancer-status-tree feature in CLI

Change-Id: Ia7804ab6baac674830c6834f67cfd411ebf4d14f
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/99/264499/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/lb/v2/loadbalancer.py', 'neutronclient/v2_0/client.py', 'neutronclient/shell.py', 'neutronclient/tests/unit/lb/v2/test_cli20_loadbalancer.py']",4,63a0a1809e2e5c06c0b3d2cd615125ee0b8f2cf1,add-lb-status-tree," self.assertIn('4321', _str)"," self.assertIn('4321', _str) ",33,1
openstack%2Fneutron-fwaas~master~I645b838beb3f1385809f10132d2d8f43145d83ae,openstack/neutron-fwaas,master,I645b838beb3f1385809f10132d2d8f43145d83ae,tempest: Skips router insertion tests if public_router_id is configured,MERGED,2016-01-27 12:06:36.000000000,2016-02-15 07:44:07.000000000,2016-02-15 07:44:07.000000000,"[{'_account_id': 3}, {'_account_id': 4656}, {'_account_id': 10692}, {'_account_id': 10850}, {'_account_id': 12999}, {'_account_id': 15226}, {'_account_id': 15330}]","[{'number': 1, 'created': '2016-01-27 12:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/99038924a64b72b7652fd2c458d45e2406c0fb9b', 'message': 'tempest: Skips router insersion tests if public_router_id is configured\n\nAnd add a comment to explain why.\n\nChange-Id: I645b838beb3f1385809f10132d2d8f43145d83ae\n'}, {'number': 2, 'created': '2016-02-10 18:41:54.000000000', 'files': ['neutron_fwaas/tests/tempest_plugin/tests/scenario/test_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/29bbaaa1d8860f4df299cd50e89865f662b98a9f', 'message': 'tempest: Skips router insertion tests if public_router_id is configured\n\nAnd add a comment to explain why.\n\nChange-Id: I645b838beb3f1385809f10132d2d8f43145d83ae\n'}]",0,273006,29bbaaa1d8860f4df299cd50e89865f662b98a9f,22,7,2,6854,,,0,"tempest: Skips router insertion tests if public_router_id is configured

And add a comment to explain why.

Change-Id: I645b838beb3f1385809f10132d2d8f43145d83ae
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/06/273006/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron_fwaas/tests/tempest_plugin/tests/scenario/test_fwaas.py'],1,99038924a64b72b7652fd2c458d45e2406c0fb9b,yamt2," if self.router_insertion and CONF.network.public_router_id: # NOTE(yamamoto): If public_router_id is configured # router1 and router2 will be the same router. msg = ""This test assumes no public_router_id configured"" raise self.skipException(msg) ",,6,0
openstack%2Fnetworking-midonet~master~Ic37ee2f94cce87f4df631a67ae897d70e44efcbd,openstack/networking-midonet,master,Ic37ee2f94cce87f4df631a67ae897d70e44efcbd,Improve translation setup,MERGED,2016-01-29 07:47:45.000000000,2016-02-15 07:43:38.000000000,2016-02-15 07:43:38.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6547}, {'_account_id': 6598}, {'_account_id': 6854}, {'_account_id': 8837}]","[{'number': 1, 'created': '2016-01-29 07:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/78f7abb937946532a696fce18119a0a04e65bfb7', 'message': 'Improve translation setup\n\nhttp://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html\n\nCloses-Bug: #1539417\nChange-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd\n'}, {'number': 2, 'created': '2016-01-30 13:03:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/7040fb84244404936a7ab8abdc5d5c94cefdd784', 'message': 'Improve translation setup\n\nhttp://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html\n\nCloses-Bug: #1539417\nChange-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd\n'}, {'number': 3, 'created': '2016-02-01 04:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/8150f27a7cabddf3318acd8e1b500711f28dd829', 'message': 'Improve translation setup\n\nAs suggested in the spec, [1]\n\n- Use the domain matching the package name  (ie. ""midonet"")\n- Update setup.cfg\n\n[1] http://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html\n\nCloses-Bug: #1539417\nChange-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd\n'}, {'number': 4, 'created': '2016-02-01 07:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/2769a975cf0a4b6cb6508c3f98f3f39e4bd7ba4d', 'message': 'Improve translation setup\n\nAs suggested in the spec, [1]\n\n- Use the domain matching the package name  (ie. ""midonet"")\n- Update setup.cfg\n\n[1] http://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html\n\nCloses-Bug: #1539417\nChange-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd\n'}, {'number': 5, 'created': '2016-02-15 03:09:48.000000000', 'files': ['midonet/neutron/_i18n.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/a8c946ce631f23559ecaf6b0e656afdba7e5abe1', 'message': 'Improve translation setup\n\nAs suggested in the spec, [1]\n\n- Use the domain matching the package name  (ie. ""midonet"")\n- Update setup.cfg\n\n[1] http://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html\n\nCloses-Bug: #1539417\nChange-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd\n'}]",13,273929,a8c946ce631f23559ecaf6b0e656afdba7e5abe1,29,6,5,6854,,,0,"Improve translation setup

As suggested in the spec, [1]

- Use the domain matching the package name  (ie. ""midonet"")
- Update setup.cfg

[1] http://specs.openstack.org/openstack-infra/infra-specs/specs/translation_setup.html

Closes-Bug: #1539417
Change-Id: Ic37ee2f94cce87f4df631a67ae897d70e44efcbd
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/29/273929/4 && git format-patch -1 --stdout FETCH_HEAD,"['midonet/neutron/_i18n.py', 'setup.cfg']",2,78f7abb937946532a696fce18119a0a04e65bfb7,translation_setup,directory = networking_midonet/locale domain = networking_midonetdomain = networking_midonet output_dir = networking_midonet/locale input_file = networking_midonet/locale/networking_midonet.potoutput_file = networking_midonet/locale/networking_midonet.pot,directory = networking-midonet/locale domain = networking-midonetdomain = networking-midonet output_dir = networking-midonet/locale input_file = networking-midonet/locale/networking-midonet.potoutput_file = networking-midonet/locale/networking-midonet.pot,7,7
openstack%2Fnetworking-midonet~master~I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f,openstack/networking-midonet,master,I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f,Stop using neutron.i18n,MERGED,2016-01-25 10:30:20.000000000,2016-02-15 07:43:33.000000000,2016-02-15 07:43:32.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 6854}]","[{'number': 1, 'created': '2016-01-25 10:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/709fe7cf4d06427f1d2a3a7ed44aa71c380ad8f5', 'message': 'Stop using neutron.i18n\n\nCloses-Bug: #1522282\nChange-Id: I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f\n'}, {'number': 2, 'created': '2016-01-25 11:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/25a1199330ca12d7b572e4bef85b9382ba27d454', 'message': 'Stop using neutron.i18n\n\nCloses-Bug: #1522282\nChange-Id: I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f\n'}, {'number': 3, 'created': '2016-01-25 12:36:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/65583883cf2f7a833e74defb254b6808c1c45793', 'message': 'Stop using neutron.i18n\n\nCloses-Bug: #1522282\nChange-Id: I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f\n'}, {'number': 4, 'created': '2016-02-15 03:09:48.000000000', 'files': ['midonet/neutron/db/loadbalancer_db.py', 'midonet/neutron/db/provider_network_db.py', 'midonet/neutron/services/loadbalancer/driver.py', 'midonet/neutron/services/l3/l3_midonet.py', 'midonet/neutron/common/config.py', 'midonet/neutron/db/task_db.py', 'midonet/neutron/services/gw_device/plugin.py', 'midonet/neutron/agent/interface.py', 'midonet/neutron/services/firewall/plugin.py', 'midonet/neutron/services/l2gateway/service_drivers/l2gw_midonet.py', 'midonet/neutron/extensions/gateway_device.py', 'midonet/neutron/services/l2gateway/plugin.py', 'midonet/neutron/client/base.py', 'midonet/neutron/ml2/mech_driver.py', 'midonet/neutron/ml2/type_uplink.py', 'midonet/neutron/_i18n.py', 'midonet/neutron/services/vpn/service_drivers/midonet_ipsec.py', 'midonet/neutron/ml2/type_midonet.py', 'tox.ini', 'midonet/neutron/ml2/sg_callback.py', 'midonet/neutron/plugin_v1.py', 'midonet/neutron/plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/00a0a89e06cba74ee84b21229db4d61bc2a5175f', 'message': 'Stop using neutron.i18n\n\nCloses-Bug: #1522282\nChange-Id: I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f\n'}]",2,271997,00a0a89e06cba74ee84b21229db4d61bc2a5175f,21,4,4,6854,,,0,"Stop using neutron.i18n

Closes-Bug: #1522282
Change-Id: I40c8a06c73ab61d9e2b8f5e58f31167d00f1d44f
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/97/271997/2 && git format-patch -1 --stdout FETCH_HEAD,"['midonet/neutron/db/loadbalancer_db.py', 'midonet/neutron/db/provider_network_db.py', 'midonet/neutron/services/loadbalancer/driver.py', 'midonet/neutron/services/l3/l3_midonet.py', 'midonet/neutron/common/config.py', 'midonet/neutron/db/task_db.py', 'midonet/neutron/services/gw_device/plugin.py', 'midonet/neutron/agent/interface.py', 'midonet/neutron/services/firewall/plugin.py', 'midonet/neutron/services/l2gateway/service_drivers/l2gw_midonet.py', 'midonet/neutron/extensions/gateway_device.py', 'midonet/neutron/services/l2gateway/plugin.py', 'midonet/neutron/client/base.py', 'midonet/neutron/ml2/mech_driver.py', 'midonet/neutron/ml2/type_uplink.py', 'midonet/neutron/services/vpn/service_drivers/midonet_ipsec.py', 'midonet/neutron/ml2/type_midonet.py', 'tox.ini', 'midonet/neutron/ml2/sg_callback.py', 'midonet/neutron/plugin_v1.py', 'midonet/neutron/plugin_v2.py']",21,709fe7cf4d06427f1d2a3a7ed44aa71c380ad8f5,translation_setup,"from midonet.neutron._i18n import _LE, _LW",from neutron import i18n_LE = i18n._LE _LW = i18n._LW,29,45
openstack%2Fnetworking-midonet~master~I75d519b2f119743ddbd18274e8a914c853ddb36a,openstack/networking-midonet,master,I75d519b2f119743ddbd18274e8a914c853ddb36a,l3: Explicitly reject floating-ip association to non-compute port,MERGED,2016-01-18 07:32:21.000000000,2016-02-15 07:41:52.000000000,2016-02-15 07:41:52.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 6854}]","[{'number': 1, 'created': '2016-01-18 07:32:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/239669789e85e45b8f301b74f8d401b1fbca8868', 'message': 'l3: Explicitly reject floating-ip association to non-compute port\n\nRather than confusing a user by leaving an inconsistent state.\n(updated db, error in backend)\n\nBecause of the difference between our implementation of LBaaS and\nthe reference implementation, it would be common for a user\nto attempt to associate a floating-ip to a VIP and get into the situation.\n\nCloses-Bug: #1535211\nChange-Id: I75d519b2f119743ddbd18274e8a914c853ddb36a\n'}, {'number': 2, 'created': '2016-01-18 11:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/fb3db320ef6a0b1dd6807d0c8a4449f46b697987', 'message': 'l3: Explicitly reject floating-ip association to non-compute port\n\nRather than confusing a user by leaving an inconsistent state.\n(updated db, error in backend)\n\nBecause of the difference between our implementation of LBaaS and\nthe reference implementation, it would be common for a user\nto attempt to associate a floating-ip to a VIP and get into the situation.\n\nCloses-Bug: #1535211\nChange-Id: I75d519b2f119743ddbd18274e8a914c853ddb36a\n'}, {'number': 3, 'created': '2016-01-18 11:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/277646db8367f8e002aecdd03a8d66124bc45689', 'message': 'l3: Explicitly reject floating-ip association to non-compute port\n\nRather than confusing a user by leaving an inconsistent state.\n(updated db, error in backend)\n\nBecause of the difference between our implementation of LBaaS and\nthe reference implementation, it would be common for a user\nto attempt to associate a floating-ip to a VIP and get into the situation.\n\nCloses-Bug: #1535211\nChange-Id: I75d519b2f119743ddbd18274e8a914c853ddb36a\n'}, {'number': 4, 'created': '2016-02-15 03:34:34.000000000', 'files': ['midonet/neutron/services/l3/l3_midonet.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/54043c7e6009725ba03aa86ada8a80b63b2663db', 'message': 'l3: Explicitly reject floating-ip association to non-compute port\n\nRather than confusing a user by leaving an inconsistent state.\n(updated db, error in backend)\n\nBecause of the difference between our implementation of LBaaS and\nthe reference implementation, it would be common for a user\nto attempt to associate a floating-ip to a VIP and get into the situation.\n\nCloses-Bug: #1535211\nChange-Id: I75d519b2f119743ddbd18274e8a914c853ddb36a\n'}]",0,268904,54043c7e6009725ba03aa86ada8a80b63b2663db,19,4,4,6854,,,0,"l3: Explicitly reject floating-ip association to non-compute port

Rather than confusing a user by leaving an inconsistent state.
(updated db, error in backend)

Because of the difference between our implementation of LBaaS and
the reference implementation, it would be common for a user
to attempt to associate a floating-ip to a VIP and get into the situation.

Closes-Bug: #1535211
Change-Id: I75d519b2f119743ddbd18274e8a914c853ddb36a
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/04/268904/1 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/services/l3/l3_midonet.py'],1,239669789e85e45b8f301b74f8d401b1fbca8868,bug/1535211,"from neutron.common import exceptions as n_exc port_id = fip['port_id'] if port_id is not None: port = self._core_plugin.get_port(context, port_id) owner = port['device_owner'] if not owner.startswith(n_const.DEVICE_OWNER_COMPUTE_PREFIX): msg = _('Cannot associate floating IP to non-compute port') raise n_exc.BadRequest(resource='floatingip', msg=msg)",,8,0
openstack%2Fsahara~master~I1f6f95b2adf959bafe3655be446ea2ce373dc66e,openstack/sahara,master,I1f6f95b2adf959bafe3655be446ea2ce373dc66e,Add log messages,ABANDONED,2016-01-21 07:30:09.000000000,2016-02-15 07:37:11.000000000,,"[{'_account_id': 3}, {'_account_id': 8932}, {'_account_id': 9740}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-01-21 07:30:09.000000000', 'files': ['sahara/service/edp/resources/launch_command.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3843b94d351bc3c13d416079056791a8a456311b', 'message': 'Add log messages\n\nLOG.error messages require translations `_LE()`\nLOG.info messages require translations `_LI()`\n\nChange-Id: I1f6f95b2adf959bafe3655be446ea2ce373dc66e\n'}]",1,270638,3843b94d351bc3c13d416079056791a8a456311b,6,4,1,18777,,,0,"Add log messages

LOG.error messages require translations `_LE()`
LOG.info messages require translations `_LI()`

Change-Id: I1f6f95b2adf959bafe3655be446ea2ce373dc66e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/38/270638/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/edp/resources/launch_command.py'],1,3843b94d351bc3c13d416079056791a8a456311b,translation/log_message,"import six from sahara.i18n import _LI from sahara.i18n import _LE log.info(_LI(""Sent SIGINT to subprocess""))run_info = ""Running %s"" % ' '.join(sys.argv[1:]) log.info(_LI(run_info)) log.info(_LI(""Waiting for subprocess {pid}"").format(pid=a.pid)) log.info(_LI(""Subprocess exit status {ret}"".format(ret=ret))) msg = six.text_type(e) log.exception(_LE(""launch command failed {msg}"").format(msg))"," log.info(""Sent SIGINT to subprocess"")log.info(""Running %s"" % ' '.join(sys.argv[1:])) log.info(""Waiting for subprocess %s"" % a.pid) log.info(""Subprocess exit status %s"" % ret) log.exception(e)",11,5
openstack%2Fheat~master~Ibe6ac45d54afca6588b1b71ffa7278977d2f4d8a,openstack/heat,master,Ibe6ac45d54afca6588b1b71ffa7278977d2f4d8a,Don't query stack tags twice,MERGED,2016-02-15 04:54:12.000000000,2016-02-15 07:24:44.000000000,2016-02-15 07:24:43.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 10487}]","[{'number': 1, 'created': '2016-02-15 04:54:12.000000000', 'files': ['heat/objects/stack_tag.py', 'heat/objects/stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/39b772844dcad70ab45a12db042db4a5ee4208a6', 'message': ""Don't query stack tags twice\n\nRetrieving the field from the db object triggers the query to\nstack_tags, so we don't need to do it a second time to retrieve the list\nof tags. Instead, use the data directly.\n\nChange-Id: Ibe6ac45d54afca6588b1b71ffa7278977d2f4d8a\n""}]",0,280062,39b772844dcad70ab45a12db042db4a5ee4208a6,7,3,1,7385,,,0,"Don't query stack tags twice

Retrieving the field from the db object triggers the query to
stack_tags, so we don't need to do it a second time to retrieve the list
of tags. Instead, use the data directly.

Change-Id: Ibe6ac45d54afca6588b1b71ffa7278977d2f4d8a
",git fetch https://review.opendev.org/openstack/heat refs/changes/62/280062/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/objects/stack_tag.py', 'heat/objects/stack.py']",2,39b772844dcad70ab45a12db042db4a5ee4208a6,stack-tags-query," stack['tags'] = stack_tag.StackTagList.from_db_object( context, db_stack.get(field))"," if db_stack.get(field) is not None: stack['tags'] = stack_tag.StackTagList.get( context, db_stack['id']) else: stack['tags'] = None",7,5
openstack%2Fheat~master~I0c4adb467fba71a43b2250c1527f198de744dcf3,openstack/heat,master,I0c4adb467fba71a43b2250c1527f198de744dcf3,Fix a grammatical mistake of the example online.,MERGED,2016-02-06 09:48:57.000000000,2016-02-15 07:21:11.000000000,2016-02-15 07:21:10.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 9542}, {'_account_id': 10487}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 19955}]","[{'number': 1, 'created': '2016-02-06 09:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8630329e6151ddd7769a91a980c91bf7d152f597', 'message': "" In the standard yaml file format, a value start with '%' means to call another yaml file.\n And now yaml don't support a value define like %value%.\n For this reason,the example online can't run successfully.\n This also makes a lot of people feel confused.\n\n Closes-Bug: #1542591\n\nChange-Id: I0c4adb467fba71a43b2250c1527f198de744dcf3\n""}, {'number': 2, 'created': '2016-02-08 06:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b004b3ee6e942f69998d48e043a8c8b48184cd6c', 'message': '\n Fix the\xa0grammatical\xa0mistake of the\xa0example online\n\n Closes-Bug: #1542591\n\nChange-Id: I0c4adb467fba71a43b2250c1527f198de744dcf3\n'}, {'number': 3, 'created': '2016-02-08 06:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5be8ba6b403ac35e7410ba0424f2522583ab64a8', 'message': 'Fix the\xa0grammatical\xa0mistake of the\xa0example online.\nYaml is not support to define a value like %value%.\nFor this reason,the example online\xa0is\xa0not\xa0correct.\n\n Closes-Bug: #1542591\n\nChange-Id: I0c4adb467fba71a43b2250c1527f198de744dcf3\n'}, {'number': 4, 'created': '2016-02-09 02:03:04.000000000', 'files': ['doc/source/template_guide/hot_spec.rst'], 'web_link': 'https://opendev.org/openstack/heat/commit/39b2ea7566bcc27e1bc41a07d5165a17cee3fabb', 'message': ""Fix a\xa0grammatical\xa0mistake of the\xa0example online.\n\nYaml don't support a value define like %value%.\nFor this reason,the example online can't run successfully.\n\n\n Closes-Bug: #1542591\n\nChange-Id: I0c4adb467fba71a43b2250c1527f198de744dcf3\n""}]",0,277064,39b2ea7566bcc27e1bc41a07d5165a17cee3fabb,16,9,4,19963,,,0,"Fix a grammatical mistake of the example online.

Yaml don't support a value define like %value%.
For this reason,the example online can't run successfully.


 Closes-Bug: #1542591

Change-Id: I0c4adb467fba71a43b2250c1527f198de744dcf3
",git fetch https://review.opendev.org/openstack/heat refs/changes/64/277064/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/template_guide/hot_spec.rst'],1,8630329e6151ddd7769a91a980c91bf7d152f597,bug/1542591, <%port%>: { get_param: ports } port_range_min: <%port%> port_range_max: <%port%> <%port%>: { get_param: ports } <%protocol%>: { get_param: protocols } template: protocol: <%protocol%> port_range_min: <%port%>, %port%: { get_param: ports } port_range_min: %port% port_range_max: %port% %port%: { get_param: ports } %protocol%: { get_param: protocols } template: protocol: %protocol% port_range_min: %port%,7,7
openstack%2Fcinder~master~I7bc7c74e8b701fac351572a3bb9d934c7f67d425,openstack/cinder,master,I7bc7c74e8b701fac351572a3bb9d934c7f67d425,Log stack trace for middleware faults,MERGED,2016-02-09 16:58:54.000000000,2016-02-15 07:16:34.000000000,2016-02-15 07:16:34.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-02-09 16:58:54.000000000', 'files': ['cinder/api/middleware/fault.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ccdfd0448b3f97d8fe533472f09274703c7e650f', 'message': 'Log stack trace for middleware faults\n\nIf an error occurs in the middleware layer,\nsuch as an exception generated by keystoneclient,\nthere is no stack trace provided, leaving the\nissue difficult to debug.\n\nLog a stack trace here with LOG.exception instead.\n\nChange-Id: I7bc7c74e8b701fac351572a3bb9d934c7f67d425\n'}]",0,277963,ccdfd0448b3f97d8fe533472f09274703c7e650f,40,5,1,4523,,,0,"Log stack trace for middleware faults

If an error occurs in the middleware layer,
such as an exception generated by keystoneclient,
there is no stack trace provided, leaving the
issue difficult to debug.

Log a stack trace here with LOG.exception instead.

Change-Id: I7bc7c74e8b701fac351572a3bb9d934c7f67d425
",git fetch https://review.opendev.org/openstack/cinder refs/changes/63/277963/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/middleware/fault.py'],1,ccdfd0448b3f97d8fe533472f09274703c7e650f,," LOG.exception(_LE(""Caught error: %(type)s %(error)s""), {'type': type(inner), 'error': inner})"," LOG.error(_LE(""Caught error: %(type)s %(error)s""), {'type': type(inner), 'error': inner})",3,3
openstack%2Fproject-config~master~I487b7e1236d993db09b4eb038e2ae8c87d287a32,openstack/project-config,master,I487b7e1236d993db09b4eb038e2ae8c87d287a32,Use pep8 instead of linters for kolla*,MERGED,2016-02-10 20:46:45.000000000,2016-02-15 07:09:48.000000000,2016-02-15 07:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-10 20:46:45.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1f8796fb7973cbb26835a283ec18afd2c428920f', 'message': 'Use pep8 instead of linters for kolla*\n\nReplace linters template with normal python-jobs template to use\npep8 instead of linters since pep8 is the standard style check interface\naccording to the PTI.\n\nChange-Id: I487b7e1236d993db09b4eb038e2ae8c87d287a32\nDepends-On: I1a48f4b1e0b0950640192bcfc55121619a844b50\nDepends-On: Ie7f5166bfd867a8c2e68c67920b6b3cf425525ee\n'}]",0,278622,1f8796fb7973cbb26835a283ec18afd2c428920f,8,4,1,6547,,,0,"Use pep8 instead of linters for kolla*

Replace linters template with normal python-jobs template to use
pep8 instead of linters since pep8 is the standard style check interface
according to the PTI.

Change-Id: I487b7e1236d993db09b4eb038e2ae8c87d287a32
Depends-On: I1a48f4b1e0b0950640192bcfc55121619a844b50
Depends-On: Ie7f5166bfd867a8c2e68c67920b6b3cf425525ee
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/278622/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1f8796fb7973cbb26835a283ec18afd2c428920f,pti-pep8-linters, - name: python-jobs - name: python-jobs, - name: python-jobs-linters - name: python-jobs-linters,2,2
openstack%2Fpython-cinderclient~master~I767710bda3b7c358c6525c9a9f074010084e411d,openstack/python-cinderclient,master,I767710bda3b7c358c6525c9a9f074010084e411d,"Allow  ""cinder backup-delete"" to delete multiple backups in one request",MERGED,2016-02-09 15:46:19.000000000,2016-02-15 07:05:43.000000000,2016-02-14 16:59:58.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 4523}, {'_account_id': 10068}, {'_account_id': 11904}, {'_account_id': 14305}, {'_account_id': 14365}, {'_account_id': 16308}]","[{'number': 1, 'created': '2016-02-09 15:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0ddfb9fc3ce2b7111d5b69e9e6452a9aa82deba8', 'message': 'Allow  ""cinder backup-delete"" to delete multiple backups in one request\n\nWhile ""cinder snapshot-delete"" and ""cinder delete"" allow multiple resources to be deleted in a single command, ""cinder backup-delete"" request can only delete one backup at a time. Adding this capability to backups in cinderclient. Enables ""cinder backup-delete"" to delete multiple backups in a single command.\n\nWith this change the command can be run as below:\n\ncinder backup-delete <backup> [<backup>...]\n\nDocImpact\nCloses-Bug: #1543056\nImplements: blueprint cli-backup-multiple-deletes\n\nChange-Id: I767710bda3b7c358c6525c9a9f074010084e411d\n'}, {'number': 2, 'created': '2016-02-11 10:38:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b7fd11bfdb2f584f31203c5db4e912bf7387f199', 'message': 'Allow  ""cinder backup-delete"" to delete multiple backups in one request\n\nWhile ""cinder snapshot-delete"" and ""cinder delete"" allow multiple resources to be deleted in a single command, ""cinder backup-delete"" request can only delete one backup at a time. Adding this capability to backups in cinderclient. Enables ""cinder backup-delete"" to delete multiple backups in a single command.\n\nWith this change the command can be run as below:\n\ncinder backup-delete <backup> [<backup>...]\n\nDocImpact\nCloses-Bug: #1543056\nImplements: blueprint cli-backup-multiple-deletes\n\nChange-Id: I767710bda3b7c358c6525c9a9f074010084e411d\n'}, {'number': 3, 'created': '2016-02-11 10:40:10.000000000', 'files': ['cinderclient/tests/unit/v2/fakes.py', 'cinderclient/tests/unit/v2/test_shell.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a3dca1599f1fe7add715a4d78318a7583941cd26', 'message': 'Allow  ""cinder backup-delete"" to delete multiple backups in one request\n\nWhile ""cinder snapshot-delete"" and ""cinder delete"" allow multiple resources to be deleted in a single command, ""cinder backup-delete"" request can only delete one backup at a time. Adding this capability to backups in cinderclient. Enables ""cinder backup-delete"" to delete multiple backups in a single command.\n\nWith this change the command can be run as below:\n\ncinder backup-delete <backup> [<backup>...]\n\nDocImpact\nCloses-Bug: #1543056\nImplements: blueprint cli-backup-multiple-deletes\n\nChange-Id: I767710bda3b7c358c6525c9a9f074010084e411d\n'}]",4,277895,a3dca1599f1fe7add715a4d78318a7583941cd26,15,8,3,14365,,,0,"Allow  ""cinder backup-delete"" to delete multiple backups in one request

While ""cinder snapshot-delete"" and ""cinder delete"" allow multiple resources to be deleted in a single command, ""cinder backup-delete"" request can only delete one backup at a time. Adding this capability to backups in cinderclient. Enables ""cinder backup-delete"" to delete multiple backups in a single command.

With this change the command can be run as below:

cinder backup-delete <backup> [<backup>...]

DocImpact
Closes-Bug: #1543056
Implements: blueprint cli-backup-multiple-deletes

Change-Id: I767710bda3b7c358c6525c9a9f074010084e411d
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/95/277895/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/unit/v2/fakes.py', 'cinderclient/tests/unit/v2/test_shell.py', 'cinderclient/v2/shell.py']",3,0ddfb9fc3ce2b7111d5b69e9e6452a9aa82deba8,bug/1543056,"@utils.arg('backup', metavar='<backup>', nargs='+', help='Name or ID of backup(s) to delete.') """"""Removes one or more backups."""""" failure_count = 0 for backup in args.backup: try: _find_backup(cs, backup).delete() except Exception as e: failure_count += 1 print(""Delete for backup %s failed: %s"" % (backup, e)) if failure_count == len(args.backup): raise exceptions.CommandError(""Unable to delete any of the specified "" ""backups."")","@utils.arg('backup', metavar='<backup>', help='Name or ID of backup to delete.') """"""Removes a backup."""""" backup = _find_backup(cs, args.backup) backup.delete()",24,5
openstack%2Fsecurity-doc~master~I7d2d7c615f868a43f403d251361878ac8dd6c813,openstack/security-doc,master,I7d2d7c615f868a43f403d251361878ac8dd6c813,Updated from openstack-manuals,MERGED,2016-02-14 18:27:23.000000000,2016-02-15 07:04:55.000000000,2016-02-15 07:04:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-14 18:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/64bbc57af0e72fdf41c93c37a8fe84aff0a72ba1', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7d2d7c615f868a43f403d251361878ac8dd6c813\n'}, {'number': 2, 'created': '2016-02-14 22:25:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/fc1cc145510ceb59e7fe62716f3288e9e36b5128', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7d2d7c615f868a43f403d251361878ac8dd6c813\n'}, {'number': 3, 'created': '2016-02-15 06:45:04.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/13ae71ac811f24a4af59970494075ee0604ab28b', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7d2d7c615f868a43f403d251361878ac8dd6c813\n'}]",0,280012,13ae71ac811f24a4af59970494075ee0604ab28b,14,3,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I7d2d7c615f868a43f403d251361878ac8dd6c813
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/12/280012/1 && git format-patch -1 --stdout FETCH_HEAD,"['common-rst/source/locale/ja/LC_MESSAGES/common.po', 'common-rst/glossary.rst', 'common-rst/conventions.rst', 'common-rst/app_support.rst']",4,64bbc57af0e72fdf41c93c37a8fe84aff0a72ba1,openstack/openstack-manuals,".. ## WARNING ########################################################## .. This file is synced from openstack/openstack-manuals repository to .. other related repositories. If you need to make changes to this file, .. make the changes in openstack-manuals. After any change merged to, .. openstack-manuals, automatically a patch for others will be proposed. .. ##################################################################### ================= Community support ================= The following resources are available to help you run and use OpenStack. The OpenStack community constantly improves and adds to the main features of OpenStack, but if you have any questions, do not hesitate to ask. Use the following resources to get OpenStack support, and troubleshoot your installations. Documentation ~~~~~~~~~~~~~ For the available OpenStack documentation, see `docs.openstack.org <http://docs.openstack.org>`__. To provide feedback on documentation, join and use the openstack-docs@lists.openstack.org mailing list at `OpenStack Documentation Mailing List <http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs>`__, or `report a bug <https://bugs.launchpad.net/openstack-manuals/+filebug>`__. The following books explain how to install an OpenStack cloud and its associated components: * `Installation Guide for openSUSE 13.2 and SUSE Linux Enterprise Server 12 <http://docs.openstack.org/liberty/install-guide-obs/>`__ * `Installation Guide for Red Hat Enterprise Linux 7 and CentOS 7 <http://docs.openstack.org/liberty/install-guide-rdo/>`__ * `Installation Guide for Ubuntu 14.04 <http://docs.openstack.org/liberty/install-guide-ubuntu/>`__ The following books explain how to configure and run an OpenStack cloud: * `Architecture Design Guide <http://docs.openstack.org/arch-design/>`__ * `Cloud Administrator Guide <http://docs.openstack.org/admin-guide-cloud/>`__ * `Configuration Reference <http://docs.openstack.org/liberty/config-reference/content/>`__ * `Operations Guide <http://docs.openstack.org/ops/>`__ * `Networking Guide <http://docs.openstack.org/liberty/networking-guide>`__ * `High Availability Guide <http://docs.openstack.org/ha-guide/>`__ * `Security Guide <http://docs.openstack.org/sec/>`__ * `Virtual Machine Image Guide <http://docs.openstack.org/image-guide/>`__ The following books explain how to use the OpenStack dashboard and command-line clients: * `API Guide <http://developer.openstack.org/api-guide/quick-start/>`__ * `End User Guide <http://docs.openstack.org/user-guide/>`__ * `Admin User Guide <http://docs.openstack.org/user-guide-admin/>`__ * `Command-Line Interface Reference <http://docs.openstack.org/cli-reference/>`__ The following documentation provides reference and guidance information for the OpenStack APIs: * `OpenStack API Complete Reference (HTML) <http://developer.openstack.org/api-ref.html>`__ * `API Complete Reference (PDF) <http://developer.openstack.org/api-ref-guides/bk-api-ref.pdf>`__ The following guide provides how to contribute to OpenStack documentation: * `Documentation contributor guide <http://docs.openstack.org/contributor-guide/>`__ ask.openstack.org ~~~~~~~~~~~~~~~~~ During the set up or testing of OpenStack, you might have questions about how a specific task is completed or be in a situation where a feature does not work correctly. Use the `ask.openstack.org <https://ask.openstack.org>`__ site to ask questions and get answers. When you visit the https://ask.openstack.org site, scan the recently asked questions to see whether your question has already been answered. If not, ask a new question. Be sure to give a clear, concise summary in the title and provide as much detail as possible in the description. Paste in your command output or stack traces, links to screen shots, and any other information which might be useful. OpenStack mailing lists ~~~~~~~~~~~~~~~~~~~~~~~ A great way to get answers and insights is to post your question or problematic scenario to the OpenStack mailing list. You can learn from and help others who might have similar issues. To subscribe or view the archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack. You might be interested in the other mailing lists for specific projects or development, which you can find `on the wiki <https://wiki.openstack.org/wiki/MailingLists>`__. A description of all mailing lists is available at https://wiki.openstack.org/wiki/MailingLists. The OpenStack wiki ~~~~~~~~~~~~~~~~~~ The `OpenStack wiki <https://wiki.openstack.org/>`__ contains a broad range of topics but some of the information can be difficult to find or is a few pages deep. Fortunately, the wiki search feature enables you to search by title or content. If you search for specific information, such as about networking or OpenStack Compute, you can find a large amount of relevant material. More is being added all the time, so be sure to check back often. You can find the search box in the upper-right corner of any OpenStack wiki page. The Launchpad Bugs area ~~~~~~~~~~~~~~~~~~~~~~~ The OpenStack community values your set up and testing efforts and wants your feedback. To log a bug, you must sign up for a Launchpad account at https://launchpad.net/+login. You can view existing bugs and report bugs in the Launchpad Bugs area. Use the search feature to determine whether the bug has already been reported or already been fixed. If it still seems like your bug is unreported, fill out a bug report. Some tips: * Give a clear, concise summary. * Provide as much detail as possible in the description. Paste in your command output or stack traces, links to screen shots, and any other information which might be useful. * Be sure to include the software and package versions that you are using, especially if you are using a development branch, such as, ``""Kilo release"" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208``. * Any deployment-specific information is helpful, such as whether you are using Ubuntu 14.04 or are performing a multi-node installation. The following Launchpad Bugs areas are available: * `Bugs: OpenStack Block Storage (cinder) <https://bugs.launchpad.net/cinder>`__ * `Bugs: OpenStack Compute (nova) <https://bugs.launchpad.net/nova>`__ * `Bugs: OpenStack Dashboard (horizon) <https://bugs.launchpad.net/horizon>`__ * `Bugs: OpenStack Identity (keystone) <https://bugs.launchpad.net/keystone>`__ * `Bugs: OpenStack Image service (glance) <https://bugs.launchpad.net/glance>`__ * `Bugs: OpenStack Networking (neutron) <https://bugs.launchpad.net/neutron>`__ * `Bugs: OpenStack Object Storage (swift) <https://bugs.launchpad.net/swift>`__ * `Bugs: Application catalog (murano) <https://bugs.launchpad.net/murano>`__ * `Bugs: Bare metal service (ironic) <https://bugs.launchpad.net/ironic>`__ * `Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__ * `Bugs: Containers service (magnum) <https://bugs.launchpad.net/magnum>`__ * `Bugs: Data processing service (sahara) <https://bugs.launchpad.net/sahara>`__ * `Bugs: Database service (trove) <https://bugs.launchpad.net/trove>`__ * `Bugs: Deployment service (fuel) <https://bugs.launchpad.net/fuel>`__ * `Bugs: DNS service (designate) <https://bugs.launchpad.net/designate>`__ * `Bugs: Key Manager Service (barbican) <https://bugs.launchpad.net/barbican>`__ * `Bugs: Monitoring (monasca) <https://bugs.launchpad.net/monasca>`__ * `Bugs: Orchestration (heat) <https://bugs.launchpad.net/heat>`__ * `Bugs: Rating (cloudkitty) <https://bugs.launchpad.net/cloudkitty>`__ * `Bugs: Shared file systems (manila) <https://bugs.launchpad.net/manila>`__ * `Bugs: Telemetry (ceilometer) <https://bugs.launchpad.net/ceilometer>`__ * `Bugs: Telemetry v3 (gnocchi) <https://bugs.launchpad.net/gnocchi>`__ * `Bugs: Workflow service (mistral) <https://bugs.launchpad.net/mistral>`__ * `Bugs: Messaging service (zaqar) <https://bugs.launchpad.net/zaqar>`__ * `Bugs: OpenStack API Documentation (developer.openstack.org) <https://bugs.launchpad.net/openstack-api-site>`__ * `Bugs: OpenStack Documentation (docs.openstack.org) <https://bugs.launchpad.net/openstack-manuals>`__ The OpenStack IRC channel ~~~~~~~~~~~~~~~~~~~~~~~~~ The OpenStack community lives in the #openstack IRC channel on the Freenode network. You can hang out, ask questions, or get immediate feedback for urgent and pressing issues. To install an IRC client or use a browser-based client, go to `https://webchat.freenode.net/ <https://webchat.freenode.net>`__. You can also use Colloquy (Mac OS X, http://colloquy.info/), mIRC (Windows, http://www.mirc.com/), or XChat (Linux). When you are in the IRC channel and want to share code or command output, the generally accepted method is to use a Paste Bin. The OpenStack project has one at http://paste.openstack.org. Just paste your longer amounts of text or logs in the web form and you get a URL that you can paste into the channel. The OpenStack IRC channel is ``#openstack`` on ``irc.freenode.net``. You can find a list of all OpenStack IRC channels at https://wiki.openstack.org/wiki/IRC. Documentation feedback ~~~~~~~~~~~~~~~~~~~~~~ To provide feedback on documentation, join and use the openstack-docs@lists.openstack.org mailing list at `OpenStack Documentation Mailing List <http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs>`__, or `report a bug <https://bugs.launchpad.net/openstack-manuals/+filebug>`__. OpenStack distribution packages ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The following Linux distributions provide community-supported packages for OpenStack: * **Debian:** https://wiki.debian.org/OpenStack * **CentOS, Fedora, and Red Hat Enterprise Linux:** https://www.rdoproject.org/ * **openSUSE and SUSE Linux Enterprise Server:** https://en.opensuse.org/Portal:OpenStack * **Ubuntu:** https://wiki.ubuntu.com/ServerTeam/CloudArchive ",,15430,0
openstack%2Fapi-site~master~I3f67692768685a0c2e2d3222b6ebf022e1471b08,openstack/api-site,master,I3f67692768685a0c2e2d3222b6ebf022e1471b08,Updated from openstack-manuals,MERGED,2016-02-14 18:27:15.000000000,2016-02-15 07:04:35.000000000,2016-02-15 07:04:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-14 18:27:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/8fb8295ecf01bdc29a2833067d36eab210f3cc8b', 'message': 'Updated from openstack-manuals\n\nChange-Id: I3f67692768685a0c2e2d3222b6ebf022e1471b08\n'}, {'number': 2, 'created': '2016-02-14 22:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/821feddfcaa55ab0c8a169440688f28ee88cc182', 'message': 'Updated from openstack-manuals\n\nChange-Id: I3f67692768685a0c2e2d3222b6ebf022e1471b08\n'}, {'number': 3, 'created': '2016-02-15 06:44:55.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/cb3c2309b87e87853ac236031d166a3b52c48238', 'message': 'Updated from openstack-manuals\n\nChange-Id: I3f67692768685a0c2e2d3222b6ebf022e1471b08\n'}]",0,280010,cb3c2309b87e87853ac236031d166a3b52c48238,14,3,3,11131,,,0,"Updated from openstack-manuals

Change-Id: I3f67692768685a0c2e2d3222b6ebf022e1471b08
",git fetch https://review.opendev.org/openstack/api-site refs/changes/10/280010/1 && git format-patch -1 --stdout FETCH_HEAD,"['common-rst/source/locale/ja/LC_MESSAGES/common.po', 'common-rst/glossary.rst', 'common-rst/conventions.rst', 'common-rst/app_support.rst']",4,8fb8295ecf01bdc29a2833067d36eab210f3cc8b,openstack/openstack-manuals,".. ## WARNING ########################################################## .. This file is synced from openstack/openstack-manuals repository to .. other related repositories. If you need to make changes to this file, .. make the changes in openstack-manuals. After any change merged to, .. openstack-manuals, automatically a patch for others will be proposed. .. ##################################################################### ================= Community support ================= The following resources are available to help you run and use OpenStack. The OpenStack community constantly improves and adds to the main features of OpenStack, but if you have any questions, do not hesitate to ask. Use the following resources to get OpenStack support, and troubleshoot your installations. Documentation ~~~~~~~~~~~~~ For the available OpenStack documentation, see `docs.openstack.org <http://docs.openstack.org>`__. To provide feedback on documentation, join and use the openstack-docs@lists.openstack.org mailing list at `OpenStack Documentation Mailing List <http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs>`__, or `report a bug <https://bugs.launchpad.net/openstack-manuals/+filebug>`__. The following books explain how to install an OpenStack cloud and its associated components: * `Installation Guide for openSUSE 13.2 and SUSE Linux Enterprise Server 12 <http://docs.openstack.org/liberty/install-guide-obs/>`__ * `Installation Guide for Red Hat Enterprise Linux 7 and CentOS 7 <http://docs.openstack.org/liberty/install-guide-rdo/>`__ * `Installation Guide for Ubuntu 14.04 <http://docs.openstack.org/liberty/install-guide-ubuntu/>`__ The following books explain how to configure and run an OpenStack cloud: * `Architecture Design Guide <http://docs.openstack.org/arch-design/>`__ * `Cloud Administrator Guide <http://docs.openstack.org/admin-guide-cloud/>`__ * `Configuration Reference <http://docs.openstack.org/liberty/config-reference/content/>`__ * `Operations Guide <http://docs.openstack.org/ops/>`__ * `Networking Guide <http://docs.openstack.org/liberty/networking-guide>`__ * `High Availability Guide <http://docs.openstack.org/ha-guide/>`__ * `Security Guide <http://docs.openstack.org/sec/>`__ * `Virtual Machine Image Guide <http://docs.openstack.org/image-guide/>`__ The following books explain how to use the OpenStack dashboard and command-line clients: * `API Guide <http://developer.openstack.org/api-guide/quick-start/>`__ * `End User Guide <http://docs.openstack.org/user-guide/>`__ * `Admin User Guide <http://docs.openstack.org/user-guide-admin/>`__ * `Command-Line Interface Reference <http://docs.openstack.org/cli-reference/>`__ The following documentation provides reference and guidance information for the OpenStack APIs: * `OpenStack API Complete Reference (HTML) <http://developer.openstack.org/api-ref.html>`__ * `API Complete Reference (PDF) <http://developer.openstack.org/api-ref-guides/bk-api-ref.pdf>`__ The following guide provides how to contribute to OpenStack documentation: * `Documentation contributor guide <http://docs.openstack.org/contributor-guide/>`__ ask.openstack.org ~~~~~~~~~~~~~~~~~ During the set up or testing of OpenStack, you might have questions about how a specific task is completed or be in a situation where a feature does not work correctly. Use the `ask.openstack.org <https://ask.openstack.org>`__ site to ask questions and get answers. When you visit the https://ask.openstack.org site, scan the recently asked questions to see whether your question has already been answered. If not, ask a new question. Be sure to give a clear, concise summary in the title and provide as much detail as possible in the description. Paste in your command output or stack traces, links to screen shots, and any other information which might be useful. OpenStack mailing lists ~~~~~~~~~~~~~~~~~~~~~~~ A great way to get answers and insights is to post your question or problematic scenario to the OpenStack mailing list. You can learn from and help others who might have similar issues. To subscribe or view the archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack. You might be interested in the other mailing lists for specific projects or development, which you can find `on the wiki <https://wiki.openstack.org/wiki/MailingLists>`__. A description of all mailing lists is available at https://wiki.openstack.org/wiki/MailingLists. The OpenStack wiki ~~~~~~~~~~~~~~~~~~ The `OpenStack wiki <https://wiki.openstack.org/>`__ contains a broad range of topics but some of the information can be difficult to find or is a few pages deep. Fortunately, the wiki search feature enables you to search by title or content. If you search for specific information, such as about networking or OpenStack Compute, you can find a large amount of relevant material. More is being added all the time, so be sure to check back often. You can find the search box in the upper-right corner of any OpenStack wiki page. The Launchpad Bugs area ~~~~~~~~~~~~~~~~~~~~~~~ The OpenStack community values your set up and testing efforts and wants your feedback. To log a bug, you must sign up for a Launchpad account at https://launchpad.net/+login. You can view existing bugs and report bugs in the Launchpad Bugs area. Use the search feature to determine whether the bug has already been reported or already been fixed. If it still seems like your bug is unreported, fill out a bug report. Some tips: * Give a clear, concise summary. * Provide as much detail as possible in the description. Paste in your command output or stack traces, links to screen shots, and any other information which might be useful. * Be sure to include the software and package versions that you are using, especially if you are using a development branch, such as, ``""Kilo release"" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208``. * Any deployment-specific information is helpful, such as whether you are using Ubuntu 14.04 or are performing a multi-node installation. The following Launchpad Bugs areas are available: * `Bugs: OpenStack Block Storage (cinder) <https://bugs.launchpad.net/cinder>`__ * `Bugs: OpenStack Compute (nova) <https://bugs.launchpad.net/nova>`__ * `Bugs: OpenStack Dashboard (horizon) <https://bugs.launchpad.net/horizon>`__ * `Bugs: OpenStack Identity (keystone) <https://bugs.launchpad.net/keystone>`__ * `Bugs: OpenStack Image service (glance) <https://bugs.launchpad.net/glance>`__ * `Bugs: OpenStack Networking (neutron) <https://bugs.launchpad.net/neutron>`__ * `Bugs: OpenStack Object Storage (swift) <https://bugs.launchpad.net/swift>`__ * `Bugs: Application catalog (murano) <https://bugs.launchpad.net/murano>`__ * `Bugs: Bare metal service (ironic) <https://bugs.launchpad.net/ironic>`__ * `Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__ * `Bugs: Containers service (magnum) <https://bugs.launchpad.net/magnum>`__ * `Bugs: Data processing service (sahara) <https://bugs.launchpad.net/sahara>`__ * `Bugs: Database service (trove) <https://bugs.launchpad.net/trove>`__ * `Bugs: Deployment service (fuel) <https://bugs.launchpad.net/fuel>`__ * `Bugs: DNS service (designate) <https://bugs.launchpad.net/designate>`__ * `Bugs: Key Manager Service (barbican) <https://bugs.launchpad.net/barbican>`__ * `Bugs: Monitoring (monasca) <https://bugs.launchpad.net/monasca>`__ * `Bugs: Orchestration (heat) <https://bugs.launchpad.net/heat>`__ * `Bugs: Rating (cloudkitty) <https://bugs.launchpad.net/cloudkitty>`__ * `Bugs: Shared file systems (manila) <https://bugs.launchpad.net/manila>`__ * `Bugs: Telemetry (ceilometer) <https://bugs.launchpad.net/ceilometer>`__ * `Bugs: Telemetry v3 (gnocchi) <https://bugs.launchpad.net/gnocchi>`__ * `Bugs: Workflow service (mistral) <https://bugs.launchpad.net/mistral>`__ * `Bugs: Messaging service (zaqar) <https://bugs.launchpad.net/zaqar>`__ * `Bugs: OpenStack API Documentation (developer.openstack.org) <https://bugs.launchpad.net/openstack-api-site>`__ * `Bugs: OpenStack Documentation (docs.openstack.org) <https://bugs.launchpad.net/openstack-manuals>`__ The OpenStack IRC channel ~~~~~~~~~~~~~~~~~~~~~~~~~ The OpenStack community lives in the #openstack IRC channel on the Freenode network. You can hang out, ask questions, or get immediate feedback for urgent and pressing issues. To install an IRC client or use a browser-based client, go to `https://webchat.freenode.net/ <https://webchat.freenode.net>`__. You can also use Colloquy (Mac OS X, http://colloquy.info/), mIRC (Windows, http://www.mirc.com/), or XChat (Linux). When you are in the IRC channel and want to share code or command output, the generally accepted method is to use a Paste Bin. The OpenStack project has one at http://paste.openstack.org. Just paste your longer amounts of text or logs in the web form and you get a URL that you can paste into the channel. The OpenStack IRC channel is ``#openstack`` on ``irc.freenode.net``. You can find a list of all OpenStack IRC channels at https://wiki.openstack.org/wiki/IRC. Documentation feedback ~~~~~~~~~~~~~~~~~~~~~~ To provide feedback on documentation, join and use the openstack-docs@lists.openstack.org mailing list at `OpenStack Documentation Mailing List <http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs>`__, or `report a bug <https://bugs.launchpad.net/openstack-manuals/+filebug>`__. OpenStack distribution packages ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ The following Linux distributions provide community-supported packages for OpenStack: * **Debian:** https://wiki.debian.org/OpenStack * **CentOS, Fedora, and Red Hat Enterprise Linux:** https://www.rdoproject.org/ * **openSUSE and SUSE Linux Enterprise Server:** https://en.opensuse.org/Portal:OpenStack * **Ubuntu:** https://wiki.ubuntu.com/ServerTeam/CloudArchive ",,15430,0
openstack%2Fsahara-image-elements~master~Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b,openstack/sahara-image-elements,master,Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b,Added support of Spark 1.6.0,MERGED,2016-02-05 13:07:35.000000000,2016-02-15 06:50:34.000000000,2016-02-15 06:50:34.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}]","[{'number': 1, 'created': '2016-02-05 13:07:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/f6c7e71270ea73928d8a5710063a4730a955b08b', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment\nbp: support-spark-160\n\nChange-Id: Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b\n'}, {'number': 2, 'created': '2016-02-05 13:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/e3dc3578bc35da3af38c6a51629a8f0350031762', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment\nDepends-on: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nbp: support-spark-160\n\nChange-Id: Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b\n'}, {'number': 3, 'created': '2016-02-08 09:50:20.000000000', 'files': ['diskimage-create/README.rst', 'diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/3626fb6429c3459d6d54b19af24b60acdcabe6ee', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment.\nchanges:\n* using spark 1.6.0 version as default version for spark plugin\n* using hadoop 2.6 for spark 1.6.0 (by setting up\n  DIB_CDH_VERSION=""5.4"")\n* we use only HDFS part of CDH for Spark plugin so we don\'t need to\n  create symbolic links for oozie\n\nDepends-on: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nbp: support-spark-160\n\nChange-Id: Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b\n'}]",0,276716,3626fb6429c3459d6d54b19af24b60acdcabe6ee,34,6,3,19372,,,0,"Added support of Spark 1.6.0

Spark 1.6.0 is available now for deployment.
changes:
* using spark 1.6.0 version as default version for spark plugin
* using hadoop 2.6 for spark 1.6.0 (by setting up
  DIB_CDH_VERSION=""5.4"")
* we use only HDFS part of CDH for Spark plugin so we don't need to
  create symbolic links for oozie

Depends-on: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be
bp: support-spark-160

Change-Id: Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/16/276716/3 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage-create/diskimage-create.sh', 'elements/hadoop-cloudera/install.d/50-install-cloudera']",2,f6c7e71270ea73928d8a5710063a4730a955b08b,bp/support-spark-160," if [ -z ""${DIB_CDH_HDFS_ONLY:-}"" ]; then # Create links to keep backward version support. ln -s /usr/lib/oozie/oozie-sharelib-yarn /usr/lib/oozie/oozie-sharelib-yarn.tar.gz ln -s /usr/lib/oozie/oozie-sharelib-mr1 /usr/lib/oozie/oozie-sharelib-mr1.tar.gz ln -s /usr/lib/oozie/oozie-sharelib-yarn.tar.gz /usr/lib/oozie/oozie-sharelib.tar.gz fi", # Create links to keep backward version support. ln -s /usr/lib/oozie/oozie-sharelib-yarn /usr/lib/oozie/oozie-sharelib-yarn.tar.gz ln -s /usr/lib/oozie/oozie-sharelib-mr1 /usr/lib/oozie/oozie-sharelib-mr1.tar.gz ln -s /usr/lib/oozie/oozie-sharelib-yarn.tar.gz /usr/lib/oozie/oozie-sharelib.tar.gz,10,5
openstack%2Fopenstack-manuals~stable%2Fliberty~I60cb825560f908d2d9a9ba5c70ced5375b80d1d0,openstack/openstack-manuals,stable/liberty,I60cb825560f908d2d9a9ba5c70ced5375b80d1d0,Imported Translations from Zanata,MERGED,2016-02-15 06:12:17.000000000,2016-02-15 06:43:18.000000000,2016-02-15 06:43:17.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-15 06:12:17.000000000', 'files': ['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/929b947b9b6a73bd4daf94b147d2f2454c2dca75', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I60cb825560f908d2d9a9ba5c70ced5375b80d1d0\n'}]",0,280075,929b947b9b6a73bd4daf94b147d2f2454c2dca75,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I60cb825560f908d2d9a9ba5c70ced5375b80d1d0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/75/280075/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'],1,929b947b9b6a73bd4daf94b147d2f2454c2dca75,zanata/translations,"""PO-Revision-Date: 2016-02-15 12:15+0000\n""msgid """" ""Choose one of the following networking options to configure services "" ""specific to it. Afterwards, return here and proceed to :ref:`neutron-"" ""controller-metadata-agent`."" msgstr """" ""Choisir une des options réseau suivantes pour configurer les services qui "" ""lui sont spécifiques. Ensuite, revenir ici et poursuivre à :ref:`neutron-"" ""controller-metadata-agent`."" msgid ""Configure the metadata agent"" msgstr ""Configurer l'agent metadata"" ""Edit the ``/etc/nova/nova.conf`` file and perform the following actions:"" msgstr """" ""Éditer le fichier ``/etc/nova/nova.conf`` et effectuer les modifications "" ""suivantes:"" msgid """"msgid ""In the ``[DEFAULT]`` section, configure access parameters:"" msgstr ""Dans la section ``[DEFAULT]``, configurer les paramètres d'accès:"" msgid ""In the ``[DEFAULT]`` section, configure the metadata host:"" msgstr ""Dans la section ``[DEFAULT]``, configurer le host metadata:"" msgid """" ""In the ``[DEFAULT]`` section, configure the metadata proxy shared secret:"" msgstr """" ""Dans la section ``[DEFAULT]``, configurer le secret partagé du proxy "" ""metadata:"" msgid """" ""In the ``[neutron]`` section, configure access parameters, enable the "" ""metadata proxy, and configure the secret:"" msgstr """" ""Dans la section ``[neutron]``, configurer les paramètres d'accès, activer le "" ""proxy metadata, et configurer le secret:"" msgid """" ""Option 1 deploys the simplest possible architecture that only supports "" ""attaching instances to public (provider) networks. No self-service networks, "" ""routers, or floating IP addresses. Only the ``admin`` or other privileged "" ""user can manage provider networks."" msgstr """" ""L'option 1 déploie l'architecture la plus simple possible qui supporte "" ""uniquement d'attacher les instances en direct aux réseaux (fournisseurs) "" ""publics. Pas de réseaux libre-service, routeurs, ou adresses IP flottantes. "" ""Seul l'utilisateur ``admin`` ou tout autre utilisateur à privilège peut "" ""gérer les réseaux fournisseurs."" msgid """" ""Option 2 also supports attaching instances to public (provider) networks."" msgstr """" ""L'option 2 supporte également le rattachement d'instances aux réseaux "" ""(fournisseurs) publics."" msgid """" ""Option 2 augments option 1 with layer-3 services that support attaching "" ""instances to self-service (private) networks. The ``demo`` or other "" ""unprivileged user can manage self-service networks including routers that "" ""provide connectivity between self-service and provider networks. "" ""Additionally, floating IP addresses provide connectivity to instances using "" ""self-service networks from external networks such as the Internet."" msgstr """" ""L'option 2 ajoute à l'option 1 des services de couche-3 qui supporte "" ""l'attachement des instances à des réseaux (privés) libre-service. "" ""L'utilisateur ``demo`` ou tout autre utilisateur sans privilège peut gérer "" ""des réseaux libre-service incluant les routeurs qui fournissent la "" ""connectivité entre les réseaux self-service et fournisseur. De plus, des "" ""adresses IP flottantes fournissent la connectivité aux instances utilisant "" ""les réseaux libre-service à partir de réseaux externes comme Internet."" ""Replace ``METADATA_SECRET`` with a suitable secret for the metadata proxy."" msgstr """" ""Remplacer ``METADATA_SECRET`` par un secret approprié pour le proxy metadata."" msgid """" ""Replace ``METADATA_SECRET`` with the secret you chose for the metadata proxy."" msgstr """" ""Remplacer ``METADATA_SECRET`` par le secret choisi pour le proxy metadata."" msgid """"msgid """" ""The :term:`metadata agent <Metadata agent>` provides configuration "" ""information such as credentials to instances."" msgstr """" ""L':term:`agent metadata <Metadata agent>` fournit les informations de "" ""configuration comme les credentials aux instances."" ""The ``external_network_bridge`` option intentionally lacks a value to enable "" ""multiple external networks on a single agent."" msgstr """" ""L'option ``external_network_bridge`` manque volontairement d'une valeur pour "" ""permettre plusieurs réseaux externes sur un seul agent."" msgid """"","""PO-Revision-Date: 2016-02-13 10:54+0000\n""#, fuzzy",96,2
openstack%2Fec2-api~master~If98c34e51cbbbf231f3517a77da5f163ff85a829,openstack/ec2-api,master,If98c34e51cbbbf231f3517a77da5f163ff85a829,use EBS image instead non-EBS image,MERGED,2016-02-14 19:44:12.000000000,2016-02-15 06:41:58.000000000,2016-02-15 06:41:58.000000000,"[{'_account_id': 3}, {'_account_id': 9312}]","[{'number': 1, 'created': '2016-02-14 19:44:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/885a44ccdc1e4a2de71684e410b940ea93cd4562', 'message': ""use EBS image instead non-EBS image\n\ninstances from non-EBS image can't be stopped.\n\nChange-Id: If98c34e51cbbbf231f3517a77da5f163ff85a829\n""}, {'number': 2, 'created': '2016-02-15 05:50:06.000000000', 'files': ['ec2api/tests/functional/api/test_volumes.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/3d860c2330ba2b69092fa658b2c66529b29e1c68', 'message': ""use EBS image instead non-EBS image\n\ninstances from non-EBS image can't be stopped.\n\nChange-Id: If98c34e51cbbbf231f3517a77da5f163ff85a829\n""}]",0,280019,3d860c2330ba2b69092fa658b2c66529b29e1c68,8,2,2,10234,,,0,"use EBS image instead non-EBS image

instances from non-EBS image can't be stopped.

Change-Id: If98c34e51cbbbf231f3517a77da5f163ff85a829
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/19/280019/2 && git format-patch -1 --stdout FETCH_HEAD,['ec2api/tests/functional/api/test_volumes.py'],1,885a44ccdc1e4a2de71684e410b940ea93cd4562,," def ztest_create_delete_volume(self): @testtools.skipUnless(CONF.aws.ebs_image_id, ""ebs image id is not defined"") instance_id = self.run_instance(ImageId=CONF.aws.ebs_image_id, clean_dict=clean_dict) @testtools.skipUnless(CONF.aws.ebs_image_id, ""EBS image id is not defined"") instance_id = self.run_instance(ImageId=CONF.aws.ebs_image_id, clean_dict=clean_dict) @testtools.skipUnless(CONF.aws.ebs_image_id, ""EBS image id is not defined"") def test_delete_detach_attached_volume(self): instance_id = self.run_instance(ImageId=CONF.aws.ebs_image_id)"," def test_create_delete_volume(self): @testtools.skipUnless(CONF.aws.image_id, ""image id is not defined"") instance_id = self.run_instance(clean_dict=clean_dict) @testtools.skipUnless(CONF.aws.image_id, ""image id is not defined"") instance_id = self.run_instance(clean_dict=clean_dict) @testtools.skipUnless(CONF.aws.image_id, ""image id is not defined"") def test_delete_detach_attached_volume(self): instance_id = self.run_instance()",9,7
openstack%2Fopenstack-manuals~master~I12df318557640cf30980b5f8940c9c17ea202b23,openstack/openstack-manuals,master,I12df318557640cf30980b5f8940c9c17ea202b23,Imported Translations from Zanata,MERGED,2016-02-15 06:11:16.000000000,2016-02-15 06:38:17.000000000,2016-02-15 06:38:16.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-15 06:11:16.000000000', 'files': ['doc/install-guide/source/locale/install-guide.pot', 'doc/common/source/locale/ja/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/cs/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bf959af0224bd73de7080448c3fcd5c50ca6c111', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I12df318557640cf30980b5f8940c9c17ea202b23\n'}]",0,280074,bf959af0224bd73de7080448c3fcd5c50ca6c111,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I12df318557640cf30980b5f8940c9c17ea202b23
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/74/280074/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/source/locale/install-guide.pot', 'doc/common/source/locale/ja/LC_MESSAGES/common.po', 'doc/install-guide/source/locale/cs/LC_MESSAGES/install-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po']",4,bf959af0224bd73de7080448c3fcd5c50ca6c111,zanata/translations,"""POT-Creation-Date: 2016-02-14 22:23+0000\n""","""POT-Creation-Date: 2016-02-11 06:45+0000\n""msgid ""Choose a suitable password for the database root account."" msgstr ""データベースの root アカウントに適切なパスワードを選択します。"" ""Create and edit the ``/etc/my.cnf.d/mariadb_openstack.cnf`` file and "" ""complete the following actions:"" msgstr """" ""ファイル ``/etc/my.cnf.d/mariadb_openstack.cnf`` を作成、編集し、以下の作業を"" ""すべて行います。"" msgid """" ""Create and edit the ``/etc/mysql/conf.d/mysqld_openstack.cnf`` file and "" ""complete the following actions:"" msgstr """" ""ファイル ``/etc/mysql/conf.d/mysqld_openstack.cnf`` を作成、編集し、以下の作"" ""業をすべて行います。"" msgid """"",375,352
openstack%2Fsenlin~master~I42e2668162a3cc1e081a536232c5527af2c4cd14,openstack/senlin,master,I42e2668162a3cc1e081a536232c5527af2c4cd14,Rework unit tests for policy service support,MERGED,2016-02-15 03:30:33.000000000,2016-02-15 06:24:10.000000000,2016-02-15 06:24:09.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 03:30:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/2f721f0a2feef4545791a6e8d1b17b3047f59624', 'message': 'Rework unit tests for profile service support\n\nThis patch reworks the unit tests for profile related operations in\nservice engine.\n\nChange-Id: I42e2668162a3cc1e081a536232c5527af2c4cd14\n'}, {'number': 2, 'created': '2016-02-15 03:31:10.000000000', 'files': ['senlin/tests/unit/engine/service/test_policies.py', 'senlin/engine/service.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/9e03544eb753d2a313425520294fcb7e2c402da2', 'message': 'Rework unit tests for policy service support\n\nThis patch reworks the unit tests for policy related operations in\nservice engine.\n\nChange-Id: I42e2668162a3cc1e081a536232c5527af2c4cd14\n'}]",0,280053,9e03544eb753d2a313425520294fcb7e2c402da2,7,2,2,8246,,,0,"Rework unit tests for policy service support

This patch reworks the unit tests for policy related operations in
service engine.

Change-Id: I42e2668162a3cc1e081a536232c5527af2c4cd14
",git fetch https://review.opendev.org/openstack/senlin refs/changes/53/280053/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/tests/unit/engine/service/test_policies.py']",2,2f721f0a2feef4545791a6e8d1b17b3047f59624,ut-policy,"import mockfrom oslo_utils import uuidutilsfrom senlin.common import exception as exc from senlin.db.sqlalchemy import api as db_apifrom senlin.policies import base as policy_mod def _setup_fakes(self): """"""Set up fake policy for the purpose of testing. This method is provided in a standalone function because not all test cases need such a set up. """""" 'KEY2': 6 } } @mock.patch.object(db_api, 'policy_get') def test_policy_find_by_uuid(self, mock_get): x_policy = mock.Mock() mock_get.return_value = x_policy aid = uuidutils.generate_uuid() result = self.eng.policy_find(self.ctx, aid) self.assertEqual(x_policy, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'policy_get_by_name') @mock.patch.object(db_api, 'policy_get') def test_policy_find_by_uuid_as_name(self, mock_get, mock_get_name): x_policy = mock.Mock() mock_get_name.return_value = x_policy mock_get.return_value = None aid = uuidutils.generate_uuid() result = self.eng.policy_find(self.ctx, aid) self.assertEqual(x_policy, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'policy_get_by_name') def test_policy_find_by_name(self, mock_get_name): x_policy = mock.Mock() mock_get_name.return_value = x_policy aid = 'this-is-not-uuid' result = self.eng.policy_find(self.ctx, aid) self.assertEqual(x_policy, result) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'policy_get_by_short_id') @mock.patch.object(db_api, 'policy_get_by_name') def test_policy_find_by_shortid(self, mock_get_name, mock_get_shortid): x_policy = mock.Mock() mock_get_shortid.return_value = x_policy mock_get_name.return_value = None aid = 'abcd-1234-abcd' result = self.eng.policy_find(self.ctx, aid) self.assertEqual(x_policy, result) mock_get_name.assert_called_once_with(self.ctx, aid, project_safe=True) mock_get_shortid.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'policy_get_by_name') def test_policy_find_not_found(self, mock_get_name): mock_get_name.return_value = None ex = self.assertRaises(exc.PolicyNotFound, self.eng.policy_find, self.ctx, 'Bogus') self.assertEqual('The policy (Bogus) could not be found.', six.text_type(ex)) mock_get_name.assert_called_once_with(self.ctx, 'Bogus', project_safe=True) @mock.patch.object(policy_mod.Policy, 'load_all') def test_policy_list(self, mock_load): x_obj_1 = mock.Mock() x_obj_1.to_dict.return_value = {'k': 'v1'} x_obj_2 = mock.Mock() x_obj_2.to_dict.return_value = {'k': 'v2'} mock_load.return_value = [x_obj_1, x_obj_2] result = self.eng.policy_list(self.ctx) self.assertEqual([{'k': 'v1'}, {'k': 'v2'}], result) mock_load.assert_called_once_with(self.ctx, limit=None, marker=None, filters=None, sort=None, project_safe=True) @mock.patch.object(policy_mod.Policy, 'load_all') def test_policy_list_with_params(self, mock_load): mock_load.return_value = [] result = self.eng.policy_list(self.ctx, limit=10, marker='KEY', filters={'foo': 'bar'}, sort='k:asc', project_safe=False) self.assertEqual([], result) mock_load.assert_called_once_with(self.ctx, limit=10, marker='KEY', filters={'foo': 'bar'}, sort='k:asc', project_safe=False) def test_policy_list_bad_param(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_list, self.ctx, limit='no') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_list, self.ctx, project_safe='no') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) def test_policy_create_default(self): self._setup_fakes() x_plugin = mock.Mock() x_plugin.validate.return_value = None @mock.patch.object(db_api, 'policy_get_by_name') def test_policy_create_name_conflict(self, mock_get): mock_get.return_value = mock.Mock() spec = { 'type': 'FakePolicy', 'version': '1.0', 'properties': { 'KEY2': 6 } } self.ctx, 'FAKE_NAME', spec) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(""The request is malformed: A policy named "" ""'FAKE_NAME' already exists."", mock_get.assert_called_once_with(self.ctx, 'FAKE_NAME', project_safe=True) # We skip the fakes setup, so we won't get the proper policy type spec = { 'type': 'FakePolicy', 'version': '1.0', 'properties': { 'KEY2': 6 } } self.ctx, 'p-2', spec) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) ""type (FakePolicy-1.0) is not found."", # This test is for the policy object constructor which may throw # exceptions if the spec is invalid self._setup_fakes() self.ctx, 'FAKE_POLICY', self.spec) self.assertEqual(exc.SpecValidationFailed, ex.exc_info[0]) self.assertEqual('Spec validation error (KEY2): Required spec item ' '""KEY2"" not assigned', six.text_type(ex.exc_info[1])) self._setup_fakes() mock_validate = self.patchobject(fakes.TestPolicy, 'validate') mock_validate.side_effect = exc.InvalidSpec(message='BOOM') self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: BOOM', six.text_type(ex.exc_info[1])) @mock.patch.object(policy_mod.Policy, 'load') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_get(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_policy = mock.Mock() x_policy.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_policy result = self.eng.policy_get(self.ctx, 'FAKE_POLICY') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_POLICY') mock_load.assert_called_once_with(self.ctx, db_policy=x_obj) @mock.patch.object(service.EngineService, 'policy_find') def test_policy_get_not_found(self, mock_find): mock_find.side_effect = exc.PolicyNotFound(policy='Bogus') self.assertEqual(exc.PolicyNotFound, ex.exc_info[0]) self.assertEqual('The policy (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(policy_mod.Policy, 'load') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_update(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_policy = mock.Mock() x_policy.name = 'OLD_NAME' x_policy.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_policy result = self.eng.policy_update(self.ctx, 'FAKE_POLICY', name='NEW_NAME') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_POLICY') mock_load.assert_called_once_with(self.ctx, db_policy=x_obj) self.assertEqual('NEW_NAME', x_policy.name) x_policy.store.assert_called_once_with(self.ctx) self.ctx, 'FAKE_POLICY', None) self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: Policy name not ' 'specified.', six.text_type(ex.exc_info[1])) @mock.patch.object(service.EngineService, 'policy_find') def test_policy_update_not_found(self, mock_find): mock_find.side_effect = exc.PolicyNotFound(policy='Bogus') self.eng.policy_update, self.ctx, 'Bogus', name='NEW_NAME') self.assertEqual(exc.PolicyNotFound, ex.exc_info[0]) self.assertEqual('The policy (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(policy_mod.Policy, 'load') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_update_no_change(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_policy = mock.Mock() x_policy.name = 'OLD_NAME' x_policy.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_policy result = self.eng.policy_update(self.ctx, 'FAKE_POLICY', name='OLD_NAME') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_POLICY') mock_load.assert_called_once_with(self.ctx, db_policy=x_obj) self.assertEqual(0, x_policy.store.call_count) self.assertEqual('OLD_NAME', x_policy.name) @mock.patch.object(policy_mod.Policy, 'delete') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_delete(self, mock_find, mock_delete): x_obj = mock.Mock(id='POLICY_ID') mock_find.return_value = x_obj mock_delete.return_value = None result = self.eng.policy_delete(self.ctx, 'FAKE_POLICY') self.assertIsNone(result) mock_find.assert_called_once_with(self.ctx, 'FAKE_POLICY') mock_delete.assert_called_once_with(self.ctx, 'POLICY_ID') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_delete_not_found(self, mock_find): mock_find.side_effect = exc.PolicyNotFound(policy='Bogus') self.assertEqual(exc.PolicyNotFound, ex.exc_info[0]) self.assertEqual('The policy (Bogus) could not be found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(policy_mod.Policy, 'delete') @mock.patch.object(service.EngineService, 'policy_find') def test_policy_delete_policy_in_use(self, mock_find, mock_delete): x_obj = mock.Mock(id='POLICY_ID') mock_find.return_value = x_obj err = exc.ResourceBusyError(resource_type='policy', resource_id='POLICY_ID') mock_delete.side_effect = err ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_delete, self.ctx, 'FAKE_POLICY') self.assertEqual(exc.ResourceInUse, ex.exc_info[0]) self.assertEqual('The policy (POLICY_ID) is still in use.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'FAKE_POLICY') mock_delete.assert_called_once_with(self.ctx, 'POLICY_ID')","from senlin.common import exception from senlin.common.i18n import _ self.eng.init_tgm() 'KEY1': 'value1', 'KEY2': 2, } } def test_policy_create_default(self): self.assertIsInstance(result, dict) def test_policy_create_already_exists(self): result = self.eng.policy_create(self.ctx, 'p-1', self.spec) self.assertIsNotNone(result) self.ctx, 'p-1', self.spec) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(_(""The request is malformed: The policy (p-1) "" ""already exists.""), self.spec['type'] = 'Bogus' self.ctx, 'p-2', self.spec) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) ""type (Bogus-1.0) is not supported."", self.ctx, 'p-2', self.spec) self.assertEqual(exception.SpecValidationFailed, ex.exc_info[0]) self.spec['properties'] = {'KEY2': 1} self.patchobject(fakes.TestPolicy, 'validate', side_effect=exception.InvalidSpec(message='BOOM')) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) def test_policy_get(self): p = self.eng.policy_create(self.ctx, 'p-1', self.spec) for identity in [p['id'], p['id'][:6], 'p-1']: result = self.eng.policy_get(self.ctx, identity) self.assertIsInstance(result, dict) self.assertEqual(p['id'], result['id']) self.assertEqual(exception.PolicyNotFound, ex.exc_info[0]) def test_policy_list(self): p1 = self.eng.policy_create(self.ctx, 'p-1', self.spec) p2 = self.eng.policy_create(self.ctx, 'p-2', self.spec) result = self.eng.policy_list(self.ctx) self.assertIsInstance(result, list) names = [p['name'] for p in result] ids = [p['id'] for p in result] self.assertIn(p1['name'], names) self.assertIn(p2['name'], names) self.assertIn(p1['id'], ids) self.assertIn(p2['id'], ids) def test_policy_list_with_limit_marker(self): p1 = self.eng.policy_create(self.ctx, 'p-1', self.spec) p2 = self.eng.policy_create(self.ctx, 'p-2', self.spec) result = self.eng.policy_list(self.ctx, limit=0) self.assertEqual(0, len(result)) result = self.eng.policy_list(self.ctx, limit=1) self.assertEqual(1, len(result)) result = self.eng.policy_list(self.ctx, limit=2) self.assertEqual(2, len(result)) result = self.eng.policy_list(self.ctx, limit=3) self.assertEqual(2, len(result)) result = self.eng.policy_list(self.ctx, marker=p1['id']) self.assertEqual(1, len(result)) result = self.eng.policy_list(self.ctx, marker=p2['id']) self.assertEqual(0, len(result)) self.eng.policy_create(self.ctx, 'p-3', self.spec) result = self.eng.policy_list(self.ctx, limit=1, marker=p1['id']) self.assertEqual(1, len(result)) result = self.eng.policy_list(self.ctx, limit=2, marker=p1['id']) self.assertEqual(2, len(result)) def test_policy_list_with_sorting(self): p1 = self.eng.policy_create(self.ctx, 'p-B', self.spec) p2 = self.eng.policy_create(self.ctx, 'p-A', self.spec) # default by created_at result = self.eng.policy_list(self.ctx) self.assertEqual(p1['id'], result[0]['id']) self.assertEqual(p2['id'], result[1]['id']) # use name for sorting result = self.eng.policy_list(self.ctx, sort='name') self.assertEqual(p2['id'], result[0]['id']) self.assertEqual(p1['id'], result[1]['id']) # unknown keys will be ignored result = self.eng.policy_list(self.ctx, sort='duang') self.assertIsNotNone(result) def test_policy_list_with_sorting_dir(self): p1 = self.eng.policy_create(self.ctx, 'p-B', self.spec) p2 = self.eng.policy_create(self.ctx, 'p-A', self.spec) p3 = self.eng.policy_create(self.ctx, 'p-C', self.spec) # default by created_at, ascending result = self.eng.policy_list(self.ctx) self.assertEqual(p1['id'], result[0]['id']) self.assertEqual(p2['id'], result[1]['id']) # sort by created_at, descending result = self.eng.policy_list(self.ctx, sort='created_at:desc') self.assertEqual(p3['id'], result[0]['id']) self.assertEqual(p2['id'], result[1]['id']) # use name for sorting, descending result = self.eng.policy_list(self.ctx, sort='name:desc') self.assertEqual(p3['id'], result[0]['id']) self.assertEqual(p1['id'], result[1]['id']) def test_policy_list_with_filters(self): self.eng.policy_create(self.ctx, 'p-B', self.spec) self.eng.policy_create(self.ctx, 'p-A', self.spec) self.eng.policy_create(self.ctx, 'p-C', self.spec) result = self.eng.policy_list(self.ctx, filters={'name': 'p-B'}) self.assertEqual(1, len(result)) self.assertEqual('p-B', result[0]['name']) result = self.eng.policy_list(self.ctx, filters={'name': 'p-D'}) self.assertEqual(0, len(result)) def test_policy_list_bad_param(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_list, self.ctx, limit='no') self.assertEqual(exception.InvalidParameter, ex.exc_info[0]) def test_policy_list_empty(self): result = self.eng.policy_list(self.ctx) self.assertIsInstance(result, list) self.assertEqual(0, len(result)) def test_policy_find(self): p = self.eng.policy_create(self.ctx, 'p-1', self.spec) pid = p['id'] result = self.eng.policy_find(self.ctx, pid) self.assertIsNotNone(result) # short id result = self.eng.policy_find(self.ctx, pid[:5]) self.assertIsNotNone(result) # name result = self.eng.policy_find(self.ctx, 'p-1') self.assertIsNotNone(result) # others self.assertRaises(exception.PolicyNotFound, self.eng.policy_find, self.ctx, 'Bogus') def test_policy_update(self): p1 = self.eng.policy_create(self.ctx, 'p-1', self.spec) pid = p1['id'] self.assertEqual(self.spec, p1['spec']) # 1. update name p2 = self.eng.policy_update(self.ctx, pid, name='p-2') self.assertEqual(pid, p2['id']) self.assertEqual('p-2', p2['name']) # check persisted into db p = self.eng.policy_get(self.ctx, pid) self.assertEqual('p-2', p['name']) def test_policy_update_not_found(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.policy_update, self.ctx, 'Bogus', name='new name') self.assertEqual(exception.PolicyNotFound, ex.exc_info[0]) self.eng.policy_create(self.ctx, 'p-1', self.spec) self.ctx, 'p-1', None) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) def test_policy_delete(self): p1 = self.eng.policy_create(self.ctx, 'p-1', self.spec) pid = p1['id'] result = self.eng.policy_delete(self.ctx, pid) self.assertIsNone(result) self.eng.policy_get, self.ctx, pid) self.assertEqual(exception.PolicyNotFound, ex.exc_info[0]) def test_policy_delete_not_found(self): self.assertEqual(exception.PolicyNotFound, ex.exc_info[0])",342,186
openstack%2Ftempest~master~I3def2552cc348bbf1cd11430d4ea234f27167edb,openstack/tempest,master,I3def2552cc348bbf1cd11430d4ea234f27167edb,"My first contribution to openstack, added uuid's",ABANDONED,2016-02-15 05:02:13.000000000,2016-02-15 06:21:48.000000000,,"[{'_account_id': 10385}, {'_account_id': 16272}]","[{'number': 1, 'created': '2016-02-15 05:02:13.000000000', 'files': ['tempest/services/messaging/json/messaging_client.py~', 'tempest/api/messaging/test_queues_negative.py~', 'tempest/api/messaging/test_queues_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a3148c69f5c9612a7e24614938f44ef79f7709e6', 'message': ""My first contribution to openstack, added uuid's\n\nChange-Id: I3def2552cc348bbf1cd11430d4ea234f27167edb\n""}]",0,280063,a3148c69f5c9612a7e24614938f44ef79f7709e6,4,2,1,15285,,,0,"My first contribution to openstack, added uuid's

Change-Id: I3def2552cc348bbf1cd11430d4ea234f27167edb
",git fetch https://review.opendev.org/openstack/tempest refs/changes/63/280063/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/messaging/json/messaging_client.py~', 'tempest/api/messaging/test_queues_negative.py~', 'tempest/api/messaging/test_queues_negative.py']",3,a3148c69f5c9612a7e24614938f44ef79f7709e6,bp/tempest-tests-zaqar, @test.idempotent_id('9d75aca5-78bc-4065-b89f-92494b3e0c3d') @test.idempotent_id('f36a4f43-3312-499a-a07f-c2d4801843c0') @test.idempotent_id('e8a79cdb-a470-4f17-9f05-2a8a77ac78c5') @test.idempotent_id('c2414071-638c-40f2-93c3-f4fd9a05ea28') @test.idempotent_id('aa1bf68b-ef70-4519-bd4f-9af7b1014990') @test.idempotent_id('b0debcbf-5b65-40d4-bf1c-7ed4b6c3fa33') @test.idempotent_id('2c1ed3e7-9832-445d-b697-080bb48ebb03') @test.idempotent_id('7bc78199-0672-456f-bc5b-e2466b16eb19') @test.idempotent_id('7e8c4b22-cc82-40bf-aa8c-7cf5ecedc59a') @test.idempotent_id('42804766-229f-4f67-8ddf-f50aa36b1c13') @test.idempotent_id('65e9310c-93b3-4841-9eef-3e0188a75121') @test.idempotent_id('169e1ef5-9bbd-4bae-b83b-ded0fc26d28c') @test.idempotent_id('35a82220-311d-4dfe-b248-af11c7bc35b5') @test.idempotent_id('d840bf7b-55fa-46d3-b3c9-4ce07040d73e') @test.idempotent_id('565d7483-bce0-4e98-966b-d13fd4d2d120') @test.idempotent_id('c4408034-e1ed-4457-b032-eba123cf4264') @test.idempotent_id('37c50b6b-5aa5-4f98-a8c1-4973e69850af') @test.idempotent_id('69a85c8a-1e38-4a68-b070-70fbaa5a4dec') @test.idempotent_id('f3e49aa4-3921-43f8-b495-5f540a3e6233') @test.idempotent_id('440ada06-0b0b-425b-9734-9abf231043b3') @test.idempotent_id('3df2aa83-c5f7-4ab2-b84d-e3b6dd54892a') @test.idempotent_id('7038c55f-6318-4322-bc64-efb666959b97') @test.idempotent_id('54a82bdb-2e3c-46c8-a3a5-e9bb404d33b6') @test.idempotent_id('459e7861-2632-419d-a0e9-16242b89e9e1') @test.idempotent_id('142e53a4-4449-460b-b75b-9e49ac7afb0d') @test.idempotent_id('c9a41c3a-6967-4ad5-ba75-790fbf95bc58') @test.idempotent_id('a6d522d3-2058-4c1e-a0be-f829c74a35f9') @test.idempotent_id('d11ba0ed-1f69-4c12-9b5c-a4c64b98dd77') @test.idempotent_id('178cef6d-dc9a-42f2-b430-f1ec82ddf925') @test.idempotent_id('9214de61-abe2-46d2-892d-b2f728f66f99') @test.idempotent_id('0e2feffd-1c71-4feb-9ffd-7f822eeb2994') @test.idempotent_id('a07bc26f-54c3-4a78-a337-285667f96789') @test.idempotent_id('96264700-b700-471d-9950-cea5d90c352c') @test.idempotent_id('38aabe21-4dc1-41b8-a89a-b0707b727514'),,577,0
openstack%2Fcinder~master~Ie05e4da082d6eae87c75200c78da68d9a18c19a7,openstack/cinder,master,Ie05e4da082d6eae87c75200c78da68d9a18c19a7,Replace exit() by sys.exit(),MERGED,2016-01-25 09:30:14.000000000,2016-02-15 06:17:19.000000000,2016-02-11 06:25:36.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9581}, {'_account_id': 11904}, {'_account_id': 13144}, {'_account_id': 14305}, {'_account_id': 15961}, {'_account_id': 16708}]","[{'number': 1, 'created': '2016-01-25 09:30:14.000000000', 'files': ['cinder/cmd/manage.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f06f15ad712c422deb4eb9ac01defa4d346144b', 'message': 'Replace exit() by sys.exit()\n\nexit() is used for interactive shell, it relies on the site module.\nsys.exit() is considered good to use in programs.\n\nTrivial-fix\n\nChange-Id: Ie05e4da082d6eae87c75200c78da68d9a18c19a7\n'}]",0,271966,5f06f15ad712c422deb4eb9ac01defa4d346144b,49,10,1,19950,,,0,"Replace exit() by sys.exit()

exit() is used for interactive shell, it relies on the site module.
sys.exit() is considered good to use in programs.

Trivial-fix

Change-Id: Ie05e4da082d6eae87c75200c78da68d9a18c19a7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/271966/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/cmd/manage.py'],1,5f06f15ad712c422deb4eb9ac01defa4d346144b,sys_exit, sys.exit(1) sys.exit(1), exit(1) exit(1),2,2
openstack%2Fha-guide~master~I3d50080b832da96a1eddc1663de7de6bc9843b6e,openstack/ha-guide,master,I3d50080b832da96a1eddc1663de7de6bc9843b6e,Imported Translations from Zanata,MERGED,2016-02-15 06:00:29.000000000,2016-02-15 06:11:39.000000000,2016-02-15 06:11:39.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-15 06:00:29.000000000', 'files': ['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/locale/ha-guide.pot'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/f96b3ffc522ef64f5f24d47a7f330af46e89ad20', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I3d50080b832da96a1eddc1663de7de6bc9843b6e\n'}]",0,280073,f96b3ffc522ef64f5f24d47a7f330af46e89ad20,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I3d50080b832da96a1eddc1663de7de6bc9843b6e
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/73/280073/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/ha-guide/source/locale/ja/LC_MESSAGES/ha-guide.po', 'doc/ha-guide/source/locale/ha-guide.pot']",2,f96b3ffc522ef64f5f24d47a7f330af46e89ad20,zanata/translations,"""POT-Creation-Date: 2016-02-15 06:00+0000\n""#: ../compute-node-ha-api.rst:4 msgid ""Configure high availability on compute nodes""#: ../compute-node-ha-api.rst:6 msgid """" ""The `Installation Guide <http://docs.openstack.org/liberty/#install-"" ""guides>`_ gives instructions for installing multiple compute nodes. To make "" ""them highly available, you must configure the environment to include "" ""multiple instances of the API and other services.""#: ../compute-node-ha.rst:4 msgid ""Configuring the compute node for high availability""#: ../controller-ha-galera-config.rst:2 msgid ""Configuration""#: ../controller-ha-galera-config.rst:4 msgid """" ""Before you launch Galera Cluster, you need to configure the server and the "" ""database to operate as part of the cluster.""#: ../controller-ha-galera-config.rst:8 msgid ""Configuring the server""#: ../controller-ha-galera-config.rst:10 msgid """" ""Certain services running on the underlying operating system of your "" ""OpenStack database may block Galera Cluster from normal operation or prevent "" ""``mysqld`` from achieving network connectivity with the cluster.""#: ../controller-ha-galera-config.rst:16 msgid ""Firewall""#: ../controller-ha-galera-config.rst:18 msgid ""Galera Cluster requires that you open four ports to network traffic:""#: ../controller-ha-galera-config.rst:20 msgid """" ""On ``3306``, Galera Cluster uses TCP for database client connections and "" ""State Snapshot Transfers methods that require the client, (that is, "" ""``mysqldump``).""#: ../controller-ha-galera-config.rst:23 msgid """" ""On ``4567`` Galera Cluster uses TCP for replication traffic. Multicast "" ""replication uses both TCP and UDP on this port.""#: ../controller-ha-galera-config.rst:25 msgid ""On ``4568`` Galera Cluster uses TCP for Incremental State Transfers.""#: ../controller-ha-galera-config.rst:26 msgid """" ""On ``4444`` Galera Cluster uses TCP for all other State Snapshot Transfer "" ""methods.""#: ../controller-ha-galera-config.rst:29 msgid """" ""For more information on firewalls, see `Firewalls and default ports <http://"" ""docs.openstack.org/liberty/config-reference/content/firewalls-default-ports."" ""html>`_, in the Configuration Reference.""#: ../controller-ha-galera-config.rst:35 msgid ""``iptables``""#: ../controller-ha-galera-config.rst:37 msgid """" ""For many Linux distributions, you can configure the firewall using the "" ""``iptables`` utility. To do so, complete the following steps:""#: ../controller-ha-galera-config.rst:40 msgid """" ""For each cluster node, run the following commands, replacing ``NODE-IP-"" ""ADDRESS`` with the IP address of the cluster node you want to open the "" ""firewall to:""#: ../controller-ha-galera-config.rst:59 msgid """" ""In the event that you also want to configure multicast replication, run this "" ""command as well:""#: ../controller-ha-galera-config.rst:69 msgid """" ""Make the changes persistent. For servers that use ``init``, use the :command:"" ""`save` command:""#: ../controller-ha-galera-config.rst:76 msgid """" ""For servers that use ``systemd``, you need to save the current packet "" ""filtering to the path of the file that ``iptables`` reads when it starts. "" ""This path can vary by distribution, but common locations are in the ``/etc`` "" ""directory, such as:""#: ../controller-ha-galera-config.rst:81 msgid ""``/etc/sysconfig/iptables``""#: ../controller-ha-galera-config.rst:82 msgid ""``/etc/iptables/iptables.rules``"" msgstr """" #: ../controller-ha-galera-config.rst:84 msgid """" ""When you find the correct path, run the :command:`iptables-save` command:"" msgstr """" #: ../controller-ha-galera-config.rst:90 #: ../controller-ha-galera-config.rst:137 msgid """" ""With the firewall configuration saved, whenever your OpenStack database "" ""starts."" msgstr """" #: ../controller-ha-galera-config.rst:94 msgid ""``firewall-cmd``"" msgstr """" #: ../controller-ha-galera-config.rst:96 msgid """" ""For many Linux distributions, you can configure the firewall using the "" ""``firewall-cmd`` utility for FirewallD. To do so, complete the following "" ""steps on each cluster node:"" msgstr """" #: ../controller-ha-galera-config.rst:100 msgid ""Add the Galera Cluster service:"" msgstr """" #: ../controller-ha-galera-config.rst:106 msgid """" ""For each instance of OpenStack database in your cluster, run the following "" ""commands, replacing ``NODE-IP-ADDRESS`` with the IP address of the cluster "" ""node you want to open the firewall to:"" msgstr """" #: ../controller-ha-galera-config.rst:117 msgid """" ""In the event that you also want to configure mutlicast replication, run this "" ""command as well:"" msgstr """" #: ../controller-ha-galera-config.rst:124 msgid """" ""To make this configuration persistent, repeat the above commands with the :"" ""option:`--permanent` option."" msgstr """" #: ../controller-ha-galera-config.rst:141 msgid ""SELinux"" msgstr """" #: ../controller-ha-galera-config.rst:143 msgid """" ""Security-Enhanced Linux is a kernel module for improving security on Linux "" ""operating systems. It is commonly enabled and configured by default on Red "" ""Hat-based distributions. In the context of Galera Cluster, systems with "" ""SELinux may block the database service, keep it from starting or prevent it "" ""from establishing network connections with the cluster."" msgstr """" #: ../controller-ha-galera-config.rst:149 msgid """" ""To configure SELinux to permit Galera Cluster to operate, complete the "" ""following steps on each cluster node:"" msgstr """" #: ../controller-ha-galera-config.rst:152 msgid ""Using the ``semanage`` utility, open the relevant ports:"" msgstr """" #: ../controller-ha-galera-config.rst:161 msgid """" ""In the event that you use multicast replication, you also need to open "" ""``4567`` to UDP traffic:"" msgstr """" #: ../controller-ha-galera-config.rst:168 msgid ""Set SELinux to allow the database server to run:"" msgstr """" #: ../controller-ha-galera-config.rst:174 msgid ""With these options set, SELinux now permits Galera Cluster to operate."" msgstr """" #: ../controller-ha-galera-config.rst:176 msgid """" ""Bear in mind, leaving SELinux in permissive mode is not a good security "" ""practice. Over the longer term, you need to develop a security policy for "" ""Galera Cluster and then switch SELinux back into enforcing mode."" msgstr """" #: ../controller-ha-galera-config.rst:181 msgid """" ""For more information on configuring SELinux to work with Galera Cluster, see "" ""the `Documentation <http://galeracluster.com/documentation-webpages/selinux."" ""html>`_"" msgstr """" #: ../controller-ha-galera-config.rst:187 msgid ""AppArmor"" msgstr """" #: ../controller-ha-galera-config.rst:189 msgid """" ""Application Armor is a kernel module for improving security on Linux "" ""operating systems. It is developed by Canonical and commonly used on Ubuntu-"" ""based distributions. In the context of Galera Cluster, systems with AppArmor "" ""may block the database service from operating normally."" msgstr """" #: ../controller-ha-galera-config.rst:194 msgid """" ""To configure AppArmor to work with Galera Cluster, complete the following "" ""steps on each cluster node:"" msgstr """" #: ../controller-ha-galera-config.rst:197 msgid """" ""Create a symbolic link for the database server in the ``disable`` directory:"" msgstr """" #: ../controller-ha-galera-config.rst:203 msgid """" ""Restart AppArmor. For servers that use ``init``, run the following command:"" msgstr """" # #-#-#-#-# controller-ha-galera-config.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-galera-manage.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-galera-config.rst:209 #: ../controller-ha-galera-manage.rst:43 ../controller-ha-galera-manage.rst:70 msgid ""For servers that use ``systemd``, instead run this command:"" msgstr """" #: ../controller-ha-galera-config.rst:215 msgid ""AppArmor now permits Galera Cluster to operate."" msgstr """" #: ../controller-ha-galera-config.rst:219 msgid ""Database configuration"" msgstr """" #: ../controller-ha-galera-config.rst:221 msgid """" ""MySQL databases, including MariaDB and Percona XtraDB, manage their "" ""configurations using a ``my.cnf`` file, which is typically located in the ``/"" ""etc`` directory. Configuration options available in these databases are also "" ""available in Galera Cluster, with some restrictions and several additions."" msgstr """" #: ../controller-ha-galera-config.rst:252 msgid ""Configuring ``mysqld``"" msgstr """" #: ../controller-ha-galera-config.rst:254 msgid """" ""While all of the configuration parameters available to the standard MySQL, "" ""MariaDB or Percona XtraDB database server are available in Galera Cluster, "" ""there are some that you must define an outset to avoid conflict or "" ""unexpected behavior."" msgstr """" #: ../controller-ha-galera-config.rst:259 msgid """" ""Ensure that the database server is not bound only to to the localhost, "" ""``127.0.0.1``. Instead, bind it to ``0.0.0.0`` to ensure it listens on all "" ""available interfaces."" msgstr """" #: ../controller-ha-galera-config.rst:267 msgid """" ""Ensure that the binary log format is set to use row-level replication, as "" ""opposed to statement-level replication:"" msgstr """" #: ../controller-ha-galera-config.rst:276 msgid ""Configuring InnoDB"" msgstr """" #: ../controller-ha-galera-config.rst:278 msgid """" ""Galera Cluster does not support non-transactional storage engines and "" ""requires that you use InnoDB by default. There are some additional "" ""parameters that you must define to avoid conflicts."" msgstr """" #: ../controller-ha-galera-config.rst:282 msgid ""Ensure that the default storage engine is set to InnoDB:"" msgstr """" #: ../controller-ha-galera-config.rst:288 msgid """" ""Ensure that the InnoDB locking mode for generating auto-increment values is "" ""set to ``2``, which is the interleaved locking mode."" msgstr """" #: ../controller-ha-galera-config.rst:295 msgid """" ""Do not change this value. Other modes may cause ``INSERT`` statements on "" ""tables with auto-increment columns to fail as well as unresolved deadlocks "" ""that leave the system unresponsive."" msgstr """" #: ../controller-ha-galera-config.rst:299 msgid """" ""Ensure that the InnoDB log buffer is written to file once per second, rather "" ""than on each commit, to improve performance:"" msgstr """" #: ../controller-ha-galera-config.rst:306 msgid """" ""Bear in mind, while setting this parameter to ``1`` or ``2`` can improve "" ""performance, it introduces certain dangers. Operating system failures can "" ""erase the last second of transactions. While you can recover this data from "" ""another node, if the cluster goes down at the same time (in the event of a "" ""data center power outage), you lose this data permanently."" msgstr """" #: ../controller-ha-galera-config.rst:312 msgid """" ""Define the InnoDB memory buffer pool size. The default value is 128 MB, but "" ""to compensate for Galera Cluster's additional memory usage, scale your usual "" ""value back by 5%:"" msgstr """" #: ../controller-ha-galera-config.rst:322 msgid ""Configuring wsrep replication"" msgstr """" #: ../controller-ha-galera-config.rst:324 msgid """" ""Galera Cluster configuration parameters all have the ``wsrep_`` prefix. "" ""There are five that you must define for each cluster node in your OpenStack "" ""database."" msgstr """" #: ../controller-ha-galera-config.rst:328 msgid """" ""**wsrep Provider** The Galera Replication Plugin serves as the wsrep "" ""Provider for Galera Cluster. It is installed on your system as the "" ""``libgalera_smm.so`` file. You must define the path to this file in your "" ""``my.cnf``."" msgstr """" #: ../controller-ha-galera-config.rst:337 msgid ""**Cluster Name** Define an arbitrary name for your cluster."" msgstr """" #: ../controller-ha-galera-config.rst:343 msgid """" ""You must use the same name on every cluster node. The connection fails when "" ""this value does not match."" msgstr """" #: ../controller-ha-galera-config.rst:346 msgid ""**Cluster Address** List the IP addresses for each cluster node."" msgstr """" #: ../controller-ha-galera-config.rst:352 msgid """" ""Replace the IP addresses given here with comma-separated list of each "" ""OpenStack database in your cluster."" msgstr """" #: ../controller-ha-galera-config.rst:355 msgid ""**Node Name** Define the logical name of the cluster node."" msgstr """" #: ../controller-ha-galera-config.rst:361 msgid ""**Node Address** Define the IP address of the cluster node."" msgstr """" #: ../controller-ha-galera-config.rst:371 msgid ""Additional parameters"" msgstr """" #: ../controller-ha-galera-config.rst:373 msgid """" ""For a complete list of the available parameters, run the ``SHOW VARIABLES`` "" ""command from within the database client:"" msgstr """" #: ../controller-ha-galera-config.rst:394 msgid """" ""For the documentation of these parameters, wsrep Provider option and status "" ""variables available in Galera Cluster, see `Reference <http://galeracluster."" ""com/documentation-webpages/reference.html>`_."" msgstr """" #: ../controller-ha-galera-install.rst:2 msgid ""Installation"" msgstr """" #: ../controller-ha-galera-install.rst:4 msgid """" ""Using Galera Cluster requires that you install two packages. The first is "" ""the database server, which must include the wsrep API patch. The second "" ""package is the Galera Replication Plugin, which enables the write-set "" ""replication service functionality with the database server."" msgstr """" #: ../controller-ha-galera-install.rst:9 msgid """" ""There are three implementations of Galera Cluster: MySQL, MariaDB and "" ""Percona XtraDB. For each implementation, there is a software repository that "" ""provides binary packages for Debian, Red Hat, and SUSE-based Linux "" ""distributions."" msgstr """" #: ../controller-ha-galera-install.rst:16 msgid ""Enabling the repository"" msgstr """" #: ../controller-ha-galera-install.rst:18 msgid """" ""Galera Cluster is not available in the base repositories of Linux "" ""distributions. In order to install it with your package manage, you must "" ""first enable the repository on your system. The particular methods for doing "" ""so vary depending on which distribution you use for OpenStack and which "" ""database server you want to use."" msgstr """" #: ../controller-ha-galera-install.rst:25 msgid ""Debian"" msgstr """" #: ../controller-ha-galera-install.rst:27 msgid """" ""For Debian and Debian-based distributions, such as Ubuntu, complete the "" ""following steps:"" msgstr """" #: ../controller-ha-galera-install.rst:30 msgid ""Add the GnuPG key for the database repository that you want to use."" msgstr """" #: ../controller-ha-galera-install.rst:37 msgid """" ""Note that the particular key value in this command varies depending on which "" ""database software repository you want to use."" msgstr """" #: ../controller-ha-galera-install.rst:41 msgid ""Database"" msgstr """" #: ../controller-ha-galera-install.rst:41 msgid ""Key"" msgstr """" #: ../controller-ha-galera-install.rst:43 msgid ""Galera Cluster for MySQL"" msgstr """" #: ../controller-ha-galera-install.rst:43 msgid ""``BC19DDBA``"" msgstr """" #: ../controller-ha-galera-install.rst:45 msgid ""MariaDB Galera Cluster"" msgstr """" #: ../controller-ha-galera-install.rst:45 msgid ""``0xcbcb082a1bb943db``"" msgstr """" #: ../controller-ha-galera-install.rst:47 msgid ""Percona XtraDB Cluster"" msgstr """" #: ../controller-ha-galera-install.rst:47 msgid ""``1C4CBDCDCD2EFD2A``"" msgstr """" #: ../controller-ha-galera-install.rst:50 msgid """" ""Add the repository to your sources list. Using your preferred text editor, "" ""create a ``galera.list`` file in the ``/etc/apt/sources.list.d/`` directory. "" ""For the contents of this file, use the lines that pertain to the software "" ""repository you want to install:"" msgstr """" #: ../controller-ha-galera-install.rst:66 msgid """" ""For each entry: Replace all instances of ``DISTRO`` with the distribution "" ""that you use, such as ``debian`` or ``ubuntu``. Replace all instances of "" ""``RELEASE`` with the release of that distribution, such as ``wheezy`` or "" ""``trusty``. Replace all instances of ``VERSION`` with the version of the "" ""database server that you want to install, such as ``5.6`` or ``10.0``."" msgstr """" #: ../controller-ha-galera-install.rst:72 msgid """" ""In the event that you do not know the release code-name for your "" ""distribution, you can use the following command to find it out:"" msgstr """" #: ../controller-ha-galera-install.rst:81 msgid ""Update the local cache."" msgstr """" #: ../controller-ha-galera-install.rst:87 msgid """" ""Packages in the Galera Cluster Debian repository are now available for "" ""installation on your system."" msgstr """" #: ../controller-ha-galera-install.rst:91 msgid ""Red Hat"" msgstr """" #: ../controller-ha-galera-install.rst:93 msgid """" ""For Red Hat Enterprise Linux and Red Hat-based Linux distributions, the "" ""process is more straightforward. In this file, only enter the text for the "" ""repository you want to use."" msgstr """" #: ../controller-ha-galera-install.rst:97 msgid """" ""For Galera Cluster for MySQL, using your preferred text editor, create a "" ""``Galera.repo`` file in the ``/etc/yum.repos.d/`` directory."" msgstr """" #: ../controller-ha-galera-install.rst:108 msgid """" ""Replace ``DISTRO`` with the name of the distribution you use, such as "" ""``centos`` or ``fedora``. Replace ``RELEASE`` with the release number, such "" ""as ``7`` for CentOS 7. Replace ``ARCH`` with your system architecture, such "" ""as ``x86_64``"" msgstr """" #: ../controller-ha-galera-install.rst:113 msgid """" ""For MariaDB Galera Cluster, using your preferred text editor, create a "" ""``Galera.repo`` file in the ``/etc/yum.repos.d/`` directory."" msgstr """" #: ../controller-ha-galera-install.rst:124 msgid """" ""Replace ``VERSION`` with the version of MariaDB you want to install, such as "" ""``5.6`` or ``10.0``. Replace ``PACKAGE`` with the package type and "" ""architecture, such as ``rhel6-amd64`` for Red Hat 6 on 64-bit architecture."" msgstr """" #: ../controller-ha-galera-install.rst:129 msgid ""For Percona XtraDB Cluster, run the following command:"" msgstr """" #: ../controller-ha-galera-install.rst:135 msgid """" ""Bear in mind that the Percona repository only supports Red Hat Enterprise "" ""Linux and CentOS distributions."" msgstr """" #: ../controller-ha-galera-install.rst:138 msgid """" ""Packages in the Galera Cluster Red Hat repository are not available for "" ""installation on your system."" msgstr """" #: ../controller-ha-galera-install.rst:144 msgid ""SUSE"" msgstr """" #: ../controller-ha-galera-install.rst:146 msgid """" ""For SUSE Enterprise Linux and SUSE-based distributions, such as openSUSE "" ""binary installations are only available for Galera Cluster for MySQL and "" ""MariaDB Galera Cluster."" msgstr """" #: ../controller-ha-galera-install.rst:150 msgid """" ""Create a ``Galera.repo`` file in the local directory. For Galera Cluster for "" ""MySQL, use the following content:"" msgstr """" #: ../controller-ha-galera-install.rst:161 msgid """" ""In the text: Replace ``DISTRO`` with the name of the distribution you use, "" ""such as ``sles`` or ``opensuse``. Replace ``RELEASE`` with the version "" ""number of that distribution."" msgstr """" #: ../controller-ha-galera-install.rst:165 msgid ""For MariaDB Galera Cluster, instead use this content:"" msgstr """" #: ../controller-ha-galera-install.rst:175 msgid """" ""In the text: Replace ``VERSION`` with the version of MariaDB you want to "" ""install, such as ``5.6`` or ``10.0``. Replace package with the package "" ""architecture you want to use, such as ``opensuse13-amd64``."" msgstr """" #: ../controller-ha-galera-install.rst:179 msgid ""Add the repository to your system:"" msgstr """" #: ../controller-ha-galera-install.rst:185 msgid ""Refresh ``zypper``:"" msgstr """" #: ../controller-ha-galera-install.rst:191 msgid """" ""Packages in the Galera Cluster SUSE repository are now available for "" ""installation."" msgstr """" #: ../controller-ha-galera-install.rst:196 msgid ""Installing Galera Cluster"" msgstr """" #: ../controller-ha-galera-install.rst:198 msgid """" ""When you finish enabling the software repository for Galera Cluster, you can "" ""install it using your package manager. The particular command and packages "" ""you need to install varies depending on which database server you want to "" ""install and which Linux distribution you use:"" msgstr """" #: ../controller-ha-galera-install.rst:203 msgid ""Galera Cluster for MySQL:"" msgstr """" #: ../controller-ha-galera-install.rst:206 #: ../controller-ha-galera-install.rst:230 #: ../controller-ha-galera-install.rst:255 msgid """" ""For Debian and Debian-based distributions, such as Ubuntu, run the following "" ""command:"" msgstr """" #: ../controller-ha-galera-install.rst:213 #: ../controller-ha-galera-install.rst:237 #: ../controller-ha-galera-install.rst:262 msgid """" ""For Red Hat Enterprise Linux and Red Hat-based distributions, such as Fedora "" ""or CentOS, instead run this command:"" msgstr """" #: ../controller-ha-galera-install.rst:220 #: ../controller-ha-galera-install.rst:244 msgid """" ""For SUSE Enterprise Linux Server and SUSE-based distributions, such as "" ""openSUSE, instead run this command:"" msgstr """" #: ../controller-ha-galera-install.rst:228 msgid ""MariaDB Galera Cluster:"" msgstr """" #: ../controller-ha-galera-install.rst:252 msgid ""Percona XtraDB Cluster:"" msgstr """" #: ../controller-ha-galera-install.rst:269 msgid """" ""Galera Cluster is now installed on your system. You must repeat this process "" ""for each controller node in your cluster."" msgstr """" #: ../controller-ha-galera-install.rst:272 msgid """" ""In the event that you already installed the standalone version of MySQL, "" ""MariaDB or Percona XtraDB, this installation purges all privileges on your "" ""OpenStack database server. You must reapply the privileges listed in the "" ""installation guide."" msgstr """" #: ../controller-ha-galera-manage.rst:2 msgid ""Management"" msgstr """" #: ../controller-ha-galera-manage.rst:4 msgid """" ""When you finish the installation and configuration process on each cluster "" ""node in your OpenStack database, you can initialize Galera Cluster."" msgstr """" #: ../controller-ha-galera-manage.rst:7 msgid ""Before you attempt this, verify that you have the following ready:"" msgstr """" #: ../controller-ha-galera-manage.rst:9 msgid """" ""Database hosts with Galera Cluster installed. You need a minimum of three "" ""hosts;"" msgstr """" #: ../controller-ha-galera-manage.rst:11 msgid ""No firewalls between the hosts;"" msgstr """" #: ../controller-ha-galera-manage.rst:12 msgid ""SELinux and AppArmor set to permit access to ``mysqld``;"" msgstr """" #: ../controller-ha-galera-manage.rst:13 msgid """" ""The correct path to ``libgalera_smm.so`` given to the ``wsrep_provider`` "" ""parameter."" msgstr """" #: ../controller-ha-galera-manage.rst:17 msgid ""Initializing the cluster"" msgstr """" #: ../controller-ha-galera-manage.rst:19 msgid """" ""In Galera Cluster, the Primary Component is the cluster of database servers "" ""that replicate into each other. In the event that a cluster node loses "" ""connectivity with the Primary Component, it defaults into a non-operational "" ""state, to avoid creating or serving inconsistent data."" msgstr """" #: ../controller-ha-galera-manage.rst:25 msgid """" ""By default, cluster nodes do not start as part of a Primary Component. "" ""Instead they assume that one exists somewhere and attempts to establish a "" ""connection with it. To create a Primary Component, you must start one "" ""cluster node using the ``--wsrep-new-cluster`` option. You can do this using "" ""any cluster node, it is not important which you choose. In the Primary "" ""Component, replication and state transfers bring all databases to the same "" ""state."" msgstr """" #: ../controller-ha-galera-manage.rst:34 msgid ""To start the cluster, complete the following steps:"" msgstr """" #: ../controller-ha-galera-manage.rst:36 msgid """" ""Initialize the Primary Component on one cluster node. For servers that use "" ""``init``, run the following command:"" msgstr """" #: ../controller-ha-galera-manage.rst:49 msgid """" ""Once the database server starts, check the cluster status using the "" ""``wsrep_cluster_size`` status variable. From the database client, run the "" ""following command:"" msgstr """" #: ../controller-ha-galera-manage.rst:63 msgid """" ""Start the database server on all other cluster nodes. For servers that use "" ""``init``, run the following command:"" msgstr """" #: ../controller-ha-galera-manage.rst:76 msgid """" ""When you have all cluster nodes started, log into the database client on one "" ""of them and check the ``wsrep_cluster_size`` status variable again."" msgstr """" #: ../controller-ha-galera-manage.rst:90 msgid """" ""When each cluster node starts, it checks the IP addresses given to the "" ""``wsrep_cluster_address`` parameter and attempts to establish network "" ""connectivity with a database server running there. Once it establishes a "" ""connection, it attempts to join the Primary Component, requesting a state "" ""transfer as needed to bring itself into sync with the cluster."" msgstr """" #: ../controller-ha-galera-manage.rst:97 msgid """" ""In the event that you need to restart any cluster node, you can do so. When "" ""the database server comes back it, it establishes connectivity with the "" ""Primary Component and updates itself to any changes it may have missed while "" ""down."" msgstr """" #: ../controller-ha-galera-manage.rst:104 msgid ""Restarting the cluster"" msgstr """" #: ../controller-ha-galera-manage.rst:106 msgid """" ""Individual cluster nodes can stop and be restarted without issue. When a "" ""database loses its connection or restarts, Galera Cluster brings it back "" ""into sync once it reestablishes connection with the Primary Component. In "" ""the event that you need to restart the entire cluster, identify the most "" ""advanced cluster node and initialize the Primary Component on that node."" msgstr """" #: ../controller-ha-galera-manage.rst:113 msgid """" ""To find the most advanced cluster node, you need to check the sequence "" ""numbers, or seqnos, on the last committed transaction for each. You can find "" ""this by viewing ``grastate.dat`` file in database directory,"" msgstr """" #: ../controller-ha-galera-manage.rst:127 msgid """" ""Alternatively, if the database server is running, use the "" ""``wsrep_last_committed`` status variable:"" msgstr """" #: ../controller-ha-galera-manage.rst:140 msgid """" ""This value increments with each transaction, so the most advanced node has "" ""the highest sequence number, and therefore is the most up to date."" msgstr """" #: ../controller-ha-galera-manage.rst:145 msgid ""Configuration tips"" msgstr """" #: ../controller-ha-galera-manage.rst:149 msgid ""Deployment strategies"" msgstr """" #: ../controller-ha-galera-manage.rst:151 msgid ""Galera can be configured using one of the following strategies:"" msgstr """" #: ../controller-ha-galera-manage.rst:154 msgid ""Each instance has its own IP address;"" msgstr """" #: ../controller-ha-galera-manage.rst:156 msgid """" ""OpenStack services are configured with the list of these IP addresses so "" ""they can select one of the addresses from those available."" msgstr """" #: ../controller-ha-galera-manage.rst:160 msgid ""Galera runs behind HAProxy."" msgstr """" #: ../controller-ha-galera-manage.rst:162 msgid """" ""HAProxy load balances incoming requests and exposes just one IP address for "" ""all the clients."" msgstr """" #: ../controller-ha-galera-manage.rst:165 msgid """" ""Galera synchronous replication guarantees a zero slave lag. The failover "" ""procedure completes once HAProxy detects that the active back end has gone "" ""down and switches to the backup one, which is then marked as 'UP'. If no "" ""back ends are up (in other words, the Galera cluster is not ready to accept "" ""connections), the failover procedure finishes only when the Galera cluster "" ""has been successfully reassembled. The SLA is normally no more than 5 "" ""minutes."" msgstr """" #: ../controller-ha-galera-manage.rst:174 msgid """" ""Use MySQL/Galera in active/passive mode to avoid deadlocks on ``SELECT ... "" ""FOR UPDATE`` type queries (used, for example, by nova and neutron). This "" ""issue is discussed more in the following:"" msgstr """" #: ../controller-ha-galera-manage.rst:178 msgid ""http://lists.openstack.org/pipermail/openstack-dev/2014-May/035264.html"" msgstr """" #: ../controller-ha-galera-manage.rst:179 msgid ""http://www.joinfu.com/"" msgstr """" #: ../controller-ha-galera-manage.rst:181 msgid """" ""Of these options, the second one is highly recommended. Although Galera "" ""supports active/active configurations, we recommend active/passive (enforced "" ""by the load balancer) in order to avoid lock contention."" msgstr """" #: ../controller-ha-galera-manage.rst:188 msgid ""Configuring HAProxy"" msgstr """" #: ../controller-ha-galera-manage.rst:190 msgid """" ""If you use HAProxy for load-balancing client access to Galera Cluster as "" ""described in the :doc:`controller-ha-haproxy`, you can use the "" ""``clustercheck`` utility to improve health checks."" msgstr """" #: ../controller-ha-galera-manage.rst:194 msgid """" ""Create a configuration file for ``clustercheck`` at ``/etc/sysconfig/"" ""clustercheck``:"" msgstr """" #: ../controller-ha-galera-manage.rst:204 msgid """" ""Log in to the database client and grant the ``clustercheck`` user "" ""``PROCESS`` privileges."" msgstr """" #: ../controller-ha-galera-manage.rst:214 msgid """" ""You only need to do this on one cluster node. Galera Cluster replicates the "" ""user to all the others."" msgstr """" #: ../controller-ha-galera-manage.rst:217 msgid """" ""Create a configuration file for the HAProxy monitor service, at ``/etc/"" ""xinetd.d/galera-monitor``:"" msgstr """" #: ../controller-ha-galera-manage.rst:239 msgid """" ""Start the ``xinetd`` daemon for ``clustercheck``. For servers that use "" ""``init``, run the following commands:"" msgstr """" #: ../controller-ha-galera-manage.rst:247 msgid ""For servers that use ``systemd``, instead run these commands:"" msgstr """" #: ../controller-ha-galera.rst:2 msgid ""Database (Galera Cluster)"" msgstr """" #: ../controller-ha-galera.rst:4 msgid """" ""The first step is to install the database that sits at the heart of the "" ""cluster. To implement high availability, run an instance of the database on "" ""each controller node and use Galera Cluster to provide replication between "" ""them. Galera Cluster is a synchronous multi-master database cluster, based "" ""on MySQL and the InnoDB storage engine. It is a high-availability service "" ""that provides high system uptime, no data loss, and scalability for growth."" msgstr """" #: ../controller-ha-galera.rst:11 msgid """" ""You can achieve high availability for the OpenStack database in many "" ""different ways, depending on the type of database that you want to use. "" ""There are three implementations of Galera Cluster available to you:"" msgstr """" #: ../controller-ha-galera.rst:15 msgid """" ""`Galera Cluster for MySQL <http://galeracluster.com/>`_ The MySQL reference "" ""implementation from Codership, Oy;"" msgstr """" #: ../controller-ha-galera.rst:17 msgid """" ""`MariaDB Galera Cluster <https://mariadb.org/>`_ The MariaDB implementation "" ""of Galera Cluster, which is commonly supported in environments based on Red "" ""Hat distributions;"" msgstr """" #: ../controller-ha-galera.rst:20 msgid """" ""`Percona XtraDB Cluster <http://www.percona.com/>`_ The XtraDB "" ""implementation of Galera Cluster from Percona."" msgstr """" #: ../controller-ha-galera.rst:23 msgid """" ""In addition to Galera Cluster, you can also achieve high availability "" ""through other database options, such as PostgreSQL, which has its own "" ""replication system."" msgstr """" #: ../controller-ha-haproxy.rst:3 msgid ""HAProxy"" msgstr """" #: ../controller-ha-haproxy.rst:5 msgid """" ""HAProxy provides a fast and reliable HTTP reverse proxy and load balancer "" ""for TCP or HTTP applications. It is particularly suited for web crawling "" ""under very high loads while needing persistence or Layer 7 processing. It "" ""realistically supports tens of thousands of connections with recent hardware."" msgstr """" #: ../controller-ha-haproxy.rst:11 msgid """" ""Each instance of HAProxy configures its front end to accept connections only "" ""from the virtual IP (VIP) address and to terminate them as a list of all "" ""instances of the corresponding service under load balancing, such as any "" ""OpenStack API service."" msgstr """" #: ../controller-ha-haproxy.rst:16 msgid """" ""This makes the instances of HAProxy act independently and fail over "" ""transparently together with the network endpoints (VIP addresses) failover "" ""and, therefore, shares the same SLA."" msgstr """" #: ../controller-ha-haproxy.rst:20 msgid """" ""You can alternatively use a commercial load balancer, which is a hardware or "" ""software. A hardware load balancer generally has good performance."" msgstr """" #: ../controller-ha-haproxy.rst:23 msgid """" ""For detailed instructions about installing HAProxy on your nodes, see its "" ""`official documentation <http://www.haproxy.org/#docs>`_."" msgstr """" #: ../controller-ha-haproxy.rst:28 msgid """" ""HAProxy should not be a single point of failure. It is advisable to have "" ""multiple HAProxy instances running, where the number of these instances is a "" ""small odd number like 3 or 5. You need to ensure its availability by other "" ""means, such as Keepalived or Pacemaker."" msgstr """" #: ../controller-ha-haproxy.rst:34 msgid """" ""The common practice is to locate an HAProxy instance on each OpenStack "" ""controller in the environment."" msgstr """" #: ../controller-ha-haproxy.rst:37 msgid """" ""Once configured (see example file below), add HAProxy to the cluster and "" ""ensure the VIPs can only run on machines where HAProxy is active:"" msgstr """" # #-#-#-#-# controller-ha-haproxy.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-pacemaker.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-haproxy.rst:40 ../controller-ha-pacemaker.rst:564 msgid ""``pcs``"" msgstr """" # #-#-#-#-# controller-ha-haproxy.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-pacemaker.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-haproxy.rst:48 ../controller-ha-pacemaker.rst:555 msgid ""``crmsh``"" msgstr """" #: ../controller-ha-haproxy.rst:50 msgid ""TBA"" msgstr """" #: ../controller-ha-haproxy.rst:53 msgid ""Example Config File"" msgstr """" #: ../controller-ha-haproxy.rst:55 msgid """" ""Here is an example ``/etc/haproxy/haproxy.cfg`` configuration file. You need "" ""a copy of it on each controller node."" msgstr """" #: ../controller-ha-haproxy.rst:60 msgid """" ""To implement any changes made to this you must restart the HAProxy service"" msgstr """" #: ../controller-ha-haproxy.rst:218 msgid """" ""The Galera cluster configuration directive ``backup`` indicates that two of "" ""the three controllers are standby nodes. This ensures that only one node "" ""services write requests because OpenStack support for multi-node writes is "" ""not yet production-ready."" msgstr """" #: ../controller-ha-haproxy.rst:225 msgid """" ""The Telemetry API service configuration does not have the ``option httpchk`` "" ""directive as it cannot process this check properly. TODO: explain why the "" ""Telemetry API is so special"" msgstr """" #: ../controller-ha-haproxy.rst:229 msgid """" ""[TODO: we need more commentary about the contents and format of this file]"" msgstr """" #: ../controller-ha-keystone.rst:4 msgid ""Identity services (keystone)"" msgstr """" #: ../controller-ha-keystone.rst:6 msgid """" ""OpenStack Identity (keystone) is the Identity service in OpenStack that is "" ""used by many services. You should be familiar with `OpenStack identity "" ""concepts <http://docs.openstack.org/liberty/install-guide-ubuntu/common/"" ""get_started_identity.html>`_ before proceeding."" msgstr """" #: ../controller-ha-keystone.rst:13 msgid """" ""Making the OpenStack Identity service highly available in active / passive "" ""mode involves:"" msgstr """" #: ../controller-ha-keystone.rst:16 msgid "":ref:`keystone-pacemaker`"" msgstr """" #: ../controller-ha-keystone.rst:17 msgid "":ref:`keystone-config-identity`"" msgstr """" #: ../controller-ha-keystone.rst:18 msgid "":ref:`keystone-services-config`"" msgstr """" #: ../controller-ha-keystone.rst:23 msgid ""Add OpenStack Identity resource to Pacemaker"" msgstr """" #: ../controller-ha-keystone.rst:25 msgid """" ""You must first download the OpenStack Identity resource to Pacemaker by "" ""running the following commands:"" msgstr """" #: ../controller-ha-keystone.rst:36 msgid """" ""You can now add the Pacemaker configuration for the OpenStack Identity "" ""resource by running the :command:`crm configure` command to connect to the "" ""Pacemaker cluster. Add the following cluster resources:"" msgstr """" #: ../controller-ha-keystone.rst:52 msgid """" ""This configuration creates ``p_keystone``, a resource for managing the "" ""OpenStack Identity service.""#: ../controller-ha-keystone.rst:83""The ``admin_bind_host`` parameter lets you use a private network for admin "" ""access.""#: ../controller-ha-keystone.rst:86 msgid """" ""To be sure that all data is highly available, ensure that everything is "" ""stored in the MySQL database (which is also highly available):""#: ../controller-ha-keystone.rst:103 msgid """" ""Configure OpenStack services to use the highly available OpenStack Identity""#: ../controller-ha-keystone.rst:105 msgid """" ""Your OpenStack services must now point their OpenStack Identity "" ""configuration to the highly available virtual cluster IP address rather than "" ""point to the physical IP address of an OpenStack Identity server as you "" ""would do in a non-HA environment.""""address is 10.0.0.11, use the following configuration in your :file:`api-"" ""paste.ini` file:""#: ../controller-ha-keystone.rst:120""You also need to create the OpenStack Identity Endpoint with this IP address.""""virtual IP addresses and define your endpoint like this:""#: ../controller-ha-keystone.rst:139# #-#-#-#-# controller-ha-memcached.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# intro-ha-arch-pacemaker.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-memcached.rst:3 ../intro-ha-arch-pacemaker.rst:179 msgid ""Memcached"" msgstr """" #: ../controller-ha-memcached.rst:5""Memcached is a general-purpose distributed memory caching system. It is used "" ""to speed up dynamic database-driven websites by caching data and objects in "" ""RAM to reduce the number of times an external data source must be read.""#: ../controller-ha-memcached.rst:10""services to store ephemeral data, such as tokens.""#: ../controller-ha-memcached.rst:13""Access to memcached is not handled by HAproxy because replicated access is "" ""currently only in an experimental state. Instead OpenStack services must be "" ""supplied with the full list of hosts running memcached.""#: ../controller-ha-memcached.rst:18""The Memcached client implements hashing to balance objects among the "" ""instances. Failure of an instance only impacts a percentage of the objects "" ""and the client automatically removes it from the list of instances. The SLA "" ""is several minutes.""#: ../controller-ha-pacemaker.rst:3#: ../controller-ha-pacemaker.rst:5""`Pacemaker <http://clusterlabs.org/>`_ cluster stack is the state-of-the-art "" ""high availability and load balancing stack for the Linux platform. Pacemaker "" ""is useful to make OpenStack infrastructure highly available. Also, it is "" ""storage and application-agnostic, and in no way specific to OpenStack.""#: ../controller-ha-pacemaker.rst:11#: ../controller-ha-pacemaker.rst:18 msgid """" ""Pacemaker does not inherently (need or want to) understand the applications "" ""it manages. Instead, it relies on resource agents (RAs), scripts that "" ""encapsulate the knowledge of how to start, stop, and check the health of "" ""each application managed by the cluster."" msgstr """" #: ../controller-ha-pacemaker.rst:23 msgid """" ""These agents must conform to one of the `OCF <https://github.com/"" ""ClusterLabs/ OCF-spec/blob/master/ra/resource-agent-api.md>`_, `SysV Init "" ""<http://refspecs.linux-foundation.org/LSB_3.0.0/LSB-Core-generic/ LSB-Core-"" ""generic/iniscrptact.html>`_, Upstart, or Systemd standards."" msgstr """" #: ../controller-ha-pacemaker.rst:28#: ../controller-ha-pacemaker.rst:34 msgid ""The steps to implement the Pacemaker cluster stack are:"" msgstr """" #: ../controller-ha-pacemaker.rst:36 msgid "":ref:`pacemaker-install`"" msgstr """" #: ../controller-ha-pacemaker.rst:37 msgid "":ref:`pacemaker-corosync-setup`"" msgstr """" #: ../controller-ha-pacemaker.rst:38 msgid "":ref:`pacemaker-corosync-start`"" msgstr """" #: ../controller-ha-pacemaker.rst:39 msgid "":ref:`pacemaker-start`"" msgstr """" #: ../controller-ha-pacemaker.rst:40 msgid "":ref:`pacemaker-cluster-properties`"" msgstr """" #: ../controller-ha-pacemaker.rst:45 msgid ""Install packages"" msgstr """" #: ../controller-ha-pacemaker.rst:47""On any host that is meant to be part of a Pacemaker cluster, you must first "" ""establish cluster communications through the Corosync messaging layer. This "" ""involves installing the following packages (and their dependencies, which "" ""your package manager usually installs automatically):""#: ../controller-ha-pacemaker.rst:54 msgid ""pacemaker""#: ../controller-ha-pacemaker.rst:56 msgid ""pcs (CentOS or RHEL) or crmsh""#: ../controller-ha-pacemaker.rst:58 msgid ""corosync""#: ../controller-ha-pacemaker.rst:60 msgid ""fence-agents (CentOS or RHEL) or cluster-glue""#: ../controller-ha-pacemaker.rst:62 msgid ""resource-agents""#: ../controller-ha-pacemaker.rst:64 msgid ""libqb0""#: ../controller-ha-pacemaker.rst:69 msgid ""Set up the cluster with `pcs`""#: ../controller-ha-pacemaker.rst:71 msgid ""Make sure pcs is running and configured to start at boot time:""#: ../controller-ha-pacemaker.rst:73 msgid "":command:`systemctl enable pcsd`""msgid "":command:`systemctl start pcsd`""#: ../controller-ha-pacemaker.rst:76 msgid ""Set a password for hacluster user **on each host**."" msgstr """" #: ../controller-ha-pacemaker.rst:78 msgid """" ""Since the cluster is a single administrative domain, it is generally "" ""accepted to use the same password on all nodes."" msgstr """" #: ../controller-ha-pacemaker.rst:81 msgid """" "":command:`echo my-secret-password-no-dont-use-this-one | passwd --stdin "" ""hacluster`"" msgstr """" #: ../controller-ha-pacemaker.rst:84 msgid """" ""Use that password to authenticate to the nodes which will make up the "" ""cluster. The :option:`-p` option is used to give the password on command "" ""line and makes it easier to script."" msgstr """" #: ../controller-ha-pacemaker.rst:88 msgid """" "":command:`pcs cluster auth controller1 controller2 controller3 -u hacluster -"" ""p my-secret-password-no-dont-use-this-one --force`"" msgstr """" #: ../controller-ha-pacemaker.rst:91 msgid ""Create the cluster, giving it a name, and start it:"" msgstr """" #: ../controller-ha-pacemaker.rst:93 msgid """" "":command:`pcs cluster setup --force --name my-first-openstack-cluster "" ""controller1 controller2 controller3`"" msgstr """" #: ../controller-ha-pacemaker.rst:95 msgid "":command:`pcs cluster start --all`"" msgstr """" #: ../controller-ha-pacemaker.rst:99 msgid """" ""In Red Hat Enterprise Linux or CentOS environments, this is a recommended "" ""path to perform configuration. For more information, see the `RHEL docs "" ""<https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/7/"" ""html/High_Availability_Add-On_Reference/ch-clusteradmin-HAAR.html#s1-"" ""clustercreate-HAAR>`_."" msgstr """" #: ../controller-ha-pacemaker.rst:104 msgid ""Set up the cluster with `crmsh`"" msgstr """" #: ../controller-ha-pacemaker.rst:106 msgid """" ""After installing the Corosync package, you must create the :file:`/etc/"" ""corosync/corosync.conf` configuration file."" msgstr """" #: ../controller-ha-pacemaker.rst:110 msgid """" ""For Ubuntu, you should also enable the Corosync service in the ``/etc/"" ""default/corosync`` configuration file."" msgstr """" #: ../controller-ha-pacemaker.rst:113 msgid """" ""Corosync can be configured to work with either multicast or unicast IP "" ""addresses or to use the votequorum library."" msgstr """" #: ../controller-ha-pacemaker.rst:117 msgid "":ref:`corosync-multicast`"" msgstr """" #: ../controller-ha-pacemaker.rst:118 msgid "":ref:`corosync-unicast`"" msgstr """" #: ../controller-ha-pacemaker.rst:119 msgid "":ref:`corosync-votequorum`"" msgstr """" #: ../controller-ha-pacemaker.rst:124#: ../controller-ha-pacemaker.rst:126""Most distributions ship an example configuration file (:file:`corosync.conf."" ""example`) as part of the documentation bundled with the Corosync package. An "" ""example Corosync configuration file is shown below:""#: ../controller-ha-pacemaker.rst:131 msgid ""**Example Corosync configuration file for multicast (corosync.conf)**""#: ../controller-ha-pacemaker.rst:202 ../controller-ha-pacemaker.rst:329 #: ../controller-ha-pacemaker.rst:413 ../controller-ha-pacemaker.rst:573 msgid ""Note the following:""#: ../controller-ha-pacemaker.rst:204#: ../controller-ha-pacemaker.rst:220 msgid """" ""With ``secauth`` enabled, Corosync nodes mutually authenticate using a 128-"" ""byte shared secret stored in the :file:`/etc/corosync/authkey` file, which "" ""may be generated with the :command:`corosync-keygen` utility. When using "" ""``secauth``, cluster communications are also encrypted."" msgstr """" #: ../controller-ha-pacemaker.rst:226 msgid """" ""In Corosync configurations using redundant networking (with more than one "" ""interface), you must select a Redundant Ring Protocol (RRP) mode other than "" ""none. ``active`` is the recommended RRP mode."" msgstr """" #: ../controller-ha-pacemaker.rst:231 msgid ""Note the following about the recommended interface configuration:"" msgstr """" #: ../controller-ha-pacemaker.rst:233 msgid """" ""Each configured interface must have a unique ``ringnumber``, starting with 0."" msgstr """" #: ../controller-ha-pacemaker.rst:236 msgid """" ""The ``bindnetaddr`` is the network address of the interfaces to bind to. The "" ""example uses two network addresses of /24 IPv4 subnets."" msgstr """" #: ../controller-ha-pacemaker.rst:239 msgid """" ""Multicast groups (``mcastaddr``) must not be reused across cluster "" ""boundaries. In other words, no two distinct clusters should ever use the "" ""same multicast group. Be sure to select multicast addresses compliant with "" ""`RFC 2365, \""Administratively Scoped IP Multicast\"" <http://www.ietf.org/rfc/"" ""rfc2365.txt>`_."" msgstr """" #: ../controller-ha-pacemaker.rst:247 msgid """" ""For firewall configurations, note that Corosync communicates over UDP only, "" ""and uses ``mcastport`` (for receives) and ``mcastport - 1`` (for sends)."" msgstr """" #: ../controller-ha-pacemaker.rst:252 msgid """" ""The service declaration for the pacemaker service may be placed in the :file:"" ""`corosync.conf` file directly or in its own separate file, :file:`/etc/"" ""corosync/service.d/pacemaker`."" msgstr """" #: ../controller-ha-pacemaker.rst:258 msgid """" ""If you are using Corosync version 2 on Ubuntu 14.04, remove or comment out "" ""lines under the service stanza, which enables Pacemaker to start up. Another "" ""potential problem is the boot and shutdown order of Corosync and Pacemaker. "" ""To force Pacemaker to start after Corosync and stop before Corosync, fix the "" ""start and kill symlinks manually:"" msgstr """" #: ../controller-ha-pacemaker.rst:269 msgid """" ""The Pacemaker service also requires an additional configuration file ``/etc/"" ""corosync/uidgid.d/pacemaker`` to be created with the following content:"" msgstr """" #: ../controller-ha-pacemaker.rst:280 msgid """" ""Once created, the :file:`corosync.conf` file (and the :file:`authkey` file "" ""if the secauth option is enabled) must be synchronized across all cluster "" ""nodes."" msgstr """" #: ../controller-ha-pacemaker.rst:287 msgid ""Set up Corosync with unicast"" msgstr """" #: ../controller-ha-pacemaker.rst:289 msgid """" ""For environments that do not support multicast, Corosync should be "" ""configured for unicast. An example fragment of the :file:`corosync.conf` "" ""file for unicastis shown below:"" msgstr """" #: ../controller-ha-pacemaker.rst:294 msgid ""**Corosync configuration file fragment for unicast (corosync.conf)**"" msgstr """" #: ../controller-ha-pacemaker.rst:331 msgid """" ""If the ``broadcast`` parameter is set to yes, the broadcast address is used "" ""for communication. If this option is set, the ``mcastaddr`` parameter should "" ""not be set."" msgstr """" #: ../controller-ha-pacemaker.rst:335#: ../controller-ha-pacemaker.rst:344 msgid """" ""Within the ``nodelist`` directive, it is possible to specify specific "" ""information about the nodes in the cluster. The directive can contain only "" ""the node sub-directive, which specifies every node that should be a member "" ""of the membership, and where non-default options are needed. Every node must "" ""have at least the ``ring0_addr`` field filled."" msgstr """" #: ../controller-ha-pacemaker.rst:354 msgid """" ""For UDPU, every node that should be a member of the membership must be "" ""specified."" msgstr """" #: ../controller-ha-pacemaker.rst:357 msgid ""Possible options are:"" msgstr """" #: ../controller-ha-pacemaker.rst:359 msgid """" ""``ring{X}_addr`` specifies the IP address of one of the nodes. {X} is the "" ""ring number."" msgstr """" #: ../controller-ha-pacemaker.rst:362 msgid """" ""``nodeid`` is optional when using IPv4 and required when using IPv6. This is "" ""a 32-bit value specifying the node identifier delivered to the cluster "" ""membership service. If this is not specified with IPv4, the node id is "" ""determined from the 32-bit IP address of the system to which the system is "" ""bound with ring identifier of 0. The node identifier value of zero is "" ""reserved and should not be used."" msgstr """" #: ../controller-ha-pacemaker.rst:375 msgid ""Set up Corosync with votequorum library"" msgstr """" #: ../controller-ha-pacemaker.rst:377 msgid """" ""The votequorum library is part of the corosync project. It provides an "" ""interface to the vote-based quorum service and it must be explicitly enabled "" ""in the Corosync configuration file. The main role of votequorum library is "" ""to avoid split-brain situations, but it also provides a mechanism to:"" msgstr """" #: ../controller-ha-pacemaker.rst:383 msgid ""Query the quorum status"" msgstr """" #: ../controller-ha-pacemaker.rst:385 msgid ""Get a list of nodes known to the quorum service"" msgstr """" #: ../controller-ha-pacemaker.rst:387 msgid ""Receive notifications of quorum state changes"" msgstr """" #: ../controller-ha-pacemaker.rst:389 msgid ""Change the number of votes assigned to a node"" msgstr """" #: ../controller-ha-pacemaker.rst:391 msgid ""Change the number of expected votes for a cluster to be quorate"" msgstr """" #: ../controller-ha-pacemaker.rst:393 msgid """" ""Connect an additional quorum device to allow small clusters remain quorate "" ""during node outages"" msgstr """" #: ../controller-ha-pacemaker.rst:396 msgid """" ""The votequorum library has been created to replace and eliminate qdisk, the "" ""disk-based quorum daemon for CMAN, from advanced cluster configurations."" msgstr """" #: ../controller-ha-pacemaker.rst:400 msgid """" ""A sample votequorum service configuration in the :file:`corosync.com` file "" ""is:"" msgstr """" #: ../controller-ha-pacemaker.rst:415 msgid """" ""Specifying ``corosync_votequorum`` enables the votequorum library; this is "" ""the only required option."" msgstr """" #: ../controller-ha-pacemaker.rst:418 msgid """" ""The cluster is fully operational with ``expected_votes`` set to 7 nodes "" ""(each node has 1 vote), quorum: 4. If a list of nodes is specified as "" ""``nodelist``, the ``expected_votes`` value is ignored."" msgstr """" #: ../controller-ha-pacemaker.rst:423 msgid """" ""Setting ``wait_for_all`` to 1 means that, When starting up a cluster (all "" ""nodes down), the cluster quorum is held until all nodes are online and have "" ""joined the cluster for the first time. This parameter is new in Corosync 2.0."" msgstr """" #: ../controller-ha-pacemaker.rst:429 msgid """" ""Setting ``last_man_standing`` to 1 enables the Last Man Standing (LMS) "" ""feature; by default, it is disabled (set to 0). If a cluster is on the "" ""quorum edge (``expected_votes:`` set to 7; ``online nodes:`` set to 4) for "" ""longer than the time specified for the ``last_man_standing_window`` "" ""parameter, the cluster can recalculate quorum and continue operating even if "" ""the next node will be lost. This logic is repeated until the number of "" ""online nodes in the cluster reaches 2. In order to allow the cluster to step "" ""down from 2 members to only 1, the ``auto_tie_breaker`` parameter needs to "" ""be set; this is not recommended for production environments."" msgstr """" #: ../controller-ha-pacemaker.rst:444 msgid """" ""``last_man_standing_window`` specifies the time, in milliseconds, required "" ""to recalculate quorum after one or most hosts have been lost from the "" ""cluster. To do the new quorum recalculation, the cluster must have quorum "" ""for at least the interval specified for ``last_man_standing_window``; the "" ""default is 10000ms."" msgstr """" #: ../controller-ha-pacemaker.rst:456 msgid ""Start Corosync"" msgstr """" #: ../controller-ha-pacemaker.rst:458 msgid """" ""Corosync is started as a regular system service. Depending on your "" ""distribution, it may ship with an LSB init script, an upstart job, or a "" ""systemd unit file. Either way, the service is usually named corosync:"" msgstr """" #: ../controller-ha-pacemaker.rst:463 msgid "":command:`# /etc/init.d/corosync start` (LSB)"" msgstr """" #: ../controller-ha-pacemaker.rst:465 msgid "":command:`# service corosync start` (LSB, alternate)"" msgstr """" #: ../controller-ha-pacemaker.rst:467 msgid "":command:`# start corosync (upstart)`"" msgstr """" #: ../controller-ha-pacemaker.rst:469 msgid "":command:`# systemctl start corosync (systemd)`"" msgstr """" #: ../controller-ha-pacemaker.rst:471 msgid ""You can now check the Corosync connectivity with two tools."" msgstr """" #: ../controller-ha-pacemaker.rst:473 msgid """" ""Use the :command:`corosync-cfgtool` utility with the :option:`-s` option to "" ""get a summary of the health of the communication rings:"" msgstr """" #: ../controller-ha-pacemaker.rst:488 msgid """" ""Use the :command:`corosync-objctl` utility to dump the Corosync cluster "" ""member list:"" msgstr """" #: ../controller-ha-pacemaker.rst:501 msgid """" ""You should see a ``status=joined`` entry for each of your constituent "" ""cluster nodes."" msgstr """" #: ../controller-ha-pacemaker.rst:504 msgid """" ""[TODO: Should the main example now use corosync-cmapctl and have the note "" ""give the command for Corosync version 1?]"" msgstr """" #: ../controller-ha-pacemaker.rst:509 msgid """" ""If you are using Corosync version 2, use the :command:`corosync-cmapctl` "" ""utility instead of :command:`corosync-objctl`; it is a direct replacement."" msgstr """" #: ../controller-ha-pacemaker.rst:515 msgid ""Start Pacemaker"" msgstr """" #: ../controller-ha-pacemaker.rst:517 msgid """" ""After the Corosync services have been started and you have verified that the "" ""cluster is communicating properly, you can start :command:`pacemakerd`, the "" ""Pacemaker master control process:"" msgstr """" #: ../controller-ha-pacemaker.rst:521 msgid "":command:`# /etc/init.d/pacemaker start` (LSB)"" msgstr """" #: ../controller-ha-pacemaker.rst:523 msgid "":command:`# service pacemaker start` (LSB, alternate)"" msgstr """" #: ../controller-ha-pacemaker.rst:525 msgid "":command:`# start pacemaker` (upstart)"" msgstr """" #: ../controller-ha-pacemaker.rst:527 msgid "":command:`# systemctl start pacemaker` (systemd)"" msgstr """" #: ../controller-ha-pacemaker.rst:529 msgid """" ""After the Pacemaker services have started, Pacemaker creates a default empty "" ""cluster configuration with no resources. Use the :command:`crm_mon` utility "" ""to observe the status of Pacemaker:"" msgstr """" #: ../controller-ha-pacemaker.rst:550 msgid ""Set basic cluster properties"" msgstr """" #: ../controller-ha-pacemaker.rst:552 msgid """" ""After you set up your Pacemaker cluster, you should set a few basic cluster "" ""properties:"" msgstr """" #: ../controller-ha-pacemaker.rst:575 msgid """" ""Setting the ``pe-warn-series-max``, ``pe-input-series-max`` and ``pe-error-"" ""series-max`` parameters to 1000 instructs Pacemaker to keep a longer history "" ""of the inputs processed and errors and warnings generated by its Policy "" ""Engine. This history is useful if you need to troubleshoot the cluster."" msgstr """" #: ../controller-ha-pacemaker.rst:581 msgid """" ""Pacemaker uses an event-driven approach to cluster state processing. The "" ""``cluster-recheck-interval`` parameter (which defaults to 15 minutes) "" ""defines the interval at which certain Pacemaker actions occur. It is usually "" ""prudent to reduce this to a shorter interval, such as 5 or 3 minutes."" msgstr """" #: ../controller-ha-pacemaker.rst:587 msgid ""After you make these changes, you may commit the updated configuration."" msgstr """" #: ../controller-ha-rabbitmq.rst:0 ../controller-ha-rabbitmq.rst:76 msgid ""Install RabbitMQ"" msgstr """" # #-#-#-#-# controller-ha-rabbitmq.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# intro-ha-arch-pacemaker.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-rabbitmq.rst:3 ../intro-ha-arch-pacemaker.rst:178 msgid ""RabbitMQ"" msgstr """" #: ../controller-ha-rabbitmq.rst:5 msgid """" ""An AMQP (Advanced Message Queuing Protocol) compliant message bus is "" ""required for most OpenStack components in order to coordinate the execution "" ""of jobs entered into the system."" msgstr """" #: ../controller-ha-rabbitmq.rst:9 msgid """" ""The most popular AMQP implementation used in OpenStack installations is "" ""RabbitMQ."" msgstr """" #: ../controller-ha-rabbitmq.rst:12 msgid """" ""RabbitMQ nodes fail over both on the application and the infrastructure "" ""layers."" msgstr """" #: ../controller-ha-rabbitmq.rst:15 msgid """" ""The application layer is controlled by the ``oslo.messaging`` configuration "" ""options for multiple AMQP hosts. If the AMQP node fails, the application "" ""reconnects to the next one configured within the specified reconnect "" ""interval. The specified reconnect interval constitutes its SLA."" msgstr """" #: ../controller-ha-rabbitmq.rst:21 msgid """" ""On the infrastructure layer, the SLA is the time for which RabbitMQ cluster "" ""reassembles. Several cases are possible. The Mnesia keeper node is the "" ""master of the corresponding Pacemaker resource for RabbitMQ; when it fails, "" ""the result is a full AMQP cluster downtime interval. Normally, its SLA is no "" ""more than several minutes. Failure of another node that is a slave of the "" ""corresponding Pacemaker resource for RabbitMQ results in no AMQP cluster "" ""downtime at all."" msgstr """" #: ../controller-ha-rabbitmq.rst:29 msgid """" ""Making the RabbitMQ service highly available involves the following steps:"" msgstr """" #: ../controller-ha-rabbitmq.rst:31 msgid "":ref:`Install RabbitMQ<rabbitmq-install>`"" msgstr """" #: ../controller-ha-rabbitmq.rst:33 msgid "":ref:`Configure RabbitMQ for HA queues<rabbitmq-configure>`"" msgstr """" #: ../controller-ha-rabbitmq.rst:35 msgid """" "":ref:`Configure OpenStack services to use Rabbit HA queues <rabbitmq-"" ""services>`"" msgstr """" #: ../controller-ha-rabbitmq.rst:40 msgid """" ""Access to RabbitMQ is not normally handled by HAproxy. Instead, consumers "" ""must be supplied with the full list of hosts running RabbitMQ with "" ""``rabbit_hosts`` and turn on the ``rabbit_ha_queues`` option."" msgstr """" #: ../controller-ha-rabbitmq.rst:45 msgid """" ""Jon Eck found the `core issue <http://people.redhat.com/jeckersb/private/vip-"" ""failover-tcp-persist.html>`_ and went into some detail regarding the "" ""`history and solution <http://john.eckersberg.com/improving-ha-failures-with-"" ""tcp-timeouts.html>`_ on his blog."" msgstr """" #: ../controller-ha-rabbitmq.rst:51 msgid ""In summary though:"" msgstr """" #: ../controller-ha-rabbitmq.rst:53 msgid """" ""The source address for the connection from HAProxy back to the client is the "" ""VIP address. However the VIP address is no longer present on the host. This "" ""means that the network (IP) layer deems the packet unroutable, and informs "" ""the transport (TCP) layer. TCP, however, is a reliable transport. It knows "" ""how to handle transient errors and will retry. And so it does."" msgstr """" #: ../controller-ha-rabbitmq.rst:60 msgid ""In this case that is a problem though, because:"" msgstr """" #: ../controller-ha-rabbitmq.rst:62 msgid """" ""TCP generally holds on to hope for a long time. A ballpark estimate is "" ""somewhere on the order of tens of minutes (30 minutes is commonly "" ""referenced). During this time it will keep probing and trying to deliver the "" ""data."" msgstr """" #: ../controller-ha-rabbitmq.rst:67 msgid """" ""It is important to note that HAProxy has no idea that any of this is "" ""happening. As far as its process is concerned, it called ``write()`` with "" ""the data and the kernel returned success. The resolution is already "" ""understood and just needs to make its way through a review."" msgstr """" #: ../controller-ha-rabbitmq.rst:78 msgid """" ""The commands for installing RabbitMQ are specific to the Linux distribution "" ""you are using:"" msgstr """" #: ../controller-ha-rabbitmq.rst:85 msgid ""Distribution"" msgstr """" #: ../controller-ha-rabbitmq.rst:86 msgid ""Command"" msgstr """" #: ../controller-ha-rabbitmq.rst:87 msgid ""Ubuntu, Debian"" msgstr """" #: ../controller-ha-rabbitmq.rst:88 msgid "":command:`# apt-get install rabbitmq-server`"" msgstr """" #: ../controller-ha-rabbitmq.rst:89 msgid ""RHEL, Fedora, CentOS"" msgstr """" #: ../controller-ha-rabbitmq.rst:90 msgid "":command:`# yum install rabbitmq-server`"" msgstr """" #: ../controller-ha-rabbitmq.rst:91 msgid ""openSUSE"" msgstr """" #: ../controller-ha-rabbitmq.rst:92 ../controller-ha-rabbitmq.rst:98 msgid "":command:`# zypper install rabbitmq-server`"" msgstr """" #: ../controller-ha-rabbitmq.rst:93 msgid ""SLES 12"" msgstr """" #: ../controller-ha-rabbitmq.rst:94 msgid "":command:`# zypper addrepo -f obs://Cloud:OpenStack:Kilo/SLE_12 Kilo`"" msgstr """" #: ../controller-ha-rabbitmq.rst:96 msgid ""[Verify fingerprint of imported GPG key; see below]"" msgstr """" #: ../controller-ha-rabbitmq.rst:103 msgid """" ""For SLES 12, the packages are signed by GPG key 893A90DAD85F9316. You should "" ""verify the fingerprint of the imported GPG key before using it."" msgstr """" #: ../controller-ha-rabbitmq.rst:114 msgid """" ""For more information, see the official installation manual for the "" ""distribution:"" msgstr """" #: ../controller-ha-rabbitmq.rst:117 msgid ""`Debian and Ubuntu <http://www.rabbitmq.com/install-debian.html>`_"" msgstr """" #: ../controller-ha-rabbitmq.rst:118 msgid """" ""`RPM based <http://www.rabbitmq.com/install-rpm.html>`_ (RHEL, Fedora, "" ""CentOS, openSUSE)"" msgstr """" #: ../controller-ha-rabbitmq.rst:124 msgid ""Configure RabbitMQ for HA queues"" msgstr """" #: ../controller-ha-rabbitmq.rst:126 msgid """" ""[TODO: This section should begin with a brief mention about what HA queues "" ""are and why they are valuable, etc]"" msgstr """" #: ../controller-ha-rabbitmq.rst:129 msgid """" ""We are building a cluster of RabbitMQ nodes to construct a RabbitMQ broker, "" ""which is a logical grouping of several Erlang nodes."" msgstr """" #: ../controller-ha-rabbitmq.rst:132 msgid ""The following components/services can work with HA queues:"" msgstr """" #: ../controller-ha-rabbitmq.rst:134 msgid ""[TODO: replace \""currently\"" with specific release names]"" msgstr """" #: ../controller-ha-rabbitmq.rst:136 msgid """" ""[TODO: Does this list need to be updated? Perhaps we need a table that shows "" ""each component and the earliest release that allows it to work with HA "" ""queues.]"" msgstr """" #: ../controller-ha-rabbitmq.rst:140 msgid ""OpenStack Compute"" msgstr """" #: ../controller-ha-rabbitmq.rst:141 msgid ""OpenStack Block Storage"" msgstr """" #: ../controller-ha-rabbitmq.rst:142 msgid ""OpenStack Networking"" msgstr """" # #-#-#-#-# controller-ha-rabbitmq.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-telemetry.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-rabbitmq.rst:143 ../controller-ha-telemetry.rst:4 msgid ""Telemetry"" msgstr """" #: ../controller-ha-rabbitmq.rst:145 msgid """" ""We have to consider that, while exchanges and bindings survive the loss of "" ""individual nodes, queues and their messages do not because a queue and its "" ""contents are located on one node. If we lose this node, we also lose the "" ""queue."" msgstr """" #: ../controller-ha-rabbitmq.rst:151 msgid """" ""Mirrored queues in RabbitMQ improve the availability of service since it is "" ""resilient to failures."" msgstr """" #: ../controller-ha-rabbitmq.rst:154 msgid """" ""Production servers should run (at least) three RabbitMQ servers; for testing "" ""and demonstration purposes, it is possible to run only two servers. In this "" ""section, we configure two nodes, called ``rabbit1`` and ``rabbit2``. To "" ""build a broker, we need to ensure that all nodes have the same Erlang cookie "" ""file."" msgstr """" #: ../controller-ha-rabbitmq.rst:162 msgid ""[TODO: Should the example instead use a minimum of three nodes?]"" msgstr """" #: ../controller-ha-rabbitmq.rst:164 msgid """" ""To do so, stop RabbitMQ everywhere and copy the cookie from the first node "" ""to each of the other node(s):"" msgstr """" #: ../controller-ha-rabbitmq.rst:171 msgid """" ""On each target node, verify the correct owner, group, and permissions of the "" ""file :file:`erlang.cookie`."" msgstr """" #: ../controller-ha-rabbitmq.rst:179 msgid ""Start RabbitMQ on all nodes and verify that the nodes are running:"" msgstr """" #: ../controller-ha-rabbitmq.rst:190 msgid ""Run the following commands on each node except the first one:"" msgstr """" #: ../controller-ha-rabbitmq.rst:204 msgid """" ""The default node type is a disc node. In this guide, nodes join the cluster "" ""as RAM nodes."" msgstr """" #: ../controller-ha-rabbitmq.rst:207 msgid ""To verify the cluster status:"" msgstr """" #: ../controller-ha-rabbitmq.rst:216 msgid """" ""If the cluster is working, you can create usernames and passwords for the "" ""queues."" msgstr """" #: ../controller-ha-rabbitmq.rst:219 msgid """" ""To ensure that all queues except those with auto-generated names are "" ""mirrored across all running nodes, set the ``ha-mode`` policy key to all by "" ""running the following command on one of the nodes:"" msgstr """" #: ../controller-ha-rabbitmq.rst:228 msgid ""More information is available in the RabbitMQ documentation:"" msgstr """" #: ../controller-ha-rabbitmq.rst:230 msgid ""`Highly Available Queues <http://www.rabbitmq.com/ha.html>`_"" msgstr """" #: ../controller-ha-rabbitmq.rst:231 msgid ""`Clustering Guide <https://www.rabbitmq.com/clustering.html>`_"" msgstr """" #: ../controller-ha-rabbitmq.rst:235 msgid """" ""As another option to make RabbitMQ highly available, RabbitMQ contains the "" ""OCF scripts for the Pacemaker cluster resource agents since version 3.5.7. "" ""It provides the active/active RabbitMQ cluster with mirrored queues. For "" ""more information, see `Auto-configuration of a cluster with a Pacemaker "" ""<http://www.rabbitmq.com/pacemaker.html>`_."" msgstr """" #: ../controller-ha-rabbitmq.rst:244 msgid ""Configure OpenStack services to use Rabbit HA queues"" msgstr """" #: ../controller-ha-rabbitmq.rst:246 msgid """" ""We have to configure the OpenStack components to use at least two RabbitMQ "" ""nodes."" msgstr """" #: ../controller-ha-rabbitmq.rst:249 msgid ""Do this configuration on all services using RabbitMQ:"" msgstr """" #: ../controller-ha-rabbitmq.rst:251 msgid ""RabbitMQ HA cluster host:port pairs:"" msgstr """" #: ../controller-ha-rabbitmq.rst:257 msgid """" ""How frequently to retry connecting with RabbitMQ: [TODO: document the unit "" ""of measure here? Seconds?]"" msgstr """" #: ../controller-ha-rabbitmq.rst:264 msgid """" ""How long to back-off for between retries when connecting to RabbitMQ: [TODO: "" ""document the unit of measure here? Seconds?]"" msgstr """" #: ../controller-ha-rabbitmq.rst:271 msgid """" ""Maximum retries with trying to connect to RabbitMQ (infinite by default):"" msgstr """" #: ../controller-ha-rabbitmq.rst:277 msgid ""Use durable queues in RabbitMQ:"" msgstr """" #: ../controller-ha-rabbitmq.rst:283 msgid ""Use HA queues in RabbitMQ (x-ha-policy: all):"" msgstr """" #: ../controller-ha-rabbitmq.rst:291 msgid """" ""If you change the configuration from an old set-up that did not use HA "" ""queues, you should restart the service:"" msgstr """" #: ../controller-ha-telemetry.rst:6 msgid ""[TODO (Add Telemetry overview)]"" msgstr """" #: ../controller-ha-telemetry.rst:9 msgid ""Telemetry central agent"" msgstr """" #: ../controller-ha-telemetry.rst:11 msgid """" ""The Telemetry central agent can be configured to partition its polling "" ""workload between multiple agents, enabling high availability."" msgstr """" #: ../controller-ha-telemetry.rst:14 msgid """" ""Both the central and the compute agent can run in an HA deployment, which "" ""means that multiple instances of these services can run in parallel with "" ""workload partitioning among these running instances."" msgstr """" #: ../controller-ha-telemetry.rst:18 msgid """" ""The `Tooz <https://pypi.python.org/pypi/tooz>`__ library provides the "" ""coordination within the groups of service instances. It provides an API "" ""above several back ends that can be used for building distributed "" ""applications."" msgstr """" #: ../controller-ha-telemetry.rst:23 msgid """" ""Tooz supports `various drivers <http://docs.openstack.org/developer/tooz/"" ""drivers.html>`__ including the following back end solutions:"" msgstr """" #: ../controller-ha-telemetry.rst:28 ../controller-ha-telemetry.rst:31 msgid ""Recommended solution by the Tooz project."" msgstr """" #: ../controller-ha-telemetry.rst:28 msgid ""`Zookeeper <http://zookeeper.apache.org/>`__."" msgstr """" #: ../controller-ha-telemetry.rst:31 msgid ""`Redis <http://redis.io/>`__."" msgstr """" #: ../controller-ha-telemetry.rst:34 msgid ""Recommended for testing."" msgstr """" #: ../controller-ha-telemetry.rst:34 msgid ""`Memcached <http://memcached.org/>`__."" msgstr """" #: ../controller-ha-telemetry.rst:36 msgid """" ""You must configure a supported Tooz driver for the HA deployment of the "" ""Telemetry services."" msgstr """" #: ../controller-ha-telemetry.rst:39 msgid """" ""For information about the required configuration options that have to be set "" ""in the :file:`ceilometer.conf` configuration file for both the central and "" ""compute agents, see the `coordination section <http://docs.openstack.org/"" ""liberty/config-reference/content/ ch_configuring-openstack-telemetry."" ""html>`__ in the OpenStack Configuration Reference."" msgstr """" #: ../controller-ha-telemetry.rst:46 msgid """" ""Without the ``backend_url`` option being set only one instance of both the "" ""central and compute agent service is able to run and function correctly."" msgstr """" #: ../controller-ha-telemetry.rst:54 msgid """" ""Memcached uses a timeout value, which should always be set to a value that "" ""is higher than the heartbeat value set for Telemetry."" msgstr """" #: ../controller-ha-telemetry.rst:57 msgid """" ""For backward compatibility and supporting existing deployments, the central "" ""agent configuration also supports using different configuration files for "" ""groups of service instances of this type that are running in parallel. For "" ""enabling this configuration, set a value for the partitioning_group_prefix "" ""option in the `central section <http://docs.openstack.org/liberty/ config-"" ""reference/content/ch_configuring-openstack-telemetry.html>`__ in the "" ""OpenStack Configuration Reference."" msgstr """" #: ../controller-ha-telemetry.rst:65 msgid """" ""For each sub-group of the central agent pool with the same "" ""``partitioning_group_prefix`` a disjoint subset of meters must be polled -- "" ""otherwise samples may be missing or duplicated. The list of meters to poll "" ""can be set in the :file:`/etc/ceilometer/pipeline.yaml` configuration file. "" ""For more information about pipelines see the `Data collection and processing "" ""<http://docs.openstack.org/admin-guide-cloud/telemetry-data-collection."" ""html#data-collection-and-processing>`__ section."" msgstr """" #: ../controller-ha-telemetry.rst:74 msgid """" ""To enable the compute agent to run multiple instances simultaneously with "" ""workload partitioning, the workload_partitioning option has to be set to "" ""``True`` under the `compute section <http://docs.openstack.org/liberty/ "" ""config-reference/content/ch_configuring-openstack-telemetry.html>`__ in the :"" ""file:`ceilometer.conf` configuration file."" msgstr """" #: ../controller-ha-vip.rst:4 msgid ""Configure the VIP"" msgstr """" #: ../controller-ha-vip.rst:6 msgid """" ""You must select and assign a virtual IP address (VIP) that can freely float "" ""between cluster nodes."" msgstr """" #: ../controller-ha-vip.rst:9 msgid """" ""This configuration creates ``vip``, a virtual IP address for use by the API "" ""node (``10.0.0.11``):"" msgstr """" #: ../controller-ha-vip.rst:12 msgid ""For ``crmsh``:"" msgstr """" #: ../controller-ha-vip.rst:19 msgid ""For ``pcs``:"" msgstr """" #: ../controller-ha.rst:4 msgid ""Configuring the controller for high availability"" msgstr """" #: ../hardware-ha-basic.rst:4 msgid ""Hardware setup""#: ../hardware-ha-basic.rst:8""`Provider networks <http://docs.openstack.org/liberty/install-guide-ubuntu/"" ""overview.html#networking-option-1-provider-networks>`_""#: ../hardware-ha-basic.rst:9""`Self-service networks <http://docs.openstack.org/liberty/install-guide-"" ""ubuntu/overview.html#networking-option-2-self-service-networks>`_""#: ../hardware-ha-basic.rst:11""However, OpenStack does not require a significant amount of resources and "" ""the following minimum requirements should support a proof-of-concept high "" ""availability environment with core services and several instances:""#: ../hardware-ha-basic.rst:16 msgid ""[TODO: Verify that these numbers are good]"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Memory"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""NIC"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Node type"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Processor"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Storage"" msgstr """" #: ../hardware-ha-basic.rst:21 msgid ""1-2"" msgstr """" #: ../hardware-ha-basic.rst:21 msgid ""100 GB"" msgstr """" #: ../hardware-ha-basic.rst:21 ../hardware-ha-basic.rst:23 msgid ""2"" msgstr """" #: ../hardware-ha-basic.rst:21 msgid ""8 GB"" msgstr """" #: ../hardware-ha-basic.rst:21 msgid ""controller node"" msgstr """" #: ../hardware-ha-basic.rst:23 msgid ""100+ GB"" msgstr """" #: ../hardware-ha-basic.rst:23 msgid ""2-4+"" msgstr """" #: ../hardware-ha-basic.rst:23 msgid ""8+ GB"" msgstr """" #: ../hardware-ha-basic.rst:23 msgid ""compute node"" msgstr """" #: ../hardware-ha-basic.rst:27""For demonstrations and studying, you can set up a test environment on "" ""virtual machines (VMs). This has the following benefits:""#: ../hardware-ha-basic.rst:31""One physical server can support multiple nodes, each of which supports "" ""almost any number of network interfaces.""#: ../hardware-ha-basic.rst:34""Ability to take periodic \""snap shots\"" throughout the installation process "" ""and \""roll back\"" to a working configuration in the event of a problem.""#: ../hardware-ha-basic.rst:37""However, running an OpenStack environment on VMs degrades the performance of "" ""your instances, particularly if your hypervisor and/or processor lacks "" ""support for hardware acceleration of nested VMs.""#: ../hardware-ha-basic.rst:44""When installing highly-available OpenStack on VMs, be sure that your "" ""hypervisor permits promiscuous mode and disables MAC address filtering on "" ""the external network.""#: ../hardware-ha.rst:4 msgid ""Hardware considerations for high availability"" msgstr """" #: ../hardware-ha.rst:6 msgid """" ""[TODO: Provide a minimal architecture example for HA, expanded on that given "" ""in http://docs.openstack.org/liberty/install-guide-ubuntu/environment.html "" ""for easy comparison]"" msgstr """" #: ../index.rst:3 msgid ""OpenStack High Availability Guide"" msgstr """" #: ../index.rst:6 msgid ""Abstract"" msgstr """" #: ../index.rst:8 msgid """" ""This guide describes how to install and configure OpenStack for high "" ""availability. It supplements the OpenStack Installation Guides and assumes "" ""that you are familiar with the material in those guides."" msgstr """" #: ../index.rst:13 msgid """" ""This guide documents OpenStack Liberty, OpenStack Kilo, and OpenStack Juno "" ""releases."" msgstr """" #: ../index.rst:16 msgid """" ""This guide is a work-in-progress and changing rapidly while we continue to "" ""test and enhance the guidance. Please note where there are open \""to do\"" "" ""items and help where you are able."" msgstr """" #: ../index.rst:21 msgid ""Contents"" msgstr """" #: ../index.rst:41 msgid ""Search in this guide"" msgstr """" #: ../index.rst:43 msgid "":ref:`search`"" msgstr """" #: ../install-ha-memcached.rst:4 msgid ""Install memcached"" msgstr """" #: ../install-ha-memcached.rst:6 msgid """" ""[TODO: Verify that Oslo supports hash synchronization; if so, this should "" ""not take more than load balancing.]"" msgstr """" #: ../install-ha-memcached.rst:9 msgid """" ""[TODO: This hands off to two different docs for install information. We "" ""should choose one or explain the specific purpose of each.]"" msgstr """" #: ../install-ha-memcached.rst:12 msgid """" ""Most OpenStack services can use memcached to store ephemeral data such as "" ""tokens. Although memcached does not support typical forms of redundancy such "" ""as clustering, OpenStack services can use almost any number of instances by "" ""configuring multiple hostnames or IP addresses. The memcached client "" ""implements hashing to balance objects among the instances. Failure of an "" ""instance only impacts a percentage of the objects and the client "" ""automatically removes it from the list of instances."" msgstr """" #: ../install-ha-memcached.rst:23 msgid """" ""To install and configure memcached, read the `official documentation "" ""<https://code.google.com/p/memcached/wiki/NewStart>`_."" msgstr """" #: ../install-ha-memcached.rst:26 msgid """" ""Memory caching is managed by `oslo.cache <http://specs.openstack.org/"" ""openstack/oslo-specs/specs/kilo/oslo-cache-using-dogpile.html>`_ so the way "" ""to use multiple memcached servers is the same for all projects."" msgstr """" #: ../install-ha-memcached.rst:30 msgid ""[TODO: Should this show three hosts?]"" msgstr """" #: ../install-ha-memcached.rst:32 msgid ""Example configuration with two hosts:"" msgstr """" #: ../install-ha-memcached.rst:38 msgid """" ""By default, `controller1` handles the caching service but, if the host goes "" ""down, `controller2` does the job. For more information about memcached "" ""installation, see the `OpenStack Cloud Administrator Guide <http://docs."" ""openstack.org/admin-guide-cloud/>`_."" msgstr """" #: ../install-ha-ntp.rst:3 msgid ""Configure NTP"" msgstr """" #: ../install-ha-ntp.rst:5 msgid """" ""You must configure NTP to properly synchronize services among nodes. We "" ""recommend that you configure the controller node to reference more accurate "" ""(lower stratum) servers and other nodes to reference the controller node. "" ""For more information, see the `Install Guides <http://docs.openstack.org/"" ""#install-guides>`_."" msgstr """" #: ../install-ha-os.rst:3 msgid ""Install operating system on each node"" msgstr """" #: ../install-ha-os.rst:5 msgid """" ""The first step in setting up your highly-available OpenStack cluster is to "" ""install the operating system on each node. Follow the instructions in the "" ""OpenStack Installation Guides:"" msgstr """" #: ../install-ha-os.rst:9 msgid """" ""`CentOS and RHEL <http://docs.openstack.org/liberty/install-guide-rdo/"" ""environment.html>`_"" msgstr """" #: ../install-ha-os.rst:10 msgid """" ""`openSUSE and SUSE Linux Enterprise Server <http://docs.openstack.org/"" ""liberty/install-guide-obs/environment.html>`_"" msgstr """" #: ../install-ha-os.rst:11 msgid """" ""`Ubuntu <http://docs.openstack.org/liberty/install-guide-ubuntu/environment."" ""html>`_"" msgstr """" #: ../install-ha-os.rst:13 msgid """" ""The OpenStack Installation Guides also include a list of the services that "" ""use passwords with important notes about using them."" msgstr """" #: ../install-ha-os.rst:16 msgid ""This guide uses the following example IP addresses:"" msgstr """" #: ../install-ha.rst:3 msgid ""Installing high availability packages"" msgstr """" #: ../install-ha.rst:5 msgid ""[TODO -- write intro to this section]"" msgstr """" #: ../intro-ha-arch-keepalived.rst:3 msgid ""The keepalived architecture"" msgstr """" #: ../intro-ha-arch-keepalived.rst:6 msgid ""High availability strategies"" msgstr """" #: ../intro-ha-arch-keepalived.rst:8 msgid """" ""The following diagram shows a very simplified view of the different "" ""strategies used to achieve high availability for the OpenStack services:"" msgstr """" #: ../intro-ha-arch-keepalived.rst:15 msgid """" ""Depending on the method used to communicate with the service, the following "" ""availability strategies will be followed:"" msgstr """" #: ../intro-ha-arch-keepalived.rst:18 msgid ""Keepalived, for the HAProxy instances."" msgstr """" #: ../intro-ha-arch-keepalived.rst:19 msgid """" ""Access via an HAProxy virtual IP, for services such as HTTPd that are "" ""accessed via a TCP socket that can be load balanced"" msgstr """" #: ../intro-ha-arch-keepalived.rst:21 msgid """" ""Built-in application clustering, when available from the application. Galera "" ""is one example of this."" msgstr """" #: ../intro-ha-arch-keepalived.rst:23 msgid """" ""Starting up one instance of the service on several controller nodes, when "" ""they can coexist and coordinate by other means. RPC in ``nova-conductor`` is "" ""one example of this."" msgstr """" #: ../intro-ha-arch-keepalived.rst:26 msgid """" ""No high availability, when the service can only work in active/passive mode."" msgstr """" #: ../intro-ha-arch-keepalived.rst:29 msgid """" ""There are known issues with cinder-volume that recommend setting it as "" ""active-passive for now, see: https://blueprints.launchpad.net/cinder/+spec/"" ""cinder-volume-active-active-support"" msgstr """" #: ../intro-ha-arch-keepalived.rst:33 msgid """" ""While there will be multiple neutron LBaaS agents running, each agent will "" ""manage a set of load balancers, that cannot be failed over to another node."" msgstr """" #: ../intro-ha-arch-keepalived.rst:38 msgid ""Architecture limitations"" msgstr """" #: ../intro-ha-arch-keepalived.rst:40 msgid """" ""This architecture has some inherent limitations that should be kept in mind "" ""during deployment and daily operations. The following sections describe "" ""these limitations."" msgstr """" #: ../intro-ha-arch-keepalived.rst:44 msgid ""Keepalived and network partitions"" msgstr """" #: ../intro-ha-arch-keepalived.rst:46 msgid """" ""In case of a network partitioning, there is a chance that two or more nodes "" ""running keepalived claim to hold the same VIP, which may lead to an "" ""undesired behaviour. Since keepalived uses VRRP over multicast to elect a "" ""master (VIP owner), a network partition in which keepalived nodes cannot "" ""communicate will result in the VIPs existing on two nodes. When the network "" ""partition is resolved, the duplicate VIPs should also be resolved. Note that "" ""this network partition problem with VRRP is a known limitation for this "" ""architecture."" msgstr """" #: ../intro-ha-arch-keepalived.rst:56 msgid ""Cinder-volume as a single point of failure"" msgstr """" #: ../intro-ha-arch-keepalived.rst:58 msgid """" ""There are currently concerns over the cinder-volume service ability to run "" ""as a fully active-active service. During the Mitaka timeframe, this is being "" ""worked on, see: https://blueprints.launchpad.net/cinder/+spec/cinder-volume-"" ""active-active-support Thus, cinder-volume will only be running on one of the "" ""controller nodes, even if it will be configured on all nodes. In case of a "" ""failure in the node running cinder-volume, it should be started in a "" ""surviving controller node."" msgstr """" #: ../intro-ha-arch-keepalived.rst:67 msgid ""Neutron-lbaas-agent as a single point of failure"" msgstr """" #: ../intro-ha-arch-keepalived.rst:69 msgid """" ""The current design of the neutron LBaaS agent using the HAProxy driver does "" ""not allow high availability for the tenant load balancers. The neutron-lbaas-"" ""agent service will be enabled and running on all controllers, allowing for "" ""load balancers to be distributed across all nodes. However, a controller "" ""node failure will stop all load balancers running on that node until the "" ""service is recovered or the load balancer is manually removed and created "" ""again."" msgstr """" #: ../intro-ha-arch-keepalived.rst:78 msgid ""Service monitoring and recovery required"" msgstr """" #: ../intro-ha-arch-keepalived.rst:80 msgid """" ""An external service monitoring infrastructure is required to check the "" ""OpenStack service health, and notify operators in case of any failure. This "" ""architecture does not provide any facility for that, so it would be "" ""necessary to integrate the OpenStack deployment with any existing monitoring "" ""environment."" msgstr """" #: ../intro-ha-arch-keepalived.rst:86 msgid ""Manual recovery after a full cluster restart"" msgstr """" #: ../intro-ha-arch-keepalived.rst:88 msgid """" ""Some support services used by RDO or RHEL OSP use their own form of "" ""application clustering. Usually, these services maintain a cluster quorum, "" ""that may be lost in case of a simultaneous restart of all cluster nodes, for "" ""example during a power outage. Each service will require its own procedure "" ""to regain quorum."" msgstr """" #: ../intro-ha-arch-keepalived.rst:94 msgid """" ""If you find any or all of these limitations concerning, you are encouraged "" ""to refer to the :doc:`Pacemaker HA architecture<intro-ha-arch-pacemaker>` "" ""instead."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:3 msgid ""The Pacemaker architecture"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:6 msgid ""What is a cluster manager"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:8 msgid """" ""At its core, a cluster is a distributed finite state machine capable of co-"" ""ordinating the startup and recovery of inter-related services across a set "" ""of machines."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:12 msgid """" ""Even a distributed and/or replicated application that is able to survive "" ""failures on one or more machines can benefit from a cluster manager:"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:16 msgid ""Awareness of other applications in the stack"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:18 msgid """" ""While SYS-V init replacements like systemd can provide deterministic "" ""recovery of a complex stack of services, the recovery is limited to one "" ""machine and lacks the context of what is happening on other machines - "" ""context that is crucial to determine the difference between a local failure, "" ""clean startup and recovery after a total site failure."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:25 msgid ""Awareness of instances on other machines"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:27 msgid """" ""Services like RabbitMQ and Galera have complicated boot-up sequences that "" ""require co-ordination, and often serialization, of startup operations across "" ""all machines in the cluster. This is especially true after site-wide failure "" ""or shutdown where we must first determine the last machine to be active."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:33 msgid """" ""A shared implementation and calculation of `quorum <http://en.wikipedia.org/"" ""wiki/Quorum_(Distributed_Systems)>`_."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:36 msgid """" ""It is very important that all members of the system share the same view of "" ""who their peers are and whether or not they are in the majority. Failure to "" ""do this leads very quickly to an internal `split-brain <http://en.wikipedia."" ""org/wiki/Split-brain_(computing)>`_ state - where different parts of the "" ""system are pulling in different and incompatible directions."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:43 msgid """" ""Data integrity through fencing (a non-responsive process does not imply it "" ""is not doing anything)"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:46 msgid """" ""A single application does not have sufficient context to know the difference "" ""between failure of a machine and failure of the applcation on a machine. The "" ""usual practice is to assume the machine is dead and carry on, however this "" ""is highly risky - a rogue process or machine could still be responding to "" ""requests and generally causing havoc. The safer approach is to make use of "" ""remotely accessible power switches and/or network switches and SAN "" ""controllers to fence (isolate) the machine before continuing."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:55 msgid ""Automated recovery of failed instances"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:57 msgid """" ""While the application can still run after the failure of several instances, "" ""it may not have sufficient capacity to serve the required volume of "" ""requests. A cluster can automatically recover failed instances to prevent "" ""additional load induced failures."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:62 msgid """" ""For this reason, the use of a cluster manager like `Pacemaker <http://"" ""clusterlabs.org>`_ is highly recommended."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:66 msgid ""Deployment flavors"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:68 msgid """" ""It is possible to deploy three different flavors of the Pacemaker "" ""architecture. The two extremes are **Collapsed** (where every component runs "" ""on every node) and **Segregated** (where every component runs in its own 3+ "" ""node cluster)."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:73 msgid """" ""Regardless of which flavor you choose, it is recommended that the clusters "" ""contain at least three nodes so that we can take advantage of `quorum "" ""<quorum_>`_."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:77 msgid """" ""Quorum becomes important when a failure causes the cluster to split in two "" ""or more partitions. In this situation, you want the majority to ensure the "" ""minority are truly dead (through fencing) and continue to host resources. "" ""For a two-node cluster, no side has the majority and you can end up in a "" ""situation where both sides fence each other, or both sides are running the "" ""same services - leading to data corruption."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:84 msgid """" ""Clusters with an even number of hosts suffer from similar issues - a single "" ""network failure could easily cause a N:N split where neither side retains a "" ""majority. For this reason, we recommend an odd number of cluster members "" ""when scaling up."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:89 msgid """" ""You can have up to 16 cluster members (this is currently limited by the "" ""ability of corosync to scale higher). In extreme cases, 32 and even up to 64 "" ""nodes could be possible, however, this is not well tested."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:94 msgid ""Collapsed"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:96 msgid """" ""In this configuration, there is a single cluster of 3 or more nodes on which "" ""every component is running."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:99 msgid """" ""This scenario has the advantage of requiring far fewer, if more powerful, "" ""machines. Additionally, being part of a single cluster allows us to "" ""accurately model the ordering dependencies between components."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:104 msgid ""This scenario can be visualized as below."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:109 msgid """" ""You would choose this option if you prefer to have fewer but more powerful "" ""boxes."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:112 msgid ""This is the most common option and the one we document here."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:115 msgid ""Segregated"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:117 msgid """" ""In this configuration, each service runs in a dedicated cluster of 3 or more "" ""nodes."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:120 msgid """" ""The benefits of this approach are the physical isolation between components "" ""and the ability to add capacity to specific components."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:123 msgid """" ""You would choose this option if you prefer to have more but less powerful "" ""boxes."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:126 msgid """" ""This scenario can be visualized as below, where each box below represents a "" ""cluster of three or more guests."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:133 msgid ""Mixed"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:135 msgid """" ""It is also possible to follow a segregated approach for one or more "" ""components that are expected to be a bottleneck and use a collapsed approach "" ""for the remainder."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:141 msgid ""Proxy server"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:143 msgid """" ""Almost all services in this stack benefit from being proxied. Using a proxy "" ""server provides:"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:146 msgid ""Load distribution"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:148 msgid """" ""Many services can act in an active/active capacity, however, they usually "" ""require an external mechanism for distributing requests to one of the "" ""available instances. The proxy server can serve this role."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:153 msgid ""API isolation"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:155 msgid """" ""By sending all API access through the proxy, we can clearly identify service "" ""interdependencies. We can also move them to locations other than "" ""``localhost`` to increase capacity if the need arises."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:160 msgid ""Simplified process for adding/removing of nodes"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:162 msgid """" ""Since all API access is directed to the proxy, adding or removing nodes has "" ""no impact on the configuration of other services. This can be very useful in "" ""upgrade scenarios where an entirely new set of machines can be configured "" ""and tested in isolation before telling the proxy to direct traffic there "" ""instead."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:168 msgid ""Enhanced failure detection"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:170 msgid """" ""The proxy can be configured as a secondary mechanism for detecting service "" ""failures. It can even be configured to look for nodes in a degraded state "" ""(such as being 'too far' behind in the replication) and take them out of "" ""circulation."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:175 msgid """" ""The following components are currently unable to benefit from the use of a "" ""proxy server:"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:180 msgid ""MongoDB"" msgstr """" #: ../intro-ha-arch-pacemaker.rst:182 msgid """" ""However, the reasons vary and are discussed under each component's heading."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:185 msgid """" ""We recommend HAProxy as the load balancer, however, there are many "" ""alternatives in the marketplace."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:188 msgid """" ""We use a check interval of 1 second, however, the timeouts vary by service."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:190 msgid """" ""Generally, we use round-robin to distribute load amongst instances of active/"" ""active services, however, Galera uses the ``stick-table`` options to ensure "" ""that incoming connections to the virtual IP (VIP) should be directed to only "" ""one of the available back ends."" msgstr """" #: ../intro-ha-arch-pacemaker.rst:195 msgid """" ""In Galera's case, although it can run active/active, this helps avoid lock "" ""contention and prevent deadlocks. It is used in combination with the "" ""``httpchk`` option that ensures only nodes that are in sync with its peers "" ""are allowed to handle requests."" msgstr """" #: ../intro-ha-compute.rst:4 msgid ""Overview of highly-available compute nodes"" msgstr """" #: ../intro-ha-concepts.rst:3 msgid ""High availability concepts"" msgstr """" #: ../intro-ha-concepts.rst:5 msgid ""High availability systems seek to minimize two things:"" msgstr """" #: ../intro-ha-concepts.rst:8 msgid """" ""Occurs when a user-facing service is unavailable beyond a specified maximum "" ""amount of time."" msgstr """" #: ../intro-ha-concepts.rst:9 msgid ""**System downtime**"" msgstr """" #: ../intro-ha-concepts.rst:12 msgid ""**Data loss**"" msgstr """" #: ../intro-ha-concepts.rst:12 msgid ""Accidental deletion or destruction of data."" msgstr """" #: ../intro-ha-concepts.rst:14 msgid """" ""Most high availability systems guarantee protection against system downtime "" ""and data loss only in the event of a single failure. However, they are also "" ""expected to protect against cascading failures, where a single failure "" ""deteriorates into a series of consequential failures. Many service providers "" ""guarantee :term:`Service Level Agreement (SLA)` including uptime percentage "" ""of computing service, which is calculated based on the available time and "" ""system downtime excluding planned outage time."" msgstr """" #: ../intro-ha-concepts.rst:23 msgid ""Redundancy and failover"" msgstr """" #: ../intro-ha-concepts.rst:25 msgid """" ""High availability is implemented with redundant hardware running redundant "" ""instances of each service. If one piece of hardware running one instance of "" ""a service fails, the system can then failover to use another instance of a "" ""service that is running on hardware that did not fail."" msgstr """" #: ../intro-ha-concepts.rst:31 msgid """" ""A crucial aspect of high availability is the elimination of single points of "" ""failure (SPOFs). A SPOF is an individual piece of equipment or software that "" ""causes system downtime or data loss if it fails. In order to eliminate "" ""SPOFs, check that mechanisms exist for redundancy of:"" msgstr """" #: ../intro-ha-concepts.rst:37 msgid ""Network components, such as switches and routers"" msgstr """" #: ../intro-ha-concepts.rst:39 msgid ""Applications and automatic service migration"" msgstr """" #: ../intro-ha-concepts.rst:41 msgid ""Storage components"" msgstr """" #: ../intro-ha-concepts.rst:43 msgid ""Facility services such as power, air conditioning, and fire protection"" msgstr """" #: ../intro-ha-concepts.rst:45 msgid """" ""In the event that a component fails and a back-up system must take on its "" ""load, most high availability systems will replace the failed component as "" ""quickly as possible to maintain necessary redundancy. This way time spent in "" ""a degraded protection state is minimized."" msgstr """" #: ../intro-ha-concepts.rst:50 msgid """" ""Most high availability systems fail in the event of multiple independent "" ""(non-consequential) failures. In this case, most implementations favor "" ""protecting data over maintaining availability."" msgstr """" #: ../intro-ha-concepts.rst:54 msgid """" ""High availability systems typically achieve an uptime percentage of 99.99% "" ""or more, which roughly equates to less than an hour of cumulative downtime "" ""per year. In order to achieve this, high availability systems should keep "" ""recovery times after a failure to about one to two minutes, sometimes "" ""significantly less."" msgstr """" #: ../intro-ha-concepts.rst:60 msgid """" ""OpenStack currently meets such availability requirements for its own "" ""infrastructure services, meaning that an uptime of 99.99% is feasible for "" ""the OpenStack infrastructure proper. However, OpenStack does not guarantee "" ""99.99% availability for individual guest instances."" msgstr """" #: ../intro-ha-concepts.rst:65#: ../intro-ha-concepts.rst:77 msgid ""Stateless vs. stateful services"" msgstr """" #: ../intro-ha-concepts.rst:79""Preventing single points of failure can depend on whether or not a service "" ""is stateless.""#: ../intro-ha-concepts.rst:83""A service that provides a response after your request and then requires no "" ""further attention. To make a stateless service highly available, you need to "" ""provide redundant instances and load balance them. OpenStack services that "" ""are stateless include ``nova-api``, ``nova-conductor``, ``glance-api``, "" ""``keystone-api``, ``neutron-api`` and ``nova-scheduler``.""#: ../intro-ha-concepts.rst:89 msgid ""Stateless service"" msgstr """" #: ../intro-ha-concepts.rst:92""A service where subsequent requests to the service depend on the results of "" ""the first request. Stateful services are more difficult to manage because a "" ""single action typically involves more than one request, so simply providing "" ""additional instances and load balancing does not solve the problem. For "" ""example, if the horizon user interface reset itself every time you went to a "" ""new page, it would not be very useful. OpenStack services that are stateful "" ""include the OpenStack database and message queue. Making stateful services "" ""highly available can depend on whether you choose an active/passive or "" ""active/active configuration.""#: ../intro-ha-concepts.rst:102 msgid ""Stateful service"" msgstr """" #: ../intro-ha-concepts.rst:105 msgid ""Active/Passive vs Active/Active"" msgstr """" #: ../intro-ha-concepts.rst:107 msgid ""Stateful services may be configured as active/passive or active/active:"" msgstr """" #: ../intro-ha-concepts.rst:110""Maintains a redundant instance that can be brought online when the active "" ""service fails. For example, OpenStack writes to the main database while "" ""maintaining a disaster recovery database that can be brought online if the "" ""main database fails.""#: ../intro-ha-concepts.rst:116""A typical active/passive installation for a stateful service maintains a "" ""replacement resource that can be brought online when required. Requests are "" ""handled using a :term:`virtual IP` address (VIP) that facilitates returning "" ""to service with minimal reconfiguration. A separate application (such as "" ""Pacemaker or Corosync) monitors these services, bringing the backup online "" ""as necessary.""#: ../intro-ha-concepts.rst:121 msgid "":term:`active/passive configuration`"" msgstr """" #: ../intro-ha-concepts.rst:124""Each service also has a backup but manages both the main and redundant "" ""systems concurrently. This way, if there is a failure, the user is unlikely "" ""to notice. The backup system is already online and takes on increased load "" ""while the main system is fixed and brought back online.""#: ../intro-ha-concepts.rst:130#: ../intro-ha-concepts.rst:134""A typical active/active installation for a stateful service includes "" ""redundant services, with all instances having an identical state. In other "" ""words, updates to one instance of a database update all other instances. "" ""This way a request to one instance is the same as a request to any other. A "" ""load balancer manages the traffic to these systems, ensuring that "" ""operational systems always handle the request.""#: ../intro-ha-concepts.rst:140 msgid "":term:`active/active configuration`""#: ../intro-ha-concepts.rst:143 msgid ""Clusters and quorums"" msgstr """" #: ../intro-ha-concepts.rst:145""The quorum specifies the minimal number of nodes that must be functional in "" ""a cluster of redundant nodes in order for the cluster to remain functional. "" ""When one node fails and failover transfers control to other nodes, the "" ""system must ensure that data and processes remain sane. To determine this, "" ""the contents of the remaining nodes are compared and, if there are "" ""discrepancies, a \""majority rules\"" algorithm is implemented.""#: ../intro-ha-concepts.rst:153""For this reason, each cluster in a high availability environment should have "" ""an odd number of nodes and the quorum is defined as more than a half of the "" ""nodes. If multiple nodes fail so that the cluster size falls below the "" ""quorum value, the cluster itself fails.""#: ../intro-ha-concepts.rst:159""For example, in a seven-node cluster, the quorum should be set to floor(7/2) "" ""+ 1 == 4. If quorum is four and four nodes fail simultaneously, the cluster "" ""itself would fail, whereas it would continue to function, if no more than "" ""three nodes fail. If split to partitions of three and four nodes "" ""respectively, the quorum of four nodes would continue to operate the "" ""majority partition and stop or fence the minority one (depending on the no-"" ""quorum-policy cluster configuration).""#: ../intro-ha-concepts.rst:167""And the quorum could also have been set to three, just as a configuration "" ""example.""#: ../intro-ha-concepts.rst:172""Note that setting the quorum to a value less than floor(n/2) + 1 is not "" ""recommended and would likely cause a split-brain in a face of network "" ""partitions.""#: ../intro-ha-concepts.rst:176""Then, for the given example when four nodes fail simultaneously, the cluster "" ""would continue to function as well. But if split to partitions of three and "" ""four nodes respectively, the quorum of three would have made both sides to "" ""attempt to fence the other and host resources. And without fencing enabled, "" ""it would go straight to running two copies of each resource.""#: ../intro-ha-concepts.rst:182""This is why setting the quorum to a value less than floor(n/2) + 1 is "" ""dangerous. However it may be required for some specific cases, like a "" ""temporary measure at a point it is known with 100% certainty that the other "" ""nodes are down.""#: ../intro-ha-concepts.rst:187#: ../intro-ha-concepts.rst:194 msgid ""Single-controller high availability mode"" msgstr """" #: ../intro-ha-concepts.rst:196""OpenStack supports a single-controller high availability mode that is "" ""managed by the services that manage highly available environments but is not "" ""actually highly available because no redundant controllers are configured to "" ""use for failover. This environment can be used for study and demonstration "" ""but is not appropriate for a production environment.""#: ../intro-ha-concepts.rst:203""It is possible to add controllers to such an environment to convert it into "" ""a truly highly available environment.""#: ../intro-ha-concepts.rst:207""High availability is not for every user. It presents some challenges. High "" ""availability may be too complex for databases or systems with large amounts "" ""of data. Replication can slow large systems down. Different setups have "" ""different prerequisites. Read the guidelines for each setup.""#: ../intro-ha-concepts.rst:213 msgid ""High availability is turned off as the default in OpenStack setups."" msgstr """" #: ../intro-ha-controller.rst:3 msgid ""Overview of highly-available controllers"" msgstr """" #: ../intro-ha-controller.rst:5""OpenStack is a set of multiple services exposed to the end users as HTTP(s) "" ""APIs. Additionally, for own internal usage OpenStack requires SQL database "" ""server and AMQP broker. The physical servers, where all the components are "" ""running are often called controllers. This modular OpenStack architecture "" ""allows to duplicate all the components and run them on different "" ""controllers. By making all the components redundant it is possible to make "" ""OpenStack highly-available.""#: ../intro-ha-controller.rst:14""In general we can divide all the OpenStack components into three categories:""#: ../intro-ha-controller.rst:16""OpenStack APIs, these are HTTP(s) stateless services written in python, easy "" ""to duplicate and mostly easy to load balance.""#: ../intro-ha-controller.rst:19""SQL relational database server provides stateful type consumed by other "" ""components. Supported databases are MySQL, MariaDB, and PostgreSQL. Making "" ""SQL database redundant is complex.""#: ../intro-ha-controller.rst:23"":term:`Advanced Message Queuing Protocol (AMQP)` provides OpenStack internal "" ""stateful communication service.""#: ../intro-ha-controller.rst:27 msgid ""Network components""#: ../intro-ha-controller.rst:29#: ../intro-ha-controller.rst:32""The configuration uses static routing without Virtual Router Redundancy "" ""Protocol (VRRP) or similar techniques implemented.""#: ../intro-ha-controller.rst:36""[TODO Need description of VIP failover inside Linux namespaces and expected "" ""SLA.]""#: ../intro-ha-controller.rst:39""See [TODO link] for more information about configuring networking for high "" ""availability.""#: ../intro-ha-controller.rst:43 msgid ""Common deployement architectures"" msgstr """" #: ../intro-ha-controller.rst:45 msgid ""There are primarily two HA architectures in use today."" msgstr """" #: ../intro-ha-controller.rst:47""One uses a cluster manager such as Pacemaker or Veritas to co-ordinate the "" ""actions of the various services across a set of machines. Since we are "" ""focused on FOSS, we will refer to this as the Pacemaker architecture.""#: ../intro-ha-controller.rst:52""The other is optimized for Active/Active services that do not require any "" ""inter-machine coordination. In this setup, services are started by your init "" ""system (systemd in most modern distributions) and a tool is used to move IP "" ""addresses between the hosts. The most common package for doing this is "" ""keepalived.""#: ../intro-ha-other.rst:4 msgid ""High availability for other components""#: ../intro-ha-storage.rst:3 msgid ""Overview of high availability storage""#: ../intro-ha-storage.rst:5""Making the Block Storage (cinder) API service highly available in active/"" ""passive mode involves:""#: ../intro-ha-storage.rst:8 msgid ""Configuring Block Storage to listen on the VIP address"" msgstr """" #: ../intro-ha-storage.rst:10""Managing the Block Storage API daemon with the Pacemaker cluster manager"" msgstr """" #: ../intro-ha-storage.rst:12 msgid ""Configuring OpenStack services to use this IP address"" msgstr """" #: ../intro-ha.rst:4 msgid ""Introduction to OpenStack high availability"" msgstr """" #: ../networking-ha-dhcp.rst:6 msgid ""Run neutron DHCP agent"" msgstr """" #: ../networking-ha-dhcp.rst:8 msgid """" ""The OpenStack Networking service has a scheduler that lets you run multiple "" ""agents across nodes; the DHCP agent can be natively highly available. To "" ""configure the number of DHCP agents per network, modify the "" ""``dhcp_agents_per_network`` parameter in the :file:`/etc/neutron/neutron."" ""conf` file. By default this is set to 1. To achieve high availability, "" ""assign more than one DHCP agent per network."" msgstr """" #: ../networking-ha-l3.rst:0 msgid ""/etc/neutron/neutron.conf parameters for high availability"" msgstr """" #: ../networking-ha-l3.rst:6 msgid ""Run neutron L3 agent"" msgstr """" #: ../networking-ha-l3.rst:8 msgid """" ""The neutron L3 agent is scalable, due to the scheduler that supports Virtual "" ""Router Redundancy Protocol (VRRP) to distribute virtual routers across "" ""multiple nodes. To enable high availability for configured routers, edit "" ""the :file:`/etc/neutron/neutron.conf` file to set the following values:"" msgstr """" #: ../networking-ha-l3.rst:19 msgid ""Parameter"" msgstr """" #: ../networking-ha-l3.rst:20 msgid ""Value"" msgstr """" #: ../networking-ha-l3.rst:21 msgid ""Description"" msgstr """" #: ../networking-ha-l3.rst:22 msgid ""l3_ha"" msgstr """" #: ../networking-ha-l3.rst:23 ../networking-ha-l3.rst:26 msgid ""True"" msgstr """" #: ../networking-ha-l3.rst:24 msgid ""All routers are highly available by default."" msgstr """" #: ../networking-ha-l3.rst:25 msgid ""allow_automatic_l3agent_failover"" msgstr """" #: ../networking-ha-l3.rst:27 msgid ""Set automatic L3 agent failover for routers"" msgstr """" #: ../networking-ha-l3.rst:28 msgid ""max_l3_agents_per_router"" msgstr """" #: ../networking-ha-l3.rst:29 ../networking-ha-l3.rst:32 msgid ""2 or more"" msgstr """" #: ../networking-ha-l3.rst:30 msgid ""Maximum number of network nodes to use for the HA router."" msgstr """" #: ../networking-ha-l3.rst:31 msgid ""min_l3_agents_per_router"" msgstr """" #: ../networking-ha-l3.rst:33 msgid """" ""Minimum number of network nodes to use for the HA router. A new router can "" ""be created only if this number of network nodes are available."" msgstr """" #: ../networking-ha-lbaas.rst:6 msgid ""Run neutron LBaaS agent"" msgstr """" #: ../networking-ha-lbaas.rst:8 msgid """" ""Currently, no native feature is provided to make the LBaaS agent highly "" ""available using the default plug-in HAProxy. A common way to make HAProxy "" ""highly available is to use the VRRP (Virtual Router Redundancy Protocol). "" ""Unfortunately, this is not yet implemented in the LBaaS HAProxy plug-in."" msgstr """" #: ../networking-ha-lbaas.rst:16 msgid ""[TODO: update this section.]"" msgstr """" #: ../networking-ha-metadata.rst:6 msgid ""Run neutron metadata agent"" msgstr """" #: ../networking-ha-metadata.rst:8 msgid """" ""No native feature is available to make this service highly available. At "" ""this time, the Active/Passive solution exists to run the neutron metadata "" ""agent in failover mode with Pacemaker.""#: ../networking-ha.rst:4 msgid ""OpenStack network nodes"" msgstr """" #: ../networking-ha.rst:6 msgid """" ""Configure networking on each node. The `Networking <http://docs.openstack."" ""org/liberty/install-guide-ubuntu/environment-networking.html>`_ section of "" ""the *Install Guide* includes basic information about configuring networking."" msgstr """" #: ../networking-ha.rst:12 msgid ""Notes from planning outline:"" msgstr """" #: ../networking-ha.rst:14 msgid """" ""Rather than configuring neutron here, we should simply mention physical "" ""network HA methods such as bonding and additional node/network requirements "" ""for L3HA and DVR for planning purposes."" msgstr """" #: ../networking-ha.rst:18 msgid """" ""Neutron agents shuld be described for active/active; deprecate single "" ""agent's instances case."" msgstr """" #: ../networking-ha.rst:20 msgid ""For Kilo and beyond, focus on L3HA and DVR."" msgstr """" #: ../networking-ha.rst:21 msgid """" ""Link to `Networking Guide <http://docs.openstack.org/networking-guide/>`_ "" ""for configuration details."" msgstr """" #: ../networking-ha.rst:24#: ../networking-ha.rst:29 msgid """" ""`LP1328922 <https://bugs.launchpad.net/openstack-manuals/+bug/1328922>` and "" ""`LP1349398 <https://bugs.launchpad.net/openstack-manuals/+bug/1349398>` are "" ""related.]"" msgstr """" #: ../networking-ha.rst:34 msgid ""OpenStack network nodes contain:"" msgstr """" #: ../networking-ha.rst:36 msgid "":ref:`Neutron DHCP agent<dhcp-agent>`"" msgstr """" #: ../networking-ha.rst:37 msgid """" ""Neutron L2 agent. Note that the L2 agent cannot be distributed and highly "" ""available. Instead, it must be installed on each data forwarding node to "" ""control the virtual network drivers such as Open vSwitch or Linux Bridge. "" ""One L2 agent runs per node and controls its virtual interfaces."" msgstr """" #: ../networking-ha.rst:43 msgid "":ref:`Neutron L3 agent<neutron-l3>`"" msgstr """" #: ../networking-ha.rst:44 msgid "":ref:`Neutron metadata agent<neutron-metadata>`"" msgstr """" #: ../networking-ha.rst:45 msgid "":ref:`Neutron LBaaS<neutron-lbaas>` (Load Balancing as a Service) agent"" msgstr """" #: ../noncore-ha.rst:4 msgid ""Configuring non-core components for high availability"" msgstr """" #: ../storage-ha-backend.rst:6 msgid ""Storage back end"" msgstr """" #: ../storage-ha-backend.rst:8 msgid """" ""Most of this guide concerns the control plane of high availability: ensuring "" ""that services continue to run even if a component fails. Ensuring that data "" ""is not lost is the data plane component of high availability; this is "" ""discussed here."" msgstr """" #: ../storage-ha-backend.rst:14 msgid ""An OpenStack environment includes multiple data pools for the VMs:"" msgstr """" #: ../storage-ha-backend.rst:16 msgid """" ""Ephemeral storage is allocated for an instance and is deleted when the "" ""instance is deleted. The Compute service manages ephemeral storage. By "" ""default, Compute stores ephemeral drives as files on local disks on the "" ""Compute node but Ceph RBD can instead be used as the storage back end for "" ""ephemeral storage."" msgstr """" #: ../storage-ha-backend.rst:24 msgid """" ""Persistent storage exists outside all instances. Two types of persistent "" ""storage are provided:"" msgstr """" #: ../storage-ha-backend.rst:27 msgid """" ""Block Storage service (cinder) can use LVM or Ceph RBD as the storage back "" ""end."" msgstr """" #: ../storage-ha-backend.rst:29 msgid """" ""Image service (glance) can use the Object Storage service (swift) or Ceph "" ""RBD as the storage back end."" msgstr """" #: ../storage-ha-backend.rst:33 msgid """" ""For more information about configuring storage back ends for the different "" ""storage options, see the `Cloud Administrator Guide <http://docs.openstack."" ""org/admin-guide-cloud/>`_.""""This section discusses ways to protect against data loss in your OpenStack "" ""environment.""#: ../storage-ha-backend.rst:41 msgid ""RAID drives""#: ../storage-ha-backend.rst:43""Configuring RAID on the hard drives that implement storage protects your "" ""data against a hard drive failure. If, however, the node itself fails, data "" ""may be lost. In particular, all volumes stored on an LVM node can be lost.""#: ../storage-ha-backend.rst:49 msgid ""Ceph""#: ../storage-ha-backend.rst:51#: ../storage-ha-backend.rst:62""Ceph RBD provides object replication capabilities by storing Block Storage "" ""volumes as Ceph RBD objects; Ceph RBD ensures that each replica of an object "" ""is stored on a different node. This means that your volumes are protected "" ""against hard drive and node failures or even the failure of the data center "" ""itself.""#: ../storage-ha-backend.rst:70""When Ceph RBD is used for ephemeral volumes as well as block and image "" ""storage, it supports `live migration <http://docs.openstack.org/admin-guide-"" ""cloud/compute-live-migration-usage.html>`_ of VMs with ephemeral drives; LVM "" ""only supports live migration of volume-backed VMs.""#: ../storage-ha-backend.rst:78 msgid ""Remote backup facilities"" msgstr """" #: ../storage-ha-backend.rst:80""[TODO: Add discussion of remote backup facilities as an alternate way to "" ""secure ones data. Include brief mention of key third-party technologies with "" ""links to their documentation]""#: ../storage-ha-cinder.rst:6 msgid ""Highly available Block Storage API""#: ../storage-ha-cinder.rst:8""Cinder provides 'block storage as a service' suitable for performance "" ""sensitive scenarios such as databases, expandable file systems, or providing "" ""a server with access to raw block level storage.""#: ../storage-ha-cinder.rst:12""Persistent block storage can survive instance termination and can also be "" ""moved across instances like any external storage device. Cinder also has "" ""volume snapshots capability for backing up the volumes.""#: ../storage-ha-cinder.rst:16""Making this Block Storage API service highly available in active/passive "" ""mode involves:""#: ../storage-ha-cinder.rst:19 msgid "":ref:`ha-cinder-pacemaker`"" msgstr """" #: ../storage-ha-cinder.rst:20 msgid "":ref:`ha-cinder-configure`"" msgstr """" #: ../storage-ha-cinder.rst:21 msgid "":ref:`ha-cinder-services`"" msgstr """" #: ../storage-ha-cinder.rst:23""In theory, you can run the Block Storage service as active/active. However, "" ""because of sufficient concerns, it is recommended running the volume "" ""component as active/passive only.""#: ../storage-ha-cinder.rst:27 msgid ""Jon Bernard writes:"" msgstr """" #: ../storage-ha-cinder.rst:63""You can read more about these concerns on the `Red Hat Bugzilla <https://"" ""bugzilla.redhat.com/show_bug.cgi?id=1193229>`_ and there is a `psuedo "" ""roadmap <https://etherpad.openstack.org/p/cinder-kilo-stabilisation-work>`_ "" ""for addressing them upstream.""#: ../storage-ha-cinder.rst:73 msgid ""Add Block Storage API resource to Pacemaker""#: ../storage-ha-cinder.rst:75""On RHEL-based systems, you should create resources for cinder's systemd "" ""agents and create constraints to enforce startup/shutdown ordering:""#: ../storage-ha-cinder.rst:91""If the Block Storage service runs on the same nodes as the other services, "" ""then it is advisable to also include:""#: ../storage-ha-cinder.rst:98""Alternatively, instead of using systemd agents, download and install the OCF "" ""resource agent:""#: ../storage-ha-cinder.rst:107""You can now add the Pacemaker configuration for Block Storage API resource. "" ""Connect to the Pacemaker cluster with the :command:`crm configure` command "" ""and add the following cluster resources:""#: ../storage-ha-cinder.rst:121 msgid """" ""This configuration creates ``p_cinder-api``, a resource for managing the "" ""Block Storage API service.""#: ../storage-ha-cinder.rst:124 msgid """" ""The command :command:`crm configure` supports batch input, so you may copy "" ""and paste the lines above into your live pacemaker configuration and then "" ""make changes as required. For example, you may enter ``edit p_ip_cinder-"" ""api`` from the :command:`crm configure` menu and edit the resource to match "" ""your preferred virtual IP address.""#: ../storage-ha-cinder.rst:131 msgid """" ""Once completed, commit your configuration changes by entering :command:"" ""`commit` from the :command:`crm configure` menu. Pacemaker then starts the "" ""Block Storage API service and its dependent resources on one of your nodes.""#: ../storage-ha-cinder.rst:139 msgid ""Configure Block Storage API service""#: ../storage-ha-cinder.rst:141 msgid ""Edit the ``/etc/cinder/cinder.conf`` file:""#: ../storage-ha-cinder.rst:143 msgid ""On a RHEL-based system, it should look something like:""#: ../storage-ha-cinder.rst:184 msgid """" ""Replace ``CINDER_DBPASS`` with the password you chose for the Block Storage "" ""database. Replace ``CINDER_PASS`` with the password you chose for the "" ""``cinder`` user in the Identity service.""#: ../storage-ha-cinder.rst:188 msgid """" ""This example assumes that you are using NFS for the physical storage, which "" ""will almost never be true in a production installation.""#: ../storage-ha-cinder.rst:191 msgid """" ""If you are using the Block Storage service OCF agent, some settings will be "" ""filled in for you, resulting in a shorter configuration file:"" msgstr """" #: ../storage-ha-cinder.rst:212 msgid """" ""Replace ``CINDER_DBPASS`` with the password you chose for the Block Storage "" ""database."" msgstr """" #: ../storage-ha-cinder.rst:218 msgid ""Configure OpenStack services to use highly available Block Storage API"" msgstr """" #: ../storage-ha-cinder.rst:220 msgid """" ""Your OpenStack services must now point their Block Storage API configuration "" ""to the highly available, virtual cluster IP address rather than a Block "" ""Storage API server’s physical IP address as you would for a non-HA "" ""environment."" msgstr """" #: ../storage-ha-cinder.rst:226 msgid ""You must create the Block Storage API endpoint with this IP."" msgstr """" #: ../storage-ha-cinder.rst:228 msgid """" ""If you are using both private and public IP addresses, you should create two "" ""virtual IPs and define your endpoint like this:"" msgstr """" #: ../storage-ha-glance.rst:3 msgid ""Highly available OpenStack Image API"" msgstr """" #: ../storage-ha-glance.rst:5 msgid """" ""The OpenStack Image service offers a service for discovering, registering, "" ""and retrieving virtual machine images. To make the OpenStack Image API "" ""service highly available in active / passive mode, you must:"" msgstr """" #: ../storage-ha-glance.rst:10 msgid "":ref:`glance-api-pacemaker`"" msgstr """" #: ../storage-ha-glance.rst:11 msgid "":ref:`glance-api-configure`"" msgstr """" #: ../storage-ha-glance.rst:12 msgid "":ref:`glance-services`"" msgstr """" #: ../storage-ha-glance.rst:14 msgid """" ""This section assumes that you are familiar with the `documentation <http://"" ""docs.openstack.org/liberty/install-guide-ubuntu/glance.html>`_ for "" ""installing the OpenStack Image API service."" msgstr """" #: ../storage-ha-glance.rst:22 msgid ""Add OpenStack Image API resource to Pacemaker"" msgstr """" # #-#-#-#-# storage-ha-glance.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# storage-ha-manila.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../storage-ha-glance.rst:24 ../storage-ha-manila.rst:20 msgid ""You must first download the resource agent to your system:"" msgstr """" #: ../storage-ha-glance.rst:32 msgid """" ""You can now add the Pacemaker configuration for the OpenStack Image API "" ""resource. Use the :command:`crm configure` command to connect to the "" ""Pacemaker cluster and add the following cluster resources:"" msgstr """" #: ../storage-ha-glance.rst:47 msgid """" ""This configuration creates ``p_glance-api``, a resource for managing the "" ""OpenStack Image API service."" msgstr """" #: ../storage-ha-glance.rst:50 msgid """" ""The :command:`crm configure` command supports batch input, so you may copy "" ""and paste the above into your live Pacemaker configuration and then make "" ""changes as required. For example, you may enter edit ``p_ip_glance-api`` "" ""from the :command:`crm configure` menu and edit the resource to match your "" ""preferred virtual IP address."" msgstr """" #: ../storage-ha-glance.rst:57 msgid """" ""After completing these steps, commit your configuration changes by entering :"" ""command:`commit` from the :command:`crm configure` menu. Pacemaker then "" ""starts the OpenStack Image API service and its dependent resources on one of "" ""your nodes."" msgstr """" #: ../storage-ha-glance.rst:66 msgid ""Configure OpenStack Image service API"" msgstr """" #: ../storage-ha-glance.rst:68 msgid """" ""Edit the :file:`/etc/glance/glance-api.conf` file to configure the OpenStack "" ""image service:"" msgstr """" #: ../storage-ha-glance.rst:91 msgid ""[TODO: need more discussion of these parameters]"" msgstr """" #: ../storage-ha-glance.rst:96 msgid """" ""Configure OpenStack services to use highly available OpenStack Image API"" msgstr """" #: ../storage-ha-glance.rst:98 msgid """" ""Your OpenStack services must now point their OpenStack Image API "" ""configuration to the highly available, virtual cluster IP address instead of "" ""pointint to the physical IP address of an OpenStack Image API server as you "" ""would in a non-HA cluster."" msgstr """" #: ../storage-ha-glance.rst:105 msgid """" ""For OpenStack Compute, for example, if your OpenStack Image API service IP "" ""address is 10.0.0.11 (as in the configuration explained here), you would use "" ""the following configuration in your :file:`nova.conf` file:"" msgstr """" #: ../storage-ha-glance.rst:118 msgid """" ""You must also create the OpenStack Image API endpoint with this IP address. "" ""If you are using both private and public IP addresses, you should create two "" ""virtual IP addresses and define your endpoint like this:"" msgstr """" #: ../storage-ha-manila.rst:6 msgid ""Highly available Shared File Systems API"" msgstr """" #: ../storage-ha-manila.rst:8 msgid """" ""Making the Shared File Systems (manila) API service highly available in "" ""active/passive mode involves:"" msgstr """" #: ../storage-ha-manila.rst:11 msgid "":ref:`ha-manila-pacemaker`"" msgstr """" #: ../storage-ha-manila.rst:12 msgid "":ref:`ha-manila-configure`"" msgstr """" #: ../storage-ha-manila.rst:13 msgid "":ref:`ha-manila-services`"" msgstr """" #: ../storage-ha-manila.rst:18 msgid ""Add Shared File Systems API resource to Pacemaker"" msgstr """" #: ../storage-ha-manila.rst:28 msgid """" ""You can now add the Pacemaker configuration for the Shared File Systems API "" ""resource. Connect to the Pacemaker cluster with the :command:`crm configure` "" ""command and add the following cluster resources:"" msgstr """" #: ../storage-ha-manila.rst:42 msgid """" ""This configuration creates ``p_manila-api``, a resource for managing the "" ""Shared File Systems API service."" msgstr """" #: ../storage-ha-manila.rst:45 msgid """" ""The :command:`crm configure` supports batch input, so you may copy and paste "" ""the lines above into your live Pacemaker configuration and then make changes "" ""as required. For example, you may enter ``edit p_ip_manila-api`` from the :"" ""command:`crm configure` menu and edit the resource to match your preferred "" ""virtual IP address."" msgstr """" #: ../storage-ha-manila.rst:51 msgid """" ""Once completed, commit your configuration changes by entering :command:"" ""`commit` from the :command:`crm configure` menu. Pacemaker then starts the "" ""Shared File Systems API service and its dependent resources on one of your "" ""nodes."" msgstr """" #: ../storage-ha-manila.rst:59 msgid ""Configure Shared File Systems API service"" msgstr """" #: ../storage-ha-manila.rst:61 msgid ""Edit the :file:`/etc/manila/manila.conf` file:"" msgstr """" #: ../storage-ha-manila.rst:80 msgid ""Configure OpenStack services to use HA Shared File Systems API"" msgstr """" #: ../storage-ha-manila.rst:82 msgid """" ""Your OpenStack services must now point their Shared File Systems API "" ""configuration to the highly available, virtual cluster IP address rather "" ""than a Shared File Systems API server’s physical IP address as you would for "" ""a non-HA environment."" msgstr """" #: ../storage-ha-manila.rst:87 msgid ""You must create the Shared File Systems API endpoint with this IP."" msgstr """" #: ../storage-ha-manila.rst:89 msgid """" ""If you are using both private and public IP addresses, you should create two "" ""virtual IPs and define your endpoints like this:"" msgstr """" #: ../storage-ha.rst:3 msgid ""Configuring Storage for high availability""","""POT-Creation-Date: 2015-09-16 18:09+0000\n""#: ../controller-ha-galera.rst:313 msgid ""(Optional) Configure the ``clustercheck`` utility.""#: ../intro-ha-concepts.rst:12 msgid ""**Data loss**""#: ../intro-ha-concepts.rst:9 msgid ""**System downtime**""#: ../networking-ha-l3.rst:0 msgid ""/etc/neutron/neutron.conf parameters for high availability""#: ../hardware-ha-basic.rst:25 msgid ""10 GB""#: ../hardware-ha-basic.rst:21 ../hardware-ha-basic.rst:25 msgid ""2 GB""#: ../networking-ha-l3.rst:29 ../networking-ha-l3.rst:32 msgid ""2 or more""#: ../hardware-ha-basic.rst:21 ../hardware-ha-basic.rst:23 #: ../hardware-ha-basic.rst:25 msgid ""3""#: ../hardware-ha-basic.rst:21 ../hardware-ha-basic.rst:23 msgid ""5 GB""#: ../hardware-ha-basic.rst:23 msgid ""512 MB""#: ../controller-ha-pacemaker.rst:416 msgid "":command:`# /etc/init.d/corosync start` (LSB)""#: ../controller-ha-pacemaker.rst:475 msgid "":command:`# /etc/init.d/pacemaker start` (LSB)""#: ../controller-ha-rabbitmq.rst:30 msgid "":command:`# apt-get install rabbitmq-server`""#: ../controller-ha-pacemaker.rst:418 msgid "":command:`# service corosync start` (LSB, alternate)""#: ../controller-ha-pacemaker.rst:477 msgid "":command:`# service pacemaker start` (LSB, alternate)""#: ../controller-ha-pacemaker.rst:420 msgid "":command:`# start corosync (upstart)`""#: ../controller-ha-pacemaker.rst:479 msgid "":command:`# start pacemaker` (upstart)""#: ../controller-ha-pacemaker.rst:422 msgid "":command:`# systemctl start corosync (systemd)`""#: ../controller-ha-pacemaker.rst:481 msgid "":command:`# systemctl start pacemaker` (systemd)""#: ../controller-ha-rabbitmq.rst:32 msgid "":command:`# yum install rabbitmq-server`""#: ../controller-ha-rabbitmq.rst:36 msgid "":command:`# zypper addrepo -f obs://Cloud:OpenStack:Kilo/SLE_12 Kilo`""#: ../controller-ha-rabbitmq.rst:34 ../controller-ha-rabbitmq.rst:40 msgid "":command:`# zypper install rabbitmq-server`""#: ../storage-ha-cinder.rst:47 msgid """" "":command:`crm configure` supports batch input, so you may copy and paste the "" ""lines above into your live pacemaker configuration and then make changes as "" ""required. For example, you may enter ``edit p_ip_cinder-api`` from the :"" ""command:`crm configure` menu and edit the resource to match your preferred "" ""virtual IP address."" msgstr """" #: ../controller-ha-rabbitmq.rst:12 msgid """" "":ref:`Configure OpenStack services to use Rabbit HA queues <rabbitmq-"" ""services>`"" msgstr """" #: ../controller-ha-rabbitmq.rst:10 msgid "":ref:`Configure RabbitMQ for HA queues<rabbitmq-configure>`"" msgstr """" #: ../controller-ha-rabbitmq.rst:8 msgid "":ref:`Install RabbitMQ<rabbitmq-install>`"" msgstr """" #: ../networking-ha.rst:35 msgid "":ref:`Neutron DHCP agent<dhcp-agent>`"" msgstr """" #: ../networking-ha.rst:42 msgid "":ref:`Neutron L3 agent<neutron-l3>`"" msgstr """" #: ../networking-ha.rst:44 msgid "":ref:`Neutron LBaaS<neutron-lbaas>` (Load Balancing as a Service) agent"" msgstr """" #: ../networking-ha.rst:43 msgid "":ref:`Neutron metadata agent<neutron-metadata>`"" msgstr """" #: ../controller-ha-pacemaker.rst:82 msgid "":ref:`corosync-multicast`"" msgstr """" #: ../controller-ha-pacemaker.rst:83 msgid "":ref:`corosync-unicast`"" msgstr """" #: ../controller-ha-pacemaker.rst:84 msgid "":ref:`corosync-votequorum`"" msgstr """" #: ../storage-ha-glance.rst:11 msgid "":ref:`glance-api-configure`"" msgstr """" #: ../storage-ha-glance.rst:10 msgid "":ref:`glance-api-pacemaker`"" msgstr """" #: ../storage-ha-glance.rst:12 msgid "":ref:`glance-services`"" msgstr """" #: ../storage-ha-cinder.rst:12 msgid "":ref:`ha-cinder-configure`"" msgstr """" #: ../storage-ha-cinder.rst:11 msgid "":ref:`ha-cinder-pacemaker`"" msgstr """" #: ../storage-ha-cinder.rst:13 msgid "":ref:`ha-cinder-services`"" msgstr """" #: ../controller-ha-keystone.rst:17 msgid "":ref:`keystone-config-identity`"" msgstr """" #: ../controller-ha-keystone.rst:16 msgid "":ref:`keystone-pacemaker`"" msgstr """" #: ../controller-ha-keystone.rst:18 msgid "":ref:`keystone-services-config`"" msgstr """" #: ../controller-ha-pacemaker.rst:42 msgid "":ref:`pacemaker-cluster-properties`"" msgstr """" #: ../controller-ha-pacemaker.rst:39 msgid "":ref:`pacemaker-corosync-setup`"" msgstr """" #: ../controller-ha-pacemaker.rst:40 msgid "":ref:`pacemaker-corosync-start`"" msgstr """" #: ../controller-ha-pacemaker.rst:38 msgid "":ref:`pacemaker-install`"" msgstr """" #: ../controller-ha-pacemaker.rst:41 msgid "":ref:`pacemaker-start`"" msgstr """" #: ../index.rst:42 msgid "":ref:`search`"" msgstr """" #: ../intro-ha-concepts.rst:138 msgid "":term:`active/active configuration`"" msgstr """" #: ../intro-ha-concepts.rst:119 msgid "":term:`active/passive configuration`"" msgstr """" #: ../intro-ha-concepts.rst:29 msgid """" ""A crucial aspect of high availability is the elimination of single points of "" ""failure (SPOFs). A SPOF is an individual piece of equipment or software that "" ""causes system downtime or data loss if it fails. In order to eliminate "" ""SPOFs, check that mechanisms exist for redundancy of:"" msgstr """" #: ../intro-ha-controller.rst:5 msgid """" ""A highly-available OpenStack environment must have a controller cluster with "" ""three or more nodes. The following components are normally included in the "" ""cluster."" msgstr """" #: ../controller-ha-pacemaker.rst:353 msgid """" ""A sample votequorum service configuration in the :file:`corosync.com` file "" ""is:"" msgstr """" #: ../intro-ha-concepts.rst:81 msgid """" ""A service that provides a response after your request and then requires no "" ""further attention. To make a stateless service highly available, you need to "" ""provide redundant instances and load balance them. OpenStack services that "" ""are stateless include ``nova-api``, ``nova-conductor``, ``glance-api``, "" ""``keystone-api``, ``neutron-api`` and ``nova-scheduler``."" msgstr """" #: ../intro-ha-concepts.rst:90 msgid """" ""A service where subsequent requests to the service depend on the results of "" ""the first request. Stateful services are more difficult to manage because a "" ""single action typically involves more than one request, so simply providing "" ""additional instances and load balancing does not solve the problem. For "" ""example, if the horizon user interface reset itself every time you went to a "" ""new page, it would not be very useful. OpenStack services that are stateful "" ""include the OpenStack database and message queue. Making stateful services "" ""highly available can depend on whether you choose an active/passive or "" ""active/active configuration."" msgstr """" #: ../intro-ha-concepts.rst:132 msgid """" ""A typical active/active installation for a stateful service includes "" ""redundant services, with all instances having an identical state. In other "" ""words, updates to one instance of a database update all other instances. "" ""This way a request to one instance is the same as a request to any other. A "" ""load balancer manages the traffic to these systems, ensuring that "" ""operational systems always handle the request."" msgstr """" #: ../intro-ha-concepts.rst:114 msgid """" ""A typical active/passive installation for a stateful service maintains a "" ""replacement resource that can be brought online when required. Requests are "" ""handled using a :term:`virtual IP` address (VIP) that facilitates returning "" ""to service with minimal reconfiguration. A separate application (such as "" ""Pacemaker or Corosync) monitors these services, bringing the backup online "" ""as necessary."" msgstr """" #: ../intro-ha-controller.rst:81 msgid ""AMQP (RabbitMQ)"" msgstr """" #: ../hardware-ha-basic.rst:36 msgid """" ""Ability to take periodic \""snap shots\"" throughout the installation process "" ""and \""roll back\"" to a working configuration in the event of a problem."" msgstr """" #: ../index.rst:6 msgid ""Abstract"" msgstr """" #: ../intro-ha-concepts.rst:12 msgid ""Accidental deletion or destruction of data."" msgstr """" #: ../intro-ha-concepts.rst:103 msgid ""Active/Passive vs Active/Active"" msgstr """" #: ../storage-ha-cinder.rst:18 msgid ""Add Block Storage API resource to Pacemaker"" msgstr """" #: ../controller-ha-keystone.rst:23 msgid ""Add OpenStack Identity resource to Pacemaker"" msgstr """" #: ../storage-ha-glance.rst:22 msgid ""Add OpenStack Image API resource to Pacemaker"" msgstr """" #: ../controller-ha-galera.rst:80 msgid """" ""Adjust the configuration by making the following changes to the :file:`/etc/"" ""mysql/my.cnf` file:"" msgstr """" #: ../storage-ha-glance.rst:58 msgid """" ""After completing these steps, commit your configuration changes by entering :"" ""command:`commit` from the :command:`crm configure` menu. Pacemaker then "" ""starts the OpenStack Image API service and its dependent resources on one of "" ""your nodes."" msgstr """" #: ../controller-ha-pacemaker.rst:76 msgid """" ""After installing the Corosync package, you must create the :file:`/etc/"" ""corosync/corosync.conf` configuration file. Corosync can be configured to "" ""work with either multicast or unicast IP addresses or to use the votequorum "" ""library."" msgstr """" #: ../controller-ha-pacemaker.rst:471 msgid """" ""After the Corosync services have been started and you have verified that the "" ""cluster is communicating properly, you can start :command:`pacemakerd`, the "" ""Pacemaker master control process:"" msgstr """" #: ../controller-ha-pacemaker.rst:483 msgid """" ""After the Pacemaker services have started, Pacemaker creates a default empty "" ""cluster configuration with no resources. Use the :command:`crm_mon` utility "" ""to observe the status of Pacemaker:"" msgstr """" #: ../controller-ha-galera.rst:438 msgid """" ""After the output from the ``clustercheck`` command is 200 on all nodes, "" ""restart the MariaDB on node 1 with the following command sequence:"" msgstr """" #: ../controller-ha-pacemaker.rst:559 msgid ""After you make these changes, you may commit the updated configuration."" msgstr """" #: ../controller-ha-pacemaker.rst:507 msgid """" ""After you set up your Pacemaker cluster, you should set a few basic cluster "" ""properties using one of the following methods:"" msgstr """" #: ../networking-ha-l3.rst:24 msgid ""All routers are highly available by default."" msgstr """" #: ../controller-ha-galera.rst:200 msgid """" ""Alternately, you can run the following command to print out just the "" ""``password`` line:"" msgstr """" #: ../storage-ha-backend.rst:14 msgid ""An OpenStack environment includes multiple data pools for the VMs:"" msgstr """" #: ../intro-ha-concepts.rst:37 msgid ""Applications and automatic service migration"" msgstr """" #: ../controller-ha-galera.rst:158 msgid """" ""Be sure that SSH root access is established for the other database servers. "" ""Then copy the :file:`debian.cnf` file to each other server and reset the "" ""file permissions and owner to reduce the security risk. Do this by issuing "" ""the following commands on the primary database server:"" msgstr """" #: ../controller-ha-galera.rst:333 msgid ""Be sure to supply a sensible password."" msgstr """" #: ../storage-ha-backend.rst:27 msgid """" ""Block Storage service (cinder) can use LVM or Ceph RBD as the storage back "" ""end."" msgstr """" #: ../controller-ha-telemetry.rst:14 msgid """" ""Both the central and the compute agent can run in an HA deployment, which "" ""means that multiple instances of these services can run in parallel with "" ""workload partitioning among these running instances."" msgstr """" #: ../install-ha-memcached.rst:38 msgid """" ""By default, `controller1` handles the caching service but, if the host goes "" ""down, `controller2` does the job. For more information about memcached "" ""installation, see the `OpenStack Cloud Administrator Guide <http://docs."" ""openstack.org/admin-guide-cloud/>`_."" msgstr """" #: ../install-ha-os.rst:12 msgid ""CentOS, Fedora, RHEL: [link to RedHat install guide]"" msgstr """" #: ../install-ha-ntp.rst:14 msgid ""CentOS: [link to centos install guide]"" msgstr """" #: ../storage-ha-backend.rst:56 msgid ""Ceph"" msgstr """" #: ../storage-ha-backend.rst:69 msgid """" ""Ceph RBD provides object replication capabilities by storing Block Storage "" ""volumes as Ceph RBD objects; Ceph RBD ensures that each replica of an object "" ""is stored on a different node. This means that your volumes are protected "" ""against hard drive and node failures or even the failure of the data center "" ""itself."" msgstr """" #: ../controller-ha-pacemaker.rst:344 msgid ""Change the number of expected votes for a cluster to be quorate"" msgstr """" #: ../controller-ha-pacemaker.rst:342 msgid ""Change the number of votes assigned to a node"" msgstr """" #: ../intro-ha-concepts.rst:141 msgid ""Clusters and quorums"" msgstr """" #: ../controller-ha-rabbitmq.rst:28 msgid ""Command"" msgstr """" #: ../storage-ha-cinder.rst:62 msgid ""Configure Block Storage API service"" msgstr """" #: ../controller-ha-galera.rst:374 msgid ""Configure MariaDB with Galera."" msgstr """" #: ../install-ha-ntp.rst:4 msgid ""Configure NTP"" msgstr """" #: ../storage-ha-glance.rst:67 msgid ""Configure OpenStack Image service API"" msgstr """" #: ../controller-ha-rabbitmq.rst:174 msgid ""Configure OpenStack services to use Rabbit HA queues"" msgstr """" #: ../storage-ha-cinder.rst:88 msgid ""Configure OpenStack services to use highly available Block Storage API"" msgstr """" #: ../storage-ha-glance.rst:97 msgid """" ""Configure OpenStack services to use highly available OpenStack Image API"" msgstr """" #: ../controller-ha-keystone.rst:103 msgid """" ""Configure OpenStack services to use the highly available OpenStack Identity"" msgstr """" #: ../controller-ha-rabbitmq.rst:66 msgid ""Configure RabbitMQ for HA queues"" msgstr """" #: ../compute-node-ha-api.rst:4 msgid ""Configure high availability on compute nodes"" msgstr """" #: ../networking-ha.rst:6 msgid """" ""Configure networking on each node. The `Networking <http://docs.openstack."" ""org/juno/install-guide/install/apt/content/ch_basic_environment.html#basics-"" ""prerequisites>`_ section of the *Install Guide* includes basic information "" ""about configuring networking."" msgstr """" #: ../controller-ha-vip.rst:4 msgid ""Configure the VIP"" msgstr """" #: ../controller-ha-galera.rst:147 msgid ""Configure the database on other database servers"" msgstr """" #: ../controller-ha-galera.rst:335 msgid """" ""Configure the monitor service (used by HAProxy) by creating the :file:`/etc/"" ""xinetd.d/galera-monitor` file with the following contents:"" msgstr """" #: ../intro-ha-storage.rst:8 msgid ""Configuring Block Storage to listen on the VIP address"" msgstr """" #: ../intro-ha-storage.rst:12 msgid ""Configuring OpenStack services to use this IP address"" msgstr """" #: ../storage-ha-backend.rst:50 msgid """" ""Configuring RAID on the hard drives that implement storage protects your "" ""data against a hard drive failure. If, however, the node itself fails, data "" ""may be lost. In particular, all volumes stored on an LVM node can be lost."" msgstr """" #: ../storage-ha.rst:3 msgid ""Configuring Storage for high availability"" msgstr """" #: ../noncore-ha.rst:4 msgid ""Configuring non-core components for high availability"" msgstr """" #: ../compute-node-ha.rst:4 msgid ""Configuring the compute node for high availability"" msgstr """" #: ../controller-ha.rst:4 msgid ""Configuring the controller for high availability"" msgstr """" #: ../controller-ha-pacemaker.rst:346 msgid """" ""Connect an additional quorum device to allow small clusters remain quorate "" ""during node outages"" msgstr """" #: ../index.rst:21 msgid ""Contents"" msgstr """" #: ../controller-ha-galera.rst:111 msgid """" ""Copy this file to all other databases servers and change the value of "" ""wsrep_cluster_address and wsrep_node_name accordingly."" msgstr """" #: ../controller-ha-pacemaker.rst:247 msgid ""Corosync configuration file fragment for unicast (corosync.conf)"" msgstr """" #: ../controller-ha-pacemaker.rst:411 msgid """" ""Corosync is started as a regular system service. Depending on your "" ""distribution, it may ship with an LSB init script, an upstart job, or a "" ""systemd unit file. Either way, the service is usually named corosync:"" msgstr """" #: ../controller-ha-galera.rst:376 msgid """" ""Create the :file:`/etc/my.cnf.d/galera.cnf` configuration file with the "" ""following content:"" msgstr """" #: ../controller-ha-galera.rst:91 msgid """" ""Create the :file:`/etc/mysql/conf.d/wsrep.cnf` file; paste the following "" ""lines into this file:"" msgstr """" #: ../controller-ha-galera.rst:321 msgid """" ""Create the :file:`/etc/sysconfig/clustercheck` file with the following "" ""contents:"" msgstr """" #: ../controller-ha-galera.rst:358 msgid ""Create the database user required by ``clustercheck``:"" msgstr """" #: ../networking-ha-lbaas.rst:8 msgid """" ""Currently, no native feature is provided to make the LBaaS agent highly "" ""available using the default plug-in HAProxy. A common way to make HAProxy "" ""highly available is to use the VRRP (Virtual Router Redundancy Protocol). "" ""Unfortunately, this is not yet implemented in the LBaaS HAProxy plug-in."" msgstr """" #: ../controller-ha-galera.rst:4 msgid ""Database (Galera/MySQL)"" msgstr """" #: ../intro-ha-controller.rst:47 msgid ""Database (MySQL/Galera)"" msgstr """" #: ../networking-ha-l3.rst:21 msgid ""Description"" msgstr """" #: ../controller-ha-rabbitmq.rst:27 msgid ""Distribution"" msgstr """" #: ../controller-ha-galera.rst:305 msgid """" ""Distributions based on Red Hat include Galera packages in their "" ""repositories. To install the most current version of the packages, run the "" ""following command:"" msgstr """" #: ../controller-ha-rabbitmq.rst:179 msgid ""Do this configuration on all services using RabbitMQ:"" msgstr """" #: ../controller-ha-pacemaker.rst:200 msgid """" ""Each configured interface must have a unique ``ringnumber``, starting with 0."" msgstr """" #: ../intro-ha-controller.rst:52 msgid """" ""Each instance has its own IP address; OpenStack services are configured with "" ""the list of these IP addresses so they can select on of the addresses from "" ""those available."" msgstr """" #: ../intro-ha-concepts.rst:122 msgid """" ""Each service also has a backup but manages both the main and redundant "" ""systems concurrently. This way, if there is a failure, the user is unlikely "" ""to notice. The backup system is already online and takes on increased load "" ""while the main system is fixed and brought back online."" msgstr """" #: ../storage-ha-cinder.rst:64 msgid ""Edit the :file:`/etc/cinder/cinder.conf` file:"" msgstr """" #: ../storage-ha-glance.rst:69 msgid """" ""Edit the :file:`/etc/glance/glance-api.conf` file to configure the OpenStack "" ""image service:"" msgstr """" #: ../storage-ha-backend.rst:16""Ephemeral storage is allocated for an instance and is deleted when the "" ""instance is deleted. The Compute service manages ephemeral storage. By "" ""default, Compute stores ephemeral drives as files on local disks on the "" ""Compute node but Ceph RBD can instead be used as the storage back end for "" ""ephemeral storage.""#: ../controller-ha-pacemaker.rst:98 msgid ""Example Corosync configuration file for multicast (corosync.conf)""#: ../install-ha-memcached.rst:32 msgid ""Example configuration with two hosts:""#: ../intro-ha-concepts.rst:41 msgid ""Facility services such as power, air conditioning, and fire protection"" msgstr """" #: ../install-ha-ntp.rst:11 msgid ""Follow the instructions in the appropriate Install Guide:"" msgstr """" #: ../networking-ha.rst:19 msgid ""For Kilo and beyond, focus on L3HA and DVR.""""address is 192.168.42.103, use the following configuration in your :file:"" ""`api-paste.ini` file:""#: ../storage-ha-glance.rst:106""For OpenStack Compute, for example, if your OpenStack Image API service IP "" ""address is 192.168.42.103 (as in the configuration explained here), you "" ""would use the following configuration in your :file:`nova.conf` file:"" msgstr """" #: ../controller-ha-rabbitmq.rst:45 msgid """" ""For SLES 12, the packages are signed by GPG key 893A90DAD85F9316. You should "" ""verify the fingerprint of the imported GPG key before using it."" msgstr """" #: ../controller-ha-pacemaker.rst:307 msgid """" ""For UDPU, every node that should be a member of the membership must be "" ""specified."" msgstr """" #: ../controller-ha-telemetry.rst:57 msgid """" ""For backward compatibility and supporting existing deployments, the central "" ""agent configuration also supports using different configuration files for "" ""groups of service instances of this type that are running in parallel. For "" ""enabling this configuration, set a value for the partitioning_group_prefix "" ""option in the `central section <http://docs.openstack.org/kilo/ config-"" ""reference/content/ch_configuring-openstack-telemetry.html>`__ in the "" ""OpenStack Configuration Reference."" msgstr """" #: ../hardware-ha-basic.rst:29 msgid """" ""For demonstrations and studying, you can set up a test environment on "" ""virtual machines (VMs). This has the following benefits:"" msgstr """" #: ../controller-ha-haproxy.rst:15 msgid """" ""For detailed instructions about installing HAProxy on your nodes, see its "" ""`official documentation <http://www.haproxy.org/#docs>`_. Note the following:"" msgstr """" #: ../controller-ha-telemetry.rst:65 msgid """" ""For each sub-group of the central agent pool with the same "" ""``partitioning_group_prefix`` a disjoint subset of meters must be polled -- "" ""otherwise samples may be missing or duplicated. The list of meters to poll "" ""can be set in the :file:`/etc/ceilometer/pipeline.yaml` configuration file. "" ""For more information about pipelines see the `Data collection and processing "" ""<http://docs.openstack.org/admin-guide-cloud/telemetry-data-collection."" ""html#data-collection-and-processing>`__ section."" msgstr """" #: ../controller-ha-pacemaker.rst:241 msgid """" ""For environments that do not support multicast, Corosync should be "" ""configured for unicast. An example fragment of the :file:`corosync.conf` "" ""file for unicastis shown below:"" msgstr """" #: ../intro-ha-concepts.rst:157 msgid """" ""For example, in a 7-node cluster, the quorum could be set to 5 or 3. If "" ""quorum is 5 and three nodes fail simultaneously, the cluster itself would "" ""fail, whereas it would continue to function if the quorum were set to 3."" msgstr """" #: ../controller-ha-pacemaker.rst:214 msgid """" ""For firewall configurations, note that Corosync communicates over UDP only, "" ""and uses ``mcastport`` (for receives) and ``mcastport - 1`` (for sends)."" msgstr """" #: ../controller-ha-telemetry.rst:39 msgid """" ""For information about the required configuration options that have to be set "" ""in the :file:`ceilometer.conf` configuration file for both the central and "" ""compute agents, see the `coordination section <http://docs.openstack.org/"" ""kilo/config-reference/content/ ch_configuring-openstack-telemetry.html>`__ "" ""in the OpenStack Configuration Reference."" msgstr """" #: ../controller-ha-rabbitmq.rst:56 msgid """" ""For more information, see the official installation manual for the "" ""distribution:"" msgstr """" #: ../intro-ha-concepts.rst:151 msgid """" ""For this reason, each cluster in a high availability environment must have "" ""an odd number of nodes and the quorum must specify an odd number of nodes. "" ""If multiple nodes fail so that the cluster size falls below the quorum "" ""value, the cluster itself fails."" msgstr """" #: ../intro-ha-controller.rst:60 msgid """" ""Galera synchronous replication guarantees a zero slave lag. The failover "" ""procedure completes once HAProxy detects that the active back end has gone "" ""down and switches to the backup one, which is then marked as 'UP'. If no "" ""back ends are up (in other words, the Galera cluster is not ready to accept "" ""connections), the failover procedure finishes only when the Galera cluster "" ""has been successfully reassembled. The SLA is normally no more than 5 "" ""minutes."" msgstr """" #: ../controller-ha-pacemaker.rst:338 msgid ""Get a list of nodes known to the quorum service"" msgstr """" #: ../intro-ha-controller.rst:33 msgid """" ""HAProxy is a load balancer that runs on each controller in the cluster but "" ""does not synchronize the state. Each instance of HAProxy configures its "" ""frontend to accept connections only from the Virtual IP (VIP) address and to "" ""terminate them as a list of all instances of the corresponding service under "" ""load balancing. For example, any OpenStack API service. This makes the "" ""instances of HAProxy act independently and fail over transparently together "" ""with the Network endpoints (VIP addresses) failover and shares the same SLA."" msgstr """" #: ../controller-ha-haproxy.rst:4 msgid ""HAProxy nodes"" msgstr """" #: ../controller-ha-haproxy.rst:6 msgid """" ""HAProxy provides a fast and reliable HTTP reverse proxy and load balancer "" ""for TCP and HTTP-based applications. It is particularly suited for web sites "" ""crawling under very high loads while needing persistence or Layer 7 "" ""processing. Supporting tens of thousands of connections is clearly realistic "" ""with today’s hardware."" msgstr """" #: ../controller-ha-haproxy.rst:19 msgid """" ""HAProxy should not be a single point of failure; you need to ensure its "" ""availability by other means, such as Pacemaker or Keepalived."" msgstr """" #: ../hardware-ha.rst:4 msgid ""Hardware considerations for high availability"" msgstr """" #: ../hardware-ha-basic.rst:4 msgid ""Hardware setup"" msgstr """" #: ../controller-ha-haproxy.rst:29 msgid """" ""Here is an example :file:`/etc/haproxy/haproxy.cfg` configuration file. "" ""[TODO: Is a copy required on each controller node?] Note that you must "" ""restart the HAProxy service to implement any changes made to this file."" msgstr """" #: ../controller-ha-galera.rst:13 msgid """" ""High Availability for the OpenStack database can be achieved in many "" ""different ways, depending on the type of database that is used in a "" ""particular installation. Galera can be used with any of the following:"" msgstr """" #: ../intro-ha-concepts.rst:3 msgid ""High availability concepts"" msgstr """" #: ../intro-ha-other.rst:4 msgid ""High availability for other components"" msgstr """" #: ../intro-ha-concepts.rst:23 msgid """" ""High availability is implemented with redundant hardware running redundant "" ""instances of each service. If one piece of hardware running one instance of "" ""a service fails, the system can then failover to use another instance of a "" ""service that is running on hardware that did not fail."" msgstr """" #: ../intro-ha-concepts.rst:5 msgid ""High availability systems seek to minimize two things:"" msgstr """" #: ../intro-ha-concepts.rst:52 msgid """" ""High availability systems typically achieve an uptime percentage of 99.99% "" ""or more, which roughly equates to less than an hour of cumulative downtime "" ""per year. In order to achieve this, high availability systems should keep "" ""recovery times after a failure to about one to two minutes, sometimes "" ""significantly less."" msgstr """" #: ../storage-ha-cinder.rst:6 msgid ""Highly available Block Storage API"" msgstr """" #: ../storage-ha-glance.rst:3 msgid ""Highly available OpenStack Image API"" msgstr """" #: ../controller-ha-rabbitmq.rst:188 msgid """" ""How frequently to retry connecting with RabbitMQ: [TODO: document the unit "" ""of measure here? Seconds?]"" msgstr """" #: ../controller-ha-rabbitmq.rst:195 msgid """" ""How long to back-off for between retries when connecting to RabbitMQ: [TODO: "" ""document the unit of measure here? Seconds?]"" msgstr """" #: ../hardware-ha-basic.rst:11 msgid """" ""However, OpenStack does not require a significant amount of resources and "" ""the following minimum requirements should support a proof-of-concept high "" ""availability environment with core services and several instances:"" msgstr """" #: ../hardware-ha-basic.rst:39 msgid """" ""However, running an OpenStack environment on VMs degrades the performance of "" ""your instances, particularly if your hypervisor and/or processor lacks "" ""support for hardware acceleration of nested VMs."" msgstr """" #: ../controller-ha-keystone.rst:4 msgid ""Identity services (keystone)"" msgstr """" #: ../controller-ha-galera.rst:317 msgid """" ""If HAProxy is used to load-balance client access to MariaDB as described in "" ""the HAProxy section of this document, you can use the ``clustercheck`` "" ""utility to improve health checks."" msgstr """" #: ../controller-ha-pacemaker.rst:284 msgid """" ""If the ``broadcast`` parameter is set to yes, the broadcast address is used "" ""for communication. If this option is set, the ``mcastaddr`` parameter should "" ""not be set."" msgstr """" #: ../controller-ha-rabbitmq.rst:153 msgid """" ""If the cluster is working, you can create usernames and passwords for the "" ""queues."" msgstr """" #: ../controller-ha-pacemaker.rst:225 msgid """" ""If you are using Corosync version 2 on Ubuntu 14.04, remove or comment out "" ""lines under the service stanza, which enables Pacemaker to start up."" msgstr """" #: ../controller-ha-pacemaker.rst:461 msgid """" ""If you are using Corosync version 2, use the :command:`corosync-cmapctl` "" ""utility instead of :command:`corosync-objctl`; it is a direct replacement.""""Virtual IP addresses and define your endpoint like this:""#: ../storage-ha-cinder.rst:98 msgid """" ""If you are using both private and public IP addresses, you should create two "" ""Virtual IPs and define your endpoint like this:"" msgstr """" #: ../controller-ha-keystone.rst:138#: ../controller-ha-rabbitmq.rst:222""If you change the configuration from an old set-up that did not use HA "" ""queues, you should restart the service:""#: ../controller-ha-galera.rst:77 msgid """" ""If you have already installed MariaDB, installing Galera will purge all "" ""privileges; you must re-apply all the permissions listed in the installation "" ""guide."" msgstr """" #: ../storage-ha-backend.rst:29 msgid """" ""Image service (glance) can use the Object Storage service (swift) or Ceph "" ""RBD as the storage back end."" msgstr """" #: ../controller-ha-pacemaker.rst:193 msgid """" ""In Corosync configurations using redundant networking (with more than one "" ""interface), you must select a Redundant Ring Protocol (RRP) mode other than "" ""none. ``active`` is the recommended RRP mode."" msgstr """" #: ../storage-ha-glance.rst:121 msgid """" ""In releases prior to Juno, this option was called ``glance_api_servers`` and "" ""located in the [DEFAULT] section."" msgstr """" #: ../intro-ha-concepts.rst:43 msgid """" ""In the event that a component fails and a back-up system must take on its "" ""load, most high availability systems will replace the failed component as "" ""quickly as possible to maintain necessary redundancy. This way time spent in "" ""a degraded protection state is minimized."" msgstr """" #: ../controller-ha-rabbitmq.rst:18 ../controller-ha-rabbitmq.rst:0 msgid ""Install RabbitMQ"" msgstr """" #: ../controller-ha-galera.rst:34 msgid """" ""Install a version of MySQL patched for wsrep (Write Set REPlication) from "" ""https://launchpad.net/codership-mysql. The wsrep API supports synchronous "" ""replication and so is suitable for configuring MySQL High Availability in "" ""OpenStack."" msgstr """" #: ../install-ha-memcached.rst:4 msgid ""Install memcached"" msgstr """" #: ../install-ha-os.rst:4 msgid ""Install operating system on each node"" msgstr """" #: ../controller-ha-pacemaker.rst:49 msgid ""Install packages"" msgstr """" #: ../controller-ha-galera.rst:32 msgid ""Install the MySQL database on the primary database server"" msgstr """" #: ../controller-ha-galera.rst:45 msgid """" ""Install the software properties, the key, and the repository; For Ubuntu "" ""14.04 \""trusty\"", the command sequence is:"" msgstr """" #: ../install-ha.rst:3 msgid ""Installing high availability packages"" msgstr """" #: ../storage-ha-backend.rst:34 msgid """" ""Instructions for configuring storage back ends for the different storage "" ""options is provided in:"" msgstr """" #: ../intro-ha.rst:4 msgid ""Introduction to OpenStack high availability"" msgstr """" #: ../controller-ha-haproxy.rst:23 msgid """" ""It is advisable to have multiple HAProxy instances running, where the number "" ""of these instances is a small odd number like 3 or 5."" msgstr """" #: ../intro-ha-concepts.rst:178 msgid """" ""It is possible to add controllers to such an environment to convert it into "" ""a truly highly available environment."" msgstr """" #: ../networking-ha.rst:20 msgid """" ""Link to `Networking Guide <http://docs.openstack.org/networking-guide/>`_ "" ""for configuration details."" msgstr """" #: ../intro-ha-controller.rst:31 msgid ""Load balancing (HAProxy)"" msgstr """" #: ../intro-ha-concepts.rst:108 msgid """" ""Maintains a redundant instance that can be brought online when the active "" ""service fails. For example, OpenStack writes to the main database while "" ""maintaining a disaster recovery database that can be brought online if the "" ""main database fails."" msgstr """" #: ../intro-ha-storage.rst:5 msgid """" ""Making the Block Storage (cinder) API service highly available in active/"" ""passive mode involves:"" msgstr """" #: ../controller-ha-keystone.rst:13 msgid """" ""Making the OpenStack Identity service highly available in active / passive "" ""mode involves:"" msgstr """" #: ../storage-ha-cinder.rst:8 msgid """" ""Making the block storage (cinder) API service highly available in active/"" ""passive mode involves:"" msgstr """" #: ../intro-ha-storage.rst:10 msgid """" ""Managing the Block Storage API daemon with the Pacemaker cluster manager"" msgstr """" #: ../controller-ha-galera.rst:291 msgid ""MariaDB with Galera (Red Hat-based platforms)"" msgstr """" #: ../controller-ha-galera.rst:293 msgid """" ""MariaDB with Galera provides synchronous database replication in an active-"" ""active, multi-master environment. High availability for the data itself is "" ""managed internally by Galera, while access availability is managed by "" ""HAProxy."" msgstr """" #: ../networking-ha-l3.rst:30 msgid ""Maximum number of network nodes to use for the HA router."" msgstr """" #: ../controller-ha-rabbitmq.rst:202 msgid """" ""Maximum retries with trying to connect to RabbitMQ (infinite by default):"" msgstr """" #: ../intro-ha-controller.rst:103 msgid ""Memcached back end"" msgstr """" #: ../intro-ha-controller.rst:105""services to store ephemeral data, such as tokens. Although Memcached does "" ""not support typical forms of redundancy such as clustering, OpenStack "" ""services can use almost any number of instances by configuring multiple "" ""hostnames or IP addresses. The Memcached client implements hashing to "" ""balance objects among the instances. Failure of an instance only impacts a "" ""percentage of the objects and the client automatically removes it from the "" ""list of instances. The SLA is several minutes.""#: ../controller-ha-telemetry.rst:54""Memcached uses a timeout value, which should always be set to a value that "" ""is higher than the heartbeat value set for Telemetry.""#: ../hardware-ha-basic.rst:19 msgid ""Memory"" msgstr """" #: ../install-ha-memcached.rst:26""Memory caching is managed by `oslo.cache <http://specs.openstack.org/"" ""openstack/oslo-specs/specs/kilo/oslo-cache-using-dogpile.html>`_ so the way "" ""to use multiple memcached servers is the same for all projects.""#: ../networking-ha-l3.rst:33 msgid """" ""Minimum number of network nodes to use for the HA router. A new router can "" ""be created only if this number of network nodes are available."" msgstr """" #: ../controller-ha-rabbitmq.rst:93 msgid """" ""Mirrored queues in RabbitMQ improve the availability of service since it is "" ""resilient to failures."" msgstr """" #: ../controller-ha-rabbitmq.rst:165 msgid ""More information is available in the RabbitMQ documentation:"" msgstr """" #: ../install-ha-memcached.rst:12 msgid """" ""Most OpenStack services can use memcached to store ephemeral data such as "" ""tokens. Although memcached does not support typical forms of redundancy such "" ""as clustering, OpenStack services can use almost any number of instances by "" ""configuring multiple hostnames or IP addresses. The memcached client "" ""implements hashing to balance objects among the instances. Failure of an "" ""instance only impacts a percentage of the objects and the client "" ""automatically removes it from the list of instances."" msgstr """" #: ../controller-ha-pacemaker.rst:92 msgid """" ""Most distributions ship an example configuration file (:file:`corosync.conf."" ""example`) as part of the documentation bundled with the Corosync package. An "" ""example Corosync configuration file is shown below:"" msgstr """" #: ../intro-ha-concepts.rst:48 msgid """" ""Most high availability systems fail in the event of multiple independent "" ""(non-consequential) failures. In this case, most implementations favor "" ""protecting data over maintaining availability."" msgstr """" #: ../intro-ha-concepts.rst:14 msgid """" ""Most high availability systems guarantee protection against system downtime "" ""and data loss only in the event of a single failure. However, they are also "" ""expected to protect against cascading failures, where a single failure "" ""deteriorates into a series of consequential failures."" msgstr """" #: ../storage-ha-backend.rst:8 msgid """" ""Most of this guide concerns the control plane of high availability: ensuring "" ""that services continue to run even if a component fails. Ensuring that data "" ""is not lost is the data plane component of high availability; this is "" ""discussed here."" msgstr """" #: ../controller-ha-pacemaker.rst:206 msgid """" ""Multicast groups (``mcastaddr``) must not be reused across cluster "" ""boundaries. In other words, no two distinct clusters should ever use the "" ""same multicast group. Be sure to select multicast addresses compliant with "" ""`RFC 2365, \""Administratively Scoped IP Multicast\"" <http://www.ietf.org/rfc/"" ""rfc2365.txt>`_."" msgstr """" #: ../controller-ha-galera.rst:19 msgid """" ""MySQL is the most common choice; the next section tells how to configure "" ""Galera/MySQL."" msgstr """" #: ../intro-ha-controller.rst:49 msgid """" ""MySQL with Galera can be configured using one of the following strategies:"" msgstr """" #: ../intro-ha-controller.rst:15 msgid ""Network components"" msgstr """" #: ../intro-ha-concepts.rst:35 msgid ""Network components, such as switches and routers"" msgstr """" #: ../networking-ha.rst:36 msgid """" ""Neutron L2 agent. Note that the L2 agent cannot be distributed and highly "" ""available. Instead, it must be installed on each data forwarding node to "" ""control the virtual network drivers such as Open vSwitch or Linux Bridge. "" ""One L2 agent runs per node and controls its virtual interfaces."" msgstr """" #: ../networking-ha.rst:17 msgid """" ""Neutron agents shuld be described for active/active; deprecate single "" ""agent's instances case."" msgstr """" #: ../controller-ha-galera.rst:149 msgid """" ""Next, you need to copy the database configuration to the other database "" ""servers. Before doing this, make a backup copy of this file that you can use "" ""to recover from an error:"" msgstr """" #: ../networking-ha-metadata.rst:8 msgid """" ""No native feature is available to make this service highly available. At "" ""this time, the Active/Passive solution exists to run the neutron metadata "" ""agent in failover mode with Pacemaker."" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Node type"" msgstr """" #: ../controller-ha-pacemaker.rst:198 msgid ""Note the following about the recommended interface configuration:"" msgstr """" # #-#-#-#-# controller-ha-haproxy.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-pacemaker.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-haproxy.rst:190 ../controller-ha-pacemaker.rst:169 #: ../controller-ha-pacemaker.rst:282 ../controller-ha-pacemaker.rst:366 #: ../controller-ha-pacemaker.rst:526 msgid ""Note the following:"" msgstr """" #: ../networking-ha.rst:11 msgid ""Notes from planning outline:"" msgstr """" #: ../controller-ha-galera.rst:206 msgid """" ""Now run the following query on each server other than the primary database "" ""node. This will ensure that you can restart the database again. You will "" ""need to supply the password you got in the previous step:"" msgstr """" #: ../intro-ha-concepts.rst:8 msgid """" ""Occurs when a user-facing service is unavailable beyond a specified maximum "" ""amount of time."" msgstr """" #: ../controller-ha-pacemaker.rst:51 msgid """" ""On any host that is meant to be part of a Pacemaker cluster, you must first "" ""establish cluster communications through the Corosync messaging layer. This "" ""involves installing the following packages (and their dependencies, which "" ""your package manager usually installs automatically):"" msgstr """" #: ../controller-ha-rabbitmq.rst:113 msgid """" ""On each target node, verify the correct owner, group, and permissions of the "" ""file :file:`erlang.cookie`."" msgstr """" #: ../controller-ha-galera.rst:426 msgid ""On node 1, run the following command:"" msgstr """" #: ../controller-ha-galera.rst:432 msgid ""On nodes 2 and 3, run the following command:"" msgstr """" #: ../storage-ha-cinder.rst:54 msgid """" ""Once completed, commit your configuration changes by entering :command:"" ""`commit` from the :command:`crm configure` menu. Pacemaker then starts the "" ""Block Storage API service and its dependent resources on one of your nodes."" msgstr """" #: ../controller-ha-pacemaker.rst:231 msgid """" ""Once created, the :file:`corosync.conf` file (and the :file:`authkey` file "" ""if the secauth option is enabled) must be synchronized across all cluster "" ""nodes."" msgstr """" #: ../hardware-ha-basic.rst:33 msgid """" ""One physical server can support multiple nodes, each of which supports "" ""almost any number of network interfaces."" msgstr """" #: ../controller-ha-galera.rst:407 msgid ""Open the firewall ports used for MariaDB and Galera communications:"" msgstr """" #: ../controller-ha-rabbitmq.rst:83 msgid ""OpenStack Block Storage"" msgstr """" #: ../controller-ha-rabbitmq.rst:82 msgid ""OpenStack Compute"" msgstr """" #: ../index.rst:3 msgid ""OpenStack High Availability Guide"" msgstr """" #: ../controller-ha-keystone.rst:6 msgid """" ""OpenStack Identity (keystone) is the Identity service in OpenStack that is "" ""used by many services. You should be familiar with `OpenStack identity "" ""concepts <http://docs.openstack.org/juno/install-guide/install/apt/content/"" ""keystone-concepts.html>`_ before proceeding."" msgstr """" #: ../controller-ha-rabbitmq.rst:84 msgid ""OpenStack Networking"" msgstr """" #: ../intro-ha-concepts.rst:58 msgid """" ""OpenStack currently meets such availability requirements for its own "" ""infrastructure services, meaning that an uptime of 99.99% is feasible for "" ""the OpenStack infrastructure proper. However, OpenStack does not guarantee "" ""99.99% availability for individual guest instances."" msgstr """" #: ../controller-ha-pacemaker.rst:6 msgid """" ""OpenStack infrastructure high availability relies on the `Pacemaker <http://"" ""clusterlabs.org/>`_ cluster stack, the state-of-the-art high availability "" ""and load balancing stack for the Linux platform. Pacemaker is storage and "" ""application-agnostic, and is in no way specific to OpenStack."" msgstr """" #: ../networking-ha.rst:4 msgid ""OpenStack network nodes"" msgstr """" #: ../networking-ha.rst:33 msgid ""OpenStack network nodes contain:"" msgstr """" #: ../intro-ha-concepts.rst:171 msgid """" ""OpenStack supports a single-controller high availability mode that is "" ""managed by the services that manage highly available environments but is not "" ""actually highly available because no redundant controllers are configured to "" ""use for failover. This environment can be used for study and demonstration "" ""but is not appropriate for a production environment."" msgstr """" #: ../intro-ha-storage.rst:3 msgid ""Overview of high availability storage"" msgstr """" #: ../intro-ha-compute.rst:4 msgid ""Overview of highly-available compute nodes"" msgstr """" #: ../intro-ha-controller.rst:3 msgid ""Overview of highly-available controllers"" msgstr """" #: ../controller-ha-pacemaker.rst:4#: ../controller-ha-pacemaker.rst:20""Pacemaker does not inherently (need or want to) understand the applications "" ""it manages. Instead, it relies on resource agents (RAs), scripts that "" ""encapsulate the knowledge of how to start, stop, and check the health of "" ""each application managed by the cluster.""#: ../controller-ha-pacemaker.rst:13#: ../controller-ha-pacemaker.rst:30#: ../controller-ha-pacemaker.rst:553""Pacemaker uses an event-driven approach to cluster state processing. The "" ""``cluster-recheck-interval`` parameter (which defaults to 15 minutes) "" ""defines the interval at which certain Pacemaker actions occur. It is usually "" ""prudent to reduce this to a shorter interval, such as 5 or 3 minutes.""#: ../networking-ha-l3.rst:19 msgid ""Parameter""#: ../storage-ha-backend.rst:24 msgid """" ""Persistent storage exists outside all instances. Two types of persistent "" ""storage are provided:""#: ../controller-ha-pacemaker.rst:310 msgid ""Possible options are:""#: ../intro-ha-concepts.rst:77 msgid """" ""Preventing single points of failure can depend on whether or not a service "" ""is stateless.""#: ../hardware-ha-basic.rst:19 msgid ""Processor""#: ../controller-ha-pacemaker.rst:531 msgid """" ""Production environments should not set the ``no-quorum-policy=\""ignore\""`` "" ""parameter.""#: ../controller-ha-rabbitmq.rst:96 msgid """" ""Production servers should run (at least) three RabbitMQ servers; for testing "" ""and demonstration purposes, it is possible to run only two servers. In this "" ""section, we configure two nodes, called ``rabbit1`` and ``rabbit2``. To "" ""build a broker, we need to ensure that all nodes have the same Erlang cookie "" ""file.""#: ../controller-ha-pacemaker.rst:336 msgid ""Query the quorum status""#: ../storage-ha-backend.rst:48 msgid ""RAID drives"" msgstr """" #: ../controller-ha-rabbitmq.rst:31 msgid ""RHEL, Fedora, CentOS"" msgstr """" #: ../controller-ha-rabbitmq.rst:3 msgid ""RabbitMQ"" msgstr """" #: ../controller-ha-rabbitmq.rst:181 msgid ""RabbitMQ HA cluster host:port pairs: [TODO: Add rabbit3 if you agree]"" msgstr """" #: ../controller-ha-rabbitmq.rst:5 msgid """" ""RabbitMQ is the default AMQP server used by many OpenStack services. Making "" ""the RabbitMQ service highly available involves the following steps:"" msgstr """" #: ../intro-ha-controller.rst:83 msgid """" ""RabbitMQ nodes fail over both on the application and the infrastructure "" ""layers. The application layer is controlled by the ``oslo.messaging`` "" ""configuration options for multiple AMQP hosts. If the AMQP node fails, the "" ""application reconnects to the next one configured within the specified "" ""reconnect interval. The specified reconnect interval constitutes its SLA. On "" ""the infrastructure layer, the SLA is the time for which RabbitMQ cluster "" ""reassembles. Several cases are possible. The Mnesia keeper node is the "" ""master of the corresponding Pacemaker resource for RabbitMQ; when it fails, "" ""the result is a full AMQP cluster downtime interval. Normally, its SLA is no "" ""more than several minutes. Failure of another node that is a slave of the "" ""corresponding Pacemaker resource for RabbitMQ results in no AMQP cluster "" ""downtime at all."" msgstr """" #: ../networking-ha.rst:13 msgid """" ""Rather than configuring neutron here, we should simply mention physical "" ""network HA methods such as bonding and additional node/network requirements "" ""for L3HA and DVR for planning purposes."" msgstr """" #: ../controller-ha-pacemaker.rst:340 msgid ""Receive notifications of quorum state changes"" msgstr """" #: ../controller-ha-telemetry.rst:34 msgid ""Recommended for testing."" msgstr """" #: ../controller-ha-telemetry.rst:28 ../controller-ha-telemetry.rst:31 msgid ""Recommended solution by the Tooz project."" msgstr """" #: ../storage-ha-backend.rst:41 msgid """" ""Red Hat Linux Enterprise, CentOS, and Fedora: [link to Red Hat install guide]"" msgstr """" #: ../install-ha-ntp.rst:15 msgid ""RedHat: [link to redhat install guide]"" msgstr """" #: ../intro-ha-concepts.rst:21 msgid ""Redundancy and failover"" msgstr """" #: ../storage-ha-backend.rst:85 msgid ""Remote backup facilities"" msgstr """" #: ../controller-ha-galera.rst:120 msgid ""Remove user accounts with empty user names because they cause problems:"" msgstr """" #: ../controller-ha-galera.rst:108 msgid """" ""Replace {NODE_NAME} with the hostname of the server. This is set for logging."" msgstr """" #: ../controller-ha-galera.rst:105 msgid """" ""Replace {PRIMARY_NODE_IP}, {SECONDARY_NODE}, and {TERTIARY__NODE_IP} with "" ""the IP addresses of your servers."" msgstr """" #: ../networking-ha-dhcp.rst:6 msgid ""Run neutron DHCP agent"" msgstr """" #: ../networking-ha-l3.rst:6 msgid ""Run neutron L3 agent"" msgstr """" #: ../networking-ha-lbaas.rst:6 msgid ""Run neutron LBaaS agent"" msgstr """" #: ../networking-ha-metadata.rst:6 msgid ""Run neutron metadata agent"" msgstr """" #: ../controller-ha-rabbitmq.rst:132 msgid ""Run the following commands on each node except the first one:"" msgstr """" #: ../controller-ha-rabbitmq.rst:35 msgid ""SLES 12"" msgstr """" #: ../index.rst:40 msgid ""Search in this guide"" msgstr """" #: ../intro-ha-controller.rst:44 msgid ""See [TODO link] for information about configuring HAProxy."" msgstr """" #: ../intro-ha-controller.rst:27 msgid """" ""See [TODO link] for more information about configuring networking for high "" ""availability."" msgstr """" #: ../networking-ha-l3.rst:27 msgid ""Set automatic L3 agent failover for routers"" msgstr """" #: ../controller-ha-pacemaker.rst:505 msgid ""Set basic cluster properties"" msgstr """" #: ../controller-ha-pacemaker.rst:516 msgid ""Set the following properties:""msgid ""Set up Corosync""#: ../controller-ha-pacemaker.rst:90#: ../controller-ha-pacemaker.rst:239 msgid ""Set up Corosync with unicast"" msgstr """" #: ../controller-ha-pacemaker.rst:328 msgid ""Set up Corosync with votequorum library"" msgstr """" #: ../controller-ha-pacemaker.rst:382""Setting ``last_man_standing`` to 1 enables the Last Man Standing (LMS) "" ""feature; by default, it is disabled (set to 0). If a cluster is on the "" ""quorum edge (``expected_votes:`` set to 7; ``online nodes:`` set to 4) for "" ""longer than the time specified for the ``last_man_standing_window`` "" ""parameter, the cluster can recalculate quorum and continue operating even if "" ""the next node will be lost. This logic is repeated until the number of "" ""online nodes in the cluster reaches 2. In order to allow the cluster to step "" ""down from 2 members to only 1, the ``auto_tie_breaker`` parameter needs to "" ""be set; this is not recommended for production environments.""#: ../controller-ha-pacemaker.rst:376 msgid """" ""Setting ``wait_for_all`` to 1 means that, When starting up a cluster (all "" ""nodes down), the cluster quorum is held until all nodes are online and have "" ""joined the cluster for the first time. This parameter is new in Corosync 2.0.""#: ../controller-ha-pacemaker.rst:547 msgid """" ""Setting the ``pe-warn-series-max``, ``pe-input-series-max`` and ``pe-error-"" ""series-max`` parameters to 1000 instructs Pacemaker to keep a longer history "" ""of the inputs processed and errors and warnings generated by its Policy "" ""Engine. This history is useful if you need to troubleshoot the cluster.""#: ../intro-ha-concepts.rst:169 msgid ""Single-controller high availability mode"" msgstr """" #: ../controller-ha-pacemaker.rst:368 msgid """" ""Specifying ``corosync_votequorum`` enables the votequorum library; this is "" ""the only required option."" msgstr """" #: ../controller-ha-galera.rst:114 msgid ""Start :command:`mysql` as root and execute the following queries:"" msgstr """" #: ../controller-ha-pacemaker.rst:409 msgid ""Start Corosync"" msgstr """" #: ../controller-ha-pacemaker.rst:469 msgid ""Start Pacemaker"" msgstr """" #: ../controller-ha-rabbitmq.rst:121 msgid ""Start RabbitMQ on all nodes and verify that the nodes are running:"" msgstr """" #: ../controller-ha-galera.rst:222 msgid ""Start all the other nodes with the following command:"" msgstr """" #: ../controller-ha-pacemaker.rst:511 msgid """" ""Start the :command:`crm` shell and enter :command:`configure` to change into "" ""the configuration menu."" msgstr """" #: ../controller-ha-galera.rst:424 msgid ""Start the MariaDB cluster:"" msgstr """" #: ../controller-ha-galera.rst:366 msgid ""Start the ``xinetd`` daemon required by ``clustercheck``:"" msgstr """" #: ../intro-ha-concepts.rst:100 msgid ""Stateful service"" msgstr """" #: ../intro-ha-concepts.rst:105 msgid ""Stateful services may be configured as active/passive or active/active:"" msgstr """" #: ../intro-ha-concepts.rst:87 msgid ""Stateless service"" msgstr """" #: ../intro-ha-concepts.rst:75 msgid ""Stateless vs. stateful services"" msgstr """" #: ../controller-ha-galera.rst:215 msgid """" ""Stop all the mysql servers and start the first server with the following "" ""command:"" msgstr """" #: ../hardware-ha-basic.rst:19 msgid ""Storage"" msgstr """" #: ../storage-ha-backend.rst:6 msgid ""Storage back end"" msgstr """" #: ../intro-ha-concepts.rst:39 msgid ""Storage components"" msgstr """" #: ../install-ha-ntp.rst:16 msgid ""SuSe: [link to suse install guide]"" msgstr """" # #-#-#-#-# controller-ha-rabbitmq.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# controller-ha-telemetry.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../controller-ha-rabbitmq.rst:85 ../controller-ha-telemetry.rst:4 msgid ""Telemetry"" msgstr """" #: ../controller-ha-telemetry.rst:9 msgid ""Telemetry central agent"" msgstr """" #: ../storage-ha-glance.rst:51 msgid """" ""The :command:`crm configure` command supports batch input, so you may copy "" ""and paste the above into your live Pacemaker configuration and then make "" ""changes as required. For example, you may enter edit ``p_ip_glance-api`` "" ""from the :command:`crm configure` menu and edit the resource to match your "" ""preferred virtual IP address."" msgstr """" #: ../controller-ha-haproxy.rst:192 msgid """" ""The Galera cluster configuration commands indicate that two of the three "" ""controllers are standby nodes. [TODO: be specific about the coding that "" ""defines this] This ensures that only one node services write requests "" ""because OpenStack support for multi-node writes is not yet production-ready."" msgstr """" #: ../intro-ha-controller.rst:56 msgid """" ""The MySQL/Galera cluster runs behind HAProxy. HAProxy the load balances "" ""incoming requests and exposes just one IP address for all the clients."" msgstr """" #: ../storage-ha-glance.rst:5 msgid """" ""The OpenStack Image service offers a service for discovering, registering, "" ""and retrieving virtual machine images. To make the OpenStack Image API "" ""service highly available in active / passive mode, you must:"" msgstr """" #: ../install-ha-os.rst:16 msgid """" ""The OpenStack Installation Guides also include a list of the services that "" ""use passwords with important notes about using them."" msgstr """" #: ../networking-ha-dhcp.rst:8 msgid """" ""The OpenStack Networking service has a scheduler that lets you run multiple "" ""agents across nodes; the DHCP agent can be natively highly available. To "" ""configure the number of DHCP agents per network, modify the "" ""``dhcp_agents_per_network`` parameter in the :file:`/etc/neutron/neutron."" ""conf` file. By default this is set to 1. To achieve high availability, "" ""assign more than one DHCP agent per network."" msgstr """" #: ../controller-ha-telemetry.rst:11 msgid """" ""The Telemetry central agent can be configured to partition its polling "" ""workload between multiple agents, enabling high availability."" msgstr """" #: ../compute-node-ha-api.rst:6 msgid """" ""The `Installation Guide <http://docs.openstack.org/juno/install-guide/"" ""install/apt/content/ch_nova.html>`_ gives instructions for installing "" ""multiple compute nodes. To make them highly available, you must configure "" ""the envirionment to include multiple instances of the API and other services."" msgstr """" #: ../controller-ha-telemetry.rst:18 msgid """" ""The `Tooz <https://pypi.python.org/pypi/tooz>`__ library provides the "" ""coordination within the groups of service instances. It provides an API "" ""above several back ends that can be used for building distributed "" ""applications."" msgstr """" #: ../controller-ha-keystone.rst:83 msgid """" ""The ``admin_bind_host`` parameter lets you use a private network for admin "" ""access."" msgstr """" #: ../controller-ha-pacemaker.rst:203 msgid """" ""The ``bindnetaddr`` is the network address of the interfaces to bind to. The "" ""example uses two network addresses of /24 IPv4 subnets."" msgstr """" #: ../controller-ha-pacemaker.rst:171#: ../controller-ha-pacemaker.rst:288#: ../controller-ha-pacemaker.rst:371 msgid """" ""The cluster is fully operational with ``expected_votes`` set to 7 nodes "" ""(each node has 1 vote), quorum: 4. If a list of nodes is specified as "" ""``nodelist``, the ``expected_votes`` value is ignored."" msgstr """" #: ../controller-ha-rabbitmq.rst:20 msgid """" ""The commands for installing RabbitMQ are specific to the Linux distribution "" ""you are using:"" msgstr """" #: ../controller-ha-haproxy.rst:26 msgid """" ""The common practice is to locate an HAProxy instance on each OpenStack "" ""controller in the environment."" msgstr """" #: ../intro-ha-controller.rst:20 msgid """" ""The configuration uses static routing without Virtual Router Redundancy "" ""Protocol (VRRP) or similar techniques implemented."" msgstr """" #: ../install-ha-os.rst:6 msgid """" ""The first step in setting up your highly-available OpenStack cluster is to "" ""install the operating system on each node. Follow the instructions in the "" ""OpenStack Installation Guides:"" msgstr """" #: ../controller-ha-galera.rst:6 msgid """" ""The first step is installing the database that sits at the heart of the "" ""cluster. To implement High Availability, run an instance of the database on "" ""each controller node, using Galera for synchronous multi-master replication. "" ""The Galera Cluster plug-in is a multi-master cluster based on synchronous "" ""replication. It is a high availability service that provides high system "" ""uptime, no data loss, and scalability for growth."" msgstr """" #: ../controller-ha-rabbitmq.rst:74 msgid ""The following components/services can work with HA queues:"" msgstr """" #: ../controller-ha-galera.rst:70 msgid """" ""The galara package is now called galera-3 and is already a dependency of "" ""mariadb-galera-server. Therefore it should not be specified on the command "" ""line."" msgstr """" #: ../networking-ha-l3.rst:8 msgid """" ""The neutron L3 agent is scalable, due to the scheduler that supports Virtual "" ""Router Redundancy Protocol (VRRP) to distribute virtual routers across "" ""multiple nodes. To enable high availability for configured routers, edit "" ""the :file:`/etc/neutron/neutron.conf` file to set the following values:"" msgstr """" #: ../intro-ha-concepts.rst:143 msgid """" ""The quorum specifies the minimal number of nodes that must be functional in "" ""a cluster of redundant nodes in order for the cluster to remain functional. "" ""When one node fails and failover transfers control to other nodes, the "" ""system must ensure that data and processes remain sane. To determine this, "" ""the contents of the remaining nodes are compared and, if there are "" ""discrepancies, a \""majority rules\"" algorithm is implemented."" msgstr """" #: ../controller-ha-galera.rst:184 msgid ""The result will be similar to this:"" msgstr """" #: ../controller-ha-pacemaker.rst:219 msgid """" ""The service declaration for the pacemaker service may be placed in the :file:"" ""`corosync.conf` file directly or in its own separate file, :file:`/etc/"" ""corosync/service.d/pacemaker`.""#: ../controller-ha-pacemaker.rst:36 msgid ""The steps to implement the Pacemaker cluster stack are:"" msgstr """" #: ../controller-ha-pacemaker.rst:349""The votequorum library has been created to replace and eliminate qdisk, the "" ""disk-based quorum daemon for CMAN, from advanced cluster configurations.""#: ../controller-ha-pacemaker.rst:330""The votequorum library is part of the corosync project. It provides an "" ""interface to the vote-based quorum service and it must be explicitly enabled "" ""in the Corosync configuration file. The main role of votequorum library is "" ""to avoid split-brain situations, but it also provides a mechanism to:""#: ../controller-ha-pacemaker.rst:534""The`` no-quorum-policy=\""ignore\""`` parameter is required in 2-node "" ""Pacemaker clusters to disable quorum enforcement. if quorum enforcement is "" ""enabled and one of the two nodes fails, then the remaining node can not "" ""establish the majority of quorum votes that are necessary to run services. "" ""This means that it is unable to take over any resources. Ignoring loss of "" ""quorum in the cluster avoids this problem and is appropriate for small "" ""configurations used for study or demonstration purposes. Clusters that "" ""ignore lose of quorum are vulnerable to split-brain because, if both nodes "" ""remain online but lose communication with each other, either node may become "" ""active.""#: ../controller-ha-pacemaker.rst:25""These agents must conform to one of the `OCF <https://github.com/ClusterLabs/"" ""OCF-spec/blob/master/ra/resource-agent-api.md>`_, `SYS-V <http://refspecs."" ""linux-foundation.org/LSB_3.0.0/LSB-Core-generic/LSB-Core-generic/iniscrptact."" ""html>`_, Upstart, or Systemd standards.""#: ../storage-ha-cinder.rst:44""This configuration creates ``p_cinder-api``, a resource for managing the "" ""Block Storage API service.""#: ../storage-ha-glance.rst:48""This configuration creates ``p_glance-api``, a resource for managing the "" ""OpenStack Image API service.""#: ../controller-ha-vip.rst:9""This configuration creates ``p_ip_api``, a virtual IP address for use by the "" ""API node (``192.168.42.103``):""#: ../controller-ha-keystone.rst:52""This configuration creates ``p_keystone``, a resource for managing the "" ""OpenStack Identity service.""#: ../intro-ha-concepts.rst:63#: ../controller-ha-galera.rst:298""This guide assumes that three nodes are used to form the MariaDB Galera "" ""cluster. Unless otherwise specified, all commands need to be executed on all "" ""cluster nodes.""#: ../index.rst:8""This guide describes how to install and configure OpenStack for high "" ""availability. It supplements the OpenStack Installation Guides and assumes "" ""that you are familiar with the material in those guides.""#: ../index.rst:13""This guide documents OpenStack Liberty, OpenStack Kilo, OpenStack Juno, and "" ""OpenStack Icehouse releases.""#: ../index.rst:16""This guide is a work-in-progress and changing rapidly while we continue to "" ""test and enhance the guidance. Please note where there are open \""to do\"" "" ""items and help where you are able.""#: ../storage-ha-glance.rst:14""This section assumes that you are familiar with the `documentation <http://"" ""docs.openstack.org/kilo/install-guide/install/apt/content/ch_glance.html>`_ "" ""for installing the OpenStack Image API service.""#: ../storage-ha-backend.rst:44""This section discusses ways to protect against data loss in your OpenStack "" ""environment.""#: ../controller-ha-keystone.rst:86 msgid """" ""To be sure that all data is highly available, ensure that everything is "" ""stored in the MySQL database (which is also highly available):"" msgstr """" #: ../controller-ha-rabbitmq.rst:106 msgid """" ""To do so, stop RabbitMQ everywhere and copy the cookie from the first node "" ""to each of the other node(s):"" msgstr """" #: ../controller-ha-telemetry.rst:74 msgid """" ""To enable the compute agent to run multiple instances simultaneously with "" ""workload partitioning, the workload_partitioning option has to be set to "" ""``True`` under the `compute section <http://docs.openstack.org/kilo/ config-"" ""reference/content/ch_configuring-openstack-telemetry.html>`__ in the :file:"" ""`ceilometer.conf` configuration file."" msgstr """" #: ../controller-ha-rabbitmq.rst:156 msgid """" ""To ensure that all queues except those with auto-generated names are "" ""mirrored across all running nodes, set the ``ha-mode`` policy key to all by "" ""running the following command on one of the nodes:"" msgstr """" #: ../controller-ha-galera.rst:303 msgid ""To install MariaDB with Galera"" msgstr """" #: ../install-ha-memcached.rst:23 msgid """" ""To install and configure memcached, read the `official documentation "" ""<https://code.google.com/p/memcached/wiki/NewStart>`_."" msgstr """" #: ../controller-ha-rabbitmq.rst:144 msgid ""To verify the cluster status:"" msgstr """" #: ../controller-ha-telemetry.rst:23 msgid """" ""Tooz supports `various drivers <http://docs.openstack.org/developer/tooz/"" ""drivers.html>`__ including the following back end solutions:"" msgstr """" #: ../networking-ha-l3.rst:23 ../networking-ha-l3.rst:26 msgid ""True"" msgstr """" #: ../controller-ha-pacemaker.rst:513 msgid """" ""Type :command:`crm configure` from a shell prompt to jump straight into the "" ""Pacemaker configuration menu."" msgstr """" #: ../intro-ha-concepts.rst:128#: ../controller-ha-rabbitmq.rst:29 msgid ""Ubuntu, Debian"" msgstr """" # #-#-#-#-# install-ha-os.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# storage-ha-backend.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../install-ha-os.rst:14 ../storage-ha-backend.rst:40 msgid ""Ubuntu: [link to Ubuntu install guide]"" msgstr """" #: ../install-ha-ntp.rst:13 msgid ""Ubuntu: [link to ubuntu install guide]"" msgstr """" #: ../controller-ha-galera.rst:61 msgid ""Update your system and install the required packages:"" msgstr """" #: ../controller-ha-rabbitmq.rst:214 msgid ""Use HA queues in RabbitMQ (x-ha-policy: all):"" msgstr """" #: ../intro-ha-controller.rst:70""Use MySQL/Galera in active/passive mode to avoid deadlocks on ``SELECT ... "" ""FOR UPDATE`` type queries (used, for example, by nova and neutron). This "" ""issue is discussed more in the following:""#: ../controller-ha-rabbitmq.rst:208 msgid ""Use durable queues in RabbitMQ:""#: ../controller-ha-pacemaker.rst:426""Use the :command:`corosync-cfgtool` utility with the :option:`-s` option to "" ""get a summary of the health of the communication rings:""#: ../controller-ha-pacemaker.rst:441""Use the :command:`corosync-objctl` utility to dump the Corosync cluster "" ""member list:""#: ../controller-ha-galera.rst:169""Use the following command after the copy to verify that all files are "" ""identical:""#: ../networking-ha-l3.rst:20 msgid ""Value"" msgstr """" #: ../controller-ha-galera.rst:126""Verify that the nodes can access each other through the firewall. On Red "" ""Hat, this means adjusting :manpage:`iptables(8)`, as in:""#: ../controller-ha-galera.rst:228""Verify the wsrep replication by logging in as root under mysql and running "" ""the following command:""#: ../controller-ha-rabbitmq.rst:71""We are building a cluster of RabbitMQ nodes to construct a RabbitMQ broker, "" ""which is a logical grouping of several Erlang nodes.""#: ../controller-ha-rabbitmq.rst:176""We have to configure the OpenStack components to use at least two RabbitMQ "" ""nodes.""#: ../controller-ha-rabbitmq.rst:87 msgid """" ""We have to consider that, while exchanges and bindings survive the loss of "" ""individual nodes, queues and their messages do not because a queue and its "" ""contents are located on one node. If we lose this node, we also lose the "" ""queue."" msgstr """" #: ../storage-ha-backend.rst:77 msgid """" ""When Ceph RBD is used for ephemeral volumes as well as block and image "" ""storage, it supports `live migration <http://docs.openstack.org/admin-guide-"" ""cloud/compute-live-migration-usage.html>`_ of VMs with ephemeral drives; LVM "" ""only supports live migration of volume-backed VMs."" msgstr """" #: ../intro-ha-concepts.rst:162#: ../hardware-ha-basic.rst:46""When installing highly-available OpenStack on VMs, be sure that your "" ""hypervisor permits promiscuous mode and disables MAC address filtering on "" ""the external network.""#: ../controller-ha-pacemaker.rst:187""With ``secauth`` enabled, Corosync nodes mutually authenticate using a 128-"" ""byte shared secret stored in the :file:`/etc/corosync/authkey` file, which "" ""may be generated with the :command:`corosync-keygen` utility. When using "" ""``secauth``, cluster communications are also encrypted.""#: ../controller-ha-pacemaker.rst:297""Within the ``nodelist`` directive, it is possible to specify specific "" ""information about the nodes in the cluster. The directive can contain only "" ""the node sub-directive, which specifies every node that should be a member "" ""of the membership, and where non-default options are needed. Every node must "" ""have at least the ``ring0_addr`` field filled.""#: ../controller-ha-telemetry.rst:46""Without the ``backend_url`` option being set only one instance of both the "" ""central and compute agent service is able to run and function correctly.""#: ../controller-ha-keystone.rst:120""You also need to create the OpenStack Identity Endpoint with this IP address.""#: ../controller-ha-galera.rst:26""You can also use PostgreSQL, which has its own replication, or another "" ""database HA option.""#: ../controller-ha-galera.rst:58""You can choose a different mirror from the list at `downloads.mariadb.org "" ""<https://downloads.mariadb.org>`_""#: ../controller-ha-galera.rst:39""You can find additional information about installing and configuring Galera/"" ""MySQL in:""#: ../storage-ha-cinder.rst:28 msgid """" ""You can now add the Pacemaker configuration for Block Storage API resource. "" ""Connect to the Pacemaker cluster with the :command:`crm configure` command "" ""and add the following cluster resources:""#: ../storage-ha-glance.rst:33 msgid """" ""You can now add the Pacemaker configuration for the OpenStack Image API "" ""resource. Use the :command:`crm configure` command to connect to the "" ""Pacemaker cluster and add the following cluster resources:"" msgstr """" #: ../controller-ha-keystone.rst:36 msgid """" ""You can now add the Pacemaker configuratioon for the OpenStack Identity "" ""resource by running the :command:`crm configure` command to connect to the "" ""Pacemaker cluster. Add the following cluster resources:"" msgstr """" #: ../controller-ha-pacemaker.rst:424 msgid ""You can now check the Corosync connectivity with two tools."" msgstr """" #: ../controller-ha-galera.rst:139 msgid """" ""You may also need to configure any NAT firewall between nodes to allow "" ""direct connections. You may need to disable SELinux or configure it to allow "" ""``mysqld`` to listen to sockets at unprivileged ports. See the `Firewalls "" ""and default ports <http://docs.openstack.org/kilo/config-reference/content/"" ""firewalls-default-ports.html>`_ section of the Configuration Reference."" msgstr """" #: ../storage-ha-glance.rst:124 msgid """" ""You must also create the OpenStack Image API endpoint with this IP address. "" ""If you are using both private and public IP addresses, you should create two "" ""Virtual IP addresses and define your endpoint like this:"" msgstr """" #: ../controller-ha-telemetry.rst:36 msgid """" ""You must configure a supported Tooz driver for the HA deployment of the "" ""Telemetry services."" msgstr """" #: ../storage-ha-cinder.rst:96 msgid ""You must create the Block Storage API endpoint with this IP."" msgstr """" #: ../controller-ha-keystone.rst:25 msgid """" ""You must first download the OpenStack Identity resource to Pacemaker by "" ""running the following commands:"" msgstr """" # #-#-#-#-# storage-ha-cinder.pot (High Availability Guide 0.0.1) #-#-#-#-# # #-#-#-#-# storage-ha-glance.pot (High Availability Guide 0.0.1) #-#-#-#-# #: ../storage-ha-cinder.rst:20 ../storage-ha-glance.rst:24 msgid ""You must first download the resource agent to your system:"" msgstr """" #: ../install-ha-ntp.rst:6 msgid """" ""You must install NTP to properly synchronize services among nodes. We "" ""recommend that you configure the controller node to reference more accurate "" ""(lower stratum) servers and other nodes to reference the controller node."" msgstr """" #: ../controller-ha-vip.rst:6 msgid """" ""You must select and assign a virtual IP address (VIP) that can freely float "" ""between cluster nodes."" msgstr """" #: ../controller-ha-galera.rst:177 msgid """" ""You need to get the database password from the :file:`debian.cnf` file. You "" ""can do this with the following command:"" msgstr """" #: ../controller-ha-pacemaker.rst:454 msgid """" ""You should see a ``status=joined`` entry for each of your constituent "" ""cluster nodes."" msgstr """" #: ../storage-ha-cinder.rst:90 msgid """" ""Your OpenStack services must now point their Block Storage API configuration "" ""to the highly available, virtual cluster IP address rather than a Block "" ""Storage API server’s physical IP address as you would for a non-HA "" ""environment."" msgstr """" #: ../controller-ha-keystone.rst:105 msgid """" ""Your OpenStack services must now point their OpenStack Identity "" ""configuration to the highly available virtual cluster IP address rather than "" ""point to the physical IP address of an OpenStack Identity server as you "" ""would do in a non-HA environment."" msgstr """" #: ../storage-ha-glance.rst:99 msgid """" ""Your OpenStack services must now point their OpenStack Image API "" ""configuration to the highly available, virtual cluster IP address instead of "" ""pointint to the physical IP address of an OpenStack Image API server as you "" ""would in a non-HA cluster."" msgstr """" #: ../controller-ha-telemetry.rst:6 msgid ""[TODO (Add Telemetry overview)]"" msgstr """" #: ../controller-ha-haproxy.rst:13 msgid ""[TODO (Add note about using commercial load-balancers]"" msgstr """" #: ../install-ha.rst:5 msgid ""[TODO -- write intro to this section]"" msgstr """" #: ../intro-ha-controller.rst:9 msgid """" ""[TODO Discuss SLA (Service Level Agreement), if this is the measure we use. "" ""Other possibilities include MTTR (Mean Time To Recover), RTO (Recovery Time "" ""Objective), and ETR (Expected Time of Repair,]"" msgstr """" #: ../intro-ha-controller.rst:24 msgid """" ""[TODO Need description of VIP failover inside Linux namespaces and expected "" ""SLA.]"" msgstr """" #: ../intro-ha-controller.rst:17#: ../install-ha-os.rst:10 msgid ""[TODO(DreidelLhasa): Replace the following with real links]"" msgstr """" #: ../install-ha-memcached.rst:6""[TODO: Verify that Oslo supports hash synchronization; if so, this should "" ""not take more than load balancing.]""#: ../storage-ha-backend.rst:87""[TODO: Add discussion of remote backup facilities as an alternate way to "" ""secure ones data. Include brief mention of key third-party technologies with "" ""links to their documentation]""#: ../controller-ha-rabbitmq.rst:78""[TODO: Does this list need to be updated? Perhaps we need a table that "" ""shows each component and the earliest release that allows it to work with HA "" ""queues.]""#: ../hardware-ha.rst:6""[TODO: Provide a minimal architecture example for HA, expanded on that given "" ""in http://docs.openstack.org/juno/install-guide/install/apt/content/"" ""ch_basic_environment.html#basics-prerequisites for easy comparison]""#: ../controller-ha-rabbitmq.rst:104 msgid ""[TODO: Should the example instead use a minimum of three nodes?]"" msgstr """" #: ../controller-ha-pacemaker.rst:457""[TODO: Should the main example now use corosync-cmapctl and have the note "" ""give the command for Corosync version 1?]""#: ../controller-ha-galera.rst:315 msgid ""[TODO: Should this be moved to some other place?]""#: ../install-ha-memcached.rst:30 msgid ""[TODO: Should this show three hosts?]""#: ../install-ha-memcached.rst:9""[TODO: This hands off to two different docs for install information. We "" ""should choose one or explain the specific purpose of each.]""#: ../controller-ha-rabbitmq.rst:68""[TODO: This section should begin with a brief mention about what HA queues "" ""are and why they are valuable, etc]""#: ../networking-ha.rst:23#: ../hardware-ha-basic.rst:16 msgid ""[TODO: Verify that these numbers are good]""msgid ""[TODO: add proper links to the install guides]"" msgstr """" #: ../controller-ha-galera.rst:441 msgid ""[TODO: is the kill command necessary here?]"" msgstr """" #: ../storage-ha-glance.rst:92 msgid ""[TODO: need more discussion of these parameters]"" msgstr """" #: ../controller-ha-galera.rst:48 msgid ""[TODO: provide instructions for SUSE and Red Hat]"" msgstr """" #: ../controller-ha-rabbitmq.rst:76 msgid ""[TODO: replace \""currently\"" with specific release names]"" msgstr """" #: ../controller-ha-galera.rst:29""[TODO: the structure of the MySQL and MariaDB sections should be made "" ""parallel]""#: ../networking-ha-lbaas.rst:16 msgid ""[TODO: update this section.]""#: ../controller-ha-haproxy.rst:198""[TODO: we need more commentary about the contents and format of this file]""#: ../controller-ha-rabbitmq.rst:38 msgid ""[Verify fingerprint of imported GPG key; see below]""#: ../storage-ha-backend.rst:58#: ../controller-ha-rabbitmq.rst:168 msgid ""`Clustering Guide <https://www.rabbitmq.com/clustering.html>`_"" msgstr """" #: ../controller-ha-rabbitmq.rst:59 msgid ""`Debian and Ubuntu <http://www.rabbitmq.com/install-debian.html>`_"" msgstr """" #: ../controller-ha-galera.rst:43""`Galera Getting Started guide <http://galeracluster.com/documentation-"" ""webpages/gettingstarted.html>`_""#: ../controller-ha-rabbitmq.rst:167 msgid ""`Highly Available Queues <http://www.rabbitmq.com/ha.html>`_"" msgstr """" #: ../networking-ha.rst:28""`LP1328922 <https://bugs.launchpad.net/openstack-manuals/+bug/1328922>` and "" ""`LP1349398 <https://bugs.launchpad.net/openstack-manuals/+bug/1349398>` are "" ""related.]""#: ../controller-ha-galera.rst:21""`MariaDB Galera Cluster <https://mariadb.org/>`_ is supported for "" ""environments based on Red Hat distributions; configuration instructions are "" ""in :ref:`maria-db-ha`.""#: ../controller-ha-telemetry.rst:34 msgid ""`Memcached <http://memcached.org/>`__.""#: ../controller-ha-galera.rst:24 msgid ""`Percona XtraDB Cluster <http://www.percona.com/>`_ works with Galera."" msgstr """" #: ../controller-ha-rabbitmq.rst:60""`RPM based <http://www.rabbitmq.com/install-rpm.html>`_ (RHEL, Fedora, "" ""CentOS, openSUSE)""#: ../controller-ha-telemetry.rst:31 msgid ""`Redis <http://redis.io/>`__."" msgstr """" #: ../controller-ha-telemetry.rst:28 msgid ""`Zookeeper <http://zookeeper.apache.org/>`__."" msgstr """" #: ../controller-ha-pacemaker.rst:397""``last_man_standing_window`` specifies the time, in milliseconds, required "" ""to recalculate quorum after one or most hosts have been lost from the "" ""cluster. To do the new quorum recalculation, the cluster must have quorum "" ""for at least the interval specified for ``last_man_standing_window``; the "" ""default is 10000ms.""#: ../controller-ha-pacemaker.rst:315""``nodeid`` is optional when using IPv4 and required when using IPv6. This is "" ""a 32-bit value specifying the node identifier delivered to the cluster "" ""membership service. If this is not specified with IPv4, the node id is "" ""determined from the 32-bit IP address of the system to which the system is "" ""bound with ring identifier of 0. The node identifier value of zero is "" ""reserved and should not be used.""#: ../controller-ha-pacemaker.rst:312""``ring{X}_addr`` specifies the IP address of one of the nodes. {X} is the "" ""ring number.""#: ../intro-ha-controller.rst:75""`http://lists.openstack.org/pipermail/openstack-dev/2014-May/035264.html`""#: ../intro-ha-controller.rst:76 ../intro-ha-controller.rst:77 msgid ""`http://www.joinfu.com/`""#: ../hardware-ha-basic.rst:8""`neutron <http://docs.openstack.org/juno/install-guide/install/apt/content/"" ""ch_overview.html#example-architecture-with-neutron-networking-hw>`_""#: ../hardware-ha-basic.rst:9""`nova-network <http://docs.openstack.org/juno/install-guide/install/apt/"" ""content/ch_overview.html#example-architecture-with-legacy-networking-hw>`_""#: ../controller-ha-galera.rst:42""`wsrep readme file <https://launchpadlibrarian.net/66669857/README-wsrep>`_""#: ../networking-ha-l3.rst:25 msgid ""allow_automatic_l3agent_failover"" msgstr """" #: ../controller-ha-pacemaker.rst:64 msgid ""cluster-glue"" msgstr """" #: ../hardware-ha-basic.rst:25 msgid ""compute node"" msgstr """" #: ../hardware-ha-basic.rst:21 msgid ""controller node"" msgstr """" #: ../controller-ha-pacemaker.rst:62 msgid ""corosync"" msgstr """" #: ../controller-ha-pacemaker.rst:60 msgid ""crmsh"" msgstr """" #: ../controller-ha-pacemaker.rst:66""fence-agents (Fedora only; all other distributions use fencing agents from "" ""cluster-glue)""#: ../networking-ha-l3.rst:22 msgid ""l3_ha""#: ../networking-ha-l3.rst:28 msgid ""max_l3_agents_per_router""#: ../networking-ha-l3.rst:31 msgid ""min_l3_agents_per_router""#: ../hardware-ha-basic.rst:23 msgid ""network node""#: ../controller-ha-rabbitmq.rst:33 msgid ""openSUSE""#: ../storage-ha-backend.rst:39 msgid ""openSUSE and SUSE Linux Enterprise: [link to SUSE install guide]""#: ../install-ha-os.rst:13 msgid ""openSUSE, SUSE Linux Enterprise Server: [link to SUSE install guide]""#: ../controller-ha-pacemaker.rst:58 msgid ""pacemaker (Note that the crm shell should be downloaded separately.)""#: ../controller-ha-pacemaker.rst:69 msgid ""resource-agents""",6739,2343
openstack%2Fcinder~master~I716a7e6067f5fc0f90623822a40e532af80bae44,openstack/cinder,master,I716a7e6067f5fc0f90623822a40e532af80bae44,Cleanup in backup reset status,MERGED,2015-11-18 05:21:07.000000000,2016-02-15 05:59:26.000000000,2016-02-11 06:25:13.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 8912}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11224}, {'_account_id': 11904}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16952}, {'_account_id': 17405}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18573}, {'_account_id': 18695}, {'_account_id': 19004}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-11-18 05:21:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e5b00ba5e11306b0fd73b240f4de824f172d8ee0', 'message': 'Cleanup in backup reset status\n\nCurrently when resetting status of a backup to error\nstate, it just changes the state.\n\nThis fix is to add the cleanup work to remove the\ntemporary volumes and snapshots.\n\nChange-Id: I716a7e6067f5fc0f90623822a40e532af80bae44\nCloses-bugs: #1517297\n'}, {'number': 2, 'created': '2015-11-18 05:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c6ea2bfe58a0740a091f6e45b59cf67c3edda3a', 'message': 'Cleanup in backup reset status\n\nCurrently when resetting status of a backup to error\nstate, it just changes the state.\n\nThis fix is to add the cleanup work to remove the\ntemporary volumes and snapshots.\n\nChange-Id: I716a7e6067f5fc0f90623822a40e532af80bae44\nCloses-Bug: #1517297\n'}, {'number': 3, 'created': '2015-11-19 05:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/49a6c7dd2d937849e4674a8af7972907ebbaf75a', 'message': 'Cleanup in backup reset status\n\nCurrently when resetting status of a backup to error\nstate, it just changes the state.\n\nThis fix is to add the cleanup work to remove the\ntemporary volumes and snapshots.\n\nChange-Id: I716a7e6067f5fc0f90623822a40e532af80bae44\nCloses-Bug: #1517297\n'}, {'number': 4, 'created': '2015-12-02 03:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eec667bddec8a2da92f2fe9ccc2eb6d814b5620d', 'message': 'Cleanup in backup reset status\n\nCurrently when resetting status of a backup to error\nstate, it just changes the state.\n\nThis fix is to add the cleanup work to remove the\ntemporary volumes and snapshots.\n\nChange-Id: I716a7e6067f5fc0f90623822a40e532af80bae44\nCloses-Bug: #1517297\n'}, {'number': 5, 'created': '2016-01-06 01:47:56.000000000', 'files': ['cinder/backup/manager.py', 'cinder/tests/unit/test_backup.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0cf0b6ee8c8ce5b4b82647e36d4d65bc0192edaa', 'message': 'Cleanup in backup reset status\n\nCurrently when resetting status of a backup to error\nstate, it just changes the state.\n\nThis fix is to add the cleanup work to remove the\ntemporary volumes and snapshots.\n\nChange-Id: I716a7e6067f5fc0f90623822a40e532af80bae44\nCloses-Bug: #1517297\n'}]",2,246748,0cf0b6ee8c8ce5b4b82647e36d4d65bc0192edaa,167,50,5,15961,,,0,"Cleanup in backup reset status

Currently when resetting status of a backup to error
state, it just changes the state.

This fix is to add the cleanup work to remove the
temporary volumes and snapshots.

Change-Id: I716a7e6067f5fc0f90623822a40e532af80bae44
Closes-Bug: #1517297
",git fetch https://review.opendev.org/openstack/cinder refs/changes/48/246748/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/backup/manager.py', 'cinder/tests/unit/test_backup.py']",2,e5b00ba5e11306b0fd73b240f4de824f172d8ee0,bug/1517297," @mock.patch.object(manager.BackupManager, '_cleanup_temp_volumes_snapshots_for_one_backup') self, mock_clean_temp): mock_clean_temp.assert_called_once_with(self.ctxt, backup) @mock.patch.object(manager.BackupManager, '_cleanup_temp_volumes_snapshots_for_one_backup') def test_backup_reset_status_from_restoring_to_available( self, mock_clean_temp): mock_clean_temp.assert_called_once_with(self.ctxt, backup) @mock.patch.object(manager.BackupManager, '_cleanup_temp_volumes_snapshots_for_one_backup') def test_backup_reset_status_to_error(self, mock_clean_temp): mock_clean_temp.assert_called_once_with(self.ctxt, backup)", self): def test_backup_reset_status_from_restoring_to_available(self): def test_backup_reset_status_to_error(self):,17,3
openstack%2Fcinder~master~I357b87fa3a2856553c71c7f5f37e9f82ff44f6f2,openstack/cinder,master,I357b87fa3a2856553c71c7f5f37e9f82ff44f6f2,Add variable QoS to NetApp cDOT drivers,MERGED,2016-02-10 15:19:15.000000000,2016-02-15 05:53:33.000000000,2016-02-12 00:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 9008}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12924}, {'_account_id': 14797}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16941}]","[{'number': 1, 'created': '2016-02-10 15:19:15.000000000', 'files': ['cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/volume/drivers/netapp/dataontap/block_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/tests/unit/volume/drivers/netapp/fakes.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/volume/drivers/netapp/dataontap/block_cmode.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/tests/unit/volume/drivers/netapp/test_utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/af1a69fc45a7ccad63fcd5bcac0fa21b3d45fdaa', 'message': 'Add variable QoS to NetApp cDOT drivers\n\nMost QoS implementations involve fixed limits, such as maxIOPS\nor maxBPS.  But there are clouds that offer QoS limits that are\npartly based on capacity of the underlying resource.  This commit\nadds two new QoS flags to the NetApp cDOT drivers, maxIOPSperGiB\nand maxBPSperGiB, which implement this capability.  A light\nrefactor of the snapshot delete paths was required to separate\nthose from the volume delete paths, since only the latter should\ninvolve the QoS logic.\n\nImplements: blueprint add-variable-qos-to-netapp-cdot-drivers\nChange-Id: I357b87fa3a2856553c71c7f5f37e9f82ff44f6f2\n'}]",2,278430,af1a69fc45a7ccad63fcd5bcac0fa21b3d45fdaa,45,11,1,11865,,,0,"Add variable QoS to NetApp cDOT drivers

Most QoS implementations involve fixed limits, such as maxIOPS
or maxBPS.  But there are clouds that offer QoS limits that are
partly based on capacity of the underlying resource.  This commit
adds two new QoS flags to the NetApp cDOT drivers, maxIOPSperGiB
and maxBPSperGiB, which implement this capability.  A light
refactor of the snapshot delete paths was required to separate
those from the volume delete paths, since only the latter should
involve the QoS logic.

Implements: blueprint add-variable-qos-to-netapp-cdot-drivers
Change-Id: I357b87fa3a2856553c71c7f5f37e9f82ff44f6f2
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/278430/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/netapp/dataontap/client/fakes.py', 'cinder/volume/drivers/netapp/utils.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/client/test_client_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_7mode.py', 'cinder/volume/drivers/netapp/dataontap/block_7mode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/fakes.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_base.py', 'cinder/tests/unit/volume/drivers/netapp/fakes.py', 'cinder/volume/drivers/netapp/dataontap/nfs_base.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_block_cmode.py', 'cinder/tests/unit/volume/drivers/netapp/dataontap/test_nfs_base.py', 'cinder/volume/drivers/netapp/dataontap/block_cmode.py', 'cinder/volume/drivers/netapp/dataontap/client/client_cmode.py', 'cinder/volume/drivers/netapp/dataontap/block_base.py', 'cinder/tests/unit/volume/drivers/netapp/test_utils.py']",15,af1a69fc45a7ccad63fcd5bcac0fa21b3d45fdaa,bp/add-variable-qos-to-netapp-cdot-drivers," def test_map_qos_spec_maxiopspergib(self): qos_spec = {'maxIOPSperGiB': 1000} mock_get_name = self.mock_object(na_utils, 'get_qos_policy_group_name') mock_get_name.return_value = 'fake_qos_policy' expected = { 'policy_name': 'fake_qos_policy', 'max_throughput': '42000iops', } result = na_utils.map_qos_spec(qos_spec, fake.VOLUME) self.assertEqual(expected, result) def test_map_qos_spec_maxbpspergib(self): qos_spec = {'maxBPSperGiB': 100000} mock_get_name = self.mock_object(na_utils, 'get_qos_policy_group_name') mock_get_name.return_value = 'fake_qos_policy' expected = { 'policy_name': 'fake_qos_policy', 'max_throughput': '4200000B/s', } result = na_utils.map_qos_spec(qos_spec, fake.VOLUME) self.assertEqual(expected, result) ",,597,32
openstack%2Ftempest~master~Ie148275aaa789b227567d635708c41ec7ddfc875,openstack/tempest,master,Ie148275aaa789b227567d635708c41ec7ddfc875,Adding negative tests for zaqar queues v1.0,ABANDONED,2016-02-11 09:51:13.000000000,2016-02-15 05:51:33.000000000,,"[{'_account_id': 3}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 15285}]","[{'number': 1, 'created': '2016-02-11 09:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/943bed63bf14312fd17bcd38f23f14f5c06cf713', 'message': 'Adding negative tests for zaqar queues v1.0\n\nChange-Id: Ie148275aaa789b227567d635708c41ec7ddfc875\n'}, {'number': 2, 'created': '2016-02-12 10:38:18.000000000', 'files': ['tempest/services/messaging/json/messaging_client.py', 'tempest/api/messaging/test_queues_negative.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/175cd9e8311142967409686d75ea74ab03d38c23', 'message': 'Adding negative tests for zaqar queues v1.0\n\nChange-Id: Ie148275aaa789b227567d635708c41ec7ddfc875\n'}]",0,278955,175cd9e8311142967409686d75ea74ab03d38c23,9,4,2,15285,,,0,"Adding negative tests for zaqar queues v1.0

Change-Id: Ie148275aaa789b227567d635708c41ec7ddfc875
",git fetch https://review.opendev.org/openstack/tempest refs/changes/55/278955/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/messaging/json/messaging_client.py', 'tempest/api/messaging/test_queues_negative.py']",2,943bed63bf14312fd17bcd38f23f14f5c06cf713,bp/tempest-tests-zaqar,"# -*- coding: utf-8 -*- # Copyright (c) 2014 Rackspace, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import logging import six import uuid import re import string import json from six import moves from tempest_lib.common.utils import data_utils from tempest_lib import exceptions as lib_exc from testtools import matchers from tempest.api.messaging import base from tempest import test from tempest.common import tempest_fixtures as fixtures from six.moves.urllib import parse as urllib from tempest.api_schema.response.messaging.v1 import queues as queues_schema from tempest import config CONF = config.CONF LOG = logging.getLogger(__name__) class QueueNegativeTestJSON(base.BaseMessagingTest): """""" Tests Queues Negative """""" @classmethod def resource_setup(cls): super(QueueNegativeTestJSON, cls).resource_setup() cls.queues = list() for _ in moves.xrange(5): queue_name = data_utils.rand_name('Queues-Test') cls.queues.append(queue_name) cls.client.create_queue(queue_name) #Create Queues @test.attr(type=['negative']) def test_queue_has_a_long_name(self): # the length of queue name should >= 1 and <=64 bytes queue_name = 'q' * 65 self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) def test_queue_name_is_not_specified(self): # the length of queue name should >= 1 and <=64 bytes queue_name = ' ' self.assertRaises(lib_exc.UnexpectedResponseCode, self.client.create_queue, queue_name) @test.attr(type=['negative']) def test_queue_name_has_a_invalid_character_set(self): # invalid name with characters queue_name = '@$@^qw@' self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) def test_queue_name_with_non_ASCII_characters(self): # invalid name with non-ASCII characters queue_name = data_utils.rand_name('\u6c49\u5b57\u6f22\u5b57') self.assertRaises(lib_exc.BadRequest, self.client.create_queue, queue_name) @test.attr(type=['negative']) def test_queue_name_with_numeric_values(self): # invalid name with characters queue_name = data_utils.rand_int_id() resp, _ = self.client.create_queue(queue_name) self.assertEqual('201' , resp['status']) @test.attr(type=['negative']) def test_create_queue_with_invalid_auth_token(self): # trying to create queue with empty headers # X-Auth-Token is not provided queue_name = data_utils.rand_name(name='queue') self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.create_queue, queue_name) @test.attr(type=['negative']) def test_check_queue_head_for_nonexistent_queue(self): #check non-existant queue head nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.head_queue,nonexistent_queuename) #List Queues @test.attr(type=['negative']) def test_request_a_nonexistent_queue(self): # List a non-existent queue nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue, nonexistent_queuename) @test.attr(type=['negative']) def test_request_after_deleting_queue(self): #Request a queue after deleting the queue #DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue, queue_name) @test.attr(type=['negative']) def test_request_with_a_greater_limit_value(self): # The limit for listing queues is between 1 - 20 , configurable params = {'limit': '200'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) def test_request_with_zero_limit_value(self): # The limit for listing queues is between 1 to 20 , configurable params = {'limit': '0'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) def test_request_with_negative_limit_value(self): # The limit for listing queues is from 1 to 20 , configurable params = {'limit': '-1'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params=params) @test.attr(type=['negative']) def test_request_with_malformed_marker(self): # Listing queues with invalid marker value params = {'marker': 'ZZZzzz..LetMeSleep'} resp, _ = self.client.list_queues_with_params(params) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_with_non_boolean_value_for_detailed(self): # Value for detailed parameter should be true or false params = {'detailed': 'None'} self.assertRaises(lib_exc.BadRequest, self.client.list_queues_with_params, params) @test.attr(type=['negative']) def test_request_with_invalid_params(self): # Listing queues params are limit, marker ,detailed params = {'Invalid': 'ImAnInvalidParam'} resp, _ = self.client.list_queues_with_params(params) self.assertEqual('200', resp['status']) @test.attr(type=['negative']) def test_list_with_invalid_auth_token(self): # trying to list queue with empty headers # X-Auth-Token is not provided queue_name = data_utils.rand_name(name='queue') self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.list_queues) #Set Queue Metadata @test.attr(type=['negative']) def test_queue_metadata_with_empty_request_body(self): #Passing empty metadata body to a queue body = ' ' queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, body) @test.attr(type=['negative']) def test_queue_metadata_with_invalid_metadata_key(self): #Set queue metadata with a long metadata key queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] value = ""a"" * 6 req_body = dict() req_body[(""key"" * 1000)] = value resp, _ = self.client.set_queue_metadata(queue_name, req_body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_by_adding_metadata_to_queue_with_existing_metadata(self): # Attempt to add metadata to a queue with metadata # Updates the current metadata value to new metadata value queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] req_body = {""Key"": ""Value""} resp, _ = self.client.set_queue_metadata(queue_name, req_body) new_req_body = {""New_Key"": ""New_Value""} resp, _ = self.client.set_queue_metadata(queue_name, new_req_body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_request_add_metadata_to_a_nonexistent_queue(self): #Add metadata to a non-existent queue body = {""Key"": ""Value""} nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.set_queue_metadata, nonexistent_queuename, body) @test.attr(type=['negative']) def test_queue_metadata_with_non_JSON_body(self): #Passing the body in a non-JSON format queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] req_body = ""123"" self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, req_body) @test.attr(type=['negative']) def test_queue_metadata_with_request_body_greater_than_configured_bytes(self): #The maximum metadata size for a queue is 65536, configurable queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] value = ""a"" * 655367 req_body = dict() req_body[(""key"")] = value self.assertRaises(lib_exc.BadRequest, self.client.set_queue_metadata, queue_name, req_body) @test.attr(type=['negative']) def test_queue_metadata_with_empty_metadata_key_value(self): queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] body = {'': 'data1'} resp, _ = self.client.set_queue_metadata(queue_name, body) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_set_queue_metadata_with_invalid_auth_token(self): # trying to set queue metadata with empty headers # X-Auth-Token is not provided queue = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] body = {""metadata"": ""My Queue""} self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.set_queue_metadata, queue, body) #Get Queue Metadata @test.attr(type=['negative']) def test_request_when_no_metadata_exists_for_the_queue(self): #show queue metadata for a queue with no metadata queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] resp, _ = self.client.show_queue_metadata(queue_name) self.assertEqual('200', resp['status']) @test.attr(type=['negative']) def test_request_metadata_for_nonexistent_queue(self): #show metadata for a non-existent queue nonexistent_queuename = data_utils.rand_name('Rand_Queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue_metadata, nonexistent_queuename) @test.attr(type=['negative']) def test_request_metadata_after_deleting_queue(self): #Get the queue metadata after deleting the queue #DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue_metadata, queue_name) @test.attr(type=['negative']) def test_get_queue_metadata_with_invalid_auth_token(self): # trying to get queue metadata with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.show_queue_metadata, queue_name) #Get Queue Stats @test.attr(type=['negative']) def test_request_stats_for_a_non_existing_queue(self): #show stats for a non-existent queue nonexistent_queuename = data_utils.rand_name('rand_queuename') self.assertRaises(lib_exc.NotFound, self.client.show_queue_stats, nonexistent_queuename) @test.attr(type=['negative']) def test_request_queue_stats_after_deleting_queue(self): #List queue stats after deleting the queue #DELETE is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) self.assertRaises(lib_exc.NotFound, self.client.show_queue_stats, queue_name) @test.attr(type=['negative']) def test_request_queue_stats_with_invalid_auth_token(self): # Get queue stats with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.show_queue_stats, queue_name) #Delete Queues @test.attr(type=['negative']) def test_delete_a_non_existent_queue(self): #Delete is an idempotent operation non_existent_queue = data_utils.rand_name('Queue_name') resp, _ = self.client.delete_queue(non_existent_queue) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_delete_the_deleted_queue(self): # Delete is an idempotent operation queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.delete_queue(queue_name) # Delete again resp, _ = self.client.delete_queue(queue_name) self.assertEqual('204', resp['status']) @test.attr(type=['negative']) def test_delete_queue_with_invalid_auth_token(self): # Delete queue with empty headers # X-Auth-Token is not provided queue_name = self.queues[data_utils.rand_int_id(0, len(self.queues) - 1)] self.client.auth_provider.set_alt_auth_data( request_part='headers', auth_data=None ) self.assertRaises(lib_exc.Unauthorized, self.client.delete_queue, queue_name) @classmethod def resource_cleanup(cls): for queue_name in cls.queues: cls.client.delete_queue(queue_name) super(QueueNegativeTestJSON, cls).resource_cleanup() ",,412,0
openstack%2Fpython-heatclient~master~I40efd6ae3ca36f0331a1e4239c5139e0af654272,openstack/python-heatclient,master,I40efd6ae3ca36f0331a1e4239c5139e0af654272,Validate for empty file for stack-adopt,MERGED,2016-01-13 21:43:09.000000000,2016-02-15 05:41:33.000000000,2016-02-15 05:41:33.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 10487}, {'_account_id': 13217}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-01-13 21:43:09.000000000', 'files': ['heatclient/tests/unit/test_shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/c2d40fe05c373428ff4edd04904aec5152a0b695', 'message': 'Validate for empty file for stack-adopt\n\nCheck if adopt-file has content and\nif not then display error\n\nChange-Id: I40efd6ae3ca36f0331a1e4239c5139e0af654272\nCloses-Bug: #1299161\n'}]",0,267189,c2d40fe05c373428ff4edd04904aec5152a0b695,9,7,1,11622,,,0,"Validate for empty file for stack-adopt

Check if adopt-file has content and
if not then display error

Change-Id: I40efd6ae3ca36f0331a1e4239c5139e0af654272
Closes-Bug: #1299161
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/89/267189/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/tests/unit/test_shell.py', 'heatclient/v1/shell.py']",2,c2d40fe05c373428ff4edd04904aec5152a0b695,bug/1299161," if not len(adopt_data): raise exc.CommandError('Invalid adopt-file, no data!') ",,13,0
openstack%2Fheat~master~I353e5d614df107067f6b249f225108a39fa0d439,openstack/heat,master,I353e5d614df107067f6b249f225108a39fa0d439,Updated from global requirements,MERGED,2016-02-11 07:39:14.000000000,2016-02-15 05:36:44.000000000,2016-02-15 05:36:43.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7385}, {'_account_id': 16203}]","[{'number': 1, 'created': '2016-02-11 07:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fa24804eb73df356b76612ca0e0d602c480334de', 'message': 'Updated from global requirements\n\nChange-Id: I353e5d614df107067f6b249f225108a39fa0d439\n'}, {'number': 2, 'created': '2016-02-11 14:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/57e9c7162c26dc0c35ffe34920dd2f0b22cfeaaf', 'message': 'Updated from global requirements\n\nChange-Id: I353e5d614df107067f6b249f225108a39fa0d439\n'}, {'number': 3, 'created': '2016-02-12 20:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3c4cbbb4e1b8b8601a2e084c267698c5304d504f', 'message': 'Updated from global requirements\n\nChange-Id: I353e5d614df107067f6b249f225108a39fa0d439\n'}, {'number': 4, 'created': '2016-02-12 20:24:52.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/fe58289da03cf0a931b76b900879c5e5f2d5ab13', 'message': 'Updated from global requirements\n\nChange-Id: I353e5d614df107067f6b249f225108a39fa0d439\n'}]",0,278899,fe58289da03cf0a931b76b900879c5e5f2d5ab13,15,4,4,11131,,,0,"Updated from global requirements

Change-Id: I353e5d614df107067f6b249f225108a39fa0d439
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/278899/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,fa24804eb73df356b76612ca0e0d602c480334de,openstack/requirements,mock>=1.2 # BSD,mock>=1.2;python_version<'3.3' # BSD,1,1
openstack%2Fcinder~stable%2Fliberty~Ifdbca7a02e2d797af9149cd185c2fa5dce661f66,openstack/cinder,stable/liberty,Ifdbca7a02e2d797af9149cd185c2fa5dce661f66,Zfssaiscsi driver should return target_lun as int,MERGED,2016-02-10 15:10:44.000000000,2016-02-15 05:32:34.000000000,2016-02-11 20:52:43.000000000,"[{'_account_id': 3}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 11509}, {'_account_id': 11904}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 14305}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16660}]","[{'number': 1, 'created': '2016-02-10 15:10:44.000000000', 'files': ['cinder/tests/unit/test_zfssa.py', 'cinder/volume/drivers/zfssa/zfssaiscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/3d15e5b975f3a04e38c8a518ab34cd3d3affc0ef', 'message': ""Zfssaiscsi driver should return target_lun as int\n\nThe zfssaiscsi driver in initialize_connection()\nreturns iscsi_properties['target_lun'] as a string.\nSolaris version of openstack expects it to be an int\nand fails for the driver. Also other drivers report\nit as an int. So this will make the zfssaiscsi driver\nmore consistent with other drivers.\n\nChange-Id: Ifdbca7a02e2d797af9149cd185c2fa5dce661f66\nCloses-bug: #1538582\n(cherry picked from commit 8f70411e411f322b58841b7e1c72ed0f83539aad)\n""}]",0,278422,3d15e5b975f3a04e38c8a518ab34cd3d3affc0ef,28,11,1,13013,,,0,"Zfssaiscsi driver should return target_lun as int

The zfssaiscsi driver in initialize_connection()
returns iscsi_properties['target_lun'] as a string.
Solaris version of openstack expects it to be an int
and fails for the driver. Also other drivers report
it as an int. So this will make the zfssaiscsi driver
more consistent with other drivers.

Change-Id: Ifdbca7a02e2d797af9149cd185c2fa5dce661f66
Closes-bug: #1538582
(cherry picked from commit 8f70411e411f322b58841b7e1c72ed0f83539aad)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/22/278422/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_zfssa.py', 'cinder/volume/drivers/zfssa/zfssaiscsi.py']",2,3d15e5b975f3a04e38c8a518ab34cd3d3affc0ef,bug1538582, iscsi_properties['target_lun'] = int(lun), iscsi_properties['target_lun'] = lun,2,2
openstack%2Ftaskflow~master~I596bccc1c42f83ee79136dd27bc87039154ff7b1,openstack/taskflow,master,I596bccc1c42f83ee79136dd27bc87039154ff7b1,Add WBE worker expiry,MERGED,2016-02-06 18:25:55.000000000,2016-02-15 05:22:43.000000000,2016-02-15 05:22:43.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9648}]","[{'number': 1, 'created': '2016-02-06 18:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/61f9ef896709b308837486419b1f80de00b1cd4f', 'message': ""Add WBE worker expiry\n\nWhen a worker hasn't responded to a notification\nrequest for a given amount of time remove it from\nbeing a useable worker that we can match task submissions\nto.\n\nChange-Id: I596bccc1c42f83ee79136dd27bc87039154ff7b1\n""}, {'number': 2, 'created': '2016-02-07 02:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/51f7a9f203768a7353c35656c80029843cab7d01', 'message': ""Add WBE worker expiry\n\nWhen a worker hasn't responded to a notification\nrequest for a given amount of time remove it from\nbeing a useable worker that we can match task submissions\nto.\n\nChange-Id: I596bccc1c42f83ee79136dd27bc87039154ff7b1\n""}, {'number': 3, 'created': '2016-02-14 19:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5dd8d81026abafb1792cd8348aed765cb606a2c6', 'message': ""Add WBE worker expiry\n\nWhen a worker hasn't responded to a notification\nrequest for a given amount of time remove it from\nbeing a useable worker that we can match task submissions\nto.\n\nChange-Id: I596bccc1c42f83ee79136dd27bc87039154ff7b1\n""}, {'number': 4, 'created': '2016-02-14 20:41:51.000000000', 'files': ['taskflow/engines/worker_based/engine.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/types.py', 'taskflow/tests/unit/worker_based/test_creation.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/tests/unit/worker_based/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/63b380fc7b4a633911ec65e87ca326cf677986ce', 'message': ""Add WBE worker expiry\n\nWhen a worker hasn't responded to a notification\nrequest for a given amount of time remove it from\nbeing a useable worker that we can match task submissions\nto.\n\nChange-Id: I596bccc1c42f83ee79136dd27bc87039154ff7b1\n""}]",0,277109,63b380fc7b4a633911ec65e87ca326cf677986ce,20,3,4,1297,,,0,"Add WBE worker expiry

When a worker hasn't responded to a notification
request for a given amount of time remove it from
being a useable worker that we can match task submissions
to.

Change-Id: I596bccc1c42f83ee79136dd27bc87039154ff7b1
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/09/277109/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/types.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/tests/unit/worker_based/test_types.py']",4,61f9ef896709b308837486419b1f80de00b1cd4f,wbe-cleanups," @mock.patch(""oslo_utils.timeutils.now"") def test_expiry(self, mock_now): finder = worker_types.ProxyWorkerFinder('me', mock.MagicMock(), [], worker_expiry=60) w, emit = finder._add('dummy-topic', [utils.DummyTask]) w.last_seen = 0 mock_now.side_effect = [120] finder.clean() self.assertEqual(0, finder.total_workers()) ",,46,1
openstack%2Ftaskflow~master~I7107ff6b77a355b4c5d301948355fb6386605388,openstack/taskflow,master,I7107ff6b77a355b4c5d301948355fb6386605388,Some WBE protocol/executor cleanups,MERGED,2016-02-05 22:34:47.000000000,2016-02-15 05:22:20.000000000,2016-02-15 05:22:20.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 9648}]","[{'number': 1, 'created': '2016-02-05 22:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4b7ca0fe989692b844642c664608185a4ca3dd5b', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nHave the request class contain a new create class\nmethod that will return a future object used by the\nrest of the engine, and the protocol object that will\nbe tracked by the executor (this avoids having to\nexpose the future object from the request object).\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 2, 'created': '2016-02-05 22:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8bc5362f5c07b7fc8289194455016cbdc2fa363b', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nHave the request class contain a new create class\nmethod that will return a future object used by the\nrest of the engine, and the protocol object that will\nbe tracked by the executor (this avoids having to\nexpose the future object from the request object).\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 3, 'created': '2016-02-06 01:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ad9346352c4d494c574b15c2aa0e40c3db76ddf5', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nHave the request class contain a new create class\nmethod that will return a future object used by the\nrest of the engine, and the protocol object that will\nbe tracked by the executor (this avoids having to\nexpose the future object from the request object).\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 4, 'created': '2016-02-06 03:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/13c15fa22090e63f529dbbc21b2c9dc6fdb83f25', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nHave the request class contain a new create class\nmethod that will return a future object used by the\nrest of the engine, and the protocol object that will\nbe tracked by the executor (this avoids having to\nexpose the future object from the request object).\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 5, 'created': '2016-02-06 03:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d50bfc3f10544c1d516159e1fa0ce5b5c47ebef4', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nHave the request class contain a new create class\nmethod that will return a future object used by the\nrest of the engine, and the protocol object that will\nbe tracked by the executor (this avoids having to\nexpose the future object from the request object).\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 6, 'created': '2016-02-06 05:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/45b29c9466e0c6b5eb768be1ec024e0daa9e0842', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 7, 'created': '2016-02-06 17:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/53af2d2e3ed08b4fad1cc0c6c4928fdc1222cfef', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 8, 'created': '2016-02-06 18:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2287021df443faa4d12c9af0c6d1107ffc591663', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 9, 'created': '2016-02-12 06:08:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/74882c39b9833d181c6fe8ca78795995ea095879', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be without having to dig\ninto the functions to figure it out).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}, {'number': 10, 'created': '2016-02-14 19:47:21.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'doc/source/workers.rst', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/engines/worker_based/types.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/tests/unit/worker_based/test_server.py', 'taskflow/tests/unit/worker_based/test_types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1ab60b7e98633379de058bf68697158046ad503a', 'message': ""Some WBE protocol/executor cleanups\n\nRemove some of the usage of @property as none of\nthese objects are publicly exposed (or have docstrings\non them) to save some space/lines of code that aren't\nreally adding any benefit.\n\nUse less **kwargs when we know exactly what the keyword\narguments will or will not be. Being explicit makes it\neasier to understand these functions (vs not knowing what\nthe arguments can or can't be).\n\nRemoves base worker finder because right now we only\nhave one implementation (at some point we will have\ntwo) but we can just wait to add a base class until\nthen.\n\nChange-Id: I7107ff6b77a355b4c5d301948355fb6386605388\n""}]",2,276941,1ab60b7e98633379de058bf68697158046ad503a,30,4,10,1297,,,0,"Some WBE protocol/executor cleanups

Remove some of the usage of @property as none of
these objects are publicly exposed (or have docstrings
on them) to save some space/lines of code that aren't
really adding any benefit.

Use less **kwargs when we know exactly what the keyword
arguments will or will not be. Being explicit makes it
easier to understand these functions (vs not knowing what
the arguments can or can't be).

Removes base worker finder because right now we only
have one implementation (at some point we will have
two) but we can just wait to add a base class until
then.

Change-Id: I7107ff6b77a355b4c5d301948355fb6386605388
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/41/276941/3 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/protocol.py']",2,4b7ca0fe989692b844642c664608185a4ca3dd5b,wbe-cleanups,"# Object that denotes nothing (none can actually be valid). NO_RESULT = object() def __init__(self, fut, task, uuid, action, arguments, timeout=REQUEST_TIMEOUT, result=NO_RESULT, failures=None): self._fut = fut self._result = result self._failures = failures self.state = WAITING self.task = task self.uuid = uuid self.created_on = timeutils.now() @classmethod def create(cls, task, uuid, action, arguments, timeout, **kwargs): """"""Makes a new request, returns future for it and the request."""""" fut = futurist.Future() fut.atom = task return fut, cls(fut, task, uuid, action, arguments, timeout, **kwargs) def set_result(self, result): """"""Sets the responses result."""""" self._fut.set_result((self._event, result)) if self.state in WAITING_STATES: 'task_cls': reflection.get_class_name(self.task), 'task_name': self.task.name, 'task_version': self.task.version, if self._result is not NO_RESULT: result = self._result if self._failures: for atom_name, failure in six.iteritems(self._failures): request['failures'][atom_name] = failure.to_dict() old_state = self.state self.state = new_state self.state = state self.data = data def to_dict(self): return dict(state=self.state, data=self.data)"," def __init__(self, task, uuid, action, arguments, timeout, **kwargs): self._task = task self._uuid = uuid self._kwargs = kwargs self._state = WAITING self._created_on = timeutils.now() self._result = futurist.Future() self._result.atom = task self._notifier = task.notifier @property def result(self): return self._result @property def notifier(self): return self._notifier @property def uuid(self): return self._uuid @property def task(self): return self._task @property def state(self): return self._state @property def created_on(self): return self._created_on if self._state in WAITING_STATES: 'task_cls': reflection.get_class_name(self._task), 'task_name': self._task.name, 'task_version': self._task.version, if 'result' in self._kwargs: result = self._kwargs['result'] if 'failures' in self._kwargs: failures = self._kwargs['failures'] for task, failure in six.iteritems(failures): request['failures'][task] = failure.to_dict() def set_result(self, result): self.result.set_result((self._event, result)) old_state = self._state self._state = new_state self._state = state self._data = data @property def state(self): return self._state @property def data(self): return self._data def to_dict(self): return dict(state=self._state, data=self._data)",51,70
openstack%2Fhorizon~master~I767fc120574fd7eb9bfd0273490632fa554e67ae,openstack/horizon,master,I767fc120574fd7eb9bfd0273490632fa554e67ae,fix network_topology router add interface redirect url,ABANDONED,2015-06-24 03:57:26.000000000,2016-02-15 05:10:57.000000000,,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 14107}, {'_account_id': 14151}]","[{'number': 1, 'created': '2015-06-24 03:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e31f753e373339bba2463cdd65184edc3b03bc99', 'message': 'fix network_topology router add interface redirect url\n\nstep to reproduce the bug:\n1.login in the horizon\n2.go to the ""Network Topology""\n3.show the router detail\n4.click the ""Add Interface"" to add interface\n5.then it redirect to the ""Router Details""\n\nwhen it finsh it sholud stay in the ""Network Topology""\n\nChange-Id: I767fc120574fd7eb9bfd0273490632fa554e67ae\nCloses-Bug: #1467846\n'}, {'number': 2, 'created': '2015-06-24 05:27:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c595434916618eccfcb5d11712f5ff1658541209', 'message': 'fix network_topology router add interface redirect url\n\nstep to reproduce the bug:\n1.login in the horizon\n2.go to the ""Network Topology""\n3.show the router detail\n4.click the ""Add Interface"" to add interface\n5.then it redirect to the ""Router Details""\n\nwhen it finsh it sholud stay in the ""Network Topology""\n\nChange-Id: I767fc120574fd7eb9bfd0273490632fa554e67ae\nCloses-Bug: #1467846\n'}, {'number': 3, 'created': '2015-06-25 14:29:50.000000000', 'files': ['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/_create.html', 'horizon/static/horizon/js/horizon.networktopology.js', 'openstack_dashboard/dashboards/project/network_topology/urls.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/create.html', 'openstack_dashboard/dashboards/project/network_topology/ports/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/ab2ba4d32734b981a29bd5af686894983400738e', 'message': 'fix network_topology router add interface redirect url\n\nstep to reproduce the bug:\n1.login in the horizon\n2.go to the ""Network Topology""\n3.show the router detail\n4.click the ""Add Interface"" to add interface\n5.then it redirect to the ""Router Details""\n\nwhen it finsh, stay in current page is better than redirect\nto other page.\n\nChange-Id: I767fc120574fd7eb9bfd0273490632fa554e67ae\nCloses-Bug: #1467846\n'}]",6,194926,ab2ba4d32734b981a29bd5af686894983400738e,13,5,3,14107,,,0,"fix network_topology router add interface redirect url

step to reproduce the bug:
1.login in the horizon
2.go to the ""Network Topology""
3.show the router detail
4.click the ""Add Interface"" to add interface
5.then it redirect to the ""Router Details""

when it finsh, stay in current page is better than redirect
to other page.

Change-Id: I767fc120574fd7eb9bfd0273490632fa554e67ae
Closes-Bug: #1467846
",git fetch https://review.opendev.org/openstack/horizon refs/changes/26/194926/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/network_topology/views.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/_create.html', 'horizon/static/horizon/js/horizon.networktopology.js', 'openstack_dashboard/dashboards/project/network_topology/urls.py', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/create.html', 'openstack_dashboard/dashboards/project/network_topology/ports/forms.py']",6,e31f753e373339bba2463cdd65184edc3b03bc99,bug/1467846,"# Copyright 2012, Nachi Ueno, NTT MCL, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import logging from django.core.urlresolvers import reverse from django.utils.translation import ugettext_lazy as _ from horizon import exceptions from openstack_dashboard.dashboards.project.routers.ports import forms LOG = logging.getLogger(__name__) class AddInterface(forms.AddInterface): failure_url = 'horizon:project:network_topology:index' def _handle_error(self, request, router_id, reason): msg = _('Failed to add_interface: %s') % reason LOG.info(msg) redirect = reverse(self.failure_url) exceptions.handle(request, msg, redirect=redirect) ",,90,1
openstack%2Ftempest-lib~master~Idf7eb50da28ceb3117fd0a4776e0d9caa3c05bc0,openstack/tempest-lib,master,Idf7eb50da28ceb3117fd0a4776e0d9caa3c05bc0,Migrated microversion testing framework from tempest,ABANDONED,2016-02-09 15:37:02.000000000,2016-02-15 04:35:07.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 8556}]","[{'number': 1, 'created': '2016-02-09 15:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/bb3d054fa3433cbd608bf3bd19402e578381fbdf', 'message': 'Migrated microversion testing framework from tempest\n\nThis migrates the below files from tempest.\nThis includes tempest commits:\n\n * api_version_request.py: I81e86faca6f8c0ffb7da22154a62236ac25cf0c0\n * api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591\n * base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * test_api_version_request.py: I57b78b4c0543b6fb0533b556886a19a03297555e\n * test_api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591\n * test_base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * test_base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n\nto see the commit history for these files refer to the above Change-Ids\nin the tempest repository.\n\nPartially implements blueprint migrate-service-clients-to-tempest-lib\n\nChange-Id: Idf7eb50da28ceb3117fd0a4776e0d9caa3c05bc0\n'}, {'number': 2, 'created': '2016-02-09 15:39:27.000000000', 'files': ['tempest_lib/exceptions.py', 'tempest_lib/tests/services/compute/test_base_compute_client.py', 'tempest_lib/tests/services/test_base_microversion_client.py', 'tempest_lib/common/api_version_request.py', 'tempest_lib/services/base_microversion_client.py', 'tempest_lib/tests/common/test_api_version_request.py', 'tempest_lib/services/compute/base_compute_client.py', 'tempest_lib/tests/common/test_api_version_utils.py', 'tempest_lib/common/api_version_utils.py'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/273a7b75ee75f018014eec576b6f703cade5353a', 'message': 'Migrated microversion testing framework from tempest\n\nThis migrates the below files from tempest.\nThis includes tempest commits:\n\n * api_version_request.py: I81e86faca6f8c0ffb7da22154a62236ac25cf0c0\n * api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591\n * base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * test_api_version_request.py: I57b78b4c0543b6fb0533b556886a19a03297555e\n * test_api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591\n * test_base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n * test_base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db\n\nto see the commit history for these files refer to the above Change-Ids\nin the tempest repository.\n\nPartially implements blueprint api-microversions-testing-support\n\nChange-Id: Idf7eb50da28ceb3117fd0a4776e0d9caa3c05bc0\n'}]",5,277890,273a7b75ee75f018014eec576b6f703cade5353a,9,4,2,8556,,,0,"Migrated microversion testing framework from tempest

This migrates the below files from tempest.
This includes tempest commits:

 * api_version_request.py: I81e86faca6f8c0ffb7da22154a62236ac25cf0c0
 * api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591
 * base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db
 * base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db
 * test_api_version_request.py: I57b78b4c0543b6fb0533b556886a19a03297555e
 * test_api_version_utils.py: Ifb6193bfc252a3343664953aaf2caae85ab50591
 * test_base_compute_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db
 * test_base_microversion_client.py: Ic25ab63946264057f3a4365cd1ed13d9a35462db

to see the commit history for these files refer to the above Change-Ids
in the tempest repository.

Partially implements blueprint api-microversions-testing-support

Change-Id: Idf7eb50da28ceb3117fd0a4776e0d9caa3c05bc0
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/90/277890/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest_lib/exceptions.py', 'tempest_lib/tests/services/compute/test_base_compute_client.py', 'tempest_lib/tests/services/test_base_microversion_client.py', 'tempest_lib/common/api_version_request.py', 'tempest_lib/services/base_microversion_client.py', 'tempest_lib/tests/common/test_api_version_request.py', 'tempest_lib/services/compute/base_compute_client.py', 'tempest_lib/tests/common/test_api_version_utils.py', 'tempest_lib/common/api_version_utils.py']",9,bb3d054fa3433cbd608bf3bd19402e578381fbdf,bp/api-microversions-testing-support,"# Copyright 2015 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import testtools from tempest_lib.common import api_version_request from tempest_lib import exceptions class BaseMicroversionTest(object): """"""Mixin class for API microversion test class."""""" # NOTE: Basically, each microversion is small API change and we # can use the same tests for most microversions in most cases. # So it is nice to define the test class as possible to run # for all microversions. We need to define microversion range # (min_microversion, max_microversion) on each test class if necessary. min_microversion = None max_microversion = 'latest' def check_skip_with_microversion(test_min_version, test_max_version, cfg_min_version, cfg_max_version): min_version = api_version_request.APIVersionRequest(test_min_version) max_version = api_version_request.APIVersionRequest(test_max_version) config_min_version = api_version_request.APIVersionRequest(cfg_min_version) config_max_version = api_version_request.APIVersionRequest(cfg_max_version) if ((min_version > max_version) or (config_min_version > config_max_version)): msg = (""Test Class versions [%s - %s]. "" ""Configuration versions [%s - %s]."" % (min_version.get_string(), max_version.get_string(), config_min_version.get_string(), config_max_version.get_string())) raise exceptions.InvalidAPIVersionRange(msg) # NOTE: Select tests which are in range of configuration like # config min config max # ----------------+--------------------------+---------------- # ...don't-select| # ...select... ...select... ...select... # |don't-select... # ......................select............................ if (max_version < config_min_version or config_max_version < min_version): msg = (""The microversion range[%s - %s] of this test is out of the "" ""configuration range[%s - %s]."" % (min_version.get_string(), max_version.get_string(), config_min_version.get_string(), config_max_version.get_string())) raise testtools.TestCase.skipException(msg) def select_request_microversion(test_min_version, cfg_min_version): test_version = api_version_request.APIVersionRequest(test_min_version) cfg_version = api_version_request.APIVersionRequest(cfg_min_version) max_version = cfg_version if cfg_version >= test_version else test_version return max_version.get_string() def assert_version_header_matches_request(api_microversion_header_name, api_microversion, response_header): """"""Checks API microversion in resposne header Verify whether microversion is present in response header and with specified 'api_microversion' value. @param: api_microversion_header_name: Microversion header name Example- ""X-OpenStack-Nova-API-Version"" @param: api_microversion: Microversion number like ""2.10"" @param: response_header: Response header where microversion is expected to be present. """""" api_microversion_header_name = api_microversion_header_name.lower() if (api_microversion_header_name not in response_header or api_microversion != response_header[api_microversion_header_name]): msg = (""Microversion header '%s' with value '%s' does not match in "" ""response - %s. "" % (api_microversion_header_name, api_microversion, response_header)) raise exceptions.InvalidHTTPResponseHeader(msg) ",,860,0
openstack%2Fironic~master~I8f406a9beb3fd3c01b15f764211ffd18494464f6,openstack/ironic,master,I8f406a9beb3fd3c01b15f764211ffd18494464f6,Add hardware inspection module for iRMC driver,MERGED,2015-06-28 23:36:20.000000000,2016-02-15 04:31:24.000000000,2016-02-12 10:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 9751}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 11076}, {'_account_id': 11278}, {'_account_id': 13689}, {'_account_id': 13719}, {'_account_id': 14629}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-06-28 23:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/48645d11dfd2d53c992118dea5c27d1bf228289f', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 2, 'created': '2015-07-28 01:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b2abbb10631f26559c893369f01e748277cc4fea', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 3, 'created': '2015-07-29 09:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bb3eccdf9623c0c8693fcb98f66333c69cacbdd7', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 4, 'created': '2015-08-02 23:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e6489c97110781614488811b5223665a874329b9', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 5, 'created': '2015-08-03 04:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9331f433ff715e56574ca9da97843294dea41796', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 6, 'created': '2015-08-05 13:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2b4335be9ce88897833df1f51fa5c300f4458c26', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 7, 'created': '2015-08-17 02:40:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b0372b79e566c0d054b4a4e30619ef4ffcfdcfab', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 8, 'created': '2015-08-20 11:56:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8066c74c1cca8e13f005c10c86d2ae82782e5105', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 9, 'created': '2015-08-31 00:40:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/553eab1972768a885fd95d9849e0d84f2969fe02', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 10, 'created': '2015-09-11 01:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3087d2ca2b5154ffe8bb3c2b42fff43fbfe0b0a3', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 11, 'created': '2015-09-22 05:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b83fabb123cfce2a8180c47bf610e7a746488366', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 12, 'created': '2015-09-28 08:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7014695e61f13015c0dbb6afb89cfc6f4d15c009', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 13, 'created': '2015-09-30 06:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/eef03c827436f9287a33301d55c9126f7c686d1b', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 14, 'created': '2015-10-06 05:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e17ccc78ece015a3329248b4201a6a20057d85b5', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 15, 'created': '2015-10-07 07:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/976b36f48c823452dc966fa32681dd13dda3f7a4', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes (having iRMC S4 and beyond).\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 16, 'created': '2015-10-09 08:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3cb35664dd40297ad147825b60479a9f00488128', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 17, 'created': '2015-10-20 04:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e6ca99f329e982d0f2fa8ff1e30dc7123cd8a305', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 18, 'created': '2015-11-27 01:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/33602a66a253c6e82a3e01e4c05bde30c091876c', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 19, 'created': '2015-12-03 09:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/52645f785edfb102a45f341159595bc4858f2a0f', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nImplements: blueprint ironic-node-properties-discovery\n'}, {'number': 20, 'created': '2015-12-11 08:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1ba873715ec48896662925e5b94c2d0ad7a325b6', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}, {'number': 21, 'created': '2015-12-14 04:52:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d3b85fc7576a387db628979364e1e816906c3358', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}, {'number': 22, 'created': '2015-12-15 04:36:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9cf3295615379d63d681e0eda523b7e95e68015d', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}, {'number': 23, 'created': '2016-01-07 01:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/80a3b557c005494d15374efb20b2c1d4c139fdfa', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}, {'number': 24, 'created': '2016-01-07 07:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/99ed7d0c7701b35d6317abca546884f73928465c', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out of band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}, {'number': 25, 'created': '2016-02-12 02:34:41.000000000', 'files': ['ironic/tests/unit/drivers/modules/irmc/test_common.py', 'ironic/tests/unit/drivers/test_irmc.py', 'ironic/drivers/modules/irmc/common.py', 'ironic/tests/unit/drivers/modules/test_snmp.py', 'ironic/drivers/fake.py', 'ironic/drivers/pxe.py', 'ironic/drivers/irmc.py', 'etc/ironic/ironic.conf.sample', 'ironic/tests/unit/drivers/third_party_driver_mock_specs.py', 'ironic/drivers/modules/snmp.py', 'ironic/tests/unit/drivers/modules/irmc/test_inspect.py', 'releasenotes/notes/irmc-oob-inspection-6d072c60f6c88ecb.yaml', 'ironic/drivers/modules/irmc/inspect.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/37590a86338e94845c74e1b1f7d8d6f61003d447', 'message': 'Add hardware inspection module for iRMC driver\n\nThis module enables iRMC out-of-band hardware inspection for FUJITSU\nPRIMERGY bare metal nodes having iRMC S4 and beyond.\n\nChange-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6\nCloses-Bug: #1525108\n'}]",111,196480,37590a86338e94845c74e1b1f7d8d6f61003d447,140,13,25,13719,,,0,"Add hardware inspection module for iRMC driver

This module enables iRMC out-of-band hardware inspection for FUJITSU
PRIMERGY bare metal nodes having iRMC S4 and beyond.

Change-Id: I8f406a9beb3fd3c01b15f764211ffd18494464f6
Closes-Bug: #1525108
",git fetch https://review.opendev.org/openstack/ironic refs/changes/80/196480/7 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/third_party_driver_mock_specs.py', 'ironic/drivers/fake.py', 'ironic/tests/drivers/irmc/test_inspect.py', 'ironic/drivers/modules/irmc/inspect.py', 'ironic/drivers/pxe.py']",5,48645d11dfd2d53c992118dea5c27d1bf228289f,add-irmc-oob-inspection,from ironic.drivers.modules.irmc import inspect as irmc_inspect self.inspect = irmc_inspect.IRMCInspect(),,259,0
openstack%2Fkolla~master~I546d25249527d7f1f7dfa2059ae38e7cc0e0a765,openstack/kolla,master,I546d25249527d7f1f7dfa2059ae38e7cc0e0a765,Designate ubuntu binary container,MERGED,2016-02-05 10:31:33.000000000,2016-02-15 04:16:20.000000000,2016-02-15 04:16:20.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 14119}, {'_account_id': 18009}, {'_account_id': 18652}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-05 10:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/bd92d375929287e5bd4c9c688edca768e146f216', 'message': 'Designate ubuntu binary container\n\nChange-Id: I546d25249527d7f1f7dfa2059ae38e7cc0e0a765\nPartially-Implements: blueprint binary-ubuntu\n'}, {'number': 2, 'created': '2016-02-08 03:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fe733f3c2d06fef8ecd26d9b1476771c5c4b120a', 'message': 'Designate ubuntu binary container\n\nChange-Id: I546d25249527d7f1f7dfa2059ae38e7cc0e0a765\nPartially-Implements: blueprint binary-ubuntu\n'}, {'number': 3, 'created': '2016-02-08 04:01:40.000000000', 'files': ['docker/designate/designate-poolmanager/Dockerfile.j2', 'docker/designate/designate-api/Dockerfile.j2', 'docker/designate/designate-mdns/Dockerfile.j2', 'docker/designate/designate-backend-bind9/Dockerfile.j2', 'docker/designate/designate-central/Dockerfile.j2', 'docker/designate/designate-sink/Dockerfile.j2', 'docker/designate/designate-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/79b9e0d3022d35db43c85a79dc1cbf862fd9df0c', 'message': 'Designate ubuntu binary container\n\nChange-Id: I546d25249527d7f1f7dfa2059ae38e7cc0e0a765\nPartially-Implements: blueprint binary-ubuntu\n'}]",9,276676,79b9e0d3022d35db43c85a79dc1cbf862fd9df0c,17,6,3,18009,,,0,"Designate ubuntu binary container

Change-Id: I546d25249527d7f1f7dfa2059ae38e7cc0e0a765
Partially-Implements: blueprint binary-ubuntu
",git fetch https://review.opendev.org/openstack/kolla refs/changes/76/276676/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/designate/designate-poolmanager/Dockerfile.j2', 'docker/designate/designate-api/Dockerfile.j2', 'docker/designate/designate-mdns/Dockerfile.j2', 'docker/designate/designate-backend-bind9/Dockerfile.j2', 'docker/designate/designate-central/Dockerfile.j2', 'docker/designate/designate-base/Dockerfile.j2', 'docker/designate/designate-sink/Dockerfile.j2']",7,bd92d375929287e5bd4c9c688edca768e146f216,bp/binary-ubuntu, {% elif base_distro in ['ubuntu'] %} RUN apt-get install -y -no-install-recommends \ designate-sink \ designateclient \ && apt-get clean ,,46,0
openstack%2Fkolla~master~I252ee9cadb5f06c383ac9f48d0b1b16d83037a41,openstack/kolla,master,I252ee9cadb5f06c383ac9f48d0b1b16d83037a41,elevates privileges and grants access to /dev/mapper to cinder backup,MERGED,2016-02-06 03:52:40.000000000,2016-02-15 03:52:06.000000000,2016-02-15 03:52:06.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-06 03:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b781aac03fdf4ccdf90fdb475c720ab91e2d8826', 'message': 'elevates privleges and grants access to /dev/mapper to cinder backup\n\n- sets privaleged: true on cinder backup container\n- adds /dev/mapper to cinder-backup mounts\n- this chage allow the cinder backup manager to acess the\n  cinder-volumes lvm volume group via the kernel device mapper.\n\nChange-Id: I252ee9cadb5f06c383ac9f48d0b1b16d83037a41\nCloses-Bug: #154257\n'}, {'number': 2, 'created': '2016-02-06 03:57:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0a07c9545c81f950d19c8c13f03b3b3bbe906c52', 'message': 'elevates privileges and grants access to /dev/mapper to cinder backup\n\n- sets privileged: true on cinder backup container\n- adds /dev/mapper to cinder-backup mounts\n- this change allows the cinder backup manager to access the\n  cinder-volumes lvm volume group via the kernel device mapper.\n\nChange-Id: I252ee9cadb5f06c383ac9f48d0b1b16d83037a41\nCloses-Bug: #154257\n'}, {'number': 3, 'created': '2016-02-06 04:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/74b94d916a81da1cf5fe302f01ccc67686e08644', 'message': 'elevates privileges and grants access to /dev/mapper to cinder backup\n\n- sets privileged: true on cinder backup container\n- adds /dev/mapper to cinder-backup mounts\n- this change allows the cinder backup manager to access the\n  cinder-volumes lvm volume group via the kernel device mapper.\n\nChange-Id: I252ee9cadb5f06c383ac9f48d0b1b16d83037a41\nCloses-Bug: #1542574\n'}, {'number': 4, 'created': '2016-02-08 16:33:14.000000000', 'files': ['ansible/roles/cinder/tasks/start.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6f80ed221918a2eefc79c7e09e2ad8e50d438b0b', 'message': 'elevates privileges and grants access to /dev/mapper to cinder backup\n\n- sets privileged: true on cinder backup container\n- adds /dev/mapper to cinder-backup mounts\n- this change allows the cinder backup manager to access the\n  cinder-volumes lvm volume group via the kernel device mapper.\n\nChange-Id: I252ee9cadb5f06c383ac9f48d0b1b16d83037a41\nCloses-Bug: #1542574\n'}]",0,276990,6f80ed221918a2eefc79c7e09e2ad8e50d438b0b,14,3,4,11604,,,0,"elevates privileges and grants access to /dev/mapper to cinder backup

- sets privileged: true on cinder backup container
- adds /dev/mapper to cinder-backup mounts
- this change allows the cinder backup manager to access the
  cinder-volumes lvm volume group via the kernel device mapper.

Change-Id: I252ee9cadb5f06c383ac9f48d0b1b16d83037a41
Closes-Bug: #1542574
",git fetch https://review.opendev.org/openstack/kolla refs/changes/90/276990/2 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/cinder/tasks/start.yml'],1,b781aac03fdf4ccdf90fdb475c720ab91e2d8826,bug/1542574," privileged: True - ""/dev/mapper/:/dev/mapper/""",,2,0
openstack%2Fsahara~master~I3f1173e74ddd589f3d363597bd1562299f92e93d,openstack/sahara,master,I3f1173e74ddd589f3d363597bd1562299f92e93d,Python3: Fix using dictionary keys(),MERGED,2016-01-14 18:03:33.000000000,2016-02-15 03:50:01.000000000,2016-02-12 10:22:23.000000000,"[{'_account_id': 3}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8686}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 18399}, {'_account_id': 18777}]","[{'number': 1, 'created': '2016-01-14 18:03:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2042a51be5a7e592e49b126e82956e7c859e813c', 'message': 'Python3: Fixes dictionary view objects\n\nIt will throw TypeError when you try to operate on\ndict.keys() like a list in python3.\nref:https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects\n\nChange-Id: I3f1173e74ddd589f3d363597bd1562299f92e93d\n'}, {'number': 2, 'created': '2016-02-11 14:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1fcddcb5cd2a1a88609306e342dc03029bb0d782', 'message': 'Python3: Fix using dictionary keys()\n\nIt will throw TypeError when you try to operate on\ndict.keys() like a list in python3.\nref:https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects\n\nChange-Id: I3f1173e74ddd589f3d363597bd1562299f92e93d\n'}, {'number': 3, 'created': '2016-02-11 14:51:50.000000000', 'files': ['sahara/plugins/cdh/client/types.py', 'sahara/utils/patches.py', 'sahara/utils/ssh_remote.py', 'sahara/plugins/hdp/ambariplugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a4029e4d0581815b08beb4669a57636244924d4d', 'message': 'Python3: Fix using dictionary keys()\n\nIt will throw TypeError when you try to operate on\ndict.keys() like a list in python3.\nref:https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects\n\nChange-Id: I3f1173e74ddd589f3d363597bd1562299f92e93d\n'}]",2,267748,a4029e4d0581815b08beb4669a57636244924d4d,27,10,3,8686,,,0,"Python3: Fix using dictionary keys()

It will throw TypeError when you try to operate on
dict.keys() like a list in python3.
ref:https://docs.python.org/3/library/stdtypes.html#dictionary-view-objects

Change-Id: I3f1173e74ddd589f3d363597bd1562299f92e93d
",git fetch https://review.opendev.org/openstack/sahara refs/changes/48/267748/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/client/types.py', 'sahara/plugins/hdp/ambariplugin.py']",2,2042a51be5a7e592e49b126e82956e7c859e813c,python_dict_keys," cluster, [], dict(list(existing.items()) + additional.items()))"," cluster, [], dict(existing.items() + additional.items()))",2,2
openstack%2Fkolla~stable%2Fliberty~I1a48f4b1e0b0950640192bcfc55121619a844b50,openstack/kolla,stable/liberty,I1a48f4b1e0b0950640192bcfc55121619a844b50,Make pep8 *the* linting interface,MERGED,2016-02-12 06:07:23.000000000,2016-02-15 03:47:12.000000000,2016-02-15 03:47:12.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 11105}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-12 06:07:23.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8c6aeb81ab029b7aa0eb184a891f5f34086d53c2', 'message': 'Make pep8 *the* linting interface\n\nAccording to the PTI (=Python Test Interface,\nhttp://governance.openstack.org/reference/cti/python_cti.html), pep8\nis the interface for codestyle checks. Move all tests from linters to\npep8.\n\nThis change will be followed by a change to project-config to use pep8\nfor testing in the gate.\n\nChange-Id: I1a48f4b1e0b0950640192bcfc55121619a844b50\n(cherry picked from commit 8ad0b110657b2be1347b467236a74ed96aae0d02)\n'}]",0,279384,8c6aeb81ab029b7aa0eb184a891f5f34086d53c2,10,4,1,7488,,,0,"Make pep8 *the* linting interface

According to the PTI (=Python Test Interface,
http://governance.openstack.org/reference/cti/python_cti.html), pep8
is the interface for codestyle checks. Move all tests from linters to
pep8.

This change will be followed by a change to project-config to use pep8
for testing in the gate.

Change-Id: I1a48f4b1e0b0950640192bcfc55121619a844b50
(cherry picked from commit 8ad0b110657b2be1347b467236a74ed96aae0d02)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/84/279384/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,8c6aeb81ab029b7aa0eb184a891f5f34086d53c2,liberty,[testenv:pep8][testenv:linters] # temporary environment until infra jobs are changed. # TODO(jaegerandi): remove this {toxinidir}/tools/run-bashate.sh flake8 {posargs} {toxinidir}/tools/validate-all-json.sh {toxinidir}/tools/validate-all-yaml.sh {toxinidir}/tools/validate-all-maintainer.sh,[testenv:linters][testenv:pep8] flake8,9,3
openstack%2Fsenlin~master~I31e6d0072e72bfbba49c2052aa781e250d0e93dc,openstack/senlin,master,I31e6d0072e72bfbba49c2052aa781e250d0e93dc,Remove 'force' kwarg from node_delete api/rpc,MERGED,2016-02-15 02:59:19.000000000,2016-02-15 03:40:43.000000000,2016-02-15 03:40:43.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-15 02:59:19.000000000', 'files': ['senlin/tests/unit/test_rpc_client.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/tests/unit/apiv1/test_nodes.py', 'senlin/rpc/client.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/2060e8c8a25a71d31ff5fdec70aefeb52ade3f74', 'message': ""Remove 'force' kwarg from node_delete api/rpc\n\nThis patch removes 'force' keyword argument from node_delete api\ncontroller and rpc client since it is not supported now.\n\nChange-Id: I31e6d0072e72bfbba49c2052aa781e250d0e93dc\nCloses-Bug: #1545552\n""}]",0,280049,2060e8c8a25a71d31ff5fdec70aefeb52ade3f74,11,3,1,11034,,,0,"Remove 'force' kwarg from node_delete api/rpc

This patch removes 'force' keyword argument from node_delete api
controller and rpc client since it is not supported now.

Change-Id: I31e6d0072e72bfbba49c2052aa781e250d0e93dc
Closes-Bug: #1545552
",git fetch https://review.opendev.org/openstack/senlin refs/changes/49/280049/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/test_rpc_client.py', 'senlin/api/openstack/v1/nodes.py', 'senlin/tests/unit/apiv1/test_nodes.py', 'senlin/rpc/client.py']",4,2060e8c8a25a71d31ff5fdec70aefeb52ade3f74,bug/1545552," def node_delete(self, ctxt, identity, cast=True): self.make_msg('node_delete', identity=identity))"," def node_delete(self, ctxt, identity, force=False, cast=True): self.make_msg('node_delete', identity=identity, force=force))",6,11
openstack%2Foslo.messaging~master~Ia174560897140352c8feecd1879a8737f890ba8d,openstack/oslo.messaging,master,Ia174560897140352c8feecd1879a8737f890ba8d,Updated from global requirements,MERGED,2016-02-12 20:29:05.000000000,2016-02-15 03:30:06.000000000,2016-02-15 03:30:06.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-12 20:29:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6d654ec05fde9d7c8645b18c983a566a6f4b5b1a', 'message': 'Updated from global requirements\n\nChange-Id: Ia174560897140352c8feecd1879a8737f890ba8d\n'}]",0,279776,6d654ec05fde9d7c8645b18c983a566a6f4b5b1a,8,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ia174560897140352c8feecd1879a8737f890ba8d
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/76/279776/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,6d654ec05fde9d7c8645b18c983a566a6f4b5b1a,openstack/requirements,kombu>=3.0.25 # BSD,kombu>=3.0.7 # BSD,1,1
openstack%2Fproject-config~master~I23384df91fc16809d23b1d06f2cc8cc4fe2c403a,openstack/project-config,master,I23384df91fc16809d23b1d06f2cc8cc4fe2c403a,Adding Check Requirements Zuul check for Monasca Client,MERGED,2016-02-14 11:30:03.000000000,2016-02-15 03:27:48.000000000,2016-02-15 03:27:48.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7052}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-14 11:30:03.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9b63c09ae22bdaef4826b4164700e6eddad304c5', 'message': 'Adding Check Requirements Zuul check for Monasca Client\n\nFor the Monasca client to be merged as part of the global\nrequirements it must check the requirements in the gate.\nThis patch adds the check to the project.\n\nChange-Id: I23384df91fc16809d23b1d06f2cc8cc4fe2c403a\n'}]",0,279959,9b63c09ae22bdaef4826b4164700e6eddad304c5,8,5,1,7052,,,0,"Adding Check Requirements Zuul check for Monasca Client

For the Monasca client to be merged as part of the global
requirements it must check the requirements in the gate.
This patch adds the check to the project.

Change-Id: I23384df91fc16809d23b1d06f2cc8cc4fe2c403a
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/279959/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,9b63c09ae22bdaef4826b4164700e6eddad304c5,monasca-reqs-check, - name: check-requirements,,1,0
openstack%2Fsenlin-dashboard~master~I2e032624012e795101ff10c7e2217aa6e2e62ff1,openstack/senlin-dashboard,master,I2e032624012e795101ff10c7e2217aa6e2e62ff1,Add receivers panel,MERGED,2016-01-19 10:02:01.000000000,2016-02-15 03:07:01.000000000,2016-02-15 03:07:01.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}]","[{'number': 1, 'created': '2016-01-19 10:02:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/48d77e70d0c0011adf98912958de97f21a945f9d', 'message': 'Add receivers panel\n\nPartially implements blueprint add-receiver-panel\n\nChange-Id: I2e032624012e795101ff10c7e2217aa6e2e62ff1\n'}, {'number': 2, 'created': '2016-01-29 12:43:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/5774f1b95bffddba511bf51f74abfb6a01f90231', 'message': 'Add receivers panel\n\nPartially implements blueprint add-receiver-panel\n\nChange-Id: I2e032624012e795101ff10c7e2217aa6e2e62ff1\n'}, {'number': 3, 'created': '2016-02-14 12:57:54.000000000', 'files': ['senlin_dashboard/cluster/receivers/panel.py', 'senlin_dashboard/cluster/receivers/urls.py', 'senlin_dashboard/cluster/dashboard.py', 'senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/receivers/templates/receivers/index.html', 'senlin_dashboard/cluster/receivers/views.py', 'senlin_dashboard/cluster/receivers/tables.py', 'senlin_dashboard/test/test_data/senlin_data.py', 'senlin_dashboard/cluster/receivers/tests.py', 'senlin_dashboard/cluster/receivers/__init__.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/77f338abc6abeb44e5110df08767ad2dae978dab', 'message': 'Add receivers panel\n\nPartially implements blueprint add-receiver-panel\n\nChange-Id: I2e032624012e795101ff10c7e2217aa6e2e62ff1\n'}]",2,269528,77f338abc6abeb44e5110df08767ad2dae978dab,14,4,3,6763,,,0,"Add receivers panel

Partially implements blueprint add-receiver-panel

Change-Id: I2e032624012e795101ff10c7e2217aa6e2e62ff1
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/28/269528/3 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/receivers/panel.py', 'senlin_dashboard/cluster/receivers/urls.py', 'senlin_dashboard/cluster/dashboard.py', 'senlin_dashboard/api/senlin.py', 'senlin_dashboard/cluster/receivers/templates/receivers/index.html', 'senlin_dashboard/cluster/receivers/views.py', 'senlin_dashboard/cluster/receivers/tables.py', 'senlin_dashboard/test/test_data/senlin_data.py', 'senlin_dashboard/cluster/receivers/tests.py', 'senlin_dashboard/cluster/receivers/__init__.py']",10,48d77e70d0c0011adf98912958de97f21a945f9d,bp/add-receiver-panel,,,212,1
openstack%2Ftaskflow~master~If80233d13d914f2ed3665001a27627b78e6ee780,openstack/taskflow,master,If80233d13d914f2ed3665001a27627b78e6ee780,Remove need for separate notify thread,MERGED,2016-02-05 20:54:34.000000000,2016-02-15 03:06:10.000000000,2016-02-15 03:06:10.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-05 20:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/47f952602adc05720b359ef903edf69cb3334b93', 'message': ""Remove need for separate notify thread\n\nInstead of having a periodic notification thread that\nwill drop messages to try to find workers we can just\nhave this same work be done in the periodically called\non_wait callback that is already used for expiring and\nmatching workers to new/updated workers.\n\nThis avoids having one more thread that doesn't do all\nthat much.\n\nChange-Id: If80233d13d914f2ed3665001a27627b78e6ee780\n""}, {'number': 2, 'created': '2016-02-05 21:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e6ac286048d54f050bb7890330fc0f785f78ae04', 'message': ""Remove need for separate notify thread\n\nInstead of having a periodic notification thread that\nwill drop messages to try to find workers we can just\nhave this same work be done in the periodically called\non_wait callback that is already used for expiring and\nmatching workers to new/updated workers.\n\nThis avoids having one more thread that doesn't do all\nthat much (and activating it during waiting calls will\nbe often enough to achieve its goal in life).\n\nChange-Id: If80233d13d914f2ed3665001a27627b78e6ee780\n""}, {'number': 3, 'created': '2016-02-05 22:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/30c8a233544ad82be3428cb0ed7ed40d3f8f38aa', 'message': ""Remove need for separate notify thread\n\nInstead of having a periodic notification thread that\nwill drop messages to try to find workers we can just\nhave this same work be done in the periodically called\non_wait callback that is already used for expiring and\nmatching workers to new/updated workers.\n\nThis avoids having one more thread that doesn't do all\nthat much (and activating it during waiting calls will\nbe often enough to achieve its goal in life).\n\nChange-Id: If80233d13d914f2ed3665001a27627b78e6ee780\n""}, {'number': 4, 'created': '2016-02-14 19:44:35.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/types.py', 'taskflow/tests/unit/worker_based/test_executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a70bd8a7e59f52bc20dd4e219c4242b0f15664b4', 'message': ""Remove need for separate notify thread\n\nInstead of having a periodic notification thread that\nwill drop messages to try to find workers we can just\nhave this same work be done in the periodically called\non_wait callback that is already used for expiring and\nmatching workers to new/updated workers.\n\nThis avoids having one more thread that doesn't do all\nthat much (and activating it during waiting calls will\nbe often enough to achieve its goal in life).\n\nChange-Id: If80233d13d914f2ed3665001a27627b78e6ee780\n""}]",0,276915,a70bd8a7e59f52bc20dd4e219c4242b0f15664b4,12,2,4,1297,,,0,"Remove need for separate notify thread

Instead of having a periodic notification thread that
will drop messages to try to find workers we can just
have this same work be done in the periodically called
on_wait callback that is already used for expiring and
matching workers to new/updated workers.

This avoids having one more thread that doesn't do all
that much (and activating it during waiting calls will
be often enough to achieve its goal in life).

Change-Id: If80233d13d914f2ed3665001a27627b78e6ee780
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/15/276915/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/engines/worker_based/types.py', 'taskflow/tests/unit/worker_based/test_executor.py']",3,47f952602adc05720b359ef903edf69cb3334b93,wbe-cleanups," retry_options=mock.ANY), self.assertRaises(RuntimeError, ex.start)"," retry_options=mock.ANY, type_handlers=mock.ANY), ex.start()",69,52
openstack%2Fapi-site~master~I589ce12b7db98b5758493d8b6801950aeac2e3e6,openstack/api-site,master,I589ce12b7db98b5758493d8b6801950aeac2e3e6,Rename common-rst.po to common.po,MERGED,2016-02-15 02:47:28.000000000,2016-02-15 02:58:57.000000000,2016-02-15 02:58:57.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-15 02:47:28.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0316447899e9e92334c5acd40472fb36ee60ceda', 'message': 'Rename common-rst.po to common.po\n\nChange-Id: I589ce12b7db98b5758493d8b6801950aeac2e3e6\n'}]",0,280046,0316447899e9e92334c5acd40472fb36ee60ceda,6,2,1,10497,,,0,"Rename common-rst.po to common.po

Change-Id: I589ce12b7db98b5758493d8b6801950aeac2e3e6
",git fetch https://review.opendev.org/openstack/api-site refs/changes/46/280046/1 && git format-patch -1 --stdout FETCH_HEAD,['common/source/locale/ja/LC_MESSAGES/common.po'],1,0316447899e9e92334c5acd40472fb36ee60ceda,common,,,0,0
openstack%2Fsecurity-doc~master~I643e6ed4bf9003a60ad39979f62c408ef0af0006,openstack/security-doc,master,I643e6ed4bf9003a60ad39979f62c408ef0af0006,Rename common-rst.po to common.po,MERGED,2016-02-15 02:41:00.000000000,2016-02-15 02:57:01.000000000,2016-02-15 02:57:01.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-15 02:41:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/287b1a77042a9bb581374ae9b64f2428f34dbd51', 'message': 'Rename common-rst.po to common.po\n\nChange-Id: I643e6ed4bf9003a60ad39979f62c408ef0af0006\n'}, {'number': 2, 'created': '2016-02-15 02:45:32.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/358ac246dc17cecde34ae35da000475e45fc0f0b', 'message': 'Rename common-rst.po to common.po\n\nChange-Id: I643e6ed4bf9003a60ad39979f62c408ef0af0006\n'}]",0,280040,358ac246dc17cecde34ae35da000475e45fc0f0b,9,2,2,10497,,,0,"Rename common-rst.po to common.po

Change-Id: I643e6ed4bf9003a60ad39979f62c408ef0af0006
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/40/280040/1 && git format-patch -1 --stdout FETCH_HEAD,['common/source/locale/ja/LC_MESSAGES/common-rst.po'],1,287b1a77042a9bb581374ae9b64f2428f34dbd51,common,,"# Translators: # Akihiro Motoki <amotoki@gmail.com>, 2013 # Andreas Jaeger <jaegerandi@gmail.com>, 2014 # myamamot <myamamot@redhat.com>, 2014 # nao nishijima <nao.nishijima.xt@hitachi.com>, 2015 # Tomoyuki KATO <tomo@dream.daynight.jp>, 2015 # yfukuda <fukuda.yuko@jp.fujitsu.com>, 2014 # ykatabam <ykatabam@redhat.com>, 2014 # # # Andreas Jaeger <jaegerandi@gmail.com>, 2016. #zanata # KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>, 2016. #zanata msgid """" msgstr """" ""Project-Id-Version: Common documents 1.0.0\n"" ""Report-Msgid-Bugs-To: \n"" ""POT-Creation-Date: 2016-02-13 05:51+0000\n"" ""MIME-Version: 1.0\n"" ""Content-Type: text/plain; charset=UTF-8\n"" ""Content-Transfer-Encoding: 8bit\n"" ""PO-Revision-Date: 2016-02-12 02:34+0000\n"" ""Last-Translator: KATO Tomoyuki <kato.tomoyuki@jp.fujitsu.com>\n"" ""Language: ja\n"" ""Plural-Forms: nplurals=1; plural=0;\n"" ""X-Generator: Zanata 3.7.3\n"" ""Language-Team: Japanese\n"" msgid ""(RADOS)"" msgstr ""(RADOS)"" msgid """" ""**CentOS, Fedora, and Red Hat Enterprise Linux:** https://www.rdoproject.org/"" msgstr """" ""**CentOS、Fedora、Red Hat Enterprise Linux:** https://www.rdoproject.org/"" msgid ""**Debian:** https://wiki.debian.org/OpenStack"" msgstr ""**Debian:** https://wiki.debian.org/OpenStack"" msgid ""**Disk and CD-ROM bus model values**"" msgstr ""**ディスクと CD-ROM のバスモデルの値**"" msgid ""**Figure:Identity tab**"" msgstr ""**図: ユーザー管理タブ**"" msgid ""**Figure:Settings tab**"" msgstr ""**図: 設定タブ**"" msgid ""**Figure: Admin tab**"" msgstr ""**図: 管理タブ**"" msgid ""**Figure: Project tab**"" msgstr ""**図: プロジェクトタブ**"" msgid ""**MacOS**"" msgstr ""**MacOS**"" msgid ""**Microsoft Windows**"" msgstr ""**Microsoft Windows**"" msgid ""**OpenStack services and clients**"" msgstr ""**OpenStack のサービスとクライアント**"" msgid ""**Process flow example**"" msgstr ""**プロセスフロー例**"" msgid ""**Red Hat Enterprise Linux, CentOS, or Fedora.**"" msgstr ""**Red Hat Enterprise Linux、CentOS、Fedora。**"" msgid ""**SUSE Linux Enterprise Server**"" msgstr ""**SUSE Linux Enterprise Server**"" msgid ""**Ubuntu and Debian**"" msgstr ""**Ubuntu、Debian**"" msgid ""**Ubuntu:** https://wiki.ubuntu.com/ServerTeam/CloudArchive"" msgstr ""**Ubuntu:** https://wiki.ubuntu.com/ServerTeam/CloudArchive"" msgid ""**VIF model values**"" msgstr ""**仮想インターフェースのモデルの値**"" msgid """" ""**openSUSE and SUSE Linux Enterprise Server:** https://en.opensuse.org/"" ""Portal:OpenStack"" msgstr """" ""**openSUSE、SUSE Linux Enterprise Server:** https://en.opensuse.org/Portal:"" ""OpenStack"" msgid ""**openSUSE**"" msgstr ""**openSUSE**"" msgid """" ""*The OpenStack Image service is used to manage the virtual machine images in "" ""an OpenStack cluster, not store them.* It provides an abstraction to "" ""different methods for storage - a bridge to the storage, not the storage "" ""itself."" msgstr """" ""*OpenStack Image service は、OpenStack クラスターにおける仮想マシンイメージを"" ""管理するために使用されます。それらを保存するためではありません。* さまざまな"" ""種類のストレージを抽象化します。ストレージへの架け橋となりますが、ストレージ"" ""ではありません。"" msgid """" ""*The OpenStack Object Storage can function on its own.* The Object Storage "" ""(swift) product can be used independently of the Compute (nova) product."" msgstr """" ""*OpenStack Object Storage は、単体で機能できます。* Object Storage (swift) 製"" ""品は、Compute (nova) 製品と独立して使用できます。"" msgid """" ""*You cannot use OpenStack Object Storage like a traditional hard drive.* The "" ""Object Storage relaxes some of the constraints of a POSIX-style file system "" ""to get other gains. You can access the objects through an API which uses "" ""HTTP. Subsequently you don't have to provide atomic operations (that is, "" ""relying on eventual consistency), you can scale a storage system easily and "" ""avoid a central point of failure."" msgstr """" ""*OpenStack Object Storage は従来のハードディスクのように使用する事が出来ませ"" ""ん。* Object Storage は他のメリットを得るために、POSIX 形式のファイルシステム"" ""の制約を緩和しています。オブジェクトには HTTP を使用する API 経由でアクセス出"" ""来ます。また、Object Storage はオブジェクトに対するアトミックな操作を提供しな"" ""い（＝結果整合性（Eventual Consistency）に依る）ので、ストレージシステムを簡"" ""単にスケールアウトでき、単一点障害を避ける事ができます。"" msgid ""6to4"" msgstr ""6to4"" msgid "":guilabel:`API Access`: View API endpoints."" msgstr "":guilabel:`API アクセス`: API エンドポイントを表示します。"" msgid """" "":guilabel:`Access & Security`: Use the following tabs to complete these "" ""tasks:"" msgstr "":guilabel:`アクセスとセキュリティー`: 以下のタブがあります。"" msgid """" "":guilabel:`Block Storage Services`: View a list of all Block Storage "" ""services."" msgstr """" "":guilabel:`ブロックストレージサービス`: 全 Block Storage サービスの一覧を見"" ""る。"" msgid "":guilabel:`Change Password`: Change the password of the user."" msgstr "":guilabel:`Change Password`: ユーザーのパスワードを変更できます。"" msgid "":guilabel:`Compute Services`: View a list of all Compute services."" msgstr "":guilabel:`コンピュート`: コンピュートサービスの一覧の表示"" msgid "":guilabel:`Compute` tab"" msgstr "":guilabel:`コンピュート` タブ"" msgid "":guilabel:`Containers`: Create and manage containers and objects."" msgstr """" "":guilabel:`コンテナー`: コンテナーとオブジェクトの作成、管理を行います。"" msgid """" "":guilabel:`Defaults`: View default quota values. Quotas are hard-coded in "" ""OpenStack Compute and define the maximum allowable size and number of "" ""resources."" msgstr """" "":guilabel:`デフォルト`: デフォルトのクォータの値を表示します。クォータは "" ""OpenStack Compute ではハードコードされており、最大許容サイズ、リソース数を定"" ""義します。"" msgid """" "":guilabel:`Flavors`: View, create, edit, view extra specifications for, and "" ""delete flavors. A flavor is size of an instance."" msgstr """" "":guilabel:`フレーバー`: フレーバーの表示、作成、編集、削除、フレーバーの追加"" ""仕様の表示を行います。フレーバーはインスタンスのサイズです。 "" msgid """" "":guilabel:`Floating IPs`: Allocate an IP address to or release it from a "" ""project."" msgstr """" "":guilabel:`Floating IP`: プロジェクトの IP アドレスの確保や解放を行います。"" msgid """" "":guilabel:`Host Aggregates`: View, create, and edit host aggregates. View "" ""the list of availability zones."" msgstr """" "":guilabel:`ホストアグリゲート`: ホストアグリゲートの表示、作成、編集を行いま"" ""す。アベイラビリティーゾーンの一覧を表示します。"" msgid "":guilabel:`Hypervisors`: View the hypervisor summary."" msgstr "":guilabel:`ハイパーバイザー`: ハイパーバイザーの概要を表示します。"" msgid """" "":guilabel:`Images`: View images and instance snapshots created by project "" ""users, plus any images that are publicly available. Create, edit, and delete "" ""images, and launch instances from images and snapshots."" msgstr """" "":guilabel:`イメージ`: プロジェクトのユーザーが作成したイメージやインスタンス"" ""のスナップショット、公開されているイメージを表示します。イメージの作成、編"" ""集、削除を行ったり、イメージやスナップショットからインスタンスを起動したりし"" ""ます。 "" msgid """" "":guilabel:`Images`: View, create, edit properties for, and delete custom "" ""images."" msgstr """" "":guilabel:`イメージ`: カスタムイメージのプロパティーの表示、作成、編集を行い"" ""ます。また、数タムイメージを削除できます。"" msgid """" "":guilabel:`Instances`: View, launch, create a snapshot from, stop, pause, or "" ""reboot instances, or connect to them through VNC."" msgstr """" "":guilabel:`インスタンス`: インスタンスの表示、起動、スナップショットの作成、"" ""停止、一時停止、リブートを行います。また、 VNC からインスタンスに接続します。"" msgid """" "":guilabel:`Instances`: View, pause, resume, suspend, migrate, soft or hard "" ""reboot, and delete running instances that belong to users of some, but not "" ""all, projects. Also, view the log for an instance or access an instance "" ""through VNC."" msgstr """" "":guilabel:`インスタンス`: 一部のプロジェクト (全プロジェクトではない) のユー"" ""ザーに所属する実行中のインスタンスの表示、一時停止、再開、休止、移行、ソフト"" ""リブート、ハードリブート、削除を行います。また、インスタンスのログを表示した"" ""り、VNC 経由でインスタンスへアクセスしたりします。 "" msgid """" "":guilabel:`Key Pairs`: View, create, edit, import, and delete key pairs."" msgstr """" "":guilabel:`キーペア`: キーペアの表示、作成、編集、インポート、削除を行いま"" ""す。"" msgid """" "":guilabel:`Metadata Definitions`: Import namespace and view the metadata "" ""information."" msgstr """" "":guilabel:`メタデータの定義`: 名前空間をインポートします。また、メタデータ情"" ""報を表示します。"" msgid "":guilabel:`Network Agents`: View the network agents."" msgstr """" "":guilabel:`ネットワークエージェント`: ネットワークエージェントを表示します。"" msgid "":guilabel:`Network Topology`: View the network topology."" msgstr """" "":guilabel:`ネットワークトポロジー`: ネットワークトポロジーを表示します。"" msgid "":guilabel:`Network` tab"" msgstr "":guilabel:`ネットワーク` タブ"" msgid "":guilabel:`Networks`: Create and manage public and private networks."" msgstr """" "":guilabel:`ネットワーク`: パブリックネットワークとプライベートネットワークの"" ""作成、管理を行います。"" msgid """" "":guilabel:`Networks`: View, create, edit properties for, and delete networks."" msgstr """" "":guilabel:`ネットワーク`: ネットワークのプロパティーの表示、作成、編集を行い"" ""ます。また、ネットワークを削除できます。"" msgid "":guilabel:`Object Store` tab"" msgstr "":guilabel:`オブジェクトストア` タブ"" msgid """" "":guilabel:`Orchestration Services`: View a list of all Orchestration "" ""services."" msgstr """" "":guilabel:`オーケストレーションサービス`: すべての Orchestration サービスの一"" ""覧を表示します。"" msgid "":guilabel:`Orchestration` tab"" msgstr "":guilabel:`オーケストレーション` タブ"" msgid "":guilabel:`Overview`: View basic reports."" msgstr "":guilabel:`概要`: 基本的なレポートを表示します。"" msgid "":guilabel:`Overview`: View reports for the project."" msgstr "":guilabel:`概要`: プロジェクトのレポートを表示します。"" msgid """" "":guilabel:`Projects`: View, create, assign users to, remove users from, and "" ""delete projects."" msgstr """" "":guilabel:`プロジェクト`: プロジェクトの表示、作成、削除を行います。また、"" ""ユーザーの割り当て、解除を行います。"" msgid """" "":guilabel:`Resource Types`: Show a list of all the supported resource types "" ""for HOT templates."" msgstr """" "":guilabel:`リソース種別`: HOT テンプレートにサポートされる、すべてのリソース"" ""種別を一覧表示します。"" msgid """" "":guilabel:`Resource Usage`: Use the following tabs to view the following "" ""usages:"" msgstr """" "":guilabel:`リソース使用状況`: 以下のタブを使用して、以下の使用状況を表示しま"" ""す。"" msgid "":guilabel:`Routers`: Create and manage routers."" msgstr "":guilabel:`ルーター`: ルーターの作成、管理を行います。"" msgid """" "":guilabel:`Routers`: View, create, edit properties for, and delete routers."" msgstr """" "":guilabel:`ルーター`: ルーターのプロパティーの表示、作成、編集を行います。ま"" ""た、ルーターを削除できます。"" msgid """" "":guilabel:`Security Groups`: View, create, edit, and delete security groups "" ""and security group rules."" msgstr """" "":guilabel:`セキュリティーグループ`: セキュリティーグループとセキュリティーグ"" ""ループルールの表示、作成、編集、削除を行います。"" msgid "":guilabel:`Services`: View a list of the services."" msgstr "":guilabel:`サービス`: サービスの一覧を表示します。"" msgid """" "":guilabel:`Stacks`: Use the REST API to orchestrate multiple composite cloud "" ""applications."" msgstr """" "":guilabel:`スタック`: REST API を使用して、複数の複合クラウドアプリケーション"" ""をオーケストレーションします。"" msgid "":guilabel:`Stats`: View the statistics of all resources."" msgstr "":guilabel:`統計情報`: すべてのリソースの統計情報を表示します。"" msgid """" "":guilabel:`System Information`: Use the following tabs to view the service "" ""information:"" msgstr """" "":guilabel:`システム情報`: 以下のタブを使用して、サービスの情報を表示します。"" msgid "":guilabel:`System` tab"" msgstr "":guilabel:`システム` タブ"" msgid "":guilabel:`Usage Report`: View the usage report."" msgstr "":guilabel:`使用状況レポート`: 使用状況レポートを表示します。"" msgid "":guilabel:`User Settings`: View and manage dashboard settings."" msgstr "":guilabel:`ユーザー設定`: ダッシュボードの設定の表示、管理を行います。"" msgid "":guilabel:`Users`: View, create, enable, disable, and delete users."" msgstr """" "":guilabel:`ユーザー`: ユーザーの表示、作成、有効化、無効化、削除を行います。"" msgid """" "":guilabel:`Volume Snapshots`: View, create, edit, and delete volume "" ""snapshots."" msgstr """" "":guilabel:`ボリュームのスナップショット`: ボリュームのスナップショットの表"" ""示、作成、編集、削除を行います。"" msgid """" "":guilabel:`Volume Snapshots`: View, manage, and delete volume snapshots."" msgstr """" "":guilabel:`ボリュームのスナップショット`: ボリュームのスナップショットの表"" ""示、管理、削除を行います。"" msgid """" "":guilabel:`Volume Types`: View, create, manage, and delete volume types."" msgstr """" "":guilabel:`ボリューム種別`: ボリューム種別の表示、作成、管理、削除を行いま"" ""す。"" msgid "":guilabel:`Volumes`: Use the following tabs to complete these tasks:"" msgstr "":guilabel:`ボリューム`: 以下のタブがあります。"" msgid "":guilabel:`Volumes`: View, create, edit, and delete volumes."" msgstr "":guilabel:`ボリューム`: ボリュームの表示、作成、編集、削除を行います。"" msgid "":guilabel:`Volumes`: View, create, manage, and delete volumes."" msgstr "":guilabel:`ボリューム`: ボリュームの表示、作成、管理、削除を行います。"" msgid ""A BLOB of data held by Object Storage; can be in any format."" msgstr """" ""Object Storage により保持されるデータの BLOB。あらゆる形式の可能性がある。"" msgid """" ""A Block Storage component that creates, attaches, and detaches persistent "" ""storage volumes."" msgstr """" ""永続ストレージボリュームを作成、接続、切断する Block Storage コンポーネント。"" msgid """" ""A Block Storage component that oversees and coordinates storage volume "" ""actions."" msgstr """" ""ストレージボリュームの操作を監督、調整する、Block Storage のコンポーネント。"" msgid ""A Block Storage node that runs the cinder-volume daemon."" msgstr ""cinder-volume デーモンを実行する Block Storage ノード。"" msgid """" ""A Block Storage volume plug-in that enables communication with the Xen "" ""Storage Manager API."" msgstr """" ""Xen Storage Manager API と通信できる Block Storage ボリュームプラグイン。"" msgid """" ""A CLI that communicates with the ``heat-api`` to run :term:`AWS` "" ""CloudFormation APIs. End developers can directly use the Orchestration REST "" ""API."" msgstr """" "":term:`AWS` CloudFormation API を実行するために、 ``heat-api`` と通信する "" ""CLI。エンドの開発者は直接 Orchestration REST API を使用することもできます。"" msgid ""A CLI that communicates with the ``trove-api`` component."" msgstr ""``trove-api`` コンポーネントと通信する CLI。"" msgid """" ""A Ceph component that communicates with external clients, checks data state "" ""and consistency, and performs quorum functions."" msgstr """" ""外部クライアントと通信し、データの状態と整合性を確認し、クォーラム機能を実行"" ""する、Ceph コンポーネント。"" msgid """" ""A Compute API parameter that downloads changes to the requested item since "" ""your last request, instead of downloading a new, fresh set of data and "" ""comparing it against the old data."" msgstr """" ""Compute API のパラメーター。古いデータと比較するために、新しいデータ群をダウ"" ""ンロードする代わりに、最後に要求した後に実行された、要求した項目への変更をダ"" ""ウンロードする。"" msgid """" ""A Compute RabbitMQ message queue that remains active when the server "" ""restarts."" msgstr """" ""サーバーの再起動時に有効なままとなる、Compute RabbitMQ メッセージキュー。"" msgid """" ""A Compute RabbitMQ setting that determines whether a message exchange is "" ""automatically created when the program starts."" msgstr """" ""メッセージ交換がプログラム起動時に自動的に作成されるかどうかを決める、"" ""Compute の RabbitMQ の設定。"" msgid """" ""A Compute back-end database table that contains the current workload, amount "" ""of free RAM, and number of VMs running on each host. Used to determine on "" ""which host a VM starts."" msgstr """" ""Computeバックエンドデータベースのテーブルには現在のワークロード、RAMの空き"" ""量、各ホストで起動しているVMの数が含まれている。VMがどのホストで開始するのか"" ""を決めるのに利用される。"" msgid """" ""A Compute component that determines where VM instances should start. Uses "" ""modular design to support a variety of scheduler types."" msgstr """" ""仮想マシンインスタンスが起動する場所を決める、Compute のコンポーネント。さま"" ""ざまな種類のスケジューラーをサポートするために、モジュール型設計を使用する。"" msgid """" ""A Compute component that enables OpenStack to communicate with Amazon EC2."" msgstr """" ""OpenStack が Amazon EC2 を利用できるようにするための Compute のコンポーネン"" ""ト。"" msgid """" ""A Compute component that manages IP address allocation, firewalls, and other "" ""network-related tasks. This is the legacy networking option and an "" ""alternative to Networking."" msgstr """" ""IP アドレス割り当て、ファイアウォール、その他ネットワーク関連タスクを管理す"" ""る Compute のコンポーネント。レガシーネットワークのオプション。Networking の"" ""代替。"" msgid """" ""A Compute component that provides dnsmasq and radvd and sets up forwarding "" ""to and from cloudpipe instances."" msgstr """" ""dnsmasq と radvd を提供し、cloudpipe インスタンスとの転送処理をセットアップす"" ""る、Compute のコンポーネント。"" msgid """" ""A Compute component that provides users access to the consoles of their VM "" ""instances through VNC or VMRC."" msgstr """" ""ユーザーが VNC や VMRC 経由で仮想マシンインスタンスのコンソールにアクセスでき"" ""るようにする Compute のコンポーネント。"" msgid """" ""A Compute component that, along with the notification system, collects "" ""meters and usage information. This information can be used for billing."" msgstr """" ""通知システムと一緒に動作し、計測項目と使用状況を収集する、Compute のコンポー"" ""ネント。この情報は課金のために使用できる。"" msgid """" ""A Compute daemon that orchestrates the network configuration of nodes, "" ""including IP addresses, VLANs, and bridging. Also manages routing for both "" ""public and private networks."" msgstr """" ""IP アドレス、VLAN、ブリッジなど、ノードのネットワーク設定をオーケストレーショ"" ""ンする Compute のデーモン。また、パブリックネットワークとプライベートネット"" ""ワークのルーティングを管理する。"" msgid """" ""A Compute networking method where the OS network configuration information "" ""is injected into the VM image before the instance starts."" msgstr """" ""インスタンスの起動前に、OS のネットワーク設定情報を仮想マシンイメージ内に注入"" ""する、Compute のネットワーク方式。"" msgid """" ""A Compute option that enables parent cells to pass resource requests to "" ""child cells if the parent cannot provide the requested resource."" msgstr """" ""親が要求されたリソースを提供できない場合、親セルがリソース要求を子セルに渡す"" ""事を可能にする Compute のオプション。"" msgid """" ""A Compute process that determines the suitability of the VM instances for a "" ""job for a particular host. For example, not enough RAM on the host, too many "" ""CPUs on the host, and so on."" msgstr """" ""特定のホストがあるジョブ向けの仮想マシンインスタンスに対して適切かどうかを判"" ""断する、Compute の処理。例えば、ホストのメモリー不足、ホストの CPU 過剰など。"" msgid ""A Debian-based Linux distribution."" msgstr ""Debian ベースの Linux ディストリビューション。"" msgid ""A Java program that can be embedded into a web page."" msgstr ""Web ページの中に組み込める Java プログラム。"" msgid ""A Linux distribution compatible with OpenStack."" msgstr ""OpenStack と互換性のある Linux ディストリビューション。"" msgid ""A Linux distribution that is compatible with OpenStack."" msgstr ""OpenStack と互換性のある Linux ディストリビューション。"" msgid ""A Networking extension that provides perimeter firewall functionality."" msgstr ""境界ファイアウォール機能を提供する Networking 拡張。"" msgid """" ""A Networking plug-in for Cisco devices and technologies, including UCS and "" ""Nexus."" msgstr ""UCS や Nexus などの Cisco デバイスや技術の Networking プラグイン。"" msgid """" ""A SQLite database that contains Object Storage accounts and related metadata "" ""and that the accounts server accesses."" msgstr """" ""Object Storage のアカウントと関連メタデータを保持し、アカウントサーバーがアク"" ""セスする、SQLite データベース。"" msgid """" ""A SQLite database that stores Object Storage containers and container "" ""metadata. The container server accesses this database."" msgstr """" ""Object Storage コンテナーとコンテナーメタデータを保存する SQLite データベー"" ""ス。コンテナーサーバーは、このデータベースにアクセスする。"" msgid """" ""A Shared File Systems service that provides a stable RESTful API. The "" ""service authenticates and routes requests throughout the Shared File Systems "" ""service. There is python-manilaclient to interact with the API."" msgstr """" ""安定版の RESTful API を提供する Shared File Systems サービス。 Shared File "" ""Systems サービスへのすべてのリクエストの認証と転送を行う。この API と通信する"" ""ための python-manilaclient が提供されています。"" msgid """" ""A VM image that does not save changes made to its volumes and reverts them "" ""to their original state after the instance is terminated."" msgstr """" ""ボリュームへの変更が保存されない仮想マシンイメージ。インスタンスの終了後、元"" ""の状態に戻される。"" msgid ""A VM instance that runs on a host."" msgstr ""ホストで動作する仮想マシンインスタンス。"" msgid """" ""A VM state where no changes occur (no changes in memory, network "" ""communications stop, etc); the VM is frozen but not shut down."" msgstr """" ""変更が発生しない (メモリーの変更なし、ネットワーク通信の停止など)、仮想マシン"" ""の状態。仮想マシンは停止するが、シャットダウンしない。"" msgid """" ""A Windows project providing guest initialization features, similar to cloud-"" ""init."" msgstr ""cloud-init 同様のゲスト初期化機能を提供する Windows プロジェクト。"" msgid """" ""A XenAPI component that provides a pluggable interface to support a wide "" ""variety of persistent storage back ends."" msgstr """" ""さまざまな種類の永続ストレージバックエンドをサポートするために、プラグイン可"" ""能なインターフェースを提供する XenAPI コンポーネント。"" msgid """" ""A bit is a single digit number that is in base of 2 (either a zero or one). "" ""Bandwidth usage is measured in bits per second."" msgstr """" ""ビットは、2 を基数とする単一のデジタル数値 (0 または 1)。帯域使用量は、ビット"" ""毎秒 (bps) で計測される。"" msgid """" ""A blob of data that the user can specify when they launch an instance. The "" ""instance can access this data through the metadata service or config drive. "" ""Commonly used to pass a shell script that the instance runs on boot."" msgstr """" ""インスタンス起動時にユーザが指定できる BLOB データ。インスタンスはこのデータ"" ""にメタデータサービスやコンフィグドライブ経由でアクセスできる。通常、インスタ"" ""ンスがブート時に実行するシェルスクリプトを渡すために使用される。"" msgid ""A central agent (``ceilometer-agent-central``)"" msgstr ""中央エージェント (``ceilometer-agent-central``)"" msgid """" ""A central hub for passing messages between daemons. Usually implemented with "" ""`RabbitMQ <http://www.rabbitmq.com/>`__, but can be implemented with an AMQP "" ""message queue, such as `Apache Qpid <http://qpid.apache.org/>`__ or `Zero MQ "" ""<http://www.zeromq.org/>`__."" msgstr """" ""デーモン間でメッセージを受け渡しするための集中ハブです。一般的に `RabbitMQ "" ""<http://www.rabbitmq.com/>`__ で実装されますが、`Apache Qpid <http://qpid."" ""apache.org/>`__ や `Zero MQ <http://www.zeromq.org/>`__ などの AMQP メッセー"" ""ジキューでも構いません。"" msgid """" ""A centralized server provides authentication and authorization services "" ""using a RESTful interface."" msgstr """" ""中央サーバーが、RESTful インターフェースを使用して、認証と認可のサービスを提"" ""供します。"" msgid """" ""A cinder component that interacts with back-end storage to manage the "" ""creation and deletion of volumes and the creation of compute volumes, "" ""provided by the cinder-volume daemon."" msgstr """" ""ボリュームの作成や削除、コンピュートボリュームの作成を管理するために、バック"" ""エンドのストレージと相互作用する cinder のコンポーネント。cinder-volume デー"" ""モンにより提供される。"" msgid """" ""A cli tool used to retrieve various metrics and telemetry information about "" ""a cluster that has been collected by the swift-recon middleware."" msgstr """" ""swift-recon ミドルウェアにより収集されたクラスターの様々な性能情報や統計情報"" ""を取得するために使用する CLI ツール。"" msgid """" ""A collection of command-line tools for administering VMs; most are "" ""compatible with OpenStack."" msgstr """" ""仮想マシンを管理するためのコマンドラインツール群。ほとんどは OpenStack と互換"" ""性がある。"" msgid """" ""A collection of components that provides object storage within Ceph. Similar "" ""to OpenStack Object Storage."" msgstr """" ""Ceph 内にオブジェクトストレージを提供するコンポーネント群。OpenStack Object "" ""Storage に似ている。"" msgid """" ""A collection of files for a specific operating system (OS) that you use to "" ""create or rebuild a server. OpenStack provides pre-built images. You can "" ""also create custom images, or snapshots, from servers that you have "" ""launched. Custom images can be used for data backups or as \""gold\"" images "" ""for additional servers."" msgstr """" ""サーバーの作成、再構築に使用する特定のオペレーティングシステム（OS）用のファ"" ""イルの集合。OpenStack は構築済みイメージを提供する。起動したサーバーからカス"" ""タムイメージ（またはスナップショット）を作成できる。"" msgid ""A collection of hypervisors grouped together through host aggregates."" msgstr ""ホストアグリゲートにより一緒にグループ化されたハイパーバイザーの集合。"" msgid """" ""A collection of servers that can share IPs with other members of the group. "" ""Any server in a group can share one or more public IPs with any other server "" ""in the group. With the exception of the first server in a shared IP group, "" ""servers must be launched into shared IP groups. A server may be a member of "" ""only one shared IP group."" msgstr """" ""グループの他のメンバーと IP を共有できるサーバー群。グループ内のサーバーは、"" ""そのグループ内の他のサーバーと 1 つ以上のパブリック IP を共有できる。共有 IP "" ""グループにおける 1 番目のサーバーを除き、サーバーは共有 IP グループの中で起動"" ""する必要がある。サーバーは、共有 IP グループ 1 つだけのメンバーになれる。"" msgid """" ""A collection of specifications used to access a service, application, or "" ""program. Includes service calls, required parameters for each call, and the "" ""expected return values."" msgstr """" ""サービス、アプリケーション、プログラムへのアクセスに使用される仕様の集合。"" ""サービス呼出、各呼出に必要なパラメーター、想定される戻り値を含む。"" msgid ""A collector (``ceilometer-collector``)"" msgstr ""コレクター (``ceilometer-collector``)"" msgid ""A comment with additional information that explains a part of the text."" msgstr ""本文を補足する説明コメントです。"" msgid """" ""A common API for vendors, admins, services, and users to meaningfully define "" ""their own custom metadata. This metadata can be used on different types of "" ""resources like images, artifacts, volumes, flavors, and aggregates. A "" ""definition includes the new property's key, description, constraints, and "" ""the resource types which it can be associated with."" msgstr """" ""ベンダー、管理者、サービス、ユーザーの独自のメタデータを有意義に定義するため"" ""の共通 API。このメタデータは、イメージ、アーティファクト、ボリューム、フレー"" ""バー、アグリゲートなどの、さまざまなリソースにおいて使用できます。定義には、"" ""新しいプロパティーのキー、説明、制約、それが関連付けられるリソース種別が含ま"" ""れます。"" msgid """" ""A community project may be elevated to this status and is then promoted to a "" ""core project."" msgstr """" ""コミュニティプロジェクトがこの状態に昇格する事があり、その後コアプロジェクト"" ""に昇格する。"" msgid ""A compute agent (``ceilometer-agent-compute``)"" msgstr ""コンピュートエージェント (``ceilometer-agent-compute``)"" msgid ""A compute service that creates VPNs on a per-project basis."" msgstr ""プロジェクトごとの VPN を作成するコンピュートのサービス。"" msgid """" ""A configurable option within Object Storage to automatically delete objects "" ""after a specified amount of time has passed or a certain date is reached."" msgstr """" ""指定された時間経過後、又は指定日になった際に自動的にオブジェクトを削除するた"" ""めの Object Storage の設定オプション。"" msgid """" ""A content delivery network is a specialized network that is used to "" ""distribute content to clients, typically located close to the client for "" ""increased performance."" msgstr """" ""コンテンツ配信ネットワークは、クライアントにコンテンツを配信するために使用さ"" ""れる特別なネットワーク。一般的に、パフォーマンス改善のために、クライアントの"" ""近くに置かれる。"" msgid """" ""A controlled reboot where a VM instance is properly restarted through "" ""operating system commands."" msgstr """" ""オペレーティングシステムのコマンド経由で、仮想マシンインスタンスが正常に再起"" ""動する、制御された再起動。"" msgid """" ""A core OpenStack project that provides a network connectivity abstraction "" ""layer to OpenStack Compute."" msgstr """" ""OpenStack のコアプロジェクトで、OpenStack Compute に対してネットワーク接続の"" ""抽象化レイヤーを提供する。"" msgid """" ""A core OpenStack project that provides a network connectivity abstraction "" ""layer to OpenStack Compute. The project name of Networking is neutron."" msgstr """" ""ネットワーク接続性の抽象化レイヤーを OpenStack Compute に提供する、OpenStack "" ""コアプロジェクト。Networking のプロジェクト名は neutron。"" msgid ""A core OpenStack project that provides block storage services for VMs."" msgstr """" ""ブロックストレージサービスを仮想マシンに提供する、OpenStack のコアプロジェク"" ""ト。"" msgid ""A core project that provides the OpenStack Image service."" msgstr ""OpenStack Image service を提供するコアプロジェクト。"" msgid """" ""A daemon that listens to a queue and carries out tasks in response to "" ""messages. For example, the cinder-volume worker manages volume creation and "" ""deletion on storage arrays."" msgstr """" ""キューをリッスンし、メッセージに応じたタスクを実行するデーモン。例えば、"" ""cinder-volume ワーカーは、ストレージにおけるボリュームの作成と削除を管理しま"" ""す。"" msgid ""A database engine supported by the Database service."" msgstr ""Database サービスがサポートしているデータベースエンジン。"" msgid """" ""A default role in the Compute RBAC system that can quarantine an instance in "" ""any project."" msgstr """" ""あらゆるプロジェクトにあるインスタンスを検疫できる、Compute RBAC システムにお"" ""けるデフォルトのロール。"" msgid """" ""A device that moves data in the form of blocks. These device nodes interface "" ""the devices, such as hard disks, CD-ROM drives, flash drives, and other "" ""addressable regions of memory."" msgstr """" ""ブロック状態のデータを移動するデバイス。これらのデバイスノードにはハードディ"" ""スク、CD-ROM ドライブ、フラッシュドライブ、その他のアドレス可能なメモリの範囲"" ""等がある。"" msgid """" ""A directory service, which allows users to login with a user name and "" ""password. It is a typical source of authentication tokens."" msgstr """" ""ユーザーがユーザー名とパスワードを用いてログインできるようにする、ディレクト"" ""リーサービス。認証トークンの一般的な情報源。"" msgid """" ""A discrete OpenStack environment with dedicated API endpoints that typically "" ""shares only the Identity (keystone) with other regions."" msgstr """" ""専用の API エンドポイントを持つ、分離した OpenStack 環境。一般的に Identity "" ""(keystone) のみを他のリージョンと共有する。"" msgid ""A disk storage protocol tunneled within Ethernet."" msgstr ""Ethernet 内をトンネルされるディスクストレージプロトコル。"" msgid """" ""A distributed memory object caching system that is used by Object Storage "" ""for caching."" msgstr """" ""Object Storage がキャッシュのために使用する、メモリーオブジェクトの分散キャッ"" ""シュシステム。"" msgid """" ""A distributed, highly fault-tolerant file system designed to run on low-cost "" ""commodity hardware."" msgstr """" ""低価格のコモディティーサーバー上で動作することを念頭に設計された、耐故障性に"" ""優れた分散ファイルシステム。"" msgid """" ""A domain within a parent domain. Subdomains cannot be registered. Subdomains "" ""enable you to delegate domains. Subdomains can themselves have subdomains, "" ""so third-level, fourth-level, fifth-level, and deeper levels of nesting are "" ""possible."" msgstr """" ""親ドメイン内のドメイン。サブドメインは登録できない。サブドメインによりドメイ"" ""ンを委譲できる。サブドメインは、サブドメインを持てるので、第 3 階層、第 4 階"" ""層、第 5 階層と深い階層構造にできる。"" msgid """" ""A driver for the Modular Layer 2 (ML2) neutron plug-in that provides layer-2 "" ""connectivity for virtual instances. A single OpenStack installation can use "" ""multiple mechanism drivers."" msgstr """" ""仮想インスタンス向けに L2 接続性を提供する、ML2 neutron プラグイン向けのドラ"" ""イバー。単一の OpenStack インストール環境が、複数のメカニズムドライバーを使用"" ""できます。"" msgid """" ""A feature of Compute that allows the unprivileged \""nova\"" user to run a "" ""specified list of commands as the Linux root user."" msgstr """" ""非特権の「nova」ユーザーが Linux の root ユーザーとして指定したコマンド一覧を"" ""実行できるようにする、Compute の機能。"" msgid """" ""A feature of the load-balancing service. It attempts to force subsequent "" ""connections to a service to be redirected to the same node as long as it is "" ""online."" msgstr """" ""負荷分散サービスの機能の 1 つ。ノードがオンラインである限り、強制的に一連の接"" ""続を同じノードにリダイレクトしようとする。"" msgid """" ""A file sharing protocol. It is a public or open variation of the original "" ""Server Message Block (SMB) protocol developed and used by Microsoft. Like "" ""the SMB protocol, CIFS runs at a higher level and uses the TCP/IP protocol."" msgstr """" ""ファイル共有プロトコル。 Microsoft が開発し使用している Server Message Block "" ""(SMB) プロトコルが公開されオープンになったものです。 SMB プロトコルと同様"" ""に、 CIFS は上位レイヤーで動作し、TCP/IP プロトコルを使用します。"" msgid """" ""A file system designed to aggregate NAS hosts, compatible with OpenStack."" msgstr """" ""NAS ホストを集約するために設計されたファイルシステム。OpenStack と互換性があ"" ""る。"" msgid """" ""A file used to customize a Compute instance. It can be used to inject SSH "" ""keys or a specific network configuration."" msgstr """" ""Compute インスタンスをカスタマイズするために使用されるファイル。SSH 鍵や特定"" ""のネットワーク設定を注入するために使用できます。"" msgid """" ""A generic term for virtualization of network functions such as switching, "" ""routing, load balancing, and security using a combination of VMs and "" ""overlays on physical network infrastructure."" msgstr """" ""複数の仮想マシンを使用して、物理ネットワーク上にオーバーレイされる、スイッチ"" ""ング、ルーティング、負荷分散、セキュリティーなどのネットワーク機能の仮想化に"" ""関する一般的な用語。"" msgid """" ""A great way to get answers and insights is to post your question or "" ""problematic scenario to the OpenStack mailing list. You can learn from and "" ""help others who might have similar issues. To subscribe or view the "" ""archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/"" ""openstack. You might be interested in the other mailing lists for specific "" ""projects or development, which you can find `on the wiki <https://wiki."" ""openstack.org/wiki/MailingLists>`__. A description of all mailing lists is "" ""available at https://wiki.openstack.org/wiki/MailingLists."" msgstr """" ""回答や洞察を得るための良い方法は、質問や問題のある状況を OpenStack メーリング"" ""リストに投稿することです。同じような問題を持つ人から学んだり、その人を助けた"" ""りできます。メーリングリストの購読やアーカイブの参照は http://lists."" ""openstack.org/cgi-bin/mailman/listinfo/openstack にアクセスしてください。特定"" ""のプロジェクトや開発に関する他のメーリングリストに興味があるかもしれません。"" ""それらは `wiki <https://wiki.openstack.org/wiki/MailingLists>`__ にまとめられ"" ""ています。すべてのメーリングリストに関する説明は http://wiki.openstack.org/"" ""MailingLists にあります。"" msgid """" ""A group of fixed and/or floating IP addresses that are assigned to a project "" ""and can be used by or assigned to the VM instances in a project."" msgstr """" ""プロジェクトに割り当てられ、プロジェクトの仮想マシンインスタンスに使用でき"" ""る、固定 IP アドレスと Floating IP アドレスのグループ。"" msgid """" ""A group of interrelated web development techniques used on the client-side "" ""to create asynchronous web applications. Used extensively in horizon."" msgstr """" ""非同期 Web アプリケーションを作成する為にクライアント側で使用される相互関係の"" ""ある Web 開発技術の集合。Horizon で広く使用されている。"" msgid """" ""A group of related button types within horizon. Buttons to start, stop, and "" ""suspend VMs are in one class. Buttons to associate and disassociate floating "" ""IP addresses are in another class, and so on."" msgstr """" ""Horizon 内で関連するボタン種別のグループ。仮想マシンを起動、停止、休止するボ"" ""タンは、1 つのクラスにある。Floating IP アドレスを関連付ける、関連付けを解除"" ""するボタンは、別のクラスにある。"" msgid """" ""A group of users; used to isolate access to Compute resources. An "" ""alternative term for a project."" msgstr """" ""ユーザーのグループ。Compute リソースへのアクセスを分離するために使用される。"" ""プロジェクトの別名。"" msgid """" ""A grouped release of projects related to OpenStack that came out in April "" ""2012, the fifth release of OpenStack. It included Compute (nova 2012.1), "" ""Object Storage (swift 1.4.8), Image (glance), Identity (keystone), and "" ""Dashboard (horizon). Essex is the code name for the fifth release of "" ""OpenStack. The design summit took place in Boston, Massachusetts, US and "" ""Essex is a nearby city."" msgstr """" ""2012年４月に登場した OpenStack 関連プロジェクトのリリース。Compute (nova "" ""2012.1), Object Storage (swift 1.4.8), Image (glance), Identity (keystone), "" ""Dashboard (horizon) が含まれる。Essex は、OpenStack の 5 番目のリリースのコー"" ""ド名。デザインサミットは、アメリカ合衆国マサチューセッツ州ボストンで開催され"" ""た。Essex はその近郊都市。"" msgid """" ""A grouped release of projects related to OpenStack that came out in February "" ""of 2011. It included only Compute (nova) and Object Storage (swift). Bexar "" ""is the code name for the second release of OpenStack. The design summit took "" ""place in San Antonio, Texas, US, which is the county seat for Bexar county."" msgstr """" ""2011 年 2 月に登場した OpenStack 関連プロジェクトのリリース。Compute (nova) "" ""と Object Storage (swift) が含まれる。Bexar は OpenStack の 2 番目のコード"" ""名。デザインサミットは、アメリカ合衆国テキサス州サンアントニオで開催された。"" ""ベア郡の郡庁所在地。"" msgid """" ""A grouped release of projects related to OpenStack that came out in the fall "" ""of 2011, the fourth release of OpenStack. It included Compute (nova 2011.3), "" ""Object Storage (swift 1.4.3), and the Image service (glance). Diablo is the "" ""code name for the fourth release of OpenStack. The design summit took place "" ""in in the Bay Area near Santa Clara, California, US and Diablo is a nearby "" ""city."" msgstr """" ""2011年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova "" ""2011.3)、Object Storage (swift 1.4.3)、Image service (glance) が含まれる。"" ""Diablo は、OpenStack の 4 番目のリリースのコード名。デザインサミットは、アメ"" ""リカ合衆国カリフォルニア州サンタクララ近くにある海岸エリアで開催された。"" ""Diablo はその近郊都市。"" msgid """" ""A grouped release of projects related to OpenStack that came out in the fall "" ""of 2012, the sixth release of OpenStack. It includes Compute (nova), Object "" ""Storage (swift), Identity (keystone), Networking (neutron), Image service "" ""(glance), and Volumes or Block Storage (cinder). Folsom is the code name for "" ""the sixth release of OpenStack. The design summit took place in San "" ""Francisco, California, US and Folsom is a nearby city."" msgstr """" ""2012年秋に登場した OpenStack 関連プロジェクトのリリース。Compute (nova), "" ""Object Storage (swift), Identity (keystone), Networking (neutron), Image "" ""service (glance)、Volumes 又は Block Storage (cinder) が含まれる。Folsom は、"" ""OpenStack の 6 番目のリリースのコード名。デザインサミットは、アメリカ合衆国カ"" ""リフォルニア州サンフランシスコで開催された。Folsom は、その近郊都市。"" msgid """" ""A high availability system design approach and associated service "" ""implementation ensures that a prearranged level of operational performance "" ""will be met during a contractual measurement period. High availability "" ""systems seeks to minimize system downtime and data loss."" msgstr """" ""高可用性システムの設計手法および関連サービスの実装により、契約された計測期間"" ""中、合意された運用レベルを満たします。高可用性システムは、システムの停止時間"" ""とデータ損失を最小化しようとします。"" msgid """" ""A horizon component that stores and tracks client session information. "" ""Implemented through the Django sessions framework."" msgstr """" ""クライアントセッションの保持と追跡を行う Horizon のコンポーネント。 Django の"" ""セッションフレームワークを用いて実装されている。"" msgid """" ""A hybrid cloud is a composition of two or more clouds (private, community or "" ""public) that remain distinct entities but are bound together, offering the "" ""benefits of multiple deployment models. Hybrid cloud can also mean the "" ""ability to connect colocation, managed and/or dedicated services with cloud "" ""resources."" msgstr """" ""ハイブリッドクラウドは、複数のクラウド (プライベート、コミュニティー、パブ"" ""リック) の組み合わせ。別々のエンティティーのままですが、一緒にまとめられる。"" ""複数の配備モデルの利点を提供する。ハイブリッドクラウドは、コロケーション、マ"" ""ネージドサービス、専用サービスをクラウドのリソースに接続する機能を意味するこ"" ""ともある。"" msgid """" ""A kind of web service API that uses REST, or Representational State "" ""Transfer. REST is the style of architecture for hypermedia systems that is "" ""used for the World Wide Web."" msgstr """" ""REST を使用する Web サービス API の 1 種。REST は、WWW 向けに使用される、ハイ"" ""パーメディアシステム向けのアーキテクチャーの形式である。"" msgid """" ""A lightweight SQL database, used as the default persistent storage method in "" ""many OpenStack services."" msgstr """" ""軽量 SQL データベース。多くの OpenStack サービスでデフォルトの永続ストレージ"" ""として使用されている。"" msgid """" ""A list of API endpoints that are available to a user after authentication "" ""with the Identity service."" msgstr ""Identity による認証後、ユーザーが利用可能な API エンドポイントの一覧。"" msgid """" ""A list of URL and port number endpoints that indicate where a service, such "" ""as Object Storage, Compute, Identity, and so on, can be accessed."" msgstr """" ""URL やポート番号のエンドポイントの一覧。Object Storage、Compute、Identity な"" ""どのサービスがアクセスできる場所を意味する。"" msgid ""A list of VM images that are available through Image service."" msgstr ""Image service 経由で利用可能な仮想マシンイメージの一覧。"" msgid """" ""A list of permissions attached to an object. An ACL specifies which users or "" ""system processes have access to objects. It also defines which operations "" ""can be performed on specified objects. Each entry in a typical ACL specifies "" ""a subject and an operation. For instance, the ACL entry ``(Alice, delete)`` "" ""for a file gives Alice permission to delete the file."" msgstr """" ""オブジェクトに対するアクセス許可の一覧。オブジェクトにアクセスできるユーザー"" ""やシステムプロセスを指定する。また、特定のオブジェクトに対してどのような操作"" ""が行えるかを定義する。通常のアクセス制御リスト (ACL) の項目では対象項目と操作"" ""を指定する。例えば、あるファイルに対して ``(Alice, delete)`` という ACL 項目"" ""が定義されると、 Alice にファイルを削除する許可が付与される。"" msgid """" ""A list of tenants that can access a given VM image within Image service."" msgstr """" ""Image service 内で指定した仮想マシンイメージにアクセスできるテナントの一覧。"" msgid """" ""A load balancer is a logical device that belongs to a cloud account. It is "" ""used to distribute workloads between multiple back-end systems or services, "" ""based on the criteria defined as part of its configuration."" msgstr """" ""負荷分散装置は、クラウドアカウントに属する論理デバイスである。その設定に定義"" ""されている基準に基づき、複数のバックエンドのシステムやサービス間でワークロー"" ""ドを分散するために使用される。"" msgid """" ""A logical set of devices, such as web servers, that you group together to "" ""receive and process traffic. The load balancing function chooses which "" ""member of the pool handles the new requests or connections received on the "" ""VIP address. Each VIP has one pool."" msgstr """" ""Web サーバーなどのデバイスの論理的な集合。一緒にトラフィックを受け、処理する"" ""ために、グループ化する。負荷分散機能は、プール内のどのメンバーが仮想 IP アド"" ""レスで受信した新規リクエストや接続を処理するかを選択します。各仮想 IP は 1 つ"" ""のプールを持ちます。"" msgid """" ""A mechanism that allows IPv6 packets to be transmitted over an IPv4 network, "" ""providing a strategy for migrating to IPv6."" msgstr """" ""IPv6 パケットを IPv4 ネットワーク経由で送信するための機構。IPv6 に移行する手"" ""段を提供する。"" msgid """" ""A mechanism that allows many resources (for example, fonts, JavaScript) on a "" ""web page to be requested from another domain outside the domain from which "" ""the resource originated. In particular, JavaScript's AJAX calls can use the "" ""XMLHttpRequest mechanism."" msgstr """" ""Web ページのさまざまなリソース (例: フォント、JavaScript) を、リソースのある"" ""ドメインの外部から要求できるようになる機能。とくに、JavaScript の AJAX コール"" ""が XMLHttpRequest 機能を使用できる。"" msgid """" ""A message that is stored both in memory and on disk. The message is not lost "" ""after a failure or restart."" msgstr """" ""メモリーとディスクの両方に保存されているメッセージ。メッセージは、故障や再起"" ""動した後も失われません。"" msgid """" ""A message that is stored in memory and is lost after the server is restarted."" msgstr ""メモリーに保存され、サービスの再起動後に失われるメッセージ。"" msgid """" ""A method for making file systems available over the network. Supported by "" ""OpenStack."" msgstr """" ""ネットワーク経由でファイルシステムを利用可能にある方式。OpenStack によりサ"" ""ポートされる。"" msgid """" ""A method of VM live migration used by KVM to evacuate instances from one "" ""host to another with very little downtime during a user-initiated "" ""switchover. Does not require shared storage. Supported by Compute."" msgstr """" ""ユーザー操作によりあるホストから別のホストに切り替え中、わずかな停止時間でイ"" ""ンスタンスを退避するために、KVM により使用される仮想マシンのライブマイグレー"" ""ションの方法。共有ストレージ不要。Compute によりサポートされる。"" msgid """" ""A method of operating system installation where a finalized disk image is "" ""created and then used by all nodes without modification."" msgstr """" ""最終的なディスクイメージが作成され、すべてのノードで変更することなく使用され"" ""る、オペレーティングシステムのインストール方法。"" msgid """" ""A method to automatically configure networking for a host at boot time. "" ""Provided by both Networking and Compute."" msgstr """" ""ホストの起動時にネットワークを自動的に設定する方式。Networking と Compute に"" ""より提供される。"" msgid """" ""A method to establish trusts between identity providers and the OpenStack "" ""cloud."" msgstr ""認証プロバイダーと OpenStack クラウド間で信頼を確立する方法。"" msgid """" ""A method to further subdivide availability zones into hypervisor pools, a "" ""collection of common hosts."" msgstr """" ""アベイラビリティーゾーンをさらに小さいハイパーバイザープールに分割するための"" ""方法。一般的なホスト群。"" msgid """" ""A minimal Linux distribution designed for use as a test image on clouds such "" ""as OpenStack."" msgstr """" ""OpenStack などのクラウドでテストイメージとして使用するために設計された最小の "" ""Linux ディストリビューション。"" msgid """" ""A model that enables access to a shared pool of configurable computing "" ""resources, such as networks, servers, storage, applications, and services, "" ""that can be rapidly provisioned and released with minimal management effort "" ""or service provider interaction."" msgstr """" ""ネットワーク、サーバー、ストレージ、アプリケーション、サービスなどの設定可能"" ""なコンピューティングリソースの共有プールにアクセスできるモデル。最小限の管理"" ""作業やサービスプロバイダーとのやりとりで、迅速に配備できてリリースできる。"" msgid """" ""A network authentication protocol which works on the basis of tickets. "" ""Kerberos allows nodes communication over a non-secure network, and allows "" ""nodes to prove their identity to one another in a secure manner."" msgstr """" ""チケットベースで機能するネットワーク認証プロトコル。 Kerberos により、安全で"" ""ないネットワークを通したノード通信ができ、ノードは安全な方法で互いに本人確認"" ""ができるようになります。"" msgid """" ""A network protocol used by a network client to obtain an IP address from a "" ""configuration server. Provided in Compute through the dnsmasq daemon when "" ""using either the FlatDHCP manager or VLAN manager network manager."" msgstr """" ""管理サーバーから IP アドレスを取得するために、ネットワーククライアントにより"" ""使用されるネットワークプロトコル。FlatDHCP マネージャーや VLAN マネージャー使"" ""用時、dnsmasq デーモン経由で Compute で提供される。"" msgid ""A network segment typically used for instance Internet access."" msgstr """" ""一般的にインスタンスのインターネットアクセスに使用されるネットワークセグメン"" ""ト。"" msgid """" ""A network segment used for administration, not accessible to the public "" ""Internet."" msgstr """" ""管理のために使用されるネットワークセグメント。パブリックなインターネットから"" ""アクセスできない。"" msgid """" ""A network segment used for instance traffic tunnels between compute nodes "" ""and the network node."" msgstr """" ""コンピュートノードとネットワークノード間で、インスタンスのトラフィックをトン"" ""ネルするために使用されるネットワークセグメント。"" msgid """" ""A network virtualization technology that attempts to reduce the scalability "" ""problems associated with large cloud computing deployments. It uses a VLAN-"" ""like encapsulation technique to encapsulate Ethernet frames within UDP "" ""packets."" msgstr """" ""大規模なクラウドコンピューティング環境に関連するスケーラビリティー問題を削減"" ""するためのネットワーク仮想化技術。VLAN のようなカプセル化技術を使用して、"" ""Ethernet フレームを UDP パケット内にカプセル化する。"" msgid ""A node that provides the Object Storage proxy service."" msgstr ""Object Storage プロキシサービスを提供するノード。"" msgid """" ""A node that runs Object Storage account, container, and object services."" msgstr """" ""Object Storage のアカウントサービス、コンテナーサービス、オブジェクトサービス"" ""を実行するノード。"" msgid """" ""A node that runs network, volume, API, scheduler, and image services. Each "" ""service may be broken out into separate nodes for scalability or "" ""availability."" msgstr """" ""ネットワーク、ボリューム、API、スケジューラー、イメージサービスなどを実行する"" ""ノード。各サービスは、スケーラビリティーや可用性のために、別々のノードに分割"" ""することもできます。"" msgid """" ""A node that runs the nova-compute daemon that manages VM instances that "" ""provide a wide range of services, such as web applications and analytics."" msgstr """" ""nova-compute デーモン、Web アプリケーションや分析のような幅広いサービスを提供"" ""する仮想マシンインスタンスを実行するノード。"" msgid ""A notification agent (``ceilometer-agent-notification``)"" msgstr ""通知エージェント (``ceilometer-agent-notification``)"" msgid """" ""A notification driver that monitors VM instances and updates the capacity "" ""cache as needed."" msgstr """" ""VM インスタンスを監視し、必要に応じて容量キャッシュを更新する通知ドライバ。"" msgid ""A notification listener (``aodh-listener``)"" msgstr ""通知リスナー (``aodh-listener``)"" msgid """" ""A number of periodic processes run on the OpenStack Image service to support "" ""caching. Replication services ensure consistency and availability through "" ""the cluster. Other periodic processes include auditors, updaters, and "" ""reapers."" msgstr """" ""キャッシュをサポートするために、 OpenStack Image service 上では多くの定期的な"" ""プロセスが実行されます。複製サービスにより、クラスター全体での一貫性と可用性"" ""が確保されます。他の定期的なプロセスには auditor、 updater, reaper がありま"" ""す。"" msgid """" ""A number within a database that is incremented each time a change is made. "" ""Used by Object Storage when replicating."" msgstr """" ""変更が行われる度に増加するデータベース内の数値。Object Storage が複製を行う際"" ""に使用する。"" msgid """" ""A package commonly installed in VM images that performs initialization of an "" ""instance after boot using information that it retrieves from the metadata "" ""service, such as the SSH public key and user data."" msgstr """" ""メタデータサービスから取得した、SSH 公開鍵やユーザーデータなどの情報を使用し"" ""て、インスタンスの起動後に初期化を実行する、一般的に仮想マシンイメージにイン"" ""ストールされるパッケージ。"" msgid """" ""A packaged version available in the Open Build Service (`https://build."" ""opensuse.org/package/show? package=python-pip&project=Cloud:OpenStack:Master "" ""<https://build.opensuse.org/package/show?package=pyt hon-pip&project=Cloud:"" ""OpenStack:Master>`__) enables you to use YaST or zypper to install the "" ""package."" msgstr """" ""Open Build Service (`https://build.opensuse.org/package/show?package=python-"" ""pip&project=Cloud:OpenStack:Master <https://build.opensuse.org/package/show?"" ""package=python-pip&project=Cloud:OpenStack:Master>`__) にあるパッケージを利用"" ""できます。または、パッケージをインストールするために YaST や zypper を使用で"" ""きます。"" msgid ""A packaged version enables you to use yum to install the package:"" msgstr ""yum を使用してインストールできるパッケージがあります。"" msgid ""A persistent storage method supported by XenAPI, such as iSCSI or NFS."" msgstr ""iSCSI や NFS など、XenAPI によりサポートされる永続ストレージ方式。"" msgid ""A person who plans, designs, and oversees the creation of clouds."" msgstr ""クラウドの作成を計画、設計および監督する人。"" msgid """" ""A personality that a user assumes to perform a specific set of operations. A "" ""role includes a set of rights and privileges. A user assuming that role "" ""inherits those rights and privileges."" msgstr """" ""ユーザーが特定の操作の組を実行すると仮定する人格。ロールは一組の権利と権限を"" ""含みます。そのロールを仮定しているユーザーは、それらの権利と権限を継承しま"" ""す。"" msgid ""A physical computer, not a VM instance (node)."" msgstr ""物理コンピューター。仮想マシンインスタンス (ノード) ではない。"" msgid """" ""A physical or virtual device that provides connectivity to another device or "" ""medium."" msgstr ""他のデバイスやメディアに接続する物理デバイスまたは仮想デバイス。"" msgid """" ""A physical or virtual network device that passes network traffic between "" ""different networks."" msgstr """" ""異なるネットワーク間でネットワーク通信を転送する、物理または仮想のネットワー"" ""クデバイス。"" msgid """" ""A piece of software that makes available another piece of software over a "" ""network."" msgstr """" ""他のソフトウェア部品をネットワーク経由で利用可能にするソフトウェア部品。"" msgid """" ""A platform that provides a suite of desktop environments that users access "" ""to receive a desktop experience from any location. This may provide general "" ""use, development, or even homogeneous testing environments."" msgstr """" ""デスクトップ環境群を提供するプラットフォーム。ユーザーがどこからでもデスク"" ""トップを利用するためにアクセスする可能性がある。一般的な使用、開発、同種のテ"" ""スト環境さえも提供できる。"" msgid ""A plug-in for the OpenStack dashboard (horizon)."" msgstr ""OpenStack dashboard (horizon) のプラグイン。"" msgid """" ""A point-in-time copy of an OpenStack storage volume or image. Use storage "" ""volume snapshots to back up volumes. Use image snapshots to back up data, or "" ""as \""gold\"" images for additional servers."" msgstr """" ""OpenStack ストレージボリュームやイメージの、ある時点でのコピー。ストレージの"" ""ボリュームスナップショットは、ボリュームをバックアップするために使用する。イ"" ""メージスナップショットは、データのバックアップを行ったり、新しいサーバー用の"" ""「ゴールド」イメージ（設定済みイメージ）としてバックアップしたりするのに使用"" ""する。"" msgid """" ""A pre-made VM image that serves as a cloudpipe server. Essentially, OpenVPN "" ""running on Linux."" msgstr """" ""cloudpipe サーバとしてサービスを行う為の、予め用意された VM イメージ。本質的"" ""には Linux 上で実行される OpenVPN。"" msgid """" ""A process that is created when a RPC call is executed; used to push the "" ""message to the topic exchange."" msgstr """" ""RPC コールが実行されるときに作成されるプロセス。メッセージをトピック交換者に"" ""プッシュするために使用される。"" msgid """" ""A process that runs in the background and waits for requests. May or may not "" ""listen on a TCP or UDP port. Do not confuse with a worker."" msgstr """" ""バックグラウンドで動作し、リクエストを待機するプロセス。TCP ポートや UDP ポー"" ""トをリッスンする可能性がある。ワーカーとは異なる。"" msgid """" ""A program that keeps the Image service VM image cache at or below its "" ""configured maximum size."" msgstr """" ""Image service の仮想マシンイメージキャッシュを設定した最大値以下に保つプログ"" ""ラム。"" msgid """" ""A programming language that is used to create systems that involve more than "" ""one computer by way of a network."" msgstr """" ""ネットワーク経由で複数のコンピューターが関連するシステムを作成するために使用"" ""されるプログラミング言語。"" msgid """" ""A project that is not officially endorsed by the OpenStack Foundation. If "" ""the project is successful enough, it might be elevated to an incubated "" ""project and then to a core project, or it might be merged with the main code "" ""trunk."" msgstr """" ""OpenStack Foundation で公認されていないプロジェクト。プロジェクトが充分成功し"" ""た場合、育成プロジェクトに昇格し、その後コアプロジェクトに昇格する事がある。"" ""あるいはメインの code trunk にマージされる事もある。"" msgid """" ""A project that ports the shell script-based project named DevStack to Python."" msgstr """" ""DevStack という名前のシェルスクリプトベースのプロジェクトを Python に移植する"" ""プロジェクト。"" msgid ""A recommended architecture for an OpenStack cloud."" msgstr ""OpenStack クラウドの推奨アーキテクチャー。"" msgid """" ""A record that specifies information about a particular domain and belongs to "" ""the domain."" msgstr ""特定のドメインに関する情報を指定し、ドメインに所属するレコード。"" msgid """" ""A remote, mountable file system in the context of the Shared File Systems. "" ""You can mount a share to, and access a share from, several hosts by several "" ""users at a time."" msgstr """" ""Shared File System サービスにおいて、リモートのマウント可能なファイルシステム"" ""のこと。同時に、複数のユーザーが複数のホストから、共有をマウントしたり、アク"" ""セスしたりできる。"" msgid ""A routing algorithm in the Compute RabbitMQ."" msgstr ""Compute RabbitMQ におけるルーティングアルゴリズム。"" msgid """" ""A routing table that is created within the Compute RabbitMQ during RPC "" ""calls; one is created for each RPC call that is invoked."" msgstr """" ""RPC コール中に Compute RabbitMQ 内で作成されるルーティングテーブル。関連する"" ""各 RPC コールに対して作成されるもの。"" msgid """" ""A running VM, or a VM in a known state such as suspended, that can be used "" ""like a hardware server."" msgstr """" ""実行中の仮想マシン。または、一時停止などの既知の状態にある仮想マシン。ハード"" ""ウェアサーバーのように使用できる。"" msgid """" ""A scheduling method used by Compute that randomly chooses an available host "" ""from the pool."" msgstr """" ""利用可能なホストをプールからランダムに選択する、Compute により使用されるスケ"" ""ジューリング方式。"" msgid ""A scripting language that is used to build web pages."" msgstr ""Web ページを構築するために使用されるスクリプト言語。"" msgid """" ""A security model that focuses on data confidentiality and controlled access "" ""to classified information. This model divide the entities into subjects and "" ""objects. The clearance of a subject is compared to the classification of the "" ""object to determine if the subject is authorized for the specific access "" ""mode. The clearance or classification scheme is expressed in terms of a "" ""lattice."" msgstr """" ""データの機密性、および区分けした情報へのアクセスの制御に注力したセキュリ"" ""ティーモデル。このモデルは、エンティティーをサブジェクト (主体) とオブジェク"" ""ト (対象) に分ける。サブジェクトが特定のアクセスモードを許可されるかどうかを"" ""判断するために、サブジェクトの権限がオブジェクトの区分と比較される。権限や区"" ""分のスキーマは、格子モデルで表現される。"" msgid """" ""A server daemon that serves the Nova Cert service for X509 certificates. "" ""Used to generate certificates for ``euca-bundle-image``. Only needed for the "" ""EC2 API."" msgstr """" ""X509 証明書用の Nova Cert サービスを提供するサーバーデーモン。 ``euca-bundle-"" ""image`` 用の証明書を生成するのに使用されます。 EC2 API を使用する場合にのみ必"" ""要です。"" msgid """" ""A set of OpenStack resources created and managed by the Orchestration "" ""service according to a given template (either an AWS CloudFormation template "" ""or a Heat Orchestration Template (HOT))."" msgstr """" ""指定されたテンプレート (AWS CloudFormation テンプレートまたは Heat "" ""Orchestration Template (HOT)) に基づいて、Orchestration により作成、管理され"" ""る OpenStack リソース群。"" msgid """" ""A set of command-line interpreter commands for managing cloud resources. "" ""Although it is not an OpenStack module, you can configure nova-api to "" ""support this EC2 interface. For more information, see the `Eucalyptus 3.4 "" ""Documentation <https://www.eucalyptus.com/docs/eucalyptus/3.4/index.html>`__."" msgstr """" ""クラウドリソースを管理するのに使用するコマンドラインツール群。 OpenStack が提"" ""供するモジュールではありませんが、 nova-api を設定して、 EC2 インターフェース"" ""をサポートするようにできます。詳しい情報は `Eucalyptus 3.4 Documentation "" ""<https://www.eucalyptus.com/docs/eucalyptus/3.4/index.html>`__ を参照してくだ"" ""さい。"" msgid """" ""A set of network traffic filtering rules that are applied to a Compute "" ""instance."" msgstr """" ""Compute のインスタンスに適用される、ネットワーク通信のフィルタリングルールの"" ""集合。"" msgid """" ""A set of segment objects that Object Storage combines and sends to the "" ""client."" msgstr """" ""Object Storage が結合し、クライアントに送信する、オブジェクトの断片の塊。"" msgid """" ""A simple certificate authority provided by Compute for cloudpipe VPNs and VM "" ""image decryption."" msgstr """" ""cloudpipe VPN と仮想マシンイメージの復号のために、Compute により提供される簡"" ""単な認証局。"" msgid """" ""A special Object Storage object that contains the manifest for a large "" ""object."" msgstr """" ""大きなオブジェクト向けのマニフェストを含む、特別な Object Storage のオブジェ"" ""クト。"" msgid """" ""A special type of VM image that is booted when an instance is placed into "" ""rescue mode. Allows an administrator to mount the file systems for an "" ""instance to correct the problem."" msgstr """" ""インスタンスがレスキューモード時に起動する、特別な種類の仮想マシンイメージ。"" ""管理者が問題を修正するために、インスタンスのファイルシステムをマウントでき"" ""る。"" msgid """" ""A specification that, when implemented by a physical PCIe device, enables it "" ""to appear as multiple separate PCIe devices. This enables multiple "" ""virtualized guests to share direct access to the physical device, offering "" ""improved performance over an equivalent virtual device. Currently supported "" ""in OpenStack Havana and later releases."" msgstr """" ""物理 PCIe デバイスにより実装されるとき、複数の別々の PCIe デバイスとして見え"" ""るようにできる仕様。これにより、複数の仮想化ゲストが物理デバイスへの直接アク"" ""セスを共有できるようになる。同等の仮想デバイス経由より性能を改善できる。"" msgid """" ""A standardized interface for managing compute, data, and network resources, "" ""currently unsupported in OpenStack."" msgstr """" ""コンピュート、データ、ネットワークのリソースを管理するための標準的なインター"" ""フェース。現在 OpenStack でサポートされない。"" msgid """" ""A string of text provided to the client after authentication. Must be "" ""provided by the user or process in subsequent requests to the API endpoint."" msgstr """" ""認証後にクライアントに提供されるテキスト文字列。API エンドポイントに続くリク"" ""エストにおいて、ユーザーまたはプロセスにより提供される必要がある。"" msgid """" ""A subset of API calls that are accessible to authorized administrators and "" ""are generally not accessible to end users or the public Internet. They can "" ""exist as a separate service (keystone) or can be a subset of another API "" ""(nova)."" msgstr """" ""認可された管理者がアクセスでき、一般的にエンドユーザーとパブリックなインター"" ""ネットがアクセスできない、API コールのサブセット。専用のサービス (keystone) "" ""が存在し、他の API (nova) のサブセットになる可能性がある。"" msgid """" ""A system by which Internet domain name-to-address and address-to-name "" ""resolutions are determined. DNS helps navigate the Internet by translating "" ""the IP address into an address that is easier to remember. For example, "" ""translating 111.111.111.1 into www.yahoo.com. All domains and their "" ""components, such as mail servers, utilize DNS to resolve to the appropriate "" ""locations. DNS servers are usually set up in a master-slave relationship "" ""such that failure of the master invokes the slave. DNS servers might also be "" ""clustered or replicated such that changes made to one DNS server are "" ""automatically propagated to other active servers. In Compute, the support "" ""that enables associating DNS entries with floating IP addresses, nodes, or "" ""cells so that hostnames are consistent across reboots."" msgstr """" ""インターネットのドメイン名からアドレス、アドレスからドメイン名に名前解決する"" ""システム。DNS は、IP アドレスを人間が覚えやすいアドレスに変換することにより、"" ""インターネットを参照しやすくする。例えば、111.111.111.1 を www.yahoo.com に変"" ""換する。すべてのドメイン、メールサーバーなどのコンポーネントは、DNS を利用し"" ""て、適切な場所を解決する。DNS サーバーは、マスターの障害がスレーブにより助け"" ""られるよう、一般的にマスターとスレーブの関係で構築する。DNS サーバーは、ある "" ""DNS サーバーへの変更が他の動作中のサーバーに自動的に反映されるよう、クラス"" ""ター化やレプリケーションされることもある。 Compute では、 Floating IP アドレ"" ""ス、ノード、セルを DNS エントリーに関連付けることができ、リブートの前後でホス"" ""ト名が変わらないようにできます。"" msgid """" ""A system that provides services to other system entities. In case of "" ""federated identity, OpenStack Identity is the service provider."" msgstr """" ""サービスを他のシステムエンティティーに提供するシステム。連合認証の場合、"" ""OpenStack Identity がサービスプロバイダーとなる。"" msgid """" ""A tool to automate system configuration and installation on Debian-based "" ""Linux distributions."" msgstr """" ""Debian 系の Linux ディストリビューションでシステム設定やインストールを自動化"" ""するツール。"" msgid """" ""A tool to automate system configuration and installation on Red Hat, Fedora, "" ""and CentOS-based Linux distributions."" msgstr """" ""Red Hat、Fedora、CentOS 系の Linux ディストリビューションにおいて、システム設"" ""定とインストールを自動化するためのツール。"" msgid ""A type of VM image that exists as a single, bootable file."" msgstr ""単独の、ブート可能なファイルとして存在する仮想マシンイメージの形式。"" msgid """" ""A type of image file that is commonly used for animated images on web pages."" msgstr ""Web ページのアニメーション画像によく使用される画像ファイルの形式。"" msgid """" ""A type of reboot where a physical or virtual power button is pressed as "" ""opposed to a graceful, proper shutdown of the operating system."" msgstr """" ""きちんとした正常なOSのシャットダウンを行わず、物理又は仮想電源ボタンを押すタ"" ""イプの再起動。"" msgid ""A unique ID given to each replica of an Object Storage database."" msgstr ""Object Storage データベースの各レプリカに与えられる一意な ID。"" msgid """" ""A unit of storage within Object Storage used to store objects. It exists on "" ""top of devices and is replicated for fault tolerance."" msgstr """" ""オブジェクトを保存するために使用される、Object Storage 内の保存単位。デバイス"" ""の上位に存在し、耐障害のために複製される。"" msgid """" ""A user specifies their username and password credentials to interact with "" ""OpenStack, using any client command. These credentials can be specified "" ""using various mechanisms, namely, the environment variable or command-line "" ""argument. It is not safe to specify the password using either of these "" ""methods."" msgstr """" ""ユーザーは、何らかのクライアントコマンドを使用して、ユーザー名とパスワードを"" ""指定して、OpenStack を使用します。これらのクレデンシャルは、環境変数やコマン"" ""ドライン引数など、さまざまな方法により指定できます。これらの方法を用いて、パ"" ""スワードを指定することは安全ではありません。"" msgid """" ""A user-created Python module that is loaded by horizon to change the look "" ""and feel of the dashboard."" msgstr """" ""ダッシュボードのルックアンドフィールを変更する為に Horizon がロードする、ユー"" ""ザが作成した Python モジュール。"" msgid """" ""A virtual network port within Networking; VIFs / vNICs are connected to a "" ""port."" msgstr """" ""Networking 内の仮想ネットワークポート。仮想インターフェースや仮想 NIC は、"" ""ポートに接続されます。"" msgid """" ""A virtual network that provides connectivity between entities. For example, "" ""a collection of virtual ports that share network connectivity. In Networking "" ""terminology, a network is always a layer-2 network."" msgstr """" ""エンティティ間の接続性を提供する仮想ネットワーク。例えば、ネットワーク接続性"" ""を共有する仮想ポート群。Networking の用語では、ネットワークは必ず L2 ネット"" ""ワークを意味する。"" msgid """" ""A volume is a detachable block storage device, similar to a USB hard drive. "" ""You can attach a volume to only one instance. To create and manage volumes, "" ""you use a combination of ``nova`` and ``cinder`` client commands."" msgstr """" ""ボリュームは、USB ハードディスクのように、着脱可能なブロックストレージです。"" ""ボリュームは、インスタンス 1 つだけに接続できます。``nova`` コマンドと "" ""``cinder`` コマンドを組み合わせて、ボリュームを作成して管理します。"" msgid ""A web framework used extensively in horizon."" msgstr ""Horizon 中で広く使用される Web フレームワーク。"" msgid """" ""A worker daemon that creates and terminates virtual machine instances "" ""through hypervisor APIs. For example:"" msgstr """" ""ハイパーバイザー API を使用して仮想マシンインスタンスの作成、終了を行うワー"" ""カーデーモン。例えば、以下のようなハイパーバイザー API に対応しています。"" msgid """" ""A worker process that verifies the integrity of Object Storage objects, "" ""containers, and accounts. Auditors is the collective term for the Object "" ""Storage account auditor, container auditor, and object auditor."" msgstr """" ""Object Storage のオブジェクト、コンテナー、アカウントの完全性を検証するワー"" ""カープロセス。auditor は、Object Storage アカウント auditor、コンテナー "" ""auditor、オブジェクト auditor の総称。"" msgid """" ""A wrapper used by the Image service that contains a VM image and its "" ""associated metadata, such as machine state, OS disk size, and so on."" msgstr """" ""仮想マシンイメージ、および、マシンの状態や OS ディスク容量などの関連メタデー"" ""タを含む、Image service により使用されるラッパー。"" msgid ""ACL"" msgstr ""ACL"" msgid ""API endpoint"" msgstr ""API エンドポイント"" msgid ""API extension"" msgstr ""API 拡張"" msgid ""API extension plug-in"" msgstr ""API 拡張プラグイン"" msgid ""API key"" msgstr ""API キー"" msgid ""API server"" msgstr ""API サーバー"" msgid ""API token"" msgstr ""API トークン"" msgid """" ""API used to access OpenStack Networking. Provides an extensible architecture "" ""to enable custom plug-in creation."" msgstr """" ""OpenStack Networking にアクセスするために利用する API。独自プラグインを作成で"" ""きる拡張性を持ったアーキテクチャーになっている。"" msgid ""API used to access OpenStack Object Storage."" msgstr ""OpenStack Object Storage にアクセスするために使用する API。"" msgid ""API version"" msgstr ""API バージョン"" msgid ""ATA over Ethernet (AoE)"" msgstr ""ATA over Ethernet (AoE)"" msgid ""AWS"" msgstr ""AWS"" msgid """" ""AWS CloudFormation allows AWS users to create and manage a collection of "" ""related resources. The Orchestration service supports a CloudFormation-"" ""compatible format (CFN)."" msgstr """" ""AWS CloudFormation により、AWS ユーザーは関連するリソース群を作成し、管理でき"" ""るようになる。オーケストレーションサービスは CloudFormation 互換形式 (CFN) を"" ""サポートする。"" msgid ""AWS CloudFormation template"" msgstr ""AWS CloudFormation テンプレート"" msgid """" ""Absolute limit on the amount of network traffic a Compute VM instance can "" ""send and receive."" msgstr """" ""Compute の仮想マシンインスタンスが送受信できるネットワーク通信量の絶対制限。"" msgid ""Accept a volume transfer request"" msgstr ""ボリュームの譲渡要求の受理"" msgid ""Accept the request:"" msgstr ""要求を確定します。"" msgid """" ""Accepts API requests and routes them to the ``manila-share`` for action."" msgstr """" ""API リクエストを受け付け、それらを処理するために ``manila-share`` に中継しま"" ""す。"" msgid """" ""Accepts API requests, and routes them to the ``cinder-volume`` for action."" msgstr """" ""API リクエストを受け付け、それらを処理するために ``cinder-volume`` に中継しま"" ""す。"" msgid ""Accepts Image API calls for image discovery, retrieval, and storage."" msgstr ""イメージの検索、取得、保存の Image API を受け付けます。"" msgid """" ""Accepts OpenStack Object Storage API and raw HTTP requests to upload files, "" ""modify metadata, and create containers. It also serves file or container "" ""listings to web browsers. To improve performance, the proxy server can use "" ""an optional cache that is usually deployed with memcache."" msgstr """" ""OpenStack Object Storage API と生の HTTP リクエストを受け付け、ファイルのアッ"" ""プロード、メタデータの変更、コンテナーの作成などを行います。ウェブブラウザー"" ""に対するファイルやコンテナーの一覧表示も行えます。性能を向上させるために、プ"" ""ロキシーサーバーがキャッシュを使うこともできます。通常はキャッシュには "" ""memcache が使用されます。"" msgid """" ""Accepts and responds to end user compute API calls. The service supports the "" ""OpenStack Compute API, the Amazon EC2 API, and a special Admin API for "" ""privileged users to perform administrative actions. It enforces some "" ""policies and initiates most orchestration activities, such as running an "" ""instance."" msgstr """" ""エンドユーザーからの compute API 呼び出しを受け取り応答します。このサービス"" ""は OpenStack Compute API、Amazon EC2 API 、および、特権ユーザーが管理用操作を"" ""実行するための特別な管理 API をサポートしています。ポリシーの適用を行います。"" ""インスタンス起動などのほとんどの処理がこのサービスから開始されます。"" msgid """" ""Accepts and routes API requests to the appropriate OpenStack Networking plug-"" ""in for action."" msgstr """" ""API リクエストを受け付け、適切な OpenStack Networking プラグインに処理を中継"" ""します。"" msgid """" ""Accepts metadata requests from instances. The ``nova-api-metadata`` service "" ""is generally used when you run in multi-host mode with ``nova-network`` "" ""installations. For details, see `Metadata service <http://docs.openstack.org/"" ""admin-guide-cloud/compute-networking-nova.html#metadata-service>`__ in the "" ""OpenStack Cloud Administrator Guide."" msgstr """" ""インスタンスからのメタデータ要求を受け取ります。 ``nova-api-metadata`` サービ"" ""スは通常 ``nova-network`` をマルチホストモードで動かしている場合に使用されま"" ""す。詳細については、OpenStack Cloud Administrator Guide の `Metadata service "" ""<http://docs.openstack.org/admin-guide-cloud/compute-networking-nova."" ""html#metadata-service>`__ を参照してください。"" msgid ""Access associated with a VM"" msgstr ""割り当てられた VM がアクセス"" msgid ""Access can be provided to a VM"" msgstr ""VM からアクセス可能"" msgid """" ""Access the Database service instance using typical database access commands. "" ""For example, with MySQL:"" msgstr """" ""一般的なデータベースアクセスコマンドを使用して、Database サービスのインスタン"" ""スにアクセスします。MySQL の例:"" msgid ""Account servers (swift-account-server)"" msgstr ""アカウントサーバー (swift-account-server)"" msgid ""Active Directory"" msgstr ""Active Directory"" msgid """" ""Acts as the gatekeeper to Object Storage and is responsible for "" ""authenticating the user."" msgstr ""Object Storage へのゲートとして動作する。ユーザーの認証に責任を持つ。"" msgid """" ""Add a line to include your newly created style sheet. For example, ``custom."" ""css`` file:"" msgstr """" ""新しく作成したスタイルシートを含む行を追加します。``custom.css`` ファイルの"" ""例::"" msgid ""Address Resolution Protocol (ARP)"" msgstr ""Address Resolution Protocol (ARP)"" msgid """" ""Administrative users can use the :guilabel:`Admin` tab to view usage and to "" ""manage instances, volumes, flavors, images, networks and so on."" msgstr """" ""管理ユーザーは :guilabel:`管理` タブを使用して、使用状況の確認、インスタン"" ""ス、ボリューム、フレーバー、イメージ、ネットワークなどの管理ができます。 "" msgid ""Administrator configures size setting, based on flavors"" msgstr ""管理者がフレーバーに基づいてサイズを設定"" msgid ""Advanced Message Queuing Protocol (AMQP)"" msgstr ""Advanced Message Queuing Protocol (AMQP)"" msgid ""Advanced RISC Machine (ARM)"" msgstr ""Advanced RISC Machine (ARM)"" msgid """" ""After the volume recipient, or new owner, accepts the transfer, you can see "" ""that the transfer is no longer available:"" msgstr """" ""ボリュームの転送先 (新しい所有者) が転送を確定した後は、その転送がすでに利用"" ""できない状態になっていることが分かります。"" msgid """" ""After you restart the Image service, you can use the following syntax to "" ""view the image's location information:"" msgstr """" ""Image service を再起動してから、以下の構文を使用してイメージの場所情報を確認"" ""します。"" msgid ""After you upload an image, you cannot change it."" msgstr ""イメージをアップロードした後は、イメージを変更できません。"" msgid """" ""All OpenStack core projects are provided under the terms of the Apache "" ""License 2.0 license."" msgstr """" ""すべての OpenStack コアプロジェクトは Apache License 2.0 ライセンスの条件で提"" ""供されている。"" msgid """" ""Allows a user to set a flag on an Object Storage container so that all "" ""objects within the container are versioned."" msgstr """" ""コンテナー内のすべてのオブジェクトがバージョンを付けられるように、ユーザーが "" ""Object Storage のコンテナーにフラグを設定できる。"" msgid ""Alphanumeric ID assigned to each Identity service role."" msgstr ""各 Identity service ロールに割り当てられる英数 ID。"" msgid ""Alternative name for the Block Storage API."" msgstr ""Block Storage API の別名。"" msgid ""Alternative name for the glance image API."" msgstr ""Glance イメージ API の別名。"" msgid ""Alternative term for a Networking plug-in or Networking API extension."" msgstr ""Networking プラグインや Networking API 拡張の別名。"" msgid ""Alternative term for a RabbitMQ message exchange."" msgstr ""RabbitMQ メッセージ交換の別名。"" msgid ""Alternative term for a VM image."" msgstr ""VM イメージの別名。"" msgid ""Alternative term for a VM instance type."" msgstr ""VM インスタンスタイプの別名。"" msgid ""Alternative term for a VM or guest."" msgstr ""仮想マシンやゲストの別名。"" msgid ""Alternative term for a cloud controller node."" msgstr ""クラウドコントローラーノードの別名。"" msgid ""Alternative term for a cloudpipe."" msgstr ""cloudpipe の別名。"" msgid ""Alternative term for a fixed IP address."" msgstr ""固定 IP アドレスの別名。"" msgid ""Alternative term for a flavor ID."" msgstr ""フレーバー ID の別名。"" msgid ""Alternative term for a non-durable exchange."" msgstr ""非永続交換の別名。"" msgid ""Alternative term for a non-durable queue."" msgstr ""非永続キューの別名。"" msgid ""Alternative term for a paused VM instance."" msgstr ""一時停止 VM インスタンスの別名。"" msgid ""Alternative term for a virtual network."" msgstr ""仮想ネットワークの別名。"" msgid ""Alternative term for a volume plug-in."" msgstr ""ボリュームプラグインの別名。"" msgid """" ""Alternative term for an API extension or plug-in. In the context of Identity "" ""service, this is a call that is specific to the implementation, such as "" ""adding support for OpenID."" msgstr """" ""API 拡張やプラグインの別名。Identity service では、OpenID のサポートの追加な"" ""ど、特定の実装を意味する。"" msgid ""Alternative term for an API token."" msgstr ""API トークンの別名。"" msgid ""Alternative term for an Amazon EC2 access key. See EC2 access key."" msgstr ""Amazon EC2 アクセスキーの別名。EC2 アクセスキー参照。"" msgid ""Alternative term for an Identity service catalog."" msgstr ""Identity サービスカタログの別名。"" msgid ""Alternative term for an Identity service default token."" msgstr ""Identity service デフォルトトークンの別名。"" msgid ""Alternative term for an Object Storage authorization node."" msgstr ""Object Storage 認可ノードの別名。"" msgid ""Alternative term for an admin API."" msgstr ""管理 API（admin API）の別名。"" msgid ""Alternative term for an ephemeral volume."" msgstr ""エフェメラルボリュームの別名。"" msgid ""Alternative term for an image."" msgstr ""イメージの別名。"" msgid ""Alternative term for instance UUID."" msgstr ""インスタンス UUID の別名。"" msgid ""Alternative term for non-durable."" msgstr ""非永続の別名。"" msgid ""Alternative term for tenant."" msgstr ""テナントの別名。"" msgid ""Alternative term for the Compute API."" msgstr ""Compute API の別名。"" msgid ""Alternative term for the Identity service API."" msgstr ""Identity service API の別名。"" msgid ""Alternative term for the Identity service catalog."" msgstr ""Identity サービスカタログの別名。"" msgid ""Alternative term for the Image service image registry."" msgstr ""Image service イメージレジストリの別名。"" msgid ""Alternative term for the Image service registry."" msgstr ""Image service レジストリの別名。"" msgid """" ""Alternatively, you can create the ``PROJECT-openrc.sh`` file from scratch, "" ""if you cannot download the file from the dashboard."" msgstr """" ""何らかの理由によりダッシュボードからファイルをダウンロードできない場合、代わ"" ""りに最初から ``PROJECT-openrc.sh`` ファイルを作成できます。"" msgid ""Amazon Kernel Image (AKI)"" msgstr ""Amazon Kernel Image (AKI)"" msgid ""Amazon Machine Image (AMI)"" msgstr ""Amazon Machine Image (AMI)"" msgid ""Amazon Ramdisk Image (ARI)"" msgstr ""Amazon Ramdisk Image (ARI)"" msgid ""Amazon Web Services."" msgstr ""Amazon Web Services。"" msgid """" ""An API endpoint used for both service-to-service communication and end-user "" ""interactions."" msgstr """" ""サービス間通信やエンドユーザーの操作などに使用される API エンドポイント。"" msgid """" ""An API on a separate endpoint for attaching, detaching, and creating block "" ""storage for compute VMs."" msgstr """" ""コンピュート VM 用のブロックストレージの作成、接続、接続解除を行うための API "" ""で、独立したエンドポイントとして提供される。"" msgid ""An API server (``aodh-api``)"" msgstr ""API サーバー (``aodh-api``)"" msgid ""An API server (``ceilometer-api``)"" msgstr ""API サーバー (``ceilometer-api``)"" msgid ""An API that is accessible to tenants."" msgstr ""テナントにアクセス可能な API。"" msgid """" ""An AWS Query API that is compatible with AWS CloudFormation. It processes "" ""API requests by sending them to the ``heat-engine`` over RPC."" msgstr """" ""AWS CloudFormation 互換の AWS Query API を提供します。受け取った API リスクエ"" ""ストを RPC 経由で ``heat-engine`` に送信します。"" msgid """" ""An Amazon EBS storage volume that contains a bootable VM image, currently "" ""unsupported in OpenStack."" msgstr """" ""ブート可能な仮想マシンイメージを含む Amazon EBS ストレージボリューム。現在 "" ""OpenStack では未サポート。"" msgid """" ""An Amazon EC2 concept of an isolated area that is used for fault tolerance. "" ""Do not confuse with an OpenStack Compute zone or cell."" msgstr """" ""耐障害性のために使用されるエリアを分離する Amazon EC2 の概念。OpenStack "" ""Compute のゾーンやセルと混同しないこと。"" msgid """" ""An IP address that a project can associate with a VM so that the instance "" ""has the same public IP address each time that it boots. You create a pool of "" ""floating IP addresses and assign them to instances as they are launched to "" ""maintain a consistent IP address for maintaining DNS assignment."" msgstr """" ""インスタンスを起動するたびに同じパブリック IP アドレスを持てるように、プロ"" ""ジェクトが仮想マシンに関連付けられる IP アドレス。DNS 割り当てを維持するため"" ""に、Floating IP アドレスのプールを作成し、インスタンスが起動するたびにそれら"" ""をインスタンスに割り当て、一貫した IP アドレスを維持します。"" msgid """" ""An IP address that can be assigned to a VM instance within the shared IP "" ""group. Public IP addresses can be shared across multiple servers for use in "" ""various high-availability scenarios. When an IP address is shared to another "" ""server, the cloud network restrictions are modified to enable each server to "" ""listen to and respond on that IP address. You can optionally specify that "" ""the target server network configuration be modified. Shared IP addresses can "" ""be used with many standard heartbeat facilities, such as keepalive, that "" ""monitor for failure and manage IP failover."" msgstr """" ""共有 IP グループ内の仮想マシンインスタンスに割り当てられる IP アドレス。パブ"" ""リック IP アドレスは、さまざまな高可用性のシナリオで使用するために複数サー"" ""バーにまたがり共有できる。IP アドレスが別のサーバーと共有されるとき、クラウド"" ""のネットワーク制限が変更され、各サーバーがリッスンでき、その IP アドレスに応"" ""答できるようになる。オプションとして、対象サーバーの変更するネットワーク設定"" ""を指定できる。共有 IP アドレスは、keepalive などの多くの標準的なハートビート"" ""機能と一緒に使用でき、エラーをモニターし、IP のフェイルオーバーを管理しる。"" msgid ""An IP address that is accessible to end-users."" msgstr ""エンドユーザがアクセス可能な IP アドレス。"" msgid """" ""An IP address that is associated with the same instance each time that "" ""instance boots, is generally not accessible to end users or the public "" ""Internet, and is used for management of the instance."" msgstr """" ""インスタンス起動時に毎回同じインスタンスに割当られるIPアドレス（一般に、エン"" ""ドユーザやパブリックインターネットからはアクセス出来ない）。インスタンスの管"" ""理に使用される。"" msgid """" ""An IP address used for management and administration, not available to the "" ""public Internet."" msgstr """" ""管理のために使用される IP アドレス。パブリックなインターネットから利用できま"" ""せん。"" msgid """" ""An IP address, typically assigned to a router, that passes network traffic "" ""between different networks."" msgstr """" ""異なるネットワーク間でネットワーク通信を中継する、IP アドレス。一般的にはルー"" ""ターに割り当てられる。"" msgid """" ""An Identity API v3 entity. Represents a collection of projects, groups and "" ""users that defines administrative boundaries for managing OpenStack Identity "" ""entities. On the Internet, separates a website from other sites. Often, the "" ""domain name has two or more parts that are separated by dots. For example, "" ""yahoo.com, usa.gov, harvard.edu, or mail.yahoo.com. Also, a domain is an "" ""entity or container of all DNS-related information containing one or more "" ""records."" msgstr """" ""Identity API v3 のエンティティー。プロジェクト、グループ、ユーザーの集合体"" ""で、 OpenStack Identity のエンティティー管理において管理境界を定義するための"" ""ものである。インターネット分野では、ドメインによりウェブサイトが区別され、多"" ""くの場合、ドメイン名はドット区切りの 2 以上の部分から構成される。例えば、 "" ""yahoo.com, usa.gov, harvard.edu, mail.yahoo.com など。また、ドメインは、DNS "" ""関連情報のエンティティーや 1 つ以上のレコードを持つ DNS 関連の情報の入れ物を"" ""表すのにも使用される。"" msgid """" ""An Identity service API access token that is associated with a specific "" ""tenant."" msgstr ""特定のテナントに関連付けられた Identity service API アクセストークン。"" msgid """" ""An Identity service API endpoint that is associated with one or more tenants."" msgstr """" ""1 つ以上のテナントと関連付けられた Identity service API エンドポイント。"" msgid """" ""An Identity service component that manages and validates tokens after a user "" ""or tenant has been authenticated."" msgstr """" ""ユーザーやテナントが認証された後、トークンを管理し、検証する Identity のコン"" ""ポーネント。"" msgid """" ""An Identity service feature that enables services, such as Compute, to "" ""automatically register with the catalog."" msgstr """" ""自動的にカタログに登録するために、Compute などのサービスを有効化する、"" ""Identity の機能。"" msgid """" ""An Identity service that lists API endpoints that are available to a user "" ""after authentication with the Identity service."" msgstr """" ""ユーザーが Identity で認証後、利用可能な API エンドポイントを一覧表示する、"" ""Identity のサービス。"" msgid """" ""An Identity service token that is not associated with a specific tenant and "" ""is exchanged for a scoped token."" msgstr """" ""特定のテナントに関連づけられていない、スコープ付きトークンのために交換され"" ""る、Identity のトークン。"" msgid """" ""An Identity v3 API entity. Represents a collection of users that is owned by "" ""a specific domain."" msgstr """" ""Identity v3 API のエンティティーで、特定のドメイン内のユーザーの集合を表す。"" msgid ""An Image service VM image that is available to all tenants."" msgstr ""すべてのテナントが利用できる Image service の仮想マシンイメージ。"" msgid ""An Image service VM image that is only available to specified tenants."" msgstr ""指定したテナントのみで利用可能な Image service の仮想マシンイメージ。"" msgid """" ""An Image service container format that indicates that no container exists "" ""for the VM image."" msgstr """" ""仮想マシンイメージ用のコンテナーが存在しないことを意味する、Image service の"" ""コンテナー形式。"" msgid """" ""An Image service that provides VM image metadata information to clients."" msgstr """" ""クライアントに仮想マシンイメージメタデータ情報を提供する Image service。"" msgid """" ""An Internet Protocol (IP) address configured on the load balancer for use by "" ""clients connecting to a service that is load balanced. Incoming connections "" ""are distributed to back-end nodes based on the configuration of the load "" ""balancer."" msgstr """" ""負荷分散するサービスへのクライアント接続に使用される負荷分散装置において設定"" ""される IP アドレス。受信の接続が、負荷分散の設定に基づいて、バックエンドの"" ""ノードに分散される。"" msgid ""An L2 network segment within Networking."" msgstr ""Networking 内の L2 ネットワークセグメント。"" msgid ""An Object Storage component that collects meters."" msgstr ""計測項目を収集する Object Storage のコンポーネント。"" msgid """" ""An Object Storage component that copies an object to remote partitions for "" ""fault tolerance."" msgstr """" ""耐障害性のためにオブジェクトをリモートパーティションをコピーする Object "" ""Storage コンポーネント。"" msgid """" ""An Object Storage component that copies changes in the account, container, "" ""and object databases to other nodes."" msgstr """" ""アカウント、コンテナー、オブジェクトデータベースを他のノードに変更点をコピー"" ""する Object Storage コンポーネント。"" msgid ""An Object Storage component that is responsible for managing objects."" msgstr ""オブジェクトの管理に責任を持つ Object Storage のコンポーネント。"" msgid """" ""An Object Storage component that provides account services such as list, "" ""create, modify, and audit. Do not confuse with OpenStack Identity service, "" ""OpenLDAP, or similar user-account services."" msgstr """" ""一覧表示、作成、変更、監査などのアカウントサービスを提供する、Object Storage "" ""のコンポーネント。OpenStack Identity、OpenLDAP、類似のユーザーアカウントサー"" ""ビスなどと混同しないこと。"" msgid """" ""An Object Storage large object that has been broken up into pieces. The re-"" ""assembled object is called a concatenated object."" msgstr """" ""部品に分割された Object Storage の大きなオブジェクト。再構築されたオブジェク"" ""トは、連結オブジェクトと呼ばれる。"" msgid """" ""An Object Storage middleware component that enables creation of URLs for "" ""temporary object access."" msgstr """" ""一時的なオブジェクトアクセスのために URL を作成できる Object Storage ミドル"" ""ウェアコンポーネント。"" msgid ""An Object Storage node that provides authorization services."" msgstr ""認可サービスを提供する Object Storage ノード。"" msgid """" ""An Object Storage node that provides container services, account services, "" ""and object services; controls the account databases, container databases, "" ""and object storage."" msgstr """" ""コンテナーサービス、アカウントサービス、オブジェクトサービスを提供する "" ""Object Storage のノード。アカウントデータベース、コンテナーデータベース、オブ"" ""ジェクトデータベースを制御する。"" msgid ""An Object Storage server that manages containers."" msgstr ""コンテナーを管理する Object Storage サーバー。"" msgid """" ""An Object Storage worker that scans for and deletes account databases and "" ""that the account server has marked for deletion."" msgstr """" ""アカウントサーバーが削除する印を付けた、アカウントデータベースをスキャンし、"" ""削除する、Object Storage のワーカー。"" msgid """" ""An OpenStack core project that provides discovery, registration, and "" ""delivery services for disk and server images. The project name of the Image "" ""service is glance."" msgstr """" ""ディスクやサーバーイメージ向けのサービスの検索、登録、配信を提供する "" ""OpenStack コアプロジェクト。Image service のプロジェクト名は glance。"" msgid ""An OpenStack core project that provides object storage services."" msgstr ""オブジェクトストレージサービスを提供する OpenStack コアプロジェクト。"" msgid """" ""An OpenStack grouped release of projects that came out in the spring of "" ""2011. It included Compute (nova), Object Storage (swift), and the Image "" ""service (glance). Cactus is a city in Texas, US and is the code name for the "" ""third release of OpenStack. When OpenStack releases went from three to six "" ""months long, the code name of the release changed to match a geography "" ""nearest the previous summit."" msgstr """" ""2011年春に登場した OpenStack 関連プロジェクトのリリース。Compute (nova)、"" ""Object Storage (swift)、Image service (glance) が含まれる。Cactus は、アメリ"" ""カ合衆国テキサス州の都市であり、OpenStack の 3 番目のリリースのコード名であ"" ""る。OpenStack のリリース間隔が 3 か月から 6 か月になったとき、リリースのコー"" ""ド名が前のサミットと地理的に近いところになるように変更された。"" msgid """" ""An OpenStack service that provides a set of services for management of "" ""shared file systems in a multi-tenant cloud environment. The service is "" ""similar to how OpenStack provides block-based storage management through the "" ""OpenStack Block Storage service project. With the Shared File Systems "" ""service, you can create a remote file system and mount the file system on "" ""your instances. You can also read and write data from your instances to and "" ""from your file system. The project name of the Shared File Systems service "" ""is manila."" msgstr """" ""マルチテナントのクラウド環境で共有ファイルシステムを管理するためのサービス群"" ""を提供する OpenStack サービス。 OpenStack がブロックベースのストレージ管理"" ""を、 OpenStack Block Storage サービスプロジェクトとして提供しているのと類似し"" ""ている。 Shared File Systems サービスを使うと、リモートファイルシステムを作成"" ""し、自分のインスタンスからそのファイルシステムをマウントし、インスタンスから"" ""そのファイルシステムの読み書きを行える。このプロジェクトのコード名は manila。"" msgid """" ""An OpenStack service, such as Compute, Object Storage, or Image service. "" ""Provides one or more endpoints through which users can access resources and "" ""perform operations."" msgstr """" ""Compute、Object Storage、Image service などの OpenStack のサービス。ユーザー"" ""がリソースにアクセスしたり、操作を実行したりできる 1 つ以上のエンドポイントを"" ""提供する。"" msgid """" ""An OpenStack-native REST API that processes API requests by sending them to "" ""the ``heat-engine`` over :term:`Remote Procedure Call (RPC)`."" msgstr """" ""OpenStack 独自の REST API を提供します。 受け取った API リスクエストを、 :"" ""term:`リモートプロシージャコール (RPC) <Remote Procedure Call (RPC)>` 経由"" ""で ``heat-engine`` に送信します。"" msgid ""An OpenStack-provided image."" msgstr ""OpenStack が提供するイメージ。"" msgid ""An OpenStack-supported hypervisor."" msgstr ""OpenStack がサポートするハイパーバイザーの１つ。"" msgid """" ""An OpenStack-supported hypervisor. KVM is a full virtualization solution for "" ""Linux on x86 hardware containing virtualization extensions (Intel VT or AMD-"" ""V), ARM, IBM Power, and IBM zSeries. It consists of a loadable kernel "" ""module, that provides the core virtualization infrastructure and a processor "" ""specific module."" msgstr """" ""OpenStack がサポートするハイパーバイザー。KVM は、仮想化拡張 (Intel VT や "" ""AMD-V) を持つ x86 ハードウェア、ARM、IBM Power、IBM zSeries 上の Linux 向けの"" ""完全仮想化ソリューション。"" msgid ""An administrator who has access to all hosts and instances."" msgstr ""すべてのホストやインスタンスへアクセス権を持つ管理者。"" msgid """" ""An administrator-defined token used by Compute to communicate securely with "" ""the Identity service."" msgstr """" ""Identity と安全に通信するために Compute により使用される、管理者により定義さ"" ""れたトークン。"" msgid ""An alarm evaluator (``aodh-evaluator``)"" msgstr ""アラーム評価器 (``aodh-evaluator``)"" msgid ""An alarm notifier (``aodh-notifier``)"" msgstr ""アラーム通知器 (``aodh-notifier``)"" msgid """" ""An alpha-numeric string of text used to access OpenStack APIs and resources."" msgstr ""OpenStack API やリソースへのアクセスに使用される英数字文字列。"" msgid ""An alternative name for Networking API."" msgstr ""Networking API の別名。"" msgid """" ""An application protocol for accessing and maintaining distributed directory "" ""information services over an IP network."" msgstr """" ""IP ネットワーク上の分散ディレクトリー情報サービスへのアクセスと管理を行うため"" ""のアプリケーションプロトコル。"" msgid """" ""An application protocol for distributed, collaborative, hypermedia "" ""information systems. It is the foundation of data communication for the "" ""World Wide Web. Hypertext is structured text that uses logical links "" ""(hyperlinks) between nodes containing text. HTTP is the protocol to exchange "" ""or transfer hypertext."" msgstr """" ""分散、協調、ハイパーメディア情報システム用のアプリケーションプロトコル。WWW "" ""のデータ通信の基盤。ハイパーテキストは、ノード間でのテキストを含む論理リンク "" ""(ハイパーリンク) を使った構造化テキストのことである。HTTP は、ハイパーテキス"" ""トを交換したり転送したりするためのプロトコル。"" msgid """" ""An application that runs on the back-end server in a load-balancing system."" msgstr ""負荷分散システムでバックエンドサーバーで動作するアプリケーション。"" msgid """" ""An authentication and authorization service for Object Storage, implemented "" ""through WSGI middleware; uses Object Storage itself as the persistent "" ""backing store."" msgstr """" ""Object Storage の認証と認可のサービス。WSGI ミドルウェア経由で実装される。"" ""バックエンドの永続的なデータストアとして、Object Storage 自身を使用する。"" msgid """" ""An authentication facility within Object Storage that enables Object Storage "" ""itself to perform authentication and authorization. Frequently used in "" ""testing and development."" msgstr """" ""Object Storage 自身が認証と認可を実行できるようになる、Object Storage 内の認"" ""証機能。テストや開発によく使用される。"" msgid """" ""An easy method to create a local LDAP directory for testing Identity and "" ""Compute. Requires Redis."" msgstr """" ""Identity と Compute のテスト目的でローカルな LDAP ディレクトリーを作成するた"" ""めの簡易な方法。Redis が必要。"" msgid """" ""An element of the Compute RabbitMQ that comes to life when a RPC call is "" ""executed. It connects to a direct exchange through a unique exclusive queue, "" ""sends the message, and terminates."" msgstr """" ""RPC コールが実行されるとき、開始される Compute RabbitMQ の要素。一意な排他"" ""キュー経由で直接交換者に接続し、メッセージを送信し、終了します。"" msgid """" ""An element of the Compute capacity cache that is calculated based on the "" ""number of build, snapshot, migrate, and resize operations currently in "" ""progress on a given host."" msgstr """" ""指定されたホスト上で現在進行中の build, snapshot, migrate, resize の操作数を"" ""元に計算される、Compute のキャパシティキャッシュの１要素。"" msgid """" ""An encrypted communications protocol for secure communication over a "" ""computer network, with especially wide deployment on the Internet. "" ""Technically, it is not a protocol in and of itself; rather, it is the result "" ""of simply layering the Hypertext Transfer Protocol (HTTP) on top of the TLS "" ""or SSL protocol, thus adding the security capabilities of TLS or SSL to "" ""standard HTTP communications. most OpenStack API endpoints and many inter-"" ""component communications support HTTPS communication."" msgstr """" ""コンピューターネットワークで、とくにインターネットで広く使われている、安全に"" ""通信を行うための暗号化通信プロトコル。技術的には、プロトコルではなく、むしろ"" ""シンプルに SSL/TLS プロトコルの上に Hypertext Transfer Protocol (HTTP) を重ね"" ""ているものである。そのため、SSL や TLS プロトコルのセキュリティー機能を標準的"" ""な HTTP 通信に追加したものである。ほとんどの OpenStack API エンドポイントや多"" ""くのコンポーネント間通信で、 HTTPS 通信がサポートされている。"" msgid """" ""An entity in the context of the Shared File Systems that encapsulates "" ""interaction with the Networking service. If the driver you selected runs in "" ""the mode requiring such kind of interaction, you need to specify the share "" ""network to create a share."" msgstr """" ""Shared File System サービスにおいて、Networking サービスとのやり取りを抽象化"" ""するエンティティー。選択したドライバーが Networking サービスとのやり取りを必"" ""要とするモードで動作している場合、共有を作成する際にネットワーク共有 (share "" ""network) を指定する必要がある。"" msgid """" ""An entity that maps Object Storage data to partitions. A separate ring "" ""exists for each service, such as account, object, and container."" msgstr """" ""Object Storage データのパーティションへのマッピングを行う。アカウント、オブ"" ""ジェクト、コンテナーというサービス単位に別々のリングが存在する。"" msgid ""An extra but helpful piece of practical advice."" msgstr ""おまけですが、役に立つ実用的な助言です。"" msgid ""An iSCSI authentication method supported by Compute."" msgstr ""Compute によりサポートされる iSCSI の認証方式。"" msgid """" ""An in-progress specification for cloud management. Currently unsupported in "" ""OpenStack."" msgstr ""策定中のクラウド管理の仕様。現在、OpenStack では未サポート。"" msgid """" ""An integrated project that aims to orchestrate multiple cloud applications "" ""for OpenStack."" msgstr """" ""OpenStack に複数のクラウドアプリケーションをオーケストレーションする為に開発"" ""されたプロジェクト。"" msgid """" ""An integrated project that orchestrates multiple cloud applications for "" ""OpenStack. The project name of Orchestration is heat."" msgstr """" ""OpenStack 向けに複数のクラウドアプリケーションをオーケストレーションする統合"" ""プロジェクト。Orchestration のプロジェクト名は heat。"" msgid """" ""An integrated project that provide scalable and reliable Cloud Database-as-a-"" ""Service functionality for both relational and non-relational database "" ""engines. The project name of Database service is trove."" msgstr """" ""リレーショナルデータベースと非リレーショナルデータベースの両エンジンに対し"" ""て、スケール可能かつ信頼できるクラウド Database-as-a-Service を提供する統合プ"" ""ロジェクト。この Database service の名前は trove。"" msgid """" ""An integrated project that provides metering and measuring facilities for "" ""OpenStack. The project name of Telemetry is ceilometer."" msgstr """" ""OpenStack にメータリングと計測の機能を提供する、統合プロジェクト。Telemetry "" ""のプロジェクト名は ceilometer。"" msgid """" ""An interface that is plugged into a port in a Networking network. Typically "" ""a virtual network interface belonging to a VM."" msgstr """" ""Networking のネットワークにおけるポートに差し込まれるインターフェース。一般的"" ""に、仮想マシンに設定された仮想ネットワークインターフェース。"" msgid """" ""An object state in Object Storage where a new replica of the object is "" ""automatically created due to a drive failure."" msgstr """" ""ドライブ故障により、オブジェクトの新しい複製が自動的に作成された、Object "" ""Storage のオブジェクトの状態。"" msgid ""An object within Object Storage that is larger than 5 GB."" msgstr ""5 GB より大きい Object Storage 内のオブジェクト。"" msgid """" ""An official OpenStack project. Currently consists of Compute (nova), Object "" ""Storage (swift), Image service (glance), Identity (keystone), Dashboard "" ""(horizon), Networking (neutron), and Block Storage (cinder), Telemetry "" ""(ceilometer), Orchestration (heat), Database service (trove), Bare Metal "" ""service (ironic), Data processing service (sahara). However, this definition "" ""is changing based on community discussions about the \""Big Tent\""."" msgstr """" ""OpenStack の公式プロジェクト。現在、 Compute (nova), Object Storage (swift), "" ""Image service (glance), Identity (keystone), Dashboard (horizon), Networking "" ""(neutron), and Block Storage (cinder), Telemetry (ceilometer), Orchestration "" ""(heat), Database service (trove), Bare Metal service (ironic), Data "" ""processing service (sahara) がある。しかしながら、この定義は「Big Tent」に関"" ""するコミュニティーの議論に基づき変更されてきている。"" msgid ""An open source LDAP server. Supported by both Compute and Identity."" msgstr """" ""オープンソース LDAP サーバー。Compute と Identity によりサポートされる。"" msgid ""An open source SQL toolkit for Python, used in OpenStack."" msgstr """" ""OpenStack で使われている、オープンソースの Python 用 SQL ツールキット。"" msgid """" ""An open source community project by Dell that aims to provide all necessary "" ""services to quickly deploy clouds."" msgstr """" ""クラウドの迅速なデプロイ用に全ての必要なサービスを提供する用途の、Dell による"" ""オープンソースコミュニティプロジェクト。"" msgid """" ""An operating system configuration management tool supporting OpenStack "" ""deployments."" msgstr """" ""OpenStack の導入をサポートするオペレーティングシステムの設定管理ツール。"" msgid """" ""An operating system configuration-management tool supported by OpenStack."" msgstr ""OpenStackがサポートするオペレーティングシステム構成管理ツール。"" msgid ""An operating system instance running under the control of a hypervisor."" msgstr """" ""ハイパーバイザーの管理下で実行しているオペレーティングシステムのインスタン"" ""ス。"" msgid """" ""An operating system instance that runs on top of a hypervisor. Multiple VMs "" ""can run at the same time on the same physical host."" msgstr """" ""ハイパーバイザー上で動作するオペレーティングシステムインスタンス。一台の物理"" ""ホストで同時に複数の VM を実行できる。"" msgid """" ""An option within Compute that enables administrators to create and manage "" ""users through the ``nova-manage`` command as opposed to using the Identity "" ""service."" msgstr """" ""管理者が、Identity を使用する代わりに、 ``nova-manage`` コマンド経由でユー"" ""ザーを作成および管理できる、Compute 内のオプション。"" msgid """" ""An option within Image service so that an image is deleted after a "" ""predefined number of seconds instead of immediately."" msgstr """" ""イメージをすぐに削除する代わりに、事前定義した秒数経過後に削除するための、"" ""Image service 内のオプション。"" msgid ""Analytics-as-a-Service for ad-hoc or bursty analytic workloads."" msgstr """" ""その場限りやバースト的な分析ワークロードに対応できる Analytics-as-a-Service"" msgid """" ""Another option is to use the unofficial binary installer provided by "" ""Christoph Gohlke (http://www.lfd.uci.edu/~gohlke/pythonlibs/#pip)."" msgstr """" ""もう 1 つの選択肢は、Christoph Gohlke さんにより提供されている非公式バイナ"" ""リーインストーラー (http://www.lfd.uci.edu/~gohlke/pythonlibs/ #pip) を使用す"" ""ることです。"" msgid ""Anvil"" msgstr ""Anvil"" msgid """" ""Any business that provides Internet access to individuals or businesses."" msgstr ""個人や組織にインターネットアクセスを提供する何らかのビジネス。"" msgid """" ""Any client software that enables a computer or device to access the Internet."" msgstr """" ""コンピューターやデバイスがインターネットにアクセスできる、何らかのクライアン"" ""トソフトウェア。"" msgid ""Any compute node that runs the network worker daemon."" msgstr ""ネットワークワーカーデーモンを実行するコンピュートノードすべて。"" msgid """" ""Any deployment-specific information is helpful, such as whether you are "" ""using Ubuntu 14.04 or are performing a multi-node installation."" msgstr """" ""環境固有の情報が役に立ちます。例えば、Ubuntu 14.04 の利用有無、複数ノードのイ"" ""ンストール有無です。"" msgid """" ""Any kind of text that contains a link to some other site, commonly found in "" ""documents where clicking on a word or words opens up a different website."" msgstr """" ""どこか別のサイトへのリンクを含む、ある種のテキスト。一般的に、別の Web サイト"" ""を開く言葉をクリックするドキュメントに見られる。"" msgid ""Any node running a daemon or worker that provides an API endpoint."" msgstr """" ""API エンドポイントを提供するデーモンまたはワーカーを実行するあらゆるノード。"" msgid """" ""Any piece of hardware or software that wants to connect to the network "" ""services provided by Networking, the network connectivity service. An entity "" ""can make use of Networking by implementing a VIF."" msgstr """" ""Networking により提供されるネットワークサービス、ネットワーク接続性サービスに"" ""接続したい、ハードウェアやソフトウェアの部品。エンティティーは、仮想インター"" ""フェースを実装することにより Networking を使用できる。"" msgid """" ""Any user, including the ``root`` user, can run commands that are prefixed "" ""with the ``$`` prompt."" msgstr """" ""``$`` プロンプトから始まるコマンドは、 ``root`` ユーザーを含むすべてのユー"" ""ザーが実行できます。"" msgid ""Apache"" msgstr ""Apache"" msgid """" ""Apache Hadoop is an open source software framework that supports data-"" ""intensive distributed applications."" msgstr """" ""Apache Hadoop は、データインテンシブな分散アプリケーションをサポートする、"" ""オープンソースソフトウェアフレームワークである。"" msgid ""Apache License 2.0"" msgstr ""Apache License 2.0"" msgid ""Apache Web Server"" msgstr ""Apache Web Server"" msgid ""Application Programming Interface (API)"" msgstr ""Application Programming Interface (API)"" msgid ""Application Service Provider (ASP)"" msgstr ""Application Service Provider (ASP)"" msgid ""Application catalog"" msgstr ""アプリケーションカタログ"" msgid """" ""Arbitrary property to associate with image. This option can be used multiple "" ""times."" msgstr """" ""イメージと関連付ける任意のプロパティ。このオプションは複数回使用できます。"" msgid """" ""As a cloud end user, you can use the OpenStack dashboard to provision your "" ""own resources within the limits set by administrators. You can modify the "" ""examples provided in this section to create other types and sizes of server "" ""instances."" msgstr """" ""あなたはクラウドのエンドユーザーとして、OpenStack dashboard を使用できます。"" ""管理者により設定された制限の範囲内で自身のリソースを展開できます。他の種類や"" ""大きさのサーバーインスタンスを作成するために、このセクションで提供される例を"" ""変更できます。"" msgid """" ""As an administrator, you can migrate a volume with its data from one "" ""location to another in a manner that is transparent to users and workloads. "" ""You can migrate only detached volumes with no snapshots."" msgstr """" ""管理者は、ユーザーに意識させず、またワークロードの中断なしに、データを含めた"" ""状態でボリュームを別の場所に移動することができます。スナップショットを持たな"" ""い、切断されているボリュームだけが移動できます。"" msgid """" ""As shown in :ref:`get_started_conceptual_architecture`, OpenStack consists "" ""of several independent parts, named the OpenStack services. All services "" ""authenticate through a common Identity service. Individual services interact "" ""with each other through public APIs, except where privileged administrator "" ""commands are necessary."" msgstr """" "":ref:`get_started_conceptual_architecture` にあるように、 OpenStack は "" ""OpenStack サービスと呼ばれる複数の独立した部品で構成されています。すべての"" ""サービスは共通の Identity service を通して認証を行います。個々のサービスは、"" ""パブリック API を通じて互いに連携します。ただし、特権管理コマンドが必要な場合"" ""もいくつかあります。"" msgid """" ""As the volume donor, request a volume transfer authorization code for a "" ""specific volume:"" msgstr """" ""ボリュームの譲渡元として、特定のボリュームのボリューム転送認証コードを要求し"" ""ます。"" msgid """" ""As the volume recipient, you must first obtain the transfer ID and "" ""authorization key from the original owner."" msgstr """" ""ボリュームの受取側として、まず、元の所有者から転送 ID と認証キーを取得する必"" ""要があります。"" msgid """" ""Ask the cloud operator for the host name or public IP address from which you "" ""can access the dashboard, and for your user name and password."" msgstr """" ""ダッシュボードへのアクセスに使用するホスト名またはパブリック IP アドレス、"" ""ユーザー名、パスワードは、クラウド運用者に聞いてください。"" msgid """" ""Association of an interface ID to a logical port. Plugs an interface into a "" ""port."" msgstr """" ""論理ポートへのインターフェースIDの紐付け。インターフェースをポートに差し込"" ""む。"" msgid ""Asynchronous JavaScript and XML (AJAX)"" msgstr ""Asynchronous JavaScript and XML (AJAX)"" msgid ""Attach a volume to an instance"" msgstr ""ボリュームのインスタンスへの接続"" msgid """" ""Attach your volume to a server, specifying the server ID and the volume ID:"" msgstr """" "" ボリュームをサーバーに接続し、サーバー ID とボリューム ID を指定します。"" msgid """" ""Attachment point where a virtual interface connects to a virtual network."" msgstr ""仮想ネットワークへの仮想インタフェースの接続ポイント。"" msgid ""Austin"" msgstr ""Austin"" msgid ""AuthN"" msgstr ""AuthN"" msgid ""AuthZ"" msgstr ""AuthZ"" msgid """" ""Authentication and identity service by Microsoft, based on LDAP. Supported "" ""in OpenStack."" msgstr """" ""Microsoft が提供する認証サービス。LDAP に基づいている。OpenStack でサポートさ"" ""れる。"" msgid ""Authentication method that uses keys rather than passwords."" msgstr ""パスワードの代わりに鍵を使用する認証方式。"" msgid """" ""Authentication method that uses two or more credentials, such as a password "" ""and a private key. Currently not supported in Identity."" msgstr """" ""パスワードと秘密鍵など、2 つ以上のクレデンシャルを使用する認証方式。Identity "" ""では現在サポートされていない。"" msgid """" ""Authorizes tokens for users that console proxies provide. See ``nova-"" ""novncproxy`` and ``nova-xvpvncproxy``. This service must be running for "" ""console proxies to work. You can run proxies of either type against a single "" ""nova-consoleauth service in a cluster configuration. For information, see "" ""`About nova-consoleauth <http://docs.openstack.org/admin-guide-cloud/compute-"" ""remote-console-access.html#about-nova-consoleauth>`__."" msgstr """" ""コンソールプロキシーがユーザーに対して提供したトークンを認証します。 ``nova-"" ""novncproxy`` や ``nova-xvpvncproxy`` を参照してください。コンソールプロキシー"" ""が動作するためには、このサービスは必須です。 1 つのクラスターでは、1 つの "" ""``nova-consoleauth`` サービスで、どちらの種類のコンソールプロキシーも動作させ"" ""ることができます。詳細な情報は、 `About nova-consoleauth <http://docs."" ""openstack.org/admin-guide-cloud/compute-remote-console-access.html#about-"" ""nova-consoleauth>`__ を参照してください。"" msgid ""Auto ACK"" msgstr ""自動 ACK"" msgid """" ""Automated software test suite designed to run against the trunk of the "" ""OpenStack core project."" msgstr """" ""OpenStack コアプロジェクトの trunk ブランチに対してテストを実行するために設計"" ""された自動ソフトウェアテストスイート。"" msgid ""Available from anywhere"" msgstr ""どこからでも利用可能"" msgid ""Available instance types"" msgstr ""利用できるインスタンス種別"" msgid ""Available networks"" msgstr ""利用可能なネットワーク"" msgid ""BMC"" msgstr ""BMC"" msgid ""Bare metal service"" msgstr ""Bare metal service"" msgid """" ""Baseboard Management Controller. The intelligence in the IPMI architecture, "" ""which is a specialized micro-controller that is embedded on the motherboard "" ""of a computer and acts as a server. Manages the interface between system "" ""management software and platform hardware."" msgstr """" ""ベースボード・マネジメント・コントローラー。IPMI アーキテクチャーにおける管理"" ""機能。コンピューターのマザーボードに埋め込まれ、サーバーとして動作する、特別"" ""なマイクロコントローラーである。システム管理ソフトウェアとプラットフォーム"" ""ハードウェアの間の通信を管理する。"" msgid """" ""Be sure to include the software and package versions that you are using, "" ""especially if you are using a development branch, such as, ``\""Kilo release"" ""\"" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208``."" msgstr """" ""使用しているソフトウェアとパッケージのバージョンを明確にします。とくに開発ブ"" ""ランチを使用している場合は、``\""Kilo release\"" vs git commit "" ""bc79c3ecc55929bac585d04a03475b72e06a3208`` などを明確にします。"" msgid """" ""Before you can run client commands, you must create and source the ``PROJECT-"" ""openrc.sh`` file to set environment variables. See :doc:`../common/"" ""cli_set_environment_variables_using_openstack_rc`."" msgstr """" ""クライアントコマンドを実行する前に、環境変数を設定するために、``PROJECT-"" ""openrc.sh`` ファイルを作成して読み込む必要があります。詳細は :doc:`../common/"" ""cli_set_environment_variables_using_openstack_rc` を参照してください。"" msgid ""Bell-LaPadula model"" msgstr ""Bell-LaPadula モデル"" msgid """" ""Belongs to a particular domain and is used to specify information about the "" ""domain. There are several types of DNS records. Each record type contains "" ""particular information used to describe the purpose of that record. Examples "" ""include mail exchange (MX) records, which specify the mail server for a "" ""particular domain; and name server (NS) records, which specify the "" ""authoritative name servers for a domain."" msgstr """" ""特定のドメインに属し、ドメインに関する情報を指定するために使用される。いくつ"" ""かの種類の DNS レコードがある。各レコード種別は、そのレコードの目的を説明する"" ""ために使用される特定の情報を含む。例えば、mail exchange (MX) レコードは、特定"" ""のドメインのメールサーバーを指定する。name server (NS) レコードは、ドメインの"" ""権威ネームサーバーを指定する。"" msgid ""Benchmark service"" msgstr ""Benchmark サービス"" msgid ""Bexar"" msgstr ""Bexar"" msgid ""Block Storage"" msgstr ""Block Storage"" msgid ""Block Storage API"" msgstr ""Block Storage API"" msgid ""Block storage (cinder)"" msgstr ""Block storage (cinder)"" msgid """" ""Block storage that is simultaneously accessible by multiple clients, for "" ""example, NFS."" msgstr """" ""複数のクライアントにより同時にアクセス可能なブロックストレージ。例えば NFS。"" msgid ""Bootstrap Protocol (BOOTP)"" msgstr ""Bootstrap Protocol (BOOTP)"" msgid ""Border Gateway Protocol (BGP)"" msgstr ""Border Gateway Protocol (BGP)"" msgid """" ""Both Image service and Compute support encrypted virtual machine (VM) images "" ""(but not instances). In-transit data encryption is supported in OpenStack "" ""using technologies such as HTTPS, SSL, TLS, and SSH. Object Storage does not "" ""support object encryption at the application level but may support storage "" ""that uses disk encryption."" msgstr """" ""Image service と Compute は、どちらも仮想マシンイメージ (インスタンスではな"" ""い) の暗号化をサポートする。転送中のデータ暗号は、HTTPS、SSL、TLS、SSH などの"" ""技術を使用して、OpenStack においてサポートされる。Object Storage は、アプリ"" ""ケーションレベルでオブジェクト暗号化をサポートしませんが、ディスク暗号化を使"" ""用するストレージをサポートする可能性がある。"" msgid ""Both a VM container format and disk format. Supported by Image service."" msgstr """" ""仮想マシンのコンテナー形式とディスク形式の両方。Image service によりサポート"" ""される。"" msgid """" ""Bring down a physical storage device for maintenance without disrupting "" ""workloads."" msgstr """" "" ワークロードを中断せずにメンテナンスを行えるように物理ストレージデバイスを停"" ""止する 。"" msgid """" ""Builds and manages rings within Object Storage, assigns partitions to "" ""devices, and pushes the configuration to other storage nodes."" msgstr """" ""Object Storage のリングの作成、管理を行い、パーティションのデバイスへの割り当"" ""てを行い、他のストレージノードに設定を転送する。"" msgid """" ""By default the help URL points to http://docs.openstack.org. Change this by "" ""editing the following attribute to the URL of your choice in "" ""``local_settings.py``:"" msgstr """" ""ヘルプの URL は、デフォルトでは http://docs.openstack.org を参照しています。"" ""これを変更するには、 ``local_settings.py`` で以下の属性をお好みの URL に変更"" ""します。"" msgid ""CA"" msgstr ""CA"" msgid ""CADF"" msgstr ""CADF"" msgid ""CALL"" msgstr ""CALL"" msgid ""CAST"" msgstr ""CAST"" msgid ""CMDB"" msgstr ""CMDB"" msgid ""Cactus"" msgstr ""Cactus"" msgid """" ""Can concurrently use multiple layer-2 networking technologies, such as "" ""802.1Q and VXLAN, in Networking."" msgstr """" ""Networking において、802.1Q や VXLAN などの複数の L2 ネットワーク技術を同時に"" ""使用できる。"" msgid """" ""Causes the network interface to pass all traffic it receives to the host "" ""rather than passing only the frames addressed to it."" msgstr """" ""ネットワークインターフェースが、そこを指定されたフレームだけではなく、ホスト"" ""に届いたすべての通信を渡すようにする。"" msgid ""CentOS"" msgstr ""CentOS"" msgid ""Ceph"" msgstr ""Ceph"" msgid """" ""Ceph component that enables a Linux block device to be striped over multiple "" ""distributed data stores."" msgstr """" ""Linux ブロックデバイスが複数の分散データストアにわたり分割できるようにする、"" ""Ceph のコンポーネント。"" msgid ""CephFS"" msgstr ""CephFS"" msgid """" ""Certificate Authority or Certification Authority. In cryptography, an entity "" ""that issues digital certificates. The digital certificate certifies the "" ""ownership of a public key by the named subject of the certificate. This "" ""enables others (relying parties) to rely upon signatures or assertions made "" ""by the private key that corresponds to the certified public key. In this "" ""model of trust relationships, a CA is a trusted third party for both the "" ""subject (owner) of the certificate and the party relying upon the "" ""certificate. CAs are characteristic of many public key infrastructure (PKI) "" ""schemes."" msgstr """" ""認証局。暗号において、電子証明書を発行するエンティティー。電子証明書は、証明"" ""書の発行先の名前により公開鍵の所有者を証明する。これにより、他の信頼される機"" ""関が証明書を信頼できるようになる。また、証明された公開鍵に対応する秘密鍵によ"" ""る表明を信頼できるようになる。この信頼関係のモデルにおいて、CA は証明書の発行"" ""先と証明書を信頼している機関の両方に対する信頼された第三者機関である。CA は、"" ""多くの公開鍵基盤 (PKI) スキームの特徴である。"" msgid ""Challenge-Handshake Authentication Protocol (CHAP)"" msgstr ""Challenge-Handshake Authentication Protocol (CHAP)"" msgid """" ""Change the colors and image file names as appropriate, though the relative "" ""directory paths should be the same. The following example file shows you how "" ""to customize your CSS file:"" msgstr """" ""カラーとイメージファイルの名前を適切に変更します。ただし、相対ディレクトリー"" ""パスは同じにすべきです。以下のサンプルファイルに、CSS ファイルをどのようにカ"" ""スタマイズするかを示します。"" msgid ""Changes to these types of disk volumes are saved."" msgstr ""この種類のディスクボリュームに変更すると、データが保存される。"" msgid """" ""Checks for and deletes unused VMs; the component of Image service that "" ""implements delayed delete."" msgstr """" ""未使用の仮想マシンを確認し、削除する。遅延削除を実装する、Image service のコ"" ""ンポーネント。"" msgid """" ""Checks for missing replicas and incorrect or corrupted objects in a "" ""specified Object Storage account by running queries against the back-end "" ""SQLite database."" msgstr """" ""バックエンドの SQLite データベースに問い合わせることにより、指定された "" ""Object Storage のアカウントに、レプリカの欠損やオブジェクトの不整合・破損がな"" ""いかを確認する。"" msgid """" ""Checks for missing replicas or incorrect objects in specified Object Storage "" ""containers through queries to the SQLite back-end database."" msgstr """" ""SQLite バックエンドデータベースへの問い合わせにより、指定した Object Storage "" ""コンテナーにおいてレプリカの欠損やオブジェクトの不整合がないかを確認する。"" msgid ""Chef"" msgstr ""Chef"" msgid """" ""Choosing a host based on the existence of a GPU is currently unsupported in "" ""OpenStack."" msgstr ""GPU の有無によりホストを選択することは、現在 OpenStack で未サポート。"" msgid ""CirrOS"" msgstr ""CirrOS"" msgid ""Cisco neutron plug-in"" msgstr ""Cisco neutron プラグイン"" msgid """" ""Click the :guilabel:`Settings` button from the user drop down menu at the "" ""top right of any page, you will see the :guilabel:`Settings` tab."" msgstr """" ""ページの右上にあるユーザードロップダウンメニューの :guilabel:`設定` ボタンを"" ""クリックすると、 :guilabel:`設定` タブが表示されます。"" msgid ""Client"" msgstr ""クライアント"" msgid """" ""Cloud Auditing Data Federation (CADF) is a specification for audit event "" ""data. CADF is supported by OpenStack Identity."" msgstr """" ""Cloud Auditing Data Federation (CADF) は、監査イベントデータの仕様である。"" ""CADF は OpenStack Identity によりサポートされる。"" msgid ""Cloud Data Management Interface (CDMI)"" msgstr """" ""クラウドデータ管理インターフェース (CDMI:Cloud Data Management Interface)"" msgid ""Cloud Infrastructure Management Interface (CIMI)"" msgstr ""Cloud Infrastructure Management Interface (CIMI)"" msgid ""Cloudbase-Init"" msgstr ""Cloudbase-Init"" msgid ""Clustering"" msgstr ""Clustering"" msgid ""Clustering service"" msgstr ""Clustering service"" msgid ""Code name for the DNS service project for OpenStack."" msgstr ""OpenStack の DNS サービスプロジェクトのコード名。"" msgid """" ""Code name for the OpenStack project that provides the Containers Service."" msgstr ""コンテナーサービスを提供する OpenStack プロジェクトのコード名。"" msgid ""Code name of the key management service for OpenStack."" msgstr ""OpenStack の key management サービスのコード名。"" msgid """" ""Collection of Compute components that represent the global state of the "" ""cloud; talks to services, such as Identity authentication, Object Storage, "" ""and node/storage workers through a queue."" msgstr """" ""クラウドの全体状況を表す Compute コンポーネント群。キュー経由で、Identity の"" ""認証、Object Storage、ノード/ストレージワーカーなどのサービスと通信する。"" msgid """" ""Collective name for the Object Storage object services, container services, "" ""and account services."" msgstr """" ""Object Storage のオブジェクトサービス、コンテナーサービス、アカウントサービス"" ""の集合名。"" msgid """" ""Collective term for Object Storage components that provide additional "" ""functionality."" msgstr ""追加機能を提供する Object Storage のコンポーネントの総称。"" msgid """" ""Collective term for a group of Object Storage components that processes "" ""queued and failed updates for containers and objects."" msgstr """" ""キュー済みや失敗した、コンテナーやオブジェクトに対する更新を処理する、Object "" ""Storage のコンポーネントのグループの総称。"" msgid """" ""Collects event and metering data by monitoring notifications sent from "" ""services."" msgstr """" ""サービスから送信される通知を監視して、イベントと計測データを収集します。"" msgid """" ""Combination of a URI and UUID used to access Image service VM images through "" ""the image API."" msgstr """" ""Image API 経由で Image service の仮想マシンイメージにアクセスするために使用さ"" ""れる、URI や UUID の組み合わせ。"" msgid ""Command prompts"" msgstr ""コマンドプロンプト"" msgid ""Common Internet File System (CIFS)"" msgstr ""Common Internet File System (CIFS)"" msgid ""Common client"" msgstr ""共通クライアント"" msgid ""Common client for the OpenStack project."" msgstr ""OpenStack プロジェクトの共通クライアント。"" msgid """" ""Community project that captures Compute AMQP communications; useful for "" ""debugging."" msgstr """" ""Compute AMQP 通信をキャプチャーする、コミュニティーのプロジェクト。デバッグに"" ""有用。"" msgid """" ""Community project that uses shell scripts to quickly build complete "" ""OpenStack development environments."" msgstr """" ""シェルスクリプトを使用して、完全な OpenStack 導入環境を迅速に構築するためのコ"" ""ミュニティープロジェクト。"" msgid """" ""Community project used to run automated tests against the OpenStack API."" msgstr """" ""OpenStack API に対して自動テストを実行するために使用されるコミュニティープロ"" ""ジェクト。"" msgid ""Community support"" msgstr ""コミュニティーのサポート"" msgid """" ""Companies that rent specialized applications that help businesses and "" ""organizations provide additional services with lower cost."" msgstr """" ""企業や組織を支援する特定のアプリケーションを貸し出す会社が、より低いコストで"" ""追加サービスを提供する。"" msgid """" ""Component of Identity that provides a rule-management interface and a rule-"" ""based authorization engine."" msgstr """" ""ルール管理インターフェースやルールベースの認可エンジンを提供する Identity の"" ""コンポーネント。"" msgid ""Compute"" msgstr ""Compute"" msgid ""Compute API"" msgstr ""Compute API"" msgid ""Compute service"" msgstr ""Compute サービス"" msgid """" ""Computer that provides explicit services to the client software running on "" ""that system, often managing a variety of computer operations. A server is a "" ""VM instance in the Compute system. Flavor and image are requisite elements "" ""when creating a server."" msgstr """" ""そのシステムにおいて動作しているクライアントソフトウェアに具体的なサービスを"" ""提供するコンピューター。さまざまなコンピューター処理を管理することもある。"" ""サーバーは、Compute システム上の仮想マシンインスタンスです。フレーバーとイ"" ""メージは、サーバーの作成時に必須の要素です。"" msgid ""Conceptual architecture"" msgstr ""概念アーキテクチャー"" msgid """" ""Configurable option within Object Storage to limit database writes on a per-"" ""account and/or per-container basis."" msgstr """" ""アカウントごと、コンテナーごとにデータベースへの書き込みを制限するための、"" ""Object Storage 内の設定オプション。"" msgid ""Configuration Management Database."" msgstr ""構成管理データベース。"" msgid """" ""Configuration setting within RabbitMQ that enables or disables message "" ""acknowledgment. Enabled by default."" msgstr """" ""メッセージ ACK を有効化または無効化する、RabbitMQ 内の設定。デフォルトで有"" ""効。"" msgid ""Configures networks for guest servers."" msgstr ""ゲストサーバー用のネットワークの作成と管理。"" msgid """" ""Connected to by a direct consumer in RabbitMQ—Compute, the message can be "" ""consumed only by the current connection."" msgstr """" ""RabbitMQ—Compute において直接利用者により接続される。メッセージは、現在の接続"" ""だけにより使用される。"" msgid ""Container servers (swift-container-server)"" msgstr ""コンテナーサーバー (swift-container-server)"" msgid ""Containers service"" msgstr ""Containers サービス"" msgid """" ""Contains configuration information that Object Storage uses to reconfigure a "" ""ring or to re-create it from scratch after a serious failure."" msgstr """" ""リングを再設定するため、深刻な障害の後に最初から再作成するために、Object "" ""Storage が使用する設定情報を含む。"" msgid """" ""Contains information about a user as provided by the identity provider. It "" ""is an indication that a user has been authenticated."" msgstr """" ""認証プロバイダーにより提供されたとおり、ユーザーに関する情報を含む。ユーザー"" ""が認証済みであることを意味する。"" msgid """" ""Contains the locations of all Object Storage partitions within the ring."" msgstr ""リング内にあるすべての Object Storage のパーティションの場所を含む。"" msgid ""Contains the output from a Linux VM console in Compute."" msgstr ""Compute の Linux 仮想マシンコンソールからの出力を含む。"" msgid ""Contractual obligations that ensure the availability of a service."" msgstr ""サービスの可用性を保証する契約上の義務。"" msgid ""Conventions"" msgstr ""表記規則"" msgid """" ""Converts an existing server to a different flavor, which scales the server "" ""up or down. The original server is saved to enable rollback if a problem "" ""occurs. All resizes must be tested and explicitly confirmed, at which time "" ""the original server is removed."" msgstr """" ""既存のサーバーを別のフレーバーに変更する。サーバーをスケールアップまたはス"" ""ケールダウンする。元のサーバーは、問題発生時にロールバックできるよう保存され"" ""る。すべてのリサイズは、元のサーバーを削除するときに、テストされ、明示的に確"" ""認される必要がある。"" msgid """" ""Copy the ``PROJECT-openrc.sh`` file to the computer from which you want to "" ""run OpenStack commands."" msgstr """" ""OpenStack コマンドを実行したいコンピューターに ``PROJECT-openrc.sh`` ファイル"" ""をコピーします。"" msgid """" ""Create a CSS style sheet in ``/usr/share/openstack-dashboard/"" ""openstack_dashboard/static/dashboard/scss/``."" msgstr """" ""CSS スタイルシートを ``/usr/share/openstack-dashboard/openstack_dashboard/"" ""static/dashboard/scss/`` に作成します。"" msgid """" ""Create a Database service instance using the :command:`trove create` command."" msgstr """" "":command:`trove create` コマンドを使用して、Database サービスのインスタンスを"" ""作成します。"" msgid """" ""Create a custom bootable volume or a volume with a large data set and "" ""transfer it to a customer."" msgstr """" ""大容量のデータセットが含まれるボリュームやカスタムのブータブルボリュームを作"" ""成して顧客に転送する。"" msgid ""Create a volume"" msgstr ""ボリュームの作成"" msgid ""Create a volume transfer request"" msgstr ""ボリューム譲渡要求の作成"" msgid """" ""Create a volume with 8 gibibytes (GiB) of space, and specify the "" ""availability zone and image:"" msgstr """" "" 容量 8 GiB のボリュームを作成し、アベイラビリティゾーンとイメージを指定しま"" ""す。 "" msgid """" ""Create an image for each type of database. For example, one for MySQL and "" ""one for MongoDB."" msgstr """" ""各種データベース用のイメージを作成します。例えば、MySQL 用のもの、MongoDB 用"" ""のものです。"" msgid ""Create and source the OpenStack RC file"" msgstr ""OpenStack RC ファイルの作成と読み込み"" msgid ""Create or update an image (glance)"" msgstr ""イメージ (glance) の作成・更新"" msgid """" ""Create two PNG logo files with transparent backgrounds using the following "" ""sizes:"" msgstr ""以下の 2 つの大きさの透過 PNG ロゴファイルを作成します。"" msgid """" ""Creates a full Object Storage development environment within a single VM."" msgstr ""単一の仮想マシンに一通りの Object Storage 開発環境を作成すること。"" msgid ""Creates and collects measurements across OpenStack."" msgstr ""OpenStack 全体の計測項目を作成、収集します。"" msgid ""Creates and manages Hadoop clusters on OpenStack."" msgstr ""OpenStack 上への Hadoop クラスターの作成と管理。"" msgid ""Creates and manages applications."" msgstr ""アプリケーションの作成と管理。"" msgid ""Creates and manages clustering services."" msgstr ""クラスタリングサービスの作成と管理。"" msgid ""Creates and manages containers."" msgstr ""コンテナーの作成と管理。"" msgid ""Creates and manages databases."" msgstr ""データベースの作成と管理。"" msgid ""Creates and manages images, instances, and flavors."" msgstr ""イメージ、インスタンス、フレーバーの作成と管理。"" msgid ""Creates and manages images."" msgstr ""イメージの作成と管理。"" msgid ""Creates and manages keys."" msgstr ""鍵の作成と管理。"" msgid ""Creates and manages shared file systems."" msgstr ""共有ファイルシステムを作成および管理します。"" msgid ""Creates and manages users, tenants, roles, endpoints, and credentials."" msgstr ""ユーザー、テナント、ロール、エンドポイント、認証情報の作成と管理。"" msgid ""Creates and manages volumes."" msgstr ""ボリュームの作成と管理。"" msgid ""Critical information about the risk of data loss or security issues."" msgstr ""データ損失やセキュリティー問題のリスクに関する致命的な情報です。"" msgid ""Cross-Origin Resource Sharing (CORS)"" msgstr ""Cross-Origin Resource Sharing (CORS)"" msgid ""Crowbar"" msgstr ""Crowbar"" msgid """" ""Currently the libvirt virtualization tool determines the disk, CD-ROM, and "" ""VIF device models based on the configured hypervisor type (``libvirt_type`` "" ""in ``/etc/nova/nova.conf`` file). For the sake of optimal performance, "" ""libvirt defaults to using virtio for both disk and VIF (NIC) models. The "" ""disadvantage of this approach is that it is not possible to run operating "" ""systems that lack virtio drivers, for example, BSD, Solaris, and older "" ""versions of Linux and Windows."" msgstr """" ""現在、libvirt 仮想化ツールは、設定したハイパーバイザーの種別 (``/etc/nova/"" ""nova.conf`` ファイルの ``libvirt_type`` で指定)を基にディスク、CD_ROM、VIF デ"" ""バイスモデルを決定します。最適なパフォーマンスを実現するため、libvirt はディ"" ""スクおよび VIF (NIC) モデルのいずれの場合も virtio を使用するように初期設定さ"" ""れています。この手法の欠点は、virtio ドライバーがないオペレーティングシステ"" ""ム (例、BSD、Solaris、Linux および Windows の以前のバージョン) を実行できない"" ""点です。"" msgid ""Currently, the clients do not support Python 3."" msgstr ""現在、クライアントは Python 3 をサポートしません。"" msgid ""Custom modules that extend some OpenStack core APIs."" msgstr ""いくつかの OpenStack コア API を拡張するカスタムモジュール。"" msgid ""Customize the dashboard"" msgstr ""ダッシュボードのカスタマイズ"" msgid ""DAC"" msgstr ""DAC"" msgid ""DHCP"" msgstr ""DHCP"" msgid ""DHCP agent"" msgstr ""DHCP エージェント"" msgid ""DNS"" msgstr ""DNS"" msgid ""DNS record"" msgstr ""DNS レコード"" msgid ""DNS service"" msgstr ""DNS サービス"" msgid ""DRTM"" msgstr ""DRTM"" msgid """" ""Daemon that provides DNS, DHCP, BOOTP, and TFTP services for virtual "" ""networks."" msgstr """" ""仮想ネットワーク向けに DNS、DHCP、BOOTP、TFTP サービスを提供するデーモン。"" msgid ""Data processing"" msgstr ""Data processing"" msgid ""Data processing service"" msgstr ""Data processing サービス"" msgid """" ""Data that is only known to or accessible by a user and used to verify that "" ""the user is who he says he is. Credentials are presented to the server "" ""during authentication. Examples include a password, secret key, digital "" ""certificate, and fingerprint."" msgstr """" ""ユーザーのみが知っている、またはアクセスできるデータ。ユーザーが正当であるこ"" ""とを検証するために使用される。クレデンシャルは、認証中にサーバーに提示され"" ""る。例えば、パスワード、秘密鍵、電子証明書、フィンガープリントなどがある。"" msgid ""Database"" msgstr ""データベース"" msgid ""Database service"" msgstr ""Database サービス"" msgid ""Debian"" msgstr ""Debian"" msgid """" ""Defines resources for a cell, including CPU, storage, and networking. Can "" ""apply to the specific services within a cell or a whole cell."" msgstr """" ""CPU、ストレージ、ネットワークを含むセルのリソースを定義する。１セルやセル全体"" ""に含まれる特定のサービスに適用可能。"" msgid """" ""Defining environment variables using an environment file is not a common "" ""practice on Microsoft Windows. Environment variables are usually defined in "" ""the :menuselection:`Advanced > System Properties` dialog box."" msgstr """" ""環境変数ファイルを用いて環境変数を定義することは、Microsoft Windows で一般的"" ""な手法ではありません。環境変数は通常、 :menuselection:`システム > 詳細設定` "" ""で定義されます。"" msgid ""Delete a volume"" msgstr ""ボリュームの削除"" msgid ""Delete a volume transfer"" msgstr ""ボリューム譲渡の削除"" msgid ""Delete the volume using either the volume name or ID:"" msgstr ""ボリューム名または ID を使用してボリュームを削除します。"" msgid ""Delete the volume:"" msgstr ""ボリュームを削除します。"" msgid """" ""Deletes all image properties that are not explicitly set in the update "" ""request. Otherwise, those properties not referenced are preserved."" msgstr """" ""更新要求に明示的に設定されていないイメージのプロパティをすべて削除します。そ"" ""うでない場合は、参照されていないプロパティは保存されます。"" msgid """" ""Denial of service (DoS) is a short form for denial-of-service attack. This "" ""is a malicious attempt to prevent legitimate users from using a service."" msgstr """" ""DoS は、サービス妨害攻撃の省略形である。正当なユーザーがサービスを使用するこ"" ""とを妨害するための悪意のある試み。"" msgid """" ""Depending on context, the core API is either the OpenStack API or the main "" ""API of a specific core project, such as Compute, Networking, Image service, "" ""and so on."" msgstr """" ""コア API は、文脈に応じて OpenStack API または特定のコアプロジェクトのメイン "" ""API を意味する。コアプロジェクトは、Compute、Networking、Image service などが"" ""ある。"" msgid ""Deployment service"" msgstr ""デプロイサービス"" msgid """" ""Describes the parameters of the various virtual machine images that are "" ""available to users; includes parameters such as CPU, storage, and memory. "" ""Alternative term for flavor."" msgstr """" ""ユーザが利用可能な様々な仮想マシンイメージのパラメーター（CPU、ストレージ、メ"" ""モリ等を含む）を示す。フレーバーの別名。"" msgid ""Description"" msgstr ""説明"" msgid ""Designate"" msgstr ""Designate"" msgid ""Designed as an OpenStack component."" msgstr ""OpenStack のコンポーネントとして設計されています。"" msgid ""Desktop-as-a-Service"" msgstr ""Desktop-as-a-Service"" msgid """" ""Determines whether back-end members of a VIP pool can process a request. A "" ""pool can have several health monitors associated with it. When a pool has "" ""several monitors associated with it, all monitors check each member of the "" ""pool. All monitors must declare a member to be healthy for it to stay active."" msgstr """" ""仮想 IP プールのバックエンドメンバーがリクエストを処理できるかどうかを判断す"" ""る。プールは、それに関連づけられた複数のヘルスモニターを持てる。すべてのモニ"" ""ターは、プールのメンバーをお互いに確認する。すべてのモニターは、その稼働状況"" ""の健全性であることをメンバーに宣言する必要がある。"" msgid ""DevStack"" msgstr ""DevStack"" msgid """" ""Device plugged into a PCI slot, such as a fibre channel or network card."" msgstr """" ""ファイバーチャネルやネットワークカードなどの PCI スロット内に挿入されるデバイ"" ""ス。"" msgid ""Diablo"" msgstr ""Diablo"" msgid """" ""Disables server-side message acknowledgment in the Compute RabbitMQ. "" ""Increases performance but decreases reliability."" msgstr """" ""Compute RabbitMQ において、サーバーサイドメッセージ交換を無効化する。性能を向"" ""上されるが、信頼性を低下させる。"" msgid ""Discover the version number for a client"" msgstr ""クライアントのバージョン番号の確認"" msgid """" ""Discretionary access control. Governs the ability of subjects to access "" ""objects, while enabling users to make policy decisions and assign security "" ""attributes. The traditional UNIX system of users, groups, and read-write-"" ""execute permissions is an example of DAC."" msgstr """" ""任意アクセス制御。サブジェクトがオブジェクトにアクセスする機能を統制する。"" ""ユーザーがポリシーを決定し、セキュリティー属性を割り当てられる。伝統的な "" ""UNIX システムのユーザー、グループ、読み書き権限が、DAC の例である。"" msgid """" ""Disk-based data storage generally represented as an iSCSI target with a file "" ""system that supports extended attributes; can be persistent or ephemeral."" msgstr """" ""ディスクを用いたデータストレージ。一般的に、拡張属性をサポートするファイルシ"" ""ステムを持つ、iSCSI ターゲットとして利用される。永続的なものと一時的なものが"" ""ある。"" msgid """" ""Disk-based virtual memory used by operating systems to provide more memory "" ""than is actually available on the system."" msgstr """" ""システムにおいて実際に利用可能なメモリーより多くのメモリーをオペレーティング"" ""システムにより使用されるディスクベースの仮想メモリー。"" msgid ""Distributed block storage system for QEMU, supported by OpenStack."" msgstr """" ""OpenStack によりサポートされる、QEMU 用の分散ブロックストレージシステム。"" msgid """" ""Distributes partitions proportionately across Object Storage devices based "" ""on the storage capacity of each device."" msgstr """" ""各デバイスのストレージキャパシティに基づき、Object Storage デバイスをまたがり"" ""パーティションを比例分配する。"" msgid ""Django"" msgstr ""Django"" msgid ""Documentation"" msgstr ""ドキュメント"" msgid ""Documentation feedback"" msgstr ""ドキュメントへのフィードバック"" msgid ""Domain Name System (DNS)"" msgstr ""Domain Name System (DNS)"" msgid """" ""Domain Name System. A hierarchical and distributed naming system for "" ""computers, services, and resources connected to the Internet or a private "" ""network. Associates a human-friendly names to IP addresses."" msgstr """" ""ドメインネームシステム。インターネットやプライベートネットワークに接続される"" ""コンピューター、サービス、リソースの名前を管理する階層化分散システム。人間が"" ""理解しやすい名前を IP アドレスに関連付ける。"" msgid ""Download and source the OpenStack RC file"" msgstr ""OpenStack RC ファイルのダウンロードと読み込み"" msgid ""Drivers"" msgstr ""ドライバー"" msgid """" ""Drivers or a service back end are integrated to the centralized server. They "" ""are used for accessing identity information in repositories external to "" ""OpenStack, and may already exist in the infrastructure where OpenStack is "" ""deployed (for example, SQL databases or LDAP servers)."" msgstr """" ""ドライバーやサービスバックエンドは、中央サーバーと統合されています。ドライ"" ""バーは、OpenStack の外部にあるリポジトリーにある認証情報にアクセスするために"" ""使用されます。こうしたリポジトリーは、OpenStack が導入されるインフラストラク"" ""チャーにすでに存在する場合もあります (例えば、SQL データベースやLDAP サー"" ""バー)。"" msgid """" ""During the set up or testing of OpenStack, you might have questions about "" ""how a specific task is completed or be in a situation where a feature does "" ""not work correctly. Use the `ask.openstack.org <https://ask.openstack."" ""org>`__ site to ask questions and get answers. When you visit the https://"" ""ask.openstack.org site, scan the recently asked questions to see whether "" ""your question has already been answered. If not, ask a new question. Be sure "" ""to give a clear, concise summary in the title and provide as much detail as "" ""possible in the description. Paste in your command output or stack traces, "" ""links to screen shots, and any other information which might be useful."" msgstr """" ""OpenStack の構築中やテスト中に、ある作業を行うのにどうすればよいか質問した"" ""り、ある機能が正しく動作しない状況になったりするかもしれません。 `ask."" ""openstack.org <https://ask.openstack.org>`__ サイトを使用して、質問して回答を"" ""得られます。 https://ask.openstack.org にアクセスしたら、最近の質問を検索し"" ""て、あなたと同じ質問がすでに回答されているかを確認します。まだの場合、新しく"" ""質問します。見出しの概要は明確かつ正確にしてください。そして、説明はできる限"" ""り詳細にしてください。コマンドの出力、スタックトレース、スクリーンショットへ"" ""のリンク、その他有用な情報を貼り付けます。"" msgid ""Dynamic Host Configuration Protocol (DHCP)"" msgstr ""動的ホスト設定プロトコル（DHCP）"" msgid """" ""Dynamic Host Configuration Protocol. A network protocol that configures "" ""devices that are connected to a network so that they can communicate on that "" ""network by using the Internet Protocol (IP). The protocol is implemented in "" ""a client-server model where DHCP clients request configuration data, such as "" ""an IP address, a default route, and one or more DNS server addresses from a "" ""DHCP server."" msgstr """" ""Dynamic Host Configuration Protocol。ネットワークに接続されたデバイスが、その"" ""ネットワーク上で IP を使用して通信できるよう、ネットワークデバイスを設定する"" ""ネットワークプロトコル。このプロトコルは、クライアントサイドモデルで実装され"" ""ている。DHCP クライアントは、IP アドレス、デフォルトルート、1 つ以上の DNS "" ""サーバーアドレス設定データを要求する。"" msgid ""Dynamic HyperText Markup Language (DHTML)"" msgstr ""Dynamic HyperText Markup Language (DHTML)"" msgid ""Dynamic root of trust measurement."" msgstr ""Dynamic root of trust measurement."" msgid ""EBS boot volume"" msgstr ""EBS ブートボリューム"" msgid ""EC2"" msgstr ""EC2"" msgid ""EC2 API"" msgstr ""EC2 API"" msgid ""EC2 Compatibility API"" msgstr ""EC2 互換API"" msgid ""EC2 access key"" msgstr ""EC2 アクセスキー"" msgid ""EC2 secret key"" msgstr ""EC2 シークレットキー"" msgid ""ESXi"" msgstr ""ESXi"" msgid ""ETag"" msgstr ""ETag"" msgid """" ""Each OpenStack project provides a command-line client, which enables you to "" ""access the project API through easy-to-use commands. For example, the "" ""Compute service provides a ``nova`` command-line client."" msgstr """" ""各 OpenStack プロジェクトは、使いやすいコマンドからプロジェクトの API にアク"" ""セスできる、コマンドラインクライアントを提供しています。例えば、Compute は "" ""``nova`` コマンドラインクライアントを提供しています。"" msgid """" ""Each OpenStack release has a code name. Code names ascend in alphabetical "" ""order: Austin, Bexar, Cactus, Diablo, Essex, Folsom, Grizzly, Havana, "" ""Icehouse, Juno, Kilo, Liberty, and Mitaka. Code names are cities or counties "" ""near where the corresponding OpenStack design summit took place. An "" ""exception, called the Waldon exception, is granted to elements of the state "" ""flag that sound especially cool. Code names are chosen by popular vote."" msgstr """" ""各 OpenStack リリースはコード名を持つ。コード名はアルファベット順になります。"" ""Austin, Bexar, Cactus, Diablo, Essex, Folsom, Grizzly, Havana, Icehouse, "" ""Juno, Kilo、Liberty、Mitaka。コード名は、対応する OpenStack デザインサミット"" ""が開催された場所の近くにある都市または国である。Waldon 例外と言われる例外は、"" ""非常に格好良く聞こえる、状態フラグの要素に保証される。コード名は、一般的な投"" ""票により選択される。"" msgid ""Easily scalable for future growth"" msgstr ""将来のサイズ増加に応じて容易に拡張可能"" msgid ""Efficiently polls metering data related to OpenStack services."" msgstr ""OpenStack サービスに関連する計測データを効率的に取得します。"" msgid """" ""Either a soft or hard reboot of a server. With a soft reboot, the operating "" ""system is signaled to restart, which enables a graceful shutdown of all "" ""processes. A hard reboot is the equivalent of power cycling the server. The "" ""virtualization platform should ensure that the reboot action has completed "" ""successfully, even in cases in which the underlying domain/VM is paused or "" ""halted/stopped."" msgstr """" ""サーバーのソフトリブートまたはハードリブート。ソフトリブートの場合、オペレー"" ""ティングに再起動のシグナルが送信されます。これにより、すべてのプロセスを穏や"" ""かにシャットダウンできます。ハードリブートは、サーバーの強制再起動と同じで"" ""す。仮想化プラットフォームは、ベースの仮想マシンが一時停止中の場合や停止中の"" ""場合でも、きちんとリブート動作を正常に完了させるべきです。"" msgid ""Elastic Block Storage (EBS)"" msgstr ""Elastic Block Storage (EBS)"" msgid ""Element of RabbitMQ that provides a response to an incoming MQ message."" msgstr ""送信されてきた MQ メッセージに応答する RabbitMQ の要素。"" msgid """" ""Enables Compute and Networking integration, which enables Networking to "" ""perform network management for guest VMs."" msgstr """" ""Compute と Networking の統合を可能にする。Networking がゲスト仮想マシン用の"" ""ネットワークを管理できるようになる。"" msgid """" ""Enables Compute to communicate with NetApp storage devices through the "" ""NetApp OnCommand Provisioning Manager."" msgstr """" ""Compute が NetApp OnCommand Provisioning Manager 経由で NetApp ストレージデバ"" ""イスと通信できるようにする。"" msgid """" ""Enables Network-Connectivity-as-a-Service for other OpenStack services, such "" ""as OpenStack Compute. Provides an API for users to define networks and the "" ""attachments into them. Has a pluggable architecture that supports many "" ""popular networking vendors and technologies."" msgstr """" ""OpenStack Compute のような他の OpenStack サービスに対して、Network-"" ""Connectivity-as-a-Service をできるようにします。ユーザーがネットワークやそれ"" ""らへの接続を定義するための API を提供します。プラグイン可能なアーキテクチャー"" ""で、数多くの人気のあるネットワークベンダーや技術に対応しています。"" msgid """" ""Enables Networking to distribute incoming requests evenly between designated "" ""instances."" msgstr """" ""Networking により、受信リクエストを指定されたインスタンス間で均等に分散できる"" ""ようになる。"" msgid """" ""Enables a Linux bridge to understand a Networking port, interface "" ""attachment, and other abstractions."" msgstr """" ""Linux ブリッジが、Networking のポート、インターフェース接続、他の抽象化を理解"" ""できるようにする。"" msgid ""Enables users to submit commands as a tenant administrator or end user."" msgstr """" ""ユーザーが、テナント管理者もしくはエンドユーザーとしてコマンドを発行するのに"" ""使用します。"" msgid """" ""Enables users to submit commands to the REST API through a command-line "" ""client authorized as either a admin user, reseller user, or swift user."" msgstr """" ""ユーザーがコマンドラインクライアントを使って REST API にコマンドを発行するの"" ""に使用します。管理者ユーザー、 reseller ユーザー、 swift ユーザーのいずれの"" ""ユーザーでも使用できます。"" msgid ""Encryption is available"" msgstr ""暗号化が利用可能"" msgid ""Encryption is not available yet"" msgstr ""暗号化はまだ利用不可"" msgid """" ""Ensure that the ``C:\\Python27\\Scripts`` directory is defined in the "" ""``PATH`` environment variable, and use the ``easy_install`` command from the "" ""setuptools package:"" msgstr """" ""``C:\\Python27\\Scripts`` ディレクトリーが ``PATH`` 環境変数に定義されている"" ""ことを確認します。setuptools パッケージの ``easy_install`` コマンドを使用しま"" ""す。"" msgid """" ""Ensure that the version of qemu you are using is version 0.14 or later. "" ""Earlier versions of qemu result in an ``unknown option -s`` error message in "" ""the ``nova-compute.log`` file."" msgstr """" ""お使いの qemu バージョンが 0.14 以降であることを確認してください。qemu のバー"" ""ジョンがそれ以前の場合、``nova-compute.log`` ファイルで ``unknown option -"" ""s`` のエラーメッセージが表示されます。 "" msgid ""Essex"" msgstr ""Essex"" msgid ""Eucalyptus Kernel Image (EKI)"" msgstr ""Eucalyptus Kernel Image (EKI)"" msgid ""Eucalyptus Machine Image (EMI)"" msgstr ""Eucalyptus Machine Image (EMI)"" msgid ""Eucalyptus Ramdisk Image (ERI)"" msgstr ""Eucalyptus Ramdisk Image (ERI)"" msgid """" ""Examine the ``/var/log/nova-api.log`` and ``/var/log/nova-compute.log`` log "" ""files for error messages."" msgstr """" ""``/var/log/nova-api.log`` と ``/var/log/nova-compute.log`` のログファイルでエ"" ""ラーメッセージを確認してください。 "" msgid ""Example: 1 TB \""extra hard drive\"""" msgstr ""例: 1 TB \""追加ハードディスク\"""" msgid ""Example: 1 TB of file share"" msgstr ""例: 1 TB のファイル共有"" msgid ""Example: 10 GB first disk, 30 GB/core second disk"" msgstr ""例: 1 番目の 10 GB ディスク、2 番目のコアあたり 30 GB ディスク"" msgid ""Example: 10s of TBs of data set storage"" msgstr ""例: 数十TBのデータセットストレージ"" msgid """" ""Extension to iptables that allows creation of firewall rules that match "" ""entire \""sets\"" of IP addresses simultaneously. These sets reside in indexed "" ""data structures to increase efficiency, particularly on systems with a large "" ""quantity of rules."" msgstr """" ""連続する IP アドレスの全体に一致するファイアウォールルールを作成できる、"" ""iptables の拡張。これらのセットは、効率化するためにインデックス化されたデータ"" ""構造、とくに大量のルールを持つシステムにあります。"" msgid ""FWaaS"" msgstr ""FWaaS"" msgid """" ""Facility in Compute that allows each virtual machine instance to have more "" ""than one VIF connected to it."" msgstr """" ""各仮想マシンインスタンスが複数の仮想インターフェースに接続できるようになる、"" ""Compute における機能。"" msgid """" ""Facility in Compute that enables a virtual machine instance to have more "" ""than one VIF connected to it."" msgstr """" ""各仮想マシンインスタンスが複数の仮想インターフェースに接続できるようになる、"" ""Compute における機能。"" msgid ""FakeLDAP"" msgstr ""FakeLDAP"" msgid """" ""Fast provisioning of Hadoop clusters on OpenStack for development and QA."" msgstr ""開発や QA 目的での Hadoop クラスターの OpenStack 上への迅速な構築"" msgid """" ""Feature in modern Ethernet networks that supports frames up to approximately "" ""9000 bytes."" msgstr ""約 9000 バイトまでのフレームをサポートする最近のイーサネット上の機能。"" msgid """" ""Feature of certain network interface drivers that combines many smaller "" ""received packets into a large packet before delivery to the kernel IP stack."" msgstr """" ""カーネルの IP スタックに届ける前に、多くの小さな受信パケットを大きなパケット"" ""に結合する、特定のネットワークインターフェースドライバーの機能。"" msgid ""Fedora"" msgstr ""Fedora"" msgid ""Feedback"" msgstr ""フィードバック"" msgid ""Fibre Channel"" msgstr ""ファイバーチャネル"" msgid ""Fibre Channel over Ethernet (FCoE)"" msgstr ""Fibre Channel over Ethernet (FCoE)"" msgid ""File Storage (manila)"" msgstr ""File Storage (manila)"" msgid """" ""File system option that enables storage of additional information beyond "" ""owner, group, permissions, modification time, and so on. The underlying "" ""Object Storage file system must support extended attributes."" msgstr """" ""所有者、グループ、パーミッション、変更時間など以外の追加情報を保存できるよう"" ""にする、ファイルシステムのオプション。Object Storage のバックエンドのファイル"" ""システムは、拡張属性をサポートする必要がある。"" msgid """" ""Filtering tool for a Linux bridging firewall, enabling filtering of network "" ""traffic passing through a Linux bridge. Used in Compute along with "" ""arptables, iptables, and ip6tables to ensure isolation of network "" ""communications."" msgstr """" ""Linux ブリッジのファイアウォール用のフィルタリングツール。Linux ブリッジを通"" ""過するネットワーク通信のフィルタリングできる。ネットワーク通信を分離するため"" ""に、OpenStack Compute において arptables、iptables、ip6tables と一緒に使用さ"" ""れる。"" msgid ""Find the matching transfer ID:"" msgstr ""合致する転送 ID を探します。"" msgid ""First, add the Open Build Service repository:"" msgstr ""まず、Open Build Service のリポジトリーを追加します。"" msgid ""Flat Manager"" msgstr ""Flat マネージャー"" msgid ""FlatDHCP Manager"" msgstr ""FlatDHCP マネージャー"" msgid ""Folsom"" msgstr ""Folsom"" msgid """" ""For IaaS, ability for a regular (non-privileged) account to manage a virtual "" ""infrastructure component such as networks without involving an administrator."" msgstr """" ""IaaS の場合、管理者が介することなく、通常の (特権を持たない) ユーザーがネット"" ""ワークなどの仮想インフラのコンポーネントを管理する機能。"" msgid ""For Mac OS X or Linux:"" msgstr ""Mac OS X または Linux の場合:"" msgid ""For Microsoft Windows:"" msgstr ""Microsoft Windows の場合:"" msgid """" ""For SUSE Linux Enterprise Server, use ``zypper`` to install the clients from "" ""the distribution packages in the Open Build Service. First, add the Open "" ""Build Service repository:"" msgstr """" ""SUSE Linux Enterprise Server の場合、``zypper`` を使用して、Open Build "" ""Service にあるディストリビューションのパッケージサービスからクライアントをイ"" ""ンストールします。まず、Open Build Service のリポジトリーを追加します。"" msgid """" ""For Ubuntu or Debian, use ``apt-get`` to install the clients from the "" ""packaged versions:"" msgstr """" ""Ubuntu と Debian の場合、``apt-get`` を使用してパッケージバージョンからクライ"" ""アントをインストールします。"" msgid """" ""For bulk import of data to the cloud, the data ingress system creates a new "" ""Block Storage volume, copies data from the physical device, and transfers "" ""device ownership to the end user."" msgstr """" ""データをまとめてクラウドにインポートために、データ受信システムが新たにブロッ"" ""クストレージボリュームを作成し、物理デバイスからデータをコピーしてから、デバ"" ""イスの所有権をエンドユーザーに転送する。"" msgid """" ""For communication between the processes of one service, an AMQP message "" ""broker is used. The service's state is stored in a database. When deploying "" ""and configuring your OpenStack cloud, you can choose among several message "" ""broker and database solutions, such as RabbitMQ, Qpid, MySQL, MariaDB, and "" ""SQLite."" msgstr """" ""あるサービス内のプロセス間の通信には、 AMQP メッセージブローカーが使用されま"" ""す。サービスの状態はデータベースに保存されます。 OpenStack クラウドをデプロイ"" ""する際には、メッセージブローカーとデータベースを RabbitMQ、 Qpid、 MySQL、 "" ""MariaDB、 SQLite などのいくつかの選択肢から選択できます。"" msgid """" ""For details about image creation, see the `Virtual Machine Image Guide "" ""<http://docs.openstack.org/image-guide/>`__."" msgstr """" ""イメージ作成の詳細は `仮想マシンイメージガイド <http://docs.openstack.org/ja/"" ""image-guide/>`__ を参照してください。"" msgid """" ""For example, copy the file to the computer from which you want to upload an "" ""image with a ``glance`` client command."" msgstr """" ""例えば、``glance`` クライアントコマンドを用いてイメージをアップロードしたいコ"" ""ンピューターにファイルをコピーします。"" msgid """" ""For example, to see the version number for the ``nova`` client, run the "" ""following command:"" msgstr """" ""例えば、``nova`` クライアントのバージョン番号を表示する場合、以下のコマンドを"" ""実行します。"" msgid """" ""For example, using the image ID shown above, you would issue the command as "" ""follows:"" msgstr """" ""例えば、上に示したイメージ ID を使用して、以下のとおりコマンドを発行します。"" msgid """" ""For example, when you specify your password using the command-line client "" ""with the :option:`--os-password` argument, anyone with access to your "" ""computer can view it in plain text with the ``ps`` field."" msgstr """" ""例えば、コマンドラインクライアントの :option:`--os-password` 引数を使用してパ"" ""スワードを指定するとき、コンピューターにアクセスできるユーザーは、``ps`` の項"" ""目に平文で表示できます。"" msgid ""For example:"" msgstr ""例:"" msgid """" ""For more sophisticated monitoring, see the `ceilometer <https://launchpad."" ""net/ceilometer>`__ project. You can also use tools, such as `Ganglia <http://"" ""ganglia.info/>`__ or `Graphite <http://graphite.wikidot.com/>`__, to gather "" ""more detailed data."" msgstr """" ""高機能のモニタリングについては、`ceilometer <https://launchpad.net/"" ""ceilometer>`__ プロジェクトを参照してください。 `Ganglia <http://ganglia."" ""info/>`__ や `Graphite <http://graphite.wikidot.com/>`__ などのツールを使用し"" ""て、より詳細なデータを収集することも可能です。"" msgid """" ""For openSUSE, use ``zypper`` to install the clients from the distribution "" ""packages service:"" msgstr """" ""openSUSE の場合、``zypper`` を使用して、ディストリビューションのパッケージ"" ""サービスからクライアントをインストールします。"" msgid """" ""For the available OpenStack documentation, see `docs.openstack.org <http://"" ""docs.openstack.org>`__."" msgstr """" ""利用可能な OpenStack ドキュメントは `docs.openstack.org <http://docs."" ""openstack.org>`__ を参照してください。"" msgid ""FormPost"" msgstr ""FormPost"" msgid ""Free up space in a thinly-provisioned back end."" msgstr ""シンプロビジョニングされたバックエンドで空き容量を解放する"" msgid """" ""From a network architecture point of view, this service must be accessible "" ""to customers and the public API for each OpenStack service. To use the "" ""administrator functionality for other services, it must also connect to "" ""Admin API endpoints, which should not be accessible by customers."" msgstr """" ""ネットワークアーキテクチャーの観点で見ると、このサービスは顧客からアクセスす"" ""ることができる必要があると同時に、各 OpenStack サービスのパブリック API にも"" ""アクセスできる必要があります。他の OpenStack サービスの管理機能を利用するに"" ""は、管理 API エンドポイントにもアクセスできる必要があります。管理 API エンド"" ""ポイントは顧客からはアクセスできないようにすべきです。"" msgid """" ""From the :guilabel:`Admin` tab, you can access the following category to "" ""complete these tasks:"" msgstr """" "":guilabel:`管理` タブから、以下のカテゴリーにアクセスして、操作を行えます。"" msgid """" ""From the :guilabel:`Project` tab, you can access the following categories:"" msgstr """" "":guilabel:`プロジェクト` タブから、以下のカテゴリーにアクセスできます。"" msgid """" ""From the :guilabel:`Project` tab, you can view and manage the resources in a "" ""selected project, including instances and images. You can select the project "" ""from the drop down menu at the top left."" msgstr """" "":guilabel:`プロジェクト` タブから、インスタンスやイメージなど、選択したプロ"" ""ジェクトのリソースを表示したり管理したりできます。左上のドロップダウンメ"" ""ニューからプロジェクトを選択できます。"" msgid """" ""Gathers statistics, lists items, updates metadata, and uploads, downloads, "" ""and deletes files stored by the Object Storage service. Gains access to an "" ""Object Storage installation for ad hoc processing."" msgstr """" ""統計情報を収集し、項目を一覧表示し、メタデータを更新し、Object Storage サービ"" ""スにより保存されたファイルをアップロード、ダウンロード、削除します。"" msgid """" ""Generally, extra properties on an Image service image to which only cloud "" ""administrators have access. Limits which user roles can perform CRUD "" ""operations on that property. The cloud administrator can configure any image "" ""property as protected."" msgstr """" ""クラウド管理者のみがアクセスできる、Image service のイメージの追加プロパ"" ""ティー。どのユーザーロールがそのプロパティーにおいて CRUD 操作を実行できるか"" ""を制限する。クラウド管理者は、保護されたイメージのプロパティーをすべて設定で"" ""きる。"" msgid ""Get CPU, memory, I/O, and network statistics for an instance."" msgstr ""インスタンスの CPU、メモリー、I/O、ネットワーク統計を取得します。"" msgid """" ""Get a summary of resource usage of all of the instances running on the host:"" msgstr """" ""ホストで実行中のインスタンスすべてのリソース使用状況 (概要) を取得します。"" msgid ""Get diagnostic statistics:"" msgstr ""診断統計を取得します。"" msgid ""Get started with OpenStack"" msgstr ""OpenStack 入門"" msgid ""Get summary statistics for each tenant:"" msgstr ""各テナントの統計サマリーを取得します。"" msgid ""Give a clear, concise summary."" msgstr ""明瞭で簡潔なまとめを。"" msgid """" ""Gives guest VMs exclusive access to a PCI device. Currently supported in "" ""OpenStack Havana and later releases."" msgstr """" ""ゲスト仮想マシンが PCI デバイスに排他的にアクセスされる。OpenStack Havana 以"" ""降でサポートされる。"" msgid ""Glossary"" msgstr ""用語集"" msgid ""GlusterFS"" msgstr ""GlusterFS"" msgid ""Governance service"" msgstr ""Governance service"" msgid ""Graphic Interchange Format (GIF)"" msgstr ""Graphic Interchange Format (GIF)"" msgid ""Graphics Processing Unit (GPU)"" msgstr ""Graphics Processing Unit (GPU)"" msgid ""Green Threads"" msgstr ""Green Threads"" msgid ""Grizzly"" msgstr ""Grizzly"" msgid ""Group"" msgstr ""グループ"" msgid ""HTML title"" msgstr ""HTML タイトル"" msgid ""Hadoop"" msgstr ""Hadoop"" msgid ""Hadoop Distributed File System (HDFS)"" msgstr ""Hadoop Distributed File System (HDFS)"" msgid ""Handles authentication and is usually OpenStack Identity."" msgstr ""認証を処理します。通常は認証に OpenStack Identity を使用します。"" msgid ""Hash of image data to use for verification."" msgstr ""イメージデータの検証に使用するハッシュ。"" msgid ""Havana"" msgstr ""Havana"" msgid ""Heat Orchestration Template (HOT)"" msgstr ""Heat Orchestration Template (HOT)"" msgid ""Heat input in the format native to OpenStack."" msgstr ""OpenStack 固有形式の Heat の入力データ。"" msgid ""Help URL"" msgstr ""ヘルプ URL"" msgid ""Helpful information that prevents the user from making mistakes."" msgstr ""ユーザーが間違いやすい箇所についてアドバイスです。"" msgid """" ""High-availability mode for legacy (nova) networking. Each compute node "" ""handles NAT and DHCP and acts as a gateway for all of the VMs on it. A "" ""networking failure on one compute node doesn't affect VMs on other compute "" ""nodes."" msgstr """" ""レガシーネットワーク (nova) の高可用性モード。各コンピュートノードは、NAT と "" ""DHCP を処理し、すべての仮想マシンのゲートウェイとして動作する。あるコンピュー"" ""トノードにおけるネットワーク障害は、他のコンピュートノードにある仮想マシンに"" ""影響しません。"" msgid """" ""High-performance 64-bit file system created by Silicon Graphics. Excels in "" ""parallel I/O operations and data consistency."" msgstr """" ""Silicon Graphics 社により作成された、高性能な 64 ビットファイルシステム。並"" ""列 I/O 処理とデータ一貫性に優れる。"" msgid ""Host Bus Adapter (HBA)"" msgstr ""Host Bus Adapter (HBA)"" msgid ""Hyper-V"" msgstr ""Hyper-V"" msgid ""Hypertext Transfer Protocol (HTTP)"" msgstr ""Hypertext Transfer Protocol (HTTP)"" msgid ""Hypertext Transfer Protocol Secure (HTTPS)"" msgstr ""Hypertext Transfer Protocol Secure (HTTPS)"" msgid ""ICMP"" msgstr ""ICMP"" msgid ""ID number"" msgstr ""ID 番号"" msgid ""IDS"" msgstr ""IDS"" msgid ""INI"" msgstr ""INI"" msgid ""IOPS"" msgstr ""IOPS"" msgid """" ""IOPS (Input/Output Operations Per Second) are a common performance "" ""measurement used to benchmark computer storage devices like hard disk "" ""drives, solid state drives, and storage area networks."" msgstr """" ""IOPS (Input/Output Operations Per Second) は、ハードディスク、SSD、SAN などの"" ""ストレージデバイスをベンチマークするために使用される、一般的なパフォーマンス"" ""指標である。"" msgid ""IP Address Management (IPAM)"" msgstr ""IP Address Management (IPAM)"" msgid ""IP address"" msgstr ""IP アドレス"" msgid ""IPL"" msgstr ""IPL"" msgid ""IPMI"" msgstr ""IPMI"" msgid ""IQN"" msgstr ""IQN"" msgid ""ISO9660"" msgstr ""ISO9660"" msgid ""IaaS"" msgstr ""IaaS"" msgid ""Icehouse"" msgstr ""Icehouse"" msgid ""Identity"" msgstr ""Identity"" msgid ""Identity API"" msgstr ""Identity API"" msgid ""Identity back end"" msgstr ""Identity バックエンド"" msgid ""Identity service API"" msgstr ""Identity service API"" msgid """" ""If Object Storage finds objects, containers, or accounts that are corrupt, "" ""they are placed in this state, are not replicated, cannot be read by "" ""clients, and a correct copy is re-replicated."" msgstr """" ""Object Storage が壊れたオブジェクト、コンテナー、アカウントを見つけた際に、そ"" ""のデータはこの状態にセットされる。この状態にセットされたデータは、複製され"" ""ず、クライアントが読み出すこともできなくなり、正しいコピーが再複製される。"" msgid """" ""If a certificate warning appears when you try to access the URL for the "" ""first time, a self-signed certificate is in use, which is not considered "" ""trustworthy by default. Verify the certificate or add an exception in the "" ""browser to bypass the warning."" msgstr """" ""この URL に初めてアクセスしようとしたときに、証明書の警告が表示された場合、自"" ""己署名証明書が使用されています。これはデフォルトでは信頼できないものとみなさ"" ""れます。証明書を検証するか、ブラウザーに例外を追加して警告が出ないようにしま"" ""す。"" msgid """" ""If a requested resource such as CPU time, disk storage, or memory is not "" ""available in the parent cell, the request is forwarded to its associated "" ""child cells. If the child cell can fulfill the request, it does. Otherwise, "" ""it attempts to pass the request to any of its children."" msgstr """" ""CPU 時間、ディスクストレージ、メモリ等の要求されたリソースが親セルで利用不可"" ""の場合、リクエストは親セルに紐付けられた子セルに転送される。子セルがリクエス"" ""トに対応可能な場合、子セルはそのリクエストを処理する。対応不可の場合、そのリ"" ""クエストを自分の子セルに渡そうとする。"" msgid """" ""If a requested resource, such as CPU time, disk storage, or memory, is not "" ""available in the parent cell, the request is forwarded to associated child "" ""cells."" msgstr """" ""要求されたリソース（CPU時間、ディスクストレージ、メモリ）が親セルで利用不可の"" ""場合、そのリクエストは紐付けられた子セルに転送される。"" msgid """" ""If the volume is in use or has snapshots, the specified host destination "" ""cannot accept the volume. If the user is not an administrator, the migration "" ""fails."" msgstr """" ""ボリュームが使用中の場合、あるいはスナップショットが存在する場合、指定のマイ"" ""グレーション先のホストは、そのボリュームを受け入れることができません。また、"" ""管理ユーザーではない場合も、マイグレーションは失敗します。"" msgid """" ""If you are logged in as an administrator, the :guilabel:`Project` tab (:ref:"" ""`dashboard-project-tab`) and :guilabel:`Admin` tab (:ref:`dashboard-admin-"" ""tab`) and :guilabel:`Identity` tab (:ref:`dashboard-identity-tab`) are "" ""displayed."" msgstr """" ""管理者としてログインしている場合、:guilabel:`プロジェクト` タブ (:ref:"" ""`dashboard-project-tab`)、 :guilabel:`管理` タブ (:ref:`dashboard-admin-"" ""tab`)、 :guilabel:`ユーザー管理` タブ (:ref:`dashboard-identity-tab`) が表示"" ""されます。"" msgid """" ""If you are logged in as an end user, the :guilabel:`Project` tab (:ref:"" ""`dashboard-project-tab`) and :guilabel:`Identity` tab (:ref:`dashboard-"" ""identity-tab`) are displayed."" msgstr """" ""エンドユーザーとしてログインしている場合、:guilabel:`プロジェクト` タブ (:"" ""ref:`dashboard-project-tab`) と :guilabel:`ユーザー管理` タブ (:ref:"" ""`dashboard-identity-tab`) が表示されます。"" msgid """" ""If you do not have a sufficient quota for the transfer, the transfer is "" ""refused."" msgstr ""転送用のクォータが不足している場合、転送は拒否されます。"" msgid """" ""If you do not want to use this theme you can remove it and its dependencies "" ""using the following command:"" msgstr """" ""このテーマを使用したくない場合、以下のコマンドを使用して、このテーマと依存"" ""パッケージを削除できます。"" msgid """" ""If you encounter problems in creating an image in the Image service or "" ""Compute, the following information may help you troubleshoot the creation "" ""process."" msgstr """" ""Image service や Compute でイメージの作成に関する問題に遭遇した場合、以下の情"" ""報が作成プロセスのトラブルシュートに役立つかもしれません。"" msgid """" ""If you need to install the source package for the command-line package, the "" ""following table lists the software needed to run the command-line clients, "" ""and provides installation instructions as needed."" msgstr """" ""コマンドラインパッケージのソースパッケージをインストールする必要がある場合、"" ""コマンドラインクライアントを実行するために必要となるソフトウェアの一覧が以下"" ""の表にまとめられています。必要に応じてインストール手順が書かれています。"" msgid """" ""If you specify a disk or CD-ROM bus model that is not supported, see the "" ""Disk_and_CD-ROM_bus_model_values_table_. If you specify a VIF model that is "" ""not supported, the instance fails to launch. See the VIF_model_values_table_."" msgstr """" ""サポートされていないディスクまたは CD-ROM バスモデルを指定する場合は "" ""Disk_and_CD-ROM_bus_model_values_table_ (ディスクと CD-ROM のバスモデルの値) "" ""を参照してください。また、サポートされていない VIF モデルを指定する場合、イン"" ""スタンスは起動できません。 VIF_model_values_table_ (仮想インターフェースのモ"" ""デルの値) を参照してください。 "" msgid """" ""If your volume was created successfully, its status is ``available``. If its "" ""status is ``error``, you might have exceeded your quota."" msgstr """" ""ボリュームが正常に作成された場合、状態は ``available`` にとなります。状態が "" ""``error`` の場合、クォータを超過している可能性があります。"" msgid ""Image API"" msgstr ""Image API"" msgid ""Image service"" msgstr ""Image service"" msgid ""Image service API"" msgstr ""Image service API"" msgid """" ""Impassable limits for guest VMs. Settings include total RAM size, maximum "" ""number of vCPUs, and maximum disk size."" msgstr """" ""ゲスト仮想マシンの超えられない制限。合計メモリー容量、最大仮想 CPU 数、最大"" ""ディスク容量の設定。"" msgid ""Implemented as a filesystem underlying OpenStack Compute"" msgstr ""OpenStack Compute が動作するファイルシステムとして実装"" msgid """" ""In Compute and Block Storage, the ability to set resource limits on a per-"" ""project basis."" msgstr """" ""プロジェクト単位に使用できるリソース上限を設定できる、Compute と Block "" ""Storage の機能。"" msgid """" ""In Compute, conductor is the process that proxies database requests from the "" ""compute process. Using conductor improves security because compute nodes do "" ""not need direct access to the database."" msgstr """" ""Compute において、コンピュートプロセスからのデータベース要求をプロキシーする"" ""処理。コンダクターを使用することにより、コンピュートノードがデータベースに直"" ""接アクセスする必要がなくなるので、セキュリティーを向上できる。"" msgid """" ""In Object Storage, tools to test and ensure dispersion of objects and "" ""containers to ensure fault tolerance."" msgstr """" ""Object Storage で、フォールトトレラントの確認の為に、オブジェクトとコンテナの"" ""分散をテスト、確認するツール。"" msgid """" ""In OpenStack Identity, entities represent individual API consumers and are "" ""owned by a specific domain. In OpenStack Compute, a user can be associated "" ""with roles, projects, or both."" msgstr """" ""OpenStack Identity では、エンティティーは個々の API 利用者を表す、特定のドメ"" ""インに属する。OpenStack Compute では、ユーザーはロール、プロジェクトもしくは"" ""その両者と関連付けることができる。"" msgid """" ""In OpenStack, the API version for a project is part of the URL. For example, "" ""``example.com/nova/v1/foobar``."" msgstr """" ""OpenStack では、プロジェクトの API バージョンが URL の一部となる。例: "" ""``example.com/nova/v1/foobar``"" msgid """" ""In a high-availability setup with an active/active configuration, several "" ""systems share the load together and if one fails, the load is distributed to "" ""the remaining systems."" msgstr """" ""アクティブ/アクティブ設定を用いた高可用構成の場合、複数のシステムが処理を一緒"" ""に分担する。また、あるシステムが故障した場合、処理が残りのシステムに分散され"" ""る。"" msgid """" ""In a high-availability setup with an active/passive configuration, systems "" ""are set up to bring additional resources online to replace those that have "" ""failed."" msgstr """" ""アクティブ/パッシブ設定を用いた高可用性セットアップでは、故障したシステムを置"" ""き換えるために、システムが追加リソースをオンラインにするようセットアップされ"" ""る。"" msgid """" ""In a text editor, create a file named ``PROJECT-openrc.sh`` and add the "" ""following authentication information:"" msgstr """" ""テキストエディターで ``PROJECT-openrc.sh`` という名前のファイルを作成し、以下"" ""の認証情報を追加します。"" msgid """" ""In order to benefit from the Identity service, other OpenStack services need "" ""to collaborate with it. When an OpenStack service receives a request from a "" ""user, it checks with the Identity service whether the user is authorized to "" ""make the request."" msgstr """" ""Identity サービスの恩恵を受けるには、他の OpenStack サービスは Identity サー"" ""ビスと協調する必要があります。OpenStack サービスは、ユーザーからのリクエスト"" ""を受けたとき、ユーザーがリクエストを発行する権限があるかどうかを Identity "" ""サービスを用いて確認します。"" msgid """" ""In the address bar, enter the host name or IP address for the dashboard, for "" ""example ``https://ipAddressOrHostName/``."" msgstr """" ""``https://ipAddressOrHostName/`` などのダッシュボードのホスト名または IP アド"" ""レスをアドレスバーに入力します。"" msgid """" ""In the context of Object Storage, this is a process that is not terminated "" ""after an upgrade, restart, or reload of the service."" msgstr """" ""Object Storage の文脈において、サービスの更新、再起動、再読み込みの後に終了し"" ""ないプロセス。"" msgid """" ""In the context of the Identity service, the worker process that provides "" ""access to the admin API."" msgstr ""Identity の領域で、管理 API へのアクセスを提供するワーカープロセス。"" msgid """" ""In the following example, the ``demo-openrc.sh`` file is sourced for the "" ""demo project:"" msgstr """" ""以下の例では、``demo-openrc.sh`` が demo プロジェクト用に読み込まれます。"" msgid """" ""In this example, :option:`--force-host-copy True` forces the generic host-"" ""based migration mechanism and bypasses any driver optimizations."" msgstr """" ""この例では、 :option:`--force-host-copy True` は、強制的に一般的なホストベー"" ""スのマイグレーションの仕組みを使用してドライバーの最適化なしで進めます。"" msgid """" ""Information that consists solely of ones and zeroes, which is the language "" ""of computers."" msgstr ""1 と 0 だけから構成される情報。コンピューターの言語。"" msgid """" ""Infrastructure-as-a-Service. IaaS is a provisioning model in which an "" ""organization outsources physical components of a data center, such as "" ""storage, hardware, servers, and networking components. A service provider "" ""owns the equipment and is responsible for housing, operating and maintaining "" ""it. The client typically pays on a per-use basis. IaaS is a model for "" ""providing cloud services."" msgstr """" ""Infrastructure-as-a-Service。IaaS は、ストレージ、ハードウェア、サーバー、"" ""ネットワークなど、データセンターの物理コンポーネントをアウトソースする組織の"" ""配備モデル。サーバープロバイダーは、設備を所有し、ハウジング、運用、メンテナ"" ""ンスに責任を持つ。クライアントは、一般的に使用量に応じて費用を払う。IaaS は、"" ""クラウドサービスを提供するモデル。"" msgid ""Initial Program Loader."" msgstr ""Initial Program Loader。初期プログラムローダー。"" msgid ""Install each client separately by using the following command:"" msgstr ""以下のコマンドを使用して、各クライアントをそれぞれインストールします。"" msgid ""Install pip through the package manager for your system:"" msgstr """" ""お使いのシステムのパッケージマネージャーから pip をインストールします。"" msgid ""Install the Database service."" msgstr ""Database サービスをインストールします。"" msgid ""Install the OpenStack client"" msgstr ""OpenStack client のインストール"" msgid ""Install the OpenStack command-line clients"" msgstr ""OpenStack コマンドラインクライアントのインストール"" msgid ""Install the prerequisite software"" msgstr ""前提ソフトウェアのインストール"" msgid """" ""Install the prerequisite software and the Python package for each OpenStack "" ""client."" msgstr """" ""前提ソフトウェアと各 OpenStack クライアント用の Python パッケージをインストー"" ""ルします。"" msgid ""Installed by default on Mac OS X."" msgstr ""Mac OS X に標準でインストールされます。"" msgid ""Installing from packages"" msgstr ""パッケージからのインストール"" msgid ""Installing with pip"" msgstr ""pip を用いたインストール"" msgid ""Instances in use"" msgstr ""使用中のインスタンス"" msgid """" ""Instruments the complex system flows that support provisioning instances, "" ""managing the lifecycle of instances, and performing operations on instances."" msgstr """" ""インスタンスの展開、インスタンスのライフサイクルの管理、インスタンス上の処理"" ""の実行をサポートする複雑なシステムフローの全体指揮を行います。"" msgid """" ""Integration with vendor specific management tools, such as Apache Ambari or "" ""Cloudera Management Console."" msgstr """" ""ベンダー固有の管理ツールとの統合。 Apache Ambari や Cloudera Management "" ""Console など。"" msgid """" ""Intelligent Platform Management Interface. IPMI is a standardized computer "" ""system interface used by system administrators for out-of-band management of "" ""computer systems and monitoring of their operation. In layman's terms, it is "" ""a way to manage a computer using a direct network connection, whether it is "" ""turned on or not; connecting to the hardware rather than an operating system "" ""or login shell."" msgstr """" ""Intelligent Platform Management Interface。IPMI は、コンピューターシステムの"" ""アウトオブバンド管理、運用監視のために、システム管理者により使用される標準的"" ""なコンピューターシステムインターフェース。平たく言うと、電源状態によらず、"" ""ネットワークの直接通信を使用してコンピューターを管理する方法。オペレーティン"" ""グシステムやログインシェルではなく、ハードウェアに接続する。"" msgid """" ""Interactions and processes that are obfuscated from the user, such as "" ""Compute volume mount, data transmission to an iSCSI target by a daemon, or "" ""Object Storage object integrity checks."" msgstr """" ""Compute のボリュームのマウント、デーモンによる iSCSI ターゲットへのデータ転"" ""送、Object Storage のオブジェクトの完全性検査など、ユーザーから見えにくい操作"" ""や処理。"" msgid """" ""Interacts directly with the Block Storage service, and processes such as the "" ""``cinder-scheduler``. It also interacts with these processes through a "" ""message queue. The ``cinder-volume`` service responds to read and write "" ""requests sent to the Block Storage service to maintain state. It can "" ""interact with a variety of storage providers through a driver architecture."" msgstr """" ""``cinder-scheduler`` などの Block Storage サービスやプロセスと直接やり取りを"" ""行います。また、メッセージキュー経由でもこれらのプロセスと連携します。 "" ""``cinder-volume`` サービスは、Block Storage サービスへ送られた読み出し、書き"" ""込みリクエストに応答し、状態を管理します。ドライバーアーキテクチャーになって"" ""おり、様々なストレージプロバイダーと連携できます。"" msgid """" ""Interacts directly with the Shared File Systems service and processes such "" ""as the ``manila-scheduler``. It also interacts with these processes through "" ""a message queue. The ``manila-share`` service responds to read and write "" ""requests sent to the Shared File Systems service to maintain state. It can "" ""interact with a variety of storage providers through a driver architecture."" msgstr """" ""``manila-scheduler`` などの Shared File Systems サービスやプロセスと直接やり"" ""取りを行います。また、メッセージキュー経由でもこれらのプロセスと連携します。 "" ""``manila-share`` サービスは、Shared File Systems サービスへ送られた読み出し、"" ""書き込みリクエストに応答し、状態を管理します。ドライバーアーキテクチャーに"" ""なっており、様々なストレージプロバイダーと連携できます。"" msgid """" ""Interface within Networking that enables organizations to create custom plug-"" ""ins for advanced features, such as QoS, ACLs, or IDS."" msgstr """" ""組織が QoS、ACL、IDS などの高度な機能向けのカスタムプラグインを作成できるよう"" ""にする、Networking 内のインターフェース。"" msgid """" ""Internally, OpenStack services are composed of several processes. All "" ""services have at least one API process, which listens for API requests, "" ""preprocesses them and passes them on to other parts of the service. With the "" ""exception of the Identity service, the actual work is done by distinct "" ""processes."" msgstr """" ""内部では、 それぞれの OpenStack サービスは複数のプロセスから構成されていま"" ""す。すべてのサービスには少なくとも 1 つの API プロセスがあり、この API プロセ"" ""スは API リクエストを待ち受け、API リクエストの前処理を行ってから、そのサービ"" ""スの別の構成要素にそのリクエストを渡します。実際の処理は別のプロセスによって"" ""行わます。ただし、 Identity service は例外です。"" msgid """" ""Internally, each command uses cURL command-line tools, which embed API "" ""requests. OpenStack APIs are RESTful APIs, and use the HTTP protocol. They "" ""include methods, URIs, media types, and response codes."" msgstr """" ""内部的に、各コマンドは API リクエストを組み込んだ cURL コマンドラインツールを"" ""使用します。OpenStack API は HTTP プロトコルを使用する RESTful API です。メ"" ""ソッド、URI、メディアタイプ、応答コードなどが含まれます。"" msgid """" ""Internet Control Message Protocol, used by network devices for control "" ""messages. For example, :command:`ping` uses ICMP to test connectivity."" msgstr """" ""インターネット制御メッセージプロトコル。制御メッセージ用にネットワークデバイ"" ""スにより使用される。例えば、:command:`ping` は接続性をテストするために ICMP "" ""を使用する。"" msgid ""Internet Service Provider (ISP)"" msgstr ""Internet Service Provider (ISP)"" msgid ""Internet Small Computer System Interface (iSCSI)"" msgstr ""Internet Small Computer System Interface (iSCSI)"" msgid ""Internet protocol (IP)"" msgstr ""インターネットプロトコル (IP)"" msgid ""Intrusion Detection System."" msgstr ""侵入検知システム。"" msgid ""It includes the following components:"" msgstr ""以下のコンポーネントで構成されます。"" msgid ""Java"" msgstr ""Java"" msgid ""JavaScript"" msgstr ""JavaScript"" msgid ""JavaScript Object Notation (JSON)"" msgstr ""JavaScript Object Notation (JSON)"" msgid ""Jenkins"" msgstr ""Jenkins"" msgid ""Juno"" msgstr ""Juno"" msgid ""Kerberos"" msgstr ""Kerberos"" msgid ""Key Manager service"" msgstr ""Key Manager サービス"" msgid ""Key features are:"" msgstr ""主要機能な以下の通りです。"" msgid ""Key management service"" msgstr ""Key management サービス"" msgid ""Kickstart"" msgstr ""Kickstart"" msgid ""Kilo"" msgstr ""Kilo"" msgid ""LBaaS"" msgstr ""LBaaS"" msgid """" ""LBaaS feature that provides availability monitoring using the ``ping`` "" ""command, TCP, and HTTP/HTTPS GET."" msgstr """" ""``ping`` コマンド、TCP、HTTP/HTTPS GET を使用してモニタリングする機能を提供す"" ""る LBaaS の機能。"" msgid """" ""Launches stacks from templates, views details of running stacks including "" ""events and resources, and updates and deletes stacks."" msgstr """" ""テンプレートからスタックを起動し、イベントやリソースを含む実行中のスタックの"" ""詳細を表示し、スタックを更新、削除します。"" msgid ""Launchpad"" msgstr ""Launchpad"" msgid ""Layer-2 (L2) agent"" msgstr ""L2 エージェント"" msgid ""Layer-2 network"" msgstr ""L2 ネットワーク"" msgid ""Layer-3 (L3) agent"" msgstr ""L3 エージェント"" msgid ""Layer-3 network"" msgstr ""L3 ネットワーク"" msgid ""Liberty"" msgstr ""Liberty"" msgid ""Lightweight Directory Access Protocol (LDAP)"" msgstr ""Lightweight Directory Access Protocol (LDAP)"" msgid ""Linux Bridge neutron plug-in"" msgstr ""Linux Bridge neutron プラグイン"" msgid ""Linux bridge"" msgstr ""Linux ブリッジ"" msgid ""Linux containers (LXC)"" msgstr ""Linux コンテナー （LXC）"" msgid """" ""Linux kernel feature that provides independent virtual networking instances "" ""on a single host with separate routing tables and interfaces. Similar to "" ""virtual routing and forwarding (VRF) services on physical network equipment."" msgstr """" ""別々のルーティングテーブルとインターフェースを持つ単一のホストにおいて、独立"" ""した仮想ネットワークインターフェースを提供する Linux カーネル機能。物理ネット"" ""ワーク環境における仮想ルーティングおよびフォワーディング (VRF) サービスと似て"" ""いる。"" msgid """" ""Linux kernel security module that provides the mechanism for supporting "" ""access control policies."" msgstr """" ""アクセス制御ポリシーをサポートするための機構を提供する Linux カーネルセキュリ"" ""ティーモジュール。"" msgid ""List available volumes and their statuses:"" msgstr ""利用可能なボリュームとその状態を表示します。"" msgid """" ""List images, and note the ID of the image that you want to use for your "" ""volume:"" msgstr """" ""イメージを一覧表示し、ボリュームに使用したいイメージの ID を記録します。"" msgid ""List instances:"" msgstr ""インスタンスを一覧表示します。"" msgid ""List or get details for images (glance)"" msgstr ""イメージ (glance) の詳細の一覧表示と取得"" msgid """" ""List the availability zones, and note the ID of the availability zone in "" ""which you want to create your volume:"" msgstr """" ""アベイラビリティゾーンを表示して、その中からボリュームを作成するアベイラビリ"" ""ティゾーンの ID をメモします。 "" msgid ""List the hosts and the nova-related services that run on them:"" msgstr """" ""ホストおよびそのホストで実行されている nova 関連のサービスを一覧表示します。"" msgid """" ""List the volumes again, and note that the status of your volume is "" ""``deleting``:"" msgstr """" "" 再度ボリュームを表示して、ボリュームの状態が deleting となっていることを確認"" ""します。 "" msgid ""List volumes:"" msgstr ""ボリュームを一覧表示します。"" msgid ""Lists allowed commands within the Compute rootwrap facility."" msgstr ""Compute rootwrap 機能内で許可されるコマンドの一覧。"" msgid """" ""Lists containers in Object Storage and stores container information in the "" ""account database."" msgstr """" ""Object Storage にあるコンテナーを一覧表示し、コンテナーの情報をアカウントデー"" ""タベースに保存する。"" msgid """" ""Local file that contains the disk image to be uploaded during the update. "" ""Alternatively, you can pass images to the client through stdin."" msgstr """" ""更新中にアップロードするディスクイメージを含むローカルファイル。または、標準"" ""入力からクライアントにイメージを渡すことができます。"" msgid """" ""Log in to the OpenStack dashboard, choose the project for which you want to "" ""download the OpenStack RC file, on the :guilabel:`Project` tab, open the :"" ""guilabel:`Compute` tab and click :guilabel:`Access & Security`."" msgstr """" ""OpenStack dashboard にログインし、OpenStack RC ファイルをダウンロードしたいプ"" ""ロジェクトを選択し、:guilabel:`プロジェクト` タブにある :guilabel:`コンピュー"" ""ト` タブにおいて、:guilabel:`アクセスとセキュリティー` をクリックします。"" msgid ""Log in to the dashboard"" msgstr ""ダッシュボードへのログイン"" msgid ""Logged in banner: 216 x 35"" msgstr ""ログイン後のバナー: 216 x 35"" msgid ""Logical Volume Manager (LVM)"" msgstr ""論理ボリュームマネージャー (LVM)"" msgid ""Logical architecture"" msgstr ""論理アーキテクチャー"" msgid """" ""Logical groupings of related code, such as the Block Storage volume manager "" ""or network manager."" msgstr """" ""Block Storage のボリュームマネージャーやネットワークマネージャーなど、関連す"" ""るコードの論理的なグループ。"" msgid ""Logical subdivision of an IP network."" msgstr ""IP ネットワークの論理分割。"" msgid ""Login screen: 365 x 50"" msgstr ""ログイン画面: 365 x 50"" msgid ""Logo"" msgstr ""ロゴ"" msgid ""Logo and site colors"" msgstr ""ロゴとサイトカラー"" msgid ""Logo link"" msgstr ""ロゴリンク"" msgid """" ""Lower power consumption CPU often found in mobile and embedded devices. "" ""Supported by OpenStack."" msgstr """" ""モバイル機器や組み込みデバイスによく利用される低消費電力 CPU。OpenStack はサ"" ""ポートしている。"" msgid """" ""MD5 hash of an object within Object Storage, used to ensure data integrity."" msgstr """" ""Object Storage 内のオブジェクトの MD5 ハッシュ。データの完全性を確認するため"" ""に使用される。"" msgid ""Makes an image accessible for all the tenants (admin-only by default)."" msgstr """" ""イメージをすべてのテナントからアクセス可能にします (デフォルトは admin 専"" ""用)。"" msgid ""Manage images"" msgstr ""イメージの管理"" msgid ""Manage volumes"" msgstr ""ボリュームの管理"" msgid """" ""Managed through REST API with UI available as part of OpenStack dashboard."" msgstr """" ""REST API 経由で管理でき、 OpenStack dashboard の一部として UI も提供されてい"" ""ます。"" msgid ""Manages accounts defined with Object Storage."" msgstr ""Object Storage で定義されるアカウントを管理します。"" msgid ""Manages actual objects, such as files, on the storage nodes."" msgstr """" ""ストレージノードにおいて、ファイルなどの実際のオブジェクトを管理します。"" msgid """" ""Manages the lifecycle of compute instances in an OpenStack environment. "" ""Responsibilities include spawning, scheduling and decommissioning of virtual "" ""machines on demand."" msgstr """" ""OpenStack 環境でコンピュートインスタンスのライフサイクルを管理します。要求に"" ""応じて仮想マシンの作成、スケジューリング、破棄などに責任を持ちます。"" msgid ""Manages the mapping of containers or folders, within Object Storage."" msgstr ""Object Storage 内でコンテナーやフォルダーの対応付けを管理します。"" msgid """" ""Many Linux distributions provide packages to make setuptools easy to "" ""install. Search your package manager for setuptools to find an installation "" ""package. If you cannot find one, download the setuptools package directly "" ""from https://pypi.python.org/pypi/setuptools."" msgstr """" ""Linux ディストリビューションの多くは、setuptools を簡単にインストールするため"" ""のパッケージを提供しています。お使いのパッケージマネージャーで setuptools を"" ""検索してインストレーションパッケージを見つけてください。見つからない場合は、"" ""https://pypi.python.org/pypi/setuptools から直接 setuptools パッケージをダウ"" ""ンロードしてください。 "" msgid ""Maps Object Storage partitions to physical storage devices."" msgstr ""Object Storage パーティションの物理ストレージデバイスへの対応付け"" msgid """" ""Massively scalable distributed storage system that consists of an object "" ""store, block store, and POSIX-compatible distributed file system. Compatible "" ""with OpenStack."" msgstr """" ""オブジェクトストア、ブロックストア、および POSIX 互換分散ファイルシステムから"" ""構成される大規模スケール可能分散ストレージシステム。OpenStack 互換。"" msgid """" ""Maximum frame or packet size for a particular network medium. Typically 1500 "" ""bytes for Ethernet networks."" msgstr """" ""特定のネットワークメディア向けの最大フレームやパケットサイズ。一般的に、イー"" ""サネット向けは 1500 バイト。"" msgid """" ""Mechanism for highly-available multi-host routing when using OpenStack "" ""Networking (neutron)."" msgstr """" ""OpenStack Networking (neutron) の使用時、高可用なマルチホストルーティングのた"" ""めの機構。"" msgid """" ""Mechanism in IP networks to detect end-to-end MTU and adjust packet size "" ""accordingly."" msgstr """" ""エンド間の MTU を検出し、パケットサイズを適切に調整するための IP ネットワーク"" ""における機構。"" msgid """" ""Mediates interactions between the ``nova-compute`` service and the database. "" ""It eliminates direct accesses to the cloud database made by the ``nova-"" ""compute`` service. The ``nova-conductor`` module scales horizontally. "" ""However, do not deploy it on nodes where the ``nova-compute`` service runs. "" ""For more information, see `Configuration Reference Guide <http://docs."" ""openstack.org/liberty/config-reference/content/ section_conductor.html>`__."" msgstr """" ""``nova-compute`` サービスとデータベース間のやりとりを仲介します。これによ"" ""り、 ``nova-compute`` サービスからのクラウドデータベースへの直接アクセスをな"" ""くすことができます。 ``nova-conductor`` モジュールは水平にスケールさせること"" ""ができます。ただし、 ``nova-compute`` サービスが実行されているノードには配置"" ""しないでください。詳しい情報は、 `Configuration Reference Guide <http://docs."" ""openstack.org/liberty/config-reference/content/ section_conductor.html>`__ を"" ""参照してください。"" msgid """" ""Message exchange that is cleared when the service restarts. Its data is not "" ""written to persistent storage."" msgstr """" ""サービスの再起動時に削除されるメッセージ交換。このデータは永続ストレージに書"" ""き込まれない。"" msgid """" ""Message queue software supported by OpenStack. An alternative to RabbitMQ. "" ""Also spelled 0MQ."" msgstr """" ""OpenStack によりサポートされるメッセージキューソフトウェア。RabbitMQ の代替。"" ""0MQ とも表記。"" msgid """" ""Message queue software supported by OpenStack; an alternative to RabbitMQ."" msgstr """" ""OpenStack によりサポートされるメッセージキューソフトウェア。RabbitMQ の代替。"" msgid """" ""Message queue that is cleared when the service restarts. Its data is not "" ""written to persistent storage."" msgstr """" ""サービスの再起動時に削除されるメッセージキュー。このデータは永続ストレージに"" ""書き込まれない。"" msgid ""Message service"" msgstr ""Message サービス"" msgid ""Messaging queue"" msgstr ""メッセージングキュー"" msgid ""Meta-Data Server (MDS)"" msgstr ""Meta-Data Server (MDS)"" msgid ""Metadata agent"" msgstr ""メタデータエージェント"" msgid ""Metadata definition service"" msgstr ""メタデータ定義サービス"" msgid """" ""Method to access VM instance consoles using a web browser. Supported by "" ""Compute."" msgstr """" ""Web ブラウザーを使用して仮想マシンインスタンスのコンソールにアクセスする方"" ""法。Compute によりサポートされる。"" msgid """" ""Middleware modules run in the address space of the OpenStack component that "" ""is using the Identity service. These modules intercept service requests, "" ""extract user credentials, and send them to the centralized server for "" ""authorization. The integration between the middleware modules and OpenStack "" ""components uses the Python Web Server Gateway Interface."" msgstr """" ""ミドルウェアモジュールは、Identity サービスを使用している OpenStack コンポー"" ""ネントの一部として動作します。これらのモジュールは、サービスリクエスト処理の"" ""中で、ユーザーのクレデンシャルを抽出し、認可を行うためそのクレデンシャルを中"" ""央サーバーに送信します。ミドルウェアモジュールと OpenStack コンポーネントの間"" ""の統合には、Python Web Server Gateway Interface を使用します。"" msgid ""Migrate a volume"" msgstr ""ボリュームの移行"" msgid """" ""Migrate a volume with the :command:`cinder migrate` command, as shown in the "" ""following example:"" msgstr """" ""以下の例にあるように、:command:`cinder migrate` コマンドでボリュームを移行し"" ""ます。"" msgid ""Mitaka"" msgstr ""Mitaka"" msgid ""Modify the properties of a volume."" msgstr ""ボリュームのプロパティーを編集します。"" msgid ""Modular Layer 2 (ML2) neutron plug-in"" msgstr ""Modular Layer 2 (ML2) neutron プラグイン"" msgid """" ""Modular system that allows the underlying message queue software of Compute "" ""to be changed. For example, from RabbitMQ to ZeroMQ or Qpid."" msgstr """" ""Compute が利用するメッセージキューソフトウェアを変更できるようにする仕組み。"" ""例えば、 RabbitMQ を ZeroMQ や Qpid に変更できる。"" msgid ""Modules"" msgstr ""モジュール"" msgid ""Monitor (LBaaS)"" msgstr ""モニター (LBaaS)"" msgid ""Monitor (Mon)"" msgstr ""モニター (Mon)"" msgid ""Monitoring"" msgstr ""Monitoring"" msgid ""Monitoring solution."" msgstr ""監視ソリューション。"" msgid """" ""Monitors and meters the OpenStack cloud for billing, benchmarking, "" ""scalability, and statistical purposes."" msgstr """" ""課金、ベンチマーク、スケーラビリティ、統計などの目的のために、OpenStack クラ"" ""ウドを監視および計測します。"" msgid """" ""Most Linux distributions include packaged versions of the command-line "" ""clients that you can install directly, see Installing_from_packages_."" msgstr """" ""多くの Linux ディストリビューションには、コマンドラインクライアントを直接イン"" ""ストールできるパッケージがあります。詳細は Installing_from_packages_ を参照し"" ""てください。"" msgid """" ""Mounted via OpenStack Block Storage controlled protocol (for example, iSCSI)"" msgstr """" ""OpenStack Block Storage が制御するプロトコル (例: iSCSI) 経由でマウントされる"" msgid ""MultiNic"" msgstr ""MultiNic"" msgid ""NAT"" msgstr ""NAT"" msgid ""NTP"" msgstr ""NTP"" msgid ""Name for the Compute component that manages VMs."" msgstr ""仮想マシンを管理する Compute のコンポーネントの名称。"" msgid ""Nebula"" msgstr ""Nebula"" msgid ""NetApp volume driver"" msgstr ""NetApp ボリュームドライバー"" msgid """" ""Network Address Translation; Process of modifying IP address information "" ""while in transit. Supported by Compute and Networking."" msgstr """" ""ネットワークアドレス変換。IP アドレス情報を転送中に変更する処理。Compute と "" ""Networking によりサポートされる。"" msgid ""Network File System (NFS)"" msgstr ""Network File System (NFS)"" msgid """" ""Network Time Protocol; Method of keeping a clock for a host or node correct "" ""via communication with a trusted, accurate time source."" msgstr """" ""ネットワーク時刻プロトコル。信頼された、正確な時刻源と通信することにより、ホ"" ""ストやノードの時刻を正確に保つ方法。"" msgid """" ""Network traffic between a user or client (north) and a server (south), or "" ""traffic into the cloud (south) and out of the cloud (north). See also east-"" ""west traffic."" msgstr """" ""ユーザーやクライアント (ノース)、とサーバー (サウス) 間のネットワーク通信、ク"" ""ラウド (サウス) とクラウド外 (ノース) 内の通信。イースト・サウス通信も参照。"" msgid """" ""Network traffic between servers in the same cloud or data center. See also "" ""north-south traffic."" msgstr """" ""同じクラウドやデータセンターにあるサーバー間のネットワーク通信。ノース・サウ"" ""ス通信も参照。"" msgid ""Networking"" msgstr ""Networking"" msgid ""Networking API"" msgstr ""Networking API"" msgid """" ""New users are assigned to this tenant if no tenant is specified when a user "" ""is created."" msgstr """" ""ユーザーを作成したときに、テナントを指定していない場合、新規ユーザーはこのテ"" ""ナントに割り当てられる。"" msgid ""Newton"" msgstr ""Newton"" msgid ""Nexenta volume driver"" msgstr ""Nexenta ボリュームドライバー"" msgid ""No ACK"" msgstr ""No ACK"" msgid """" ""Note that extra dependencies may be required, per operating system, "" ""depending on the package being installed, such as is the case with Tempest."" msgstr """" ""Tempest の場合など、インストールするパッケージに応じて、依存関係によりオペ"" ""レーティングシステムごとの追加パッケージが必要になるかもしれないことに注意し"" ""てください。"" msgid ""Note that the volume is now available."" msgstr ""ボリュームが利用可能になっていることに注意してください。"" msgid ""Note the ID of your volume."" msgstr ""ボリュームの ID を記録します。"" msgid ""Notices"" msgstr ""注記"" msgid ""Notices take these forms:"" msgstr ""注記には以下の種類があります。"" msgid ""Nova API"" msgstr ""Nova API"" msgid """" ""Number that is unique to every computer system on the Internet. Two versions "" ""of the Internet Protocol (IP) are in use for addresses: IPv4 and IPv6."" msgstr """" ""インターネットにあるすべてのコンピューターシステムを一意にする番号。Internet "" ""Protocol (IP) は、IPv4 と IPv6 の 2 つのバージョンがアドレス付けのために使用"" ""中です。"" msgid ""Object Storage"" msgstr ""Object Storage"" msgid ""Object Storage (swift)"" msgstr ""Object Storage (swift)"" msgid ""Object Storage API"" msgstr ""Object Storage API"" msgid ""Object Storage Device (OSD)"" msgstr ""Object Storage Device (OSD)"" msgid """" ""Object Storage middleware that uploads (posts) an image through a form on a "" ""web page."" msgstr """" ""Web ページのフォームからイメージをアップロード (投稿) する、Object Storage の"" ""ミドルウェア。"" msgid ""Object servers (swift-object-server)"" msgstr ""オブジェクトサーバー (swift-object-server)"" msgid """" ""Object storage service by Amazon; similar in function to Object Storage, it "" ""can act as a back-end store for Image service VM images."" msgstr """" ""Amazon により提供されるオブジェクトストレージ。Object Storage の機能に似てい"" ""る。Image service の仮想マシンイメージのバックエンドとして動作できる。"" msgid ""Ocata"" msgstr ""Ocata"" msgid ""Oldie"" msgstr ""Oldie"" msgid """" ""On Red Hat Enterprise Linux, CentOS, or Fedora, use ``yum`` to install the "" ""clients from the packaged versions available in `RDO <https://www.rdoproject."" ""org/>`__:"" msgstr """" ""Red Hat Enterprise Linux、CentOS、Fedora の場合、``yum`` を使用して、`RDO "" ""<https://www.rdoproject.org/>`__ にあるクライアントのパッケージをインストール"" ""します。"" msgid """" ""On any shell from which you want to run OpenStack commands, source the "" ""``PROJECT-openrc.sh`` file for the respective project."" msgstr """" ""OpenStack コマンドを実行したいシェルで、それぞれのプロジェクト用の ``PROJECT-"" ""openrc.sh`` ファイルを読み込みます。"" msgid """" ""On any shell from which you want to run OpenStack commands, source the "" ""``PROJECT-openrc.sh`` file for the respective project. In this example, you "" ""source the ``admin-openrc.sh`` file for the admin project:"" msgstr """" ""OpenStack コマンドを実行したいシェルで、それぞれのプロジェクト用の ``PROJECT-"" ""openrc.sh`` ファイルを読み込みます。この例では、admin プロジェクト用の "" ""``admin-openrc.sh`` ファイルを読み込みます。"" msgid """" ""On the :guilabel:`API Access` tab, click :guilabel:`Download OpenStack RC "" ""File` and save the file. The filename will be of the form ``PROJECT-openrc."" ""sh`` where ``PROJECT`` is the name of the project for which you downloaded "" ""the file."" msgstr """" "":guilabel:`API アクセス` タブで、:guilabel:`OpenStack RC ファイルのダウンロー"" ""ド` をクリックしてファイルを保存します。ファイル名は ``PROJECT-openrc.sh`` の"" ""形式とし、``PROJECT`` にはファイルをダウンロードするプロジェクト名を入力しま"" ""す。 "" msgid """" ""On the Log In page, enter your user name and password, and click :guilabel:"" ""`Sign In`."" msgstr """" ""ログインページにおいて、ユーザー名とパスワードを入力して :guilabel:`ログイン"" ""` をクリックします。"" msgid ""On-instance / ephemeral"" msgstr ""インスタンス上 / 一時"" msgid """" ""Once you have the dashboard installed you can customize the way it looks and "" ""feels to suit your own needs."" msgstr """" ""ダッシュボードをインストールすると、ルックアンドフィールを必要に応じてカスタ"" ""マイズできます。"" msgid """" ""One of the RPC primitives used by the OpenStack message queue software. "" ""Sends a message and does not wait for a response."" msgstr """" ""OpenStack メッセージキューソフトウェアにより使用される RPC プリミティブの 1 "" ""つ。メッセージを送信し、応答を待たない。"" msgid """" ""One of the RPC primitives used by the OpenStack message queue software. "" ""Sends a message and waits for a response."" msgstr """" ""OpenStack のメッセージキューソフトウェアにより使用される、RPC プリミティブの "" ""1 つ。メッセージを送信し、応答を待つ。"" msgid ""One of the VM image disk formats supported by Image service."" msgstr """" ""Image service によりサポートされる、仮想マシンイメージディスク形式の 1 つ。"" msgid """" ""One of the VM image disk formats supported by Image service; an unstructured "" ""disk image."" msgstr """" ""Image service によりサポートされる仮想マシンイメージのディスク形式の 1 つ。"" msgid """" ""One of the default roles in the Compute RBAC system and the default role "" ""assigned to a new user."" msgstr """" ""Compute RBAC システムにあるデフォルトのロールの 1 つ。新規ユーザーに割り当て"" ""られるデフォルトのロール。"" msgid """" ""One of the default roles in the Compute RBAC system. Enables a user to add "" ""other users to a project, interact with VM images that are associated with "" ""the project, and start and stop VM instances."" msgstr """" ""Compute RBAC システムにおけるデフォルトのロールの 1 つ。ユーザーが他のユー"" ""ザーをプロジェクトに追加でき、プロジェクトに関連付けられた仮想マシンイメージ"" ""を操作でき、仮想マシンインスタンスを起動および終了できるようになる。"" msgid """" ""One of the default roles in the Compute RBAC system. Enables the user to "" ""allocate publicly accessible IP addresses to instances and change firewall "" ""rules."" msgstr """" ""Compute RBAC システムにおけるデフォルトのロールの 1 つ。ユーザーが、パブリッ"" ""クにアクセス可能な IP アドレスをインスタンスに割り当てられ、ファイアウォール"" ""ルールを変更できるようになる。"" msgid """" ""One of the default roles in the Compute RBAC system. Grants complete system "" ""access."" msgstr """" ""Compute RBAC システムにおけるデフォルトのロールの 1 つ。システムの完全なアク"" ""セス権を付与する。"" msgid ""One of the hypervisors supported by OpenStack."" msgstr ""OpenStack によりサポートされるハイパーバイザーの一つ。"" msgid ""One of the supported response formats in OpenStack."" msgstr ""OpenStack でサポートされる応答形式の 1 つ。"" msgid ""Open Cloud Computing Interface (OCCI)"" msgstr ""Open Cloud Computing Interface (OCCI)"" msgid ""Open Virtualization Format (OVF)"" msgstr ""Open Virtualization Format (OVF)"" msgid ""Open a web browser that has JavaScript and cookies enabled."" msgstr ""JavaScript とクッキーが有効化されたウェブブラウザーを開きます。"" msgid """" ""Open source GUI and CLI tools used for remote console access to VMs. "" ""Supported by Compute."" msgstr """" ""仮想マシンへのリモートコンソールアクセスに使用される、オープンソースの GUI / "" ""CUI ツール。"" msgid """" ""Open source tool used to access remote hosts through an encrypted "" ""communications channel, SSH key injection is supported by Compute."" msgstr """" ""暗号化した通信チャネル経由でリモートホストにアクセスするために使用されるオー"" ""プンソースのツール。SSH 鍵インジェクションが Compute によりサポートされる。"" msgid ""Open the following HTML template in an editor of your choice:"" msgstr ""以下の HTML テンプレートをお好きなエディターで開きます。"" msgid ""Open vSwitch"" msgstr ""Open vSwitch"" msgid ""Open vSwitch (OVS) agent"" msgstr ""Open vSwitch (OVS) エージェント"" msgid """" ""Open vSwitch is a production quality, multilayer virtual switch licensed "" ""under the open source Apache 2.0 license. It is designed to enable massive "" ""network automation through programmatic extension, while still supporting "" ""standard management interfaces and protocols (for example NetFlow, sFlow, "" ""SPAN, RSPAN, CLI, LACP, 802.1ag)."" msgstr """" ""Open vSwitch は、商用品質、複数階層の仮想スイッチ。オープンソースの Apache "" ""2.0 license に基づき許諾される。標準的な管理インターフェースやプロトコルと使"" ""用ながら、プログラム拡張により大規模なネットワーク自動化を実現できるよう設計"" ""されている (例えば、NetFlow、sFlow、SPAN、RSPAN、CLI、LACP、802.1ag)。"" msgid ""Open vSwitch neutron plug-in"" msgstr ""Open vSwitch neutron プラグイン"" msgid ""OpenLDAP"" msgstr ""OpenLDAP"" msgid ""OpenStack"" msgstr ""OpenStack"" msgid """" ""OpenStack APIs are open-source Python clients, and can run on Linux or Mac "" ""OS X systems. On some client commands, you can specify a debug parameter to "" ""show the underlying API request for the command. This is a good way to "" ""become familiar with the OpenStack API calls."" msgstr """" ""OpenStack API は、オープンソースの Python クライアントです。Linux や Mac OS "" ""X システムにおいて使用できます。いくつかのクライアントコマンドでは、デバッグ"" ""パラメーターを指定して、そのコマンドの基盤となる API リクエストを表示できま"" ""す。OpenStack API コールに慣れるには、この方法が便利です。"" msgid ""OpenStack Block Storage"" msgstr ""OpenStack Block Storage"" msgid ""OpenStack Compute"" msgstr ""OpenStack Compute"" msgid ""OpenStack Compute consists of the following areas and their components:"" msgstr ""OpenStack Compute は、以下のコンポーネントから構成されます。"" msgid """" ""OpenStack Compute interacts with OpenStack Identity for authentication; "" ""OpenStack Image service for disk and server images; and OpenStack dashboard "" ""for the user and administrative interface. Image access is limited by "" ""projects, and by users; quotas are limited per project (the number of "" ""instances, for example). OpenStack Compute can scale horizontally on "" ""standard hardware, and download images to launch instances."" msgstr """" ""OpenStack Compute は、認証については OpenStack Identity サービスと、ディスク"" ""やサーバーイメージについては OpenStack Image サービスと、ユーザーや管理者向け"" ""インターフェースについては OpenStack Dashboard と連携して動作します。イメージ"" ""アクセスはプロジェクトやユーザー単位で限定され、クォータ (例えば、インスタン"" ""ス数) はプロジェクト単位に適用されます。 OpenStack Compute は標準的なハード"" ""ウェアを使って水平にスケールさせることができます。イメージをダウンロードし"" ""て、インスタンスを起動します。"" msgid ""OpenStack Data processing service"" msgstr ""OpenStack Data processing サービス"" msgid ""OpenStack Database service"" msgstr ""OpenStack Database service"" msgid ""OpenStack Identity"" msgstr ""OpenStack Identity"" msgid ""OpenStack Image service"" msgstr ""OpenStack Image service"" msgid ""OpenStack Networking"" msgstr ""OpenStack Networking"" msgid """" ""OpenStack Networking (neutron) allows you to create and attach interface "" ""devices managed by other OpenStack services to networks. Plug-ins can be "" ""implemented to accommodate different networking equipment and software, "" ""providing flexibility to OpenStack architecture and deployment."" msgstr """" ""OpenStack Networking (neutron) を使うと、他の OpenStack サービスにより管理さ"" ""れているインターフェースデバイスを作成して、ネットワークに接続できます。様々"" ""なネットワーク装置やネットワークソフトウェアに対応するプラグインを実装するこ"" ""とができ、 OpenStack のアーキテクチャーと環境に柔軟性をもたらします。"" msgid """" ""OpenStack Networking agent that provides DHCP services for virtual networks."" msgstr """" ""仮想ネットワーク向けに DHCP サービスを提供する OpenStack Networking エージェ"" ""ント。"" msgid """" ""OpenStack Networking agent that provides layer-2 connectivity for virtual "" ""networks."" msgstr """" ""仮想ネットワーク向けに L2 接続性を提供する OpenStack Networking エージェン"" ""ト。"" msgid """" ""OpenStack Networking agent that provides layer-3 (routing) services for "" ""virtual networks."" msgstr """" ""仮想ネットワーク向けに L3 (ルーティング) サービスを提供する OpenStack "" ""Networking エージェント。"" msgid """" ""OpenStack Networking agent that provides metadata services for instances."" msgstr """" ""インスタンスにメタデータサービスを提供する OpenStack Networking エージェン"" ""ト。"" msgid """" ""OpenStack Networking mainly interacts with OpenStack Compute to provide "" ""networks and connectivity for its instances."" msgstr """" ""OpenStack Networking は、おもに OpenStack Compute を連携して、コンピュートイ"" ""ンスタンスにネットワークと接続性を提供します。"" msgid ""OpenStack Networking plug-ins and agents"" msgstr ""OpenStack Networking プラグインおよびエージェント"" msgid ""OpenStack Object Storage"" msgstr ""OpenStack Object Storage"" msgid ""OpenStack Orchestration service"" msgstr ""OpenStack Orchestration サービス"" msgid ""OpenStack Services"" msgstr ""OpenStack のサービス"" msgid ""OpenStack Shared File Systems service"" msgstr ""OpenStack Shared File Systems サービス"" msgid ""OpenStack Telemetry service"" msgstr ""OpenStack Telemetry サービス"" msgid ""OpenStack code name"" msgstr ""OpenStack コード名"" msgid ""OpenStack dashboard"" msgstr ""OpenStack dashboard"" msgid ""OpenStack dashboard — :guilabel:`Admin` tab"" msgstr ""OpenStack dashboard — :guilabel:`管理` タブ"" msgid ""OpenStack dashboard — :guilabel:`Identity` tab"" msgstr ""OpenStack dashboard — :guilabel:`ユーザー管理` タブ"" msgid ""OpenStack dashboard — :guilabel:`Project` tab"" msgstr ""OpenStack dashboard — :guilabel:`プロジェクト` タブ"" msgid ""OpenStack dashboard — :guilabel:`Settings` tab"" msgstr ""OpenStack dashboard — :guilabel:`設定` タブ"" msgid ""OpenStack distribution packages"" msgstr ""OpenStack ディストリビューション"" msgid """" ""OpenStack is a cloud operating system that controls large pools of compute, "" ""storage, and networking resources throughout a data center, all managed "" ""through a dashboard that gives administrators control while empowering their "" ""users to provision resources through a web interface. OpenStack is an open "" ""source project licensed under the Apache License 2.0."" msgstr """" ""OpenStack は、データセンター全体のコンピュートリソース、ストレージリソース、"" ""ネットワークリソースの大規模なプールを制御する、クラウドオペレーティングシス"" ""テム。管理者はすべてダッシュボードから制御できる。ユーザーは Web インター"" ""フェースからリソースを配備できる。Apache License 2.0 に基づき許諾されるオープ"" ""ンソースのプロジェクト。"" msgid ""OpenStack mailing lists"" msgstr ""OpenStack メーリングリスト"" msgid """" ""OpenStack project that aims to make cloud services easier to consume and "" ""integrate with application development process by automating the source-to-"" ""image process, and simplifying app-centric deployment. The project name is "" ""solum."" msgstr """" ""クラウドサービスをより簡単に利用し、アプリケーション開発プロセスと統合するこ"" ""とを目的とする OpenStack プロジェクト。ソースからイメージまでの手順を自動化"" ""し、アプリケーション中心の開発を単純化します。プロジェクト名は solum。"" msgid """" ""OpenStack project that aims to produce an OpenStack messaging service that "" ""affords a variety of distributed application patterns in an efficient, "" ""scalable and highly-available manner, and to create and maintain associated "" ""Python libraries and documentation. The code name for the project is zaqar."" msgstr """" ""効率的、拡張可能、高可用な方法で、さまざまな分散アプリケーションのパターンを"" ""提供する、OpenStack messaging service を開発することを目指している OpenStack "" ""プロジェクト。また、関連する Python ライブラリーやドキュメントを作成してメン"" ""テナンスする。このプロジェクトのコード名は zaqar。"" msgid """" ""OpenStack project that produces a secret storage and generation system "" ""capable of providing key management for services wishing to enable "" ""encryption features. The code name of the project is barbican."" msgstr """" ""暗号化機能を有効化したいサービスに鍵管理機能を提供する機能を持つ、シークレッ"" ""トストレージと生成システムを開発する OpenStack プロジェクト。このプロジェクト"" ""の名前は barbican。"" msgid """" ""OpenStack project that produces a set of Python libraries containing code "" ""shared by OpenStack projects."" msgstr """" ""OpenStack プロジェクトに共有されるコードを含む Python ライブラリー群を作成す"" ""る OpenStack プロジェクト。"" msgid ""OpenStack project that provides a Clustering service."" msgstr ""クラスタリングサービスを提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides a Monitoring service."" msgstr ""モニタリングサービスを提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provides a Software Development Lifecycle Automation "" ""service."" msgstr """" ""ソフトウェア開発ライフサイクル自動化サービスを提供する OpenStack プロジェク"" ""ト。"" msgid ""OpenStack project that provides a dashboard, which is a web interface."" msgstr """" ""ダッシュボードを提供する OpenStack プロジェクト。Web インターフェース。"" msgid """" ""OpenStack project that provides a framework for performance analysis and "" ""benchmarking of individual OpenStack components as well as full production "" ""OpenStack cloud deployments. The code name of the project is rally."" msgstr """" ""各 OpenStack コンポーネント、本番の OpenStack 環境のパフォーマンス分析とベン"" ""チマーク向けにフレームワークを提供する OpenStack プロジェクト。このプロジェク"" ""トの名前は rally。"" msgid ""OpenStack project that provides a message service to applications."" msgstr """" ""メッセージサービスをアプリケーションに提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides a scalable data-processing stack and "" ""associated management interfaces. The code name for the project is sahara."" msgstr """" ""スケールアウト可能なデータ処理基盤と関連する管理インターフェースを提供する、"" ""OpenStack のプロジェクト。プロジェクトのコード名は sahara です。"" msgid """" ""OpenStack project that provides a set of services for management of "" ""application containers in a multi-tenant cloud environment. The code name of "" ""the project name is magnum."" msgstr """" ""マルチテナントクラウド環境において、アプリケーションコンテナーの管理サービス"" ""を提供する、OpenStack のプロジェクト。プロジェクトのコード名は magnum です。"" msgid """" ""OpenStack project that provides a simple YAML-based language to write "" ""workflows, tasks and transition rules, and a service that allows to upload "" ""them, modify, run them at scale and in a highly available manner, manage and "" ""monitor workflow execution state and state of individual tasks. The code "" ""name of the project is mistral."" msgstr """" ""ワークフロー、タスク、状態遷移ルールを書くための YAML ベースの言語を提供し、"" ""それらをアップロード、編集できるサービス、それらを大規模かつ高可用に実行でき"" ""るサービス、ワークフローの実行状態および個々のタスクの状態を管理および監視で"" ""きるサービスを提供する OpenStack プロジェクト。このプロジェクトのコード名は "" ""mistral。"" msgid ""OpenStack project that provides an Application catalog."" msgstr ""アプリケーションカタログを提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides an application catalog service so that users "" ""can compose and deploy composite environments on an application abstraction "" ""level while managing the application lifecycle. The code name of the project "" ""is murano."" msgstr """" ""ユーザーがアプリケーションのライフサイクルを管理しながら、アプリケーションの"" ""抽象的なレベルで合成環境を作成して配備できるよう、アプリケーションカタログ"" ""サービスを提供する OpenStack プロジェクト。このプロジェクトのコード名は "" ""murano。"" msgid """" ""OpenStack project that provides backup restore and disaster recovery as a "" ""service."" msgstr """" ""バックアップリストアとディザスターリカバリーをサービスとして提供する "" ""OpenStack プロジェクト。"" msgid ""OpenStack project that provides compute services."" msgstr ""コンピュートサービスを提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides database services to applications."" msgstr """" ""データベースサービスをアプリケーションに提供する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provides scalable, on demand, self service access to "" ""authoritative DNS services, in a technology-agnostic manner. The code name "" ""for the project is designate."" msgstr """" ""技術によらない方法で、権威 DNS サービスへの拡張可能、オンデマンド、セルフサー"" ""ビスのアクセスを提供する OpenStack プロジェクト。このプロジェクトのコード名"" ""は designate。"" msgid """" ""OpenStack project that provides shared file systems as service to "" ""applications."" msgstr """" ""共有ファイルシステムをアプリケーションに提供する OpenStack のプロジェクト。"" msgid ""OpenStack project that provides the Benchmark service."" msgstr ""Benchmark service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Governance service."" msgstr ""Governance service を提供する OpenStack プロジェクト。"" msgid ""OpenStack project that provides the Workflow service."" msgstr ""ワークフローサービスを提供する OpenStack プロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。"" msgid """" ""OpenStack project that provisions bare metal, as opposed to virtual, "" ""machines. The code name for the project is ironic."" msgstr """" ""マシンを仮想とみなして、ベアメタルに展開する OpenStack のプロジェクト。このプ"" ""ロジェクトのコード名は ironic です。"" msgid """" ""OpenStack project to provide Governance-as-a-Service across any collection "" ""of cloud services in order to monitor, enforce, and audit policy over "" ""dynamic infrastructure. The code name for the project is congress."" msgstr """" ""動的なインフラストラクチャー全体でポリシーを監視、強制、監査するために、さま"" ""ざまなクラウドサービス群にわたり、Governance as a Service を提供する "" ""OpenStack プロジェクト。このプロジェクトのコード名は congress。"" msgid """" ""OpenStack provides an Infrastructure-as-a-Service (:term:`IaaS`) solution "" ""through a set of interrelated services. Each service offers an application "" ""programming interface (:term:`API <Application Programming Interface "" ""(API)>`) that facilitates this integration. Depending on your needs, you can "" ""install some or all services."" msgstr """" ""OpenStack は、互いに連携する一連のサービス群により Infrastructure-as-a-"" ""Service (:term:`IaaS`) ソリューションを提供します。各サービスはこの統合を促"" ""す :term:`API <Application Programming Interface (API)>` を提供します。必要に"" ""応じて、いくつかのサービスをインストールすることもできますし、すべてのサービ"" ""スをインストールすることもできます。"" msgid ""OpenStack services"" msgstr ""OpenStack のサービス"" msgid ""OpenStack supports accessing the Amazon EC2 API through Compute."" msgstr """" ""OpenStack は、Compute 経由で Amazon EC2 API へのアクセスをサポートする。"" msgid """" ""OpenStack supports encryption technologies such as HTTPS, SSH, SSL, TLS, "" ""digital certificates, and data encryption."" msgstr """" ""OpenStack は、HTTPS、SSH、SSL、TLS、電子証明書、データ暗号化などの暗号化技術"" ""をサポートします。"" msgid """" ""OpenStack-on-OpenStack program. The code name for the OpenStack Deployment "" ""program."" msgstr """" ""OpenStack-on-OpenStack プログラム。OpenStack Deployment プログラムのコード"" ""名。"" msgid """" ""Opens all objects for an object server and verifies the MD5 hash, size, and "" ""metadata for each object."" msgstr """" ""あるオブジェクトサーバー用の全オブジェクトを開き、各オブジェクトの MD5 ハッ"" ""シュ、サイズ、メタデータを検証する。"" msgid """" ""Optionally, you can specify a name for the transfer by using the ``--display-"" ""name displayName`` parameter."" msgstr """" ""オプションとして、``--display-name displayName`` パラメーターを使用して転送の"" ""名前を指定することができます。"" msgid """" ""Orchestrates multiple composite cloud applications by using either the "" ""native HOT template format or the AWS CloudFormation template format, "" ""through both an OpenStack-native REST API and a CloudFormation-compatible "" ""Query API."" msgstr """" ""OpenStack ネイティブの REST API および CloudFormation 互換のクエリー API 経由"" ""で、ネイティブの HOT テンプレート形式または AWS CloudFormation テンプレート形"" ""式を使用することで、複数の混合クラウドアプリケーションを統合します。"" msgid """" ""Orchestrates the launching of templates and provides events back to the API "" ""consumer."" msgstr ""テンプレートの起動全体を指揮し、API 利用者に返すイベントを生成します。"" msgid ""Orchestration"" msgstr ""Orchestration"" msgid """" ""Organizes and stores objects in Object Storage. Similar to the concept of a "" ""Linux directory but cannot be nested. Alternative term for an Image service "" ""container format."" msgstr """" ""Object Storage でオブジェクトを整理して保存する。Linux のディレクトリと似てい"" ""るが、入れ子にできない。Image service のコンテナー形式の別名。"" msgid ""Oslo"" msgstr ""Oslo"" msgid ""Override environment variable values"" msgstr ""環境変数の値の上書き"" msgid ""Overview"" msgstr ""概要"" msgid ""PCI passthrough"" msgstr ""PCI パススルー"" msgid ""Package"" msgstr ""パッケージ"" msgid """" ""Pages that use HTML, JavaScript, and Cascading Style Sheets to enable users "" ""to interact with a web page or show simple animation."" msgstr """" ""ユーザーが Web ページと通信したり、簡単なアニメーションを表示したりするため"" ""に、HTML、JavaScript、CSS を使用するページ。"" msgid """" ""Passed to API requests and used by OpenStack to verify that the client is "" ""authorized to run the requested operation."" msgstr """" ""クライアントが要求した操作を実行する権限を持つことを検証するために、API リク"" ""エストに渡され、OpenStack により使用される。"" msgid """" ""Passes requests from clients to the appropriate workers and returns the "" ""output to the client after the job completes."" msgstr """" ""クライアントからのリクエストを適切なワーカーに渡す。ジョブ完了後、出力をクラ"" ""イアントに返す。"" msgid """" ""Performs housekeeping tasks on the large data store. The replication "" ""services ensure consistency and availability through the cluster. Other "" ""periodic processes include auditors, updaters, and reapers."" msgstr """" ""大規模なデータストアでハウスキーピング作業を実行します。複製サービスにより、"" ""クラスター全体で一貫性と可用性が確保されます。他の定期的なプロセスに "" ""auditor、 updater, reaper などがあります。"" msgid ""Persists until VM is terminated"" msgstr ""仮想マシンが削除されるまで存続"" msgid ""Persists until deleted"" msgstr ""削除されるまで存続"" msgid ""Physical host dedicated to running compute nodes."" msgstr ""コンピュートノード実行専用の物理ホスト。"" msgid ""Plans deployments."" msgstr ""デプロイメント計画の立案。"" msgid ""Platform-as-a-Service (PaaS)"" msgstr ""Platform-as-a-Service (PaaS)"" msgid ""Pluggable system of Hadoop installation engines."" msgstr ""プラグイン型の、Hadoop インストールエンジン。"" msgid """" ""Plugs and unplugs ports, creates networks or subnets, and provides IP "" ""addressing. These plug-ins and agents differ depending on the vendor and "" ""technologies used in the particular cloud. OpenStack Networking ships with "" ""plug-ins and agents for Cisco virtual and physical switches, NEC OpenFlow "" ""products, Open vSwitch, Linux bridging, and the VMware NSX product."" msgstr """" ""ポートの接続と切断、ネットワークやサブネットの作成、 IP アドレスの提供を行い"" ""ます。これらのプラグインとエージェントは、それぞれのクラウドにおいて使用され"" ""るベンダーと技術により異なります。OpenStack Networking には、 Cisco の仮想ス"" ""イッチと物理スイッチ、NEC OpenFlow 製品、Open vSwitch、Linux ブリッジ、"" ""VMware NSX 製品用のプラグインとエージェントが同梱されています。"" msgid """" ""Point in time since the last container and accounts database sync among "" ""nodes within Object Storage."" msgstr """" ""最新のコンテナーとアカウントのデータベースが Object Storage 内のノード間で同"" ""期された基準時間。"" msgid ""Possible use cases for data migration include:"" msgstr ""データ移動で考えられるユースケースは、以下のとおりです。"" msgid """" ""Predefined templates of Hadoop configurations with the ability to modify "" ""parameters."" msgstr """" ""Hadoop 設定の事前定義済みテンプレート。パラメーターを変更する機能があります。"" msgid ""Prerequisite"" msgstr ""前提"" msgid ""Prevents an image from being deleted."" msgstr ""イメージが削除されることを防ぎます。"" msgid """" ""Principal communications protocol in the internet protocol suite for "" ""relaying datagrams across network boundaries."" msgstr """" ""ネットワーク境界を越えてデータグラムを中継するための、インターネットプロトコ"" ""ルにおける中心的な通信プロトコル。"" msgid ""Prints the image size in a human-friendly format."" msgstr ""人間が理解しやすい形式でイメージの容量を表示します。"" msgid """" ""Processes client requests for VMs, updates Image service metadata on the "" ""registry server, and communicates with the store adapter to upload VM images "" ""from the back-end store."" msgstr """" ""仮想マシンに対するクライアントリクエスト、レジストリーサーバーにおける Image "" ""service のメタデータの更新、バックエンドストアから仮想マシンイメージをアップ"" ""ロードするためのストアアダプターを用いた通信を処理する。"" msgid """" ""Processing is fairly complex. Basically, the daemon accepts actions from the "" ""queue and performs a series of system commands such as launching a KVM "" ""instance and updating its state in the database."" msgstr """" ""処理内容はかなり複雑です。このデーモンはキューからアクションを受け取り、 KVM "" ""インスタンスの起動やデータベースの状態更新など一連のシステムコマンドを実行し"" ""ます。"" msgid ""Programming language used extensively in OpenStack."" msgstr ""OpenStack において幅広く使用されるプログラミング言語。"" msgid ""Project name"" msgstr ""プロジェクト名"" msgid """" ""Project name for OpenStack Network Information Service. To be merged with "" ""Networking."" msgstr """" ""OpenStack Network Information Service のプロジェクト名。Networking と統合予"" ""定。"" msgid ""Projects"" msgstr ""プロジェクト"" msgid """" ""Projects are organizational units in the cloud, and are also known as "" ""tenants or accounts. Each user is a member of one or more projects. Within a "" ""project, a user creates and manages instances."" msgstr """" ""プロジェクトは、クラウドにおける組織単位です。テナントやアカウントとしても呼"" ""ばれます。各ユーザーは、1 つ以上のプロジェクトのメンバーです。ユーザーは、プ"" ""ロジェクト内でインスタンスの作成や管理を行います。"" msgid """" ""Projects represent the base unit of “ownership” in OpenStack, in that all "" ""resources in OpenStack should be owned by a specific project. In OpenStack "" ""Identity, a project must be owned by a specific domain."" msgstr """" ""プロジェクトは OpenStack における「所有権」の基本的な単位で、OpenStack におけ"" ""るあらゆるリソースは何らかのテナントに属する。 OpenStack Identity では、プロ"" ""ジェクトは特定のドメインに何らかのドメインに属する。"" msgid """" ""Protocol that encapsulates a wide variety of network layer protocols inside "" ""virtual point-to-point links."" msgstr """" ""仮想のポイントツーポイントリンク内で、さまざまなネットワーク層のプロトコルを"" ""カプセル化するプロトコル。"" msgid """" ""Provide as much detail as possible in the description. Paste in your command "" ""output or stack traces, links to screen shots, and any other information "" ""which might be useful."" msgstr """" ""できるだけ詳細な情報を記入してください。コマンドの出力結果やスタックトレー"" ""ス、スクリーンショットへのリンク、その他有用な情報などがいいでしょう。"" msgid """" ""Provided by Compute in the form of cloudpipes, specialized instances that "" ""are used to create VPNs on a per-project basis."" msgstr """" ""Compute では cloudpipe の形で提供される。 cloudpipe では、特別なインスタンス"" ""を使って、プロジェクト毎に VPN が作成される。"" msgid ""Provided in Compute through the system usage data facility."" msgstr ""システム使用状況データ機能経由で Compute において提供される。"" msgid """" ""Provides Shared File System service via nfs, cifs, glusterfs, or hdfs "" ""protocol"" msgstr """" ""NFS, CIFS, GlusterFS, HDFS プロトコル経由で共有ファイルシステムが提供される"" msgid """" ""Provides a method of allocating space on mass-storage devices that is more "" ""flexible than conventional partitioning schemes."" msgstr """" ""伝統的なパーティションスキーマよりも柔軟に、大規模ストレージデバイスに領域を"" ""割り当てる方式を提供する。"" msgid """" ""Provides a predefined list of actions that the user can perform, such as "" ""start or stop VMs, reset passwords, and so on. Supported in both Identity "" ""and Compute and can be configured using the horizon dashboard."" msgstr """" ""仮想マシンの起動や停止、パスワードの初期化など、ユーザーが実行できる操作の事"" ""前定義済み一覧を提供する。Identity と Compute においてサポートされる。ダッ"" ""シュボードを使用して設定できる。"" msgid """" ""Provides a proxy for accessing running instances through a SPICE connection. "" ""Supports browser-based HTML5 client."" msgstr """" ""SPICE コネクション経由で実行中のインスタンスのアクセスへプロキシーを提供しま"" ""す。ブラウザーベースの HTML5 クライアントをサポートします。"" msgid """" ""Provides a proxy for accessing running instances through a VNC connection. "" ""Supports an OpenStack-specific Java client."" msgstr """" ""VNC コネクション経由で実行中のインスタンスのアクセスへプロキシーを提供しま"" ""す。 OpenStack 固有の Java クライアントをサポートします。"" msgid """" ""Provides a proxy for accessing running instances through a VNC connection. "" ""Supports browser-based novnc clients."" msgstr """" ""VNC コネクション経由で実行中のインスタンスへアクセスするプロキシーを提供しま"" ""す。ブラウザーベースの novnc クライアントをサポートします。"" msgid """" ""Provides a web-based self-service portal to interact with underlying "" ""OpenStack services, such as launching an instance, assigning IP addresses "" ""and configuring access controls."" msgstr """" ""インスタンスの起動、IP アドレスの割り当て、アクセス制御の設定など、 "" ""OpenStack サービスを操作するために、ウェブベースのセルフサービスポータルを提"" ""供します。"" msgid """" ""Provides an OpenStack-native RESTful API that supports JSON to provision and "" ""manage Trove instances."" msgstr """" ""Trove インスタンスの作成と管理を行うための、JSON に対応した OpenStack 固有の "" ""RESTful API を提供します。"" msgid """" ""Provides an authentication and authorization service for other OpenStack "" ""services. Provides a catalog of endpoints for all OpenStack services."" msgstr """" ""他の OpenStack サービスに対して認証および認可サービスを提供します。すべての "" ""OpenStack サービスに対してエンドポイントのカタログを提供します。"" msgid """" ""Provides an interface to the underlying Open vSwitch service for the "" ""Networking plug-in."" msgstr """" ""Networking のプラグインに対して、バックエンドの Open vSwitch サービスへのイン"" ""ターフェースを提供する。"" msgid """" ""Provides capabilities to provision and scale Hadoop clusters in OpenStack by "" ""specifying parameters like Hadoop version, cluster topology and nodes "" ""hardware details."" msgstr """" ""OpenStack においてスケール可能な Hadoop クラスターを展開する機能を提供しま"" ""す。Hadoop のバージョン、クラスタートポロジー、ノードのハードウェアの詳細など"" ""のパラメーターを指定します。"" msgid """" ""Provides data redundancy and fault tolerance by creating copies of Object "" ""Storage objects, accounts, and containers so that they are not lost when the "" ""underlying storage fails."" msgstr """" ""Object Storage のオブジェクト、アカウント、コンテナーのコピーを作成すること"" ""で、データ冗長性や耐障害性を実現する。これにより、バックエンドのストレージが"" ""故障した場合でもデータは失わない。"" msgid """" ""Provides logical partitioning of Compute resources in a child and parent "" ""relationship. Requests are passed from parent cells to child cells if the "" ""parent cannot provide the requested resource."" msgstr """" ""親子関係で Compute リソースの論理パーティションを提供する。親セルが要求された"" ""リソースを提供できない場合、親セルからのリクエストは子セルに渡される。"" msgid """" ""Provides persistent block storage to running instances. Its pluggable driver "" ""architecture facilitates the creation and management of block storage "" ""devices."" msgstr """" ""実行中のインスタンスに永続的なブロックストレージを提供します。そのプラグイン"" ""可能なドライバーアーキテクチャーにより、ブロックストレージデバイスの作成と管"" ""理が簡単に行えます。"" msgid """" ""Provides scalable and reliable Cloud Database-as-a-Service functionality for "" ""both relational and non-relational database engines."" msgstr """" ""リレーショナルデータベースと非リレーショナルデータベースの両エンジン用にス"" ""ケール可能かつ信頼できるクラウド Database-as-a-Service を提供します。"" msgid ""Provides support for NexentaStor devices in Compute."" msgstr ""Compute において NexentaStor デバイスのサポートを提供する。"" msgid ""Provides support for Open vSwitch in Networking."" msgstr ""Networking で Open vSwitch のサポートを提供する。"" msgid ""Provides support for VMware NSX in Neutron."" msgstr ""Neutron における VMware NSX サポートを提供する。"" msgid """" ""Provides support for new and specialized types of back-end storage for the "" ""Block Storage volume manager."" msgstr """" ""Block Storage のボリュームマネージャーに対して、新しい特別な種類のバックエン"" ""ドストレージのサポートを提供する。"" msgid """" ""Provides to the consumer the ability to deploy applications through a "" ""programming language or tools supported by the cloud platform provider. An "" ""example of Platform-as-a-Service is an Eclipse/Java programming platform "" ""provided with no downloads required."" msgstr """" ""クラウドプラットフォームプロバイダーによりサポートされるプログラミング言語や"" ""ツールを用いてアプリケーションを配備する機能を利用者に提供する。PaaS の例は、"" ""ダウンロードする必要がない、Eclipse/Java プログラミングプラットフォームです。"" msgid ""Proxy servers (swift-proxy-server)"" msgstr ""プロキシサーバー (swift-proxy-server)"" msgid """" ""Publishes collected data to various targets including data stores and "" ""message queues."" msgstr """" ""収集したデータを、データストアやメッセージキューなどの様々な宛先に発行しま"" ""す。"" msgid ""Puppet"" msgstr ""Puppet"" msgid ""Python"" msgstr ""Python"" msgid ""Python 2.7 or later"" msgstr ""Python 2.7 以降"" msgid ""QEMU Copy On Write 2 (QCOW2)"" msgstr ""QEMU Copy On Write 2 (QCOW2)"" msgid """" ""QEMU is a generic and open source machine emulator and virtualizer. One of "" ""the hypervisors supported by OpenStack, generally used for development "" ""purposes."" msgstr """" ""QEMU は、汎用のオープンソースのマシンエミュレーターと仮想化ソフトウェアです。"" ""OpenStack がサポートするハイパーバイザーの一つ。一般に、開発目的で使用され"" ""る。"" msgid ""Qpid"" msgstr ""Qpid"" msgid ""Quick EMUlator (QEMU)"" msgstr ""Quick EMUlator (QEMU)"" msgid ""RADOS Block Device (RBD)"" msgstr ""RADOS Block Device (RBD)"" msgid ""RAM filter"" msgstr ""RAM フィルター"" msgid ""RAM overcommit"" msgstr ""RAM オーバーコミット"" msgid """" ""RDO, openSUSE, SUSE Linux Enterprise, Debian, and Ubuntu have client "" ""packages that can be installed without ``pip``."" msgstr """" ""RDO、openSUSE、SUSE Linux Enterprise、Debian、Ubuntu は、``pip`` なしで利用で"" ""きるクライアントパッケージがあります。"" msgid ""REST API"" msgstr ""REST API"" msgid ""RESTful"" msgstr ""RESTful"" msgid ""RPC driver"" msgstr ""RPC ドライバー"" msgid ""RXTX cap"" msgstr ""RXTX キャップ"" msgid ""RXTX quota"" msgstr ""RXTX クォータ"" msgid ""RabbitMQ"" msgstr ""RabbitMQ"" msgid ""Rackspace Cloud Files"" msgstr ""Rackspace Cloud Files"" msgid ""Rating service"" msgstr ""Rating サービス"" msgid ""Rating service."" msgstr ""Rating サービス。"" msgid ""Recon"" msgstr ""recon"" msgid ""Red Hat Enterprise Linux (RHEL)"" msgstr ""Red Hat Enterprise Linux (RHEL)"" msgid """" ""Reducing the size of files by special encoding, the file can be decompressed "" ""again to its original content. OpenStack supports compression at the Linux "" ""file system level but does not support compression for things such as Object "" ""Storage objects or Image service VM images."" msgstr """" ""特別なエンコーディングによりファイル容量を減らすこと。このファイルは、元の内"" ""容に展開できます。OpenStack は、Linux ファイルシステムレベルの圧縮をサポート"" ""しますが、Object Storage のオブジェクトや Image service の仮想マシンイメージ"" ""などの圧縮をサポートしません。"" msgid ""Released as open source by NASA in 2010 and is the basis for Compute."" msgstr """" ""2010 年に NASA によりオープンソースとしてリリースされた。Compute の基になっ"" ""た。"" msgid """" ""Released as open source by Rackspace in 2010; the basis for Object Storage."" msgstr """" ""Rackspace により 2010 年にオープンソースとして公開された。Object Storage の"" ""ベース。"" msgid ""Reliable, Autonomic Distributed Object Store"" msgstr ""Reliable, Autonomic Distributed Object Store"" msgid ""Remote Procedure Call (RPC)"" msgstr ""Remote Procedure Call (RPC)"" msgid """" ""Removes all data on the server and replaces it with the specified image. "" ""Server ID and IP addresses remain the same."" msgstr """" ""サーバからすべてのデータを消去し、特定のイメージで置き換える。サーバのIDとIP"" ""アドレスは変更されない。"" msgid ""Represents a virtual, isolated OSI layer-2 subnet in Networking."" msgstr ""Networking における仮想の分離された OSI L-2 サブネットを表す。"" msgid ""Resize a volume"" msgstr ""ボリュームのリサイズ"" msgid """" ""Resize the volume by passing the volume ID and the new size (a value greater "" ""than the old one) as parameters:"" msgstr """" ""パラメーターとしてボリューム ID と新しいサイズ (以前のボリュームよりも大きい"" ""サイズ) を指定して、ボリュームをリサイズします。"" msgid ""Restart Apache for this change to take effect."" msgstr ""Apache を再起動して、この変更を反映します。"" msgid ""Restart the Apache service."" msgstr ""Apache サービスを再起動します。"" msgid ""Role Based Access Control (RBAC)"" msgstr ""Role Based Access Control (RBAC)"" msgid ""Routes information between the Block Storage processes."" msgstr ""Block Storage プロセス間で情報を転送します。"" msgid ""Routes information between the Shared File Systems processes."" msgstr ""Shared File Systems プロセス間の情報を中継します。"" msgid ""Run the following command to discover the version number for a client:"" msgstr """" ""クライアントのバージョン番号を確認するために、以下のコマンドを実行します。"" msgid ""Runs automated tests against the core OpenStack API; written in Rails."" msgstr """" ""コア OpenStack API に対して自動テストを実行する。Rails で書かれている。"" msgid """" ""Runs on a central management server and determines when to fire alarms. The "" ""alarms are generated based on defined rules against events, which are "" ""captured by the Telemetry Data Collection service's notification agents."" msgstr """" ""中央管理サーバーで実行され、通知を発動するタイミングを判断します。通知は、イ"" ""ベントに対して定義されたルールに基づいて生成されます。これは、Telemetry Data "" ""Collection サービスの通知エージェントにより収集されます。"" msgid """" ""Runs on a central management server to poll for resource utilization "" ""statistics for resources not tied to instances or compute nodes. Multiple "" ""agents can be started to scale service horizontally."" msgstr """" ""中央管理サーバーで実行され、インスタンスやコンピュートノードに関連付いていな"" ""いリソースの使用統計をポーリングします。複数のエージェントを実行し、水平に"" ""サービスをスケールさせることができます。"" msgid """" ""Runs on a central management server(s) and consumes messages from the "" ""message queue(s) to build event and metering data."" msgstr """" ""中央管理サーバーで実行され、メッセージキューからメッセージを読みだして、イベ"" ""ントや計測データを作成します。"" msgid """" ""Runs on central management server(s) and dispatches collected telemetry data "" ""to a data store or external consumer without modification."" msgstr """" ""中央管理サーバーで実行され、収集した計測データを、データストアや通知を使わな"" ""い外部の使用者に送り出します。"" msgid """" ""Runs on each compute node and polls for resource utilization statistics. "" ""There may be other types of agents in the future, but for now our focus is "" ""creating the compute agent."" msgstr """" ""各コンピュートノードで実行され、リソース使用統計をポーリングします。将来的に"" ""は他の種類のエージェントも作成されるかもしれませんが、現時点ではコンピュート"" ""エージェントに注力しています。"" msgid """" ""Runs on one or more central management servers to allow alarms to be set "" ""based on the threshold evaluation for a collection of samples."" msgstr """" ""1つ以上の中央管理サーバーで実行され、収集したサンプルデータに対する閾値の評価"" ""を行い、アラームをセットします。"" msgid """" ""Runs on one or more central management servers to determine when alarms fire "" ""due to the associated statistic trend crossing a threshold over a sliding "" ""time window."" msgstr """" ""1つ以上の中央管理サーバーで実行され、関連する統計の傾向がスライディングタイム"" ""ウィンドウで閾値に違反した場合にアラームを発行するかを判定します。"" msgid """" ""Runs on one or more central management servers to provide access to the "" ""alarm information stored in the data store."" msgstr """" ""1 つ以上の中央管理サーバーで実行され、データストアへのデータアクセス手段を提"" ""供します。"" msgid """" ""Runs on one or more central management servers to provide data access from "" ""the data store."" msgstr """" ""1つ以上の中央管理サーバーで実行され、データストアへのデータアクセス手段を提供"" ""します。"" msgid """" ""Runs on the host, and receives messages from guest instances that want to "" ""update information on the host."" msgstr """" ""ホストで実行され、ホストにおいてアップデートしたい情報のメッセージをゲストイ"" ""ンスタンスから受信します。"" msgid ""Runs operating systems and provides scratch space"" msgstr ""オペレーティングシステムを実行し、新規領域を提供する"" msgid """" ""Runs within the guest instance. Manages and performs operations on the "" ""database itself."" msgstr """" ""ゲストインスタンスの中で実行します。データベース自身の処理を管理、実行しま"" ""す。"" msgid ""S3"" msgstr ""S3"" msgid ""SAML assertion"" msgstr ""SAML アサーション"" msgid ""SELinux"" msgstr ""SELinux"" msgid """" ""SINA standard that defines a RESTful API for managing objects in the cloud, "" ""currently unsupported in OpenStack."" msgstr """" ""クラウドにあるオブジェクトを管理するための RESTful API を定義する SINA 標準。"" ""現在 OpenStack ではサポートされていない。"" msgid ""SPICE"" msgstr ""SPICE"" msgid ""SQL database"" msgstr ""SQL データベース"" msgid ""SQL-Alchemy"" msgstr ""SQL-Alchemy"" msgid ""SQLite"" msgstr ""SQLite"" msgid ""SUSE Linux Enterprise Server (SLES)"" msgstr ""SUSE Linux Enterprise Server (SLES)"" msgid """" ""Script that initializes the building of the ring file, takes daemon names as "" ""parameter and offers commands. Documented in http://docs.openstack.org/"" ""developer/swift/admin_guide.html#managing-services."" msgstr """" ""リングファイルを初期化し、パラメーターとしてデーモンの名前を受け付け、コマン"" ""ドを提供するスクリプトです。ドキュメントは http://docs.openstack.org/"" ""developer/swift/admin_guide.html#managing-services にあります。"" msgid ""See API endpoint."" msgstr ""API エンドポイントを参照。"" msgid ""See access control list."" msgstr ""「アクセス制御リスト」参照。"" msgid """" ""Selects the optimal storage provider node on which to create the share. A "" ""similar component to the ``cinder-scheduler``."" msgstr """" ""共有を作成するのに適切なストレージプロバイダーノードを選択します。 ``cinder-"" ""scheduler`` と同様のコンポーネントです。"" msgid """" ""Selects the optimal storage provider node on which to create the volume. A "" ""similar component to the ``nova-scheduler``."" msgstr """" ""ボリュームを作成するのに適切なストレージプロバイダーノードを選択します。 "" ""``nova-scheduler`` と同様のコンポーネントです。"" msgid """" ""Send the volume transfer ID and authorization key to the new owner (for "" ""example, by email)."" msgstr """" ""ボリューム転送 ID と認証キーを新しい所有者に送信します (例: 電子メール)。"" msgid ""Server"" msgstr ""サーバー"" msgid ""Service"" msgstr ""サービス"" msgid ""Service Level Agreement (SLA)"" msgstr ""サービス水準合意 (SLA; Service Level Agreement)"" msgid ""Set environment variables using the OpenStack RC file"" msgstr ""OpenStack RC ファイルを用いた環境変数の設定"" msgid """" ""Set of bits that make up a single character; there are usually 8 bits to a "" ""byte."" msgstr ""1 つの文字を構成するビットの組。通常は 8 ビットで 1 バイトになる。"" msgid """" ""Set the HTML title, which appears at the top of the browser window, by "" ""adding the following line to ``local_settings.py``:"" msgstr """" ""``local_settings.py`` に以下の行を追加して、HTML タイトルを設定します。 HTML "" ""タイトルは、ブラウザーウィンドウの上部に表示されます。"" msgid """" ""Setting for the Compute RabbitMQ message delivery mode; can be set to either "" ""transient or persistent."" msgstr """" ""Compute RabbitMQ メッセージ配信モード用設定。transient（一時）又は "" ""persistent（永続）のいずれかを設定できる。"" msgid ""Shared File Systems API"" msgstr ""共有ファイルシステム API"" msgid ""Shared File Systems service"" msgstr ""Shared File Systems サービス"" msgid ""Shared file systems"" msgstr ""共有ファイルシステム"" msgid ""Sheepdog"" msgstr ""Sheepdog"" msgid ""Show host usage statistics"" msgstr ""ホストの使用統計の表示"" msgid ""Show information for your volume:"" msgstr ""お使いのボリュームの情報を表示します。"" msgid ""Show instance usage statistics"" msgstr ""インスタンスの使用統計の表示"" msgid ""Show usage statistics for hosts and instances"" msgstr ""ホストおよびインスタンスの使用統計の表示"" msgid """" ""Similar to :option:`--location` in usage, but indicates that the image "" ""server should immediately copy the data and store it in its configured image "" ""store."" msgstr """" ""使用方法は :option:`--location` に似ていますが、イメージサーバーはすぐにデー"" ""タをコピーして設定済みのイメージストアに保存する必要があると指定します。"" msgid """" ""Similar to the ``nova-compute`` service, accepts networking tasks from the "" ""queue and manipulates the network. Performs tasks such as setting up "" ""bridging interfaces or changing IPtables rules."" msgstr """" ""``nova-compute`` と似ています。 キューからネットワーク関係のタスクを受け取"" ""り、ネットワーク操作を行ないます。例えば、ブリッジインターフェースの準備や "" ""iptables ルールの変更などのタスクを行います。"" msgid ""Simple Cloud Identity Management (SCIM)"" msgstr ""Simple Cloud Identity Management (SCIM)"" msgid """" ""Since the installation process compiles source files, this requires the "" ""related Python development package for your operating system and "" ""distribution."" msgstr """" ""インストール中にソースファイルをコンパイルするため、お使いのオペレーティング"" ""システム環境に応じた、関連する Python 開発パッケージが必要になります。"" msgid ""Single-root I/O Virtualization (SR-IOV)"" msgstr ""Single-root I/O Virtualization (SR-IOV)"" msgid ""Site colors"" msgstr ""サイトのカラー"" msgid ""Sizing based on need"" msgstr ""必要なサイズを指定"" msgid ""Sizings based on need"" msgstr ""必要なサイズを指定"" msgid ""SmokeStack"" msgstr ""SmokeStack"" msgid """" ""Soft limit on the amount of network traffic a Compute VM instance can send "" ""and receive."" msgstr """" ""Compute の仮想マシンインスタンスが送受信できるネットワーク通信量のソフト制"" ""限。"" msgid ""Software Development Lifecycle Automation service"" msgstr ""ソフトウェア開発ライフサイクル自動化サービス"" msgid """" ""Software component providing the actual implementation for Networking APIs, "" ""or for Compute APIs, depending on the context."" msgstr """" ""利用形態に応じた、Networking API や Compute API の具体的な実装を提供するソフ"" ""トウェアコンポーネント。"" msgid """" ""Software that arbitrates and controls VM access to the actual underlying "" ""hardware."" msgstr ""VM のアクセスを実際の下位ハードウェアに仲介して制御するソフトウェア。"" msgid """" ""Software that enables multiple VMs to share a single physical NIC within "" ""Compute."" msgstr """" ""複数の仮想マシンが Compute 内で単一の物理 NIC を共有するためのソフトウェア。"" msgid """" ""Software that runs on a host or node and provides the features and functions "" ""of a hardware-based network switch."" msgstr """" ""ホストやノードで実行され、ハードウェアのネットワークスイッチの機能を提供する"" ""ソフトウェア。"" msgid ""SolidFire Volume Driver"" msgstr ""SolidFire Volume Driver"" msgid ""Some tips:"" msgstr ""使いこなすヒント:"" msgid ""Something you must be aware of before proceeding."" msgstr ""続行する前に注意が必要なものです。"" msgid """" ""Special tenant that contains all services that are listed in the catalog."" msgstr ""カタログに一覧化される全サービスを含む特別なテナント。"" msgid """" ""Specification for managing identity in the cloud, currently unsupported by "" ""OpenStack."" msgstr """" ""クラウドで認証情報を管理するための仕様。現在、OpenStack によりサポートされて"" ""いない。"" msgid """" ""Specifies additional requirements when Compute determines where to start a "" ""new instance. Examples include a minimum amount of network bandwidth or a "" ""GPU."" msgstr """" ""Compute が新しいインスタンスを起動する場所を判断するとき、追加の要件を指定す"" ""る。例えば、ネットワーク帯域の最小量、GPU などがある。"" msgid """" ""Specifies the authentication source used by Image service or Identity. In "" ""the Database service, it refers to the extensions implemented for a data "" ""store."" msgstr """" ""Image サービスや Identity サービスが使用する認証元を指定する。 Database サー"" ""ビスでは、データストア用に実装された拡張を指す。"" msgid ""StackTach"" msgstr ""StackTach"" msgid ""Standard for packaging VM images. Supported in OpenStack."" msgstr ""仮想マシンイメージのパッケージ化の標準。OpenStack でサポートされる。"" msgid ""StaticWeb"" msgstr ""StaticWeb"" msgid ""Storage concepts"" msgstr ""ストレージの考え方"" msgid """" ""Storage protocol similar in concept to TCP/IP; encapsulates SCSI commands "" ""and data."" msgstr """" ""TCP/IP に似た概念のストレージプロトコル。SCSI コマンドとデータをカプセル化す"" ""る。"" msgid """" ""Storage protocol that encapsulates SCSI frames for transport over IP "" ""networks."" msgstr """" ""IP ネットワーク上で転送するために、SCSI フレームをカプセル化するストレージプ"" ""ロトコル。"" msgid ""Storage repository for image files"" msgstr ""イメージファイル用のストレージリポジトリー"" msgid """" ""Storage ring build and rebalance utility. Documented in http://docs."" ""openstack.org/developer/swift/admin_guide.html#managing-the-rings."" msgstr """" ""ストレージリングの作成とリバランスを行うツール。ドキュメントは http://docs."" ""openstack.org/developer/swift/admin_guide.html#managing-the-rings にありま"" ""す。"" msgid ""Storage types"" msgstr ""ストレージ種別"" msgid ""Stores CephFS metadata."" msgstr ""CephFS メタデータを格納する。"" msgid """" ""Stores and retrieves arbitrary unstructured data objects via a RESTful, HTTP "" ""based API. It is highly fault tolerant with its data replication and scale-"" ""out architecture. Its implementation is not like a file server with "" ""mountable directories. In this case, it writes objects and files to multiple "" ""drives, ensuring the data is replicated across a server cluster."" msgstr """" ""RESTful な HTTP ベースの API 経由で任意の非構造データオブジェクトを保存および"" ""取得します。データ複製による高い耐障害性と、スケールアウトアーキテクチャーを"" ""持ちます。その実装は、マウント可能なディレクトリを持つファイルサーバーとは異"" ""なります。オブジェクトやファイルを複数のドライブに書き込み、データがサーバク"" ""ラスター間で複製されていることを保証します。"" msgid """" ""Stores and retrieves virtual machine disk images. OpenStack Compute makes "" ""use of this during instance provisioning."" msgstr """" ""仮想マシンディスクイメージを保存および取得します。OpenStack Compute がインス"" ""タンスの配備中に使用します。"" msgid """" ""Stores image metadata and you can choose your database depending on your "" ""preference. Most deployments use MySQL or SQLite."" msgstr """" ""イメージのメタデータを保存します。お好みのデータベースを選択できます。多くの"" ""環境では MySQL か SQLite を使用します。"" msgid """" ""Stores most build-time and run-time states for a cloud infrastructure, "" ""including:"" msgstr """" ""クラウドインフラの、作成中、実行中のほとんどの状態を保持します。例えば以下の"" ""ような情報があります。"" msgid """" ""Stores, processes, and retrieves metadata about images. Metadata includes "" ""items such as size and type."" msgstr """" ""イメージに関するメタデータの保存、処理、取得を行います。メタデータは容量や形"" ""式などの項目があります。"" msgid """" ""String of text known only by the user; used along with an access key to make "" ""requests to the Compute API."" msgstr """" ""ユーザーのみが知っているテキスト文字列。リクエストを Compute API に発行するた"" ""めに、アクセスキーと一緒に使用される。"" msgid ""Subdivides physical CPUs. Instances can then use those divisions."" msgstr """" ""物理 CPU を分割する。インスタンスは、これらの分割したものを使用できる。"" msgid ""Support for different Hadoop distributions:"" msgstr ""さまざまな Hadoop ディストリビューションをサポートしています。"" msgid ""Supported model values"" msgstr ""サポートされるモデルの値"" msgid ""Supports interaction with VMware products in Compute."" msgstr ""Compute で VMware 製品の操作をサポートする。"" msgid """" ""Takes a virtual machine instance request from the queue and determines on "" ""which compute server host it runs."" msgstr """" ""仮想マシンインスタンスの作成要求を受け取ってキューイングし、インスタンスをど"" ""のコンピュートサーバーホストで実行するかを決定します。"" msgid ""Telemetry"" msgstr ""Telemetry"" msgid ""Telemetry Alarming service"" msgstr ""Telemetry Alarming サービス"" msgid ""Telemetry Data Collection service"" msgstr ""Telemetry Data Collection サービス"" msgid ""Telemetry v3"" msgstr ""Telemetry v3"" msgid ""TempAuth"" msgstr ""TempAuth"" msgid ""TempURL"" msgstr ""TempURL"" msgid ""Tempest"" msgstr ""Tempest"" msgid ""Tenant API"" msgstr ""テナント API"" msgid """" ""Term for an Object Storage process that runs for a long time. Can indicate a "" ""hung process."" msgstr """" ""長時間動作している Object Storage のプロセスを指す用語。ハングしたプロセスを"" ""意味する可能性もある。"" msgid """" ""Term used in the OSI network architecture for the data link layer. The data "" ""link layer is responsible for media access control, flow control and "" ""detecting and possibly correcting errors that may occur in the physical "" ""layer."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるデータリンク層に使用される用語。デー"" ""タリンク層は、メディアアクセス制御、フロー制御、物理層で発生する可能性のある"" ""エラー検知、できる限りエラー訂正に責任を持つ。"" msgid """" ""Term used in the OSI network architecture for the network layer. The network "" ""layer is responsible for packet forwarding including routing from one node "" ""to another."" msgstr """" ""OSI ネットワークアーキテクチャーにおけるネットワーク層に使用される用語。ネッ"" ""トワーク層は、パケット転送、あるノードから別のノードへのルーティングに責任を"" ""持つ。"" msgid ""The :command:`delete` command does not return any output."" msgstr "":command:`delete` コマンドは何も出力しません。"" msgid ""The :command:`extend` command does not return any output."" msgstr "":command:`extend` コマンドは何も出力しません。"" msgid ""The :command:`volume-detach` command does not return any output."" msgstr "":command:`volume-detach` コマンドは何も出力しません。"" msgid """" ""The API used to access the OpenStack Identity service provided through "" ""keystone."" msgstr """" ""keystone が提供する OpenStack Identity サービスへのアクセスに使用される API。"" msgid ""The Amazon commercial block storage product."" msgstr ""Amazon のブロックストレージの商用製品。"" msgid ""The Amazon commercial compute product, similar to Compute."" msgstr ""Amazon の商用コンピュート製品。Compute と似ている。"" msgid """" ""The Apache Software Foundation supports the Apache community of open-source "" ""software projects. These projects provide software products for the public "" ""good."" msgstr """" ""The Apache Software Foundation は、オープンソースソフトウェアプロジェクトの "" ""Apache コミュニティーをサポートする。これらのプロジェクトは、公共財のためにソ"" ""フトウェア製品を提供する。"" msgid ""The Block Storage driver for the SolidFire iSCSI storage appliance."" msgstr """" ""SolidFire iSCSI ストレージアプライアンス向けの Block Storage ドライバー。"" msgid ""The Block Storage service consists of the following components:"" msgstr ""Block Storage サービスは、以下のコンポーネントから構成されます。"" msgid """" ""The Border Gateway Protocol is a dynamic routing protocol that connects "" ""autonomous systems. Considered the backbone of the Internet, this protocol "" ""connects disparate networks to form a larger network."" msgstr """" ""Border Gateway Protocol は、自律システムを接続する、動的ルーティングプロトコ"" ""ルである。インターネットのバックボーンと比べて、このプロトコルは、より大きな"" ""ネットワークを形成するために、異なるネットワークを接続する。"" msgid ""The Ceph storage daemon."" msgstr ""Ceph ストレージデーモン。"" msgid """" ""The Compute RabbitMQ message exchange that remains active when the server "" ""restarts."" msgstr """" ""サーバーの再起動時に有効なままになる Compute の RabbitMQ メッセージ交換。"" msgid """" ""The Compute VM scheduling algorithm that attempts to start a new VM on the "" ""host with the least amount of load."" msgstr """" ""新規仮想マシンを合計負荷の最も低いホストで起動しようとする、Compute 仮想マシ"" ""ンスケジューリングアルゴリズム。"" msgid """" ""The Compute component that chooses suitable hosts on which to start VM "" ""instances."" msgstr """" ""仮想マシンインスタンスを起動するために適切なホストを選択する Compute のコン"" ""ポーネント。"" msgid """" ""The Compute component that contains a list of the current capabilities of "" ""each host within the cell and routes requests as appropriate."" msgstr """" ""セル内にある各ホストの現在のキャパシティー一覧を持ち、リクエストを適切にルー"" ""ティングする、Compute のコンポーネント。"" msgid """" ""The Compute component that gives IP addresses to authorized nodes and "" ""assumes DHCP, DNS, and routing configuration and services are provided by "" ""something else."" msgstr """" ""認可されたノードに IP アドレスを割り当てる Compute のコンポーネント。DHCP、"" ""DNS、ルーティングの設定とサービスが別の何かにより提供されることを仮定してい"" ""る。"" msgid """" ""The Compute component that manages various network components, such as "" ""firewall rules, IP address allocation, and so on."" msgstr """" ""ファイアウォールのルール、IP アドレスの割り当てなど、さまざまなネットワークの"" ""コンポーネントを管理する、Compute のコンポーネント。"" msgid """" ""The Compute component that provides dnsmasq (DHCP, DNS, BOOTP, TFTP) and "" ""radvd (routing) services."" msgstr """" ""dnsmasq (DHCP、DNS、BOOTP、TFTP) や radvd (ルーティング) のサービスを提供す"" ""る Compute のコンポーネント。"" msgid """" ""The Compute component that runs on each compute node and manages the VM "" ""instance lifecycle, including run, reboot, terminate, attach/detach volumes, "" ""and so on. Provided by the nova-compute daemon."" msgstr """" ""各ノードで動作し、仮想マシンインスタンスのライフサイクル (実行、再起動、終"" ""了、ボリュームの接続や切断など) を管理する、Compute のコンポーネント。nova-"" ""compute デーモンにより提供される。"" msgid """" ""The Compute direct exchanges, fanout exchanges, and topic exchanges use this "" ""key to determine how to process a message; processing varies depending on "" ""exchange type."" msgstr """" ""Compute の直接交換、ファンアウト交換、トピック交換は、このキーを使用して、"" ""メッセージを処理する方法を判断する。処理内容は交換形式に応じて変化する。"" msgid """" ""The Compute scheduling method that attempts to fill a host with VMs rather "" ""than starting new VMs on a variety of hosts."" msgstr """" ""様々なホスト上で新しい VM を起動するよりも、なるべく一つのホストを埋めようと"" ""する Compute スケジューリング手法。"" msgid """" ""The Compute service can send alerts through its notification system, which "" ""includes a facility to create custom notification drivers. Alerts can be "" ""sent to and displayed on the horizon dashboard."" msgstr """" ""Compute のサービスは、通知システム経由で警告を送信できる。カスタム通知ドライ"" ""バーを作成する機能がある。警告は、送信したり、ダッシュボードに表示したりでき"" ""る。"" msgid """" ""The Compute service provides accounting information through the event "" ""notification and system usage data facilities."" msgstr """" ""Compute サービスは、イベント通知やシステム使用状況データ機能からアカウンティ"" ""ング情報を提供する。"" msgid ""The Compute setting that enables or disables RAM overcommitment."" msgstr ""RAM オーバーコミットを有効化または無効化する Compute の設定。"" msgid """" ""The Data processing service for OpenStack (sahara) aims to provide users "" ""with a simple means to provision data processing (Hadoop, Spark) clusters by "" ""specifying several parameters like Hadoop version, cluster topology, node "" ""hardware details and a few more. After a user fills in all the parameters, "" ""the Data processing service deploys the cluster in a few minutes. Sahara "" ""also provides a means to scale already provisioned clusters by adding or "" ""removing worker nodes on demand."" msgstr """" ""OpenStack 用 Data processing サービス (sahara) の目的は、 Hadoop バージョン、"" ""クラスターのトポロジー、ノードハードウェアの詳細などのいくつかのパラメーター"" ""を指定するだけで、(Hadoop や Spark の) データ処理クラスターをセットアップする"" ""簡単な方法をユーザーに提供することです。ユーザーが必要なパラメーターをすべて"" ""入力すると、 Data processing サービスは数分でクラスターを展開します。 要求に"" ""応じてワーカーノードの追加、削除を行って、すでに展開済みのクラスターのサイズ"" ""を変更する手段も提供しています。"" msgid ""The Database service includes the following components:"" msgstr ""Database サービスは以下のコンポーネントで構成されます。"" msgid """" ""The Database service provides resource isolation at high performance levels, "" ""and automates complex administrative tasks such as deployment, "" ""configuration, patching, backups, restores, and monitoring."" msgstr """" ""Database サービスは、高い性能レベルでのリソースの分離ができ、配備、設定、パッ"" ""チ適用、バックアップ、リストア、監視などの複雑な管理作業を自動化します。"" msgid """" ""The Database service provides scalable and reliable cloud provisioning "" ""functionality for both relational and non-relational database engines. Users "" ""can quickly and easily use database features without the burden of handling "" ""complex administrative tasks. Cloud users and database administrators can "" ""provision and manage multiple database instances as needed."" msgstr """" ""Database サービスは、リレーショナルデータベースと非リレーショナルデータベース"" ""の両方のエンジン向けにスケール可能な信頼できるクラウド展開機能を提供します。"" ""ユーザーは、複雑な管理作業を実行することなく、迅速かつ容易にデータベース機能"" ""を利用できます。クラウドのユーザーとデータベース管理者は、必要に応じて、複数"" ""のデータベースインスタンスを配備および管理できます。"" msgid ""The Identity component that provides high-level authorization services."" msgstr ""高レベルの認可サービスを提供する Identity のコンポーネント。"" msgid ""The Identity service component that provides authentication services."" msgstr ""認証サービスを提供する Identity のコンポーネント。"" msgid ""The Identity service contains these components:"" msgstr ""Identity サービスには、以下のコンポーネントがあります。"" msgid """" ""The Identity service endpoint template that contains services available to "" ""all tenants."" msgstr """" ""すべてのテナントが利用可能なサービスを含む、Identity のエンドポイントテンプ"" ""レート。"" msgid ""The Image service API endpoint for management of VM images."" msgstr ""仮想マシンイメージの管理用の Image service API エンドポイント。"" msgid ""The Launchpad Bugs area"" msgstr ""Launchpad バグエリア"" msgid """" ""The Network Controller provides virtual networks to enable compute servers "" ""to interact with each other and with the public network. All machines must "" ""have a public and private network interface. A VLAN network is a private "" ""network interface, which is controlled by the ``vlan_interface`` option with "" ""VLAN managers."" msgstr """" ""ネットワークコントローラーは、コンピュートサーバー間、およびコンピュートサー"" ""バーとパブリックネットワークとの通信を行う仮想ネットワークを用意する。すべて"" ""の物理マシンにはパブリック側とプライベート側のネットワークインタフェースが必"" ""要。VLAN ネットワークはプライベート側のネットワークインタフェースで、VLAN マ"" ""ネージャーの ``vlan_interface`` オプションで指定される。"" msgid """" ""The Network Controller provides virtual networks to enable compute servers "" ""to interact with each other and with the public network. All machines must "" ""have a public and private network interface. A private network interface can "" ""be a flat or VLAN network interface. A flat network interface is controlled "" ""by the flat_interface with flat managers. A VLAN network interface is "" ""controlled by the ``vlan_interface`` option with VLAN managers."" msgstr """" ""ネットワークコントローラーは、コンピュートサーバー間、およびコンピュートサー"" ""バーとパブリックネットワークとの通信を行う仮想ネットワークを用意する。すべて"" ""の物理マシンにはパブリック側とプライベート側のネットワークインタフェースが必"" ""要。プライベートネットワークインターフェースは、フラットネットワークまたは "" ""VLAN ネットワークインターフェースにできる。フラットネットワークインターフェー"" ""スは、フラットマネージャーを用いて flat_interface により制御される。VLAN ネッ"" ""トワークインターフェースは、 VLAN マネージャーの ``vlan_interface`` オプショ"" ""ンにより制御される。"" msgid """" ""The Network Controller provides virtual networks to enable compute servers "" ""to interact with each other and with the public network. All machines must "" ""have a public and private network interface. The public network interface is "" ""controlled by the ``public_interface`` option."" msgstr """" ""コンピュートサーバーがパブリックネットワークと相互通信できるよう、ネットワー"" ""クコントローラーが仮想ネットワークを提供する。全マシンにはパブリックとプライ"" ""ベートのネットワークインターフェースがなければならない。パブリックネットワー"" ""クインターフェースは ``public_interface`` オプションにより制御される。"" msgid """" ""The Object Storage back-end process that creates and manages object replicas."" msgstr """" ""オブジェクトの複製を作成および管理する Object Storage のバックエンドプロセ"" ""ス。"" msgid """" ""The Object Storage component that provides container services, such as "" ""create, delete, list, and so on."" msgstr """" ""作成、削除、一覧表示などのコンテナーサービスを提供する Object Storage のコン"" ""ポーネント。"" msgid """" ""The Object Storage context of an account. Do not confuse with a user account "" ""from an authentication service, such as Active Directory, /etc/passwd, "" ""OpenLDAP, OpenStack Identity, and so on."" msgstr """" ""Object Storage のアカウントのコンテキスト。Active Directory、/etc/passwd、"" ""OpenLDAP、OpenStack Identity などの認証サービスのユーザーアカウントと混同しな"" ""いこと。"" msgid """" ""The OpenStack :term:`Identity service <Identity>` provides a single point of "" ""integration for managing authentication, authorization, and service catalog "" ""services. Other OpenStack services use the Identity service as a common "" ""unified API. Additionally, services that provide information about users but "" ""that are not included in OpenStack (such as LDAP services) can be integrated "" ""into a pre-existing infrastructure."" msgstr """" ""OpenStack :term:`Identity サービス <Identity>` は、認証、認可、サービスカタロ"" ""グサービスを管理する OpenStack で唯一のサービスです。他の OpenStack サービス"" ""は共通の統一 API として Identity サービスを使用します。また、ユーザー関連の情"" ""報を提供する OpenStack 外のサービス (LDAP サービスなど) なども既存のインフラ"" ""に統合できます。"" msgid """" ""The OpenStack Administrator configures the basic infrastructure using the "" ""following steps:"" msgstr ""OpenStack の管理者は、以下の手順で、基本的なインフラを設定します。"" msgid """" ""The OpenStack Block Storage service (cinder) adds persistent storage to a "" ""virtual machine. Block Storage provides an infrastructure for managing "" ""volumes, and interacts with OpenStack Compute to provide volumes for "" ""instances. The service also enables management of volume snapshots, and "" ""volume types."" msgstr """" ""OpenStack Block Storage サービス (cinder) は、永続ストレージを仮想マシンに提"" ""供します。Block Storage は、ボリュームを管理するインフラを提供し、ボリューム"" ""をインスタンスに提供するために OpenStack Compute と通信します。このサービスに"" ""より、ボリュームのスナップショットやボリューム種別を管理できます。"" msgid ""The OpenStack IRC channel"" msgstr ""OpenStack IRC チャンネル"" msgid ""The OpenStack Image service includes the following components:"" msgstr ""OpenStack Image service には、以下のコンポーネントがあります。"" msgid """" ""The OpenStack Image service is central to Infrastructure-as-a-Service (IaaS) "" ""as shown in :ref:`get_started_conceptual_architecture`. It accepts API "" ""requests for disk or server images, and metadata definitions from end users "" ""or OpenStack Compute components. It also supports the storage of disk or "" ""server images on various repository types, including OpenStack Object "" ""Storage."" msgstr """" ""OpenStack Image service は、:ref:`get_started_conceptual_architecture` に書か"" ""れているように Infrastructure-as-a-Service (IaaS) の中核です。エンドユーザー"" ""や OpenStack Compute のコンポーネントからの、ディスクやサーバーイメージ、メタ"" ""データ定義に関する API リクエストを受け付けます。ディスクやサーバーイメージの"" ""保管場所として、OpenStack Object Storage などの様々な種類のリポジトリーに対応"" ""しています。"" msgid """" ""The OpenStack Object Storage is a multi-tenant object storage system. It is "" ""highly scalable and can manage large amounts of unstructured data at low "" ""cost through a RESTful HTTP API."" msgstr """" ""OpenStack Object Storage は、マルチテナントのオブジェクトストレージシステムで"" ""す。高いスケーラビリティーを持ちます。RESTful HTTP API 経由で大規模な非構造"" ""データを低コストで管理できます。"" msgid """" ""The OpenStack Shared File Systems service (manila) provides file storage to "" ""a virtual machine. The Shared File Systems service provides an "" ""infrastructure for managing shares and provides access to shares to "" ""instances. The service also enables management of share types as well as "" ""share snapshots if a driver supports snapshots."" msgstr """" ""OpenStack Shared Files Systems サービス (manila) は、仮想マシンにファイルスト"" ""レージを提供します。 Shared File Systems サービスは、ファイル共有を管理し、"" ""ファイル共有へのアクセスをインスタンスに提供するための基盤を提供します。共有"" ""種別を管理することができ、ドライバーがスナップショットに対応している場合には"" ""共有のスナップショットを取ることもできます。"" msgid """" ""The OpenStack community lives in the #openstack IRC channel on the Freenode "" ""network. You can hang out, ask questions, or get immediate feedback for "" ""urgent and pressing issues. To install an IRC client or use a browser-based "" ""client, go to `https://webchat.freenode.net/ <https://webchat.freenode."" ""net>`__. You can also use Colloquy (Mac OS X, http://colloquy.info/), mIRC "" ""(Windows, http://www.mirc.com/), or XChat (Linux). When you are in the IRC "" ""channel and want to share code or command output, the generally accepted "" ""method is to use a Paste Bin. The OpenStack project has one at http://paste."" ""openstack.org. Just paste your longer amounts of text or logs in the web "" ""form and you get a URL that you can paste into the channel. The OpenStack "" ""IRC channel is ``#openstack`` on ``irc.freenode.net``. You can find a list "" ""of all OpenStack IRC channels at https://wiki.openstack.org/wiki/IRC."" msgstr """" ""OpenStack コミュニティーは、Freenode ネットワークに #openstack IRC チャンネル"" ""を持っています。緊急の問題に関して、ここに参加して、質問して、すぐにフィード"" ""バックを得ることができます。IRC クライアントをインストールする場合、ブラウ"" ""ザーベースのクライアントを使用する場合、`https://webchat.freenode.net/ "" ""<https://webchat.freenode.net>`__ にアクセスしてください。Colloquy (Mac OS "" ""X, http://colloquy.info/)、mIRC (Windows, http://www.mirc.com/)、XChat "" ""(Linux) を使用することもできます。IRC チャンネルに参加して、コードやコマンド"" ""の出力を共有したい場合、一般的に Paste Bin を使用する方法があります。"" ""OpenStack プロジェクトには http://paste.openstack.org があります。長いテキス"" ""トやログをウェブフォームに貼り付けるだけです。そして、URL を取得して IRC チャ"" ""ンネルに貼り付けます。OpenStack の IRC チャンネルは ``irc.freenode.net`` にあ"" ""る ``#openstack`` です。OpenStack の IRC チャンネル一覧は https://wiki."" ""openstack.org/wiki/IRC にあります。"" msgid """" ""The OpenStack community values your set up and testing efforts and wants "" ""your feedback. To log a bug, you must sign up for a Launchpad account at "" ""https://launchpad.net/+login. You can view existing bugs and report bugs in "" ""the Launchpad Bugs area. Use the search feature to determine whether the bug "" ""has already been reported or already been fixed. If it still seems like your "" ""bug is unreported, fill out a bug report."" msgstr """" ""OpenStack コミュニティーは、あなたの構成やテスト作業を重視しており、あなたの"" ""フィードバックを期待しています。バグを報告する場合、 https://launchpad.net/"" ""+login で Launchpad アカウントをサインアップする必要があります。既存のバグを"" ""確認したり、Launchpad バグエリアにバグを報告したりできます。検索機能を使用し"" ""て、バグがすでに報告されているか、すでに解決されているかを確認できます。バグ"" ""がまだ報告されていないようであれば、バグ報告を記入します。"" msgid """" ""The OpenStack configuration files use an INI format to describe options and "" ""their values. It consists of sections and key value pairs."" msgstr """" ""OpenStack 設定ファイルは、オプションやその値を記述するために、INI 形式を使用"" ""する。セクションとキーバリューペアから構成される。"" msgid """" ""The OpenStack core project that enables management of volumes, volume "" ""snapshots, and volume types. The project name of Block Storage is cinder."" msgstr """" ""ボリューム、ボリュームのスナップショット、ボリューム種別を管理する、"" ""OpenStack のコアプロジェクト。Block Storage のプロジェクト名は cinder。"" msgid """" ""The OpenStack core project that provides a central directory of users mapped "" ""to the OpenStack services they can access. It also registers endpoints for "" ""OpenStack services. It acts as a common authentication system. The project "" ""name of Identity is keystone."" msgstr """" ""ユーザーがアクセスできる OpenStack サービスに対応付けられた、ユーザーの中央"" ""ディレクトリーを提供する、OpenStack コアプロジェクト。OpenStack サービスのエ"" ""ンドポイントも登録する。一般的な認証システムとして動作する。Identity のプロ"" ""ジェクト名は keystone。"" msgid """" ""The OpenStack core project that provides compute services. The project name "" ""of Compute service is nova."" msgstr """" ""コンピュートサービスを提供する OpenStack のコアプロジェクト。Compute のプロ"" ""ジェクト名は nova。"" msgid """" ""The OpenStack core project that provides eventually consistent and redundant "" ""storage and retrieval of fixed digital content. The project name of "" ""OpenStack Object Storage is swift."" msgstr """" ""結果整合性（eventually consistent）、ストレージ冗長化、静的デジタルコンテンツ"" ""取得、といった機能を提供する、OpenStack のコアプロジェクト。OpenStack Object "" ""Storage のプロジェクト名は swift。"" msgid """" ""The OpenStack dashboard by default on Ubuntu installs the ``openstack-"" ""dashboard-ubuntu-theme`` package."" msgstr """" ""Ubuntu の OpenStack dashboard は、デフォルトで ``openstack-dashboard-ubuntu-"" ""theme`` パッケージをインストールします。"" msgid """" ""The OpenStack dashboard is a modular `Django web application <https://www."" ""djangoproject.com/>`__ that provides a graphical interface to OpenStack "" ""services."" msgstr """" ""OpenStack dashboard は、モジュール型の `Django Web アプリケーション<https://"" ""www.djangoproject.com/>`__ です。OpenStack サービスのグラフィカルインター"" ""フェースを提供します。"" msgid ""The OpenStack documentation uses several typesetting conventions."" msgstr ""OpenStack のドキュメントでは、以下の表記規則を採用しています。"" msgid """" ""The OpenStack end user deploys the Database service using the following "" ""steps:"" msgstr """" ""OpenStack のエンドユーザーは、以下の手順で Database サービスを配備します。"" msgid """" ""The OpenStack project is an open source cloud computing platform for all "" ""types of clouds, which aims to be simple to implement, massively scalable, "" ""and feature rich. Developers and cloud computing technologists from around "" ""the world create the OpenStack project."" msgstr """" ""OpenStack project はあらゆる種類のクラウド向けのオープンソースのクラウドコン"" ""ピューティングプラットフォームです。シンプルな実装、大規模なスケーラビリ"" ""ティ、豊富な機能を目指しています。世界中の開発者とクラウドコンピューティング"" ""技術者が OpenStack project を作っています。"" msgid """" ""The OpenStack project that OpenStack project that implements clustering "" ""services and libraries for the management of groups of homogeneous objects "" ""exposed by other OpenStack services. The project name of Clustering service "" ""is senlin."" msgstr """" ""クラスタリングサービスと、他の OpenStack サービスにより公開された均質なオブ"" ""ジェクトグループを管理するためのライブラリーを実現する OpenStack プロジェク"" ""ト。このプロジェクトのコード名は senlin。"" msgid """" ""The OpenStack project that provides a multi-tenant, highly scalable, "" ""performant, fault-tolerant Monitoring-as-a-Service solution for metrics, "" ""complex event processing, and logging. It builds an extensible platform for "" ""advanced monitoring services that can be used by both operators and tenants "" ""to gain operational insight and visibility, ensuring availability and "" ""stability. The project name is monasca."" msgstr """" ""マルチテナントで、高いスケーラビリティーを持ち、高性能で、耐障害性のある、"" ""Monitoring-as-a-Service ソリューションを提供する OpenStack プロジェクト。 計"" ""測情報、複合イベント処理 (complex event processing)、ログ監視が対象。オペレー"" ""ター、テナントの両者が利用できる、高度なモニタリングサービスに対応できる拡張"" ""性のあるプラットフォームを開発しており、可用性と安定性を確保しながら、運用上"" ""の問題の特定や可視化を実現できる。プロジェクト名は monasca。"" msgid """" ""The OpenStack project that provides integrated tooling for backing up, "" ""restoring, and recovering file systems, instances, or database backups. The "" ""project name is freezer."" msgstr """" ""ファイルシステム、インスタンス、データベースバックアップのバックアップ、リス"" ""トア、リカバリー用の統合ツールを提供する OpenStack プロジェクト。プロジェクト"" ""名は freezer。"" msgid ""The OpenStack stack uses the following storage types:"" msgstr ""OpenStack のスタックは、以下のストレージ種別を使用します。"" msgid ""The OpenStack wiki"" msgstr ""OpenStack wiki"" msgid ""The Orchestration service consists of the following components:"" msgstr ""Orchestration サービスは、以下のコンポーネントから構成されます。"" msgid """" ""The Orchestration service provides a template-based orchestration for "" ""describing a cloud application by running OpenStack API calls to generate "" ""running cloud applications. The software integrates other core components of "" ""OpenStack into a one-file template system. The templates allow you to create "" ""most OpenStack resource types, such as instances, floating IPs, volumes, "" ""security groups, and users. It also provides advanced functionality, such as "" ""instance high availability, instance auto-scaling, and nested stacks. This "" ""enables OpenStack core projects to receive a larger user base."" msgstr """" ""Orchestration サービスは、クラウドアプリケーションを記述できるテンプレート"" ""ベースのオーケストレーション機能を提供します。 OpenStack API を呼び出して、実"" ""際に動くクラウドアプリケーションを生成します。このサービスにより、他の "" ""OpenStack のコアコンポーネントを 1ファイルのテンプレートシステムに統合できま"" ""す。テンプレートを使って、ほとんどの種類の OpenStack リソースを作成できます。"" ""例えば、インスタンス、 Floating IP、ボリューム、セキュリティーグループ、ユー"" ""ザーなどです。インスタンスの高可用化、インスタンスのオートスケーリング、入れ"" ""子になったスタックといった、高度な機能も提供しています。これにより、より多く"" ""のユーザーが OpenStack コアプロジェクトを利用することになります。"" msgid ""The POSIX-compliant file system provided by Ceph."" msgstr ""Ceph により提供される POSIX 互換ファイルシステム。"" msgid """" ""The SCSI disk protocol tunneled within Ethernet, supported by Compute, "" ""Object Storage, and Image service."" msgstr """" ""イーサネット内でトンネルされる SCSI ディスクプロトコル。Compute、Object "" ""Storage、Image service によりサポートされる。"" msgid ""The Shared File Systems service consists of the following components:"" msgstr ""Shared File Systems サービスは、以下のコンポーネントから構成されます。"" msgid """" ""The Simple Protocol for Independent Computing Environments (SPICE) provides "" ""remote desktop access to guest virtual machines. It is an alternative to "" ""VNC. SPICE is supported by OpenStack."" msgstr """" ""Simple Protocol for Independent Computing Environments (SPICE) は、ゲスト仮想"" ""マシンに対するリモートデスクトップアクセスを提供する。VNC の代替品。SPICE は "" ""OpenStack によりサポートされる。"" msgid ""The Telemetry Alarming service consists of the following components:"" msgstr ""Telemetry Alarming サービスは、以下のコンポーネントから構成されます。"" msgid """" ""The Telemetry Alarming services trigger alarms when the collected metering "" ""or event data break the defined rules."" msgstr """" ""Telemetry Alarming サービスは、収集したメーターやイベントデータが定義済みルー"" ""ルを満たさない場合、アラームを生成します。"" msgid ""The Telemetry Data Collection services provide the following functions:"" msgstr ""Telemetry Data Collection サービスは、以下の機能を持ちます。"" msgid ""The Telemetry service consists of the following components:"" msgstr ""Telemetry サービスは、以下のコンポーネントから構成されます。"" msgid """" ""The URL where the data for this image resides. For example, if the image "" ""data is stored in swift, you could specify ``swift://account:key@example.com/"" ""container/obj``."" msgstr """" ""このイメージのデータが格納されている URL。たとえば、イメージデータが swift に"" ""格納されている場合 ``swift://account:key@example.com/container/obj`` を指定し"" ""ます。 "" msgid ""The Xen administrative API, which is supported by Compute."" msgstr ""Xen 管理 API。Compute によりサポートされる。"" msgid """" ""The `OpenStack wiki <https://wiki.openstack.org/>`__ contains a broad range "" ""of topics but some of the information can be difficult to find or is a few "" ""pages deep. Fortunately, the wiki search feature enables you to search by "" ""title or content. If you search for specific information, such as about "" ""networking or OpenStack Compute, you can find a large amount of relevant "" ""material. More is being added all the time, so be sure to check back often. "" ""You can find the search box in the upper-right corner of any OpenStack wiki "" ""page."" msgstr """" ""`OpenStack wiki <https://wiki.openstack.org/>`__ には、さまざまな情報がありま"" ""す。しかし、いくつかの情報は見つけにくく、深い場所にあります。幸い、wiki 検索"" ""機能により、見出しや内容を検索できます。ネットワークや OpenStack Compute な"" ""ど、特定の情報を探している場合、非常に多くの関連項目を見つけられます。情報が"" ""いつでも追加されているので、ときどき確認し直してください。すべての OpenStack "" ""wiki ページの右上に、検索ボックスがあります。"" msgid """" ""The ``cinder-backup`` service provides backing up volumes of any type to a "" ""backup storage provider. Like the ``cinder-volume`` service, it can interact "" ""with a variety of storage providers through a driver architecture."" msgstr """" ""``cinder-backup`` サービスは、あらゆる種類のボリュームのバックアップをバック"" ""アップストレージプロバイダーに提供します。 ``cinder-volume`` サービスのよう"" ""に、ドライバーアーキテクチャーになっており、さまざまな種類のストレージプロバ"" ""イダーを利用できます。"" msgid """" ""The ``cpu`` column shows the sum of the virtual CPUs for instances running "" ""on the host."" msgstr """" ""``cpu`` の列は、ホストで実行中のインスタンスの仮想 CPU 総数を表示します。"" msgid """" ""The ``disk_gb`` column shows the sum of the root and ephemeral disk sizes "" ""(in GB) of the instances that run on the host."" msgstr """" ""``disk_gb`` の列は、ホストで実行中のインスタンスの一時ディスクのサイズ (GB) "" ""と root の合計を表示します。"" msgid """" ""The ``memory_mb`` column shows the sum of the memory (in MB) allocated to "" ""the instances that run on the host."" msgstr """" ""``memory_mb`` の列は、ホストで実行中のインスタンスに割り当てられたメモリー "" ""(MB) 合計を表示します。"" msgid """" ""The ``nova-network`` worker daemon; provides services such as giving an IP "" ""address to a booting nova instance."" msgstr """" ""``nova-network`` ワーカーデーモン。起動中の Nova インスタンスに IP アドレスを"" ""付与する等のサービスを提供する。"" msgid """" ""The ``root`` user must run commands that are prefixed with the ``#`` prompt. "" ""You can also prefix these commands with the :command:`sudo` command, if "" ""available, to run them."" msgstr """" ""``#`` プロンプトから始まるコマンドは ``root`` ユーザーで実行する必要がありま"" ""す。これらのコマンドを実行するのに :command:`sudo` コマンドを使用することもで"" ""きます。"" msgid """" ""The ability to encrypt data at the file system, disk partition, or whole-"" ""disk level. Supported within Compute VMs."" msgstr """" ""ファイルシステム、ディスクパーティション、ディスク全体を暗号化する機能。"" ""Compute の仮想マシン内でサポートされる。"" msgid """" ""The ability to start new VM instances based on the actual memory usage of a "" ""host, as opposed to basing the decision on the amount of RAM each running "" ""instance thinks it has available. Also known as RAM overcommit."" msgstr """" ""実行中の各インスタンスが利用可能と考えている RAM 量に基づく判断をベースにする"" ""代わりに、ホスト上の実際のメモリ使用量をベースにした、新しい VM インスタンス"" ""を起動する機能。"" msgid """" ""The ability to start new VM instances based on the actual memory usage of a "" ""host, as opposed to basing the decision on the amount of RAM each running "" ""instance thinks it has available. Also known as memory overcommit."" msgstr """" ""実行中の各インスタンスが利用可能と考えている RAM 量に基づく判断をベースにする"" ""代わりに、ホスト上の実際のメモリ使用量をベースにした、新しい VM インスタンス"" ""を起動する機能。"" msgid """" ""The ability within Compute to move running virtual machine instances from "" ""one host to another with only a small service interruption during switchover."" msgstr """" ""切り替え中のわずかなサービス中断のみで、実行中の仮想マシンをあるホストから別"" ""のホストに移動する、Compute 内の機能。"" msgid """" ""The act of verifying that a user, process, or client is authorized to "" ""perform an action."" msgstr """" ""ユーザー、プロセス、クライアントが操作を実行する権限を持つかどうかを確認する"" ""こと。"" msgid """" ""The amount of available data used by communication resources, such as the "" ""Internet. Represents the amount of data that is used to download things or "" ""the amount of data available to download."" msgstr """" ""インターネットなどの通信リソースにより使用される、利用可能なデータ量。何かを"" ""ダウンロードするために使用されるデータの合計量、またはダウンロードするために"" ""利用可能なデータの合計量を表す。"" msgid """" ""The amount of time it takes for a new Object Storage object to become "" ""accessible to all clients."" msgstr """" ""Object Storage の新規オブジェクトがすべてのクライアントからアクセス可能になる"" ""までにかかる時間。"" msgid """" ""The association between an Image service VM image and a tenant. Enables "" ""images to be shared with specified tenants."" msgstr """" ""Image service の仮想マシンイメージとテナント間の関連。イメージを特別なテナン"" ""トと共有できるようになる。"" msgid """" ""The back-end store used by Image service to store VM images, options include "" ""Object Storage, local file system, S3, or HTTP."" msgstr """" ""仮想マシンイメージを保存するために、Image service により使用されるバックエン"" ""ドストア。オプションとして、Object Storage、ローカルファイルシステム、S3、"" ""HTTP がある。"" msgid """" ""The cloud operator assigns roles to users. Roles determine who can upload "" ""and manage images. The operator might restrict image upload and management "" ""to only cloud administrators or operators."" msgstr """" ""クラウド運用者はユーザーにロールを割り当てます。ロールはイメージをアップロー"" ""ドおよび管理できるユーザーを決定します。運用者はイメージのアップロードと管理"" ""をクラウド管理者や運用者のみに制限するかもしれません。"" msgid """" ""The code name for the eighth release of OpenStack. The design summit took "" ""place in Portland, Oregon, US and Havana is an unincorporated community in "" ""Oregon."" msgstr """" ""OpenStack の 8 番目のリリースのコード名。デザインサミットがアメリカ合衆国オレ"" ""ゴン州ポートランドで開催された。Havana は、オレゴン州の非法人コミュニティーで"" ""ある。"" msgid """" ""The code name for the eleventh release of OpenStack. The design summit took "" ""place in Paris, France. Due to delays in the name selection, the release was "" ""known only as K. Because ``k`` is the unit symbol for kilo and the reference "" ""artifact is stored near Paris in the Pavillon de Breteuil in Sèvres, the "" ""community chose Kilo as the release name."" msgstr """" ""OpenStack の 11 番目のリリースのコード名。デザインサミットは、フランスのパリ"" ""で開催された。名前選定の遅れにより、このリリースは K のみで知られていた。 "" ""``k`` はキロを表す単位記号であり、その原器がパリ近郊の Pavillon de Breteuil "" ""in Sèvres に保存されているので、コミュニティーはリリース名として Kilo を選択"" ""した。"" msgid """" ""The code name for the fifteenth release of OpenStack. The design summit will "" ""take place in Barcelona, Spain. Ocata is a beach north of Barcelona."" msgstr """" ""OpenStack の 14 番目のリリースのコード名。デザインサミットは、スペインのバル"" ""セロナで開催される。Ocata はバルセロナ北部のビーチ。"" msgid """" ""The code name for the fourteenth release of OpenStack. The design summit "" ""will take place in Austin, Texas, US. The release is named after \""Newton "" ""House\"" which is located at 1013 E. Ninth St., Austin, TX. which is listed "" ""on the National Register of Historic Places."" msgstr """" ""OpenStack の 14 番目のリリースのコード名。デザインサミットは、アメリカ合衆国"" ""テキサス州オースチンで開催される。リリースの名前は、テキサス州オースチンの "" ""1013 E. Ninth St. にある「Newton House」にちなんでいる。これはアメリカ合衆国"" ""国家歴史登録財に登録されている。"" msgid """" ""The code name for the initial release of OpenStack. The first design summit "" ""took place in Austin, Texas, US."" msgstr """" ""OpenStack の初期リリースのコード名。最初のデザインサミットは、アメリカ合衆国"" ""テキサス州オースチンで開催された。"" msgid """" ""The code name for the ninth release of OpenStack. The design summit took "" ""place in Hong Kong and Ice House is a street in that city."" msgstr """" ""OpenStack の 9 番目のリリースのコード名。デザインサミットは、香港で開催され"" ""た。Ice House は、その近くにある通りである。"" msgid """" ""The code name for the seventh release of OpenStack. The design summit took "" ""place in San Diego, California, US and Grizzly is an element of the state "" ""flag of California."" msgstr """" ""OpenStack の 7 番目のリリースのコード名。デザインサミットがアメリカ合衆国カリ"" ""フォルニア州サンディエゴで開催された。Grizzly は、カリフォルニア州の州旗に使"" ""われている。"" msgid """" ""The code name for the tenth release of OpenStack. The design summit took "" ""place in Atlanta, Georgia, US and Juno is an unincorporated community in "" ""Georgia."" msgstr """" ""OpenStack の 10 番目のリリースのコード名。デザインサミットはアメリカ合衆国"" ""ジョージア州アトランタにて開催された。Juno は、ジョージア州の非公式コミュニ"" ""ティー。"" msgid """" ""The code name for the thirteenth release of OpenStack. The design summit "" ""took place in Tokyo, Japan. Mitaka is a city in Tokyo."" msgstr """" ""OpenStack の 13 番目のリリースのコード名。デザインサミットは、日本の東京で開"" ""催された。三鷹は、東京にある都市です。"" msgid """" ""The code name for the twelfth release of OpenStack. The design summit took "" ""place in Vancouver, Canada and Liberty is the name of a village in the "" ""Canadian province of Saskatchewan."" msgstr """" ""OpenStack の 12 番目のリリースのコード名。デザインサミットは、カナダのバン"" ""クーバーで開催された。Liberty は、サスカチュワン州にある村の名前。"" msgid ""The collaboration site for OpenStack."" msgstr ""OpenStack 用コラボレーションサイト。"" msgid """" ""The common agents are L3 (layer 3), DHCP (dynamic host IP addressing), and a "" ""plug-in agent."" msgstr """" ""共通のエージェントは、L3 エージェント、DHCP エージェント、プラグインエージェ"" ""ントです。"" msgid """" ""The container format of the image. Acceptable formats are ami, ari, aki, "" ""bare, docker, and ovf."" msgstr """" ""イメージのコンテナー形式。対応形式は ami、ari、aki、docker、bare、ovf です。"" msgid """" ""The cooperative threading model used by Python; reduces race conditions and "" ""only context switches when specific library calls are made. Each OpenStack "" ""service is its own thread."" msgstr """" ""Python により使用される協調スレッドモデル。特定のライブラリーコールが発行され"" ""るときの競合状態とコンテキストスイッチを減らす。各 OpenStack サービスは自身の"" ""スレッドである。"" msgid ""The current state of a guest VM image."" msgstr ""ゲスト仮想マシンイメージの現在の状態。"" msgid """" ""The current status of a VM image in Image service, not to be confused with "" ""the status of a running instance."" msgstr """" ""Image service における仮想マシンイメージの現在の状態。実行中のインスタンスの"" ""状態と混同しないこと。"" msgid """" ""The daemon, worker, or service that a client communicates with to access an "" ""API. API endpoints can provide any number of services, such as "" ""authentication, sales data, performance meters, Compute VM commands, census "" ""data, and so on."" msgstr """" ""クライアントが API にアクセスするために通信するデーモン、ワーカーまたはサービ"" ""ス。API エンドポイントは、認証、売上データ、パフォーマンス統計、Compute 仮想"" ""マシンコマンド、センサスデータなどのような数多くのサービスを提供できます。"" msgid ""The dashboard is generally installed on the controller node."" msgstr ""ダッシュボードは通常はコントローラーノードにインストールされます。"" msgid """" ""The dashboard is usually deployed through `mod_wsgi <http://code.google.com/"" ""p/modwsgi/>`__ in Apache. You can modify the dashboard code to make it "" ""suitable for different sites."" msgstr """" ""ダッシュボードは、一般的に Apache の `mod_wsgi <http://code.google.com/p/"" ""modwsgi/>`__ 経由で配備されます。ダッシュボードのコードを修正して、それぞれの"" ""サイトに適するように変更できます。"" msgid ""The default message queue software used by OpenStack."" msgstr ""OpenStackでデフォルトで採用されているメッセージキューのソフトウェア。"" msgid """" ""The default panel that is displayed when a user accesses the horizon "" ""dashboard."" msgstr """" ""ユーザーがダッシュボードにアクセスした際に表示されるデフォルトのパネル。"" msgid """" ""The disk format of the image. Acceptable formats are ami, ari, aki, vhd, "" ""vmdk, raw, qcow2, vdi, and iso."" msgstr """" ""イメージのディスク形式。利用可能な形式は ami、ari、aki、vhd、vmdk、raw、"" ""qcow2、vdi、iso です。"" msgid ""The fibre channel protocol tunneled within Ethernet."" msgstr ""イーサネットでトンネルされるファイバーチャネルプロトコル。"" msgid """" ""The following CLIs are deprecated in favor of ``openstack``, the Common "" ""OpenStack client supporting multiple services:"" msgstr """" ""以下の CLI は、複数のサービスをサポートする OpenStack 共通クライアント "" ""``openstack`` により置き換えられ、非推奨となります。"" msgid ""The following Launchpad Bugs areas are available:"" msgstr ""以下の Launchpad バグエリアが利用できます。"" msgid """" ""The following Linux distributions provide community-supported packages for "" ""OpenStack:"" msgstr ""OpenStack のコミュニティサポート版を提供しているディストリビューション"" msgid """" ""The following books explain how to configure and run an OpenStack cloud:"" msgstr ""OpenStackクラウドの設定と実行に関するガイド:"" msgid """" ""The following books explain how to install an OpenStack cloud and its "" ""associated components:"" msgstr ""OpenStack クラウドと関連コンポーネントの導入ガイド:"" msgid """" ""The following books explain how to use the OpenStack dashboard and command-"" ""line clients:"" msgstr """" ""以下のドキュメントは、OpenStack dashboard とコマンドラインクライアントの使用"" ""方法を説明しています。"" msgid ""The following can easily be customized:"" msgstr ""以下の項目を簡単にカスタマイズできます。"" msgid """" ""The following clients, while valid, are de-emphasized in favor of a common "" ""client. Instead of installing and learning all these clients, we recommend "" ""installing and using the OpenStack client. You may need to install an "" ""individual project's client because coverage is not yet sufficient in the "" ""OpenStack client. If you need to install an individual client's project, "" ""replace the ``<project>`` name in this ``pip install`` command using the "" ""list below."" msgstr """" ""以下のクライアントは、まだ有効ですが、共通クライアントに置き換えられ、強調さ"" ""れなくなりました。これらのクライアントをすべてインストールして学習する代わり"" ""に、OpenStack クライアントをインストールして使用することを推奨します。"" ""OpenStack クライアントにおいて十分にカバーされていないため、各プロジェクトの"" ""クライアントをインストールする必要があるかもしれません。各プロジェクトのクラ"" ""イアントをインストールする必要がある場合、以下の一覧を使用して、この ``pip "" ""install`` の ``<project>`` の名前を置き換えてください。"" msgid """" ""The following diagram shows the most common, but not the only possible, "" ""architecture for an OpenStack cloud:"" msgstr """" ""以下の図に、最も一般的な OpenStack クラウドのアーキテクチャーを示します。これ"" ""が唯一の OpenStack のアーキテクチャーというわけではありません。"" msgid """" ""The following diagram shows the relationships among the OpenStack services:"" msgstr ""以下の図は OpenStack サービス間の関連性を示しています。"" msgid """" ""The following documentation provides reference and guidance information for "" ""the OpenStack APIs:"" msgstr """" ""以下のドキュメントは、OpenStack API に関するリファレンスとガイダンスを提供し"" ""ます。"" msgid """" ""The following example shows how to update an existing image with a "" ""properties that describe the disk bus, the CD-ROM bus, and the VIF model:"" msgstr """" ""以下の例は、ディスクバス、CD-ROM バス、VIF モデルのプロパティを指定して、既存"" ""のイメージを更新する方法を表します。"" msgid """" ""The following example shows the command for installing the OpenStack client "" ""with ``pip``, which supports multiple services."" msgstr """" ""以下の例は、``pip`` を用いて OpenStack client をインストールするコマンドを示"" ""します。"" msgid """" ""The following example shows the command that you would use to upload a "" ""CentOS 6.3 image in qcow2 format and configure it for public access:"" msgstr """" ""以下の例は、CentOS 6.3 イメージを qcow2 形式でアップロードし、パブリックなア"" ""クセス用に設定するために使用するコマンドを表します。"" msgid """" ""The following examples show the host usage statistics for a host called "" ""``devstack``."" msgstr ""以下の例では、``devstack`` という名前のホストの使用統計を表示します。"" msgid """" ""The following guide provides how to contribute to OpenStack documentation:"" msgstr """" ""OpenStack ドキュメントに貢献する方法については以下のガイドに説明があります。"" msgid """" ""The following list explains the optional arguments that you can use with the "" ""``create`` and ``update`` commands to modify image properties. For more "" ""information, refer to Image service chapter in the `OpenStack Command-Line "" ""Interface Reference <http://docs.openstack.org/cli-reference/index.html>`__."" msgstr """" ""以下の一覧は、イメージのプロパティを変更するために、``create`` コマンドと "" ""``update`` コマンドで使用できるオプション引数の一覧です。詳細は `OpenStack "" ""Command-Line Interface Reference <http://docs.openstack.org/cli-reference/"" ""index.html>`__ の Image service の章を参照してください。"" msgid """" ""The following resources are available to help you run and use OpenStack. The "" ""OpenStack community constantly improves and adds to the main features of "" ""OpenStack, but if you have any questions, do not hesitate to ask. Use the "" ""following resources to get OpenStack support, and troubleshoot your "" ""installations."" msgstr """" ""OpenStack の利用に役立つリソースとして以下のものがあります。OpenStack コミュ"" ""ニティーは、OpenStack を継続的に改善、機能追加していますが、もしあなたが何ら"" ""かの疑問に直面したら、遠慮せずに相談してください。下記のリソースを OpenStack "" ""のサポートとトラブルシュートに活用してください。"" msgid """" ""The following table describes the OpenStack services that make up the "" ""OpenStack architecture:"" msgstr """" ""以下の表は OpenStack アーキテクチャーを構成する OpenStack のサービスについて"" ""まとめたものです。"" msgid """" ""The following table lists the command-line client for each OpenStack service "" ""with its package name and description."" msgstr """" ""以下の表は、各 OpenStack サービスのコマンドラインクライアント、そのパッケージ"" ""名、説明の一覧です。"" msgid """" ""The logo also acts as a hyperlink. The default behavior is to redirect to "" ""``horizon:user_home``. To change this, add the following attribute to "" ""``local_settings.py``:"" msgstr """" ""ロゴはハイパーリンクとしても機能します。デフォルトの動作では、``horizon:"" ""user_home`` にリダイレクトします。これを変更するには、以下の属性を "" ""``local_settings.py`` に追加します。"" msgid """" ""The main virtual communication line used by all AMQP messages for inter-"" ""cloud communications within Compute."" msgstr """" ""Compute 内でクラウド内通信のためにすべての AMQP メッセージにより使用されるメ"" ""インの仮想通信ライン。"" msgid """" ""The method of storage used by horizon to track client sessions, such as "" ""local memory, cookies, a database, or memcached."" msgstr """" ""クライアントのセッションを管理するために、horizon により使用される保存方法。"" ""ローカルメモリー、クッキー、データベース、memcached など。"" msgid """" ""The method that a service uses for persistent storage, such as iSCSI, NFS, "" ""or local disk."" msgstr """" ""サービスが、iSCSI、NFS、ローカルディスクなどの永続ストレージを使用する方式。"" msgid """" ""The method used by the Compute RabbitMQ for intra-service communications."" msgstr ""内部サービス通信のために Compute RabbitMQ により使用される方法。"" msgid ""The minimum amount of RAM needed to boot the image, in megabytes."" msgstr ""ブートイメージに必要となるメモリの最小容量。ギガバイト単位。"" msgid ""The minimum size of the disk needed to boot the image, in gigabytes."" msgstr ""ブートイメージに必要となるディスクの最小容量。ギガバイト単位。"" msgid ""The most common web server software currently used on the Internet."" msgstr """" ""現在インターネットにおいて使用されている最も一般的な Web サーバーソフトウェ"" ""ア。"" msgid ""The name of the image."" msgstr ""イメージの名前。"" msgid """" ""The nova-api daemon provides access to nova services. Can communicate with "" ""other APIs, such as the Amazon EC2 API."" msgstr """" ""Compute サービスへのアクセスを提供する nova-api デーモン。Amazon EC2 API のよ"" ""うな他の API でも通信可能。"" msgid ""The number of replicas of the data in an Object Storage ring."" msgstr ""Object Storage リングにおけるデータ複製数。"" msgid """" ""The open standard messaging protocol used by OpenStack components for intra-"" ""service communications, provided by RabbitMQ, Qpid, or ZeroMQ."" msgstr """" ""インフラサービス通信のために OpenStack コンポーネントにより使用されるオープン"" ""な標準メッセージングプロトコル。RabbitMQ、Qpid、ZeroMQ により提供される。"" msgid """" ""The output shows that the volume is attached to the server with ID "" ""``84c6e57d-a6b1-44b6-81eb-fcb36afd31b5``, is in the nova availability zone, "" ""and is bootable."" msgstr """" ""この出力から、このボリュームは ID が ``84c6e57d-a6b1-44b6-81eb-"" ""fcb36afd31b5`` のサーバーに接続されていること、nova のアベイラビリティゾーン"" ""内にあること、ブータブルであることが分かります。"" msgid """" ""The output shows the volume transfer ID in the ``id`` row and the "" ""authorization key."" msgstr """" ""この出力では、認証キーと、``id`` の行にボリュームの転送 ID が表示されます。"" msgid """" ""The persistent data store used to save and retrieve information for a "" ""service, such as lists of Object Storage objects, current state of guest "" ""VMs, lists of user names, and so on. Also, the method that the Image service "" ""uses to get and store VM images. Options include Object Storage, local file "" ""system, S3, and HTTP."" msgstr """" ""Object Storage のオブジェクトの一覧、ゲスト仮想マシンの現在の状態、ユーザー名"" ""の一覧など、サービスに関する情報を保存および取得するために使用される永続デー"" ""タストア。また、Image service が仮想マシンイメージを取得および保存するために"" ""使用する方式。Object Storage、ローカルファイルシステム、S3、HTTP などの選択肢"" ""がある。"" msgid """" ""The person responsible for planning and maintaining an OpenStack "" ""installation."" msgstr ""OpenStack インストールを計画し、管理する責任者。"" msgid """" ""The point where a user interacts with a service; can be an API endpoint, the "" ""horizon dashboard, or a command-line tool."" msgstr """" ""ユーザーがサービスと通信する箇所。API エンドポイント、ダッシュボード、コマン"" ""ドラインツールの可能性がある。"" msgid """" ""The practice of placing one packet type within another for the purposes of "" ""abstracting or securing data. Examples include GRE, MPLS, or IPsec."" msgstr """" ""データを抽象化やセキュア化する目的で、あるパケット形式を別の形式の中に入れる"" ""ための方法。例えば、GRE、MPLS、IPsec などがある。"" msgid """" ""The practice of utilizing a secondary environment to elastically build "" ""instances on-demand when the primary environment is resource constrained."" msgstr """" ""主環境がリソース制限されたとき、要求時に応じてインスタンスを伸縮自在に構築す"" ""るために、副環境を利用する慣習。"" msgid """" ""The primary load balancing configuration object. Specifies the virtual IP "" ""address and port where client traffic is received. Also defines other "" ""details such as the load balancing method to be used, protocol, and so on. "" ""This entity is sometimes known in load-balancing products as a virtual "" ""server, vserver, or listener."" msgstr """" ""主たる負荷分散の設定オブジェクト。クライアント通信を受け付ける仮想 IP とポー"" ""トを指定する。使用する負荷分散方式、プロトコルなどの詳細も定義する。このエン"" ""ティティは、virtual server、vserver、listener のような負荷分散製品においても"" ""知られている。"" msgid """" ""The procedure for volume transfer is intended for tenants (both the volume "" ""donor and recipient) within the same cloud."" msgstr """" ""ボリューム転送の手続きは、テナント (ボリュームの譲渡元と受信者) が同じクラウ"" ""ド内にあることを意図しています。"" msgid """" ""The process associating a Compute floating IP address with a fixed IP "" ""address."" msgstr """" ""Compute の Floating IP アドレスと固定 IP アドレスを関連づけるプロセス。"" msgid """" ""The process of automating IP address allocation, deallocation, and "" ""management. Currently provided by Compute, melange, and Networking."" msgstr """" ""IP アドレスの割り当て、割り当て解除、管理を自動化するプロセス。現在、"" ""Compute、melange、Networking により提供される。"" msgid """" ""The process of connecting a VIF or vNIC to a L2 network in Networking. In "" ""the context of Compute, this process connects a storage volume to an "" ""instance."" msgstr """" ""Networking において、仮想インターフェースや仮想 NIC を L2 ネットワークに接続"" ""するプロセス。Compute の文脈では、ストレージボリュームをインスタンスに接続す"" ""るプロセス。"" msgid """" ""The process of copying data to a separate physical device for fault "" ""tolerance and performance."" msgstr """" ""別の物理デバイスにデータをコピーする処理。耐障害性や性能のために行われる。"" msgid """" ""The process of distributing Object Storage partitions across all drives in "" ""the ring; used during initial ring creation and after ring reconfiguration."" msgstr """" ""リング内のすべてのドライブにわたり、Object Storage のパーティションを分散させ"" ""る処理。初期リング作成中、リング再設定後に使用される。"" msgid """" ""The process of filtering incoming network traffic. Supported by Compute."" msgstr """" ""入力ネットワーク通信をフィルタリングする処理。Compute によりサポートされる。"" msgid """" ""The process of finding duplicate data at the disk block, file, and/or object "" ""level to minimize storage use—currently unsupported within OpenStack."" msgstr """" ""ディスク使用を最小化するために、ディスクブロック、ファイル、オブジェクトレベ"" ""ルにあるデータの重複を見つけるプロセス。現在 OpenStack 内では未サポート。"" msgid """" ""The process of migrating one or all virtual machine (VM) instances from one "" ""host to another, compatible with both shared storage live migration and "" ""block migration."" msgstr """" ""１つまたは全ての仮想マシン（VM）インスタンスをあるホストから別のホストにマイ"" ""グレーションする処理。共有ストレージのライブマイグレーションとブロックマイグ"" ""レーション両方と互換がある。"" msgid ""The process of moving a VM instance from one host to another."" msgstr ""VM インスタンスをあるホストから別のホストに移動させる処理。"" msgid """" ""The process of putting a file into a virtual machine image before the "" ""instance is started."" msgstr """" ""インスタンスが起動する前に、仮想マシンイメージ中にファイルを配置する処理。"" msgid """" ""The process of removing the association between a floating IP address and a "" ""fixed IP address. Once this association is removed, the floating IP returns "" ""to the address pool."" msgstr """" ""Floating IP アドレスと固定 IP アドレスの関連付けを解除する処理。この関連付け"" ""が解除されると、Floating IP はアドレスプールに戻されます。"" msgid """" ""The process of removing the association between a floating IP address and "" ""fixed IP and thus returning the floating IP address to the address pool."" msgstr """" ""Floating IP アドレスと固定 IP の関連付けを削除する処理。これにより、Floating "" ""IP アドレスをアドレスプールに返す。"" msgid """" ""The process of spreading client requests between two or more nodes to "" ""improve performance and availability."" msgstr """" ""パフォーマンスや可用性を向上するために、2 つ以上のノード間でクライアントリク"" ""エストを分散する処理。"" msgid """" ""The process of taking a floating IP address from the address pool so it can "" ""be associated with a fixed IP on a guest VM instance."" msgstr """" ""アドレスプールから Floating IP アドレスを取得するプロセス。ゲスト仮想マシンイ"" ""ンスタンスに固定 IP を関連付けられるようにする。"" msgid """" ""The process that confirms that the user, process, or client is really who "" ""they say they are through private key, secret token, password, fingerprint, "" ""or similar method."" msgstr """" ""ユーザー、プロセスまたはクライアントが、秘密鍵、秘密トークン、パスワード、指"" ""紋または同様の方式により示されている主体と本当に同じであることを確認するプロ"" ""セス。"" msgid """" ""The project name for the Telemetry service, which is an integrated project "" ""that provides metering and measuring facilities for OpenStack."" msgstr """" ""Telemetry サービスのプロジェクト名。OpenStack 向けにメータリングと計測機能を"" ""提供する、統合プロジェクト。"" msgid ""The project that provides OpenStack Identity services."" msgstr ""OpenStack Identity サービスを提供するプロジェクト。"" msgid """" ""The protocol by which layer-3 IP addresses are resolved into layer-2 link "" ""local addresses."" msgstr ""L3 IP プロトコルが L2 リンクローカルアドレスに解決されるプロトコル。"" msgid ""The queue"" msgstr ""キュー"" msgid """" ""The recommended way to install setuptools on Microsoft Windows is to follow "" ""the documentation provided on the setuptools website (https://pypi.python."" ""org/pypi/setuptools). Another option is to use the unofficial binary "" ""installer maintained by Christoph Gohlke (`http://www.lfd.uci.edu/~gohlke/"" ""pythonlibs/ #setuptools <http://www.lfd.uci.edu/~gohlke/ pythonlibs/"" ""#setuptools>`__)."" msgstr """" ""Microsoft Windows に setuptools をインストールする推奨方法は、の Web サイト "" ""(https://pypi.python.org/pypi/setuptools) にあるドキュメントに従うことです。"" ""もう 1 つの選択肢は、Christoph Gohlke さんによりメンテナンスされている非公式"" ""バイナリーインストーラー (`http://www.lfd.uci.edu/~gohlke/pythonlibs/"" ""#setuptools <http://www.lfd.uci.edu/~gohlke/ pythonlibs/#setuptools>`__) を使"" ""用することです。"" msgid """" ""The registry is a private internal service meant for use by OpenStack Image "" ""service. Do not expose this service to users."" msgstr """" ""レジストリーは OpenStack Image service 自身が使用するプライベートな内部サービ"" ""スです。ユーザーに公開しないでください。"" msgid """" ""The router advertisement daemon, used by the Compute VLAN manager and "" ""FlatDHCP manager to provide routing services for VM instances."" msgstr """" ""ルーター通知デーモン。仮想マシンインスタンスにルーティングサービスを提供する"" ""ために、Compute の VLAN マネージャーと FlatDHCP マネージャーにより使用され"" ""る。"" msgid """" ""The row that has the value ``used_max`` in the ``PROJECT`` column shows the "" ""sum of the resources allocated to the instances that run on the host."" msgstr """" ""``PROJECT`` 列にある ``used_max`` という値の行は、ホストで実行中のインスタン"" ""スに割り当てられたリソースの合計を表示します。"" msgid """" ""The row that has the value ``used_now`` in the ``PROJECT`` column shows the "" ""sum of the resources allocated to the instances that run on the host, plus "" ""the resources allocated to the virtual machine of the host itself."" msgstr """" ""``PROJECT`` 列にある ``used_now`` という値の行は、ホストで実行中のインスタン"" ""スに割り当てられたリソースの合計と、ホスト自体の仮想マシンに割り当てられたリ"" ""ソースを表示します。"" msgid """" ""The service enables deployers to integrate with the Orchestration service "" ""directly or through custom plug-ins."" msgstr """" ""オペレーターは 直接、あるいはカスタムプラグイン経由で様々なものを "" ""Orchestration サービスと統合できます。"" msgid """" ""The software package used to provide AMQP messaging capabilities within "" ""Compute. Default package is RabbitMQ."" msgstr """" ""Compute 内で AMQP メッセージング機能を提供するために使用されるソフトウェア"" ""パッケージ。標準のパッケージは RabbitMQ。"" msgid ""The solution addresses the following use cases:"" msgstr ""このソリューションで、以下のユースケースが解決できます。"" msgid """" ""The source used by Identity service to retrieve user information; an "" ""OpenLDAP server, for example."" msgstr """" ""ユーザー情報を取得するために、Identity により使用されるソース。例えば、"" ""OpenLDAP。"" msgid """" ""The step in the Compute scheduling process when hosts that cannot run VMs "" ""are eliminated and not chosen."" msgstr """" ""VM を実行できないホストを排除し、選択されないようにする Compute のスケジュー"" ""リング処理の段階。"" msgid """" ""The storage method used by the Identity service catalog service to store and "" ""retrieve information about API endpoints that are available to the client. "" ""Examples include an SQL database, LDAP database, or KVS back end."" msgstr """" ""クライアントが利用可能な API エンドポイントに関する情報を保存、取得するのに、"" ""Identity サービスのカタログサービスが使用する保存方式。SQL データベース、"" ""LDAP データベース、KVS バックエンドなどがある。"" msgid """" ""The sum of each cost used when deciding where to start a new VM instance in "" ""Compute."" msgstr """" ""Compute で新しい仮想マシンを起動する場所を判断するときに使用される各コストの"" ""合計。"" msgid ""The tenant who owns an Image service virtual machine image."" msgstr ""Image service の仮想マシンイメージを所有するテナント。"" msgid ""The tenant who should own the image. The size of image data, in bytes."" msgstr ""イメージを所有するプロジェクト。イメージのバイト単位の容量。"" msgid """" ""The top of the window displays your user name. You can also access the :"" ""guilabel:`Settings` tab (:ref:`dashboard-settings-tab`) or sign out of the "" ""dashboard."" msgstr """" ""ウィンドウの上部に自分のユーザー名が表示されます。また、 :guilabel:`設定` タ"" ""ブ (:ref:`dashboard-settings-tab`) にアクセスしたり、ダッシュボードからログア"" ""ウトしたりできます。"" msgid """" ""The transfer of data, usually in the form of files, from one computer to "" ""another."" msgstr """" ""あるコンピューターから他のコンピューターへのデータの転送。通常はファイルの形"" ""式。"" msgid """" ""The underlying format that a disk image for a VM is stored as within the "" ""Image service back-end store. For example, AMI, ISO, QCOW2, VMDK, and so on."" msgstr """" ""仮想マシンのディスクイメージが Image service のバックエンドストア内で保存され"" ""る、バックエンドの形式。AMI、ISO、QCOW2、VMDK などがある。"" msgid """" ""The universal measurement of how quickly data is transferred from place to "" ""place."" msgstr """" ""データがある場所から別の場所にどのくらい速く転送されるかの普遍的な計測基準。"" msgid """" ""The valid model values depend on the ``libvirt_type`` setting, as shown in "" ""the following tables."" msgstr """" ""有効なモデルの値は、以下の表にあるように ``libvirt_type`` 設定により左右され"" ""ます。"" msgid """" ""The visible tabs and functions in the dashboard depend on the access "" ""permissions, or roles, of the user you are logged in as."" msgstr """" ""ダッシュボードに表示されるタブと機能は、ログインユーザーのアクセス権限やロー"" ""ルにより異なります。 "" msgid """" ""The volume must be in an ``available`` state or the request will be denied. "" ""If the transfer request is valid in the database (that is, it has not "" ""expired or been deleted), the volume is placed in an ``awaiting transfer`` "" ""state. For example:"" msgstr """" ""ボリュームが ``利用可能`` の状態でない場合、要求は却下されます。転送要求が"" ""データベース内で有効な場合 (失効していない、または削除されていない場合)、ボ"" ""リュームは ``awaiting transfer`` の状態になります。たとえば、 "" msgid """" ""The web-based management interface for OpenStack. An alternative name for "" ""horizon."" msgstr ""OpenStack 用 Web ベース管理インターフェース。Horizon の別名。"" msgid ""Then install pip and use it to manage client installation:"" msgstr ""pip をインストールして、インストールするクライアントを管理します。"" msgid ""Then you can install the packages:"" msgstr ""そして、パッケージをインストールします。"" msgid """" ""Theoretically, OpenStack Compute can support any database that SQL-Alchemy "" ""supports. Common databases are SQLite3 for test and development work, MySQL, "" ""and PostgreSQL."" msgstr """" ""理論的には、OpenStack Compute は SQL-Alchemy がサポートするデータベースをすべ"" ""てサポートします。一般的に使用されているデータベースは、テスト・開発用には "" ""SQLite3、それ以外では MySQL や PostgreSQL です。"" msgid """" ""There are also packaged versions of the clients available in `RDO <https://"" ""www.rdoproject.org/>`__ that enable yum to install the clients as described "" ""in Installing_from_packages_."" msgstr """" ""Installing_from_packages_ に記載されているように、yum を使用してインストール"" ""できるクライアントパッケージも `RDO <https://www.rdoproject.org/>`__ にありま"" ""す。"" msgid """" ""There are also packaged versions of the clients available that enable zypper "" ""to install the clients as described in Installing_from_packages_."" msgstr """" ""Installing_from_packages_ に記載されているように、zypper を使用してインストー"" ""ルできるクライアントパッケージもあります。"" msgid """" ""These services communicate by using the OpenStack messaging bus. Only the "" ""collector and API server have access to the data store."" msgstr """" ""これらのサービスは OpenStack のメッセージバスを使って通信します。コレクター"" ""と API サーバーだけがデータストアにアクセスできます。"" msgid """" ""These values are computed by using information about the flavors of the "" ""instances that run on the hosts. This command does not query the CPU usage, "" ""memory usage, or hard disk usage of the physical host."" msgstr """" ""これらの値は、ホストで実行されるインスタンスのフレーバーに関する情報を使用し"" ""て計算されます。このコマンドは、物理ホストの CPU の使用状況、メモリーの使用状"" ""況、ハードディスクの使用状況の問い合わせは行いません。"" msgid ""This example creates a ``my-new-volume`` volume based on an image."" msgstr """" ""以下の例では、イメージをベースにして ``my-new-volume`` ボリュームを作成しま"" ""す。"" msgid ""This example is a high-level process flow for using Database services:"" msgstr """" ""この例は、Database サービスを使用するための高レベルなプロセスフローです。"" msgid """" ""This glossary offers a list of terms and definitions to define a vocabulary "" ""for OpenStack-related concepts."" msgstr """" ""この用語集は、OpenStack 関連の概念の語彙を定義するための用語や定義の一覧を提"" ""供します。"" msgid ""This guide focuses on the ``local_settings.py`` file."" msgstr ""このガイドは ``local_settings.py`` ファイルでの設定を扱います。"" msgid """" ""This guide is adapted from `How To Custom Brand The OpenStack \""Horizon\"" "" ""Dashboard <http://www.prestonlee.com/2012/05/09/how-to-custom-brand-the-"" ""openstack-horizon-dashboard/>`_."" msgstr """" ""このガイドは `How To Custom Brand The OpenStack \""Horizon\"" Dashboard "" ""<http://www.prestonlee.com/2012/05/09/how-to-custom-brand-the-openstack-"" ""horizon-dashboard/>`_ を元にしています。"" msgid ""This section describes OpenStack services in detail."" msgstr ""このセクションでは OpenStack のサービスを詳しく説明します。"" msgid """" ""To add to OpenStack glossary, clone the `openstack/openstack-manuals "" ""repository <https://git.openstack.org/cgit/openstack/openstack-manuals>`__ "" ""and update the source file ``doc/glossary/glossary-terms.xml`` through the "" ""OpenStack contribution process."" msgstr """" ""OpenStack 用語集に追加する場合、OpenStack の貢献プロセスに沿って、 "" ""`openstack/openstack-manuals リポジトリー <https://git.openstack.org/cgit/"" ""openstack/openstack-manuals>`__ をクローンし、ソースファイル ``doc/glossary/"" ""glossary-terms.xml`` を更新してください。"" msgid """" ""To avoid storing the password in plain text, you can prompt for the "" ""OpenStack password interactively."" msgstr """" ""OpenStack のパスワードを対話的に入力して、パスワードを平文で保存することを避"" ""けることもできます。"" msgid ""To create an image, use :command:`glance image-create`:"" msgstr "":command:`glance image-create` を使用して、イメージを作成します。"" msgid """" ""To delete your volume, you must first detach it from the server. To detach "" ""the volume from your server and check for the list of existing volumes, see "" ""steps 1 and 2 in Resize_a_volume_."" msgstr """" "" ボリュームを削除するには、まずサーバーからボリュームを切り離す必要がありま"" ""す。サーバーからボリュームを切り離して既存のボリューム一覧を確認するには、"" ""Resize_a_volume_ のステップ 1 と 2 を参照します。"" msgid """" ""To design, deploy, and configure OpenStack, administrators must understand "" ""the logical architecture."" msgstr """" ""クラウド管理者は、OpenStack を設計、導入、設定するために、論理アーキテク"" ""チャーを理解する必要があります。"" msgid """" ""To get a list of images and to get further details about a single image, "" ""use :command:`glance image-list` and :command:`glance image-show` commands."" msgstr """" ""イメージの一覧を取得して単一のイメージの詳細を確認するには、 :command:"" ""`glance image-list` と :command:`glance image-show` コマンドを使用します。"" msgid """" ""To install the clients on a Linux, Mac OS X, or Microsoft Windows system, "" ""use pip. It is easy to use, ensures that you get the latest version of the "" ""clients from the `Python Package Index <https://pypi.python.org/>`__, and "" ""lets you update or remove the packages later on."" msgstr """" ""Linux、Mac OS X、Microsoft Windows システムにクライアントをインストールする場"" ""合、pip を使用します。これは使いやすく、 `Python Package Index <https://pypi."" ""python.org/>`__ からきちんと最新版のクライアントを取得します。また、後から更"" ""新や削除することもできます。"" msgid """" ""To provide feedback on documentation, join and use the openstack-docs@lists."" ""openstack.org mailing list at `OpenStack Documentation Mailing List <http://"" ""lists.openstack.org/cgi-bin/mailman/listinfo/openstack-docs>`__, or `report "" ""a bug <https://bugs.launchpad.net/openstack-manuals/+filebug>`__."" msgstr """" ""ドキュメントにフィードバックを行う場合は、`OpenStack Documentation メーリング"" ""リスト <http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack-"" ""docs>`__ にある openstack-docs@lists.openstack.org メーリングリストに参加して"" ""ください。または、`バグ報告 <https://bugs.launchpad.net/openstack-manuals/"" ""+filebug>`__ をしてください。"" msgid ""To remove the client, run the :command:`pip uninstall` command:"" msgstr """" ""クライアントを削除する場合、 :command:`pip uninstall` コマンドを実行します。"" msgid """" ""To resize your volume, you must first detach it from the server. To detach "" ""the volume from your server, pass the server ID and volume ID to the "" ""following command:"" msgstr """" ""ボリュームをリサイズするには、まずボリュームをサーバーから切り離します。以下"" ""のコマンドでサーバー ID とボリューム ID を指定して、サーバーからボリュームを"" ""切り離します。"" msgid """" ""To set the required environment variables for the OpenStack command-line "" ""clients, you must create an environment file called an OpenStack rc file, or "" ""``openrc.sh`` file. If your OpenStack installation provides it, you can "" ""download the file from the OpenStack dashboard as an administrative user or "" ""any other user. This project-specific environment file contains the "" ""credentials that all OpenStack services use."" msgstr """" ""OpenStack コマンドラインクライアントに必要な環境変数を設定するには、"" ""OpenStack rc ファイルと呼ばれる環境ファイルまたは ``openrc.sh`` ファイルを作"" ""成する必要があります。OpenStack のインストールでこのファイルが提供される場合"" ""は、管理ユーザーまたはその他のユーザーで OpenStack Dashboard からダウンロード"" ""してください。このプロジェクト固有の環境ファイルには、OpenStack サービスが使"" ""用する認証情報が含まれます。 "" msgid """" ""To store location metadata for images, which enables direct file access for "" ""a client, update the ``/etc/glance/glance-api.conf`` file with the following "" ""statements:"" msgstr """" ""イメージの場所のメタデータを保存してクライアントが直接ファイルにアクセスでき"" ""るようにするには、``/etc/glance/glance-api.conf`` ファイルで以下のステートメ"" ""ントを追加更新します。 "" msgid ""To update an image by name or ID, use :command:`glance image-update`:"" msgstr """" "":command:`glance image-update` を使用して、名前または ID によりイメージを更新"" ""します。"" msgid """" ""To upgrade a client, add the :option:`--upgrade` option to the :command:`pip "" ""install` command:"" msgstr """" "":command:`pip install` コマンドを :option:`--upgrade` オプションを追加して、"" ""クライアントをアップグレードします。"" msgid """" ""To use the Virtual Network Computing (VNC) client for the dashboard, your "" ""browser must support HTML5 Canvas and HTML5 WebSockets. The VNC client is "" ""based on noVNC. For details, see `noVNC: HTML5 VNC Client <https://github."" ""com/kanaka/noVNC/blob/master/README.md>`__. For a list of supported "" ""browsers, see `Browser support <https://github.com/kanaka/noVNC/wiki/Browser-"" ""support>`__."" msgstr """" ""ダッシュボードにおいて Virtual Network Computing (VNC) クライアントを使用する"" ""ためには、ブラウザーが HTML5 Canvas と HTML5 WebSockets をサポートしている必"" ""要があります。詳細は `noVNC: HTML5 VNC Client <https://github.com/kanaka/"" ""noVNC/blob/master/README.md>`__ を参照してください。また、サポートされるブラ"" ""ウザーの一覧は `Browser support <https://github.com/kanaka/noVNC/wiki/"" ""Browser-support>`__ を参照してください。"" msgid """" ""To verify that your volume was created successfully, list the available "" ""volumes:"" msgstr """" ""ボリュームが正常に作成されたことを確認するには、利用可能なボリュームを一覧表"" ""示します。"" msgid """" ""To view your changes reload your dashboard. If necessary go back and modify "" ""your CSS file as appropriate."" msgstr """" ""ダッシュボードを再読み込みして、変更を表示します。必要があれば、上に戻って "" ""CSS ファイルを適切に変更してください。"" msgid """" ""Tool used for maintaining Address Resolution Protocol packet filter rules in "" ""the Linux kernel firewall modules. Used along with iptables, ebtables, and "" ""ip6tables in Compute to provide firewall services for VMs."" msgstr """" ""Linux カーネルファイアウォールモジュールで ARP パケットフィルタールールを維持"" ""するために使用されるツール。仮想マシン向けのファイアウォールサービスを提供す"" ""るために、Compute で iptables、ebtables、ip6tables と一緒に使用される。"" msgid """" ""Tool used in OpenStack development to ensure correctly ordered testing of "" ""changes in parallel."" msgstr """" ""OpenStack 開発で使用されているツールで、変更のテストを正しい順番を保証しなが"" ""ら並列に実行する。"" msgid ""Tool used to run jobs automatically for OpenStack development."" msgstr ""OpenStack 開発のためにジョブを自動的に実行するために使用されるツール。"" msgid """" ""Tool used to set up, maintain, and inspect the tables of IPv6 packet filter "" ""rules in the Linux kernel. In OpenStack Compute, ip6tables is used along "" ""with arptables, ebtables, and iptables to create firewalls for both nodes "" ""and VMs."" msgstr """" ""Linux カーネルで IPv6 パケットフィルタールールのテーブルをセットアップ、維"" ""持、検査するために使用されるツール。OpenStack Compute では、ノードと仮想マシ"" ""ンの両方に対するファイアウォールを作成するために、ip6tables が arptables、"" ""ebtables、iptables と一緒に使用される。"" msgid ""Torpedo"" msgstr ""Torpedo"" msgid ""Transfer a volume"" msgstr ""ボリュームの譲渡"" msgid ""TripleO"" msgstr ""TripleO"" msgid ""Troubleshoot image creation"" msgstr ""イメージ作成のトラブルシューティング"" msgid """" ""Type of Compute scheduler that evenly distributes instances among available "" ""hosts."" msgstr """" ""利用可能なホスト間でインスタンスを平等に分散させる、Compute のスケジューラー"" ""の一種。"" msgid ""UUID for each Compute or Image service VM flavor or instance type."" msgstr """" ""Compute や Image service の仮想マシンの各フレーバーやインスタンスタイプの "" ""UUID。"" msgid ""UUID used by Image service to uniquely identify each VM image."" msgstr """" ""各仮想マシンイメージを一意に識別するために Image service により使用される "" ""UUID。"" msgid ""Ubuntu"" msgstr ""Ubuntu"" msgid """" ""Under the Compute distributed scheduler, this is calculated by looking at "" ""the capabilities of each host relative to the flavor of the VM instance "" ""being requested."" msgstr """" ""Compute の分散スケジューラーにおいて、要求している仮想マシンインスタンスのフ"" ""レーバーに関連する、各ホストのキャパシティーにより計算される。"" msgid """" ""Unique ID applied to each storage volume under the Block Storage control."" msgstr """" ""Block Storage の管理下にある各ストレージボリュームに適用される一意な ID。"" msgid ""Unique ID assigned to each Networking VIF."" msgstr ""各 Networking VIF に割り当てられる一意な ID。"" msgid """" ""Unique ID assigned to each Object Storage request; used for debugging and "" ""tracing."" msgstr """" ""各 Object Storage リクエストに割り当てられる一意な ID。デバッグや追跡に使用さ"" ""れる。"" msgid ""Unique ID assigned to each guest VM instance."" msgstr ""各ゲスト仮想マシンインスタンスに割り当てられる一意な ID。"" msgid """" ""Unique ID assigned to each network segment within Networking. Same as "" ""network UUID."" msgstr """" ""Networking 内の各ネットワークセグメントに割り当てられる一意な ID。ネットワー"" ""ク UUID と同じ。"" msgid ""Unique ID assigned to each request sent to Compute."" msgstr ""Compute に送られる各リクエストに割り振られる一意な ID。"" msgid """" ""Unique ID assigned to each service that is available in the Identity service "" ""catalog."" msgstr """" ""Identity のサービスカタログで利用可能な各サービスに割り当てられる一意な ID。"" msgid """" ""Unique ID assigned to each tenant within the Identity service. The project "" ""IDs map to the tenant IDs."" msgstr """" ""Identity 内で各テナントに割り当てられる一意な ID。プロジェクト ID は、テナン"" ""ト ID に対応付けられる。"" msgid ""Unique ID for a Networking VIF or vNIC in the form of a UUID."" msgstr ""Networking 仮想インターフェースや vNIC 用の一意な UUID 形式の ID。"" msgid ""Unique ID for a Networking network segment."" msgstr ""Networking ネットワークセグメントの一意な ID。"" msgid ""Unique ID for a Networking port."" msgstr ""Networking ポートのユニーク ID。"" msgid """" ""Unique numeric ID associated with each user in Identity, conceptually "" ""similar to a Linux or LDAP UID."" msgstr """" ""Identity で各ユーザーと関連付けられた一意な数値 ID。概念として、Linux や "" ""LDAP の UID を同じ。"" msgid ""Uniquely ID for an Object Storage object."" msgstr ""Object Storage オブジェクト用の一意な ID。"" msgid ""Upgrade or remove clients"" msgstr ""クライアントの更新と削除"" msgid """" ""Upload your new images to ``/usr/share/openstack-dashboard/"" ""openstack_dashboard/static/dashboard/img/``."" msgstr """" ""新しいイメージを ``/usr/share/openstack-dashboard/openstack_dashboard/static/"" ""dashboard/img/`` にアップロードします。"" msgid """" ""Use OpenStack Compute to host and manage cloud computing systems. OpenStack "" ""Compute is a major part of an Infrastructure-as-a-Service (:term:`IaaS`) "" ""system. The main modules are implemented in Python."" msgstr """" ""OpenStack Compute を使用して、クラウドコンピューティングシステムを動かし管理"" ""を行います。OpenStack Compute は、Infrastructure-as-a-Service (:term:`IaaS`) "" ""システムの主要な要素です。主要なモジュールは Python で実装されています。"" msgid ""Use cases include:"" msgstr ""以下のユースケースがあります。"" msgid """" ""Use pip to install the OpenStack clients on a Linux, Mac OS X, or Microsoft "" ""Windows system. It is easy to use and ensures that you get the latest "" ""version of the client from the `Python Package Index <https://pypi.python."" ""org/pypi>`__. Also, pip enables you to update or remove a package."" msgstr """" ""Linux、Mac OS X、Microsoft Windows システムに OpenStack クライアントをインス"" ""トールする場合、pip を使用します。これは使いやすく、きちんと最新版のクライア"" ""ントを `Python Package Index <https://pypi.python.org/pypi>`__ から取得しま"" ""す。また、パッケージを更新したり削除したりできます。"" msgid """" ""Use the :command:`trove list` command to get the ID of the instance, "" ""followed by the :command:`trove show` command to get the IP address of it."" msgstr """" "":command:`trove list` コマンドを使用して、インスタンスの ID を取得します。続"" ""けて、:command:`trove show` コマンドを使用して、その IP アドレスを取得しま"" ""す。"" msgid """" ""Use the :command:`trove-manage` command to import images and offer them to "" ""tenants."" msgstr """" "":command:`trove-manage` コマンドを使用して、イメージをインポートして、それら"" ""をテナントに提供します。"" msgid """" ""Used along with an EC2 access key when communicating with the Compute EC2 "" ""API; used to digitally sign each request."" msgstr """" ""Compute EC2 API 利用時に EC2 アクセスキーと一緒に使用される。各リクエストを電"" ""子署名するために使用される。"" msgid ""Used along with an EC2 secret key to access the Compute EC2 API."" msgstr ""Compute EC2 API にアクセスするために、EC2 秘密鍵と一緒に使用される。"" msgid ""Used along with an EKI to create an EMI."" msgstr ""EMI を作成するために、EKI と一緒に使用する。"" msgid ""Used along with an ERI to create an EMI."" msgstr ""EMI を作成するために、ERI と一緒に使用する。"" msgid """" ""Used along with arptables and ebtables, iptables create firewalls in "" ""Compute. iptables are the tables provided by the Linux kernel firewall "" ""(implemented as different Netfilter modules) and the chains and rules it "" ""stores. Different kernel modules and programs are currently used for "" ""different protocols: iptables applies to IPv4, ip6tables to IPv6, arptables "" ""to ARP, and ebtables to Ethernet frames. Requires root privilege to "" ""manipulate."" msgstr """" ""Compute においてファイアウォールを作成する、arptables、ebtables、iptables と"" ""一緒に使用される。iptables は、Linux カーネルファイアウォール (別の "" ""Netfilter モジュール) により提供されるテーブル、それを保存するチェインやルー"" ""ル。複数のカーネルモジュールとプログラムが、別々のプロトコルに対して使用され"" ""る。iptables は IPv4、ip6tables は IPv6、arptables は ARP、ebtables は "" ""Ethernet フレームに適用される。操作すうために root 権限が必要になる。"" msgid """" ""Used by Image service to obtain images on the local host rather than re-"" ""downloading them from the image server each time one is requested."" msgstr """" ""イメージが要求されたときに、イメージサーバーから再ダウンロードするのではな"" ""く、ローカルホストにあるイメージを取得するために、Image service により使用さ"" ""れる。"" msgid """" ""Used by Object Storage devices to determine which storage devices are "" ""suitable for the job. Devices are weighted by size."" msgstr """" ""どのストレージデバイスがジョブに対して適切であるかを判断するために、Object "" ""Storage デバイスにより使用される。デバイスは容量により重み付けされる。"" msgid """" ""Used by Object Storage to determine the location of an object in the ring. "" ""Maps objects to partitions."" msgstr """" ""リング内でオブジェクトの場所を判断するために、Object Storage により使用され"" ""る。オブジェクトをパーティションに対応付ける。"" msgid """" ""Used by Object Storage to determine which partition data should reside on."" msgstr """" ""パーティションデータが配置されるべき場所を決めるために、Object Storage により"" ""使用される。"" msgid ""Used by Object Storage to push object replicas."" msgstr """" ""オブジェクトの複製をプッシュするために Object Storage により使用される。"" msgid """" ""Used by most OpenStack Networking installations to route information between "" ""the neutron-server and various agents. Also acts as a database to store "" ""networking state for particular plug-ins."" msgstr """" ""ほとんどの OpenStack Networking のインストール環境において、neutron-server と"" ""各種エージェント間での情報の転送に使用されます。プラグインによってはネット"" ""ワーク状態を保存するのにも使用されます。"" msgid ""Used for adding additional persistent storage to a virtual machine (VM)"" msgstr ""永続的なストレージを仮想マシン（VM）へ追加するために使用される"" msgid ""Used for providing file shares to a virtual machine"" msgstr ""ファイル共有を仮想マシンに提供するために使用される"" msgid ""Used for storing virtual machine images and data"" msgstr ""仮想マシンイメージとデータを保存するために使用される"" msgid """" ""Used to mark Object Storage objects that have been deleted; ensures that the "" ""object is not updated on another node after it has been deleted."" msgstr """" ""Object Storage のオブジェクトが削除済みであることを示す印をつけるために使用さ"" ""れる。オブジェクトの削除後、他のノードにおいて更新されないことを保証する。"" msgid """" ""Used to restrict communications between hosts and/or nodes, implemented in "" ""Compute using iptables, arptables, ip6tables, and ebtables."" msgstr """" ""ホストノード間の通信を制限する為に使用される。iptables, arptables, "" ""ip6tables, ebtables を使用して Compute により実装される。"" msgid ""Used to track segments of a large object within Object Storage."" msgstr ""Object Storage 内で大きなオブジェクトを管理するために使用される。"" msgid ""User Mode Linux (UML)"" msgstr ""User Mode Linux (UML)"" msgid ""User-defined alphanumeric string in Compute; the name of a project."" msgstr ""Compute でユーザーが定義した英数文字列。プロジェクトの名前。"" msgid ""User-friendly UI for ad-hoc analytics queries based on Hive or Pig."" msgstr """" ""Hive や Pig をベースにした、アドホックな分析クエリー向けのユーザーフレンド"" ""リーな UI。"" msgid """" ""Users can access OpenStack via the web-based user interface implemented by "" ""the :ref:`get_started_dashboard`, via `command-line clients <http://docs."" ""openstack.org/cli-reference/>`__ and by issuing API requests through tools "" ""like browser plug-ins or :command:`curl`. For applications, `several SDKs "" ""<http://developer.openstack.org/#sdk>`__ are available. Ultimately, all "" ""these access methods issue REST API calls to the various OpenStack services."" msgstr """" ""ユーザーが OpenStack にアクセスする方法はいくつかあり、 :ref:"" ""`get_started_dashboard` が提供するウェブベースのユーザーインターフェースを使"" ""う方法、 `コマンドラインクライアント <http://docs.openstack.org/cli-"" ""reference/>`__ を使う方法、ブラウザーのプラグインや :command:`curl` のような"" ""ツールを使って API リクエストを発行する方法などがあります。アプリケーション向"" ""けには `様々な SDK <http://developer.openstack.org/#sdk>`__ があります。最終"" ""的には、これらのアクセスはいずれも各種の OpenStack サービスへの REST API 呼び"" ""出しになります。"" msgid """" ""Users of Object Storage interact with the service through the proxy server, "" ""which in turn looks up the location of the requested data within the ring "" ""and returns the results to the user."" msgstr """" ""Object Storage のユーザーは、リング中にあるリクエストされたデータの場所を参照"" ""してユーザに結果を返すプロキシサーバーを介して、このサービスに通信する。"" msgid """" ""Utilization of unused compute power from general purpose OpenStack IaaS "" ""cloud."" msgstr """" ""汎用的な OpenStack IaaS クラウドの使用されていないコンピュートリソースの活用"" msgid ""VIF UUID"" msgstr ""VIF UUID"" msgid ""VIP"" msgstr ""仮想 IP"" msgid ""VLAN manager"" msgstr ""VLAN マネージャー"" msgid ""VLAN network"" msgstr ""VLAN ネットワーク"" msgid ""VM Remote Control (VMRC)"" msgstr ""VM Remote Control (VMRC)"" msgid ""VM disk (VMDK)"" msgstr ""VM disk (VMDK)"" msgid ""VM image"" msgstr ""仮想マシンイメージ"" msgid ""VM image container format supported by Image service."" msgstr ""Image service によりサポートされる仮想マシンイメージのコンテナー形式。"" msgid ""VMware API"" msgstr ""VMware API"" msgid ""VMware NSX Neutron plug-in"" msgstr ""VMware NSX Neutron プラグイン"" msgid ""VMwareAPI for VMware"" msgstr ""VMware 向けの VMwareAPI"" msgid ""VNC proxy"" msgstr ""VNC プロキシ"" msgid ""VXLAN"" msgstr ""VXLAN"" msgid ""Various periodic processes"" msgstr ""さまざまな定期タスク"" msgid """" ""Various repository types are supported including normal file systems, Object "" ""Storage, RADOS block devices, HTTP, and Amazon S3. Note that some "" ""repositories will only support read-only usage."" msgstr """" ""さまざまな種類のリポジトリーがサポートされており、通常のファイルシステム、"" ""Object Storage、RADOS ブロックデバイス、HTTP、Amazon S3 などがあります。いく"" ""つかのリポジトリーでは、読み込み専用の利用だけがサポートされている点に注意し"" ""てください。"" msgid """" ""Verify that transfer list is now empty and that the volume is again "" ""available for transfer:"" msgstr ""転送一覧が空になり、ボリュームが転送に使用できることを確認します。"" msgid ""View pending transfers:"" msgstr "" 待機中の転送を確認します。"" msgid ""Virtual Central Processing Unit (vCPU)"" msgstr ""仮想CPU (vCPU)"" msgid ""Virtual Disk Image (VDI)"" msgstr ""Virtual Disk Image (VDI)"" msgid ""Virtual Hard Disk (VHD)"" msgstr ""Virtual Hard Disk (VHD)"" msgid ""Virtual Network Computing (VNC)"" msgstr ""Virtual Network Computing (VNC)"" msgid ""Virtual Network InterFace (VIF)"" msgstr ""仮想ネットワークインタフェース (VIF)"" msgid """" ""Virtual network type that uses neither VLANs nor tunnels to segregate tenant "" ""traffic. Each flat network typically requires a separate underlying physical "" ""interface defined by bridge mappings. However, a flat network can contain "" ""multiple subnets."" msgstr """" ""テナントの通信を分離するために、VLAN もトンネルも使用しない仮想ネットワーク方"" ""式。各フラットネットワークは、一般的にブリッジマッピングにより定義された、"" ""バックエンドに専用の物理インターフェースを必要とする。しかしながら、フラット"" ""ネットワークは複数のサブネットを含められる。"" msgid ""VirtualBox"" msgstr ""VirtualBox"" msgid ""VirtualE1000"" msgstr ""VirtualE1000"" msgid ""VirtualPCNet32"" msgstr ""VirtualPCNet32"" msgid ""VirtualVmxnet"" msgstr ""VirtualVmxnet"" msgid """" ""Virtualization API library used by OpenStack to interact with many of its "" ""supported hypervisors."" msgstr """" ""多くのサポートハイパーバイザーと通信するために、OpenStack により使用される仮"" ""想化 API ライブラリー。"" msgid ""Volume API"" msgstr ""Volume API"" msgid """" ""Volume that does not save the changes made to it and reverts to its original "" ""state when the current user relinquishes control."" msgstr """" ""変更が保存されないボリューム。現在のユーザーが制御を解放したとき、元の状態に"" ""戻される。"" msgid ""WSGI middleware"" msgstr ""WSGI ミドルウェア"" msgid """" ""WSGI middleware component of Object Storage that serves container data as a "" ""static web page."" msgstr """" ""コンテナーデータを静的 Web ページとして取り扱う Object Storage の WSGI ミドル"" ""ウェアコンポーネント。"" msgid ""What's next"" msgstr ""次の手順"" msgid """" ""When installing OpenStack Identity service, you must register each service "" ""in your OpenStack installation. Identity service can then track which "" ""OpenStack services are installed, and where they are located on the network."" msgstr """" ""OpenStack Identity をインストールする際に、OpenStack の各サービスを登録する必"" ""要があります。これにより、Identity サービスは、OpenStack のサービスがインス"" ""トールされていること、それらがネットワーク上のどこにあるかを把握できます。"" msgid """" ""When the volume is fully deleted, it disappears from the list of volumes:"" msgstr """" ""ボリュームが完全に削除されると、ボリュームの一覧には表示されなくなります。"" msgid """" ""When viewing a list of images, you can also use ``grep`` to filter the list, "" ""as follows:"" msgstr """" ""以下のように、イメージ一覧の確認の際に、``grep`` を使用して一覧をフィルタリン"" ""グすることができます。 "" msgid """" ""When you are prompted for an OpenStack password, enter the password for the "" ""user who downloaded the ``PROJECT-openrc.sh`` file."" msgstr """" ""OpenStack パスワードの入力プロンプトが表示されたとき、``PROJECT-openrc.sh`` "" ""ファイルをダウンロードしたユーザーのパスワードを入力します。"" msgid """" ""When you run OpenStack client commands, you can override some environment "" ""variable settings by using the options that are listed at the end of the "" ""``help`` output of the various client commands. For example, you can "" ""override the ``OS_PASSWORD`` setting in the ``PROJECT-openrc.sh`` file by "" ""specifying a password on a :command:`openstack` command, as follows:"" msgstr """" ""OpenStack クライアントコマンドを実行するとき、さまざまなクライアントコマンド"" ""の ``help`` 出力の最後に一覧表示されるオプションを使用することにより、いくつ"" ""かの環境変数を上書きできます。たとえば以下のように、:command:`openstack` コ"" ""マンドにパスワードを指定することにより、``PROJECT-openrc.sh`` ファイルで設定"" ""した ``OS_PASSWORD`` 設定を上書きできます。"" msgid """" ""When you source the file, environment variables are set for your current "" ""shell. The variables enable the OpenStack client commands to communicate "" ""with the OpenStack services that run in the cloud."" msgstr """" ""このファイルを読み込むと、環境変数が現在のシェルに対して設定されます。この変"" ""数により OpenStack クライアントコマンドがクラウドで実行中の OpenStack サービ"" ""スとやりとりできるようになります。"" msgid """" ""When you use OpenStack with VMware vCenter Server, you need to specify the "" ""``vmware_disktype`` and ``vmware_adaptertype`` properties with :command:"" ""`glance image-create`. Also, we recommend that you set the ``hypervisor_type="" ""\""vmware\""`` property. For more information, see `Images with VMware vSphere "" ""<http://docs.openstack.org/liberty/config-reference/content/vmware."" ""html#VMware_images>`_ in the *OpenStack Configuration Reference*."" msgstr """" ""OpenStack を VMware vCenter Server と一緒に使用している場合、:command:"" ""`glance image-create` を用いて ``vmware_disktype`` と ``vmware_adaptertype`` "" ""プロパティーを指定する必要があります。また、``hypervisor_type=\""vmware\""`` プ"" ""ロパティーを設定することを推奨します。詳細は *OpenStack Configuration "" ""Reference* の `Images with VMware vSphere <http://docs.openstack.org/liberty/"" ""config-reference/content/vmware.html#VMware_images>`_ を参照してください。"" msgid ""Where ``PASSWORD`` is your password."" msgstr ""ここで ``PASSWORD`` は、お使いのパスワードです。"" msgid ""While logged in as the volume donor, list the available volumes:"" msgstr """" ""ボリュームの譲渡元としてログインし、利用可能なボリュームを一覧表示します。"" msgid """" ""While the ``auth_key`` property is visible in the output of ``cinder "" ""transfer-create VOLUME_ID``, it will not be available in subsequent ``cinder "" ""transfer-show TRANSFER_ID`` commands."" msgstr """" ""``auth_key`` プロパティーが ``cinder transfer-create VOLUME_ID`` の出力に含ま"" ""れますが、後続の ``cinder transfer-show TRANSFER_ID`` コマンドではこれを利用"" ""できません。"" msgid """" ""While you can install the ``keystone`` client for interacting with version "" ""2.0 of the service's API, you should use the ``openstack`` client for all "" ""Identity interactions."" msgstr """" ""Identity API バージョン 2.0 を利用するために ``keystone`` クライアントをイン"" ""ストールできますが、すべての Identity 処理に ``openstack`` クライアントを使用"" ""すべきです。"" msgid """" ""Within RabbitMQ and Compute, it is the messaging interface that is used by "" ""the scheduler service to receive capability messages from the compute, "" ""volume, and network nodes."" msgstr """" ""RabbitMQ と Compute の中で、コンピュートノード、ボリュームノード、ネットワー"" ""クノードからのメッセージを受け付ける機能のために、スケジューラーサービスによ"" ""り使用されるメッセージングインターフェース。"" msgid ""Work in progress - expected for the Mitaka release"" msgstr ""Mitaka リリースに向けて開発中"" msgid ""Workflow service"" msgstr ""Workflow サービス"" msgid ""Workflow service for OpenStack cloud."" msgstr ""OpenStack クラウド向け Workflow サービス。"" msgid ""XFS"" msgstr ""XFS"" msgid ""Xen"" msgstr ""Xen"" msgid ""Xen API"" msgstr ""Xen API"" msgid ""Xen Cloud Platform (XCP)"" msgstr ""Xen Cloud Platform (XCP)"" msgid ""Xen Storage Manager Volume Driver"" msgstr ""Xen Storage Manager Volume Driver"" msgid """" ""Xen is a hypervisor using a microkernel design, providing services that "" ""allow multiple computer operating systems to execute on the same computer "" ""hardware concurrently."" msgstr """" ""Xen は、マイクロカーネル設計を使用したハイパーバイザー。複数のコンピューター"" ""オペレーティングシステムを同じコンピューターハードウェアで同時に実行できるよ"" ""うになるサービスを提供する。"" msgid ""XenAPI for XenServer/XCP"" msgstr ""XenServer/XCP 向けの XenAPI"" msgid ""XenServer"" msgstr ""XenServer"" msgid """" ""You are not prompted for the password with this method. The password lives "" ""in clear text format in the ``PROJECT-openrc.sh`` file. Restrict the "" ""permissions on this file to avoid security problems. You can also remove the "" ""``OS_PASSWORD`` variable from the file, and use the :option:`--password` "" ""parameter with OpenStack client commands instead."" msgstr """" ""この方法を用いると、パスワードを聞かれません。パスワードは ``PROJECT-openrc."" ""sh`` ファイルに平文で記載されています。セキュリティー問題を避けるために、この"" ""ファイルのパーミッションを制限します。このファイルから ``OS_PASSWORD`` 変数を"" ""削除し、OpenStack クライアントコマンドで :option:`--password` パラメーターを"" ""使用することもできます。"" msgid ""You can install pip and use it to manage client installation:"" msgstr """" ""pip をインストールして、インストールするクライアントを管理することができま"" ""す。"" msgid """" ""You can run the commands from the command line, or include the commands "" ""within scripts to automate tasks. If you provide OpenStack credentials, such "" ""as your user name and password, you can run these commands on any computer."" msgstr """" ""コマンドライン、または作業を自動化するスクリプトの中からコマンドを実行できま"" ""す。ユーザー名とパスワードのような、OpenStack のクレデンシャルを指定すると、"" ""どのコンピューターでもこれらのコマンドを実行できます。"" msgid """" ""You can show basic statistics on resource usage for hosts and instances."" msgstr """" ""ホストやインスタンスのリソース使用状況に関する基本的な統計を表示できます。"" msgid """" ""You can transfer a volume from one owner to another by using the :command:"" ""`cinder transfer*` commands. The volume donor, or original owner, creates a "" ""transfer request and sends the created transfer ID and authorization key to "" ""the volume recipient. The volume recipient, or new owner, accepts the "" ""transfer by using the ID and key."" msgstr """" "":command:`cinder transfer*` コマンドを使用して、別の所有者に転送することがで"" ""きます。ボリュームドナーまたは元の所有者が転送要求を作成し、作成した転送 ID "" ""と認証キーをボリュームの転送先に送信します。ボリュームの転送先または新規所有"" ""者が ID とキーを使用して転送を確定します。 "" msgid """" ""You can upload images through the ``glance`` client or the Image service "" ""API. You can use the ``nova`` client for the image management. The latter "" ""provides mechanisms to list and delete images, set and delete image "" ""metadata, and create images of a running instance or snapshot and backup "" ""types."" msgstr """" ""``glance`` クライアントまたは Image service API 経由でイメージをアップロード"" ""できます。イメージ管理のために ``nova`` クライアントを使用できます。後者は、"" ""イメージの一覧表示や削除、イメージのメタデータの設定や削除、実行中のインスタ"" ""ンスのスナップショットやバックアップの作成、などの機能を提供します。"" msgid """" ""You must set the ``OS_CACERT`` environment variable when using the https "" ""protocol in the ``OS_AUTH_URL`` environment setting because the verification "" ""process for the TLS (HTTPS) server certificate uses the one indicated in the "" ""environment. This certificate will be used when verifying the TLS (HTTPS) "" ""server certificate."" msgstr """" ""``OS_AUTH_URL`` 環境設定に HTTPS プロトコルを使用する場合、TLS (HTTPS) のサー"" ""バー証明書を検証するプロセスが、環境において指定されたものを使用するため、"" ""``OS_CACERT`` 環境変数を使用する必要があります。TLS (HTTPS) サーバー証明書を"" ""検証するとき、この証明書が使用されます。"" msgid ""ZeroMQ"" msgstr ""ZeroMQ"" msgid ""Zuul"" msgstr ""Zuul"" msgid """" ""`API Complete Reference (PDF) <http://developer.openstack.org/api-ref-guides/"" ""bk-api-ref.pdf>`__"" msgstr """" ""`API Complete Reference (PDF) <http://developer.openstack.org/api-ref-guides/"" ""bk-api-ref.pdf>`__"" msgid ""`API Guide <http://developer.openstack.org/api-guide/quick-start/>`__"" msgstr ""`API ガイド <http://developer.openstack.org/api-guide/quick-start/>`__"" msgid ""`Admin User Guide <http://docs.openstack.org/user-guide-admin/>`__"" msgstr """" ""`管理ユーザーガイド <http://docs.openstack.org/ja/user-guide-admin/>`__"" msgid ""`Architecture Design Guide <http://docs.openstack.org/arch-design/>`__"" msgstr """" ""`アーキテクチャー設計ガイド <http://docs.openstack.org/arch-design/>`__"" msgid """" ""`Block Storage <http://www.openstack.org/software/releases/liberty/"" ""components/cinder>`__"" msgstr """" ""`Block Storage <http://www.openstack.org/software/releases/liberty/"" ""components/cinder>`__"" msgid """" ""`Bugs: Application catalog (murano) <https://bugs.launchpad.net/murano>`__"" msgstr """" ""`バグ: Application catalog (murano) <https://bugs.launchpad.net/murano>`__"" msgid """" ""`Bugs: Bare metal service (ironic) <https://bugs.launchpad.net/ironic>`__"" msgstr """" ""`バグ: Bare metal service (ironic) <https://bugs.launchpad.net/ironic>`__"" msgid """" ""`Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgstr """" ""`バグ: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgid """" ""`Bugs: Containers service (magnum) <https://bugs.launchpad.net/magnum>`__"" msgstr """" ""`バグ: Containers service (magnum) <https://bugs.launchpad.net/magnum>`__"" msgid """" ""`Bugs: DNS service (designate) <https://bugs.launchpad.net/designate>`__"" msgstr """" ""`バグ: DNS service (designate) <https://bugs.launchpad.net/designate>`__"" msgid """" ""`Bugs: Data processing service (sahara) <https://bugs.launchpad.net/"" ""sahara>`__"" msgstr """" ""`バグ: Data processing service (sahara) <https://bugs.launchpad.net/"" ""sahara>`__"" msgid ""`Bugs: Database service (trove) <https://bugs.launchpad.net/trove>`__"" msgstr ""`バグ: Database service (trove) <https://bugs.launchpad.net/trove>`__"" msgid ""`Bugs: Deployment service (fuel) <https://bugs.launchpad.net/fuel>`__"" msgstr ""`バグ: Deployment service (fuel) <https://bugs.launchpad.net/fuel>`__"" msgid """" ""`Bugs: Key Manager Service (barbican) <https://bugs.launchpad.net/"" ""barbican>`__"" msgstr """" ""`バグ: Key Manager Service (barbican) <https://bugs.launchpad.net/"" ""barbican>`__"" msgid ""`Bugs: Messaging service (zaqar) <https://bugs.launchpad.net/zaqar>`__"" msgstr ""`バグ: Messaging service (zaqar) <https://bugs.launchpad.net/zaqar>`__"" msgid ""`Bugs: Monitoring (monasca) <https://bugs.launchpad.net/monasca>`__"" msgstr ""`バグ: Monitoring (monasca) <https://bugs.launchpad.net/monasca>`__"" msgid """" ""`Bugs: OpenStack API Documentation (developer.openstack.org) <https://bugs."" ""launchpad.net/openstack-api-site>`__"" msgstr """" ""`バグ: OpenStack API Documentation (developer.openstack.org) <https://bugs."" ""launchpad.net/openstack-api-site>`__"" msgid """" ""`Bugs: OpenStack Block Storage (cinder) <https://bugs.launchpad.net/"" ""cinder>`__"" msgstr """" ""`バグ: OpenStack Block Storage (cinder) <https://bugs.launchpad.net/"" ""cinder>`__"" msgid ""`Bugs: OpenStack Compute (nova) <https://bugs.launchpad.net/nova>`__"" msgstr ""`バグ: OpenStack Compute (nova) <https://bugs.launchpad.net/nova>`__"" msgid """" ""`Bugs: OpenStack Dashboard (horizon) <https://bugs.launchpad.net/horizon>`__"" msgstr """" ""`バグ: OpenStack Dashboard (horizon) <https://bugs.launchpad.net/horizon>`__"" msgid """" ""`Bugs: OpenStack Documentation (docs.openstack.org) <https://bugs.launchpad."" ""net/openstack-manuals>`__"" msgstr """" ""`バグ: OpenStack Documentation (docs.openstack.org) <https://bugs.launchpad."" ""net/openstack-manuals>`__"" msgid """" ""`Bugs: OpenStack Identity (keystone) <https://bugs.launchpad.net/keystone>`__"" msgstr """" ""`バグ: OpenStack Identity (keystone) <https://bugs.launchpad.net/keystone>`__"" msgid """" ""`Bugs: OpenStack Image service (glance) <https://bugs.launchpad.net/"" ""glance>`__"" msgstr """" ""`バグ: OpenStack Image service (glance) <https://bugs.launchpad.net/"" ""glance>`__"" msgid """" ""`Bugs: OpenStack Networking (neutron) <https://bugs.launchpad.net/neutron>`__"" msgstr """" ""`バグ: OpenStack Networking (neutron) <https://bugs.launchpad.net/neutron>`__"" msgid """" ""`Bugs: OpenStack Object Storage (swift) <https://bugs.launchpad.net/swift>`__"" msgstr """" ""`バグ: OpenStack Object Storage (swift) <https://bugs.launchpad.net/swift>`__"" msgid ""`Bugs: Orchestration (heat) <https://bugs.launchpad.net/heat>`__"" msgstr ""`バグ: Orchestration (heat) <https://bugs.launchpad.net/heat>`__"" msgid ""`Bugs: Rating (cloudkitty) <https://bugs.launchpad.net/cloudkitty>`__"" msgstr ""`バグ: Rating (cloudkitty) <https://bugs.launchpad.net/cloudkitty>`__"" msgid """" ""`Bugs: Shared file systems (manila) <https://bugs.launchpad.net/manila>`__"" msgstr """" ""`バグ: Shared file systems (manila) <https://bugs.launchpad.net/manila>`__"" msgid """" ""`Bugs: Telemetry (ceilometer) <https://bugs.launchpad.net/ceilometer>`__"" msgstr """" ""`バグ: Telemetry (ceilometer) <https://bugs.launchpad.net/ceilometer>`__"" msgid ""`Bugs: Telemetry v3 (gnocchi) <https://bugs.launchpad.net/gnocchi>`__"" msgstr ""`バグ: Telemetry v3 (gnocchi) <https://bugs.launchpad.net/gnocchi>`__"" msgid """" ""`Bugs: Workflow service (mistral) <https://bugs.launchpad.net/mistral>`__"" msgstr """" ""`バグ: Workflow service (mistral) <https://bugs.launchpad.net/mistral>`__"" msgid ""`Ceilometer <http://docs.openstack.org/developer/ceilometer/>`__"" msgstr ""`Ceilometer <http://docs.openstack.org/developer/ceilometer/>`__"" msgid ""`Cinder <http://docs.openstack.org/developer/cinder/>`__"" msgstr ""`Cinder <http://docs.openstack.org/developer/cinder/>`__"" msgid """" ""`Cloud Administrator Guide <http://docs.openstack.org/admin-guide-cloud/>`__"" msgstr """" ""`クラウド管理者ガイド <http://docs.openstack.org/admin-guide-cloud/>`__"" msgid """" ""`Command-Line Interface Reference <http://docs.openstack.org/cli-reference/"" "">`__"" msgstr """" ""`Command-Line Interface Reference <http://docs.openstack.org/cli-reference/"" "">`__"" msgid """" ""`Compute <http://www.openstack.org/software/releases/liberty/components/"" ""nova>`__"" msgstr """" ""`Compute <http://www.openstack.org/software/releases/liberty/components/"" ""nova>`__"" msgid """" ""`Configuration Reference <http://docs.openstack.org/liberty/config-reference/"" ""content/>`__"" msgstr """" ""`設定リファレンス <http://docs.openstack.org/liberty/config-reference/"" ""content/>`__"" msgid """" ""`Dashboard <http://www.openstack.org/software/releases/liberty/components/"" ""horizon>`__"" msgstr """" ""`Dashboard <http://www.openstack.org/software/releases/liberty/components/"" ""horizon>`__"" msgid """" ""`Data processing service <http://www.openstack.org/software/releases/liberty/"" ""components/sahara>`__"" msgstr """" ""`Data processing service <http://www.openstack.org/software/releases/liberty/"" ""components/sahara>`__"" msgid """" ""`Database service <http://www.openstack.org/software/releases/liberty/"" ""components/trove>`__"" msgstr """" ""`Database service <http://www.openstack.org/software/releases/liberty/"" ""components/trove>`__"" msgid """" ""`Documentation contributor guide <http://docs.openstack.org/contributor-"" ""guide/>`__"" msgstr """" ""`Documentation contributor guide <http://docs.openstack.org/contributor-"" ""guide/>`__"" msgid ""`End User Guide <http://docs.openstack.org/user-guide/>`__"" msgstr ""`エンドユーザーガイド <http://docs.openstack.org/ja/user-guide/>`__"" msgid ""`Glance <http://docs.openstack.org/developer/glance/>`__"" msgstr ""`Glance <http://docs.openstack.org/developer/glance/>`__"" msgid ""`Heat <http://docs.openstack.org/developer/heat/>`__"" msgstr ""`Heat <http://docs.openstack.org/developer/heat/>`__"" msgid ""`High Availability Guide <http://docs.openstack.org/ha-guide/>`__"" msgstr ""`高可用性ガイド <http://docs.openstack.org/ha-guide/>`__"" msgid ""`Horizon <http://docs.openstack.org/developer/horizon/>`__"" msgstr ""`Horizon <http://docs.openstack.org/developer/horizon/>`__"" msgid """" ""`Identity service <http://www.openstack.org/software/releases/liberty/"" ""components/keystone>`__"" msgstr """" ""`Identity service <http://www.openstack.org/software/releases/liberty/"" ""components/keystone>`__"" msgid """" ""`Image service <http://www.openstack.org/software/releases/liberty/"" ""components/glance>`__"" msgstr """" ""`Image service <http://www.openstack.org/software/releases/liberty/"" ""components/glance>`__"" msgid """" ""`Installation Guide for Red Hat Enterprise Linux 7 and CentOS 7 <http://docs."" ""openstack.org/liberty/install-guide-rdo/>`__"" msgstr """" ""`インストールガイド Red Hat Enterprise Linux 7, CentOS 7 <http://docs."" ""openstack.org/liberty/install-guide-rdo/>`__"" msgid """" ""`Installation Guide for Ubuntu 14.04 <http://docs.openstack.org/liberty/"" ""install-guide-ubuntu/>`__"" msgstr """" ""`インストールガイド Ubuntu 14.04 版 <http://docs.openstack.org/liberty/"" ""install-guide-ubuntu/>`__"" msgid """" ""`Installation Guide for openSUSE 13.2 and SUSE Linux Enterprise Server 12 "" ""<http://docs.openstack.org/liberty/install-guide-obs/>`__"" msgstr """" ""`インストールガイド openSUSE 13.2、SUSE Linux Enterprise Server 12 版 "" ""<http://docs.openstack.org/liberty/install-guide-obs/>`__"" msgid ""`Keystone <http://docs.openstack.org/developer/keystone/>`__"" msgstr ""`Keystone <http://docs.openstack.org/developer/keystone/>`__"" msgid """" ""`Networking <http://www.openstack.org/software/releases/liberty/components/"" ""neutron>`__"" msgstr """" ""`Networking <http://www.openstack.org/software/releases/liberty/components/"" ""neutron>`__"" msgid """" ""`Networking Guide <http://docs.openstack.org/liberty/networking-guide>`__"" msgstr ""`ネットワークガイド <http://docs.openstack.org/ja/networking-guide>`__"" msgid ""`Neutron <http://docs.openstack.org/developer/neutron/>`__"" msgstr ""`Neutron <http://docs.openstack.org/developer/neutron/>`__"" msgid ""`Nova <http://docs.openstack.org/developer/nova/>`__"" msgstr ""`Nova <http://docs.openstack.org/developer/nova/>`__"" msgid """" ""`Object Storage <http://www.openstack.org/software/releases/liberty/"" ""components/swift>`__"" msgstr """" ""`Object Storage <http://www.openstack.org/software/releases/liberty/"" ""components/swift>`__"" msgid """" ""`OpenStack API Complete Reference (HTML) <http://developer.openstack.org/api-"" ""ref.html>`__"" msgstr """" ""`OpenStack API Complete Reference (HTML) <http://developer.openstack.org/api-"" ""ref.html>`__"" msgid ""`Operations Guide <http://docs.openstack.org/ops/>`__"" msgstr ""`運用ガイド <http://docs.openstack.org/ja/openstack-ops/content/>`__"" msgid """" ""`Orchestration <http://www.openstack.org/software/releases/liberty/"" ""components/heat>`__"" msgstr """" ""`Orchestration <http://www.openstack.org/software/releases/liberty/"" ""components/heat>`__"" msgid ""`Sahara <http://docs.openstack.org/developer/sahara/>`__"" msgstr ""`Sahara <http://docs.openstack.org/developer/sahara/>`__"" msgid ""`Security Guide <http://docs.openstack.org/sec/>`__"" msgstr """" ""`セキュリティーガイド <http://docs.openstack.org/ja/security-guide/>`__"" msgid ""`Swift <http://docs.openstack.org/developer/swift/>`__"" msgstr ""`Swift <http://docs.openstack.org/developer/swift/>`__"" msgid """" ""`Telemetry <http://www.openstack.org/software/releases/liberty/components/"" ""ceilometer>`__"" msgstr """" ""`Telemetry <http://www.openstack.org/software/releases/liberty/components/"" ""ceilometer>`__"" msgid ""`Trove <http://docs.openstack.org/developer/trove/>`__"" msgstr ""`Trove <http://docs.openstack.org/developer/trove/>`__"" msgid """" ""`Virtual Machine Image Guide <http://docs.openstack.org/image-guide/>`__"" msgstr """" ""`仮想マシンイメージガイド <http://docs.openstack.org/ja/image-guide/>`__"" msgid ""``--checksum CHECKSUM``"" msgstr ""``--checksum CHECKSUM``"" msgid ""``--container-format CONTAINER_FORMAT``"" msgstr ""``--container-format CONTAINER_FORMAT``"" msgid ""``--copy-from IMAGE_URL``"" msgstr ""``--copy-from IMAGE_URL``"" msgid ""``--disk-format DISK_FORMAT``"" msgstr ""``--disk-format DISK_FORMAT``"" msgid ""``--file FILE``"" msgstr ""``--file FILE``"" msgid ""``--human-readable``"" msgstr ""``--human-readable``"" msgid ""``--is-protected [True|False]``"" msgstr ""``--is-protected [True|False]``"" msgid ""``--is-public [True|False]``"" msgstr ""``--is-public [True|False]``"" msgid ""``--location IMAGE_URL``"" msgstr ""``--location IMAGE_URL``"" msgid ""``--min-disk DISK_GB``"" msgstr ""``--min-disk DISK_GB``"" msgid ""``--min-ram DISK_RAM``"" msgstr ""``--min-ram DISK_RAM``"" msgid ""``--name NAME``"" msgstr ""``--name NAME``"" msgid ""``--owner TENANT_ID --size SIZE``"" msgstr ""``--owner TENANT_ID --size SIZE``"" msgid ""``--property KEY=VALUE``"" msgstr ""``--property KEY=VALUE``"" msgid ""``--purge-props``"" msgstr ""``--purge-props``"" msgid ""``barbican`` - Key Manager Service API"" msgstr ""``barbican`` - Key Manager Service API"" msgid ""``ceilometer`` - Telemetry API"" msgstr ""``ceilometer`` - Telemetry API"" msgid ""``cinder`` - Block Storage API and extensions"" msgstr ""``cinder`` - Block Storage API および拡張"" msgid ""``cloudkitty`` - Rating service API"" msgstr ""``cloudkitty`` - Rating service API"" msgid ""``designate`` - DNS service API"" msgstr ""``designate`` - DNS service API"" msgid ""``euca2ools`` client"" msgstr ""``euca2ools`` クライアント"" msgid """" ""``filesystem_store_metadata_file = filePath``, where filePath points to a "" ""JSON file that defines the mount point for OpenStack images on your system "" ""and a unique ID. For example:"" msgstr """" ""``filesystem_store_metadata_file = filePath``。filePath は、お使いのシステム"" ""の OpenStack イメージのマウントポイントを定義する JSON ファイルおよび一意の "" ""ID を参照するようにします。例: "" msgid ""``fuel`` - Deployment service API"" msgstr ""``fuel`` - Deployment service API"" msgid ""``glance`` - Image service API"" msgstr ""``glance`` - Image service API"" msgid ""``gnocchi`` - Telemetry API v3"" msgstr ""``gnocchi`` - Telemetry API v3"" msgid ""``heat-api-cfn`` component"" msgstr ""``heat-api-cfn`` コンポーネント"" msgid ""``heat-api`` component"" msgstr ""``heat-api`` コンポーネント"" msgid ""``heat-engine``"" msgstr ""``heat-engine``"" msgid ""``heat`` - Orchestration API"" msgstr ""``heat`` - Orchestration API"" msgid ""``heat`` command-line client"" msgstr ""``heat`` コマンドラインクライアント"" msgid ""``keystone`` - Identity service API and extensions"" msgstr ""``keystone`` - Identity サービス API および拡張"" msgid ""``magnum`` - Containers service API"" msgstr ""``magnum`` - Containers service API"" msgid ""``manila`` - Shared file systems API"" msgstr ""``manila`` - Shared file systems API"" msgid ""``mistral`` - Workflow service API"" msgstr ""``mistral`` - Workflow service API"" msgid ""``monasca`` - Monitoring API"" msgstr ""``monasca`` - Monitoring API"" msgid ""``murano`` - Application catalog API"" msgstr ""``murano`` - Application catalog API"" msgid ""``neutron`` - Networking API"" msgstr ""``neutron`` - Networking API"" msgid ""``nova-api-metadata`` service"" msgstr ""``nova-api-metadata`` サービス"" msgid ""``nova-api`` service"" msgstr ""``nova-api`` サービス"" msgid ""``nova-cert`` daemon"" msgstr ""``nova-cert`` デーモン"" msgid ""``nova-cert`` module"" msgstr ""``nova-cert`` モジュール"" msgid ""``nova-compute`` service"" msgstr ""``nova-compute`` サービス"" msgid ""``nova-conductor`` module"" msgstr ""``nova-conductor`` モジュール"" msgid ""``nova-consoleauth`` daemon"" msgstr ""``nova-consoleauth`` デーモン"" msgid ""``nova-network worker`` daemon"" msgstr ""``nova-network worker`` デーモン"" msgid ""``nova-novncproxy`` daemon"" msgstr ""``nova-novncproxy`` デーモン"" msgid ""``nova-scheduler`` service"" msgstr ""``nova-scheduler`` サービス"" msgid ""``nova-spicehtml5proxy`` daemon"" msgstr ""``nova-spicehtml5proxy`` デーモン"" msgid ""``nova-xvpvncproxy`` daemon"" msgstr ""``nova-xvpvncproxy`` デーモン"" msgid ""``nova`` - Compute API and extensions"" msgstr ""``nova`` - Compute API および拡張"" msgid ""``nova`` client"" msgstr ""``nova`` クライアント"" msgid ""``openstack`` - Common OpenStack client supporting multiple services"" msgstr """" ""``openstack`` - 複数の OpenStack サービスをサポートする共通クライアント"" msgid ""``python-troveclient`` command-line client"" msgstr ""``python-troveclient`` コマンドラインクライアント"" msgid ""``sahara`` - Data Processing API"" msgstr ""``sahara`` - Data Processing API"" msgid ""``senlin`` - Clustering service API"" msgstr ""``senlin`` - Clustering service API"" msgid ""``show_multiple_locations = True``"" msgstr ""``show_multiple_locations = True``"" msgid ""``swift`` - Object Storage API"" msgstr ""``swift`` - Object Storage API"" msgid ""``trove-api`` component"" msgstr ""``trove-api`` コンポーネント"" msgid ""``trove-conductor`` service"" msgstr ""``trove-conductor`` サービス"" msgid ""``trove-guestagent`` service"" msgstr ""``trove-guestagent`` サービス"" msgid ""``trove-taskmanager`` service"" msgstr ""``trove-taskmanager`` サービス"" msgid ""``trove`` - Database service API"" msgstr ""``trove`` - Database service API"" msgid ""absolute limit"" msgstr ""絶対制限"" msgid ""access control list"" msgstr ""アクセス制御リスト"" msgid ""access key"" msgstr ""アクセスキー"" msgid ""account"" msgstr ""アカウント"" msgid ""account auditor"" msgstr ""account auditor"" msgid ""account database"" msgstr ""アカウントデータベース"" msgid ""account reaper"" msgstr ""account reaper"" msgid ""account server"" msgstr ""account server"" msgid ""account service"" msgstr ""account service"" msgid ""accounting"" msgstr ""アカウンティング"" msgid ""active/active configuration"" msgstr ""アクティブ/アクティブ設定"" msgid ""active/passive configuration"" msgstr ""アクティブ/パッシブ設定"" msgid ""address pool"" msgstr ""アドレスプール"" msgid ""admin API"" msgstr ""管理 API"" msgid ""admin server"" msgstr ""管理サーバー"" msgid ""alert"" msgstr ""アラート"" msgid ""allocate"" msgstr ""確保"" msgid ""applet"" msgstr ""アプレット"" msgid ""application server"" msgstr ""アプリケーションサーバー"" msgid ""arptables"" msgstr ""arptables"" msgid ""ask.openstack.org"" msgstr ""ask.openstack.org"" msgid ""associate"" msgstr ""割り当て"" msgid ""attach"" msgstr ""接続"" msgid ""attachment (network)"" msgstr ""アタッチ（ネットワーク）"" msgid ""auditing"" msgstr ""監査"" msgid ""auditor"" msgstr ""auditor"" msgid ""auth node"" msgstr ""認可ノード"" msgid ""authentication"" msgstr ""認証"" msgid ""authentication token"" msgstr ""認証トークン"" msgid ""authorization"" msgstr ""認可"" msgid ""authorization node"" msgstr ""認可ノード"" msgid ""auto declare"" msgstr ""自動宣言"" msgid ""availability zone"" msgstr ""アベイラビリティゾーン"" msgid ""back end"" msgstr ""バックエンド"" msgid ""back-end catalog"" msgstr ""バックエンドカタログ"" msgid ""back-end store"" msgstr ""バックエンドストア"" msgid ""backup restore and disaster recovery as a service"" msgstr ""backup restore and disaster recovery as a service"" msgid ""bandwidth"" msgstr ""帯域"" msgid ""barbican"" msgstr ""barbican"" msgid ""bare"" msgstr ""bare"" msgid ""base image"" msgstr ""ベースイメージ"" msgid ""binary"" msgstr ""バイナリ"" msgid ""bit"" msgstr ""ビット"" msgid ""bits per second (BPS)"" msgstr ""bps"" msgid ""block device"" msgstr ""ブロックデバイス"" msgid ""block migration"" msgstr ""ブロックマイグレーション"" msgid ""bootable disk image"" msgstr ""ブータブルディスクイメージ"" msgid ""browser"" msgstr ""ブラウザー"" msgid ""builder file"" msgstr ""ビルダーファイル"" msgid ""bursting"" msgstr ""超過利用"" msgid ""button class"" msgstr ""ボタンクラス"" msgid ""byte"" msgstr ""バイト"" msgid ""cache pruner"" msgstr ""cache pruner"" msgid ""capability"" msgstr ""キャパシティ"" msgid ""capacity cache"" msgstr ""capacity cache"" msgid ""capacity updater"" msgstr ""capacity updater"" msgid ""catalog"" msgstr ""カタログ"" msgid ""catalog service"" msgstr ""カタログサービス"" msgid ""ceilometer"" msgstr ""ceilometer"" msgid ""cell"" msgstr ""セル"" msgid ""cell forwarding"" msgstr ""セルフォワーディング"" msgid ""cell manager"" msgstr ""セルマネージャー"" msgid ""certificate authority"" msgstr ""認証局"" msgid ""chance scheduler"" msgstr ""チャンススケジューラー"" msgid ""changes since"" msgstr ""changes since"" msgid ""child cell"" msgstr ""子セル"" msgid ""cinder"" msgstr ""cinder"" msgid ""cinder-api"" msgstr ""cinder-api"" msgid ""cinder-backup daemon"" msgstr ""cinder-backup デーモン"" msgid ""cinder-scheduler daemon"" msgstr ""cinder-scheduler デーモン"" msgid ""cinder-volume"" msgstr ""cinder-volume"" msgid ""cloud architect"" msgstr ""クラウドアーキテクト"" msgid ""cloud computing"" msgstr ""クラウドコンピューティング"" msgid ""cloud controller"" msgstr ""クラウドコントローラー"" msgid ""cloud controller node"" msgstr ""クラウドコントローラーノード"" msgid ""cloud-init"" msgstr ""cloud-init"" msgid ""cloudadmin"" msgstr ""cloudadmin"" msgid ""cloudkitty"" msgstr ""cloudkitty"" msgid ""cloudpipe"" msgstr ""cloudpipe"" msgid ""cloudpipe image"" msgstr ""cloudpipe イメージ"" msgid ""command filter"" msgstr ""コマンドフィルター"" msgid ""community project"" msgstr ""コミュニティープロジェクト"" msgid ""compression"" msgstr ""圧縮"" msgid ""compute controller"" msgstr ""コンピュートコントローラー"" msgid ""compute host"" msgstr ""コンピュートホスト"" msgid ""compute node"" msgstr ""コンピュートノード"" msgid ""compute worker"" msgstr ""コンピュートワーカー"" msgid ""concatenated object"" msgstr ""連結オブジェクト"" msgid ""conductor"" msgstr ""コンダクター"" msgid ""congress"" msgstr ""congress"" msgid ""consistency window"" msgstr ""一貫性ウインドウ"" msgid ""console log"" msgstr ""コンソールログ"" msgid ""container"" msgstr ""コンテナー"" msgid ""container auditor"" msgstr ""コンテナーオーディター"" msgid ""container database"" msgstr ""コンテナーデータベース"" msgid ""container format"" msgstr ""コンテナーフォーマット"" msgid ""container server"" msgstr ""コンテナーサーバー"" msgid ""container service"" msgstr ""コンテナーサービス"" msgid ""content delivery network (CDN)"" msgstr ""コンテンツ配信ネットワーク (CDN)"" msgid ""controller node"" msgstr ""コントローラーノード"" msgid ""core API"" msgstr ""コアAPI"" msgid ""core project"" msgstr ""コアプロジェクト"" msgid ""cost"" msgstr ""コスト"" msgid ""credentials"" msgstr ""クレデンシャル"" msgid ""current workload"" msgstr ""カレントワークロード"" msgid ""customer"" msgstr ""カスタマー"" msgid ""customization module"" msgstr ""カスタムモジュール"" msgid ""daemon"" msgstr ""デーモン"" msgid ""dashboard"" msgstr ""ダッシュボード"" msgid ""data encryption"" msgstr ""データ暗号化"" msgid ""data store"" msgstr ""データストア"" msgid ""database ID"" msgstr ""データベース ID"" msgid ""database replicator"" msgstr ""データベースレプリケーター"" msgid ""deallocate"" msgstr ""割り当て解除"" msgid ""deduplication"" msgstr ""重複排除"" msgid ""default panel"" msgstr ""デフォルトパネル"" msgid ""default tenant"" msgstr ""デフォルトテナント"" msgid ""default token"" msgstr ""デフォルトトークン"" msgid ""delayed delete"" msgstr ""遅延削除"" msgid ""delivery mode"" msgstr ""デリバリーモード"" msgid ""denial of service (DoS)"" msgstr ""サービス妨害 (DoS)"" msgid ""deprecated auth"" msgstr ""非推奨認証"" msgid ""developer"" msgstr ""developer"" msgid ""device ID"" msgstr ""デバイス ID"" msgid ""device weight"" msgstr ""デバイスウェイト"" msgid ""direct consumer"" msgstr ""直接使用者"" msgid ""direct exchange"" msgstr ""直接交換"" msgid ""direct publisher"" msgstr ""直接発行者"" msgid ""disassociate"" msgstr ""関連付け解除"" msgid ""disk encryption"" msgstr ""ディスク暗号化"" msgid ""disk format"" msgstr ""ディスクフォーマット"" msgid ""dispersion"" msgstr ""dispersion"" msgid ""distributed virtual router (DVR)"" msgstr ""分散仮想ルーター (DVR)"" msgid ""dnsmasq"" msgstr ""dnsmasq"" msgid ""domain"" msgstr ""ドメイン"" msgid ""download"" msgstr ""ダウンロード"" msgid ""durable exchange"" msgstr ""永続交換"" msgid ""durable queue"" msgstr ""永続キュー"" msgid ""e1000"" msgstr ""e1000"" msgid ""east-west traffic"" msgstr ""イースト・ウエスト通信"" msgid ""ebtables"" msgstr ""ebtables"" msgid ""encapsulation"" msgstr ""カプセル化"" msgid ""encryption"" msgstr ""暗号化"" msgid ""endpoint"" msgstr ""エンドポイント"" msgid ""endpoint registry"" msgstr ""エンドポイントレジストリ"" msgid ""endpoint template"" msgstr ""エンドポイントテンプレート"" msgid ""entity"" msgstr ""エンティティー"" msgid ""ephemeral image"" msgstr ""一時イメージ"" msgid ""ephemeral volume"" msgstr ""一時ボリューム"" msgid ""euca2ools"" msgstr ""euca2ools"" msgid ""evacuate"" msgstr ""退避"" msgid ""exchange"" msgstr ""交換"" msgid ""exchange type"" msgstr ""交換種別"" msgid ""exclusive queue"" msgstr ""排他キュー"" msgid ""extended attributes (xattr)"" msgstr ""拡張属性 (xattr)"" msgid ""extension"" msgstr ""エクステンション"" msgid ""external network"" msgstr ""外部ネットワーク"" msgid ""extra specs"" msgstr ""拡張仕様"" msgid ""fan-out exchange"" msgstr ""ファンアウト交換"" msgid ""federated identity"" msgstr ""連合認証"" msgid ""fill-first scheduler"" msgstr ""充填優先スケジューラー"" msgid ""filter"" msgstr ""フィルター"" msgid ""firewall"" msgstr ""ファイアウォール"" msgid ""fixed IP address"" msgstr ""fixed IP アドレス"" msgid ""flat mode injection"" msgstr ""フラットモードインジェクション"" msgid ""flat network"" msgstr ""フラットネットワーク"" msgid ""flavor"" msgstr ""フレーバー"" msgid ""flavor ID"" msgstr ""フレーバー ID"" msgid ""floating IP address"" msgstr ""Floating IP アドレス"" msgid ""freezer"" msgstr ""freezer"" msgid ""front end"" msgstr ""フロントエンド"" msgid ""fuel"" msgstr ""fuel"" msgid ""gateway"" msgstr ""ゲートウェイ"" msgid ""generic receive offload (GRO)"" msgstr ""generic receive offload (GRO)"" msgid ""generic routing encapsulation (GRE)"" msgstr ""generic routing encapsulation (GRE)"" msgid ""glance"" msgstr ""glance"" msgid ""glance API server"" msgstr ""glance API サーバー"" msgid ""glance registry"" msgstr ""Glance レジストリ"" msgid ""glance-api"" msgstr ""glance-api"" msgid ""glance-registry"" msgstr ""glance-registry"" msgid ""global endpoint template"" msgstr ""グローバルエンドポイントテンプレート"" msgid ""gnocchi"" msgstr ""gnocchi"" msgid ""golden image"" msgstr ""ゴールデンイメージ"" msgid ""guest OS"" msgstr ""ゲスト OS"" msgid ""handover"" msgstr ""handover"" msgid ""hard reboot"" msgstr ""ハードリブート"" msgid ""health monitor"" msgstr ""ヘルスモニター"" msgid ""heat"" msgstr ""heat"" msgid ""high availability (HA)"" msgstr ""高可用性"" msgid ""horizon"" msgstr ""Horizon"" msgid ""horizon plug-in"" msgstr ""horizon プラグイン"" msgid ""host"" msgstr ""ホスト"" msgid ""host aggregate"" msgstr ""ホストアグリゲート"" msgid ""hybrid cloud"" msgstr ""ハイブリッドクラウド"" msgid ""hyperlink"" msgstr ""ハイパーリンク"" msgid ""hypervisor"" msgstr ""ハイパーバイザー"" msgid ""hypervisor pool"" msgstr ""ハイパーバイザープール"" msgid ""iSCSI"" msgstr ""iSCSI"" msgid """" ""iSCSI Qualified Name (IQN) is the format most commonly used for iSCSI names, "" ""which uniquely identify nodes in an iSCSI network. All IQNs follow the "" ""pattern iqn.yyyy-mm.domain:identifier, where 'yyyy-mm' is the year and month "" ""in which the domain was registered, 'domain' is the reversed domain name of "" ""the issuing organization, and 'identifier' is an optional string which makes "" ""each IQN under the same domain unique. For example, 'iqn.2015-10.org."" ""openstack.408ae959bce1'."" msgstr """" ""iSCSI Qualified Name (IQN) は iSCSI の名前として最も広く使われている形式で、 "" ""iSCSI ネットワークで一意にノードを識別するのに使われます。すべての IQN は "" ""iqn.yyyy-mm.domain:identifier という形式です。ここで、 'yyyy-mm' はそのドメイ"" ""ンが登録された年と月、 'domain' は発行組織の登録されたドメイン名、 "" ""'identifier' は同じドメイン内の各 IQN 番号を一意なものにするためのオプション"" ""文字列です。例えば 'iqn.2015-10.org.openstack.408ae959bce1'"" msgid ""ide"" msgstr ""ide"" msgid ""identity provider"" msgstr ""識別情報プロバイダー"" msgid ""image"" msgstr ""イメージ"" msgid ""image ID"" msgstr ""イメージ ID"" msgid ""image UUID"" msgstr ""イメージ UUID"" msgid ""image cache"" msgstr ""イメージキャッシュ"" msgid ""image membership"" msgstr ""イメージメンバーシップ"" msgid ""image owner"" msgstr ""イメージ所有者"" msgid ""image registry"" msgstr ""イメージレジストリー"" msgid ""image status"" msgstr ""イメージ状態"" msgid ""image store"" msgstr ""イメージストア"" msgid ""incubated project"" msgstr ""インキュベートプロジェクト"" msgid ""ingress filtering"" msgstr ""イングレスフィルタリング"" msgid ""injection"" msgstr ""インジェクション"" msgid ""instance"" msgstr ""インスタンス"" msgid ""instance ID"" msgstr ""インスタンス ID"" msgid ""instance UUID"" msgstr ""インスタンス UUID"" msgid ""instance state"" msgstr ""インスタンス状態"" msgid ""instance tunnels network"" msgstr ""インスタンストンネルネットワーク"" msgid ""instance type"" msgstr ""インスタンスタイプ"" msgid ""instance type ID"" msgstr ""インスタンスタイプ ID"" msgid ""interface"" msgstr ""インターフェース"" msgid ""interface ID"" msgstr ""インターフェース ID"" msgid ""ip6tables"" msgstr ""ip6tables"" msgid ""ipset"" msgstr ""ipset"" msgid ""iptables"" msgstr ""iptables"" msgid ""ironic"" msgstr ""ironic"" msgid ""itsec"" msgstr ""itsec"" msgid ""jumbo frame"" msgstr ""ジャンボフレーム"" msgid ""kernel-based VM (KVM)"" msgstr ""kernel-based VM (KVM)"" msgid ""keystone"" msgstr ""keystone"" msgid ""large object"" msgstr ""ラージオブジェクト"" msgid ""libvirt"" msgstr ""libvirt"" msgid ""libvirt for KVM or QEMU"" msgstr ""KVM/QEMU 向けの libvirt"" msgid ""libvirt\\_type setting"" msgstr ""libvirt\\_type setting"" msgid ""live migration"" msgstr ""ライブマイグレーション"" msgid ""load balancer"" msgstr ""負荷分散装置"" msgid ""load balancing"" msgstr ""負荷分散"" msgid ""magnum"" msgstr ""magnum"" msgid ""management API"" msgstr ""マネジメント API"" msgid ""management network"" msgstr ""管理ネットワーク"" msgid ""manager"" msgstr ""マネージャー"" msgid ""manifest"" msgstr ""マニフェスト"" msgid ""manifest object"" msgstr ""マニフェストオブジェクト"" msgid ""manila"" msgstr ""manila"" msgid ""manila-api"" msgstr ""manila-api"" msgid ""manila-scheduler daemon"" msgstr ""manila-scheduler デーモン"" msgid ""manila-share"" msgstr ""manila-share"" msgid ""maximum transmission unit (MTU)"" msgstr ""最大転送単位 (MTU)"" msgid ""mechanism driver"" msgstr ""メカニズムドライバー"" msgid ""melange"" msgstr ""melange"" msgid ""membership"" msgstr ""メンバーシップ"" msgid ""membership list"" msgstr ""メンバーシップリスト"" msgid ""memcached"" msgstr ""memcached"" msgid ""memory overcommit"" msgstr ""メモリーオーバーコミット"" msgid ""message broker"" msgstr ""メッセージブローカー"" msgid ""message bus"" msgstr ""メッセージバス"" msgid ""message queue"" msgstr ""メッセージキュー"" msgid ""migration"" msgstr ""マイグレーション"" msgid ""mistral"" msgstr ""mistral"" msgid ""monasca"" msgstr ""monasca"" msgid ""multi-factor authentication"" msgstr ""多要素認証"" msgid ""multi-host"" msgstr ""マルチホスト"" msgid ""multinic"" msgstr ""マルチ NIC"" msgid ""murano"" msgstr ""murano"" msgid ""ne2k\\_pci"" msgstr ""ne2k\\_pci"" msgid ""netadmin"" msgstr ""netadmin"" msgid ""netfront"" msgstr ""netfront"" msgid ""network"" msgstr ""Network"" msgid ""network ID"" msgstr ""ネットワーク ID"" msgid ""network UUID"" msgstr ""ネットワーク UUID"" msgid ""network controller"" msgstr ""ネットワークコントローラー"" msgid ""network manager"" msgstr ""ネットワークマネージャー"" msgid ""network namespace"" msgstr ""ネットワーク名前空間"" msgid ""network node"" msgstr ""ネットワークノード"" msgid ""network segment"" msgstr ""ネットワークセグメント"" msgid ""network worker"" msgstr ""ネットワークワーカー"" msgid ""neutron"" msgstr ""neutron"" msgid ""neutron API"" msgstr ""neutron API"" msgid ""neutron manager"" msgstr ""neutron マネージャー"" msgid ""neutron plug-in"" msgstr ""neutron プラグイン"" msgid ""neutron-server"" msgstr ""neutron-server"" msgid ""node"" msgstr ""node"" msgid ""non-durable exchange"" msgstr ""非永続交換"" msgid ""non-durable queue"" msgstr ""非永続キュー"" msgid ""non-persistent volume"" msgstr ""非永続ボリューム"" msgid ""north-south traffic"" msgstr ""ノース・サウス通信"" msgid ""nova"" msgstr ""nova"" msgid ""nova-network"" msgstr ""nova-network"" msgid ""object"" msgstr ""オブジェクト"" msgid ""object auditor"" msgstr ""オブジェクトオーディター"" msgid ""object expiration"" msgstr ""オブジェクト有効期限"" msgid ""object hash"" msgstr ""オブジェクトハッシュ"" msgid ""object path hash"" msgstr ""オブジェクトパスハッシュ"" msgid ""object replicator"" msgstr ""オブジェクトレプリケーター"" msgid ""object server"" msgstr ""オブジェクトサーバー"" msgid ""object versioning"" msgstr ""オブジェクトバージョニング"" msgid ""openSUSE"" msgstr ""openSUSE"" msgid ""openstack"" msgstr ""openstack"" msgid ""operator"" msgstr ""運用者"" msgid ""orphan"" msgstr ""orphan"" msgid ""parent cell"" msgstr ""親セル"" msgid ""partition"" msgstr ""パーティション"" msgid ""partition index"" msgstr ""パーティションインデックス"" msgid ""partition shift value"" msgstr ""パーティションシフト値"" msgid ""path MTU discovery (PMTUD)"" msgstr ""path MTU discovery (PMTUD)"" msgid ""pause"" msgstr ""一時停止"" msgid ""pcnet"" msgstr ""pcnet"" msgid ""persistent message"" msgstr ""永続メッセージ"" msgid ""persistent volume"" msgstr ""永続ボリューム"" msgid ""personality file"" msgstr ""パーソナリティーファイル"" msgid ""pip package"" msgstr ""pip パッケージ"" msgid ""plug-in"" msgstr ""プラグイン"" msgid ""policy service"" msgstr ""ポリシーサービス"" msgid ""pool"" msgstr ""プール"" msgid ""pool member"" msgstr ""プールメンバー"" msgid ""port"" msgstr ""ポート"" msgid ""port UUID"" msgstr ""ポート UUID"" msgid ""preseed"" msgstr ""preseed"" msgid ""private IP address"" msgstr ""プライベート IP アドレス"" msgid ""private image"" msgstr ""プライベートイメージ"" msgid ""private network"" msgstr ""プライベートネットワーク"" msgid ""project"" msgstr ""プロジェクト"" msgid ""project ID"" msgstr ""プロジェクト ID"" msgid ""project VPN"" msgstr ""プロジェクト VPN"" msgid ""promiscuous mode"" msgstr ""プロミスキャスモード"" msgid ""protected property"" msgstr ""保護プロパティー"" msgid ""provider"" msgstr ""プロバイダー"" msgid ""proxy node"" msgstr ""プロキシノード"" msgid ""proxy server"" msgstr ""プロキシサーバー"" msgid ""public API"" msgstr ""パブリック API"" msgid ""public IP address"" msgstr ""パブリック IP アドレス"" msgid ""public image"" msgstr ""パブリックイメージ"" msgid ""public key authentication"" msgstr ""公開鍵認証"" msgid ""public network"" msgstr ""パブリックネットワーク"" msgid ""python-barbicanclient"" msgstr ""python-barbicanclient"" msgid ""python-ceilometerclient"" msgstr ""python-ceilometerclient"" msgid ""python-cinderclient"" msgstr ""python-cinderclient"" msgid ""python-cloudkittyclient"" msgstr ""python-cloudkittyclient"" msgid ""python-fuelclient"" msgstr ""python-fuelclient"" msgid ""python-glanceclient"" msgstr ""python-glanceclient"" msgid ""python-gnocchiclient"" msgstr ""python-gnocchiclient"" msgid ""python-heatclient"" msgstr ""python-heatclient"" msgid ""python-keystoneclient"" msgstr ""python-keystoneclient"" msgid ""python-magnumclient"" msgstr ""python-magnumclient"" msgid ""python-manilaclient"" msgstr ""python-manilaclient"" msgid ""python-mistralclient"" msgstr ""python-mistralclient"" msgid ""python-monascaclient"" msgstr ""python-monascaclient"" msgid ""python-muranoclient"" msgstr ""python-muranoclient"" msgid ""python-neutronclient"" msgstr ""python-neutronclient"" msgid ""python-novaclient"" msgstr ""python-novaclient"" msgid ""python-openstackclient"" msgstr ""python-openstackclient"" msgid ""python-saharaclient"" msgstr ""python-saharaclient"" msgid ""python-senlinclient"" msgstr ""python-senlinclient"" msgid ""python-swiftclient"" msgstr ""python-swiftclient"" msgid ""python-troveclient"" msgstr ""python-troveclient"" msgid ""qemu or kvm"" msgstr ""qemu または kvm"" msgid ""quarantine"" msgstr ""隔離"" msgid ""quota"" msgstr ""クォータ"" msgid ""radvd"" msgstr ""radvd"" msgid ""rally"" msgstr ""rally"" msgid ""rate limit"" msgstr ""レートリミット"" msgid ""raw"" msgstr ""raw"" msgid ""rebalance"" msgstr ""リバランス"" msgid ""reboot"" msgstr ""リブート"" msgid ""rebuild"" msgstr ""リビルド"" msgid ""record"" msgstr ""レコード"" msgid ""record ID"" msgstr ""レコード ID"" msgid ""reference architecture"" msgstr ""リファレンスアーキテクチャー"" msgid ""region"" msgstr ""リージョン"" msgid ""registry"" msgstr ""レジストリー"" msgid ""registry server"" msgstr ""レジストリサーバー"" msgid ""replica"" msgstr ""レプリカ"" msgid ""replica count"" msgstr ""レプリカ数"" msgid ""replication"" msgstr ""レプリケーション"" msgid ""replicator"" msgstr ""レプリケーター"" msgid ""request ID"" msgstr ""リクエスト ID"" msgid ""rescue image"" msgstr ""レスキューイメージ"" msgid ""resize"" msgstr ""リサイズ"" msgid ""ring"" msgstr ""リング"" msgid ""ring builder"" msgstr ""リングビルダー"" msgid ""role"" msgstr ""ロール"" msgid ""role ID"" msgstr ""ロール ID"" msgid ""rootwrap"" msgstr ""rootwrap"" msgid ""round-robin scheduler"" msgstr ""ラウンドロビンスケジューラー"" msgid ""router"" msgstr ""ルーター"" msgid ""routing key"" msgstr ""ルーティングキー"" msgid ""rsync"" msgstr ""rsync"" msgid ""rtl8139"" msgstr ""rtl8139"" msgid ""sahara"" msgstr ""sahara"" msgid ""scheduler manager"" msgstr ""スケジューラーマネージャー"" msgid ""scoped token"" msgstr ""スコープ付きトークン"" msgid ""scrubber"" msgstr ""スクラバー"" msgid ""scsi"" msgstr ""scsi"" msgid ""secret key"" msgstr ""シークレットキー"" msgid ""secure shell (SSH)"" msgstr ""secure shell (SSH)"" msgid ""security group"" msgstr ""セキュリティーグループ"" msgid ""segmented object"" msgstr ""分割オブジェクト"" msgid ""self-service"" msgstr ""セルフサービス"" msgid ""senlin"" msgstr ""senlin"" msgid ""server"" msgstr ""サーバー"" msgid ""server UUID"" msgstr ""サーバー UUID"" msgid ""server image"" msgstr ""サーバーイメージ"" msgid ""service"" msgstr ""サービス"" msgid ""service ID"" msgstr ""サービス ID"" msgid ""service catalog"" msgstr ""サービスカタログ"" msgid ""service provider"" msgstr ""サービスプロバイダー"" msgid ""service registration"" msgstr ""サービス登録"" msgid ""service tenant"" msgstr ""サービステナント"" msgid ""service token"" msgstr ""サービストークン"" msgid ""session back end"" msgstr ""セッションバックエンド"" msgid ""session persistence"" msgstr ""セッション持続性"" msgid ""session storage"" msgstr ""セッションストレージ"" msgid ""setuptools package"" msgstr ""setuptools パッケージ"" msgid ""share"" msgstr ""共有"" msgid ""share network"" msgstr ""ネットワーク共有 (share network)"" msgid ""shared IP address"" msgstr ""共有 IP アドレス"" msgid ""shared IP group"" msgstr ""共有 IP グループ"" msgid ""shared storage"" msgstr ""共有ストレージ"" msgid ""snapshot"" msgstr ""スナップショット"" msgid ""soft reboot"" msgstr ""ソフトリブート"" msgid ""solum"" msgstr ""solum"" msgid ""spread-first scheduler"" msgstr ""分散優先スケジューラー"" msgid ""stack"" msgstr ""スタック"" msgid ""static IP address"" msgstr ""静的 IP アドレス"" msgid ""storage back end"" msgstr ""ストレージバックエンド"" msgid ""storage manager"" msgstr ""ストレージマネージャー"" msgid ""storage manager back end"" msgstr ""ストレージマネージャーバックエンド"" msgid ""storage node"" msgstr ""ストレージノード"" msgid ""storage services"" msgstr ""ストレージサービス"" msgid ""strategy"" msgstr ""ストラテジー"" msgid ""subdomain"" msgstr ""サブドメイン"" msgid ""subnet"" msgstr ""サブネット"" msgid ""suspend"" msgstr ""休止"" msgid ""swap"" msgstr ""スワップ"" msgid ""swauth"" msgstr ""swauth"" msgid ""swift"" msgstr ""swift"" msgid ""swift All in One (SAIO)"" msgstr ""swift All in One (SAIO)"" msgid ""swift client"" msgstr ""swift クライアント"" msgid ""swift middleware"" msgstr ""swift ミドルウェア"" msgid ""swift proxy server"" msgstr ""swift プロキシサーバー"" msgid ""swift storage node"" msgstr ""swift ストレージノード"" msgid ""swift-init"" msgstr ""swift-init"" msgid ""swift-recon"" msgstr ""swift-recon"" msgid ""swift-ring-builder"" msgstr ""swift-ring-builder"" msgid ""sync point"" msgstr ""同期ポイント"" msgid ""sysadmin"" msgstr ""sysadmin"" msgid ""system usage"" msgstr ""システム使用状況"" msgid ""tenant"" msgstr ""テナント"" msgid ""tenant ID"" msgstr ""テナント ID"" msgid ""tenant endpoint"" msgstr ""テナントエンドポイント"" msgid ""token"" msgstr ""トークン"" msgid ""token services"" msgstr ""トークンサービス"" msgid ""tombstone"" msgstr ""tombstone"" msgid ""topic publisher"" msgstr ""トピック発行者"" msgid ""transaction ID"" msgstr ""トランザクション ID"" msgid ""transient"" msgstr ""一時"" msgid ""transient exchange"" msgstr ""一時交換"" msgid ""transient message"" msgstr ""一時メッセージ"" msgid ""transient queue"" msgstr ""一時キュー"" msgid ""trove"" msgstr ""trove"" msgid ""unscoped token"" msgstr ""スコープなしトークン"" msgid ""updater"" msgstr ""アップデーター"" msgid ""user"" msgstr ""ユーザー"" msgid ""user data"" msgstr ""ユーザーデータ"" msgid ""vSphere"" msgstr ""vSphere"" msgid ""virtio"" msgstr ""virtio"" msgid ""virtual IP"" msgstr ""仮想 IP"" msgid ""virtual VLAN"" msgstr ""仮想 VLAN"" msgid ""virtual machine (VM)"" msgstr ""仮想マシン (VM)"" msgid ""virtual network"" msgstr ""仮想ネットワーク"" msgid ""virtual networking"" msgstr ""仮想ネットワーク"" msgid ""virtual port"" msgstr ""仮想ポート"" msgid ""virtual private network (VPN)"" msgstr ""仮想プライベートネットワーク (VPN)"" msgid ""virtual server"" msgstr ""仮想サーバー"" msgid ""virtual switch (vSwitch)"" msgstr ""仮想スイッチ (vSwitch)"" msgid ""vmware"" msgstr ""vmware"" msgid ""volume"" msgstr ""ボリューム"" msgid ""volume ID"" msgstr ""ボリューム ID"" msgid ""volume controller"" msgstr ""ボリュームコントローラー"" msgid ""volume driver"" msgstr ""ボリュームドライバー"" msgid ""volume manager"" msgstr ""ボリュームマネージャー"" msgid ""volume node"" msgstr ""ボリュームノード"" msgid ""volume plug-in"" msgstr ""ボリュームプラグイン"" msgid ""volume worker"" msgstr ""ボリュームワーカー"" msgid ""weight"" msgstr ""ウェイト"" msgid ""weighted cost"" msgstr ""重み付けコスト"" msgid ""weighting"" msgstr ""重み付け"" msgid ""worker"" msgstr ""ワーカー"" msgid ""x509 certificates."" msgstr ""x509 証明書。"" msgid ""xen"" msgstr ""xen"" msgid ""zaqar"" msgstr ""zaqar"" ",0,11177
openstack%2Fpython-senlinclient~master~Ia4a7c516778a9c9188eda610bebb061684cf5b01,openstack/python-senlinclient,master,Ia4a7c516778a9c9188eda610bebb061684cf5b01,Apply list_formatter on two properties,MERGED,2016-02-10 17:42:12.000000000,2016-02-15 02:47:13.000000000,2016-02-15 02:47:13.000000000,"[{'_account_id': 3}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-10 17:42:12.000000000', 'files': ['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/b9bc0f48f7354b85c47b5f9df4df18eb3794e38c', 'message': ""Apply list_formatter on two properties\n\nApply the 'list_formatter' from 'utils' on two properties of\noperation 'show-action' that are, 'depended_by' and 'depends_on'.\n\nChange-Id: Ia4a7c516778a9c9188eda610bebb061684cf5b01\nCloses-Bug: #1544098\n""}]",0,278540,b9bc0f48f7354b85c47b5f9df4df18eb3794e38c,7,3,1,19840,,,0,"Apply list_formatter on two properties

Apply the 'list_formatter' from 'utils' on two properties of
operation 'show-action' that are, 'depended_by' and 'depends_on'.

Change-Id: Ia4a7c516778a9c9188eda610bebb061684cf5b01
Closes-Bug: #1544098
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/40/278540/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/v1/shell.py']",2,b9bc0f48f7354b85c47b5f9df4df18eb3794e38c,bug/1544098," 'depends_on': utils.list_formatter, 'depended_by': utils.list_formatter,",,4,0
openstack%2Foslo.service~master~I2ab070ab8eca81818ccf6dfea4607b4bfbd8bd07,openstack/oslo.service,master,I2ab070ab8eca81818ccf6dfea4607b4bfbd8bd07,Fix misspelling and rewrite sentence,MERGED,2016-02-04 01:19:59.000000000,2016-02-15 02:24:18.000000000,2016-02-15 02:24:18.000000000,"[{'_account_id': 3}, {'_account_id': 7293}, {'_account_id': 8119}, {'_account_id': 9796}, {'_account_id': 16871}]","[{'number': 1, 'created': '2016-02-04 01:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/95956c0c36e3baa0677cc04cc3c0ef915dbe32d6', 'message': 'Fix spell typo\n\nChange-Id: I2ab070ab8eca81818ccf6dfea4607b4bfbd8bd07\n'}, {'number': 2, 'created': '2016-02-04 01:25:18.000000000', 'files': ['oslo_service/service.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/fdb486172209df7c86e8748a139f8fbb1be214b7', 'message': 'Fix misspelling and rewrite sentence\n\nChange-Id: I2ab070ab8eca81818ccf6dfea4607b4bfbd8bd07\n'}]",2,276009,fdb486172209df7c86e8748a139f8fbb1be214b7,15,5,2,16237,,,0,"Fix misspelling and rewrite sentence

Change-Id: I2ab070ab8eca81818ccf6dfea4607b4bfbd8bd07
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/09/276009/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_service/service.py'],1,95956c0c36e3baa0677cc04cc3c0ef915dbe32d6,spell-fix, # if we are here it means that we try to do graceful shutdown., # if we are here it means that we try to do gracefull shutdown.,1,1
openstack%2Foslo.service~master~Ifc77b908699b911f60f039ac54f98391a7e53732,openstack/oslo.service,master,Ifc77b908699b911f60f039ac54f98391a7e53732,Add a more useful/detailed frame dumping function,MERGED,2016-02-03 20:58:52.000000000,2016-02-15 02:21:34.000000000,2016-02-15 02:21:34.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-03 20:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/267cbf4be7aef8d3dba7ce16624fb5df567adf21', 'message': 'Add a more useful/detailed frame dumping function\n\nWhen things start behaving badly having access to a more\ncapable frame dumping function can be pretty handy to gain\nmore insight into what the greenthreads are doing (and what\nthe functions and those functions local variables are that\nthey are currently running with).\n\nThis adds such a capability to the pgt() alias function that\nthe backdoor exposes, the default usage shows the simpler and\nless useful print_stack() output but the newer and less simple\noutput can be enabled by calling pgt(False).\n\nDoing so will produce output like:\n\nhttps://gist.github.com/harlowja/5417f9196c6024168418\n\nChange-Id: Ifc77b908699b911f60f039ac54f98391a7e53732\n'}, {'number': 2, 'created': '2016-02-03 21:17:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/c51bf788d83cf7a4fc8421076a960ba6a386c002', 'message': 'Add a more useful/detailed frame dumping function\n\nWhen things start behaving badly having access to a more\ncapable frame dumping function can be pretty handy to gain\nmore insight into what the greenthreads are doing (and what\nthe functions and those functions local variables are that\nthey are currently running with).\n\nThis adds such a capability to the pgt() alias function that\nthe backdoor exposes, the default usage shows the simpler and\nless useful print_stack() output but the newer and less simple\noutput can be enabled by calling pgt(False).\n\nDoing so will produce output like:\n\nhttps://gist.github.com/harlowja/5417f9196c6024168418\n\nChange-Id: Ifc77b908699b911f60f039ac54f98391a7e53732\n'}, {'number': 3, 'created': '2016-02-03 21:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/5aacfb0d31db4d3ed2a917c9c0bcca413a26ec6e', 'message': 'Add a more useful/detailed frame dumping function\n\nWhen things start behaving badly having access to a more\ncapable frame dumping function can be pretty handy to gain\nmore insight into what the greenthreads are doing (and what\nthe functions and those functions local variables are that\nthey are currently running with).\n\nThis adds such a capability to the pgt() alias function that\nthe backdoor exposes, the default usage shows the simpler and\nless useful print_stack() output but the newer and less simple\noutput can be enabled by calling pgt(False).\n\nDoing so will produce output like:\n\nhttps://gist.github.com/harlowja/b91b512dcf1b6db592bb\n\nChange-Id: Ifc77b908699b911f60f039ac54f98391a7e53732\n'}, {'number': 4, 'created': '2016-02-03 21:28:19.000000000', 'files': ['oslo_service/eventlet_backdoor.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/81cc23f306d17aadd7f9cd35695f03c779237870', 'message': 'Add a more useful/detailed frame dumping function\n\nWhen things start behaving badly having access to a more\ncapable frame dumping function can be pretty handy to gain\nmore insight into what the greenthreads are doing (and what\nthe functions and those functions local variables are that\nthey are currently running with).\n\nThis adds such a capability to the pgt() alias function that\nthe backdoor exposes, the default usage shows the simpler and\nless useful print_stack() output but the newer and less simple\noutput can be enabled by calling pgt(False).\n\nDoing so will produce output like:\n\nhttps://gist.github.com/harlowja/b91b512dcf1b6db592bb\n\nChange-Id: Ifc77b908699b911f60f039ac54f98391a7e53732\n'}]",0,275921,81cc23f306d17aadd7f9cd35695f03c779237870,16,3,4,1297,,,0,"Add a more useful/detailed frame dumping function

When things start behaving badly having access to a more
capable frame dumping function can be pretty handy to gain
more insight into what the greenthreads are doing (and what
the functions and those functions local variables are that
they are currently running with).

This adds such a capability to the pgt() alias function that
the backdoor exposes, the default usage shows the simpler and
less useful print_stack() output but the newer and less simple
output can be enabled by calling pgt(False).

Doing so will produce output like:

https://gist.github.com/harlowja/b91b512dcf1b6db592bb

Change-Id: Ifc77b908699b911f60f039ac54f98391a7e53732
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/21/275921/3 && git format-patch -1 --stdout FETCH_HEAD,['oslo_service/eventlet_backdoor.py'],1,267cbf4be7aef8d3dba7ce16624fb5df567adf21,better-dump,"def _dump_frame(f, frame_chapter): print("" %s Frame: '%s'"" % (frame_chapter, f.f_code.co_name)) print("" File: '%s'"" % (f.f_code.co_filename)) print("" Captured at line number: %s"" % (f.f_lineno)) print("" Local variables:"") for var_name in sorted(f.f_locals.keys()): print("" %s => %s"" % (var_name, f.f_locals[var_name])) def _detailed_dump_frames(f, thread_index): i = 0 while f is not None: _dump_frame(f, ""%s.%s"" % (thread_index, i + 1)) f = f.f_back i += 1 def _print_greenthreads(simple=True): if simple: traceback.print_stack(gt.gr_frame) else: _detailed_dump_frames(gt.gr_frame, i)",def _print_greenthreads(): traceback.print_stack(gt.gr_frame),22,2
openstack%2Fsenlin~master~Ibbe01d65e87c537512c03755abb8c418b1a208b7,openstack/senlin,master,Ibbe01d65e87c537512c03755abb8c418b1a208b7,Remove some EVENT call from cluster module,MERGED,2016-02-14 09:22:07.000000000,2016-02-15 02:01:22.000000000,2016-02-15 02:01:22.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-14 09:22:07.000000000', 'files': ['senlin/tests/unit/engine/test_cluster.py', 'senlin/engine/cluster.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/80363cba60a24141fe933bf3dd6ed4e06cb55874', 'message': ""Remove some EVENT call from cluster module\n\nWe don't need the EVENT generation in cluster module. The information\ngenerated are not so useful because all those similar information has\nbeen dumped duing action execution.\n\nChange-Id: Ibbe01d65e87c537512c03755abb8c418b1a208b7\n""}]",0,279939,80363cba60a24141fe933bf3dd6ed4e06cb55874,7,3,1,8246,,,0,"Remove some EVENT call from cluster module

We don't need the EVENT generation in cluster module. The information
generated are not so useful because all those similar information has
been dumped duing action execution.

Change-Id: Ibbe01d65e87c537512c03755abb8c418b1a208b7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/39/279939/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/test_cluster.py', 'senlin/engine/cluster.py']",2,80363cba60a24141fe933bf3dd6ed4e06cb55874,rm-event-call-1," """"""A cluster is a collection of objects of the same profile type. """"""","from senlin.engine import event as EVENT '''A cluster is a set of homogeneous objects of the same profile. ''' EVENT.info(context, self, 'update') EVENT.info(context, self, 'create')",2,16
openstack%2Fsenlin~master~I176423aba4410c15b6496845e3edfca742c6f28f,openstack/senlin,master,I176423aba4410c15b6496845e3edfca742c6f28f,Remove some EVENT calls from node module,MERGED,2016-02-14 09:21:48.000000000,2016-02-15 02:00:43.000000000,2016-02-15 02:00:43.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-14 09:21:48.000000000', 'files': ['senlin/tests/unit/engine/test_node.py', 'senlin/engine/node.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a02ce6a063dd7a59f8643bf135c8c2bc5877700a', 'message': 'Remove some EVENT calls from node module\n\nThe events generated from node modules are not so useful because most of\nthe information are already dumped duing action execution.\n\nChange-Id: I176423aba4410c15b6496845e3edfca742c6f28f\n'}]",0,279938,a02ce6a063dd7a59f8643bf135c8c2bc5877700a,7,3,1,8246,,,0,"Remove some EVENT calls from node module

The events generated from node modules are not so useful because most of
the information are already dumped duing action execution.

Change-Id: I176423aba4410c15b6496845e3edfca742c6f28f
",git fetch https://review.opendev.org/openstack/senlin refs/changes/38/279938/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/engine/test_node.py', 'senlin/engine/node.py']",2,a02ce6a063dd7a59f8643bf135c8c2bc5877700a,rm-event-call-2,,"from senlin.engine import event as EVENT EVENT.info(context, self, 'update') EVENT.info(context, self, 'create') EVENT.warning(context, self, action, status, msg) EVENT.info(context, self, 'create') EVENT.info(context, self, 'delete')",10,47
openstack%2Fsenlin~master~I3c0dca959d63d949a8d7d70dcc84d9af968c50ad,openstack/senlin,master,I3c0dca959d63d949a8d7d70dcc84d9af968c50ad,Revise authorization doc,MERGED,2016-02-15 01:26:03.000000000,2016-02-15 01:44:39.000000000,2016-02-15 01:44:39.000000000,"[{'_account_id': 3}, {'_account_id': 6348}]","[{'number': 1, 'created': '2016-02-15 01:26:03.000000000', 'files': ['doc/source/developer/authorization.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a351e44ebea3159aaf58eb875f50aabba7f38cad', 'message': 'Revise authorization doc\n\nWe are no longer encrypting things even for the trusts now. This patch\nfixes the related documentation for this purpose.\n\nChange-Id: I3c0dca959d63d949a8d7d70dcc84d9af968c50ad\n'}]",0,280034,a351e44ebea3159aaf58eb875f50aabba7f38cad,6,2,1,8246,,,0,"Revise authorization doc

We are no longer encrypting things even for the trusts now. This patch
fixes the related documentation for this purpose.

Change-Id: I3c0dca959d63d949a8d7d70dcc84d9af968c50ad
",git fetch https://review.opendev.org/openstack/senlin refs/changes/34/280034/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/developer/authorization.rst'],1,a351e44ebea3159aaf58eb875f50aabba7f38cad,fix-auth-doc,," Encryption of Credentials ------------------------- Since Senlin is creating a trust for each user. This trust information should be treated as sensitive information. When storing them into database, it has better be encrypted, and that is exactly how Senlin is doing now. In future, this kind of data may be migrated to the Barbican service. As of now, Senlin utilizes the `cryptography` package to do an encryption of the data. The encrypted data can be decrypted only using the generated key. Senlin will return the key to the requester, along with the UUID of the generated webhook.",0,14
openstack%2Fpython-aodhclient~master~I07248e3160367cb489ef8d061196dce0d0d81192,openstack/python-aodhclient,master,I07248e3160367cb489ef8d061196dce0d0d81192,cleanup existing tests,MERGED,2016-02-11 18:49:35.000000000,2016-02-15 01:43:02.000000000,2016-02-15 01:43:02.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 8290}, {'_account_id': 9526}]","[{'number': 1, 'created': '2016-02-11 18:49:35.000000000', 'files': ['aodhclient/tests/functional/test_alarm.py'], 'web_link': 'https://opendev.org/openstack/python-aodhclient/commit/f894408cc533a6bb2d1154544a0aa93c959d2816', 'message': ""cleanup existing tests\n\nsome of these tests don't pass once we enable environment properly\nwith gnocchi.\n\nChange-Id: I07248e3160367cb489ef8d061196dce0d0d81192\n""}]",0,279230,f894408cc533a6bb2d1154544a0aa93c959d2816,8,4,1,6537,,,0,"cleanup existing tests

some of these tests don't pass once we enable environment properly
with gnocchi.

Change-Id: I07248e3160367cb489ef8d061196dce0d0d81192
",git fetch https://review.opendev.org/openstack/python-aodhclient refs/changes/30/279230/1 && git format-patch -1 --stdout FETCH_HEAD,['aodhclient/tests/functional/test_alarm.py'],1,f894408cc533a6bb2d1154544a0aa93c959d2816,fix-tests," self.assertFirstLineStartsWith(result.split('\n'), 'Conflict (HTTP 409)') self.assertFirstLineStartsWith(result.split('\n'), ""Not found (HTTP 404)"") self.assertFirstLineStartsWith(result.split('\n'), ""Not found (HTTP 404)"") self.assertFirstLineStartsWith(result.split('\n'), 'Conflict (HTTP 409)') self.assertFirstLineStartsWith(result.split('\n'), ""Not found (HTTP 404)"") self.assertFirstLineStartsWith(result.split('\n'), ""Not found (HTTP 404)"")"," self.assertEqual(result.strip(), 'Conflict (HTTP 409)') self.assertEqual(result.strip(), ""Not found (HTTP 404)"") self.assertEqual(result.strip(), ""Not found (HTTP 404)"") self.assertEqual(result.strip(), 'Conflict (HTTP 409)') self.assertEqual(result.strip(), ""Not found (HTTP 404)"") self.assertEqual(result.strip(), ""Not found (HTTP 404)"")",12,6
openstack%2Fmurano~master~Iec3c1edbb98de3332888dd01b2b428c8496c3fa1,openstack/murano,master,Iec3c1edbb98de3332888dd01b2b428c8496c3fa1,Don't use list lenght check in Repository test suite,MERGED,2016-02-14 11:20:40.000000000,2016-02-15 01:38:39.000000000,2016-02-15 01:38:39.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7821}, {'_account_id': 14107}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-14 11:20:40.000000000', 'files': ['murano_tempest_tests/tests/api/application_catalog/test_repository.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/3658e2e20a74cd8a335405f027d31424e8c303e3', 'message': ""Don't use list lenght check in Repository test suite\n\n- Replace assertEqual for package list checks to assertIn and assertNotIn\nfor object in TestRepositorySanity class.\n\nChange-Id: Iec3c1edbb98de3332888dd01b2b428c8496c3fa1\nCloses-Bug: #1545090\n""}]",0,279957,3658e2e20a74cd8a335405f027d31424e8c303e3,10,5,1,13962,,,0,"Don't use list lenght check in Repository test suite

- Replace assertEqual for package list checks to assertIn and assertNotIn
for object in TestRepositorySanity class.

Change-Id: Iec3c1edbb98de3332888dd01b2b428c8496c3fa1
Closes-Bug: #1545090
",git fetch https://review.opendev.org/openstack/murano refs/changes/57/279957/1 && git format-patch -1 --stdout FETCH_HEAD,['murano_tempest_tests/tests/api/application_catalog/test_repository.py'],1,3658e2e20a74cd8a335405f027d31424e8c303e3,bug/1545090," package_list = self.application_catalog_client.get_list_packages() self.assertIn(package, package_list) package_list = self.application_catalog_client.get_list_packages() self.assertNotIn(package, package_list)"," packages_list = self.application_catalog_client.get_list_packages() updated_packages_list = self.application_catalog_client.\ get_list_packages() self.assertEqual(len(packages_list) + 1, len(updated_packages_list)) updated_packages_list = self.application_catalog_client.\ get_list_packages() self.assertEqual(len(packages_list), len(updated_packages_list))",4,7
openstack%2Fnetworking-midonet~master~I68e062ed53f5d105b4181f0b9ba394c4f6b242bf,openstack/networking-midonet,master,I68e062ed53f5d105b4181f0b9ba394c4f6b242bf,Reject fixed_ips updates on non-VIF ports,MERGED,2016-01-20 13:38:01.000000000,2016-02-15 01:37:04.000000000,2016-02-15 01:37:04.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 6854}, {'_account_id': 8837}]","[{'number': 1, 'created': '2016-01-20 13:38:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/01437a5a13b8d65b7f45e9a070fc6b29a0ecc89c', 'message': ""Reject fixed_ips updates on non-VIF ports\n\nBecause our backend doesn't have it implemented. (yet?)\n\nCloses-Bug: #1533122\nChange-Id: I68e062ed53f5d105b4181f0b9ba394c4f6b242bf\n""}, {'number': 2, 'created': '2016-01-21 04:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/9fce9c2310c1b174a50becd96b933432e81cb011', 'message': ""Reject fixed_ips updates on non-VIF ports\n\nBecause our backend doesn't have it implemented. (yet?)\n\nCloses-Bug: #1533122\nChange-Id: I68e062ed53f5d105b4181f0b9ba394c4f6b242bf\n""}, {'number': 3, 'created': '2016-01-21 07:57:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/d40fff075deac04c2b2ee0f951302b7a26f602be', 'message': ""Reject fixed_ips updates on non-VIF ports\n\nBecause our backend doesn't have it implemented. (yet?)\n\nCloses-Bug: #1533122\nChange-Id: I68e062ed53f5d105b4181f0b9ba394c4f6b242bf\n""}, {'number': 4, 'created': '2016-01-27 07:57:50.000000000', 'files': ['midonet/neutron/tests/unit/test_midonet_plugin.py', 'midonet/neutron/ml2/mech_driver.py', 'midonet/neutron/tests/unit/test_midonet_plugin_v2.py', 'midonet/neutron/tests/unit/test_midonet_plugin_ml2.py', 'midonet/neutron/common/utils.py', 'midonet/neutron/plugin_v1.py', 'midonet/neutron/plugin_v2.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/3b113c2b62e3fe4acb3e6f0ba3abfeed7b1f7cca', 'message': ""Reject fixed_ips updates on non-VIF ports\n\nBecause our backend doesn't have it implemented. (yet?)\n\nCloses-Bug: #1533122\nChange-Id: I68e062ed53f5d105b4181f0b9ba394c4f6b242bf\n""}]",0,270188,3b113c2b62e3fe4acb3e6f0ba3abfeed7b1f7cca,18,5,4,6854,,,0,"Reject fixed_ips updates on non-VIF ports

Because our backend doesn't have it implemented. (yet?)

Closes-Bug: #1533122
Change-Id: I68e062ed53f5d105b4181f0b9ba394c4f6b242bf
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/88/270188/4 && git format-patch -1 --stdout FETCH_HEAD,"['midonet/neutron/ml2/mech_driver.py', 'midonet/neutron/common/utils.py', 'midonet/neutron/plugin_v1.py', 'midonet/neutron/plugin_v2.py']",4,01437a5a13b8d65b7f45e9a070fc6b29a0ecc89c,bug/1475931,"from midonet.neutron.common import utils as c_utils c_utils.check_update_port(original_port, p)",,33,0
openstack%2Foslo.config~master~Ieedf522eda1f57d6e4ea1b30a01df656019ac0c5,openstack/oslo.config,master,Ieedf522eda1f57d6e4ea1b30a01df656019ac0c5,add generator hook for apps to update option defaults,MERGED,2016-02-10 20:21:46.000000000,2016-02-15 01:35:28.000000000,2016-02-15 00:59:39.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2903}, {'_account_id': 5638}, {'_account_id': 16051}]","[{'number': 1, 'created': '2016-02-10 20:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/18b89e001c55ad7d6bbf9a6b8e90f4c5f1945742', 'message': ""add generator hook for apps to update option defaults\n\nProvide a way for applications to hook into the config sample generator\nto change the defaults for options before the sample output is\nrendered.\n\nWe have to use the same public functions exposed by libraries\nfor this purpose, but we can't guarantee the import order of the option\ndiscovery functions, so this patch adds an explicit hook to let the\napplication invoke set_defaults() before we ask the functions for their\noptions.\n\nThe results depend on the libraries returning the original Opt objects\nrather than copies, so we may have to make changes to some list_opts()\nimplementations in other libraries.\n\nChange-Id: Ieedf522eda1f57d6e4ea1b30a01df656019ac0c5\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}, {'number': 2, 'created': '2016-02-12 19:39:33.000000000', 'files': ['oslo_config/tests/test_generator.py', 'oslo_config/generator.py', 'doc/source/generator.rst'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/b09ba4a3e044d163b129a20421684d557105c4fe', 'message': ""add generator hook for apps to update option defaults\n\nProvide a way for applications to hook into the config sample generator\nto change the defaults for options before the sample output is\nrendered.\n\nWe have to use the same public functions exposed by libraries\nfor this purpose, but we can't guarantee the import order of the option\ndiscovery functions, so this patch adds an explicit hook to let the\napplication invoke set_defaults() before we ask the functions for their\noptions.\n\nThe results depend on the libraries returning the original Opt objects\nrather than copies, so we may have to make changes to some list_opts()\nimplementations in other libraries.\n\nChange-Id: Ieedf522eda1f57d6e4ea1b30a01df656019ac0c5\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",2,278604,b09ba4a3e044d163b129a20421684d557105c4fe,19,5,2,2472,,,0,"add generator hook for apps to update option defaults

Provide a way for applications to hook into the config sample generator
to change the defaults for options before the sample output is
rendered.

We have to use the same public functions exposed by libraries
for this purpose, but we can't guarantee the import order of the option
discovery functions, so this patch adds an explicit hook to let the
application invoke set_defaults() before we ask the functions for their
options.

The results depend on the libraries returning the original Opt objects
rather than copies, so we may have to make changes to some list_opts()
implementations in other libraries.

Change-Id: Ieedf522eda1f57d6e4ea1b30a01df656019ac0c5
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/04/278604/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/tests/test_generator.py', 'oslo_config/generator.py', 'doc/source/generator.rst']",3,18b89e001c55ad7d6bbf9a6b8e90f4c5f1945742,generator-override-defaults,".. note:: You should return the original options, not a copy, because the default update hooks depend on the original option object being returned.Modifying Defaults from Other Namespaces ---------------------------------------- Occasionally applications need to override the defaults for options defined in libraries. At runtime this is done using an API within the library. Since the config generator cannot guarantee the order in which namespaces will be imported, we can't ensure that application code can change the option defaults before the generator loads the options from a library. Instead, a separate optional processing hook is provided for applications to register a function to update default values after *all* options are loaded. The hooks are registered in a separate entry point namespace (``oslo.config.opts.defaults``), using the same entry point name as the application's ``list_opts()`` function. :: [entry_points] oslo.config.opts.defaults = keystone = keystone.common.config:update_opt_defaults The update function should take no arguments. It should invoke the public :func:`set_defaults` functions in any libraries for which it has option defaults to override, just as the application does during its normal startup process. :: from oslo_log import log def update_opt_defaults(): log.set_defaults( default_log_levels=log.DEFAULT_LOG_LEVELS + ['noisy=WARN'], ) ","You might choose to return a copy of the options so that the return value can't be modified for nefarious purposes, though this is not strictly necessary:: def list_opts(): return [('blaa', copy.deepcopy(opts))]",102,5
openstack%2Fnetworking-midonet~master~I1b442a5b9754626dd256193161874bcd6b99576f,openstack/networking-midonet,master,I1b442a5b9754626dd256193161874bcd6b99576f,tox_install: Add an explicit BRANCH_NAME,MERGED,2016-02-10 03:57:57.000000000,2016-02-15 01:34:29.000000000,2016-02-15 01:34:29.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 8837}]","[{'number': 1, 'created': '2016-02-10 03:57:57.000000000', 'files': ['tools/tox_install_project.sh'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/9595f3eb1580d2962e5e4ca4ea70540fa378956e', 'message': 'tox_install: Add an explicit BRANCH_NAME\n\nFollowing I484637d2502f276313edc2279078a200ebc2689a\n\nChange-Id: I1b442a5b9754626dd256193161874bcd6b99576f\n'}]",0,278193,9595f3eb1580d2962e5e4ca4ea70540fa378956e,9,4,1,6854,,,0,"tox_install: Add an explicit BRANCH_NAME

Following I484637d2502f276313edc2279078a200ebc2689a

Change-Id: I1b442a5b9754626dd256193161874bcd6b99576f
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/93/278193/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/tox_install_project.sh'],1,9595f3eb1580d2962e5e4ca4ea70540fa378956e,tox_install3,BRANCH_NAME=master --branch ${BRANCH_NAME} \ pip install -U -egit+https://git.openstack.org/openstack/${PROJ}@${BRANCH_NAME}#egg=${PROJ}, pip install -U -egit+https://git.openstack.org/openstack/${PROJ}#egg=${PROJ},3,1
openstack%2Fnetworking-midonet~master~Ife756ea59b298c87e3d36c822a98c33abadac983,openstack/networking-midonet,master,Ife756ea59b298c87e3d36c822a98c33abadac983,loadbalancer: Add missing whitespaces in exception messages,MERGED,2016-01-18 09:37:02.000000000,2016-02-15 01:27:51.000000000,2016-02-15 01:27:51.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 8837}]","[{'number': 1, 'created': '2016-01-18 09:37:02.000000000', 'files': ['midonet/neutron/db/loadbalancer_db.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/ce5f843f035f54edf8f182b7619a4ed61b15bb69', 'message': 'loadbalancer: Add missing whitespaces in exception messages\n\nChange-Id: Ife756ea59b298c87e3d36c822a98c33abadac983\n'}]",0,268951,ce5f843f035f54edf8f182b7619a4ed61b15bb69,8,3,1,6854,,,0,"loadbalancer: Add missing whitespaces in exception messages

Change-Id: Ife756ea59b298c87e3d36c822a98c33abadac983
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/51/268951/1 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/db/loadbalancer_db.py'],1,ce5f843f035f54edf8f182b7619a4ed61b15bb69,lb-message," msg = (_LE(""The VIP and pool cannot be on the same subnet if "" msg = (_LE(""The VIP and pool cannot be on the same subnet if """," msg = (_LE(""The VIP and pool cannot be on the same subnet if"" msg = (_LE(""The VIP and pool cannot be on the same subnet if""",2,2
openstack%2Fmanila~master~I890ba4c54b0da10060767620ff5ff7e480d79a9c,openstack/manila,master,I890ba4c54b0da10060767620ff5ff7e480d79a9c,Removed ignored checks from tox.ini and fixed pep8 issues,MERGED,2015-12-31 12:54:22.000000000,2016-02-15 01:21:16.000000000,2016-02-15 01:21:16.000000000,"[{'_account_id': 3}, {'_account_id': 8851}, {'_account_id': 10725}, {'_account_id': 11865}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 16883}, {'_account_id': 17565}, {'_account_id': 17717}, {'_account_id': 18128}, {'_account_id': 18142}]","[{'number': 1, 'created': '2015-12-31 12:54:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/142e28755c68e63c563eed5fde9e37612851fa4e', 'message': 'Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt\nwas beyoind the stated in global requerements.\nCinder, nova, neutron, glance are using the hacking\nversion according to global requrements and with this\npatch manila alligns rows.\n\nUpdated the version of hacking and fixed severel\npep8 issues due to the hacking version propagation.\n\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n'}, {'number': 2, 'created': '2016-01-03 10:17:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/64521422794a05a1ae53ccc896a7bffe34eb5768', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 3, 'created': '2016-01-04 15:31:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a5f6acea73cf6dd08fa2b65635ef432a162c4d97', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 4, 'created': '2016-01-04 16:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/c9699c8dd7d8c9b1d14fc05abc98f2a37d80f593', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 5, 'created': '2016-01-07 12:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/aafd42842dc51529d6f88ad71923422ffee86264', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 6, 'created': '2016-01-08 07:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2dc60b4215621d74e12b663e4e7ac45c632ff683', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requirements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 7, 'created': '2016-01-08 09:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/da32bb24a58e8e6195d6346bf0f99cfd49eb1402', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requirements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 8, 'created': '2016-01-09 23:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/0383958ad8031e5973eb3b9c17f58a0d5cd7474c', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 9, 'created': '2016-01-11 09:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/d4f16336d86286ea0e865abbaf63e42503318e9c', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 10, 'created': '2016-01-11 21:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/72caca6edc4a7136ac03cbcec10035afc6181e7e', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 11, 'created': '2016-01-12 11:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/eb5adf4d8c12d24befae57f65352d07f4bb8955e', 'message': ""Updated hacking version and fixed pep8 issues\n\nThe version of hacking in test-requrements.txt was beyond\nthe stated in global requirements. Cinder, Nova, Neutron,\nGlance are using the hacking version according to global\nrequirements and with this patch manila aligns rows.\n\nUpdated the version of hacking and fixed several pep8 issues\ndue to the hacking version propagation.\n\nThe list of fixed issues:\n    - W292 No newline at end of file\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}, {'number': 12, 'created': '2016-02-14 12:56:58.000000000', 'files': ['manila/network/linux/ovs_lib.py', 'tools/lintstack.py', 'manila/tests/__init__.py', 'manila/api/v1/limits.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/share/drivers/emc/test_driver.py', 'manila/tests/monkey_patch_example/example_a.py', 'manila/tests/share/test_manager.py', 'tox.ini', 'manila/tests/monkey_patch_example/example_b.py', 'manila/__init__.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/4a61faa065dc445bb32cff1a464d2e22e84e5427', 'message': ""Removed ignored checks from tox.ini and fixed pep8 issues\n\nDue to the hacking version update several pep8 checks where ignored\nin the flakes8 section of the tox.ini. Removed ignored checks and fixed\nappropriate pep8 issues.\n\nThe list of fixed issues:\n    - H105 Don't use author tags\n    - H238 Old style class declaration, use new style (inherit from `object`)\n    - H501 Do not use self.__dict__ for string formatting\n\nCloses-Bug: 1530719\nChange-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c\n""}]",20,262781,4a61faa065dc445bb32cff1a464d2e22e84e5427,113,11,12,18142,,,0,"Removed ignored checks from tox.ini and fixed pep8 issues

Due to the hacking version update several pep8 checks where ignored
in the flakes8 section of the tox.ini. Removed ignored checks and fixed
appropriate pep8 issues.

The list of fixed issues:
    - H105 Don't use author tags
    - H238 Old style class declaration, use new style (inherit from `object`)
    - H501 Do not use self.__dict__ for string formatting

Closes-Bug: 1530719
Change-Id: I890ba4c54b0da10060767620ff5ff7e480d79a9c
",git fetch https://review.opendev.org/openstack/manila refs/changes/81/262781/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/views/versions.py', 'manila/api/v1/limits.py', 'test-requirements.txt', 'manila/tests/api/test_versions.py', 'manila/tests/api/v2/test_share_types.py', 'manila/tests/share/test_migration.py', 'manila/share/drivers/netapp/dataontap/protocols/base.py', 'manila/network/linux/ovs_lib.py', 'manila/tests/api/openstack/test_versioned_method.py', 'manila_tempest_tests/tests/api/admin/test_scheduler_stats.py', 'tools/lintstack.py', 'manila/tests/api/v1/test_scheduler_stats.py', 'manila/tests/api/views/test_versions.py', 'manila/tests/api/openstack/test_wsgi.py', 'manila/tests/share/drivers/emc/test_driver.py', 'manila/tests/monkey_patch_example/example_a.py', 'tox.ini', 'manila/tests/monkey_patch_example/example_b.py']",18,142e28755c68e63c563eed5fde9e37612851fa4e,bug/1530719,class ExampleClassB(object):,class ExampleClassB():,26,21
openstack%2Fapi-site~master~I7b80319a657d880680679af8024381639aff437f,openstack/api-site,master,I7b80319a657d880680679af8024381639aff437f,"[Orchestration API v1] Missing sample response for ""Show event details"" API",MERGED,2016-01-29 15:33:30.000000000,2016-02-15 01:08:04.000000000,2016-02-13 17:49:34.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 19935}]","[{'number': 1, 'created': '2016-01-29 15:33:30.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/0748dde89bee60cb4557cc073d8448b0085bc4b4', 'message': '[Orchestration API v1] Missing sample response\nfor ""Show event details"" API\n\nThis patch does correct orchestration-api.wadl\nto show sample response of ""Show event details"" API.\n\nChange-Id: I7b80319a657d880680679af8024381639aff437f\nCloses-Bug: #1539593\n'}]",1,274117,0748dde89bee60cb4557cc073d8448b0085bc4b4,14,4,1,19935,,,0,"[Orchestration API v1] Missing sample response
for ""Show event details"" API

This patch does correct orchestration-api.wadl
to show sample response of ""Show event details"" API.

Change-Id: I7b80319a657d880680679af8024381639aff437f
Closes-Bug: #1539593
",git fetch https://review.opendev.org/openstack/api-site refs/changes/17/274117/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl'],1,0748dde89bee60cb4557cc073d8448b0085bc4b4,bug/1539593," <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xml:lang=""EN"" <representation mediaType=""application/json""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <xsdxt:code href=""samples/event-show-response.json""/> </wadl:doc> </representation>"," <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN"" <xsdxt:code href=""samples/event-show-response.json""/> <representation mediaType=""application/json""/>",8,4
openstack%2Fpython-muranoclient~master~I73c24bbc39b9ec348d46d7ec243d07c25145d92c,openstack/python-muranoclient,master,I73c24bbc39b9ec348d46d7ec243d07c25145d92c,Add Status field_labels for environment list,MERGED,2016-01-21 09:07:22.000000000,2016-02-15 01:05:31.000000000,2016-02-15 01:05:31.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 12597}, {'_account_id': 13962}, {'_account_id': 14107}]","[{'number': 1, 'created': '2016-01-21 09:07:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/61b7186749d6941615a00ecc02bf1054c62e1c98', 'message': ""Add Status field_labels for environment list\n\nNow the environment list didn't have 'Status' Row,\nwe need display it to user.\n\nChange-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c\nCloses-Bug: #1535600\n""}, {'number': 2, 'created': '2016-01-21 10:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/7f82f0b6861eed99045ce3f174dfde7bd5dc6992', 'message': ""Add Status field_labels for environment list\n\nNow the environment list didn't have 'Status' Row,\nwe need display it to user.\n\nChange-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c\nCloses-Bug: #1535600\n""}, {'number': 3, 'created': '2016-02-11 20:05:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/bd6ad4057f9d6ec97d442e5e4417cfd68546311e', 'message': ""Add Status field_labels for environment list\n\nNow the environment list didn't have 'Status' Row,\nwe need display it to user.\n\nChange-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c\nCloses-Bug: #1535600\n""}, {'number': 4, 'created': '2016-02-14 00:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/e277c13d866a620f54b03297f9652e186f59797e', 'message': ""Add Status field_labels for environment list\n\nNow the environment list didn't have 'Status' Row,\nwe need display it to user.\n\nChange-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c\nCloses-Bug: #1535600\n""}, {'number': 5, 'created': '2016-02-14 02:24:48.000000000', 'files': ['muranoclient/tests/functional/cli/test_murano.py', 'muranoclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/7f521c6fb77743ebab1be3fd1005cd9cb7368c56', 'message': ""Add Status field_labels for environment list\n\nNow the environment list didn't have 'Status' Row,\nwe need display it to user.\n\nChange-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c\nCloses-Bug: #1535600\n""}]",6,270674,7f521c6fb77743ebab1be3fd1005cd9cb7368c56,31,7,5,14107,,,0,"Add Status field_labels for environment list

Now the environment list didn't have 'Status' Row,
we need display it to user.

Change-Id: I73c24bbc39b9ec348d46d7ec243d07c25145d92c
Closes-Bug: #1535600
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/74/270674/5 && git format-patch -1 --stdout FETCH_HEAD,"['muranoclient/tests/functional/cli/test_murano.py', 'muranoclient/v1/shell.py']",2,61b7186749d6941615a00ecc02bf1054c62e1c98,bug/1535600," field_labels = ['ID', 'Name', 'Status', 'Created', 'Updated'] fields = ['id', 'name', 'status', 'created', 'updated']"," field_labels = ['ID', 'Name', 'Created', 'Updated'] fields = ['id', 'name', 'created', 'updated']",4,3
openstack%2Fapi-site~master~I4394c3cebdda6ef8af5d4cd427e55b6ee77f9559,openstack/api-site,master,I4394c3cebdda6ef8af5d4cd427e55b6ee77f9559,[Orchestration API v1]Missing information when listing template versions,MERGED,2016-02-04 08:53:27.000000000,2016-02-15 01:04:21.000000000,2016-02-13 13:16:26.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 10497}, {'_account_id': 17958}]","[{'number': 1, 'created': '2016-02-04 08:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/6ccca140068b738a81936ffc4ed4c932dd477298', 'message': '[Orchestration API v1]Missing information when listing template versions\n\nThis patch fixes missing ""Normal response codes"" and Response body when listing\nall available template versions using Orchestration API v1.\n\nChange-Id: I4394c3cebdda6ef8af5d4cd427e55b6ee77f9559\nCloses-Bug: #1541724\n'}, {'number': 2, 'created': '2016-02-04 12:33:49.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-versions-response.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/9e0c4a3783d57ba1b86210ded3577641da0a700b', 'message': '[Orchestration API v1]Missing information when listing template versions\n\nThis patch fixes missing ""Normal response codes"" and Response body when listing\nall available template versions using Orchestration API v1.\n\nChange-Id: I4394c3cebdda6ef8af5d4cd427e55b6ee77f9559\nCloses-Bug: #1541724\n'}]",0,276101,9e0c4a3783d57ba1b86210ded3577641da0a700b,10,4,2,17958,,,0,"[Orchestration API v1]Missing information when listing template versions

This patch fixes missing ""Normal response codes"" and Response body when listing
all available template versions using Orchestration API v1.

Change-Id: I4394c3cebdda6ef8af5d4cd427e55b6ee77f9559
Closes-Bug: #1541724
",git fetch https://review.opendev.org/openstack/api-site refs/changes/01/276101/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-versions-response.json']",2,6ccca140068b738a81936ffc4ed4c932dd477298,bug/1541724,"{ ""template_versions"": [ { ""version"": ""heat_template_version.2014-10-16"", ""type"": ""hot"" }, { ""version"": ""heat_template_version.2015-04-30"", ""type"": ""hot"" }, { ""version"": ""HeatTemplateFormatVersion.2012-12-12"", ""type"": ""cfn"" }, { ""version"": ""heat_template_version.2015-10-15"", ""type"": ""hot"" }, { ""version"": ""AWSTemplateFormatVersion.2010-09-09"", ""type"": ""cfn"" }, { ""version"": ""heat_template_version.2013-05-23"", ""type"": ""hot"" }, { ""version"": ""heat_template_version.2016-04-08"", ""type"": ""hot"" } ] } ",,42,0
openstack%2Faodh~master~I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab,openstack/aodh,master,I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab,Don't send notificaton when recording alarm change,ABANDONED,2015-11-18 02:45:06.000000000,2016-02-15 01:03:20.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 1894}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 8290}]","[{'number': 1, 'created': '2015-11-18 02:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/b8337997b9a5c973bcf02a7db91a04b04f21e96c', 'message': ""Don't send notificaton when recording alarm change\n\nWhen updating an alarm (include setting alarm state), aodh will record the\nalarm change as default, and will send a notification include the details\nabout alarm change to message bus. To keep consistent, when alarm\nevaluator refreshing an alarm state, it will record the alarm change and\nsend a notification about the alarm change. As we have aodh-notifier to\ntrigger actions of alarm when refresh alarm state, and we will record all\nthe alarm change details to database when alarm updated, I think the\nnotification is redundant.\n\nCloses-Bug: #1517286\nChange-Id: I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab\n""}, {'number': 2, 'created': '2015-11-18 03:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/56d96e8a77b8fc734728dcf3887fc14056a3da0a', 'message': ""Don't send notificaton when recording alarm change\n\nWhen updating an alarm (include setting alarm state), aodh will record the\nalarm change as default, and will send a notification include the details\nabout alarm change to message bus. To keep consistent, when alarm\nevaluator refreshing an alarm state, it will record the alarm change and\nsend a notification about the alarm change. As we have aodh-notifier to\ntrigger actions of alarm when refresh alarm state, and we will record all\nthe alarm change details to database when alarm updated, I think the\nnotification is redundant.\n\nCloses-Bug: #1517286\nChange-Id: I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab\n""}, {'number': 3, 'created': '2015-11-24 07:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/aodh/commit/69d967192e719136f348061b86f2e65ed471506c', 'message': ""Don't send notificaton when recording alarm change\n\nWhen updating an alarm (include setting alarm state), aodh will record the\nalarm change as default, and will send a notification include the details\nabout alarm change to message bus. To keep consistent, when alarm\nevaluator refreshing an alarm state, it will record the alarm change and\nsend a notification about the alarm change. As we have aodh-notifier to\ntrigger actions of alarm when refresh alarm state, and we will record all\nthe alarm change details to database when alarm updated, I think the\nnotification is redundant.\n\nThis change deprecate the notification firstly and will remove it in N*\n\nCloses-Bug: #1517286\nChange-Id: I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab\n""}, {'number': 4, 'created': '2015-11-30 01:53:45.000000000', 'files': ['aodh/api/controllers/v2/alarms.py', 'aodh/evaluator/__init__.py'], 'web_link': 'https://opendev.org/openstack/aodh/commit/0caec6f44531a41538640d646c7dff7fe613e999', 'message': ""Don't send notificaton when recording alarm change\n\nWhen updating an alarm (include setting alarm state), aodh will record the\nalarm change as default, and will send a notification include the details\nabout alarm change to message bus. To keep consistent, when alarm\nevaluator refreshing an alarm state, it will record the alarm change and\nsend a notification about the alarm change. As we have aodh-notifier to\ntrigger actions of alarm when refresh alarm state, and we will record all\nthe alarm change details to database when alarm updated, I think the\nnotification is redundant.\n\nThis change deprecate the notification firstly and will remove it in N*\n\nCloses-Bug: #1517286\nChange-Id: I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab\n""}]",2,246727,0caec6f44531a41538640d646c7dff7fe613e999,23,7,4,8290,,,0,"Don't send notificaton when recording alarm change

When updating an alarm (include setting alarm state), aodh will record the
alarm change as default, and will send a notification include the details
about alarm change to message bus. To keep consistent, when alarm
evaluator refreshing an alarm state, it will record the alarm change and
send a notification about the alarm change. As we have aodh-notifier to
trigger actions of alarm when refresh alarm state, and we will record all
the alarm change details to database when alarm updated, I think the
notification is redundant.

This change deprecate the notification firstly and will remove it in N*

Closes-Bug: #1517286
Change-Id: I4cdb7df4445733ab219f12ff7f27bc67b07bc3ab
",git fetch https://review.opendev.org/openstack/aodh refs/changes/27/246727/3 && git format-patch -1 --stdout FETCH_HEAD,"['aodh/api/controllers/v2/alarms.py', 'aodh/evaluator/__init__.py', 'aodh/tests/functional/api/v2/test_alarm_scenarios.py', 'aodh/tests/unit/evaluator/test_threshold.py']",4,b8337997b9a5c973bcf02a7db91a04b04f21e96c,bug/1517286," def test_alarm_change_record(self, utcnow, mock_uuid): mock_uuid.side_effect = ['fake_event_id_0', 'fake_event_id_1']"," @mock.patch.object(messaging, 'get_notifier') def test_alarm_change_record(self, get_notifier, utcnow, mock_uuid): # the context.RequestContext() method need to generate uuid, # so we need to provide 'fake_uuid_0' and 'fake_uuid_1' for that. mock_uuid.side_effect = ['fake_event_id_0', 'fake_uuid_0', 'fake_event_id_1', 'fake_uuid_1'] change_notifier = mock.MagicMock() get_notifier.return_value = change_notifier notify_calls = change_notifier.info.call_args_list notification = ""alarm.state_transition"" expected_payloads = [mock.call(mock.ANY, notification, p) for p in payloads] self.assertEqual(expected_payloads, notify_calls)",2,103
openstack%2Foslo-specs~master~I2c21c30b621cf12fcc588097533416f5792ebe4c,openstack/oslo-specs,master,I2c21c30b621cf12fcc588097533416f5792ebe4c,oslo.messaging message compression proposal,ABANDONED,2015-11-19 15:58:57.000000000,2016-02-15 00:49:55.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 7109}, {'_account_id': 7534}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-11-19 15:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/8d36abee7fea12a2aea1e760919aea3948c4a5e5', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 2, 'created': '2015-11-20 09:07:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/805e378857993c2712496d7b08dda7bdeb9c8fcf', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 3, 'created': '2015-11-20 10:04:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/50ae2abac5fd1a188f09b23c8999ed292727b522', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 4, 'created': '2015-12-01 10:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/bc6b303d4204ec6f96be385cb068de20360d19b0', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 5, 'created': '2015-12-03 09:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/cc9e424a184f6bc148e70e8221e27b60c809da83', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 6, 'created': '2015-12-04 09:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/985da038ee88f0812a0e6973c022648ffdfd3358', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}, {'number': 7, 'created': '2016-01-19 09:29:26.000000000', 'files': ['specs/mitaka/message-compression.rst'], 'web_link': 'https://opendev.org/openstack/oslo-specs/commit/b4b59ee989647450d5e5e05d320c4c2a79457088', 'message': 'oslo.messaging message compression proposal\n\nblueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression\n\nFor now oslo.messaging passes raw messages to messaging transport.\nFor large messages we may need compression to reduce load on messaging transport.\n\nChange-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c\n'}]",24,247668,b4b59ee989647450d5e5e05d320c4c2a79457088,46,11,7,7534,,,0,"oslo.messaging message compression proposal

blueprint: https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression

For now oslo.messaging passes raw messages to messaging transport.
For large messages we may need compression to reduce load on messaging transport.

Change-Id: I2c21c30b621cf12fcc588097533416f5792ebe4c
",git fetch https://review.opendev.org/openstack/oslo-specs refs/changes/68/247668/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/message-compression.rst'],1,8d36abee7fea12a2aea1e760919aea3948c4a5e5,bp/https,"============================= Compress large messages ============================= https://blueprints.launchpad.net/oslo.messaging/+spec/message-compression For now oslo.messaging passes raw messages to messaging transport. For large messages we may need compression to reduce load on messaging transport. Problem description =================== In some cases (e.g big OpenStack clusters) messages that are passed through messaging service can reach dozens MB. For such cases compression can be useful. The suggestion is to compress messages after certain size limit that can be configured. Proposed change =============== Changes in oslo_messaging/_drivers/common.py: Provide new message format - rpc envelop version 3.0 The current message format (version 2.0) is: { 'oslo.version': <RPC Envelope Version as a String>, 'oslo.message': <Application Message Payload, JSON encoded> } Suggested 3.0 format: { 'oslo.version': <RPC Envelope Version as a String>, 'oslo.message': <Application Message Payload, JSON encoded>, 'compression_method': <Compression method, None if not compressed> } Add compression to serialize_msg Implement separate deserializers for 2.0 and 3.0 version compression methods to use: zlib Alternatives ------------ Find out in what projects and cases large messages appear. Think about way to avoid sending such messages Impact on Existing APIs ----------------------- None Security impact --------------- None Performance Impact ------------------ None Configuration Impact -------------------- New options: compress_method - default None means that no compression used compress_threshold - compress message if its length more than value. Developer Impact ---------------- None Testing Impact -------------- Functional test required Implementation ============== Assignee(s) ----------- Primary assignee: yportnova@mirantis.com Other contributors: None Milestones ---------- None Work Items ---------- * implement compression Incubation ========== N/A Documentation Impact ==================== None Dependencies ============ oslo.messaging References ========== None",,124,0
openstack%2Fmurano-dashboard~master~I4098cacd4150b80a0f06982b31dbff9de8433cc4,openstack/murano-dashboard,master,I4098cacd4150b80a0f06982b31dbff9de8433cc4,Update URLs to Django 1.8 style,MERGED,2016-02-09 13:11:59.000000000,2016-02-15 00:48:36.000000000,2016-02-15 00:48:36.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8358}, {'_account_id': 10063}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-09 13:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/43814f2582222532adbd57d81655f6e3e2a7ceaf', 'message': 'Update URLs to Django 1.8 style\n\ndjango.conf.urls.patterns() is deprecated since 1.8.\nWe should not use patterns(), so this patch updates URLs to\n1.8 style.\n\nChange-Id: I4098cacd4150b80a0f06982b31dbff9de8433cc4\nCloses-Bug: #1539354\n'}, {'number': 2, 'created': '2016-02-13 05:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cb9ed27a994af160831b11180a2a94ffd67c01a7', 'message': 'Update URLs to Django 1.8 style\n\ndjango.conf.urls.patterns() is deprecated since 1.8.\nWe should not use patterns(), so this patch updates URLs to\n1.8 style.\n\nChange-Id: I4098cacd4150b80a0f06982b31dbff9de8433cc4\nCloses-Bug: #1539354\n'}, {'number': 3, 'created': '2016-02-13 05:28:27.000000000', 'files': ['muranodashboard/packages/urls.py', 'muranodashboard/categories/urls.py', 'muranodashboard/environments/urls.py', 'muranodashboard/catalog/urls.py', 'muranodashboard/images/urls.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/411c11d45d75af61fde878cbce91e602ad432c6d', 'message': 'Update URLs to Django 1.8 style\n\ndjango.conf.urls.patterns() is deprecated since 1.8.\nWe should not use patterns(), so this patch updates URLs to\n1.8 style.\n\nChange-Id: I4098cacd4150b80a0f06982b31dbff9de8433cc4\nCloses-Bug: #1539354\n'}]",6,277819,411c11d45d75af61fde878cbce91e602ad432c6d,44,12,3,14363,,,0,"Update URLs to Django 1.8 style

django.conf.urls.patterns() is deprecated since 1.8.
We should not use patterns(), so this patch updates URLs to
1.8 style.

Change-Id: I4098cacd4150b80a0f06982b31dbff9de8433cc4
Closes-Bug: #1539354
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/19/277819/3 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/categories/urls.py', 'muranodashboard/packages/urls.py', 'muranodashboard/environments/urls.py', 'muranodashboard/catalog/urls.py', 'muranodashboard/images/urls.py']",5,43814f2582222532adbd57d81655f6e3e2a7ceaf,bug/1539354,"from django.conf.urls import url # noqa urlpatterns = [ url(r'^$', views.MarkedImagesView.as_view(), name='index'), url(r'^mark_image$', views.MarkImageView.as_view(), name='mark_image'), url(r'^remove_metadata$', views.MarkedImagesView.as_view(), name='remove_metadata'), ]","from django.conf import urlsurlpatterns = urls.patterns( '', urls.url(r'^$', views.MarkedImagesView.as_view(), name='index'), urls.url(r'^mark_image$', views.MarkImageView.as_view(), name='mark_image'), urls.url(r'^remove_metadata$', views.MarkedImagesView.as_view(), name='remove_metadata'), )",65,104
openstack%2Foslo.service~master~Iff4ea2b00e50f6928a22ac2309e77b8bafade087,openstack/oslo.service,master,Iff4ea2b00e50f6928a22ac2309e77b8bafade087,Use requests in TestWSGIServerWithSSL instead of raw socket client,MERGED,2016-02-11 12:18:27.000000000,2016-02-15 00:42:45.000000000,2016-02-15 00:42:45.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-11 12:18:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/5dfb74a3fa5c149489894f125ea36e79774713e3', 'message': 'Fix TestWSGIServerWithSSL tests to correctly read from GreenSSLSocket\n\nIt seems that since some of the latest eventlet releases (0.18.0\nmost likely) sock.read() returns a single line, not the whole\nresponse as the tests expected.\n\nChange-Id: Iff4ea2b00e50f6928a22ac2309e77b8bafade087\n'}, {'number': 2, 'created': '2016-02-11 13:38:42.000000000', 'files': ['oslo_service/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/d94735ba25f0597bfc6969378d64dabe3ba8537b', 'message': ""Use requests in TestWSGIServerWithSSL instead of raw socket client\n\nIt seems that since some of the latest eventlet releases (0.18.2\nmost likely) sock.read() returns a single line, not the whole\nresponse as the tests expected.\n\nThere's no discernable reason why we need to use a raw\neventlet-based client TestWSGIServerWithSSL to confirm that a\nwsgi server is listening correctly and returning the expected\nresponse, especially since using eventlet leads to unreliable\ni/o on the socket unless there is an explicit yield before\nasserting the value of the response.\n\nSo requests is used to query the servers and verify the response.\n\nBased on the nova review: https://review.openstack.org/#/c/278089\n\nChange-Id: Iff4ea2b00e50f6928a22ac2309e77b8bafade087\n""}]",0,279011,d94735ba25f0597bfc6969378d64dabe3ba8537b,9,3,2,7293,,,0,"Use requests in TestWSGIServerWithSSL instead of raw socket client

It seems that since some of the latest eventlet releases (0.18.2
most likely) sock.read() returns a single line, not the whole
response as the tests expected.

There's no discernable reason why we need to use a raw
eventlet-based client TestWSGIServerWithSSL to confirm that a
wsgi server is listening correctly and returning the expected
response, especially since using eventlet leads to unreliable
i/o on the socket unless there is an explicit yield before
asserting the value of the response.

So requests is used to query the servers and verify the response.

Based on the nova review: https://review.openstack.org/#/c/278089

Change-Id: Iff4ea2b00e50f6928a22ac2309e77b8bafade087
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/11/279011/2 && git format-patch -1 --stdout FETCH_HEAD,['oslo_service/tests/test_wsgi.py'],1,5dfb74a3fa5c149489894f125ea36e79774713e3,," @staticmethod def _read_response_greenssl_sock(sock): response = [] while True: line = sock.read(8192) if not line: break response.append(line) return response response = self._read_response_greenssl_sock(cli) self.assertEqual(""PONG"", response[-1]) response = self._read_response_greenssl_sock(cli) self.assertEqual(""PONG"", response[-1]) self.assertEqual(""PONG"", response[-4:])"," response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") self.assertEqual(response[-4:], ""PONG"")",17,5
openstack%2Foslo.config~master~Ie6616e76bf0c23a6303cdb1e441754ccba37a9c3,openstack/oslo.config,master,Ie6616e76bf0c23a6303cdb1e441754ccba37a9c3,refactor generator._list_opts for further enhancement,MERGED,2016-02-10 20:21:46.000000000,2016-02-15 00:39:53.000000000,2016-02-15 00:39:53.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2016-02-10 20:21:46.000000000', 'files': ['oslo_config/tests/test_generator.py', 'oslo_config/generator.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/1a64804a9a2513e89d4ccd2e2524f54838651d96', 'message': 'refactor generator._list_opts for further enhancement\n\nThe _list_opts() function combines the behavior for loading the options\nand the behavior for cleaning and filtering them. This patch breaks it\nup a bit and updates the relevant tests, to prepare for the next patch\nwhich will add some new behavior to _list_opts().\n\nChange-Id: Ie6616e76bf0c23a6303cdb1e441754ccba37a9c3\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,278603,1a64804a9a2513e89d4ccd2e2524f54838651d96,8,2,1,2472,,,0,"refactor generator._list_opts for further enhancement

The _list_opts() function combines the behavior for loading the options
and the behavior for cleaning and filtering them. This patch breaks it
up a bit and updates the relevant tests, to prepare for the next patch
which will add some new behavior to _list_opts().

Change-Id: Ie6616e76bf0c23a6303cdb1e441754ccba37a9c3
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/03/278603/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_config/tests/test_generator.py', 'oslo_config/generator.py']",2,1a64804a9a2513e89d4ccd2e2524f54838651d96,generator-override-defaults,"def _get_raw_opts_loaders(namespaces): invoke_on_load=False) return [(e.name, e.plugin) for e in mgr] def _list_opts(namespaces): """"""List the options available via the given namespaces. Duplicate options from a namespace are removed. :param namespaces: a list of namespaces registered under 'oslo.config.opts' :returns: a list of (namespace, [(group, [opt_1, opt_2])]) tuples """""" opts = [ (namespace, loader()) for namespace, loader in _get_raw_opts_loaders(namespaces) ]","def _list_opts(namespaces): invoke_on_load=True) opts = [(ep.name, ep.obj) for ep in mgr] ",40,31
openstack%2Fmurano-dashboard~master~Ic0a0d1006497fd3f4ab57029ab7794e2081bcf4a,openstack/murano-dashboard,master,Ic0a0d1006497fd3f4ab57029ab7794e2081bcf4a,WIP,ABANDONED,2016-02-15 00:04:04.000000000,2016-02-15 00:37:41.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2016-02-15 00:04:04.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/423bed5bd943e57a48ef9e09a3fbf0283b6d5dd7', 'message': 'WIP\n\nChange-Id: Ic0a0d1006497fd3f4ab57029ab7794e2081bcf4a\n'}]",0,280032,423bed5bd943e57a48ef9e09a3fbf0283b6d5dd7,5,2,1,13962,,,0,"WIP

Change-Id: Ic0a0d1006497fd3f4ab57029ab7794e2081bcf4a
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/32/280032/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,423bed5bd943e57a48ef9e09a3fbf0283b6d5dd7,,,,0,0
openstack%2Fmurano~master~I96c93615620435bcbc8d841ab3b34ab1d99389e9,openstack/murano,master,I96c93615620435bcbc8d841ab3b34ab1d99389e9,Add the max length check for environment update,MERGED,2016-01-20 17:28:39.000000000,2016-02-15 00:33:49.000000000,2016-02-15 00:33:49.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7821}, {'_account_id': 12597}, {'_account_id': 13111}, {'_account_id': 13149}, {'_account_id': 13323}, {'_account_id': 13962}, {'_account_id': 14107}, {'_account_id': 15168}, {'_account_id': 18675}]","[{'number': 1, 'created': '2016-01-20 17:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7113260d4cc47ea8afcf14f92f1db0a0e9639456', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 2, 'created': '2016-01-21 02:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b2215ef6da7a665a5cb5e9388644fe2da3c74cf1', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 3, 'created': '2016-02-04 08:06:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/5081ca6e02db738b9226d6101fc56f6b52146f10', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 4, 'created': '2016-02-04 08:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/68a5175903e361b7f6098b3bfd16621aefc574af', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 5, 'created': '2016-02-04 08:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b6578b6cde42da323d4bb3268344f206888348ef', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 6, 'created': '2016-02-13 23:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/a48151c8941df5fea1c7b92c11acb0f633249f5a', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}, {'number': 7, 'created': '2016-02-14 02:43:23.000000000', 'files': ['murano/api/v1/environments.py', 'murano/tests/unit/api/v1/test_environments.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/4992c26fe0fd67307c1f6330f0ece30f88429f51', 'message': ""Add the max length check for environment update\n\nenvironment update don't check the name max length,\nSo will cause the db insert error.\n\nChange-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9\nCloses-Bug: #1536287\n""}]",14,270327,4992c26fe0fd67307c1f6330f0ece30f88429f51,47,12,7,14107,,,0,"Add the max length check for environment update

environment update don't check the name max length,
So will cause the db insert error.

Change-Id: I96c93615620435bcbc8d841ab3b34ab1d99389e9
Closes-Bug: #1536287
",git fetch https://review.opendev.org/openstack/murano refs/changes/27/270327/6 && git format-patch -1 --stdout FETCH_HEAD,['murano/api/v1/environments.py'],1,7113260d4cc47ea8afcf14f92f1db0a0e9639456,bug/1536287, if len(str(body['name']).strip()) > 255: msg = _('Environment name should be 255 characters maximum') LOG.exception(msg) raise exc.HTTPBadRequest(explanation=msg),,4,0
openstack%2Fdevstack~master~I78257c0ef314e97e4abddf82b709fc496401cf14,openstack/devstack,master,I78257c0ef314e97e4abddf82b709fc496401cf14,Documentation: nova-volume (n-vol) is long gone.,MERGED,2016-02-12 14:24:28.000000000,2016-02-14 23:57:27.000000000,2016-02-14 23:57:26.000000000,"[{'_account_id': 3}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-12 14:24:28.000000000', 'files': ['doc/source/faq.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/326e480d2972191c89b9bae88c987ef12f648f93', 'message': 'Documentation: nova-volume (n-vol) is long gone.\n\nLong live cinder-volume (c-vol) !\n\nChange-Id: I78257c0ef314e97e4abddf82b709fc496401cf14\n'}]",0,279562,326e480d2972191c89b9bae88c987ef12f648f93,8,2,1,7350,,,0,"Documentation: nova-volume (n-vol) is long gone.

Long live cinder-volume (c-vol) !

Change-Id: I78257c0ef314e97e4abddf82b709fc496401cf14
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/279562/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/faq.rst'],1,326e480d2972191c89b9bae88c987ef12f648f93,,``local.conf`` (using ``c-vol`` in this example): disable_service c-vol,``local.conf`` (using ``n-vol`` in this example): disable_service n-vol,2,2
openstack%2Fnetworking-midonet~master~I8939e44aa11000b011ffbc359c6bbc79f923f561,openstack/networking-midonet,master,I8939e44aa11000b011ffbc359c6bbc79f923f561,devstackgaterc: Disable a few tests and explain why,MERGED,2016-02-08 09:58:54.000000000,2016-02-14 23:17:05.000000000,2016-02-14 23:17:05.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}, {'_account_id': 6854}]","[{'number': 1, 'created': '2016-02-08 09:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/b7962e63ab5646c51524850b0ff303b267034ea3', 'message': 'devstackgaterc: Disable a few tests\n\nChange-Id: I8939e44aa11000b011ffbc359c6bbc79f923f561\nRelated-Bug: #1535185\n'}, {'number': 2, 'created': '2016-02-12 01:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/26e349bbf234b926ebeb77ddfce863c799697e96', 'message': 'devstackgaterc: Disable a few tests\n\nChange-Id: I8939e44aa11000b011ffbc359c6bbc79f923f561\nRelated-Bug: #1535185\n'}, {'number': 3, 'created': '2016-02-14 11:11:05.000000000', 'files': ['devstack/devstackgaterc'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/bafd7d0d20d13053f5baa20217fc3da59da80712', 'message': 'devstackgaterc: Disable a few tests and explain why\n\nChange-Id: I8939e44aa11000b011ffbc359c6bbc79f923f561\nRelated-Bug: #1535185\n'}]",2,277327,bafd7d0d20d13053f5baa20217fc3da59da80712,14,4,3,6854,,,0,"devstackgaterc: Disable a few tests and explain why

Change-Id: I8939e44aa11000b011ffbc359c6bbc79f923f561
Related-Bug: #1535185
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/27/277327/3 && git format-patch -1 --stdout FETCH_HEAD,['devstack/devstackgaterc'],1,b7962e63ab5646c51524850b0ff303b267034ea3,bug/1535185,"# Skip non-networking api tests r=""$r|(?:tempest\.api\.compute\..*)"" r=""$r|(?:tempest\.api\.identity\..*)"" r=""$r|(?:tempest\.api\.image\..*)"" ",,5,0
openstack%2Fmurano~master~Ie51440ef7dab044f2ac3ab1f06cbf93402cf1103,openstack/murano,master,Ie51440ef7dab044f2ac3ab1f06cbf93402cf1103,Update glare definitions path,MERGED,2016-02-12 14:34:27.000000000,2016-02-14 23:06:46.000000000,2016-02-14 23:06:46.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7821}, {'_account_id': 13962}]","[{'number': 1, 'created': '2016-02-12 14:34:27.000000000', 'files': ['contrib/glance/muranoartifact/v1/package.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/93931f487cce1b923fc648db32c111d21a60ad4e', 'message': 'Update glare definitions path\n\nGlare has been moved to a separate service and has been\nrenamed/refactored into glare namespace. This commit updates murano\nplugin accordingly.\n\nRelated bp: move-v3-to-glare\n\nChange-Id: Ie51440ef7dab044f2ac3ab1f06cbf93402cf1103\n'}]",0,279565,93931f487cce1b923fc648db32c111d21a60ad4e,12,4,1,15168,,,0,"Update glare definitions path

Glare has been moved to a separate service and has been
renamed/refactored into glare namespace. This commit updates murano
plugin accordingly.

Related bp: move-v3-to-glare

Change-Id: Ie51440ef7dab044f2ac3ab1f06cbf93402cf1103
",git fetch https://review.opendev.org/openstack/murano refs/changes/65/279565/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/glance/muranoartifact/v1/package.py'],1,93931f487cce1b923fc648db32c111d21a60ad4e,bp/move-v3-to-glare,from glance.common.glare import definitions,from glance.common.artifacts import definitions,1,1
openstack%2Fpython-muranoclient~master~I7f435aedf40fa16af8417c21d778efc0c70979d6,openstack/python-muranoclient,master,I7f435aedf40fa16af8417c21d778efc0c70979d6,Fix checks for Project/Tenant command line arguments,MERGED,2016-02-13 07:15:50.000000000,2016-02-14 23:02:23.000000000,2016-02-14 23:02:23.000000000,"[{'_account_id': 3}, {'_account_id': 7226}, {'_account_id': 7821}, {'_account_id': 12597}, {'_account_id': 13962}, {'_account_id': 14107}]","[{'number': 1, 'created': '2016-02-13 07:15:50.000000000', 'files': ['muranoclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/ffa0fe44315e8ad7fd978342dd4e8cd6871c01a3', 'message': 'Fix checks for Project/Tenant command line arguments\n\nOS_PROJECT_ID/OS_TENANT_ID and OS_PROJECT_NAME/OS_TENANT_NAME are\nsupposed to be used interchangeably. Current implementation doesn\'t\nhandle this properly. It requires ""tenant"" parameters to be present\neven if ""project"" arguments are provided. The check is done twice\nwhich is redundant, inconsistent and catches some paths which don\'t\nrequire those arguments at all.\n\nThe redundant check has been removed and better of two available\nchecks has been moved to proper place in the code.\n\nChange-Id: I7f435aedf40fa16af8417c21d778efc0c70979d6\nCloses-Bug: #1545182\n'}]",0,279868,ffa0fe44315e8ad7fd978342dd4e8cd6871c01a3,11,6,1,20312,,,0,"Fix checks for Project/Tenant command line arguments

OS_PROJECT_ID/OS_TENANT_ID and OS_PROJECT_NAME/OS_TENANT_NAME are
supposed to be used interchangeably. Current implementation doesn't
handle this properly. It requires ""tenant"" parameters to be present
even if ""project"" arguments are provided. The check is done twice
which is redundant, inconsistent and catches some paths which don't
require those arguments at all.

The redundant check has been removed and better of two available
checks has been moved to proper place in the code.

Change-Id: I7f435aedf40fa16af8417c21d778efc0c70979d6
Closes-Bug: #1545182
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/68/279868/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/shell.py'],1,ffa0fe44315e8ad7fd978342dd4e8cd6871c01a3,bug/1545182," if not any([args.os_tenant_name, args.os_tenant_id, args.os_project_id, args.os_project_name]): raise exc.CommandError(""You must provide a project name or"" "" project id via --os-project-name,"" "" --os-project-id, env[OS_PROJECT_ID]"" "" or env[OS_PROJECT_NAME]. You may"" "" use os-project and os-tenant"" "" interchangeably."")"," if not any([args.os_tenant_name, args.os_tenant_id, args.os_project_id, args.os_project_name]): raise exc.CommandError(""You must provide a project name or"" "" project id via --os-project-name,"" "" --os-project-id, env[OS_PROJECT_ID]"" "" or env[OS_PROJECT_NAME]. You may"" "" use os-project and os-tenant"" "" interchangeably."") if not (args.os_tenant_id or args.os_tenant_name): raise exc.CommandError( ""You must provide a tenant name "" ""or tenant id via --os-tenant-name, "" ""--os-tenant-id, env[OS_TENANT_NAME] "" ""or env[OS_TENANT_ID] OR a project name "" ""or project id via --os-project-name, "" ""--os-project-id, env[OS_PROJECT_ID] or "" ""env[OS_PROJECT_NAME]"") ",8,19
openstack%2Fzaqar~master~I99b830c4db4f2b9449cad713f37474f5ecbce05e,openstack/zaqar,master,I99b830c4db4f2b9449cad713f37474f5ecbce05e,Fix improperly LOG using in Zaqar,MERGED,2016-02-09 12:49:23.000000000,2016-02-14 22:39:47.000000000,2016-02-14 22:39:47.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 8846}, {'_account_id': 12321}, {'_account_id': 13995}]","[{'number': 1, 'created': '2016-02-09 12:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cdde55b6b94ae2ab073f0175c3f5aa7362038693', 'message': 'Fix improperly LOG using in Zaqar\n\nIn zaqar, there are some improperly log using in code tree. Like in some\nplace, should use LOG.exception not LOG.error, repeat log calling, etc.\n\nThose could be optimized for better code.\n\nChange-Id: I99b830c4db4f2b9449cad713f37474f5ecbce05e\nCloses-Bug: #1543563\n'}, {'number': 2, 'created': '2016-02-10 01:20:05.000000000', 'files': ['zaqar/bootstrap.py', 'zaqar/storage/redis/utils.py', 'zaqar/storage/utils.py', 'zaqar/notification/notifier.py', 'zaqar/storage/mongodb/utils.py', 'zaqar/notification/task/webhook.py', 'zaqar/notification/task/mailto.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/1685f5853aa9b6a3959df9773acc952db814a15c', 'message': 'Fix improperly LOG using in Zaqar\n\nIn zaqar, there are some improperly log using in code tree. Like in some\nplace, should use LOG.exception not LOG.error, repeat log calling, etc.\n\nThose could be optimized for better code.\n\nChange-Id: I99b830c4db4f2b9449cad713f37474f5ecbce05e\nCloses-Bug: #1543563\n'}]",6,277812,1685f5853aa9b6a3959df9773acc952db814a15c,17,5,2,8846,,,0,"Fix improperly LOG using in Zaqar

In zaqar, there are some improperly log using in code tree. Like in some
place, should use LOG.exception not LOG.error, repeat log calling, etc.

Those could be optimized for better code.

Change-Id: I99b830c4db4f2b9449cad713f37474f5ecbce05e
Closes-Bug: #1543563
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/12/277812/2 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/bootstrap.py', 'zaqar/storage/redis/utils.py', 'zaqar/storage/utils.py', 'zaqar/notification/notifier.py', 'zaqar/storage/mongodb/utils.py', 'zaqar/notification/task/webhook.py', 'zaqar/notification/task/mailto.py']",7,cdde55b6b94ae2ab073f0175c3f5aa7362038693,bug/1543563," LOG.exception(_LE('Failed to create process for sendmail, ' 'because %s.') % str(err)) except Exception as exc: LOG.exception(_LE('Failed to send email because %s.') % str(exc))"," LOG.error(_LE('Failed to create process for sendmail, ' 'because %s') % str(err)) except Exception as exc: LOG.exception(_LE('Failed to send email')) LOG.exception(exc)",25,20
openstack%2Fstorlets~master~I9fb7eb27d9a126cb2347ce7aea38141f6096e068,openstack/storlets,master,I9fb7eb27d9a126cb2347ce7aea38141f6096e068,Make sure Storlet Docker images don't include apt cache,MERGED,2016-02-05 09:22:55.000000000,2016-02-14 22:27:06.000000000,2016-02-14 22:27:06.000000000,"[{'_account_id': 3}, {'_account_id': 11317}]","[{'number': 1, 'created': '2016-02-05 09:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/e9687b63dc099ba3cae7c81680553f1881665a34', 'message': 'Remove apt cache file from Storlet Docker images\n\nThis patch makes Storlet Docker images not to include apt cache in it,\nand help us to reduce image size.\n\nChange-Id: I9fb7eb27d9a126cb2347ce7aea38141f6096e068\n'}, {'number': 2, 'created': '2016-02-05 09:26:16.000000000', 'files': ['Deploy/playbook/roles/docker_base_jre_image/templates/ubuntu_14.04_jre8_Dockerfile'], 'web_link': 'https://opendev.org/openstack/storlets/commit/eefccb6dbf292761cf131df54692b120af0362a5', 'message': ""Make sure Storlet Docker images don't include apt cache\n\nThis patch makes Storlet Docker images not to include apt cache.\nIt reduces the size of docker images, and make it easy to deploy them.\n\nChange-Id: I9fb7eb27d9a126cb2347ce7aea38141f6096e068\n""}]",0,276636,eefccb6dbf292761cf131df54692b120af0362a5,7,2,2,9816,,,0,"Make sure Storlet Docker images don't include apt cache

This patch makes Storlet Docker images not to include apt cache.
It reduces the size of docker images, and make it easy to deploy them.

Change-Id: I9fb7eb27d9a126cb2347ce7aea38141f6096e068
",git fetch https://review.opendev.org/openstack/storlets refs/changes/36/276636/2 && git format-patch -1 --stdout FETCH_HEAD,['Deploy/playbook/roles/docker_base_jre_image/templates/ubuntu_14.04_jre8_Dockerfile'],1,e9687b63dc099ba3cae7c81680553f1881665a34,dockerfile,"# The following operations shoud be defined in one line # to prevent apt cache file is included in docker image. RUN apt-get update && \ apt-get install python -y && \ apt-get install software-properties-common -y && \ add-apt-repository ppa:webupd8team/java && \ apt-get update && \ echo ""oracle-java8-installer shared/accepted-oracle-license-v1-1 select true"" | sudo debconf-set-selections && \ apt-get install oracle-java8-installer -y && \ apt-get clean","RUN [""apt-get"", ""update""] RUN [""apt-get"", ""install"", ""python"", ""-y""] RUN [""apt-get"", ""install"", ""software-properties-common"", ""-y""] RUN [""add-apt-repository"", ""ppa:webupd8team/java""] RUN [""apt-get"", ""update""] RUN echo ""oracle-java8-installer shared/accepted-oracle-license-v1-1 select true"" | sudo debconf-set-selections RUN [""apt-get"", ""install"", ""oracle-java8-installer"", ""-y""]",10,7
openstack%2Fopenstack-manuals~master~Iff3386ec6691d365af10eba74c2ae1d0d1b02524,openstack/openstack-manuals,master,Iff3386ec6691d365af10eba74c2ae1d0d1b02524,Fix repo sync,MERGED,2016-02-14 18:47:32.000000000,2016-02-14 22:22:26.000000000,2016-02-14 22:22:26.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-14 18:47:32.000000000', 'files': ['tools/sync-projects.sh'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e81351c181faecb3a7af83901672c65dcbcadaa6', 'message': ""Fix repo sync\n\nUse correct path for files, it's now common instead of common-rst.\n\nChange-Id: Iff3386ec6691d365af10eba74c2ae1d0d1b02524\n""}]",0,280015,e81351c181faecb3a7af83901672c65dcbcadaa6,6,2,1,6547,,,0,"Fix repo sync

Use correct path for files, it's now common instead of common-rst.

Change-Id: Iff3386ec6691d365af10eba74c2ae1d0d1b02524
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/15/280015/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/sync-projects.sh'],1,e81351c181faecb3a7af83901672c65dcbcadaa6,, copy_rst common copy_rst_trans common copy_rst doc/common copy_rst common copy_rst_trans common, copy_rst common-rst copy_rst_trans common-rst copy_rst doc/common-rst copy_rst common-rst copy_rst_trans common-rst,5,5
openstack%2Fgnocchi~stable%2F1.3~I7b37ccdf2988135504add1801c23e28e9123ccd0,openstack/gnocchi,stable/1.3,I7b37ccdf2988135504add1801c23e28e9123ccd0,statsd have some required configuration options,MERGED,2016-02-12 14:15:07.000000000,2016-02-14 22:22:14.000000000,2016-02-14 22:22:14.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}]","[{'number': 1, 'created': '2016-02-12 14:15:07.000000000', 'files': ['gnocchi/opts.py', 'gnocchi/statsd.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/427dc28f2c6f12c409270411d3168e3403f75953', 'message': 'statsd have some required configuration options\n\nCloses-bug: #1481439\nChange-Id: I7b37ccdf2988135504add1801c23e28e9123ccd0\n(cherry-picked from b877365de696bc3184b0da7571b7bb264e636654)\n'}]",0,279553,427dc28f2c6f12c409270411d3168e3403f75953,9,3,1,1669,,,0,"statsd have some required configuration options

Closes-bug: #1481439
Change-Id: I7b37ccdf2988135504add1801c23e28e9123ccd0
(cherry-picked from b877365de696bc3184b0da7571b7bb264e636654)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/53/279553/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/opts.py', 'gnocchi/statsd.py']",2,427dc28f2c6f12c409270411d3168e3403f75953,bug/1481439,"from oslo_config import cfg for field in [""resource_id"", ""user_id"", ""project_id""]: if conf.statsd[field] is None: raise cfg.RequiredOptError(field, cfg.OptGroup(""statsd"")) ",,13,5
openstack%2Fstorlets~master~I1de30b631c9ad6321ee837bbf9e6ae96eb78d181,openstack/storlets,master,I1de30b631c9ad6321ee837bbf9e6ae96eb78d181,Refactor Storlet Handler middleware,MERGED,2016-02-03 10:54:56.000000000,2016-02-14 22:20:30.000000000,2016-02-14 22:20:30.000000000,"[{'_account_id': 3}, {'_account_id': 4608}, {'_account_id': 9816}, {'_account_id': 11317}]","[{'number': 1, 'created': '2016-02-03 10:54:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/51a21cffbc79773ab46fb03d3818edce8f9e6f38', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 2, 'created': '2016-02-04 01:27:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/7f7d836db097949cd165aa9933b25f615e564b19', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 3, 'created': '2016-02-04 01:48:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/453039537cc9d60e4650e79628c31ab928097eec', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 4, 'created': '2016-02-04 02:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b63ee60024cffc6ce597255f7461407826aefaa8', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 5, 'created': '2016-02-04 02:56:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/77baec2c8515218a8f53b28a24a84a103a10825b', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 6, 'created': '2016-02-04 04:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/d11e6d9a8ab0572b49d0de3005c185679396b7e7', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 7, 'created': '2016-02-04 05:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/be72f52be84be80c3ef9fe676666f591a46d30a2', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 8, 'created': '2016-02-04 06:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/ab9c07292da2102b6f4dd1a13867fba4e70ad0fd', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 9, 'created': '2016-02-04 08:02:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/a0d6262c190956deb1e5f165da95e2a68792a8a7', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 10, 'created': '2016-02-04 08:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/96d694c2b207690911b7f88a5e2b4784162c2bef', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 11, 'created': '2016-02-04 08:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/7e7fcd36fd5785cff58e75ad00223c523d3cc7da', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 12, 'created': '2016-02-04 08:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/019c94b1014db37832af269c52c7005d8cf0e1cf', 'message': ""WIP: Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nWIP reason -> some functional failures found\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 13, 'created': '2016-02-04 09:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/350d057d6187ced4a1e9b23e7eeef842bea19ee4', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 14, 'created': '2016-02-04 12:33:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/65a704bea00a42429d8c771714111ca3e46f9fa8', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 15, 'created': '2016-02-05 02:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/6564860e314a196595dd5a865ae7ddc77ff4a892', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 16, 'created': '2016-02-08 01:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/a4d2e6fb96897e6f3ce74c6cbbcb40bef2f33f8d', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 17, 'created': '2016-02-08 01:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/be9f06a8cda5f4300bb8d12fd5e2f1afa151f5f2', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 18, 'created': '2016-02-08 01:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/b223a40d9d8dda4d4f2a102c50fc5d5738f3dad9', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 19, 'created': '2016-02-08 02:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/storlets/commit/1143257c62a871f6743e49c78c219d4937b25a01', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}, {'number': 20, 'created': '2016-02-08 02:32:45.000000000', 'files': ['tests/unit/swift/storlet_middleware/test_storlet_handler.py', 'Engine/swift/storlet_gateway/storlet_docker_gateway.py', 'Engine/swift/storlet_middleware/storlet_handler.py'], 'web_link': 'https://opendev.org/openstack/storlets/commit/448551a7485de41777bd0029b8e7bc7e5c8cfdeb', 'message': ""Refactor Storlet Handler middleware\n\nFor now, StorletHandlerMiddleware has too many if branches\nfor handling the request. (e.g. where to execute storlet, when\nto execute, so on) However it decrease the maintenacibility\nbecause it's not obvious where the statement belongs.\n\nIn this patch, split the handling sequence into mainly 2 Handler\nclasses called StorletProxyHandler and StorletObjectHandler which\ninherit BaseStorletHandler.\n\nBaseStorletHandler consists of common component for both chiled classes.\n(e.g. is_storlet_exection) And then chiled classes cover for their own\nrequet handling.\n\nNote that you may be able to find some odd code around header handling\nbut basically this code keep *original* handling not to modify current\nbehavior so if you find unnecessary code with this, please contribute\nto improve the code in future work :-)\n\nCo-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>\n\nChange-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181\n""}]",60,275619,448551a7485de41777bd0029b8e7bc7e5c8cfdeb,57,4,20,4608,,,0,"Refactor Storlet Handler middleware

For now, StorletHandlerMiddleware has too many if branches
for handling the request. (e.g. where to execute storlet, when
to execute, so on) However it decrease the maintenacibility
because it's not obvious where the statement belongs.

In this patch, split the handling sequence into mainly 2 Handler
classes called StorletProxyHandler and StorletObjectHandler which
inherit BaseStorletHandler.

BaseStorletHandler consists of common component for both chiled classes.
(e.g. is_storlet_exection) And then chiled classes cover for their own
requet handling.

Note that you may be able to find some odd code around header handling
but basically this code keep *original* handling not to modify current
behavior so if you find unnecessary code with this, please contribute
to improve the code in future work :-)

Co-Authored-By: Takashi Kajinami <kajinamit@nttdata.co.jp>

Change-Id: I1de30b631c9ad6321ee837bbf9e6ae96eb78d181
",git fetch https://review.opendev.org/openstack/storlets refs/changes/19/275619/17 && git format-patch -1 --stdout FETCH_HEAD,['Engine/swift/storlet_middleware/storlet_handler.py'],1,51a21cffbc79773ab46fb03d3818edce8f9e6f38,handler-refactor," HTTPInternalServerError, Request, Response, wsgifyclass NotStorletRequest(Exception): pass class BaseStorletHandler(object): """""" This is a abstract handler for Proxy/Object Server middleware """""" def __init__(self, request, conf, app, logger): """""" :param request: swob.Request instance :param conf: gatway conf dict :raises NotStorletRequest: """""" self.request = request self.storlet_containers = [conf.get('storlet_container'), conf.get('storlet_dependency')] self.app = app self.logger = logger self.conf = conf if self.is_storlet_execution or self.is_storlet_object_request: ver, acc, cont, obj = self.get_vaco() gateway_class = conf['gateway_module'] self.gateway = gateway_class( conf, logger, app, ver, acc, cont, obj) self._update_storlet_parameters_from_headers() else: raise NotStorletRequest() def get_vaco(self): """""" Parse method of path from self.request which depends on chiled class (Proxy or Object) :return tuple: a string tuple of (version, account, container, object) """""" raise NotImplemented() def handle_request(self): """""" Run storlet """""" raise NotImplemented() @property def is_storlet_execution(self): return 'X-Run-Storlet' in self.request.headers @property def is_storlet_object_request(self): _, _, container, obj = self.get_vaco() return container in self.storlet_containers and obj @property def is_range_request(self): """""" Determines whether the request is a byte-range request """""" return 'Range' in self.request.headers def is_slo_response(self, resp): _, account, container, obj = self.get_vaco() self.logger.info( 'Verify if {0}/{1}/{2} is an SLO assembly object'.format( account, container, obj)) is_slo = 'X-Static-Large-Object' in resp.headers if is_slo: self.logger.info('{0}/{1}/{2} is indeed an SLO assembly ' 'object'.format(account, container, obj)) else: self.logger.info('{0}/{1}/{2} is NOT an SLO assembly object'. format(account, container, obj)) return is_slo def _update_storlet_parameters_from_headers(self): """""" Extract parameters for header (an alternative to parmeters through the query string) """""" parameters = {} for param in self.request.headers: if param.lower().startswith('x-storlet-parameter'): keyvalue = self.request.headers[param] keyvalue = urllib.unquote(keyvalue) [key, value] = keyvalue.split(':') parameters[key] = value self.request.params.update(parameters) def apply_storlet(self, resp): _, _, container, obj = self.get_vaco() (out_md, app_iter) = self.gateway.gatewayProxyGetFlow( self.request, container, obj, resp) # TODO(kota_): make sure why we need new request instance? old_env = self.request.environ.copy() orig_req = Request.blank(old_env['PATH_INFO'], old_env) resp_headers = resp.headers if 'Content-Length' in resp_headers: resp_headers.pop('Content-Length') if 'Transfer-Encoding' in resp.headers: resp_headers.pop('Transfer-Encoding') return Response(app_iter=app_iter, headers=resp_headers, request=orig_req, conditional_response=True) class StorletProxyHandler(BaseStorletHandler): def __init__(self, request, conf, app, logger): super(StorletProxyHandler, self).__init__( request, conf, app, logger) # In proxy server, stolet handler validate if storlet enabled # at the account, anyway account_meta = get_account_info(self.request.environ, self.app)['meta'] storlets_enabled = account_meta.get('storlet-enabled', 'False') if not config_true_value(storlets_enabled): self.logger.info('Account disabled for storlets') raise HTTPBadRequest('Account disabled for storlets', request=self.request) def get_vaco(self): return self.request.split_path(4, 4, rest_with_last=True) def is_proxy_runnable(self, resp): if resp.is_success: # SLO / proxy only case: # storlet to be invoked now at proxy side: runnable = any( [self.is_range_request, self.is_slo_response(resp), self.conf['storlet_execute_on_proxy_only']]) return runnable else: _, account, container, obj = self.get_vaco() self.logger.error( 'Failed to check if {0}/{1}/{2} is an SLO' 'assembly object. Got status {3}'.format( account, container, obj, resp.status)) return False def handle_request(self): if self.is_storlet_object_request: self.gateway.validateStorletUpload(self.request) return self.request.get_response(self.app) else: # This should be self.is_storlet_execution if hasattr(self, self.request.method): resp = getattr(self, self.request.method)() return resp def GET(self): self.gateway.authorizeStorletExecution(self.request) # The get request may be a SLO object GET request. # Simplest solution would be to invoke a HEAD # for every GET request to test if we are in SLO case. # In order to save the HEAD overhead we implemented # a slightly more involved flow: # At proxy side, we augment request with Storlet stuff # and let the request flow. # At object side, we invoke the plain (non Storlet) # request and test if we are in SLO case. # and invoke Storlet only if non SLO case. # Back at proxy side, we test if test received # full object to detect if we are in SLO case, # and invoke Storlet only if in SLO case. self.gateway.augmentStorletRequest(self.request) original_resp = self.request.get_response(self.app) if self.is_proxy_runnable(original_resp): return self.apply_storlet(original_resp) elif original_resp.is_success: # Non proxy GET case: Storlet was already invoked at # object side if 'Transfer-Encoding' in original_resp.headers: original_resp.headers.pop('Transfer-Encoding') old_env = self.request.environ.copy() orig_req = Request.blank(old_env['PATH_INFO'], old_env) resp_headers = original_resp.headers resp_headers['Content-Length'] = None return Response(app_iter=original_resp.app_iter, headers=resp_headers, request=orig_req, conditional_response=True) else: # failure case return original_resp def PUT(self): self.gateway.authorizeStorletExecution(self.request) self.gateway.augmentStorletRequest(self.request) _, _, container, obj = self.get_vaco() (out_md, app_iter) = \ self.gateway.gatewayProxyPutFlow(self.request, container, obj) self.request.environ['wsgi.input'] = app_iter if 'CONTENT_LENGTH' in self.request.environ: self.request.environ.pop('CONTENT_LENGTH') self.request.headers['Transfer-Encoding'] = 'chunked' return self.request.get_response(self.app) class StorletObjectHandler(BaseStorletHandler): def __init__(self, request, conf, app, logger): super(StorletObjectHandler, self).__init__( request, conf, app, logger) def get_vaco(self): _, _, acc, cont, obj = self.request.split_path( 5, 5, rest_with_last=True) # TODO(kota_): make sure why object server api version is 0? return ('0', acc, cont, obj) @property def is_slo_get_request(self): """""" Determines from a GET request and its associated response if the object is a SLO """""" return self.request.params.get('multipart-manifest') == 'get' def handle_request(self): if hasattr(self, self.request.method): return getattr(self, self.request.method)() else: # TODO(kota_): make sure this happen? raise Exception('Something wrong heppened') def GET(self): self.logger.info('GET. Run storlet') orig_resp = self.request.get_response(self.app) if not is_success(orig_resp.status_int): return orig_resp _, account, container, obj = self.get_vaco() # not sure manifest file should not be run with storlet not_runnable = any( [self.is_range_request, self.is_slo_get_request, self.conf['storlet_execute_on_proxy_only'], self.is_slo_response(orig_resp)]) if not_runnable: # For SLOs, and proxy only mode # Storlet are executed on the proxy # Therefore we return the object part without # Storlet invocation: self.logger.info('storlet_handler: invocation ' 'over %s/%s/%s %s' % (account, container, obj, 'to be executed on proxy')) return orig_resp else: # We apply here the Storlet: self.logger.info('storlet_handler: invocation ' 'over %s/%s/%s %s' % (account, container, obj, 'to be executed locally')) return self.apply_storlet(orig_resp) self.exec_server = storlet_conf.get('execution_server') if self.exec_server == 'proxy': self.handler_class = StorletProxyHandler elif self.exec_server == 'object': self.handler_class = StorletObjectHandler else: raise Exception( 'execution_server is supported only either proxy or object') request_handler = self.handler_class( req, self.gateway_conf, self.app, self.logger) _, account, container, obj = request_handler.get_vaco() self.logger.debug('storlet_handler call in %s: with %s/%s/%s' % (self.exec_server, account, container, obj)) except HTTPException: raise except (ValueError, NotStorletRequest): return request_handler.handle_request()"," HTTPInternalServerError, HTTPNotFound, Request, Response, wsgify self.execution_server = storlet_conf.get('execution_server') # storlet_handler deals only with objects if self.execution_server == 'proxy': version, account, container, obj = req.split_path( 4, 4, rest_with_last=True) else: device, partition, account, container, obj = \ req.split_path(5, 5, rest_with_last=True) version = '0' except ValueError: return req.get_response(self.app) self.logger.debug('storlet_handler call in %s: with %s/%s/%s' % (self.execution_server, account, container, obj)) storlet_execution = False if 'X-Run-Storlet' in req.headers: storlet_execution = True if storlet_execution or container in self.storlet_containers: gateway = self.gateway_module(self.gateway_conf, self.logger, self.app, version, account, container, obj) else: if storlet_execution: header_parameters = \ self._extract_parameters_from_headers(req) req.params.update(header_parameters) if self.execution_server == 'object' and storlet_execution: if req.method == 'GET': self.logger.info('GET. Run storlet') orig_resp = req.get_response(self.app) if not is_success(orig_resp.status_int): return orig_resp if self._is_range_request(req) is True or \ self._is_slo_get_request(req, orig_resp, account, container, obj) or \ self.proxy_only_storlet_execution is True: # For SLOs, and proxy only mode # Storlet are executed on the proxy # Therefore we return the object part without # Storlet invocation: self.logger.info('storlet_handler: invocation ' 'over %s/%s/%s %s' % (account, container, obj, 'to be executed on proxy')) return orig_resp else: # We apply here the Storlet: self.logger.info('storlet_handler: invocation ' 'over %s/%s/%s %s' % (account, container, obj, 'to be executed locally')) old_env = req.environ.copy() orig_req = Request.blank(old_env['PATH_INFO'], old_env) (out_md, app_iter) = \ gateway.gatewayObjectGetFlow(req, container, obj, orig_resp) if 'Content-Length' in orig_resp.headers: orig_resp.headers.pop('Content-Length') if 'Transfer-Encoding' in orig_resp.headers: orig_resp.headers.pop('Transfer-Encoding') return Response(app_iter=app_iter, headers=orig_resp.headers, request=orig_req, conditional_response=True) elif (self.execution_server == 'proxy'): if (storlet_execution or container in self.storlet_containers): account_meta = get_account_info(req.environ, self.app)['meta'] storlets_enabled = account_meta.get('storlet-enabled', 'False') if not config_true_value(storlets_enabled): self.logger.info('Account disabled for storlets') raise HTTPBadRequest('Account disabled for storlets', request=req) if req.method == 'GET' and storlet_execution: gateway.authorizeStorletExecution(req) # The get request may be a SLO object GET request. # Simplest solution would be to invoke a HEAD # for every GET request to test if we are in SLO case. # In order to save the HEAD overhead we implemented # a slightly more involved flow: # At proxy side, we augment request with Storlet stuff # and let the request flow. # At object side, we invoke the plain (non Storlet) # request and test if we are in SLO case. # and invoke Storlet only if non SLO case. # Back at proxy side, we test if test received # full object to detect if we are in SLO case, # and invoke Storlet only if in SLO case. gateway.augmentStorletRequest(req) original_resp = req.get_response(self.app) if self._is_range_request(req) is True or \ self._is_slo_get_request(req, original_resp, account, container, obj) or \ self.proxy_only_storlet_execution is True: # SLO / proxy only case: # storlet to be invoked now at proxy side: (out_md, app_iter) = \ gateway.gatewayProxyGetFlow(req, container, obj, original_resp) # adapted from non SLO GET flow if is_success(original_resp.status_int): old_env = req.environ.copy() orig_req = Request.blank(old_env['PATH_INFO'], old_env) resp_headers = original_resp.headers resp_headers['Content-Length'] = None return Response(app_iter=app_iter, headers=resp_headers, request=orig_req, conditional_response=True) return original_resp else: # Non proxy GET case: Storlet was already invoked at # object side if 'Transfer-Encoding' in original_resp.headers: original_resp.headers.pop('Transfer-Encoding') if is_success(original_resp.status_int): old_env = req.environ.copy() orig_req = Request.blank(old_env['PATH_INFO'], old_env) resp_headers = original_resp.headers resp_headers['Content-Length'] = None return Response(app_iter=original_resp.app_iter, headers=resp_headers, request=orig_req, conditional_response=True) return original_resp elif req.method == 'PUT': if (container in self.storlet_containers): gateway.validateStorletUpload(req) if storlet_execution: gateway.authorizeStorletExecution(req) gateway.augmentStorletRequest(req) (out_md, app_iter) = \ gateway.gatewayProxyPutFlow(req, container, obj) req.environ['wsgi.input'] = app_iter if 'CONTENT_LENGTH' in req.environ: req.environ.pop('CONTENT_LENGTH') req.headers['Transfer-Encoding'] = 'chunked' return req.get_response(self.app) def _extract_parameters_from_headers(self, req): """""" Extract parameters for header (an alternative to parmeters through the query string) :param req: the request :returns: a dictionary with the header parameters """""" parameters = {} for param in req.headers: if param.lower().startswith('x-storlet-parameter'): keyvalue = req.headers[param] keyvalue = urllib.unquote(keyvalue) [key, value] = keyvalue.split(':') parameters[key] = value return parameters def _is_range_request(self, req): """""" Determines whether the request is a byte-range request :param args: :param req: the request """""" if 'Range' in req.headers: return True return False def _is_slo_get_request(self, req, resp, account, container, obj): """""" Determines from a GET request and its associated response if the object is a SLO :param req: the request :param resp: the response :param account: the account as extracted from req :param container: the response as extracted from req :param obj: the response as extracted from req """""" if req.method != 'GET': return False if req.params.get('multipart-manifest') == 'get': return False self.logger.info('Verify if {0}/{1}/{2} is an SLO assembly object'. format(account, container, obj)) if resp.is_success: for key in resp.headers: if (key.lower() == 'x-static-large-object' and config_true_value(resp.headers[key])): self.logger.info('{0}/{1}/{2} is indeed an SLO assembly ' 'object'.format(account, container, obj)) return True self.logger.info('{0}/{1}/{2} is NOT an SLO assembly object'. format(account, container, obj)) return False self.logger.error('Failed to check if {0}/{1}/{2} is an SLO assembly ' 'object. Got status {3}'. format(account, container, obj, resp.status)) if resp.status_int == 404: raise HTTPNotFound('The target object is not found') raise Exception('Failed to check if {0}/{1}/{2} is an SLO assembly ' 'object. Got status {3}'.format(account, container, obj, resp.status)) ",286,225
openstack%2Ftelemetry-specs~master~I1c7264dae8801179e78cb8c5ce7665f61bac9191,openstack/telemetry-specs,master,I1c7264dae8801179e78cb8c5ce7665f61bac9191,Fix .gitreview after repo renaming,MERGED,2016-02-13 01:18:16.000000000,2016-02-14 22:00:32.000000000,2016-02-14 22:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6547}]","[{'number': 1, 'created': '2016-02-13 01:18:16.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/46396a9d1a45cc23796fcb3b728ef9c50d2ad029', 'message': 'Fix .gitreview after repo renaming\n\nChange-Id: I1c7264dae8801179e78cb8c5ce7665f61bac9191\n'}]",0,279831,46396a9d1a45cc23796fcb3b728ef9c50d2ad029,12,3,1,6786,,,0,"Fix .gitreview after repo renaming

Change-Id: I1c7264dae8801179e78cb8c5ce7665f61bac9191
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/31/279831/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,46396a9d1a45cc23796fcb3b728ef9c50d2ad029,gitreview-fix,project=openstack/telemetry-specs.git,project=openstack/ceilometer-specs.git,1,1
openstack%2Frally~master~I2621f4f75eac394951081270338bd63dc43b599e,openstack/rally,master,I2621f4f75eac394951081270338bd63dc43b599e,Add heat siege workload scenario,MERGED,2016-01-26 12:55:08.000000000,2016-02-14 21:59:24.000000000,2016-02-14 21:59:24.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 13919}, {'_account_id': 14168}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-01-26 12:55:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c5f6fd68145842bad59605c3d4ab26197103889d', 'message': 'Add heat iperf workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 2, 'created': '2016-01-26 13:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/96fa23f23748f8f1a5c69dd0bc9fa16873294235', 'message': 'Add heat iperf workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 3, 'created': '2016-01-26 14:03:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/00f736934f98f2f2d5f62e1393410a6c3824b5de', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 4, 'created': '2016-01-27 13:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/968c4f044463494cc278c76da9abe1eeb255b13d', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 5, 'created': '2016-01-27 13:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a82a1a1d03b524bc5e7834d34e75f1788d250add', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 6, 'created': '2016-01-27 14:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/934f16ff9b0a15a80b9c4afc71a34ae6039b26e6', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 7, 'created': '2016-01-27 16:44:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3aed4dad6128a13220fd85f2229b0b2be4c905f0', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 8, 'created': '2016-01-27 17:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4b74fb24118b561614084afd404106a2e4f7ba3f', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 9, 'created': '2016-01-27 18:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4f98428e452b67e035ada0392dfdc9e32c1a50f6', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 10, 'created': '2016-01-27 20:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/120ee3474dcf89772ab337c4b3ed8170f2dd9e52', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 11, 'created': '2016-01-27 20:44:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/21559169982bd86d93cb418760f104750d58303e', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 12, 'created': '2016-01-27 21:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e2f09835caa0d65596c6bc9f49172f8ce18bcd5c', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 13, 'created': '2016-01-28 09:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/abf0d7cc2c8bcf14d740a61b3c516532afd9ffcd', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 14, 'created': '2016-01-28 10:30:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e09deb486fd0b0f2be588a26038101b98982023a', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 15, 'created': '2016-01-28 10:31:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b7698b9953503b9c587e3b55c5eebe390af807e5', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 16, 'created': '2016-01-28 10:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/13dac940ce7e33834d466d298af848c806148931', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 17, 'created': '2016-01-28 11:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4e3e6eba5f69cd6251a9d6c040548b05f262ddc9', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 18, 'created': '2016-01-28 13:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/88ed547d68aebfd810b467f0bcf96f57c1e0f38f', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 19, 'created': '2016-01-28 14:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/95469a58354b92923d228cdca05f1c6a5a7ec155', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 20, 'created': '2016-01-28 17:05:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0c101089b79b57a469b40ad7913b733ab28969d1', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 21, 'created': '2016-01-29 11:53:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b753931e67038dd72158ea2f1ac5aa6bce85f43b', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 22, 'created': '2016-02-02 00:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/572faef70ee22be294fb43672dae89d548d0e902', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 23, 'created': '2016-02-03 00:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/97fe26f1b490cbf49a63500bbf8e0271099ea025', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 24, 'created': '2016-02-03 01:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b9ef7f67ff43a66365c4be66b5064211ea3fee86', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 25, 'created': '2016-02-05 19:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5c0a5f241cbdb7cb9cc89bbb0599e863402c90f5', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 26, 'created': '2016-02-05 19:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a7369fbfa503e0318722dded3607baa4c16eb00a', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 27, 'created': '2016-02-05 19:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d0ec5982e3f694f90ad16b8ceb660ef787104d48', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 28, 'created': '2016-02-06 12:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f70faf36960bb0d7b4102188c7b14a571a6a842e', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 29, 'created': '2016-02-06 21:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0757430711e17b8dd30f695708c6ccfa88f09aae', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 30, 'created': '2016-02-08 13:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7ab0aa63451a3f983f862e702065dbd7984ab51d', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}, {'number': 31, 'created': '2016-02-12 08:05:01.000000000', 'files': ['rally-jobs/extra/workload/wordpress_heat_template.yaml', 'rally/plugins/openstack/services/heat/main.py', 'rally-jobs/rally-mos.yaml', 'rally/plugins/workload/siege.py', 'tests/unit/plugins/openstack/services/heat/test_main.py', 'rally/plugins/workload/__init__.py', 'tests/unit/plugins/openstack/services/heat/__init__.py', 'rally/plugins/openstack/scenarios/vm/vmtasks.py', 'samples/tasks/scenarios/workload/wordpress.json', 'tests/unit/plugins/openstack/context/ceilometer/test_samples.py', 'rally/plugins/openstack/services/__init__.py', 'tests/unit/plugins/workload/__init__.py', 'rally/plugins/openstack/services/heat/__init__.py', 'tests/unit/plugins/openstack/services/__init__.py', 'rally-jobs/extra/workload/wp-instances.yaml', 'samples/tasks/scenarios/workload/wordpress.yaml', 'tests/unit/plugins/openstack/scenarios/vm/test_vmtasks.py', 'tests/unit/plugins/workload/test_siege.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/9de7fdce775626ace26c1a2e4b410dc94f97ba93', 'message': 'Add heat siege workload scenario\n\nChange-Id: I2621f4f75eac394951081270338bd63dc43b599e\n'}]",32,272510,9de7fdce775626ace26c1a2e4b410dc94f97ba93,112,9,31,7369,,,0,"Add heat siege workload scenario

Change-Id: I2621f4f75eac394951081270338bd63dc43b599e
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/272510/19 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/openstack/scenarios/vm/vmtasks.py', 'samples/tasks/scenarios/workload/wordpress_heat_template.yaml', 'rally/plugins/openstack/services/heat/main.py', 'rally-jobs/rally-mos.yaml', 'samples/tasks/scenarios/workload/wp-instances.yaml', 'rally/plugins/openstack/services/__init__.py', 'rally/plugins/workload/siege.py', 'rally/plugins/openstack/services/heat/__init__.py', 'samples/tasks/scenarios/workload/wordpress.yaml']",9,c5f6fd68145842bad59605c3d4ab26197103889d,heat4,"--- VMTasks.runcommand_heat: - args: workload: resource: [""rally.plugins.workload"", ""siege.py""] username: ""fedora"" template: samples/tasks/scenarios/workload/wordpress_heat_template.yaml files: wp-instances.yaml: samples/tasks/scenarios/workload/wp-instances.yaml parameters: wp_instances_count: 2 wp_instance_type: gig instance_type: gig wp_image: fedora image: fedora network_id: 9d477754-e9ba-4560-9b2b-9ce9d36638ce router_id: c497caa1-9d73-402b-bcd1-cc269e9af29e context: users: tenants: 1 users_per_tenant: 1 flavors: - name: gig ram: 1024 disk: 4 vcpus: 1 runner: concurrency: 1 timeout: 3000 times: 1 type: constant ",,558,1
openstack%2Fbifrost~master~I6279242de9bedf35d95c048fc2ce586435c3850b,openstack/bifrost,master,I6279242de9bedf35d95c048fc2ce586435c3850b,Add option to disabled default gateway on bifrost,MERGED,2016-02-08 20:38:49.000000000,2016-02-14 21:43:45.000000000,2016-02-14 21:43:44.000000000,"[{'_account_id': 3}, {'_account_id': 1106}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2016-02-08 20:38:49.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/1d14c610fe486d25f7d19500504fcba1723eee8b', 'message': 'Add option to disabled default gateway on bifrost\n\nThere are situations where we can have different nics\nliving together, and the default gateway needs to be set\nexternally, not in the nic managed by bifrost.\nThe way dnsmasq works, is that if you do not set any\nip for default gateway, it assumes that to be the dnsmasq management\nip, and creates a default gateway in all nics attached to it.\nThat prevents default gateway being set externally, causing errors\nof duplicated gateways.\nTo disable it, we need to pass a simple dhcp-option=3. So adding\nthis possibility to the template, just allowing a dnsmasq_router=false\nto be passed as option.\n\nChange-Id: I6279242de9bedf35d95c048fc2ce586435c3850b\n'}]",0,277555,1d14c610fe486d25f7d19500504fcba1723eee8b,18,5,1,6133,,,0,"Add option to disabled default gateway on bifrost

There are situations where we can have different nics
living together, and the default gateway needs to be set
externally, not in the nic managed by bifrost.
The way dnsmasq works, is that if you do not set any
ip for default gateway, it assumes that to be the dnsmasq management
ip, and creates a default gateway in all nics attached to it.
That prevents default gateway being set externally, causing errors
of duplicated gateways.
To disable it, we need to pass a simple dhcp-option=3. So adding
this possibility to the template, just allowing a dnsmasq_router=false
to be passed as option.

Change-Id: I6279242de9bedf35d95c048fc2ce586435c3850b
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/55/277555/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/templates/dnsmasq.conf.j2', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml']",2,1d14c610fe486d25f7d19500504fcba1723eee8b,,"# If set to false, it will disable default route creation in clients.",,5,0
openstack%2Fpython-zaqarclient~master~I55f149b90028f89bb7ff0878a7450df981524026,openstack/python-zaqarclient,master,I55f149b90028f89bb7ff0878a7450df981524026,Fix wrong api version type,MERGED,2016-01-15 03:18:45.000000000,2016-02-14 21:09:08.000000000,2016-02-14 21:09:08.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 8846}, {'_account_id': 12321}, {'_account_id': 15054}, {'_account_id': 18683}]","[{'number': 1, 'created': '2016-01-15 03:18:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/b39749a8d5aacef2885b2a8fad571f150c8dcb10', 'message': 'Fix wrong api version type\n\nThe api version from openstack client is a string, not a number.\nSo we need to convert it to float(since we have v1.1) before\ncomparing it with a version number.\n\nCloses-Bug: 1534378\n\nChange-Id: I55f149b90028f89bb7ff0878a7450df981524026\n'}, {'number': 2, 'created': '2016-01-19 22:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/ffe06c69c72f55f2c9d7ca524338b5a32ca6e1eb', 'message': 'Fix wrong api version type\n\nThe api version from openstack client is a string, not a number.\nSo we need to convert it to float(since we have v1.1) before\ncomparing it with a version number.\n\nCloses-Bug: 1534378\n\nChange-Id: I55f149b90028f89bb7ff0878a7450df981524026\n'}, {'number': 3, 'created': '2016-01-23 10:49:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/44ab0efa84ad9ee0bd3f198f110bdf8fc134467d', 'message': 'Fix wrong api version type\n\nThe api version from openstack client is a string, not a number.\nSo we need to convert it to the right type before comparing it\nwith a version number.\n\nCloses-Bug: 1534378\n\nChange-Id: I55f149b90028f89bb7ff0878a7450df981524026\n'}, {'number': 4, 'created': '2016-02-01 15:10:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/d7eba0daf69c1aac42cc2f1dc5b9efbfef1e2055', 'message': 'Fix wrong api version type\n\nThe api version from openstack client is a string, not a number.\nSo we need to convert it to the right type before comparing it\nwith a version number.\n\nCloses-Bug: 1534378\n\nChange-Id: I55f149b90028f89bb7ff0878a7450df981524026\n'}, {'number': 5, 'created': '2016-02-02 01:39:01.000000000', 'files': ['zaqarclient/queues/cli.py', 'zaqarclient/queues/v1/queues.py'], 'web_link': 'https://opendev.org/openstack/python-zaqarclient/commit/0e2f625dd724923904dbfbece0baa69e33dbcb22', 'message': 'Fix wrong api version type\n\nThe api version from openstack client is a string, not a number.\nSo we need to convert it to the right type before comparing it\nwith a version number.\n\nCloses-Bug: 1534378\n\nChange-Id: I55f149b90028f89bb7ff0878a7450df981524026\n'}]",3,267906,0e2f625dd724923904dbfbece0baa69e33dbcb22,31,8,5,6484,,,0,"Fix wrong api version type

The api version from openstack client is a string, not a number.
So we need to convert it to the right type before comparing it
with a version number.

Closes-Bug: 1534378

Change-Id: I55f149b90028f89bb7ff0878a7450df981524026
",git fetch https://review.opendev.org/openstack/python-zaqarclient refs/changes/06/267906/3 && git format-patch -1 --stdout FETCH_HEAD,"['zaqarclient/queues/v1/flavor.py', 'zaqarclient/queues/v2/queues.py', 'zaqarclient/queues/v1/queues.py', 'zaqarclient/queues/v1/pool.py']",4,b39749a8d5aacef2885b2a8fad571f150c8dcb10,bug/1534378, if float(self.client.api_version) >= 1.1 and self.group:, if self.client.api_version >= 1.1 and self.group:,6,6
openstack%2Ftaskflow~master~I056f334614e0f0a518b9110f861dd65acf9e7ea7,openstack/taskflow,master,I056f334614e0f0a518b9110f861dd65acf9e7ea7,Updated from global requirements,MERGED,2016-02-12 20:31:07.000000000,2016-02-14 20:37:12.000000000,2016-02-14 20:37:11.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2016-02-12 20:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/07173a308a29689256096c412f78fe9af12c7ce7', 'message': 'Updated from global requirements\n\nChange-Id: I056f334614e0f0a518b9110f861dd65acf9e7ea7\n'}, {'number': 2, 'created': '2016-02-14 01:15:39.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/7ea2bfc2974c4854e8d718383af961acb8daffeb', 'message': 'Updated from global requirements\n\nChange-Id: I056f334614e0f0a518b9110f861dd65acf9e7ea7\n'}]",0,279778,7ea2bfc2974c4854e8d718383af961acb8daffeb,11,2,2,11131,,,0,"Updated from global requirements

Change-Id: I056f334614e0f0a518b9110f861dd65acf9e7ea7
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/78/279778/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,07173a308a29689256096c412f78fe9af12c7ce7,openstack/requirements,kombu>=3.0.25 # BSD,kombu>=3.0.7 # BSD,1,1
openstack%2Fpython-heatclient~master~I851662206b71d9912eea197f6c82bbd3723bdeba,openstack/python-heatclient,master,I851662206b71d9912eea197f6c82bbd3723bdeba,OSC plugin for software config show,MERGED,2016-01-16 04:44:03.000000000,2016-02-14 20:29:31.000000000,2016-02-14 20:29:31.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 7128}, {'_account_id': 10487}, {'_account_id': 16203}, {'_account_id': 18389}]","[{'number': 1, 'created': '2016-01-16 04:44:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/670f659caa4d16ea3bdf57db7b03dbbdfb25bf59', 'message': 'OSC plugin for software config show\n\nThis change implements ""openstack software config show"" command\n\nBlueprint: heat-support-python-openstackclient\nChange-Id: I851662206b71d9912eea197f6c82bbd3723bdeba\n'}, {'number': 2, 'created': '2016-02-11 17:16:30.000000000', 'files': ['heatclient/osc/v1/software_config.py', 'heatclient/tests/unit/osc/v1/test_software_config.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0ea973243327d3c45b3e5bf3396ece7a7731248a', 'message': 'OSC plugin for software config show\n\nThis change implements ""openstack software config show"" command\n\nBlueprint: heat-support-python-openstackclient\nChange-Id: I851662206b71d9912eea197f6c82bbd3723bdeba\n'}]",4,268554,0ea973243327d3c45b3e5bf3396ece7a7731248a,19,6,2,16203,,,0,"OSC plugin for software config show

This change implements ""openstack software config show"" command

Blueprint: heat-support-python-openstackclient
Change-Id: I851662206b71d9912eea197f6c82bbd3723bdeba
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/54/268554/2 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/osc/v1/software_config.py', 'heatclient/tests/unit/osc/v1/test_software_config.py', 'setup.cfg']",3,670f659caa4d16ea3bdf57db7b03dbbdfb25bf59,bp/heat-support-python-openstackclient, software_config_show = heatclient.osc.v1.software_config:ShowConfig,,173,0
openstack%2Ftaskflow~master~I129a8ec24cb9e7b2169031e16d3c836cfb608c75,openstack/taskflow,master,I129a8ec24cb9e7b2169031e16d3c836cfb608c75,Use system random where possible,ABANDONED,2015-09-14 19:40:22.000000000,2016-02-14 20:27:20.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1941}, {'_account_id': 6601}, {'_account_id': 9107}, {'_account_id': 9648}]","[{'number': 1, 'created': '2015-09-14 19:40:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/408f3c04719c0587b9d5019536fac44d395479ea', 'message': 'Use system random if possible\n\nOne of the bandit checks is to attempt to use the system random\nlibrary (which is better at producing randomness) vs using the\ndefault random class, this change attempts to use system random\nand fallsback to using the default random module when system random\nis not available.\n\nSee: https://wiki.openstack.org/wiki/Security/Projects/Bandit\n\nChange-Id: I129a8ec24cb9e7b2169031e16d3c836cfb608c75\n'}, {'number': 2, 'created': '2015-09-14 23:58:35.000000000', 'files': ['taskflow/engines/worker_based/types.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/34ef0c12c2f5783e6797eb8a353c73bd83a0b7d8', 'message': 'Use system random where possible\n\nOne of the bandit checks is to attempt to use the system random\nlibrary (which is better at producing randomness) vs using the\ndefault random class, this change moves to using system random\nwhere applicable.\n\nSee: https://wiki.openstack.org/wiki/Security/Projects/Bandit\n\nChange-Id: I129a8ec24cb9e7b2169031e16d3c836cfb608c75\n'}]",2,223268,34ef0c12c2f5783e6797eb8a353c73bd83a0b7d8,11,6,2,1297,,,0,"Use system random where possible

One of the bandit checks is to attempt to use the system random
library (which is better at producing randomness) vs using the
default random class, this change moves to using system random
where applicable.

See: https://wiki.openstack.org/wiki/Security/Projects/Bandit

Change-Id: I129a8ec24cb9e7b2169031e16d3c836cfb608c75
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/68/223268/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/worker_based/types.py'],1,408f3c04719c0587b9d5019536fac44d395479ea,, try: _RNG = random.SystemRandom() except NotImplementedError: _RNG = random.Random() return self._RNG.choice(available_workers), return random.choice(available_workers),6,1
openstack%2Fkolla~master~I5331020993b62c8635a4a97dc3a3d2e01e3d4360,openstack/kolla,master,I5331020993b62c8635a4a97dc3a3d2e01e3d4360,Fix detect_distro,MERGED,2016-02-12 02:16:39.000000000,2016-02-14 20:23:26.000000000,2016-02-14 20:23:26.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 13039}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-02-12 02:16:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/27bd24b6c0037dbe4754754884cf5287336d9c3f', 'message': 'Fix detect_distro\n\nIt was run before ansible was installed and did not properly fail\n\nTrivialFix\n\nChange-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360\n'}, {'number': 2, 'created': '2016-02-12 02:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0253e32c9cf96c147e29e52d99c8502bd8138de8', 'message': 'Fix detect_distro\n\nIt was run before ansible was installed and did not properly fail.\nThis prevented the mirrors for apt from being properly used.\n\nTrivialFix\n\nChange-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360\n'}, {'number': 3, 'created': '2016-02-12 02:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fc2eaf7c4fad2a3881f0265a81485996a6545d62', 'message': 'Fix detect_distro\n\nIt was run before ansible was installed and did not properly fail.\nThis prevented the mirrors for apt from being properly used.\n\nTrivialFix\n\nChange-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360\n'}, {'number': 4, 'created': '2016-02-12 03:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7451296e8029c1a58f1899bf92d5b4e96b1623bc', 'message': 'Fix detect_distro\n\nIt was run before ansible was installed and did not properly fail.\nThis prevented the mirrors for apt from being properly used.\n\nTrivialFix\n\nChange-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360\n'}, {'number': 5, 'created': '2016-02-12 03:39:16.000000000', 'files': ['tools/setup_gate.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/44a4682da288508db3c995e98bf32fc658d109e0', 'message': 'Fix detect_distro\n\nIt was run before ansible was installed and did not properly fail.\nThis prevented the mirrors for apt from being properly used.\n\nTrivialFix\n\nChange-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360\n'}]",0,279363,44a4682da288508db3c995e98bf32fc658d109e0,13,4,5,14119,,,0,"Fix detect_distro

It was run before ansible was installed and did not properly fail.
This prevented the mirrors for apt from being properly used.

TrivialFix

Change-Id: I5331020993b62c8635a4a97dc3a3d2e01e3d4360
",git fetch https://review.opendev.org/openstack/kolla refs/changes/63/279363/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/setup_gate.sh'],1,27bd24b6c0037dbe4754754884cf5287336d9c3f,non-root, detect_distro,detect_distro,1,1
openstack%2Fkolla~master~Id0e7cf9e1c0c4259b8a50c39e95214103256517b,openstack/kolla,master,Id0e7cf9e1c0c4259b8a50c39e95214103256517b,Fix non-root deploys,MERGED,2016-02-05 19:42:25.000000000,2016-02-14 20:23:20.000000000,2016-02-14 20:23:20.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 13039}, {'_account_id': 14119}, {'_account_id': 17130}, {'_account_id': 18652}, {'_account_id': 19300}]","[{'number': 1, 'created': '2016-02-05 19:42:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/80af298c640ff966ee2a3a6947d8ab5fdd5494db', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 2, 'created': '2016-02-05 20:40:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d3af4339386b406b45caab6174f051ed797070d1', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 3, 'created': '2016-02-05 21:38:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2aa3c7cbb806a0c8c2126efe0ca1babdde6e9141', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 4, 'created': '2016-02-07 14:44:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ce6daa41b89cc358f3c86844185ce722392e4c6a', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 5, 'created': '2016-02-08 07:51:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0bc37ba6fe82fc7c3409c6c1b0b136062955a660', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 6, 'created': '2016-02-12 02:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/62558e8ec4a8ccfc243393cf470038f7d1c586c1', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 7, 'created': '2016-02-12 03:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/182b1db9f663d1bb085c922ebf2516afe398f9e6', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}, {'number': 8, 'created': '2016-02-12 03:39:16.000000000', 'files': ['tools/kolla-ansible'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9f7c3b630d0c1f3902063c03588c04dd84bd36ea', 'message': 'Fix non-root deploys\n\nTrivialFix\n\nChange-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b\n'}]",5,276887,9f7c3b630d0c1f3902063c03588c04dd84bd36ea,33,9,8,14119,,,0,"Fix non-root deploys

TrivialFix

Change-Id: Id0e7cf9e1c0c4259b8a50c39e95214103256517b
",git fetch https://review.opendev.org/openstack/kolla refs/changes/87/276887/8 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/glance/tasks/start.yml', 'ansible/roles/murano/tasks/start.yml', 'ansible/roles/heat/tasks/start.yml', 'ansible/roles/cinder/tasks/start.yml', 'ansible/roles/neutron/tasks/start.yml', 'ansible/roles/nova/tasks/start.yml', 'ansible/roles/keystone/tasks/start.yml', 'ansible/roles/common/tasks/start.yml', 'ansible/roles/swift/tasks/start.yml', 'ansible/roles/magnum/tasks/start.yml', 'ansible/roles/mistral/tasks/start.yml', 'tools/kolla-ansible']",12,80af298c640ff966ee2a3a6947d8ab5fdd5494db,non-root," --configdir <config_path> Specify path to directory with globals.ymlLONG_OPTS=""help,inventory:,playbook:,tags:,keyfile:,configdir:""CONFIG_OPTS=""-e @/root/kolla_config/globals.yml -e @/root/kolla_config/passwords.yml"" (--configdir) CONFIG_OPTS=""-e @$2/globals.yml -e @$2/passwords.yml"" shift 2 ;; CMD=""ansible-playbook -i $INVENTORY $CONFIG_OPTS $EXTRA_OPTS $PLAYBOOK""","LONG_OPTS=""help,inventory:,playbook:,tags:,keyfile:""EXTRA_OPTS=""-e @/etc/kolla/globals.yml -e @/etc/kolla/passwords.yml""CMD=""ansible-playbook -i $INVENTORY $EXTRA_OPTS $PLAYBOOK""",57,51
openstack%2Fkolla~master~I85fde385dba3579abad497e327170d30b8b9fc7c,openstack/kolla,master,I85fde385dba3579abad497e327170d30b8b9fc7c,Switch to docker registry v2,MERGED,2016-02-09 05:28:54.000000000,2016-02-14 20:09:38.000000000,2016-02-14 20:09:38.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 7244}, {'_account_id': 14119}, {'_account_id': 18009}, {'_account_id': 18652}, {'_account_id': 19300}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-09 05:28:54.000000000', 'files': ['dev/vagrant/centos-bootstrap.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/ef9aca2f63e9d3e0007e408d9e7360b74375dca4', 'message': 'Switch to docker registry v2\n\nWith docker 1.10, the v2 registry finally has decent performances.\n\nTrivialFix\n\nChange-Id: I85fde385dba3579abad497e327170d30b8b9fc7c\n'}]",0,277691,ef9aca2f63e9d3e0007e408d9e7360b74375dca4,12,8,1,13039,,,0,"Switch to docker registry v2

With docker 1.10, the v2 registry finally has decent performances.

TrivialFix

Change-Id: I85fde385dba3579abad497e327170d30b8b9fc7c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/91/277691/1 && git format-patch -1 --stdout FETCH_HEAD,['dev/vagrant/centos-bootstrap.sh'],1,ef9aca2f63e9d3e0007e408d9e7360b74375dca4,vagrant-fixes, registry:2, registry:0.9.1,1,1
openstack%2Fkolla~master~I408415e95483c1b8988d0f67c654212de63bece2,openstack/kolla,master,I408415e95483c1b8988d0f67c654212de63bece2,Fetching IP addresses for vagrant-hostmanager from libvirt,MERGED,2016-02-09 05:28:54.000000000,2016-02-14 20:09:31.000000000,2016-02-14 20:09:31.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 14027}, {'_account_id': 14119}, {'_account_id': 18009}, {'_account_id': 19300}, {'_account_id': 19542}]","[{'number': 1, 'created': '2016-02-09 05:28:54.000000000', 'files': ['dev/vagrant/Vagrantfile', 'dev/vagrant/newest_dhcp_lease.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e715856f5228ab8199f4a0bd08253137411c0b99', 'message': 'Fetching IP addresses for vagrant-hostmanager from libvirt\n\nTo fetch the IP address from the interface other than eth0 for\nvagrant-hostmanager plugin, it must be fetched from the DHCP\nleases from libvirt network. The previously used one-liner,\nwhich was using virsh with awk, returns multiple addresses\nwhen VM was destroyed before expiration of its DHCP lease.\n\nThis script solved this problem by getting only the newest\nDHCP lease and gives a possibility to destroy Vagrant\nenvironment and set up again without worrying about hosts\nresolving.\n\nCo-Authored-By: Michal Rostecki <mrostecki@mirantis.com>\nPartially-Implements: blueprint vagrant\nRelated-Id: Ic469b46f4d02d873c27114cbd268b86521eef32b\nRelated-Id: I81f07b7e4a202af68fd3cf9fdb308c3734c40a83\n\nChange-Id: I408415e95483c1b8988d0f67c654212de63bece2\n'}]",0,277690,e715856f5228ab8199f4a0bd08253137411c0b99,11,7,1,13039,,,0,"Fetching IP addresses for vagrant-hostmanager from libvirt

To fetch the IP address from the interface other than eth0 for
vagrant-hostmanager plugin, it must be fetched from the DHCP
leases from libvirt network. The previously used one-liner,
which was using virsh with awk, returns multiple addresses
when VM was destroyed before expiration of its DHCP lease.

This script solved this problem by getting only the newest
DHCP lease and gives a possibility to destroy Vagrant
environment and set up again without worrying about hosts
resolving.

Co-Authored-By: Michal Rostecki <mrostecki@mirantis.com>
Partially-Implements: blueprint vagrant
Related-Id: Ic469b46f4d02d873c27114cbd268b86521eef32b
Related-Id: I81f07b7e4a202af68fd3cf9fdb308c3734c40a83

Change-Id: I408415e95483c1b8988d0f67c654212de63bece2
",git fetch https://review.opendev.org/openstack/kolla refs/changes/90/277690/1 && git format-patch -1 --stdout FETCH_HEAD,"['dev/vagrant/Vagrantfile', 'dev/vagrant/newest_dhcp_lease.py']",2,e715856f5228ab8199f4a0bd08253137411c0b99,vagrant-fixes,"#!/usr/bin/env python # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. """""" Command-line utility to get the IP address from the newest DHCP lease. It's written for using with vagrant-hostmanager and vagrant-libvirt plugins. Vagrant-hostmanager by default fetches only IP addresses from eth0 interfaces on VM-s. Therefore, the first purpose of this utility is to be able to fetch the address also from the other interfaces. Libvirt/virsh only lists all DHCP leases for the given network with timestamps. DHCP leases have their expiration time, but are not cleaned up after destroying VM. If someone destroys and sets up the VM with the same hostname, we have many DHCP leases for the same hostname and we have to look up for timestamp. That's the second purpose of this script. """""" import argparse import csv import functools import operator import xml.etree.ElementTree as etree import libvirt class NoBridgeInterfaceException(Exception): pass class NoDHCPLeaseException(Exception): pass def libvirt_conn(f): @functools.wraps(f) def wrapper(*args, **kwargs): conn = libvirt.openReadOnly('qemu:///system') return f(conn, *args, **kwargs) return wrapper @libvirt_conn def get_vir_network_dhcp_lease(conn, vm_name): """"""Libvirt since 1.2.6 version provides DHCPLeases method in virNetwork. That's the current official way for getting DHCP leases and this information isn't stored anywhere else anymore. """""" network = conn.networkLookupByName('vagrant-private-dhcp') dhcp_leases = libvirt.virNetwork.DHCPLeases(network) vm_dhcp_leases = filter(lambda lease: lease['hostname'] == vm_name, dhcp_leases) newest_vm_dhcp_lease = sorted(vm_dhcp_leases, key=operator.itemgetter('expirytime'), reverse=True)[0]['ipaddr'] return newest_vm_dhcp_lease def get_mac_address(conn, domain_name): """"""Get MAC address from domain XML."""""" domain = conn.lookupByName(domain_name) domain_xml = domain.XMLDesc() domain_tree = etree.fromstring(domain_xml) devices = domain_tree.find('devices') interfaces = devices.iterfind('interface') for interface in interfaces: interface_type = interface.get('type') if interface_type != 'bridge': continue mac_element = interface.find('mac') mac_address = mac_element.get('address') return mac_address raise NoBridgeInterfaceException() @libvirt_conn def get_dnsmasq_dhcp_lease(conn, vm_name): """"""In libvirt under 1.2.6 DHCP leases are stored in file. There is no API for DHCP leases yet. """""" domain_name = 'vagrant_' + vm_name mac_address = get_mac_address(conn, domain_name) with open( '/var/lib/libvirt/dnsmasq/vagrant-private-dhcp.leases' ) as leases_file: reader = csv.reader(leases_file, delimiter=' ') for row in reader: lease_mac, lease_ip, lease_vm_name = row[1:4] if not (lease_mac == mac_address and lease_vm_name == vm_name): continue return lease_ip raise NoDHCPLeaseException() def main(): parser = argparse.ArgumentParser() parser.add_argument('vm_name', help='Name of the virtual machine') args = parser.parse_args() vm_name = args.vm_name if libvirt.getVersion() >= 1002006: newest_dhcp_lease = get_vir_network_dhcp_lease(vm_name) else: newest_dhcp_lease = get_dnsmasq_dhcp_lease(vm_name) print(newest_dhcp_lease) if __name__ == '__main__': main() ",,132,1
openstack%2Ffuel-library~master~Ibfad0fb4142dcbd5de086183caa805db50e9c86e,openstack/fuel-library,master,Ibfad0fb4142dcbd5de086183caa805db50e9c86e,Fix rspec tests for the 'l23network' module,ABANDONED,2016-02-14 00:34:10.000000000,2016-02-14 19:51:23.000000000,,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 14200}]","[{'number': 1, 'created': '2016-02-14 00:34:10.000000000', 'files': ['deployment/puppet/l23network/lib/puppet/provider/l3_clear_route/lnx.rb', 'deployment/puppet/l23network/spec/unit/puppet/provider/l23_stored_config/ovs_centos7__ovs2lnx_patch__spec.rb', 'deployment/puppet/l23network/spec/unit/puppet/provider/l23_stored_config/ovs_redhat7__ovs2lnx_patch__spec.rb', 'deployment/puppet/l23network/manifests/init.pp', 'deployment/puppet/l23network/spec/unit/puppet/provider/l3_clear_route/lnx__spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8f6b5d837f6182bc4c7051cb4e48871afc856913', 'message': ""Fix rspec tests for the 'l23network' module\n\nThis commit fixes the second non-critical part of the bug with\nregular expression warnings and eliminates ugly messages during\nthe exception in the 'route_delete' function.\n\nAlso, it contains the fix for the 'package' resource with the\nattribute 'ensure' set to 'purged' value when RSpec tests executed\non non-Ubuntu environments.\n\nChange-Id: Ibfad0fb4142dcbd5de086183caa805db50e9c86e\nPartial-Bug: #1539975\n""}]",2,279905,8f6b5d837f6182bc4c7051cb4e48871afc856913,13,8,1,14200,,,0,"Fix rspec tests for the 'l23network' module

This commit fixes the second non-critical part of the bug with
regular expression warnings and eliminates ugly messages during
the exception in the 'route_delete' function.

Also, it contains the fix for the 'package' resource with the
attribute 'ensure' set to 'purged' value when RSpec tests executed
on non-Ubuntu environments.

Change-Id: Ibfad0fb4142dcbd5de086183caa805db50e9c86e
Partial-Bug: #1539975
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/05/279905/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/l23network/lib/puppet/provider/l3_clear_route/lnx.rb', 'deployment/puppet/l23network/spec/unit/puppet/provider/l23_stored_config/ovs_centos7__ovs2lnx_patch__spec.rb', 'deployment/puppet/l23network/spec/unit/puppet/provider/l23_stored_config/ovs_redhat7__ovs2lnx_patch__spec.rb', 'deployment/puppet/l23network/manifests/init.pp', 'deployment/puppet/l23network/spec/unit/puppet/provider/l3_clear_route/lnx__spec.rb']",5,8f6b5d837f6182bc4c7051cb4e48871afc856913,bug/1539975," provider.class.stubs(:route_delete).raises(Exception, ""The route default via p2p22 is already removed!\nRTNETLINK answers: No such process"")"," provider.class.stubs(:iproute).with(['--force', 'route', 'delete', name, 'via', '172.18.128.1', 'dev', 'p2p22']).raises(""Command 'ip --force route delete default via 172.18.128.1 dev p2p22' has been failed with exit_code=1:\nRTNETLINK answers: No such process"")",6,5
openstack%2Fkolla~master~I4d585733a9abd201c1b0680e6196dd2a36db3c7e,openstack/kolla,master,I4d585733a9abd201c1b0680e6196dd2a36db3c7e,Fix keystone initial auth mechanism,MERGED,2016-02-14 04:29:32.000000000,2016-02-14 19:36:53.000000000,2016-02-14 19:36:53.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 14119}, {'_account_id': 16993}]","[{'number': 1, 'created': '2016-02-14 04:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/feea7702d60eb2f1bcd26aa0d53095f7d6fd14d2', 'message': 'Fix keystone initial auth mechanism\n\nA recent change in keystone [1] has deprecated the token auth\nmechanism that we used. We reintroduce it temporarily while a more\npermanant solution is worked on.\n\n[1] https://github.com/openstack/keystone/commit/5286b4a297b5a94895a311a9e564aa87cb54dbfd\n\nChange-Id: I4d585733a9abd201c1b0680e6196dd2a36db3c7e\nCloses-Bug: #1545292\n'}, {'number': 2, 'created': '2016-02-14 14:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ef72a84ff69265068ee65b19ebca5629341788bd', 'message': 'Fix keystone initial auth mechanism\n\nA recent change in keystone [1] has deprecated the token auth\nmechanism that we used. We reintroduce it temporarily while a more\npermanant solution is worked on.\n\n[1] https://github.com/openstack/keystone/commit/5286b4a297b5a94895a311a9e564aa87cb54dbfd\n\nChange-Id: I4d585733a9abd201c1b0680e6196dd2a36db3c7e\nCloses-Bug: #1545292\n'}, {'number': 3, 'created': '2016-02-14 15:59:21.000000000', 'files': ['docker/keystone/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/8ef7434770846e81aa04009838bd1df69cc29ac8', 'message': 'Fix keystone initial auth mechanism\n\nA recent change in keystone [1] has deprecated the token auth\nmechanism that we used. We reintroduce it temporarily while a more\npermanant solution is worked on.\n\n[1] https://github.com/openstack/keystone/commit/5286b4a297b5a94895a311a9e564aa87cb54dbfd\n\nChange-Id: I4d585733a9abd201c1b0680e6196dd2a36db3c7e\nCloses-Bug: #1545292\n'}]",0,279917,8ef7434770846e81aa04009838bd1df69cc29ac8,16,5,3,14119,,,0,"Fix keystone initial auth mechanism

A recent change in keystone [1] has deprecated the token auth
mechanism that we used. We reintroduce it temporarily while a more
permanant solution is worked on.

[1] https://github.com/openstack/keystone/commit/5286b4a297b5a94895a311a9e564aa87cb54dbfd

Change-Id: I4d585733a9abd201c1b0680e6196dd2a36db3c7e
Closes-Bug: #1545292
",git fetch https://review.opendev.org/openstack/kolla refs/changes/17/279917/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/keystone/Dockerfile.j2'],1,feea7702d60eb2f1bcd26aa0d53095f7d6fd14d2,bug/1545292,# NOTE(SamYaple): This is to reintroduce a deprecated option as a quick-fix # until the correct new procedure is implemented. # TODO(SamYaple): Replace this with `keystone-manage bootstrap` RUN sed -i 's|token_auth json_body|token_auth admin_token_auth json_body|g' /etc/keystone/keystone-paste.ini ,,5,0
openstack%2Fkolla~master~Ib1568e186bdd7d19b7e5af151388197755902488,openstack/kolla,master,Ib1568e186bdd7d19b7e5af151388197755902488,Install keystone-dist-paste.ini in /etc/keystone,MERGED,2016-02-14 14:50:25.000000000,2016-02-14 19:35:32.000000000,2016-02-14 19:35:32.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-14 14:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1879432a51f4c1bff7b4de805cb0aebad95f14c0', 'message': ""Install keystone-dist-paste.ini in /etc/keystone\n\nThe CentOS packages install a default version of the paste file\nbut don't install them in the /etc directory.  Kolla doesn't\nconfigure the paste files, so this file never gets setup properly.\n\nWith the recent change in Keystone around the default admin_token\nbeing changed, this triggered Keystone to return a 401 Auth error.\n\nA follow-on patch from Sam edits this file, and that patch breaks\nthe build without this dependent patch.\n\nTrivialFix\n\nChange-Id: Ib1568e186bdd7d19b7e5af151388197755902488\n""}, {'number': 2, 'created': '2016-02-14 15:59:21.000000000', 'files': ['docker/keystone/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/03568ce863f84da54d7e52af996d4f48c1c5c387', 'message': ""Install keystone-dist-paste.ini in /etc/keystone\n\nThe CentOS packages install a default version of the paste file\nbut don't install them in the /etc directory.  Kolla doesn't\nconfigure the paste files, so this file never gets setup properly.\n\nWith the recent change in Keystone around the default admin_token\nbeing changed, this triggered Keystone to return a 401 Auth error.\n\nA follow-on patch from Sam edits this file, and that patch breaks\nthe build without this dependent patch.\n\nTrivialFix\n\nChange-Id: Ib1568e186bdd7d19b7e5af151388197755902488\n""}]",1,279988,03568ce863f84da54d7e52af996d4f48c1c5c387,11,3,2,2834,,,0,"Install keystone-dist-paste.ini in /etc/keystone

The CentOS packages install a default version of the paste file
but don't install them in the /etc directory.  Kolla doesn't
configure the paste files, so this file never gets setup properly.

With the recent change in Keystone around the default admin_token
being changed, this triggered Keystone to return a 401 Auth error.

A follow-on patch from Sam edits this file, and that patch breaks
the build without this dependent patch.

TrivialFix

Change-Id: Ib1568e186bdd7d19b7e5af151388197755902488
",git fetch https://review.opendev.org/openstack/kolla refs/changes/88/279988/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/keystone/Dockerfile.j2'],1,1879432a51f4c1bff7b4de805cb0aebad95f14c0,bug/1545292," && cp -a /usr/share/keystonekeystone-dist-paste.ini /etc/keystone/keystone-paste.ini \ && sed -i -r 's,^(Listen 80),#\1,' /etc/httpd/conf/httpd.conf "," && sed -i -r 's,^(Listen 80),#\1,' /etc/httpd/conf/httpd.conf",2,1
openstack%2Fnova~master~I20a6122613e3534da84fb934523c5af0fc7d6607,openstack/nova,master,I20a6122613e3534da84fb934523c5af0fc7d6607,[WIP] Check Nova breakage with pycryptodome===3.4,ABANDONED,2016-02-13 21:19:59.000000000,2016-02-14 19:06:12.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-02-13 21:19:59.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/a93c03106c3236fe832a6346fb276c57cda5d4db', 'message': '[WIP] Check Nova breakage with pycryptodome===3.4\n\nChange-Id: I20a6122613e3534da84fb934523c5af0fc7d6607\n'}]",0,279897,a93c03106c3236fe832a6346fb276c57cda5d4db,10,7,1,5638,,,0,"[WIP] Check Nova breakage with pycryptodome===3.4

Change-Id: I20a6122613e3534da84fb934523c5af0fc7d6607
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/279897/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a93c03106c3236fe832a6346fb276c57cda5d4db,,pycryptodome>=3.4,,1,0
openstack%2Fopenstack-manuals~master~I85fbc64af27e24c5b98fe032b4fb86cc2967360b,openstack/openstack-manuals,master,I85fbc64af27e24c5b98fe032b4fb86cc2967360b,Rename common-rst to common on synced repos,MERGED,2016-02-14 09:40:54.000000000,2016-02-14 18:23:54.000000000,2016-02-14 18:23:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-14 09:40:54.000000000', 'files': ['tools/sync-projects.sh'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6df6806940cad69217bc59b00ee3d9ebd8bb9ecd', 'message': 'Rename common-rst to common on synced repos\n\nChange-Id: I85fbc64af27e24c5b98fe032b4fb86cc2967360b\n'}]",0,279947,6df6806940cad69217bc59b00ee3d9ebd8bb9ecd,8,3,1,10497,,,0,"Rename common-rst to common on synced repos

Change-Id: I85fbc64af27e24c5b98fe032b4fb86cc2967360b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/279947/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/sync-projects.sh'],1,6df6806940cad69217bc59b00ee3d9ebd8bb9ecd,common, $TARGET, $TARGET/common-rst.po,1,1
openstack%2Fkolla~master~I5168191182c249df68fd0b5c70a778f223326974,openstack/kolla,master,I5168191182c249df68fd0b5c70a778f223326974,rabbitmq_data container is removed,MERGED,2016-02-14 12:59:26.000000000,2016-02-14 18:10:40.000000000,2016-02-14 18:10:39.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-14 12:59:26.000000000', 'files': ['tools/cleanup-containers'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a5a0a830ef00d62cb24358d317c4959e5750fd73', 'message': 'rabbitmq_data container is removed\n\nTrivialFix\n\nChange-Id: I5168191182c249df68fd0b5c70a778f223326974\n'}]",0,279963,a5a0a830ef00d62cb24358d317c4959e5750fd73,7,3,1,18723,,,0,"rabbitmq_data container is removed

TrivialFix

Change-Id: I5168191182c249df68fd0b5c70a778f223326974
",git fetch https://review.opendev.org/openstack/kolla refs/changes/63/279963/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/cleanup-containers'],1,a5a0a830ef00d62cb24358d317c4959e5750fd73,, rabbitmq \," rabbitmq{,_data} \",1,1
openstack%2Frequirements~master~Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc,openstack/requirements,master,Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc,Add certifi to global requirements,ABANDONED,2015-09-07 21:09:50.000000000,2016-02-14 17:59:04.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 5638}, {'_account_id': 8143}, {'_account_id': 8871}, {'_account_id': 9591}, {'_account_id': 11536}]","[{'number': 1, 'created': '2015-09-07 21:09:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4fa169304c3ca65b1af912cea664ad960487761b', 'message': 'Add certifi to global requirements\n\nCertifi was part of the requests package. Now it has been extracted\nand becomes a separated package. Certifi is required by the\nauto-generated python binding of kubernetes, which magnum depends on.\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}, {'number': 2, 'created': '2015-10-03 21:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/29168fa061612d7032325353b6d03d92b2b0e86f', 'message': 'Add certifi to global requirements\n\nCertifi is required by the auto-generated python binding of\nkubernetes, which magnum depends on.\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}, {'number': 3, 'created': '2015-10-07 19:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/eff1048067cf406344524af76035724dbd25f7bd', 'message': 'Add certifi to global requirements\n\nCertifi is required by the auto-generated python binding of\nkubernetes, which magnum depends on. Recently, magnum merged a patch,\nwhich temprorarily works around the missing of certifi:\n\nhttps://review.openstack.org/#/c/221376/\n\nWe plan to revert the patch above after certifi is added to the\nglobal requirements. In addition, this commit removed the requirement\nof python 2.7 in upper constraints, since certifi supports python 3.4\nas well [1].\n\n[1] https://github.com/certifi/python-certifi/blob/master/setup.py\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}, {'number': 4, 'created': '2015-10-13 13:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/34c6d0b573e66e10b9d8bff346b54ad5287e673e', 'message': 'Add certifi to global requirements\n\nCertifi is required by the auto-generated python binding of\nkubernetes, which magnum depends on. Recently, magnum merged a patch,\nwhich temprorarily works around the missing of certifi:\n\nhttps://review.openstack.org/#/c/221376/\n\nWe plan to revert the patch above after certifi is added to the\nglobal requirements. In addition, this commit removed the requirement\nof python 2.7 in upper constraints, since certifi supports python 3.4\nas well [1].\n\n[1] https://github.com/certifi/python-certifi/blob/master/setup.py\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}, {'number': 5, 'created': '2015-11-08 16:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/824a78fc2c7fe46fb0c1c60eb7813c8433ea25ac', 'message': 'Add certifi to global requirements\n\nCertifi is required by the auto-generated python binding of\nkubernetes, which magnum depends on. Recently, magnum merged a patch,\nwhich temprorarily works around the missing of certifi:\n\nhttps://review.openstack.org/#/c/221376/\n\nWe plan to revert the patch above after certifi is added to the\nglobal requirements. In addition, this commit removed the requirement\nof python 2.7 in upper constraints, since certifi supports python 3.4\nas well [1].\n\nThis library satisfies most requirements in README. This library is:\n* is actively maintained\n* is good code\n* is compatible with py3\n* is licensed under Mozilla Public License 2.0\n* is not packaged in the distros, since it is python specific\n* This library has features that are not yet covered under other\n  libraries in global requirements\n\n[1] https://github.com/certifi/python-certifi/blob/master/setup.py\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}, {'number': 6, 'created': '2015-11-10 23:17:21.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f33cef103cb75d3d72cdc3b6187cda8de03cea47', 'message': 'Add certifi to global requirements\n\nCertifi is required by the auto-generated python binding of\nkubernetes, which magnum depends on. Recently, magnum merged a patch,\nwhich temprorarily works around the missing of certifi:\n\nhttps://review.openstack.org/#/c/221376/\n\nWe plan to revert the patch above after certifi is added to the\nglobal requirements. In addition, this commit removed the requirement\nof python 2.7 in upper constraints, since certifi supports python 3.4\nas well [1].\n\nThis library satisfies most requirements in README. This library is:\n* is actively maintained\n* is good code\n* is compatible with py3\n* is licensed under Mozilla Public License 2.0\n* is not packaged in the distros, since it is python specific\n* This library has features that are not yet covered under other\n  libraries in global requirements\n\n[1] https://github.com/certifi/python-certifi/blob/master/setup.py\n\nChange-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc\n'}]",1,221107,f33cef103cb75d3d72cdc3b6187cda8de03cea47,45,9,6,11536,,,0,"Add certifi to global requirements

Certifi is required by the auto-generated python binding of
kubernetes, which magnum depends on. Recently, magnum merged a patch,
which temprorarily works around the missing of certifi:

https://review.openstack.org/#/c/221376/

We plan to revert the patch above after certifi is added to the
global requirements. In addition, this commit removed the requirement
of python 2.7 in upper constraints, since certifi supports python 3.4
as well [1].

This library satisfies most requirements in README. This library is:
* is actively maintained
* is good code
* is compatible with py3
* is licensed under Mozilla Public License 2.0
* is not packaged in the distros, since it is python specific
* This library has features that are not yet covered under other
  libraries in global requirements

[1] https://github.com/certifi/python-certifi/blob/master/setup.py

Change-Id: Ib3acfdbae02a6a7a2dd656a6a5925ab74d81b0bc
",git fetch https://review.opendev.org/openstack/requirements refs/changes/07/221107/2 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,4fa169304c3ca65b1af912cea664ad960487761b,certifi,certifi===2015.9.6.2,certifi===2015.9.6.1;python_version=='2.7',2,1
openstack%2Fpython-openstackclient~master~I5dac1eed6eb8e67298bb446418835a6ab85c859c,openstack/python-openstackclient,master,I5dac1eed6eb8e67298bb446418835a6ab85c859c,"Support ""network delete"" command in nova network",MERGED,2016-02-09 19:08:24.000000000,2016-02-14 17:53:05.000000000,2016-02-14 17:53:05.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}, {'_account_id': 17130}]","[{'number': 1, 'created': '2016-02-09 19:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/65c26afe9b9b79a0974fc755508f505c6c8fa804', 'message': 'Support ""network delete"" command in nova network\n\n""network delete"" command is not implemented in nova network.\nThis patch implements it.\n\nChange-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c\nDepends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e\npartial-Bug: 1543672\n'}, {'number': 2, 'created': '2016-02-10 08:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40532082fd6d223d4956379466e500067b2926df', 'message': 'Support ""network delete"" command in nova network\n\n""network delete"" command is not implemented in nova network.\nThis patch implements it.\n\nChange-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c\nDepends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e\npartial-Bug: 1543672\n'}, {'number': 3, 'created': '2016-02-11 14:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3f093bb4a4be472ae2df1566926668511acc22af', 'message': 'Support ""network delete"" command in nova network\n\n""network delete"" command is not implemented in nova network.\nThis patch implements it.\n\nChange-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c\nDepends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e\npartial-Bug: 1543672\n'}, {'number': 4, 'created': '2016-02-14 05:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/569f4021ccf145873ad896c14f05a04786077f24', 'message': 'Support ""network delete"" command in nova network\n\n""network delete"" command is not implemented in nova network.\nThis patch implements it.\n\nChange-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c\nDepends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e\npartial-Bug: 1543672\n'}, {'number': 5, 'created': '2016-02-14 09:11:37.000000000', 'files': ['openstackclient/tests/compute/v2/fakes.py', 'doc/source/commands.rst', 'openstackclient/network/v2/network.py', 'openstackclient/tests/network/v2/test_network.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/27a0da65e37679bc042373d0e04ce88333d38a3b', 'message': 'Support ""network delete"" command in nova network\n\n""network delete"" command is not implemented in nova network.\nThis patch implements it.\n\nChange-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c\nDepends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e\npartial-Bug: 1543672\n'}]",0,278042,27a0da65e37679bc042373d0e04ce88333d38a3b,27,8,5,14937,,,0,"Support ""network delete"" command in nova network

""network delete"" command is not implemented in nova network.
This patch implements it.

Change-Id: I5dac1eed6eb8e67298bb446418835a6ab85c859c
Depends-On: I1b59264cd40aaf1062f4e8db233ccb7fd0e95f0e
partial-Bug: 1543672
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/42/278042/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/compute/v2/fakes.py', 'openstackclient/network/v2/network.py', 'openstackclient/tests/network/v2/test_network.py']",3,65c26afe9b9b79a0974fc755508f505c6c8fa804,bug/1543672,"from openstackclient.tests.compute.v2 import fakes as compute_fakes# Tests for Neutron network # # Tests for Nova network # class TestNetworkCompute(compute_fakes.TestComputev2): def setUp(self): super(TestNetworkCompute, self).setUp() # Get a shortcut to the compute client self.compute = self.app.client_manager.compute class TestDeleteNetworkCompute(TestNetworkCompute): # The network to delete. _network = network_fakes.FakeNetwork.create_one_network() def setUp(self): super(TestDeleteNetworkCompute, self).setUp() self.app.client_manager.network_endpoint_enabled = False self.compute.networks.delete.return_value = None # Return value of utils.find_resource() self.compute.networks.get.return_value = self._network # Get the command object to test self.cmd = network.DeleteNetwork(self.app, None) def test_network_delete_compute(self): arglist = [ self._network.name, ] verifylist = [ ('network', [self._network.name]), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) result = self.cmd.take_action(parsed_args) self.compute.networks.delete.assert_called_with(self._network.id) self.assertIsNone(result)",,63,5
openstack%2Fglance~master~I6b770fb4f09420855770fef6c4125313bed15046,openstack/glance,master,I6b770fb4f09420855770fef6c4125313bed15046,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 13:40:43.000000000,2016-02-14 17:46:57.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-14 13:40:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/glance/commit/739d777a3eaa7afa13f8883e7ed1f4b6148bdf6d', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\nChange-Id: I6b770fb4f09420855770fef6c4125313bed15046\n'}]",0,279979,739d777a3eaa7afa13f8883e7ed1f4b6148bdf6d,3,1,1,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Depends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
Change-Id: I6b770fb4f09420855770fef6c4125313bed15046
",git fetch https://review.opendev.org/openstack/glance refs/changes/79/279979/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,739d777a3eaa7afa13f8883e7ed1f4b6148bdf6d,,pycryptodome>=3.4 # Public Domain,pycrypto>=2.6 # Public Domain,1,1
openstack%2Fapi-site~master~I2007268dde122edf5437c4905dbb8e9cc3b06529,openstack/api-site,master,I2007268dde122edf5437c4905dbb8e9cc3b06529,Rename common-rst to common,MERGED,2016-02-14 09:35:38.000000000,2016-02-14 17:35:43.000000000,2016-02-14 17:35:43.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-14 09:35:38.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common-rst.po', 'common/conventions.rst', 'tools/build-rst.sh', 'common/README.txt', 'common/app_support.rst', 'firstapp/source/common', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'common/glossary.rst', 'common-rst/README.txt'], 'web_link': 'https://opendev.org/openstack/api-site/commit/84758f1e47d37d9b2b0ad2b1f9cf4069ddd06fd7', 'message': 'Rename common-rst to common\n\nChange-Id: I2007268dde122edf5437c4905dbb8e9cc3b06529\n'}]",0,279943,84758f1e47d37d9b2b0ad2b1f9cf4069ddd06fd7,8,3,1,10497,,,0,"Rename common-rst to common

Change-Id: I2007268dde122edf5437c4905dbb8e9cc3b06529
",git fetch https://review.opendev.org/openstack/api-site refs/changes/43/279943/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/source/locale/ja/LC_MESSAGES/common-rst.po', 'common/conventions.rst', 'tools/build-rst.sh', 'common/README.txt', 'common/app_support.rst', 'firstapp/source/common', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'common-rst/README.txt', 'common/glossary.rst']",11,84758f1e47d37d9b2b0ad2b1f9cf4069ddd06fd7,common,,,27,27
openstack%2Fsecurity-doc~master~I50d520be92ddcef9c7b42da357da48a1f88f4531,openstack/security-doc,master,I50d520be92ddcef9c7b42da357da48a1f88f4531,Rename common-rst to common,MERGED,2016-02-14 09:39:10.000000000,2016-02-14 17:29:35.000000000,2016-02-14 17:29:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-14 09:39:10.000000000', 'files': ['common/source/locale/ja/LC_MESSAGES/common-rst.po', 'common/conventions.rst', 'common/README.txt', 'security-guide/source/common', 'common/app_support.rst', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'common/glossary.rst', 'common-rst/README.txt'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/8ef0475085974b5444a68bb0670b16c29ed127d1', 'message': 'Rename common-rst to common\n\nChange-Id: I50d520be92ddcef9c7b42da357da48a1f88f4531\n'}]",0,279945,8ef0475085974b5444a68bb0670b16c29ed127d1,8,3,1,10497,,,0,"Rename common-rst to common

Change-Id: I50d520be92ddcef9c7b42da357da48a1f88f4531
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/45/279945/1 && git format-patch -1 --stdout FETCH_HEAD,"['common/source/locale/ja/LC_MESSAGES/common-rst.po', 'common/conventions.rst', 'common/README.txt', 'common/app_support.rst', 'security-guide/source/common', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'common-rst/README.txt', 'common/glossary.rst']",10,8ef0475085974b5444a68bb0670b16c29ed127d1,common,,,12,12
openstack%2Fha-guide~master~I601a27bb398ca21504530ca4298d304ab1688d46,openstack/ha-guide,master,I601a27bb398ca21504530ca4298d304ab1688d46,Rename common-rst to common,MERGED,2016-02-14 09:29:25.000000000,2016-02-14 17:28:35.000000000,2016-02-14 17:28:35.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2016-02-14 09:29:25.000000000', 'files': ['doc/common/glossary.rst', 'doc/ha-guide/source/common', 'doc/common/README.txt', 'doc/common/conventions.rst', 'doc/common/app_support.rst', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'doc/common-rst/README.txt'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/58284843f94d222d26eda8db23c60085998bfc3f', 'message': 'Rename common-rst to common\n\nChange-Id: I601a27bb398ca21504530ca4298d304ab1688d46\n'}]",0,279942,58284843f94d222d26eda8db23c60085998bfc3f,7,3,1,10497,,,0,"Rename common-rst to common

Change-Id: I601a27bb398ca21504530ca4298d304ab1688d46
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/42/279942/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common/glossary.rst', 'doc/ha-guide/source/common', 'doc/common/README.txt', 'doc/common/conventions.rst', 'doc/common/app_support.rst', 'tools/generatepot-rst.sh', 'doc-tools-check-languages.conf', 'tox.ini', 'doc/common-rst/README.txt']",9,58284843f94d222d26eda8db23c60085998bfc3f,common,,"Important note about this directory =================================== Because this directory is synced from openstack-manuals, make any changes in openstack-manuals/doc/common-rst. After changes to the synced files merge to openstack-manuals/doc/common-rst, a patch is automatically proposed for this directory. ",12,12
openstack%2Fopenstacksdk~master~I48662698e9a272a9e42a46f6108ed79f5107d8fe,openstack/openstacksdk,master,I48662698e9a272a9e42a46f6108ed79f5107d8fe,Basic resource.prop for ID attributes (compute),MERGED,2016-02-12 15:52:00.000000000,2016-02-14 17:07:06.000000000,2016-02-14 17:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2016-02-12 15:52:00.000000000', 'files': ['openstack/compute/v2/server_interface.py', 'openstack/compute/v2/server.py', 'openstack/tests/unit/compute/v2/test_server.py', 'openstack/compute/v2/server_ip.py', 'openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8268a2eba4e8351177f53d2d7974061c92f5c08c', 'message': 'Basic resource.prop for ID attributes (compute)\n\nThis patch set updates all compute resource objects to use basic\nproperties for ID attributes. In particular, the following changes\nwere made:\n  - Use basic *_id resource.prop for ID attributes\n  - Clarify documentation for ID attributes\n\nChange-Id: I48662698e9a272a9e42a46f6108ed79f5107d8fe\nPartial-Bug: #1461200\n'}]",0,279618,8268a2eba4e8351177f53d2d7974061c92f5c08c,7,2,1,8410,,,0,"Basic resource.prop for ID attributes (compute)

This patch set updates all compute resource objects to use basic
properties for ID attributes. In particular, the following changes
were made:
  - Use basic *_id resource.prop for ID attributes
  - Clarify documentation for ID attributes

Change-Id: I48662698e9a272a9e42a46f6108ed79f5107d8fe
Partial-Bug: #1461200
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/18/279618/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/compute/v2/server_interface.py', 'openstack/compute/v2/server.py', 'openstack/tests/unit/compute/v2/test_server.py', 'openstack/compute/v2/server_ip.py', 'openstack/compute/v2/_proxy.py']",5,8268a2eba4e8351177f53d2d7974061c92f5c08c,bug/1461200, :param flavor: Either the ID of a flavor or a :param server: Either the ID of an image or a :param server: Either the ID of an image or a :param server: Either the ID of a image or a :param server: Either the ID of an image or a :param server: Either the ID of an image or a :param keypair: Either the ID of a keypair or a :param server: Either the ID of a server or a :param server: Either the ID of a server or a :param server: Either the ID of a server or a :param server: Either the ID of a server or a :param server: Either the ID of a server or a :param server: Either the ID of a server or a, :param flavor: Either the id of a flavor or a :param server: Either the id of an image or a :param server: Either the id of an image or a :param server: Either the id of a image or a :param server: Either the id of an image or a :param server: Either the id of an image or a :param keypair: Either the id of a keypair or a :param server: Either the id of a server or a :param server: Either the id of a server or a :param server: Either the id of a server or a :param server: Either the id of a server or a :param server: Either the id of a server or a :param server: Either the id of a server or a,20,26
openstack%2Fopenstacksdk~master~Ibd04e5b78274a60ea0cf4faea4783116c343ff37,openstack/openstacksdk,master,Ibd04e5b78274a60ea0cf4faea4783116c343ff37,Basic resource.prop for ID attributes (identity),MERGED,2016-02-11 14:07:18.000000000,2016-02-14 17:00:21.000000000,2016-02-14 17:00:21.000000000,"[{'_account_id': 3}, {'_account_id': 8257}]","[{'number': 1, 'created': '2016-02-11 14:07:18.000000000', 'files': ['openstack/identity/v3/project.py', 'openstack/identity/v3/group.py', 'openstack/identity/v3/_proxy.py', 'openstack/identity/v3/credential.py', 'openstack/identity/v2/_proxy.py', 'openstack/identity/v3/endpoint.py', 'openstack/identity/v3/trust.py', 'openstack/identity/v3/user.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/a5a383fdd49ac834f7c9532756b3d81009bef58a', 'message': 'Basic resource.prop for ID attributes (identity)\n\nThis patch set updates all identity resource objects to use basic\nproperties for ID attributes. In particular, the following changes\nwere made:\n - Clarify documentation for ID attributes\n\nChange-Id: Ibd04e5b78274a60ea0cf4faea4783116c343ff37\nPartial-Bug: #1461200\n'}]",0,279089,a5a383fdd49ac834f7c9532756b3d81009bef58a,7,2,1,8410,,,0,"Basic resource.prop for ID attributes (identity)

This patch set updates all identity resource objects to use basic
properties for ID attributes. In particular, the following changes
were made:
 - Clarify documentation for ID attributes

Change-Id: Ibd04e5b78274a60ea0cf4faea4783116c343ff37
Partial-Bug: #1461200
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/89/279089/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/identity/v3/project.py', 'openstack/identity/v3/group.py', 'openstack/identity/v3/_proxy.py', 'openstack/identity/v3/credential.py', 'openstack/identity/v2/_proxy.py', 'openstack/identity/v3/endpoint.py', 'openstack/identity/v3/trust.py', 'openstack/identity/v3/user.py']",8,a5a383fdd49ac834f7c9532756b3d81009bef58a,bug/1461200," #: References the user's default project ID against which to authorize, #: References the domain ID which owns the user; if a domain ID is not #: default it to the domain ID to which the client's token is scoped."," #: References the user's default project against which to authorize, #: References the domain which owns the user; if a domain is not #: default it to the domain to which the client's token is scoped.",30,30
openstack%2Fopenstacksdk~master~I8d78e5bd7aa94667501e0037ee84a1fea4d2c62a,openstack/openstacksdk,master,I8d78e5bd7aa94667501e0037ee84a1fea4d2c62a,Basic resource.prop for ID attributes (telemetry),MERGED,2016-02-10 20:50:04.000000000,2016-02-14 17:00:12.000000000,2016-02-14 17:00:12.000000000,"[{'_account_id': 3}, {'_account_id': 8257}, {'_account_id': 8410}]","[{'number': 1, 'created': '2016-02-10 20:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0068268a2ad90899c37442523fe3c1cb612ef13e', 'message': 'Basic resource.prop for ID attributes (telemetry)\n\nThis patch set updates all telemetry resource objects to clarify\ndocumentation for ID attributes.\n\nChange-Id: I8d78e5bd7aa94667501e0037ee84a1fea4d2c62a\nPartial-Bug: #1461200\n'}, {'number': 2, 'created': '2016-02-10 21:33:04.000000000', 'files': ['openstack/telemetry/v2/sample.py', 'openstack/telemetry/v2/alarm_change.py', 'openstack/tests/unit/telemetry/v2/test_alarm_change.py', 'openstack/telemetry/v2/resource.py', 'openstack/telemetry/v2/meter.py', 'openstack/telemetry/v2/alarm.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7c9e4c3acc625de64f32cb2460eabafcf58a2535', 'message': 'Basic resource.prop for ID attributes (telemetry)\n\nThis patch set updates all telemetry resource objects to use basic\nproperties for ID attributes. In particular, the following changes\nwere made:\n  - Use basic *_id resource.prop for ID attributes\n  - Clarify documentation for ID attributes\n\nChange-Id: I8d78e5bd7aa94667501e0037ee84a1fea4d2c62a\nPartial-Bug: #1461200\n'}]",2,278625,7c9e4c3acc625de64f32cb2460eabafcf58a2535,10,3,2,8410,,,0,"Basic resource.prop for ID attributes (telemetry)

This patch set updates all telemetry resource objects to use basic
properties for ID attributes. In particular, the following changes
were made:
  - Use basic *_id resource.prop for ID attributes
  - Clarify documentation for ID attributes

Change-Id: I8d78e5bd7aa94667501e0037ee84a1fea4d2c62a
Partial-Bug: #1461200
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/25/278625/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/sample.py', 'openstack/telemetry/v2/alarm_change.py', 'openstack/telemetry/v2/resource.py', 'openstack/telemetry/v2/meter.py', 'openstack/telemetry/v2/alarm.py']",5,0068268a2ad90899c37442523fe3c1cb612ef13e,bug/1461200, #: The ID of the alarm #: The ID of the project that owns the alarm, #: The UUID of the alarm #: The ID of the project or tenant that owns the alarm,15,15
openstack%2Fopenstacksdk~master~I8c247efda4dc03606dd833aa59a84aad4aa1e20b,openstack/openstacksdk,master,I8c247efda4dc03606dd833aa59a84aad4aa1e20b,Updated from global requirements,ABANDONED,2016-02-10 21:59:17.000000000,2016-02-14 16:56:16.000000000,,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}]","[{'number': 1, 'created': '2016-02-10 21:59:17.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/92b0a71456e9e3917803bcf48584a97398e43da2', 'message': 'Updated from global requirements\n\nChange-Id: I8c247efda4dc03606dd833aa59a84aad4aa1e20b\n'}]",0,278734,92b0a71456e9e3917803bcf48584a97398e43da2,6,3,1,11131,,,0,"Updated from global requirements

Change-Id: I8c247efda4dc03606dd833aa59a84aad4aa1e20b
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/34/278734/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,92b0a71456e9e3917803bcf48584a97398e43da2,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,1,1
openstack%2Fcinder~master~I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8,openstack/cinder,master,I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8,Update db in CGSnapshot create,MERGED,2016-01-21 22:14:27.000000000,2016-02-14 16:50:24.000000000,2016-02-14 16:50:24.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11224}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-01-21 22:14:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/746cdb9febc6083972471e2076f54bf616b1aad1', 'message': 'Update db in CGSnapshot create\n\nModel_update returned from the driver in cgsnapshot_create\nis not used to update the db. This patch changes that.\n\nChange-Id: I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8\n'}, {'number': 2, 'created': '2016-02-05 17:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/908d19a48687b7fa22e44770a8210e7e3c6e74d5', 'message': 'Update db in CGSnapshot create\n\nModel_update returned from the driver in cgsnapshot_create\nis not used to update the db. This patch changes that.\n\nChange-Id: I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8\n'}, {'number': 3, 'created': '2016-02-08 19:23:30.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/ce7e952d7800b6b94ba381c29558d0d6fb67711d', 'message': 'Update db in CGSnapshot create\n\nModel_update returned from the driver in cgsnapshot_create\nis not used to update the db. This patch changes that.\n\nChange-Id: I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8\n'}]",4,271054,ce7e952d7800b6b94ba381c29558d0d6fb67711d,171,46,3,6491,,,0,"Update db in CGSnapshot create

Model_update returned from the driver in cgsnapshot_create
is not used to update the db. This patch changes that.

Change-Id: I051da3b3a8f570c9dbd0893dfc93c8500a1c9cc8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/54/271054/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,746cdb9febc6083972471e2076f54bf616b1aad1,cgsnapshot_modelupdate," self.db.snapshot_update(context, snap_model['id'], snap_model) cgsnapshot.update(model_update) cgsnapshot.save() ",,7,0
openstack%2Fneutron~master~Ibd9cb966eb2dcb1686c10846a9ded0f44039790e,openstack/neutron,master,Ibd9cb966eb2dcb1686c10846a9ded0f44039790e,Fix the redirection of neutron gerrit dashboard,ABANDONED,2015-10-28 09:23:14.000000000,2016-02-14 16:48:09.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 16237}, {'_account_id': 17108}, {'_account_id': 17120}, {'_account_id': 17211}, {'_account_id': 17776}, {'_account_id': 19896}, {'_account_id': 20084}]","[{'number': 1, 'created': '2015-10-28 09:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/533f065f3104d8a3f9fbc5c2b4afba31b66c6a12', 'message': ""There are some url in neutron gerrit dashboards redirect to an new url,it's not a big problem but i think it need be corrected.\n\nCloses-Bug: #1508452\nChange-Id: Ibd9cb966eb2dcb1686c10846a9ded0f44039790e\n""}, {'number': 2, 'created': '2016-01-29 07:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ddcaecb8039f31ab2fd3852fd00fbd4ce18e2181', 'message': ""Fix the redirection of neutron gerrit dashboard\n\nThere are some url links in neutron gerrit dashboards which redirect to\na new url. It's not a big problem but i think it need be corrected.\n\nTrivialFix\n\nCloses-Bug: #1508452\nChange-Id: Ibd9cb966eb2dcb1686c10846a9ded0f44039790e\n""}, {'number': 3, 'created': '2016-01-29 07:39:39.000000000', 'files': ['doc/source/dashboards/index.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/8813436b66157e9d67d203e35480d1a69879efab', 'message': ""Fix the redirection of neutron gerrit dashboard\n\nThere are some url links in neutron gerrit dashboards which redirect to\na new url. It's not a big problem but i think it need be corrected.\n\nTrivialFix\n\nCloses-Bug: #1510814\nChange-Id: Ibd9cb966eb2dcb1686c10846a9ded0f44039790e\n""}]",7,239879,8813436b66157e9d67d203e35480d1a69879efab,40,21,3,17106,,,0,"Fix the redirection of neutron gerrit dashboard

There are some url links in neutron gerrit dashboards which redirect to
a new url. It's not a big problem but i think it need be corrected.

TrivialFix

Closes-Bug: #1510814
Change-Id: Ibd9cb966eb2dcb1686c10846a9ded0f44039790e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/239879/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/dashboards/index.rst'],1,533f065f3104d8a3f9fbc5c2b4afba31b66c6a12,bug/1510814,.. _Gerrit Dashboard Creator: https://github.com/openstack/gerrit-dash-creator,.. _Gerrit Dashboard Creator: https://github.com/stackforge/gerrit-dash-creator,1,1
openstack%2Fkolla~master~I413468641bad5476cfcba61cb0e2189c31f3d682,openstack/kolla,master,I413468641bad5476cfcba61cb0e2189c31f3d682,Make kolla-toolbox container build on CentOS bin,MERGED,2016-02-13 01:50:06.000000000,2016-02-14 16:20:05.000000000,2016-02-14 16:20:05.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-13 01:50:06.000000000', 'files': ['docker/kolla-toolbox/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5dd79bbbef1d886914a1bf77bb098442cfe522e4', 'message': 'Make kolla-toolbox container build on CentOS bin\n\nAnsible installs pytz from pip which is newer then then pytz in\nRDO repositories.  As part of this process, it removes pytz\nwhich corrupts the python installation in some way.  This causes\nfurther pip usage to produce a backtrace causing the kolla-toolbox\ncontainer not to build.\n\nMixing pip and RPM is not good.\n\nChange-Id: I413468641bad5476cfcba61cb0e2189c31f3d682\nCloses-Bug: #1545215\n'}]",0,279838,5dd79bbbef1d886914a1bf77bb098442cfe522e4,10,3,1,2834,,,0,"Make kolla-toolbox container build on CentOS bin

Ansible installs pytz from pip which is newer then then pytz in
RDO repositories.  As part of this process, it removes pytz
which corrupts the python installation in some way.  This causes
further pip usage to produce a backtrace causing the kolla-toolbox
container not to build.

Mixing pip and RPM is not good.

Change-Id: I413468641bad5476cfcba61cb0e2189c31f3d682
Closes-Bug: #1545215
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/279838/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/kolla-toolbox/Dockerfile.j2'],1,5dd79bbbef1d886914a1bf77bb098442cfe522e4,bug/1545215, && yum clean all \ && yum -y remove pytz, && yum clean all,2,1
openstack%2Fkeystonemiddleware~master~I592bceea4f514fbc1611359cc10145baf2a08646,openstack/keystonemiddleware,master,I592bceea4f514fbc1611359cc10145baf2a08646,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 13:42:46.000000000,2016-02-14 15:53:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-14 13:42:46.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/740097009dfcd7a1748ff67d5040352f9223ba41', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\nChange-Id: I592bceea4f514fbc1611359cc10145baf2a08646\n'}]",0,279983,740097009dfcd7a1748ff67d5040352f9223ba41,3,1,1,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Depends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
Change-Id: I592bceea4f514fbc1611359cc10145baf2a08646
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/83/279983/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,740097009dfcd7a1748ff67d5040352f9223ba41,,pycryptodome>=3.4 # Public Domain,pycrypto>=2.6 # Public Domain,1,1
openstack%2Fkeystoneauth~master~Ic834f3296a114f0c5d42a6d7cc0766a4259196f1,openstack/keystoneauth,master,Ic834f3296a114f0c5d42a6d7cc0766a4259196f1,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 13:42:21.000000000,2016-02-14 15:53:32.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-14 13:42:21.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/keystoneauth/commit/3c08518fa87ee49afa96b4c707493e926a65574a', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nChange-Id: Ic834f3296a114f0c5d42a6d7cc0766a4259196f1\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\n'}]",0,279982,3c08518fa87ee49afa96b4c707493e926a65574a,3,1,1,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Change-Id: Ic834f3296a114f0c5d42a6d7cc0766a4259196f1
Depends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
",git fetch https://review.opendev.org/openstack/keystoneauth refs/changes/82/279982/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,3c08518fa87ee49afa96b4c707493e926a65574a,,pycryptodome>=3.4 # Public Domain,pycrypto>=2.6 # Public Domain,1,1
openstack%2Fheat~master~I7e27ff6900b01f39586674c5bf1f2659c17a2f45,openstack/heat,master,I7e27ff6900b01f39586674c5bf1f2659c17a2f45,[WIP] Switch from pycrypto to pycryptodome,ABANDONED,2016-02-14 13:41:21.000000000,2016-02-14 15:53:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2016-02-14 13:41:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/3b502813ddbb6548356b0cb9adfd83a498e9347b', 'message': '[WIP] Switch from pycrypto to pycryptodome\n\nDepends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d\nChange-Id: I7e27ff6900b01f39586674c5bf1f2659c17a2f45\n'}]",0,279980,3b502813ddbb6548356b0cb9adfd83a498e9347b,3,1,1,5638,,,0,"[WIP] Switch from pycrypto to pycryptodome

Depends-On: I82bb5d323f9b08f34f955ea61a81f64de811aa7d
Change-Id: I7e27ff6900b01f39586674c5bf1f2659c17a2f45
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/279980/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3b502813ddbb6548356b0cb9adfd83a498e9347b,,pycryptodome>=3.4 # Public Domain,pycrypto>=2.6 # Public Domain,1,1
openstack%2Fkolla~master~Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91,openstack/kolla,master,Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91,Remove the openstack_release option in the globals.yml file,MERGED,2016-01-31 07:20:47.000000000,2016-02-14 15:44:38.000000000,2016-02-14 15:44:38.000000000,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 2834}, {'_account_id': 7488}, {'_account_id': 14119}, {'_account_id': 18009}]","[{'number': 1, 'created': '2016-01-31 07:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9b29b052d38eaca6b5096224243c20aac6664e0c', 'message': 'Make the default openstack_release to 2.0.0 in globals.yml file\n\nTrivialFix\n\nChange-Id: Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91\n'}, {'number': 2, 'created': '2016-02-12 08:20:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1f7516cc65f9bc4b675f15b438d78b7611f1a7dc', 'message': 'Remove the openstack_release option in the globals.yml file\n\nNormally, the end user should not change this.\n\nTrivialFix\n\nChange-Id: Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91\n'}, {'number': 3, 'created': '2016-02-12 08:21:10.000000000', 'files': ['etc/kolla/globals.yml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/10172ec311277362b9b4228edd54945d8cba715e', 'message': 'Remove the openstack_release option in the globals.yml file\n\nNormally, the end user should not change this.\n\nTrivialFix\n\nChange-Id: Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91\n'}]",0,274408,10172ec311277362b9b4228edd54945d8cba715e,22,6,3,7488,,,0,"Remove the openstack_release option in the globals.yml file

Normally, the end user should not change this.

TrivialFix

Change-Id: Ida74ed0e5ae3ff689e2acbafb9d491341bbbcf91
",git fetch https://review.opendev.org/openstack/kolla refs/changes/08/274408/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/kolla/globals.yml'],1,9b29b052d38eaca6b5096224243c20aac6664e0c,trivial/fix_openstack_release,"#openstack_release: ""2.0.0""","#openstack_release: ""1.0.0""",1,1
openstack%2Fneutron~master~I2412c1689683da9d7ec884a4cea506d4eed99453,openstack/neutron,master,I2412c1689683da9d7ec884a4cea506d4eed99453,Add BGP Dynamic Routing DB Model and Basic CRUD,MERGED,2015-07-14 15:12:02.000000000,2016-02-14 14:51:39.000000000,2016-02-12 05:38:50.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 2888}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7018}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 11682}, {'_account_id': 12412}, {'_account_id': 13667}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15309}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15482}, {'_account_id': 15752}, {'_account_id': 16707}, {'_account_id': 17211}, {'_account_id': 17455}, {'_account_id': 17500}, {'_account_id': 17609}, {'_account_id': 18855}, {'_account_id': 20084}]","[{'number': 1, 'created': '2015-07-14 15:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6966883a6c750b178ab4c3a4c6f32c0dc6c2c075', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 2, 'created': '2015-07-14 19:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f8ec368cb0f59f9abf4e97243df4bf8edbaf67c8', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\nThis patch currently displays the complete list of\nfloating IP host routes to be advertised via the\nNeutron API.\n\nOutstanding Items:\n- DB query to return tenant network routes by network\n  and bgp_speaker_id\n- DB query to return DVR host routes by network and\n  bgp_speaker_id\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 3, 'created': '2015-07-16 09:42:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/41960f7dea2242d8047ea623de6c40d94c7b0469', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\nThis patch currently displays the complete list of\nfloating IP host routes to be advertised via the\nNeutron API.\n\nOutstanding Items:\n- DB query to return tenant network routes by network\n  and bgp_speaker_id\n- DB query to return DVR host routes by network and\n  bgp_speaker_id\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 4, 'created': '2015-07-16 13:24:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd4c0083f68a8d095b6ecc81d287d57d40912dd8', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\nThis patch currently displays the complete list of\nfloating IP host routes to be advertised via the\nNeutron API.\n\nOutstanding Items:\n- DB query to return tenant network routes by network\n  and bgp_speaker_id\n- DB query to return DVR host routes by network and\n  bgp_speaker_id\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 5, 'created': '2015-07-24 23:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe5d42faa742ac34731959b0c537c474b360fcbc', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 6, 'created': '2015-07-25 15:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d9feba0394f42d6735564ca437b0d1e94ec82b9', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 7, 'created': '2015-07-26 06:51:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c6af5f5dfbbb8448b344cf87a8a866d4b99f3d3b', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: Vikram Choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 8, 'created': '2015-07-30 16:34:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2402644874d6abf269116a2e8ed2174eb04d30bf', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 9, 'created': '2015-07-30 20:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/93a2092a7f5ae9c77c660661d3b472c7cc554389', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 10, 'created': '2015-08-10 11:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/46f0b72ad14c4d126e2595e3285b5820dbb9d136', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\nOutstanding Items:\n- Flesh-out DVR specific lookups for next-hops and fixed IP host routes\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 11, 'created': '2015-08-12 07:10:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7211f5572ae850eb3b912ced311ff8fb26a6e975', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n- Wire up handlers for router gateway and interface create/delete\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 12, 'created': '2015-08-12 07:51:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c5f656a48f0ba5b7db97cd26d7abc7f6d2ac5c8', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n- Wire up handlers for router gateway and interface create/delete\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 13, 'created': '2015-08-15 18:31:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27a81f5247f10ffac20e163c0292f06c8c1dfd54', 'message': '[WIP] BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n- Wire up handlers for router gateway and interface create/delete\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 14, 'created': '2015-08-18 00:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9dba912e8122075f4bcfd448c9859de30471038c', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n- Make API tests run (or at least skip) in the gate\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 15, 'created': '2015-08-20 10:58:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/456a3dc2c386fae5704759fcc715e630571c0df7', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n- Make API tests run (or at least skip) in the gate\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 16, 'created': '2015-08-21 23:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c03f5ed099f58bebb94fe7422c86346750da6ced', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 17, 'created': '2015-08-25 20:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d84117274928ad81eaa6881838817f31b7304b0', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 18, 'created': '2015-08-26 06:24:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39640bcbd4bbdd5624a9d6d0b87ddd095b533afd', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 19, 'created': '2015-08-26 14:54:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8a4195662ae5741f6174507213b2af4ef641c8b1', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 20, 'created': '2015-08-26 18:00:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9264b943263320132854a729226873c74c0d61c', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 21, 'created': '2015-08-26 21:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/116f38421877e760d1a386611d57632e4cadaf01', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 22, 'created': '2015-08-30 19:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5f538b151c3a0d81d2040b5d3f143357a4c30342', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 23, 'created': '2015-09-04 06:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f26dba490055365ea0920d73ae5e429f260a985', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 24, 'created': '2015-09-05 07:47:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1b247ef6a823d3e0328f65426bf69b5ea45a932e', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 25, 'created': '2015-09-05 07:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/244a1abf2cc9d44b9fa423d8efae72f3173c03f4', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 26, 'created': '2015-09-11 20:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f6816a1a76bb872fd7e3ba0ce65e8e64968b71c2', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 27, 'created': '2015-09-14 16:55:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/78d2d11484dcd3b1e5c77947ee055171c29d1594', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 28, 'created': '2015-09-14 20:47:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/486cfbc7f34817c1ea624aca2cd9c98edf5835cb', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 29, 'created': '2015-09-15 22:37:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/47b891763df158e3f6b1e124ae5e2b885f1392f4', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hp.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 30, 'created': '2015-09-22 23:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c1c7441c2f796d6daa19e04e416b3acece28ba7', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 31, 'created': '2015-09-24 00:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6bb4b55a4adc58a2c99cfa098b109fde369785d', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 32, 'created': '2015-09-28 22:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2358e0487e83c2d484270f079c75e1b68d7b73e', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\n\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nadmin users.\n\nOutstanding Items:\n- Address scope awareness of route lookups\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 33, 'created': '2015-10-15 17:14:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b9dcc8a29509ff099903157bee7759c899c23467', 'message': 'BGP Dynamic Routing: introduce entities and model\n\nThis is the first patch to provide BGP dynamic route\nadvertisement functionality in Neutron.\nThis patch provides a new extension (""bgp_speaker"") with\nsupport for basic CRUD on bgp_speaker and bgp_peer, as\nwell as bgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\nOutstanding Items:\n- Address scope awareness of route lookups\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 34, 'created': '2015-11-03 01:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/652b81f8ad9ca039f540e665a25f319f1c295036', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 35, 'created': '2015-11-04 00:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7eb7a18176779d63f4ff6c961f7e86027bf36190', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 36, 'created': '2015-11-04 22:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/82efa730fd56ce9f4aeaf9346e2d5408acf87273', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 37, 'created': '2015-11-10 21:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2c468ad4555fa51aca6a1f81c989677db0bb1990', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 38, 'created': '2015-11-11 17:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ac3f4aaadb50e3abae08bc5d4962192679ccf67', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 39, 'created': '2015-11-30 19:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/442fb9e331e296908ae65ad850f54d4577858a0d', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 40, 'created': '2015-12-17 20:10:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ef3def989b682e347e755559ba33abdb6d0a3913', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\nThis patch provides BGP-related functionality only to\nadmin users.\n\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\n'}, {'number': 41, 'created': '2015-12-29 12:32:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b5506d2de7fb17cbe6b73bc0e02589bff398347', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nOutstanding Items:\n - Fix API tests failures.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 42, 'created': '2016-01-01 10:38:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dbb63886837b115f7f588616af83ffafadb26a2b', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 43, 'created': '2016-01-01 12:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3966d5fa27acaaa08eb922e181f17b96302a3f53', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 44, 'created': '2016-01-03 14:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/af49578af95fe0e2522b0281a413f99558179fb0', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 45, 'created': '2016-01-05 09:01:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0d02bb70d3adac60afedb270aa446c4b642fac84', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 46, 'created': '2016-01-05 14:14:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb5a62d2f4e9f9d49bfb060822dd7cadee1a87de', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 47, 'created': '2016-01-07 00:56:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6574b50e78a40a06e90f2602b0685ac12b4e8430', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 48, 'created': '2016-01-12 23:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d9396788345fe10174c3ea26288a9996618d8d86', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 49, 'created': '2016-01-20 00:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bae2f7321093c282ce7a2d41ee4d1241d1da499c', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 50, 'created': '2016-01-21 18:27:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/03d770802ca03ab5ebc879a440e31cfe42a7c060', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 51, 'created': '2016-01-25 20:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3298d03c21c1d84fb270526323c07cb14c1b33cd', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 52, 'created': '2016-01-25 22:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8d185ada9997965dfae6e8894f32cc3c3cc190f3', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 53, 'created': '2016-01-26 06:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0682a47b7a0b3f9821780bb78262488ae58ff45a', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 54, 'created': '2016-01-29 01:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6893837b434c58ff777107381c6ab580a086af67', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 55, 'created': '2016-01-30 01:23:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b159834d6fd4f86a89e9c6c947335aeaca26fe83', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 56, 'created': '2016-02-01 22:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2f9f4fffb11cda921e7ca73e4db6aac1928fbc68', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 57, 'created': '2016-02-04 18:19:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/83111b795396d4a0be5c4b3d3be42f53c585bc13', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 58, 'created': '2016-02-05 23:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4257153d487153b4fe907623852096a3102f6461', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 59, 'created': '2016-02-07 04:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd329a28a2f7b6446b531eb7855e8cfd8af84158', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 60, 'created': '2016-02-08 18:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e12db946fb65ebe8e24918b7b769820624c0ee0', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 61, 'created': '2016-02-09 01:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7aabb05b8009cb379209af74e4a9746fff9d0868', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 62, 'created': '2016-02-10 00:57:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/aa992c6ca3deb5aa4deb5f7d4346e2604a419c60', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 63, 'created': '2016-02-10 16:56:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fbfa624db1d0f1ef0f2b9b1d5cca529216ba3350', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 64, 'created': '2016-02-11 00:19:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/732167077498fa797a08cdf9543d55abda0ff6db', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 65, 'created': '2016-02-11 00:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4eeb499653cd3975d84a505c39b52d1cba081636', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 66, 'created': '2016-02-11 15:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/457e8c3af386545b422b34a350242ddf32394141', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 67, 'created': '2016-02-11 17:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3bae44644ffea48882c7544874b67f9e00a808fc', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}, {'number': 68, 'created': '2016-02-11 21:46:58.000000000', 'files': ['neutron/tests/unit/db/test_bgp_db.py', 'neutron/db/migration/models/head.py', 'neutron/tests/contrib/gate_hook.sh', 'neutron/db/migration/alembic_migrations/versions/EXPAND_HEAD', 'devstack/plugin.sh', 'neutron/services/bgp/__init__.py', 'neutron/db/migration/alembic_migrations/versions/mitaka/expand/15be73214821_add_bgp_model_data.py', 'neutron/tests/api/test_bgp_speaker_extensions.py', 'neutron/tests/tempest/services/network/json/network_client.py', 'devstack/lib/bgp', 'neutron/tests/api/test_bgp_speaker_extensions_negative.py', 'neutron/services/bgp/bgp_plugin.py', 'neutron/extensions/bgp.py', 'setup.cfg', 'etc/policy.json', 'neutron/tests/etc/policy.json', 'neutron/db/bgp_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/773a3916ea771c8fc2ae787d226339e66d89338c', 'message': 'Add BGP Dynamic Routing DB Model and Basic CRUD\n\nThis patch enables basic CRUD on BGP dynamic routing\nentities bgp_speaker and bgp_peer, as well as\nbgp_speaker-bgp_peer and bgp_speaker-network\nbindings.\n\nAn admin user can create BgpSpeakers and configure\npeering entities (BgpPeers) for BgpSpeakers. BgpSpeaker\nto BgpPeer association is n-to-n. An admin user can\nalso associate networks with BgpSpeakers. Relationship\nbetween BgpSpeaker and Network is 1-to-n.\n\nThis patch provides BGP-related functionality only to\nthe admin users.\n\nPartially-Implements: blueprint bgp-dynamic-routing\nCo-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nCo-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>\nChange-Id: I2412c1689683da9d7ec884a4cea506d4eed99453\n'}]",536,201621,773a3916ea771c8fc2ae787d226339e66d89338c,1186,53,68,4187,,,0,"Add BGP Dynamic Routing DB Model and Basic CRUD

This patch enables basic CRUD on BGP dynamic routing
entities bgp_speaker and bgp_peer, as well as
bgp_speaker-bgp_peer and bgp_speaker-network
bindings.

An admin user can create BgpSpeakers and configure
peering entities (BgpPeers) for BgpSpeakers. BgpSpeaker
to BgpPeer association is n-to-n. An admin user can
also associate networks with BgpSpeakers. Relationship
between BgpSpeaker and Network is 1-to-n.

This patch provides BGP-related functionality only to
the admin users.

Partially-Implements: blueprint bgp-dynamic-routing
Co-Authored-By: Ryan Tidwell <ryan.tidwell@hpe.com>
Co-Authored-By: Jaume Devesa <devvesa@gmail.com>
Co-Authored-By: vikram.choudhary <vikram.choudhary@huawei.com>
Change-Id: I2412c1689683da9d7ec884a4cea506d4eed99453
",git fetch https://review.opendev.org/openstack/neutron refs/changes/21/201621/66 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/migration/models/head.py', 'neutron/db/migration/alembic_migrations/versions/15be73214821_add_bgp_speaker_model_data.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/tests/unit/services/bgp_speaker/__init__.py', 'neutron/db/bgp_speaker_db.py', 'neutron/db/migration/alembic_migrations/versions/HEAD', 'neutron/services/bgp_speaker/__init__.py', 'neutron/services/bgp_speaker/plugin.py', 'neutron/extensions/bgp_speaker.py', 'neutron/plugins/common/constants.py', 'neutron/tests/unit/services/bgp_speaker/test_bgp_speaker.py', 'neutron/tests/unit/extensions/test_bgp_speaker.py', 'tools/check_unit_test_structure.sh', 'setup.cfg', 'etc/policy.json', 'neutron/tests/etc/policy.json']",16,6966883a6c750b178ab4c3a4c6f32c0dc6c2c075,bp/bgp-dynamic-routing," ""create_lsn"": ""rule:admin_only"", ""get_bgp_speaker"": ""rule:admin_only"", ""create_bgp_speaker"": ""rule:admin_only"", ""update_bgp_speaker"": ""rule:admin_only"", ""delete_bgp_speaker"": ""rule:admin_only"", ""get_bgp_peer"": ""rule:admin_only"", ""create_bgp_peer"": ""rule:admin_only"", ""update_bgp_peer"": ""rule:admin_only"", ""delete_bgp_peer"": ""rule:admin_only"", ""add_bgp_peer"": ""rule:admin_only"", ""remove_bgp_peer"": ""rule:admin_only"", ""advertise_network"": ""rule:admin_only"", ""stop_network_advertisement"": ""rule:admin_only"", ""get_advertised_routes"":""rule:admin_only"""," ""create_lsn"": ""rule:admin_only""",1488,6
openstack%2Fdevstack~master~If109af452ad583417e3a3a3ef1c9b545f1ec9b89,openstack/devstack,master,If109af452ad583417e3a3a3ef1c9b545f1ec9b89,"Revert ""reduce default lease time to 5 minutes""",MERGED,2016-02-11 11:31:56.000000000,2016-02-14 14:45:40.000000000,2016-02-14 14:45:40.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7118}]","[{'number': 1, 'created': '2016-02-11 11:31:56.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/629e56540f3dec14465bc88ef51c6974bac67f12', 'message': 'Revert ""reduce default lease time to 5 minutes""\n\nWe have a fix in Nova which should make this unessessary,\nrevert to see if that\'s true.\n\nThis reverts commit 61aa0e9f1968c9991dee7bb5aec9a2a63ac0339d.\n\nChange-Id: If109af452ad583417e3a3a3ef1c9b545f1ec9b89\n'}]",0,278995,629e56540f3dec14465bc88ef51c6974bac67f12,8,3,1,2750,,,0,"Revert ""reduce default lease time to 5 minutes""

We have a fix in Nova which should make this unessessary,
revert to see if that's true.

This reverts commit 61aa0e9f1968c9991dee7bb5aec9a2a63ac0339d.

Change-Id: If109af452ad583417e3a3a3ef1c9b545f1ec9b89
",git fetch https://review.opendev.org/openstack/devstack refs/changes/95/278995/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,629e56540f3dec14465bc88ef51c6974bac67f12,dhcp_lease,," # force down dhcp leases to 5 minutes, which lets us expire faster iniset $NOVA_CONF DEFAULT dhcp_lease_time 300",0,2
openstack%2Fdevstack~master~If441c61bb6f13f85f771dd31609b10d3dd1ee93c,openstack/devstack,master,If441c61bb6f13f85f771dd31609b10d3dd1ee93c,worlddump: add empty newline after every command output,MERGED,2016-02-11 12:43:27.000000000,2016-02-14 14:42:51.000000000,2016-02-14 14:42:51.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-11 12:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/479ee04d78ce8396856b10c5e40c3f4e25af4d52', 'message': 'worlddump: add empty newline after every command output\n\nIt makes it a bit easier to read the output since each new command is\nnow visually separated from the output of the previous one.\n\nChange-Id: If441c61bb6f13f85f771dd31609b10d3dd1ee93c\n'}, {'number': 2, 'created': '2016-02-11 15:09:38.000000000', 'files': ['tools/worlddump.py'], 'web_link': 'https://opendev.org/openstack/devstack/commit/190b29d45e15fd7a0fddb89dbb304fb35554814e', 'message': 'worlddump: add empty newline after every command output\n\nIt makes it a bit easier to read the output since each new command is\nnow visually separated from the output of the previous one.\n\nChange-Id: If441c61bb6f13f85f771dd31609b10d3dd1ee93c\n'}]",0,279028,190b29d45e15fd7a0fddb89dbb304fb35554814e,17,5,2,9656,,,0,"worlddump: add empty newline after every command output

It makes it a bit easier to read the output since each new command is
now visually separated from the output of the previous one.

Change-Id: If441c61bb6f13f85f771dd31609b10d3dd1ee93c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/28/279028/2 && git format-patch -1 --stdout FETCH_HEAD,['tools/worlddump.py'],1,479ee04d78ce8396856b10c5e40c3f4e25af4d52,neutron-worlddump, print,,1,0
openstack%2Fdevstack~master~I46a2c36d95327087085df07cb797eb91249a893c,openstack/devstack,master,I46a2c36d95327087085df07cb797eb91249a893c,Only use lsb_release for distro tags,MERGED,2014-08-27 06:16:46.000000000,2016-02-14 14:42:43.000000000,2016-02-14 14:42:43.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5196}, {'_account_id': 7118}, {'_account_id': 7175}, {'_account_id': 7350}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11351}, {'_account_id': 11564}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-08-27 06:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/d9b4b3e2cd783e63d9abc06f5ccaa6233380fb66', 'message': ""[WIP] only use lsb_release for distro tags\n\nAs yet untested change to only use lsb_release.  All that other stuff\nseems pretty unnecessary for the current situation.\n\nlsb_release is pre-installed on all nodepool images, so this shouldn't\ntrigger there.\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}, {'number': 2, 'created': '2014-08-27 07:22:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2e5dc42297c9eb38bdd452df48f95c88944e42e6', 'message': ""[WIP] only use lsb_release for distro tags\n\nAs yet untested change to only use lsb_release.  All that other stuff\nseems pretty unnecessary for the current situation.\n\nlsb_release is pre-installed on all nodepool images, so this shouldn't\ntrigger there.\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}, {'number': 3, 'created': '2014-08-28 00:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2c29f3517721633e559ba010992eda22f5b5c089', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the OSX checking is irrelevant and untested\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove irrelevant osx checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install it is added if it does not exist.\n\n - The unset os_UPDATE is removed -- only in *very* special\n   circumstances would we want to pin something to an update release,\n   as it will break at the next point-release.  These should be\n   handled in-situ\n\n - standarise suse to just ""sles11"" per above change\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 4, 'created': '2014-09-02 11:22:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/56a37ad55f40f7560107a213f197e3cb96603814', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the OSX checking is irrelevant and untested\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove irrelevant osx checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install it is added if it does not exist.\n\n - The unset os_UPDATE is removed -- only in *very* special\n   circumstances would we want to pin something to an update release,\n   as it will break at the next point-release.  These should be\n   handled in-situ\n\n - standarise suse to just ""sles11"" per above change\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 5, 'created': '2014-09-22 01:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f6316dcb29aac86cfe8b96a26cb6a9e3b6510ac8', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - split out OSX checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install it is added if it does not exist.\n\n - The unset os_UPDATE is removed -- only in *very* special\n   circumstances would we want to pin something to an update release,\n   as it will break at the next point-release.  These should be\n   handled in-situ\n\n - standarise suse to just ""sles11"" per above change\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 6, 'created': '2014-10-16 22:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2981b588e06bb3a9e6a0e3eac216d48c126c7493', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - split out OSX checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install it is added if it does not exist.\n\n - The unset os_UPDATE is removed -- only in *very* special\n   circumstances would we want to pin something to an update release,\n   as it will break at the next point-release.  These should be\n   handled in-situ\n\n - standarise suse to just ""sles11"" per above change\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 7, 'created': '2014-11-20 00:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c6eec21c9232749864f8f767f4dc59a985e78ad8', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - split out OSX checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install it is added if it does not exist.\n\n - The unset os_UPDATE is removed -- only in *very* special\n   circumstances would we want to pin something to an update release,\n   as it will break at the next point-release.  These should be\n   handled in-situ\n\n - standarise suse to just ""sles11"" per above change\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 8, 'created': '2015-12-03 02:46:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7e962d5143841deed1c2f233700a0befa6a5a110', 'message': 'only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it\'s pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - If using lsb_release, os_UPDATE has never actually been set.\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I\'m guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - split out OSX checking\n\n - only use the output of lsb_release.\n\n - A small check to pre-install lsb packages if not detected (that\n   avoids chicken-egg-problem of package-install wrappers relying on\n   os_* flags)\n\n - The largely unset os_UPDATE is removed, ergo os_RELEASE is just the\n   output of ""lsb_release -r""\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n'}, {'number': 9, 'created': '2015-12-03 23:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/b988fe24935a7be1b563b8e8c11ed732737a2b1b', 'message': ""Only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it's pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - If using lsb_release, os_UPDATE has never actually been set.\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I'm guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove OSX checking (moved here after discussions in\n   I31d0fdd30928ecc8d959a95838b1d3affd28ac6f)\n\n - only use the output of lsb_release.\n\n - A small best-effort check to pre-install lsb packages if not\n   detected (that avoids chicken-egg-problem of package-install\n   wrappers relying on os_* flags).\n\n - The unset os_UPDATE is removed.  It's only previous use was for\n   setting separate suse versions in the DISTRO element for matching\n   during package installs (since removed) -- the same could be\n   achieved by parsing os_RELEASE if required.\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}, {'number': 10, 'created': '2015-12-04 00:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3055dbb64b480f6121abc15af6889d8ad3cf08d2', 'message': ""Only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it's pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - If using lsb_release, os_UPDATE has never actually been set.\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I'm guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove OSX checking (moved here after discussions in\n   I31d0fdd30928ecc8d959a95838b1d3affd28ac6f)\n\n - only use the output of lsb_release.\n\n - A small best-effort check to pre-install lsb packages if not\n   detected (that avoids chicken-egg-problem of package-install\n   wrappers relying on os_* flags).\n\n - The unset os_UPDATE is removed.  It's only previous use was for\n   setting separate suse versions in the DISTRO element for matching\n   during package installs (since removed)\n\n - DISTRO setting is modified to use the parts of os_RELEASE it wants.\n   Per-above, this is the correct place to parse out specifics.\n\n - Call out the is_* functions, which are a better way to detect\n   platforms\n\n - Export the variables as read-only, since they shouldn't be reset\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}, {'number': 11, 'created': '2015-12-08 04:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a34dad6220a5f00e236acedc2466a640ba630b26', 'message': ""Only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it's pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - If using lsb_release, os_UPDATE has never actually been set.\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I'm guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove OSX checking (moved here after discussions in\n   I31d0fdd30928ecc8d959a95838b1d3affd28ac6f)\n\n - only use the output of lsb_release.\n\n - A small best-effort check to pre-install lsb packages if not\n   detected (that avoids chicken-egg-problem of package-install\n   wrappers relying on os_* flags).\n\n - The unset os_UPDATE is removed.  It's only previous use was for\n   setting separate suse versions in the DISTRO element for matching\n   during package installs (since removed)\n\n - DISTRO setting is modified to use the parts of os_RELEASE it wants.\n   Per-above, this is the correct place to parse out specifics.\n\n - Call out the is_* functions, which are a better way to detect\n   platforms\n\n - Export the variables as read-only, since they shouldn't be reset\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}, {'number': 12, 'created': '2016-01-11 22:24:01.000000000', 'files': ['tools/create-stack-user.sh', 'clean.sh', 'tools/info.sh', 'functions-common', 'unstack.sh', 'tools/install_prereqs.sh', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7710e7fc273dd9af6799ea565bbd21ce03745a44', 'message': ""Only use lsb_release for distro tags\n\nThe existing GetOSVersion has a lot of unused code which is wrong in\nseveral ways\n\n - the only path tested in upstream CI is with lsb_release, because\n   it's pre-installed on all nodes\n\n - the /etc/redhat-release checking probably still works, but is\n   unnecessary\n\n - If using lsb_release, os_UPDATE has never actually been set.\n\n - the /etc/SuSE-release branch checking is broken if the lsb package\n   is actually installed.  lsb checking does not set os_UPDATE but yet\n   the SuSE DISTRO setting relies on this to set a patch level (and so\n   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm\n   matching is stuck hard-coded to update 2.  I'm guessing\n   installation is actually broken there.\n\n - the debian checking branch is broken.  The VERSION tags have been\n   removed and were not supposed to be relied on anyway (see notes in\n   [1])\n\nThis simplifies things:\n\n - remove OSX checking (moved here after discussions in\n   I31d0fdd30928ecc8d959a95838b1d3affd28ac6f)\n\n - only use the output of lsb_release.\n\n - A small best-effort check to pre-install lsb packages if not\n   detected (that avoids chicken-egg-problem of package-install\n   wrappers relying on os_* flags).\n\n - The unset os_UPDATE is removed.  It's only previous use was for\n   setting separate suse versions in the DISTRO element for matching\n   during package installs (since removed)\n\n - DISTRO setting is modified to use the parts of os_RELEASE it wants.\n   Per-above, this is the correct place to parse out specifics.\n\n - Call out the is_* functions, which are a better way to detect\n   platforms\n\n - Export the variables as read-only, since they shouldn't be reset\n\n[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/\n\nChange-Id: I46a2c36d95327087085df07cb797eb91249a893c\n""}]",28,117104,7710e7fc273dd9af6799ea565bbd21ce03745a44,99,16,12,7118,,,0,"Only use lsb_release for distro tags

The existing GetOSVersion has a lot of unused code which is wrong in
several ways

 - the only path tested in upstream CI is with lsb_release, because
   it's pre-installed on all nodes

 - the /etc/redhat-release checking probably still works, but is
   unnecessary

 - If using lsb_release, os_UPDATE has never actually been set.

 - the /etc/SuSE-release branch checking is broken if the lsb package
   is actually installed.  lsb checking does not set os_UPDATE but yet
   the SuSE DISTRO setting relies on this to set a patch level (and so
   does some of the rpm tags).  SuSE 11 is up to update 3, but the rpm
   matching is stuck hard-coded to update 2.  I'm guessing
   installation is actually broken there.

 - the debian checking branch is broken.  The VERSION tags have been
   removed and were not supposed to be relied on anyway (see notes in
   [1])

This simplifies things:

 - remove OSX checking (moved here after discussions in
   I31d0fdd30928ecc8d959a95838b1d3affd28ac6f)

 - only use the output of lsb_release.

 - A small best-effort check to pre-install lsb packages if not
   detected (that avoids chicken-egg-problem of package-install
   wrappers relying on os_* flags).

 - The unset os_UPDATE is removed.  It's only previous use was for
   setting separate suse versions in the DISTRO element for matching
   during package installs (since removed)

 - DISTRO setting is modified to use the parts of os_RELEASE it wants.
   Per-above, this is the correct place to parse out specifics.

 - Call out the is_* functions, which are a better way to detect
   platforms

 - Export the variables as read-only, since they shouldn't be reset

[1] http://sources.debian.net/src/base-files/7.5/debian/changelog/

Change-Id: I46a2c36d95327087085df07cb797eb91249a893c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/04/117104/6 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,d9b4b3e2cd783e63d9abc06f5ccaa6233380fb66,use_lsb,"declare os_VENDOR os_RELEASE os_PACKAGE os_CODENAME # can't use generic install_package* because they depend on this if [[ ! -x $(which lsb_release 2>/dev/null) ]]; then if [ -x /usr/bin/apt-get ]; sudo apt-get install -y lsb-release elif [ -x /usr/bin/yum ]; local lsb_pkg=lsb if [ -f /etc/redhat-release ]; then lsb_pkg=redhat-lsb fi sudo yum install -y ${lsb_pkg} die $LINENO ""Can not find lsb_release"" os_VENDOR=$(lsb_release -i -s) os_RELEASE=$(lsb_release -r -s) os_CODENAME=$(lsb_release -c -s) os_PACKAGE=""rpm"" if [[ ""Debian,Ubuntu,LinuxMint"" =~ $os_VENDOR ]]; os_PACKAGE=""deb"" fi if [[ ""SUSE LINUX"" =~ $os_VENDOR ]]; then if lsb_release -d -s | grep -q openSUSE ; then os_VENDOR=""openSUSE"" fi elif [[ $os_VENDOR == ""openSUSE project"" ]]; then os_VENDOR=""openSUSE"" elif [[ $os_VENDOR =~ Red.*Hat ]]; then os_VENDOR=""Red Hat"" fi ","# ``os_UPDATE`` - update: ex. the ``5`` in ``RHEL6.5``declare os_VENDOR os_RELEASE os_UPDATE os_PACKAGE os_CODENAME # Figure out which vendor we are if [[ -x ""`which sw_vers 2>/dev/null`"" ]]; then # OS/X os_VENDOR=`sw_vers -productName` os_RELEASE=`sw_vers -productVersion` os_UPDATE=${os_RELEASE##*.} os_RELEASE=${os_RELEASE%.*} os_PACKAGE="""" if [[ ""$os_RELEASE"" =~ ""10.7"" ]]; then os_CODENAME=""lion"" elif [[ ""$os_RELEASE"" =~ ""10.6"" ]]; then os_CODENAME=""snow leopard"" elif [[ ""$os_RELEASE"" =~ ""10.5"" ]]; then os_CODENAME=""leopard"" elif [[ ""$os_RELEASE"" =~ ""10.4"" ]]; then os_CODENAME=""tiger"" elif [[ ""$os_RELEASE"" =~ ""10.3"" ]]; then os_CODENAME=""panther"" os_CODENAME="""" elif [[ -x $(which lsb_release 2>/dev/null) ]]; then os_VENDOR=$(lsb_release -i -s) os_RELEASE=$(lsb_release -r -s) os_UPDATE="""" os_PACKAGE=""rpm"" if [[ ""Debian,Ubuntu,LinuxMint"" =~ $os_VENDOR ]]; then os_PACKAGE=""deb"" elif [[ ""SUSE LINUX"" =~ $os_VENDOR ]]; then lsb_release -d -s | grep -q openSUSE if [[ $? -eq 0 ]]; then os_VENDOR=""openSUSE"" fi elif [[ $os_VENDOR == ""openSUSE project"" ]]; then os_VENDOR=""openSUSE"" elif [[ $os_VENDOR =~ Red.*Hat ]]; then os_VENDOR=""Red Hat"" fi os_CODENAME=$(lsb_release -c -s) elif [[ -r /etc/redhat-release ]]; then # Red Hat Enterprise Linux Server release 5.5 (Tikanga) # Red Hat Enterprise Linux Server release 7.0 Beta (Maipo) # CentOS release 5.5 (Final) # CentOS Linux release 6.0 (Final) # Fedora release 16 (Verne) # XenServer release 6.2.0-70446c (xenenterprise) os_CODENAME="""" for r in ""Red Hat"" CentOS Fedora XenServer; do os_VENDOR=$r if [[ -n ""`grep \""$r\"" /etc/redhat-release`"" ]]; then ver=`sed -e 's/^.* \([0-9].*\) (\(.*\)).*$/\1\|\2/' /etc/redhat-release` os_CODENAME=${ver#*|} os_RELEASE=${ver%|*} os_UPDATE=${os_RELEASE##*.} os_RELEASE=${os_RELEASE%.*} break fi os_VENDOR="""" done os_PACKAGE=""rpm"" elif [[ -r /etc/SuSE-release ]]; then for r in openSUSE ""SUSE Linux""; do if [[ ""$r"" = ""SUSE Linux"" ]]; then os_VENDOR=""SUSE LINUX"" else os_VENDOR=$r fi if [[ -n ""`grep \""$r\"" /etc/SuSE-release`"" ]]; then os_CODENAME=`grep ""CODENAME = "" /etc/SuSE-release | sed 's:.* = ::g'` os_RELEASE=`grep ""VERSION = "" /etc/SuSE-release | sed 's:.* = ::g'` os_UPDATE=`grep ""PATCHLEVEL = "" /etc/SuSE-release | sed 's:.* = ::g'` break fi os_VENDOR="""" done os_PACKAGE=""rpm"" # If lsb_release is not installed, we should be able to detect Debian OS elif [[ -f /etc/debian_version ]] && [[ $(cat /proc/version) =~ ""Debian"" ]]; then os_VENDOR=""Debian"" os_PACKAGE=""deb"" os_CODENAME=$(awk '/VERSION=/' /etc/os-release | sed 's/VERSION=//' | sed -r 's/\""|\(|\)//g' | awk '{print $2}') os_RELEASE=$(awk '/VERSION_ID=/' /etc/os-release | sed 's/VERSION_ID=//' | sed 's/\""//g')",32,83
openstack%2Fdevstack~stable%2Fliberty~Idfdc54210e33c71719c7fd0c905d0b802809e173,openstack/devstack,stable/liberty,Idfdc54210e33c71719c7fd0c905d0b802809e173,Set unprovision and active timeout to match build_timeout,MERGED,2016-02-10 23:27:17.000000000,2016-02-14 14:42:36.000000000,2016-02-14 14:42:36.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 7118}, {'_account_id': 10342}, {'_account_id': 10343}, {'_account_id': 11655}, {'_account_id': 14760}]","[{'number': 1, 'created': '2016-02-10 23:27:17.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/bcc239f30f4656f054b124cf4a47b1ecfafde939', 'message': 'Set unprovision and active timeout to match build_timeout\n\nThe build_timeout for the ironic baremetal build is at\n340s. Modify the unprovision_timeout and active_timeout\nto match BUILD_TIMEOUT to avoid frequent failures during\nIPA gate jobs.\n\nChange-Id: Idfdc54210e33c71719c7fd0c905d0b802809e173\nRelated-Bug: #1393099\n(cherry picked from commit ad69e69e3f278bd28319224035997e11477617c4)\n'}]",0,278792,bcc239f30f4656f054b124cf4a47b1ecfafde939,20,7,1,5805,,,0,"Set unprovision and active timeout to match build_timeout

The build_timeout for the ironic baremetal build is at
340s. Modify the unprovision_timeout and active_timeout
to match BUILD_TIMEOUT to avoid frequent failures during
IPA gate jobs.

Change-Id: Idfdc54210e33c71719c7fd0c905d0b802809e173
Related-Bug: #1393099
(cherry picked from commit ad69e69e3f278bd28319224035997e11477617c4)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/278792/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,bcc239f30f4656f054b124cf4a47b1ecfafde939,increase-timeouts, iniset $TEMPEST_CONFIG baremetal unprovision_timeout $BUILD_TIMEOUT iniset $TEMPEST_CONFIG baremetal active_timeout $BUILD_TIMEOUT, iniset $TEMPEST_CONFIG baremetal unprovision_timeout 300,2,1
openstack%2Fdevstack~master~I37d5012e89cb3650e4f325b6d77d70f28f87d3e7,openstack/devstack,master,I37d5012e89cb3650e4f325b6d77d70f28f87d3e7,Remove Neutron Midonet plugin file completely,MERGED,2016-01-13 14:25:14.000000000,2016-02-14 14:42:29.000000000,2016-02-14 14:42:28.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1653}, {'_account_id': 2750}, {'_account_id': 6854}]","[{'number': 1, 'created': '2016-01-13 14:25:14.000000000', 'files': ['lib/neutron_plugins/midonet'], 'web_link': 'https://opendev.org/openstack/devstack/commit/7e843edca791224eea1d53fc963267dded0c220b', 'message': 'Remove Neutron Midonet plugin file completely\n\noverride-defaults mechanism allows us to define\ns_neutron_plugin_security_group before loading lib/neutron,\nand we no longer need to have a plugin-specific file in\nthe master DevStack repository.\n\nChange-Id: I37d5012e89cb3650e4f325b6d77d70f28f87d3e7\nDepends-On: I5e02acd288e53dd06a369d348ec77ead57d476fd\n'}]",1,266938,7e843edca791224eea1d53fc963267dded0c220b,14,5,1,841,,,0,"Remove Neutron Midonet plugin file completely

override-defaults mechanism allows us to define
s_neutron_plugin_security_group before loading lib/neutron,
and we no longer need to have a plugin-specific file in
the master DevStack repository.

Change-Id: I37d5012e89cb3650e4f325b6d77d70f28f87d3e7
Depends-On: I5e02acd288e53dd06a369d348ec77ead57d476fd
",git fetch https://review.opendev.org/openstack/devstack refs/changes/38/266938/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/midonet'],1,7e843edca791224eea1d53fc963267dded0c220b,cleanup-neutron-plugin-midonet,,"#!/bin/bash # REVISIT(devvesa): This file is needed so Q_PLUGIN=midonet will work. # FIXME(yamamoto): This function should not be here, but unfortunately # devstack calls it before the external plugins are fetched function has_neutron_plugin_security_group { # 0 means True here return 0 } ",0,10
openstack%2Fdevstack~master~I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5,openstack/devstack,master,I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5,Enable neutron-lib for LIBS_FROM_GIT for backwards compat jobs,MERGED,2016-02-11 01:37:31.000000000,2016-02-14 14:42:21.000000000,2016-02-14 14:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10980}]","[{'number': 1, 'created': '2016-02-11 01:37:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/4c8f73223d5789bbcb09a93aeba97c5091b9cb52', 'message': 'Enable neutron-lib for LIBS_FROM_GIT for backwards compat jobs\n\nChange-Id: I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5\n'}, {'number': 2, 'created': '2016-02-11 03:52:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/29a95f716cac3114e6d9cb10873370f96300112d', 'message': 'Enable neutron-lib for LIBS_FROM_GIT for backwards compat jobs\n\nChange-Id: I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5\n'}, {'number': 3, 'created': '2016-02-11 18:01:13.000000000', 'files': ['tests/test_libs_from_pypi.sh', 'stackrc', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/86561c347d70c5124c139eb80fe1c0466e5a62f2', 'message': 'Enable neutron-lib for LIBS_FROM_GIT for backwards compat jobs\n\nChange-Id: I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5\n'}]",0,278823,86561c347d70c5124c139eb80fe1c0466e5a62f2,25,8,3,10980,,,0,"Enable neutron-lib for LIBS_FROM_GIT for backwards compat jobs

Change-Id: I8dd84c59d2ec3a7c01ff4f1aaf7fa61d7466cfd5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/23/278823/3 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_libs_from_pypi.sh', 'stackrc', 'lib/neutron-legacy']",3,4c8f73223d5789bbcb09a93aeba97c5091b9cb52,libs-from-git-neutron-lib," # Install neutron-lib from git so we make sure we're testing # the latest code. if use_library_from_git ""neutron-lib""; then git_clone_by_name ""neutron-lib"" setup_dev_lib ""neutron-lib"" fi ",,11,1
openstack%2Fcinder~master~I9a1fa59700233335fa50b02ff6cc3085a9e25b7a,openstack/cinder,master,I9a1fa59700233335fa50b02ff6cc3085a9e25b7a,EMC VMAX - Method not being called for V3,MERGED,2015-12-01 21:12:46.000000000,2016-02-14 14:25:35.000000000,2016-02-11 02:03:37.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 8122}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12670}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13915}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 14865}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17450}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19191}, {'_account_id': 19371}, {'_account_id': 19852}, {'_account_id': 19904}, {'_account_id': 19917}]","[{'number': 1, 'created': '2015-12-01 21:12:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/edaf781ceaa7ae89c03838eccf6791342e410139', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 2, 'created': '2015-12-03 01:16:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/aa04e70a5f4f9841bb18e7bf5a5ff64f1a1c5604', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 3, 'created': '2015-12-07 13:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5c1f914ee449386920da4b78e8d4bedf7f5e8c01', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 4, 'created': '2015-12-15 03:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14483b603d0bb28afb52f8882574bf68f561f7e7', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 5, 'created': '2015-12-17 22:52:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1846e16550fe11a029a3d10860194fc15a054419', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 6, 'created': '2015-12-20 21:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4b5b15a7977de82a228f93c27535b3e5ba1272ed', 'message': 'EMC VMAX - _remove_last_vol_and_delete_sg not being called for V3\n\nThe method to remove the last volume and delete the storage group\nwas not being called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 7, 'created': '2016-01-20 10:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/3be6010e9c7c6b6600811518c233d327fb618761', 'message': 'EMC VMAX - Method not being called for V3\n\nThe method _remove_last_vol_and_delete_sg to remove\nthe last volume and delete the storage group was not\nbeing called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 8, 'created': '2016-01-27 20:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ff5bafa2762b35427631ae81d7dfb1e3f8eedc1', 'message': 'EMC VMAX - Method not being called for V3\n\nThe method _remove_last_vol_and_delete_sg to remove\nthe last volume and delete the storage group was not\nbeing called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 9, 'created': '2016-01-30 20:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b7a460a49526252ecd114fbd51453c2a1d35c5b', 'message': 'EMC VMAX - Method not being called for V3\n\nThe method _remove_last_vol_and_delete_sg to remove\nthe last volume and delete the storage group was not\nbeing called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 10, 'created': '2016-02-04 11:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/7226696937d1bfcab7a8c1a5db3e418edf1696ac', 'message': 'EMC VMAX - Method not being called for V3\n\nThe method _remove_last_vol_and_delete_sg to remove\nthe last volume and delete the storage group was not\nbeing called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}, {'number': 11, 'created': '2016-02-05 00:09:18.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_fc.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/tests/unit/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/521617e11783d4f39758b738da0ff9aa8bdc703d', 'message': 'EMC VMAX - Method not being called for V3\n\nThe method _remove_last_vol_and_delete_sg to remove\nthe last volume and delete the storage group was not\nbeing called for the VMAX3, due to an indentation error.\n\nChange-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a\nCloses-Bug: #1520549\n'}]",12,252066,521617e11783d4f39758b738da0ff9aa8bdc703d,435,65,11,12670,,,0,"EMC VMAX - Method not being called for V3

The method _remove_last_vol_and_delete_sg to remove
the last volume and delete the storage group was not
being called for the VMAX3, due to an indentation error.

Change-Id: I9a1fa59700233335fa50b02ff6cc3085a9e25b7a
Closes-Bug: #1520549
",git fetch https://review.opendev.org/openstack/cinder refs/changes/66/252066/11 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_fc.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_iscsi.py', 'cinder/tests/unit/test_emc_vmax.py']",4,edaf781ceaa7ae89c03838eccf6791342e410139,bug/1520549," def test_cleanup_last_vol(self): conn = FakeEcomConnection() masking = self.driver.common.masking extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': True} controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageGroupInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstance = EMC_StorageVolume() volumeInstance.path = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = self.data.test_volume['name'] masking._last_volume_delete_masking_view = mock.Mock() storageSystemInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageSystem"")[0]) # Failure case, an exception is thrown in # _remove_last_vol_and_delete_sg so the returning the vol to # the default SG cannot continue self.assertRaises( exception.VolumeBackendAPIException, masking._cleanup_last_vol, conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstance, volumeName, storageSystemInstanceName, False, extraSpecs) # Success case, the last vol is removed and the SG is deleted masking._remove_last_vol_and_delete_sg = mock.Mock(return_value=True) masking._cleanup_last_vol( conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstance, volumeName, storageSystemInstanceName, False, extraSpecs) ",,80,8
openstack%2Fkarbor~master~If6e30250b34ffcbaa9a8458e679d5bc93dbecc73,openstack/karbor,master,If6e30250b34ffcbaa9a8458e679d5bc93dbecc73,Move protection service,MERGED,2016-02-09 13:26:55.000000000,2016-02-14 14:12:47.000000000,2016-02-14 14:12:47.000000000,"[{'_account_id': 3}, {'_account_id': 11904}, {'_account_id': 13070}, {'_account_id': 17151}]","[{'number': 1, 'created': '2016-02-09 13:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/198a03444edfec41acd519acdabdc4c4da6a09c2', 'message': ""Move protection service\n\nThis moves the protection service code to a new subdirectory called\n'services' this is so that all the services are neatly structured in the\nfile system hierarchy.\n\nThis code should have no functional differences from the original code.\nAll code changes are only to facilitate this move.\n\nChange-Id: If6e30250b34ffcbaa9a8458e679d5bc93dbecc73\n""}, {'number': 2, 'created': '2016-02-14 13:12:49.000000000', 'files': ['smaug/services/protection/protection_plugin.py', 'smaug/services/protection/checkpoint.py', 'smaug/services/protection/manager.py', 'smaug/services/__init__.py', 'smaug/services/protection/__init__.py', 'smaug/tests/unit/protection/test_manager.py', 'smaug/services/protection/rpcapi.py', 'smaug/services/protection/provider.py', 'smaug/services/protection/api.py', 'smaug/common/config.py', 'smaug/services/protection/bank_plugin.py', 'smaug/operationengine/manager.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/a1a0bbba7722a41fa804273644febe283e936fad', 'message': ""Move protection service\n\nThis moves the protection service code to a new subdirectory called\n'services' this is so that all the services are neatly structured in\nthe file system hierarchy.\n\nThis code should have no functional differences from the original code.\nAll code changes are only to facilitate this move.\n\nChange-Id: If6e30250b34ffcbaa9a8458e679d5bc93dbecc73\n""}]",0,277827,a1a0bbba7722a41fa804273644febe283e936fad,12,4,2,2023,,,0,"Move protection service

This moves the protection service code to a new subdirectory called
'services' this is so that all the services are neatly structured in
the file system hierarchy.

This code should have no functional differences from the original code.
All code changes are only to facilitate this move.

Change-Id: If6e30250b34ffcbaa9a8458e679d5bc93dbecc73
",git fetch https://review.opendev.org/openstack/karbor refs/changes/27/277827/1 && git format-patch -1 --stdout FETCH_HEAD,"['smaug/services/protection/protection_plugin.py', 'smaug/services/protection/checkpoint.py', 'smaug/services/protection/manager.py', 'smaug/services/__init__.py', 'smaug/services/protection/__init__.py', 'smaug/tests/unit/protection/test_manager.py', 'smaug/services/protection/rpcapi.py', 'smaug/services/protection/provider.py', 'smaug/services/protection/api.py', 'smaug/common/config.py', 'smaug/services/protection/bank_plugin.py', 'smaug/operationengine/manager.py']",12,198a03444edfec41acd519acdabdc4c4da6a09c2,service_move,from smaug.services.protection import api as protection_api,from smaug.protection import api as protection_api,5,5
openstack%2Fsahara~master~I9a46a503c7e52d756c7de8c8694dbfc51f80f2be,openstack/sahara,master,I9a46a503c7e52d756c7de8c8694dbfc51f80f2be,Added support of Spark 1.6.0,MERGED,2016-02-05 13:42:52.000000000,2016-02-14 14:10:05.000000000,2016-02-14 14:10:05.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 8932}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-02-05 13:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7a225dc4c10f129cf5aa65aa268f0ce642506d66', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment\n\nChange-Id: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nDepends-on: Id3c4fb5a0cb1349824972c1be90ea0e0be64cb4b\nCo-Authored-By: Vitaly Gridnev <vgridnev@mirantis.com>\nbp: support-spark-160\n'}, {'number': 2, 'created': '2016-02-05 13:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/392bd12408c9204ce023ffb60dc1bd70366bb1c0', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment\n\nChange-Id: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nCo-Authored-By: Vitaly Gridnev <vgridnev@mirantis.com>\nbp: support-spark-160\n'}, {'number': 3, 'created': '2016-02-05 15:43:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5dfc16df2c2bd59f146ad54eb502043ea6bf9a89', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment.\nAlso added injection of spark.xml into jar to allow correct work with\nswift datasourceses\n\nChange-Id: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nCo-Authored-By: Vitaly Gridnev <vgridnev@mirantis.com>\nbp: support-spark-160\n'}, {'number': 4, 'created': '2016-02-08 16:58:21.000000000', 'files': ['sahara/service/edp/spark/engine.py', 'sahara/plugins/spark/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/47d9e68d6e9a40c758d847eced028d954594eca0', 'message': 'Added support of Spark 1.6.0\n\nSpark 1.6.0 is available now for deployment.\nAlso added the current working directory to the driver class path for\nproper reading of the spark.xml file\n\nChange-Id: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be\nCo-Authored-By: Vitaly Gridnev <vgridnev@mirantis.com>\nbp: support-spark-160\n'}]",2,276734,47d9e68d6e9a40c758d847eced028d954594eca0,21,9,4,19372,,,0,"Added support of Spark 1.6.0

Spark 1.6.0 is available now for deployment.
Also added the current working directory to the driver class path for
proper reading of the spark.xml file

Change-Id: I9a46a503c7e52d756c7de8c8694dbfc51f80f2be
Co-Authored-By: Vitaly Gridnev <vgridnev@mirantis.com>
bp: support-spark-160
",git fetch https://review.opendev.org/openstack/sahara refs/changes/34/276734/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/spark/engine.py', 'sahara/plugins/spark/plugin.py']",2,7a225dc4c10f129cf5aa65aa268f0ce642506d66,bp/support-spark-160," return ['1.6.0', '1.3.1', '1.0.0']"," return ['1.3.1', '1.0.0']",10,1
openstack%2Fsahara~master~Id19eeae194d7e4c97f041e067f1ee8a57a675815,openstack/sahara,master,Id19eeae194d7e4c97f041e067f1ee8a57a675815,Add regex matching for job_list(),MERGED,2016-02-10 22:16:54.000000000,2016-02-14 14:09:58.000000000,2016-02-14 14:09:58.000000000,"[{'_account_id': 3}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-10 22:16:54.000000000', 'files': ['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2f9d4f5a80296ac1298bdf4c9c4cdd6f9233452f', 'message': 'Add regex matching for job_list()\n\n    This change implements regex matching for filters on string\n    values passed to job_list() in the REST api.\n    No existing internal calls that use job_get_all()\n    are affected.\n\n    Partial-bug: #1503345\n\nChange-Id: Id19eeae194d7e4c97f041e067f1ee8a57a675815\n'}]",0,278766,2f9d4f5a80296ac1298bdf4c9c4cdd6f9233452f,7,3,1,8091,,,0,"Add regex matching for job_list()

    This change implements regex matching for filters on string
    values passed to job_list() in the REST api.
    No existing internal calls that use job_get_all()
    are affected.

    Partial-bug: #1503345

Change-Id: Id19eeae194d7e4c97f041e067f1ee8a57a675815
",git fetch https://review.opendev.org/openstack/sahara refs/changes/66/278766/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py']",6,2f9d4f5a80296ac1298bdf4c9c4cdd6f9233452f,bug/1503345," def job_get_all(self, context, regex_search=False, **kwargs): :param context: The context, and associated authentication, to use with this operation :param regex_search: If True, enable regex matching for filter values. See the user guide for more information on how regex matching is handled. If False, no regex matching is done. :param kwargs: Specifies values for named fields by which to constrain the search return self.db.job_get_all(context, regex_search, **kwargs)"," def job_get_all(self, context, **kwargs): e.g. job_get_all(name='myjob', type='MapReduce') return self.db.job_get_all(context, **kwargs)",80,16
openstack%2Fsahara~master~Id34696ca128214ebb555980ca1f9f068dabc1a11,openstack/sahara,master,Id34696ca128214ebb555980ca1f9f068dabc1a11,Add regex matching for job_binary_list(),MERGED,2016-02-10 21:21:32.000000000,2016-02-14 14:09:51.000000000,2016-02-14 14:09:51.000000000,"[{'_account_id': 3}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-10 21:21:32.000000000', 'files': ['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/12db2b72e15dfe12daccc1869df99310896f915c', 'message': 'Add regex matching for job_binary_list()\n\nThis change implements regex matching for filters on string\nvalues passed to job_binary_list() in the REST api.\nNo existing internal calls that use job_binary_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: Id34696ca128214ebb555980ca1f9f068dabc1a11\n'}]",0,278640,12db2b72e15dfe12daccc1869df99310896f915c,7,3,1,8091,,,0,"Add regex matching for job_binary_list()

This change implements regex matching for filters on string
values passed to job_binary_list() in the REST api.
No existing internal calls that use job_binary_get_all()
are affected.

Partial-bug: #1503345

Change-Id: Id34696ca128214ebb555980ca1f9f068dabc1a11
",git fetch https://review.opendev.org/openstack/sahara refs/changes/40/278640/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py']",6,12db2b72e15dfe12daccc1869df99310896f915c,bug/1503345," def job_binary_get_all(self, context, regex_search=False, **kwargs): :param context: The context, and associated authentication, to use with this operation :param regex_search: If True, enable regex matching for filter values. See the user guide for more information on how regex matching is handled. If False, no regex matching is done. :param kwargs: Specifies values for named fields by which to constrain the search return self.db.job_binary_get_all(context, regex_search, **kwargs)"," def job_binary_get_all(self, context, **kwargs): return self.db.job_binary_get_all(context, **kwargs)",82,18
openstack%2Fsahara~master~I906ddf6dc27336c39b7ccf298b0e3558ec86178b,openstack/sahara,master,I906ddf6dc27336c39b7ccf298b0e3558ec86178b,Add regex matching for data_sources_list(),MERGED,2016-02-01 23:47:11.000000000,2016-02-14 14:01:29.000000000,2016-02-14 14:01:29.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 18777}]","[{'number': 1, 'created': '2016-02-01 23:47:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4527e3731193b3a23574724fa204b127ebd32341', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 2, 'created': '2016-02-01 23:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4d44961c04e2c9423f119befe1e46b3b97ce0dab', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 3, 'created': '2016-02-02 18:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9d4677bf55cf0ceb8c41ef4d2ec886a29cbccb65', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 4, 'created': '2016-02-02 18:58:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/79ddf38fc73db81ac4c8064f500c7c1137cfb008', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 5, 'created': '2016-02-02 19:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/efdf256dc0ad113a3a4db2dcec3af15646b7770f', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 6, 'created': '2016-02-10 19:17:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f8e21edec442e151dfe8597a1d48cfc7d673768', 'message': 'Add substring matching for data_sources_list()\n\nThis change implements substring matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}, {'number': 7, 'created': '2016-02-10 19:59:23.000000000', 'files': ['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/d842d600ada126ef134def7a3e39a1afea3d1770', 'message': 'Add regex matching for data_sources_list()\n\nThis change implements regex matching for filters on string\nvalues passed to data_sources_list() in the REST api.\nNo existing internal calls that use data_sources_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b\n'}]",2,274940,d842d600ada126ef134def7a3e39a1afea3d1770,27,8,7,8091,,,0,"Add regex matching for data_sources_list()

This change implements regex matching for filters on string
values passed to data_sources_list() in the REST api.
No existing internal calls that use data_sources_get_all()
are affected.

Partial-bug: #1503345

Change-Id: I906ddf6dc27336c39b7ccf298b0e3558ec86178b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/40/274940/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py']",6,4527e3731193b3a23574724fa204b127ebd32341,bug/1503345," def data_source_get_all(self, context, substr_search=False, **kwargs): return self.db.data_source_get_all(context, substr_search, **kwargs)"," def data_source_get_all(self, context, **kwargs): return self.db.data_source_get_all(context, **kwargs)",82,8
openstack%2Fkarbor~master~Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c,openstack/karbor,master,Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c,Basic design doc for Bank Plugin lease,MERGED,2016-01-19 09:28:45.000000000,2016-02-14 13:49:43.000000000,2016-02-14 13:49:43.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 10068}, {'_account_id': 13070}, {'_account_id': 15069}, {'_account_id': 16203}, {'_account_id': 17151}, {'_account_id': 19346}, {'_account_id': 19720}]","[{'number': 1, 'created': '2016-01-19 09:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/4cb2fe44d19040d597c6113a918dbdfe1513321f', 'message': 'Basic design doc for Bank Plugin lease\ndesign document for Bank Plugin lease\n\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 2, 'created': '2016-01-19 09:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/b665d25768427d8f102ec2218d55752246ee41fb', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 3, 'created': '2016-01-20 01:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/74543f5937a1cdca4ed7300f2c2f9c25180a9309', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nCloses-Bug: #1529199\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 4, 'created': '2016-01-20 01:23:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/6cef6d3453f834fbce81739cbc98f7dc8b012be4', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nCloses-Bug: #1529199\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 5, 'created': '2016-01-21 01:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/0ab47e30e2c90397e77105d2d90406aca8003d81', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nCloses-Bug: #1529199\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 6, 'created': '2016-01-28 03:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor/commit/cb1aab33d4766e269e823a829adabf171e3fc6aa', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nCloses-Bug: #1529199\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}, {'number': 7, 'created': '2016-02-01 01:37:59.000000000', 'files': ['doc/source/specs/index.rst', 'doc/source/specs/bank-plugin-lease.rst'], 'web_link': 'https://opendev.org/openstack/karbor/commit/4cd1110dbe890bc312c85c5773423437fa76b269', 'message': 'Basic design doc for Bank Plugin lease\n\ndesign document for Bank Plugin lease\n\nCloses-Bug: #1529199\nChange-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c\n'}]",5,269509,4cd1110dbe890bc312c85c5773423437fa76b269,36,9,7,19345,,,0,"Basic design doc for Bank Plugin lease

design document for Bank Plugin lease

Closes-Bug: #1529199
Change-Id: Iaaeb7d50e998f68ba53414932d72cd3a2dbb339c
",git fetch https://review.opendev.org/openstack/karbor refs/changes/09/269509/6 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/protection-service/bank-plugin-lease.rst'],1,4cb2fe44d19040d597c6113a918dbdfe1513321f,bug/1529199,"================= Bank Plugin Basic ================= Bank Plugin is a component of smaug (an openstack project working as a service for data protection), which is responsible for execute CRUD actions in Bank. The bank is a backend (such as swift) which is used to store the metadata/data of protection checkpoints. Here, we take swift as an bank implementation example. ******* leases ******* Checkpoint is maitained with status, which is a enum type: protecting, available, restoring, deleted, etc. The status is used for smaug API layer to control access to one checkpoint from users. With the 'protecting' status, there're two cases which we can't tell the difference: 1. The protection service is working and those 'protecting' checkpoints are being executed; 2. When the Protection Service crushes, those 'protecting' checkpoints are actually zombie ones; In the second case, we need a garbage collection component (GC) to cleanup those zombie checkpoints. In order to tell whether the checkpoint is being executed or a zombie, we introduce a lease mechanism based on bank plugin. Here, we take swift as an example. The lease is stored as an object in swift with the characteristics of auto-deleted. The owner of one checkpoint will periodically refresh the expire time of the lease object key. When the protection service crushes, the leases of bank plugins will be auto-deleted by the swift-object-expirer(one service of swift). When GC comes to check whether one checkpoint is a zombie to be collected, GC will first get the owner of the checkpoint. Then it will check whether the lease of the owner exists. If the lease exists, those 'protecting' checkpoints can not be deleted by the GC; otherwise the GC will cleanup them. Granularity ================= To avoid flood to bank server, we don't keep one lease for per checkpoint. Instead, we keep one lease per checkpoint owner. So the granularity of lease is per bank plugin instance. When one protection service instance gets initialized, each bank plugin instance will get initialized as well. Each bank plugin will start to maintain its own leases with its corresponding bank server. Here, every bank plugin will play a role as lease client while the bank server (swift cluster) plays as the lease server. Functions =============== acquire_lease ------------- Each bank plugin (lease client) will use this function to acquire a lease from bank server (lease server). For swift specifically, it will create a lease object in swift container and set an expire_window for this lease. The expire_window represents the validity of this lease from creation(or latest-renew) until being auto-deleted by swift server. The value of expire_window should be configurable. We use owner_id to identify one instance of bank plugin. The owner_id is a uuid created when bank plugin instance is initiated, say, generated from sha256 with parameter as hostname and the timestamp instance initiated. The key of lease object stored in swift looks like this: /account/leases/owner_id. In order to map one checkpoint to its owner, we will create an index like this: /account/checkpoints/checkpoint_id/owner_id when creating a checkpoint. - create_owner_id: create a uuid to represent this bank plugin instance - put_object: use swift-client to create a lease object in swift, and set 'X-Delete-After' as: expire_window - set_expire_time in memory in lease client side: set the expire_time as: now+expired_time renew_lease ----------------- This function will be called by each lease client in the background periodically. The renew_window represents the period with which the lease client will refresh lease frequently. This renew_window is configurable as well, where renew_window < expire_window. If lease client succeeds to renew lease, this lease has a new expire_window in lease server from now on. Then the lease client side will update the expire_time in memory with value as: expire_time = now + expired_window. If lease client fails to renew, this lease object keeps the old expire_window in lease server side. The lease client won't update its expire_time in memory. - post_object: use swift-client to reset the 'X-Delete-After' header as: expired_window - update_expire_time: if post_object succeeds, update expire_time as: now+expired_window; otherwise, don't refresh the expire_time. check_lease_validity -------------------- This function is used by the checkpoint owner to check whether there is enough time to execute an update operation to one checkpoint (or anything else garded by the lease) before the lease expiring. We use validity_window to represent the time window inside which an update operation to a checkpoint should complete. This window is configurable and should be estimated by admin. This function will check if validity_window <= expire_time - now. If it's true, this function will return true and thus allow update operation to go ahead; otherwise, this function will return false and the update operation will abort. Although the lease may haven't expired when validity_window <= expire_time - now, there might not be enough time to finish the update operation. If we allow the update operation to go ahead under this situation, there is a risk that while the operation is still on-going, the lease has been recycled by lease server during this period. check_lease_instance -------------------- This function is used by GC to check whether the lease object exists or not in lease server side. Specifically for checkpoints, GC will scan all checkpoints in 'protecting' status. It will first get the owner of a checkpoint through its index, and then check the existence of the lease object in lease server. If the lease object doesn't exist, it will take this checkpoint as zombie and go ahead to recycle it. Otherwise, it will skip this checkpoint and leave it there. Configurations ============== renew_window ------------ - represents the period with which lease client will renew the lease in background. expire_window -------------- - represents how long this lease from creation or latest-renew to expire in lease server side. - Note: expired_window > renew_window. To make renew mechanism more robust, we recommend to set expired_window = N*renew_window. With this setting, we allow (N-1) times failure to renew lease to tolerate unstable network case or IO scheduling issue; validity_window --------------- - the window estimated by user, how long one update operation will take at most. The constraint here should be: validity_window < expire_window. - Note: Same background as renew_window setting, to allow (N-1) times failure of renew lease, we recommend to set validity_window <= renew_window. ",,109,0
openstack%2Fvitrage~master~I08ccc8780b6a48fe5db69c6ec9a67310863f5663,openstack/vitrage,master,I08ccc8780b6a48fe5db69c6ec9a67310863f5663,fix typo,MERGED,2016-02-14 13:29:52.000000000,2016-02-14 13:41:51.000000000,2016-02-14 13:41:51.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-02-14 13:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/vitrage/commit/4b4a908e78cf1e186b1bea569a7e2bdf29e0ed4d', 'message': 'fix typo\n\nChange-Id: I08ccc8780b6a48fe5db69c6ec9a67310863f5663\n'}, {'number': 2, 'created': '2016-02-14 13:33:37.000000000', 'files': ['vitrage/api/controllers/v1/__init__.py', 'vitrage/synchronizer/plugins/__init__.py', 'etc/vitrage/vitrage.conf.sample'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/cd932db3ff7c9c416f4c9fb0dcee0655592694e5', 'message': 'fix typo\n\nChange-Id: I08ccc8780b6a48fe5db69c6ec9a67310863f5663\n'}]",0,279976,cd932db3ff7c9c416f4c9fb0dcee0655592694e5,7,2,2,19134,,,0,"fix typo

Change-Id: I08ccc8780b6a48fe5db69c6ec9a67310863f5663
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/76/279976/2 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/synchronizer/plugins/__init__.py', 'etc/vitrage/vitrage.conf.sample']",2,4b4a908e78cf1e186b1bea569a7e2bdf29e0ed4d,rca-api,# A path for the static plugins for the synchronizer (string value),# A path for the static plugins for the syncronizer (string value),2,2
openstack%2Fpython-saharaclient~master~I2c611d6b5ae08eacc11513e0dd2548e42b9dc828,openstack/python-saharaclient,master,I2c611d6b5ae08eacc11513e0dd2548e42b9dc828,Keystoneclient to keystoneauth migration,MERGED,2016-01-27 14:22:18.000000000,2016-02-14 13:32:34.000000000,2016-02-14 13:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2016-01-27 14:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/7daff10ba62655d9a98405ff1a57510f8ac11baf', 'message': 'Keystoneclient to keystoneauth migration\n\nKeystoneauth was extracted from keystoneclient so we need\nto migrate to keystoneauth\n\nalso deleted get_projects_list method because it is not used\n\nChange-Id: I2c611d6b5ae08eacc11513e0dd2548e42b9dc828\nbp: keystoneclient-to-keystoneauth\n'}, {'number': 2, 'created': '2016-01-27 14:37:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/0c2d1149a4dd12410533078bb71a464e9e018689', 'message': 'Keystoneclient to keystoneauth migration\n\nKeystoneauth was extracted from keystoneclient so we need\nto migrate to keystoneauth\n\nalso deleted get_projects_list method because it is not used\n\nChange-Id: I2c611d6b5ae08eacc11513e0dd2548e42b9dc828\nbp: keystoneclient-to-keystoneauth\n'}, {'number': 3, 'created': '2016-02-11 14:48:03.000000000', 'files': ['requirements.txt', 'doc/source/api.rst', 'saharaclient/shell.py', 'saharaclient/api/client.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/a3ac46644889e460f3f9e3fe89a87296d2a4ac8a', 'message': 'Keystoneclient to keystoneauth migration\n\nKeystoneauth was extracted from keystoneclient so we need\nto migrate to keystoneauth\n\nalso deleted get_projects_list method because it is not used\n\nChange-Id: I2c611d6b5ae08eacc11513e0dd2548e42b9dc828\nbp: keystoneclient-to-keystoneauth\n'}]",0,273064,a3ac46644889e460f3f9e3fe89a87296d2a4ac8a,19,6,3,19372,,,0,"Keystoneclient to keystoneauth migration

Keystoneauth was extracted from keystoneclient so we need
to migrate to keystoneauth

also deleted get_projects_list method because it is not used

Change-Id: I2c611d6b5ae08eacc11513e0dd2548e42b9dc828
bp: keystoneclient-to-keystoneauth
",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/64/273064/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'doc/source/api.rst', 'saharaclient/shell.py', 'saharaclient/api/client.py']",4,7daff10ba62655d9a98405ff1a57510f8ac11baf,bp/keystoneclient-to-keystoneauth,from keystoneauth1 import adapter from keystoneauth1.identity import v2 from keystoneauth1.identity import v3 from keystoneauth1 import token_endpoint from keystoneauth1 import exceptions from keystoneauth1 import session as keystone_session,"from keystoneclient import adapter from keystoneclient.auth.identity import v2 from keystoneclient.auth.identity import v3 from keystoneclient.auth import token_endpoint from keystoneclient import exceptions from keystoneclient import session as keystone_session from keystoneclient.v2_0 import client as keystone_client_v2 @staticmethod def get_projects_list(keystone_client): if isinstance(keystone_client, keystone_client_v2.Client): return keystone_client.tenants return keystone_client.projects",18,25
openstack%2Fvitrage~master~I24ae06a3c79a878326ad5c3464f9c155448aff55,openstack/vitrage,master,I24ae06a3c79a878326ad5c3464f9c155448aff55,fix resource show and list,MERGED,2016-02-14 13:16:24.000000000,2016-02-14 13:29:04.000000000,2016-02-14 13:29:04.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-02-14 13:16:24.000000000', 'files': ['vitrage/api/controllers/v1/resource.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/5030a4111d206ba18c1aff2d990b967cca012eb4', 'message': 'fix resource show and list\n\njust a mock for now\n\nChange-Id: I24ae06a3c79a878326ad5c3464f9c155448aff55\n'}]",0,279974,5030a4111d206ba18c1aff2d990b967cca012eb4,6,2,1,19134,,,0,"fix resource show and list

just a mock for now

Change-Id: I24ae06a3c79a878326ad5c3464f9c155448aff55
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/74/279974/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/api/controllers/v1/resource.py'],1,5030a4111d206ba18c1aff2d990b967cca012eb4,rca-api, # todo(eyalb1) need a mock for this return [{'None': None}] # todo(eyalb1) need a mock for this return {'None': None}, return dict() return dict(),4,2
openstack%2Fkolla~master~Ic2541c95d3ed983a00fbd946d75d5174e0a8d20c,openstack/kolla,master,Ic2541c95d3ed983a00fbd946d75d5174e0a8d20c,Test of the Ubuntu gate on master,ABANDONED,2016-02-13 04:45:01.000000000,2016-02-14 13:28:20.000000000,,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-13 04:45:01.000000000', 'files': ['loc'], 'web_link': 'https://opendev.org/openstack/kolla/commit/871f6e48bcba9123fb4f6fdf6c56a791a08675d6', 'message': 'Test of the Ubuntu gate on master\n\nI suspect a recent regression has resulted in a consistent 401 error\nfrom keystone.  This appears to happen on both centos and ubuntu\ndeployments and I want to see if it is a result of my toolbox change\nin the review queue.\n\nChange-Id: Ic2541c95d3ed983a00fbd946d75d5174e0a8d20c\n'}]",0,279852,871f6e48bcba9123fb4f6fdf6c56a791a08675d6,5,3,1,2834,,,0,"Test of the Ubuntu gate on master

I suspect a recent regression has resulted in a consistent 401 error
from keystone.  This appears to happen on both centos and ubuntu
deployments and I want to see if it is a result of my toolbox change
in the review queue.

Change-Id: Ic2541c95d3ed983a00fbd946d75d5174e0a8d20c
",git fetch https://review.opendev.org/openstack/kolla refs/changes/52/279852/1 && git format-patch -1 --stdout FETCH_HEAD,['loc'],1,871f6e48bcba9123fb4f6fdf6c56a791a08675d6,,ANSIBLE=`TEST OF THE UBUNTU GATE find ansible -type f -exec cat {} \; | wc -l`,ANSIBLE=`find ansible -type f -exec cat {} \; | wc -l`,1,1
openstack%2Fsahara~master~Ic453e889a55d5e321d63bdb8bd0a4bbf4c384797,openstack/sahara,master,Ic453e889a55d5e321d63bdb8bd0a4bbf4c384797,Remove support of HDP 2.2,MERGED,2016-02-12 15:51:40.000000000,2016-02-14 13:25:53.000000000,2016-02-14 13:25:53.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-12 15:51:40.000000000', 'files': ['sahara/plugins/ambari/deploy.py', 'sahara/tests/unit/plugins/ambari/test_plugin.py', 'sahara/plugins/ambari/resources/configs-2.2.json', 'sahara/tests/unit/plugins/ambari/test_configs.py', 'sahara/plugins/ambari/plugin.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a47e592a7398bf7b5bf66b46a48cfe631fa6090e', 'message': ""Remove support of HDP 2.2\n\nAmbari plugin didn't enabled by default in Sahara.\nAnd current supported version of HDP is 2.3.\nHence we can remove support of HDP 2.2\n\nChange-Id: Ic453e889a55d5e321d63bdb8bd0a4bbf4c384797\n""}]",0,279617,a47e592a7398bf7b5bf66b46a48cfe631fa6090e,8,4,1,19372,,,0,"Remove support of HDP 2.2

Ambari plugin didn't enabled by default in Sahara.
And current supported version of HDP is 2.3.
Hence we can remove support of HDP 2.2

Change-Id: Ic453e889a55d5e321d63bdb8bd0a4bbf4c384797
",git fetch https://review.opendev.org/openstack/sahara refs/changes/17/279617/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/ambari/deploy.py', 'sahara/tests/unit/plugins/ambari/test_plugin.py', 'sahara/plugins/ambari/resources/configs-2.2.json', 'sahara/tests/unit/plugins/ambari/test_configs.py', 'sahara/plugins/ambari/plugin.py']",5,a47e592a7398bf7b5bf66b46a48cfe631fa6090e,remove_hdp22," return [""2.3""]"," return [""2.3"", ""2.2""]",3,1252
openstack%2Fsahara~master~I5698a724bc030b838faa06330a0d3dc77cc0d07a,openstack/sahara,master,I5698a724bc030b838faa06330a0d3dc77cc0d07a,Don't use Mock.called_once_with that does not exist,MERGED,2016-02-11 15:11:33.000000000,2016-02-14 13:22:54.000000000,2016-02-14 13:22:54.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-11 15:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b161efcd11c94f0a2082a64be9d1677dde3f626e', 'message': ""Don't use Mock.called_once_with that does not exist\n\nclass mock.Mock does not exist method called_once_with, it just exists\nmethod assert_called_once_with. Currently there are still ome places\nwhere we use called_once_with method, this patch let's correct it.\n\nNOTE: called_once_with() does nothing because it's a mock object.\n\nCloses-Bug: #1544522\nChange-Id: I5698a724bc030b838faa06330a0d3dc77cc0d07a\n""}, {'number': 2, 'created': '2016-02-12 05:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9d1e50b86a24b21fc59954e03c22f2cdb5ca53e5', 'message': ""Don't use Mock.called_once_with that does not exist\n\nclass mock.Mock does not exist method called_once_with, it just exists\nmethod assert_called_once_with. Currently there are still ome places\nwhere we use called_once_with method, this patch let's correct it.\n\nNOTE: called_once_with() does nothing because it's a mock object.\n\nCloses-Bug: #1544522\nChange-Id: I5698a724bc030b838faa06330a0d3dc77cc0d07a\n""}, {'number': 3, 'created': '2016-02-12 08:33:52.000000000', 'files': ['sahara/tests/unit/plugins/vanilla/test_confighints_helper.py', 'sahara/tests/unit/plugins/cdh/test_confighints_helper.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7d01fabc5e16de0363afeb55c07fde889eb38a32', 'message': ""Don't use Mock.called_once_with that does not exist\n\nclass mock.Mock does not exist method called_once_with, it just exists\nmethod assert_called_once_with. Currently there are still ome places\nwhere we use called_once_with method, this patch let's correct it.\n\nNOTE: called_once_with() does nothing because it's a mock object.\n\nCloses-Bug: #1544522\nChange-Id: I5698a724bc030b838faa06330a0d3dc77cc0d07a\n""}]",3,279126,7d01fabc5e16de0363afeb55c07fde889eb38a32,23,5,3,15424,,,0,"Don't use Mock.called_once_with that does not exist

class mock.Mock does not exist method called_once_with, it just exists
method assert_called_once_with. Currently there are still ome places
where we use called_once_with method, this patch let's correct it.

NOTE: called_once_with() does nothing because it's a mock object.

Closes-Bug: #1544522
Change-Id: I5698a724bc030b838faa06330a0d3dc77cc0d07a
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/279126/3 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/unit/plugins/vanilla/test_confighints_helper.py', 'sahara/tests/unit/plugins/cdh/test_confighints_helper.py']",2,b161efcd11c94f0a2082a64be9d1677dde3f626e,bug/1544522, load_hadoop_xml_defaults.assert_called_once_with('sample-config.xml') load_hadoop_xml_defaults.assert_called_once_with('sample-config.xml') load_hadoop_xml_defaults.assert_called_once_with('sample-config.xml'), load_hadoop_xml_defaults.called_once_with('sample-config.xml') load_hadoop_xml_defaults.called_once_with('sample-config.xml') load_hadoop_xml_defaults.called_once_with('sample-config.xml'),6,6
openstack%2Ftricircle~master~I154f63ee232266f3c243a57d127957b3344a6349,openstack/tricircle,master,I154f63ee232266f3c243a57d127957b3344a6349,dal: Fix bad default parameter in list_sites,ABANDONED,2015-10-21 13:01:09.000000000,2016-02-14 13:14:31.000000000,,"[{'_account_id': 3}, {'_account_id': 13070}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-10-21 13:01:09.000000000', 'files': ['tricircle/db/models.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/003187b61a1a9818bbd5b5780045c9776cc570f0', 'message': ""dal: Fix bad default parameter in list_sites\n\ncore.query_resource() expects and iterable as 'filters' and can't handle\nNone\n\nChange-Id: I154f63ee232266f3c243a57d127957b3344a6349\n""}]",0,238049,003187b61a1a9818bbd5b5780045c9776cc570f0,6,3,1,2023,,,0,"dal: Fix bad default parameter in list_sites

core.query_resource() expects and iterable as 'filters' and can't handle
None

Change-Id: I154f63ee232266f3c243a57d127957b3344a6349
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/49/238049/1 && git format-patch -1 --stdout FETCH_HEAD,['tricircle/db/models.py'],1,003187b61a1a9818bbd5b5780045c9776cc570f0,experiment_future,"def list_sites(context, filters={}):","def list_sites(context, filters):",1,1
openstack%2Ftricircle~master~I28dd8dc39cd73e1e7b81085ca26ba32f8e258317,openstack/tricircle,master,I28dd8dc39cd73e1e7b81085ca26ba32f8e258317,Scheduler initalization code,ABANDONED,2015-10-27 15:44:05.000000000,2016-02-14 13:14:12.000000000,,"[{'_account_id': 3}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-10-27 15:44:05.000000000', 'files': ['tricircle/adapter_service/service.py', 'cmd/adapter_service.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/0e77ab1a67ff83f072918e4bd5ce37df683aea90', 'message': 'Scheduler initalization code\n\nChange-Id: I28dd8dc39cd73e1e7b81085ca26ba32f8e258317\n'}]",0,239698,0e77ab1a67ff83f072918e4bd5ce37df683aea90,5,2,1,2023,,,0,"Scheduler initalization code

Change-Id: I28dd8dc39cd73e1e7b81085ca26ba32f8e258317
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/98/239698/1 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/adapter_service/service.py', 'cmd/adapter_service.py']",2,0e77ab1a67ff83f072918e4bd5ce37df683aea90,experiment_future,from tricircle.adapter_service import scheduler def _set_up_scheduler_server(): scheduler_server = scheduler.create_server() scheduler_server.start() _set_up_scheduler_server(),,8,3
openstack%2Ftricircle~master~I7ac10940671599ca6f9aa1cd16d6374781cb9cd2,openstack/tricircle,master,I7ac10940671599ca6f9aa1cd16d6374781cb9cd2,Move adapter code to it's own adapter service,ABANDONED,2015-09-09 11:10:13.000000000,2016-02-14 13:14:04.000000000,,"[{'_account_id': 3}, {'_account_id': 11819}, {'_account_id': 12076}, {'_account_id': 13070}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-09-09 11:10:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/af448b9b26bec74effb1289c09feabef0593094b', 'message': ""Move adapter code to it's own adapter service\n\nThis patch doesn't actually any functionality in the cascade service.\nThe adapter keeps sending fake information. Communication between the\nadapter and the cascade layer will be added in a later patch.\n\nThis is just to move the files around as that kind of change is hard to\nreview.\n\nChange-Id: I7ac10940671599ca6f9aa1cd16d6374781cb9cd2\n""}, {'number': 2, 'created': '2015-09-24 14:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/b5c0b55cde61037de139f666db929294bc659bef', 'message': ""Move adapter code to it's own adapter service\n\nThis patch doesn't actually any functionality in the cascade service.\nThe adapter keeps sending fake information. Communication between the\nadapter and the cascade layer will be added in a later patch.\n\nThis is just to move the files around as that kind of change is hard to\nreview.\n\nChange-Id: I7ac10940671599ca6f9aa1cd16d6374781cb9cd2\n""}, {'number': 3, 'created': '2015-10-06 15:05:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/d8de98b5b16f0c2df2e71c3af6252714ca1dde54', 'message': ""Move adapter code to it's own adapter service\n\nThis patch doesn't actually any functionality in the cascade service.\nThe adapter keeps sending fake information. Communication between the\nadapter and the cascade layer will be added in a later patch.\n\nThis is just to move the files around as that kind of change is hard to\nreview.\n\nChange-Id: I7ac10940671599ca6f9aa1cd16d6374781cb9cd2\n""}, {'number': 4, 'created': '2015-10-21 13:01:09.000000000', 'files': ['tricircle/adapter_service/scheduler.py', 'tricircle/adapter_service/site_manager.py', 'devstack/plugin.sh', 'etc/adapter_service.conf', 'tricircle/adapter_service/__init__.py', 'tricircle/adapter_service/endpoints/__init__.py', 'tricircle/adapter_service/endpoints/networking.py', 'devstack/settings', 'tricircle/adapter_service/service.py', 'tricircle/cascade_service/service.py', 'devstack/local.conf.sample', 'tricircle/adapter_service/compute.py', 'tricircle/common/topics.py', 'tricircle/common/cascading_networking_api.py', 'tricircle/common/rpc.py', 'cmd/adapter_service.py', 'cmd/cascade_service.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/27299c49495d2c6bf6372d5af54c1428f3a9e4b2', 'message': ""Move adapter code to it's own adapter service\n\nThis patch doesn't actually any functionality in the cascade service.\nThe adapter keeps sending fake information. Communication between the\nadapter and the cascade layer will be added in a later patch.\n\nThis is just to move the files around as that kind of change is hard to\nreview.\n\nChange-Id: I7ac10940671599ca6f9aa1cd16d6374781cb9cd2\n""}]",4,221703,27299c49495d2c6bf6372d5af54c1428f3a9e4b2,20,5,4,2023,,,0,"Move adapter code to it's own adapter service

This patch doesn't actually any functionality in the cascade service.
The adapter keeps sending fake information. Communication between the
adapter and the cascade layer will be added in a later patch.

This is just to move the files around as that kind of change is hard to
review.

Change-Id: I7ac10940671599ca6f9aa1cd16d6374781cb9cd2
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/03/221703/4 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/adapter_service/scheduler.py', 'tricircle/adapter_service/site_manager.py', 'devstack/plugin.sh', 'etc/adapter_service.conf', 'tricircle/adapter_service/__init__.py', 'tricircle/adapter_service/endpoints/__init__.py', 'tricircle/adapter_service/endpoints/networking.py', 'devstack/settings', 'tricircle/adapter_service/service.py', 'tricircle/cascade_service/service.py', 'devstack/local.conf.sample', 'tricircle/adapter_service/compute.py', 'tricircle/common/topics.py', 'tricircle/common/cascading_networking_api.py', 'tricircle/common/rpc.py', 'cmd/adapter_service.py', 'cmd/cascade_service.py']",17,af448b9b26bec74effb1289c09feabef0593094b,experiment_future," logging.setup(cfg.CONF, ""tricircle_adapter_service"", version='0.1')"," import eventlet if __name__ == ""__main__"": eventlet.monkey_patch() import tracebackfrom nova import exception as nova_exception import nova.db.api from nova.conductor import rpcapi as conductor_rpcapi from nova.i18n import _LE from nova.objects import base as objects_base import nova.rpc as nova_rpc def block_db_access(): class NoDB(object): def __getattr__(self, attr): return self def __call__(self, *args, **kwargs): stacktrace = """".join(traceback.format_stack()) LOG = logging.getLogger('nova.compute') LOG.error(_LE('No db access allowed in nova-compute: %s'), stacktrace) raise nova_exception.DBNotAllowed('nova-compute') nova.db.api.IMPL = NoDB() def set_up_nova_object_indirection(): conductor = conductor_rpcapi.ConductorAPI() conductor.client.target.exchange = ""nova"" objects_base.NovaObject.indirection_api = conductor logging.setup(cfg.CONF, ""cascade_service"", version='0.1') def _set_up_nova_objects(): nova_rpc.init(cfg.CONF) import nova.objects as nova_objects block_db_access() set_up_nova_object_indirection() nova_objects.register_all() def _disable_quotas(): from nova import quota QUOTAS = quota.QUOTAS QUOTAS._driver_cls = quota.NoopQuotaDriver() _set_up_nova_objects() _disable_quotas() process_command_line_arguments()",679,87
openstack%2Fnova~stable%2Fliberty~I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa,openstack/nova,stable/liberty,I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa,Replace eventlet-based raw socket client with requests,MERGED,2016-02-09 21:51:11.000000000,2016-02-14 13:13:55.000000000,2016-02-10 02:41:36.000000000,"[{'_account_id': 3}, {'_account_id': 2271}, {'_account_id': 9008}, {'_account_id': 11564}, {'_account_id': 12898}]","[{'number': 1, 'created': '2016-02-09 21:51:11.000000000', 'files': ['nova/tests/unit/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0d5b3c6d7a4463ba6972507d38300f70cbf87c16', 'message': ""Replace eventlet-based raw socket client with requests\n\nThere's no discernable reason why we need to use a raw\neventlet-based client TestWSGIServerWithSSL to confirm that a\nwsgi server is listening correctly and returning the expected\nresponse, especially since using eventlet leads to unreliable\ni/o on the socket unless there is an explicit yield before\nasserting the value of the response.\n\nSo requests is used to query the servers and verify the response.\n\nChange-Id: I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa\nCloses-Bug: #1543766\n(cherry picked from commit d754a830861fb55b047e7b4d43ba7f485fc120dd)\n""}]",0,278108,0d5b3c6d7a4463ba6972507d38300f70cbf87c16,11,5,1,6873,,,0,"Replace eventlet-based raw socket client with requests

There's no discernable reason why we need to use a raw
eventlet-based client TestWSGIServerWithSSL to confirm that a
wsgi server is listening correctly and returning the expected
response, especially since using eventlet leads to unreliable
i/o on the socket unless there is an explicit yield before
asserting the value of the response.

So requests is used to query the servers and verify the response.

Change-Id: I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa
Closes-Bug: #1543766
(cherry picked from commit d754a830861fb55b047e7b4d43ba7f485fc120dd)
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/278108/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_wsgi.py'],1,0d5b3c6d7a4463ba6972507d38300f70cbf87c16,bug/1543766-liberty," response = requests.post( 'https://127.0.0.1:%s/' % fake_ssl_server.port, verify=os.path.join(SSL_CERT_DIR, 'ca.crt'), data='PING') self.assertEqual(response.text, 'PONG') response = requests.post( 'https://127.0.0.1:%s/' % fake_ssl_server.port, verify=os.path.join(SSL_CERT_DIR, 'ca.crt'), data='PING') self.assertEqual(response.text, 'PONG') response = requests.post('http://127.0.0.1:%s/' % fake_server.port, data='PING') self.assertEqual(response.text, 'PONG') fake_server.stop() fake_server.wait()"," cli = eventlet.connect((""localhost"", fake_ssl_server.port)) cli = eventlet.wrap_ssl(cli, ca_certs=os.path.join(SSL_CERT_DIR, 'ca.crt')) cli.write('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") cli = eventlet.connect((""localhost"", fake_ssl_server.port)) cli = eventlet.wrap_ssl(cli, ca_certs=os.path.join(SSL_CERT_DIR, 'ca.crt')) cli.write('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") cli = eventlet.connect((""localhost"", fake_server.port)) cli.sendall('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.recv(8192) self.assertEqual(response[-4:], ""PONG"")",13,22
openstack%2Ftricircle~master~Id23ce2d3f5f7fb98468b622e65eeb24931e5f323,openstack/tricircle,master,Id23ce2d3f5f7fb98468b622e65eeb24931e5f323,Fix wrong messages in devstack plugin,ABANDONED,2015-10-21 13:01:09.000000000,2016-02-14 13:13:52.000000000,,"[{'_account_id': 3}, {'_account_id': 13070}, {'_account_id': 16237}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-10-21 13:01:09.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/e3e4f1973a3631bea73aa7c5f01d15f60e2b44d6', 'message': 'Fix wrong messages in devstack plugin\n\nChange-Id: Id23ce2d3f5f7fb98468b622e65eeb24931e5f323\n'}]",0,238050,e3e4f1973a3631bea73aa7c5f01d15f60e2b44d6,7,4,1,2023,,,0,"Fix wrong messages in devstack plugin

Change-Id: Id23ce2d3f5f7fb98468b622e65eeb24931e5f323
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/50/238050/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,e3e4f1973a3631bea73aa7c5f01d15f60e2b44d6,experiment_future," echo ""Configuring Tricircle Cascade Service"" echo ""Configuring Tricircle Adapter Service"""," echo ""Configuring Neutron for Tricircle Cascade Service"" echo ""Configuring Neutron for Tricircle Adapter Service""",2,2
openstack%2Ftricircle~master~Ibc9583d37a29d20bdd70243ca5e4b97b4e45cced,openstack/tricircle,master,Ibc9583d37a29d20bdd70243ca5e4b97b4e45cced,Implement get_admin_context(),ABANDONED,2015-10-21 13:01:09.000000000,2016-02-14 13:13:45.000000000,,"[{'_account_id': 3}, {'_account_id': 13070}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-10-21 13:01:09.000000000', 'files': ['tricircle/context.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/b5c2a7e37ca0e8020371252c8d9fd8425fae9bb2', 'message': ""Implement get_admin_context()\n\nThough no code currently uses it it's a method we will surely need and I\nalready used it for some internal testing.\n\nChange-Id: Ibc9583d37a29d20bdd70243ca5e4b97b4e45cced\n""}]",0,238051,b5c2a7e37ca0e8020371252c8d9fd8425fae9bb2,6,3,1,2023,,,0,"Implement get_admin_context()

Though no code currently uses it it's a method we will surely need and I
already used it for some internal testing.

Change-Id: Ibc9583d37a29d20bdd70243ca5e4b97b4e45cced
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/51/238051/1 && git format-patch -1 --stdout FETCH_HEAD,['tricircle/context.py'],1,b5c2a7e37ca0e8020371252c8d9fd8425fae9bb2,experiment_future," def get_admin_context(): return Context( user_id=None, project_id=None, is_admin=True, overwrite=False, )",,9,0
openstack%2Ftricircle~master~Id2cafef5eb1fc25f67eba719594fbf3b93ed09c5,openstack/tricircle,master,Id2cafef5eb1fc25f67eba719594fbf3b93ed09c5,Implement initial Work Distribution Queue,ABANDONED,2015-10-21 13:01:09.000000000,2016-02-14 13:13:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11819}, {'_account_id': 13070}, {'_account_id': 16911}]","[{'number': 1, 'created': '2015-10-21 13:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/92c7ed439bd030a0e12fe3dbd928715c93fc4288', 'message': 'Implement initial Work Distribution Queue\n\nCurrently only forwards the action. In the future, more specialized\nlogic will look at the commands.\n\nAlso adds all the boilerplate for oslo_versionedobjects in tricircle and\nbinding around the Site object.\n\nFuture patches will add functionality inside the adapter and use the\ninformation returned by list_sites() instead of the current hard coded\ndata.\n\nChange-Id: Id2cafef5eb1fc25f67eba719594fbf3b93ed09c5\n'}, {'number': 2, 'created': '2015-10-27 15:44:05.000000000', 'files': ['cmd/distributor_service.py', 'tricircle/distributor_service/__init__.py', 'tricircle/objects/dal.py', 'tricircle/objects/site.py', 'devstack/plugin.sh', 'etc/distributor_service.conf', 'tricircle/distributor_service/service.py', 'devstack/settings', 'tricircle/objects/base.py', 'tricircle/cascade_service/rpcapi.py', 'tricircle/distributor_service/rpcapi.py', 'tricircle/cascade_service/service.py', 'tricircle/common/cache.py', 'devstack/local.conf.sample', 'tricircle/common/topics.py', 'tricircle/objects/__init__.py', 'tricircle/common/rpc.py', 'tricircle/common/serializer.py', 'tricircle/objects/fields.py', 'cmd/adapter_service.py', 'cmd/cascade_service.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/950abacef2eec32e5950cf95c85d8d074c640bea', 'message': 'Implement initial Work Distribution Queue\n\nCurrently only forwards the action. In the future, more specialized\nlogic will look at the commands.\n\nAlso adds all the boilerplate for oslo_versionedobjects in tricircle and\nbinding around the Site object.\n\nFuture patches will add functionality inside the adapter and use the\ninformation returned by list_sites() instead of the current hard coded\ndata.\n\nChange-Id: Id2cafef5eb1fc25f67eba719594fbf3b93ed09c5\n'}]",10,238052,950abacef2eec32e5950cf95c85d8d074c640bea,11,5,2,2023,,,0,"Implement initial Work Distribution Queue

Currently only forwards the action. In the future, more specialized
logic will look at the commands.

Also adds all the boilerplate for oslo_versionedobjects in tricircle and
binding around the Site object.

Future patches will add functionality inside the adapter and use the
information returned by list_sites() instead of the current hard coded
data.

Change-Id: Id2cafef5eb1fc25f67eba719594fbf3b93ed09c5
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/52/238052/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/queue_service.conf', 'tricircle/objects/dal.py', 'cmd/queue_service.py', 'tricircle/objects/site.py', 'tricircle/queue_service/service.py', 'devstack/plugin.sh', 'devstack/settings', 'tricircle/objects/base.py', 'tricircle/queue_service/__init__.py', 'tricircle/cascade_service/rpcapi.py', 'tricircle/cascade_service/service.py', 'tricircle/common/cache.py', 'devstack/local.conf.sample', 'tricircle/queue_service/rpcapi.py', 'tricircle/common/topics.py', 'tricircle/objects/__init__.py', 'tricircle/common/rpc.py', 'tricircle/common/serializer.py', 'tricircle/objects/fields.py', 'cmd/adapter_service.py', 'cmd/cascade_service.py']",21,92c7ed439bd030a0e12fe3dbd928715c93fc4288,experiment_future,"from tricircle import objects as tricircle_objects def _set_up_tricircle_objects(): tricircle_objects.register_all() if __name__ == ""__main__"": _set_up_tricircle_objects() process_command_line_arguments()","if __name__ == ""__main__"":",1226,26
openstack%2Fvitrage~master~I291eb72881af445fd9eb20a96a9096ec108a97fe,openstack/vitrage,master,I291eb72881af445fd9eb20a96a9096ec108a97fe,add rca mock,MERGED,2016-02-14 12:40:06.000000000,2016-02-14 13:13:18.000000000,2016-02-14 13:13:18.000000000,"[{'_account_id': 3}, {'_account_id': 19134}]","[{'number': 1, 'created': '2016-02-14 12:40:06.000000000', 'files': ['vitrage/api/controllers/v1/__init__.py', 'vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/topology.py', 'etc/vitrage/rca.sample.json', 'etc/vitrage/graph.sample.json', 'etc/vitrage/vitrage.conf.sample', 'etc/vitrage/alarms.sample.json'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/5ef520b28d8831bd40adeb3387085f282e6c9393', 'message': 'add rca mock\n\nChange-Id: I291eb72881af445fd9eb20a96a9096ec108a97fe\n'}]",0,279962,5ef520b28d8831bd40adeb3387085f282e6c9393,6,2,1,19134,,,0,"add rca mock

Change-Id: I291eb72881af445fd9eb20a96a9096ec108a97fe
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/62/279962/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/api/controllers/v1/__init__.py', 'vitrage/api/controllers/v1/rca.py', 'vitrage/api/controllers/v1/topology.py', 'etc/vitrage/rca.sample.json', 'etc/vitrage/graph.sample.json', 'etc/vitrage/vitrage.conf.sample', 'etc/vitrage/alarms.sample.json']",7,5ef520b28d8831bd40adeb3387085f282e6c9393,rca-api,"{ ""alarms"": [ { ""id"": ""04cf683b-58a8-4b59-941a-9a1594fa0fe7"", ""project_id"": ""da3a1ab32-1c62-22cb-bf04-660bd33cd74d"", ""state"": ""available"", ""update_timestamp"": ""2016-01-18T06:14:20.782134+00:00"", ""category"": ""alarm"", ""type"": ""CPU_HIGH"", ""name"": ""cpu high"", ""severity"": ""major"" }, { ""id"": ""05af123a-56a2-4b59-741a-7b1482dabac2"", ""project_id"": ""da3a1ab32-1c62-22cb-bf04-660bd33cd74d"", ""state"": ""available"", ""update_timestamp"": ""2016-01-18T06:12:28.987651+00:00"", ""category"": ""alarm"", ""type"": ""NO_SPACE_ON_DISK"", ""name"": ""no space on disk"", ""severity"": ""critical"" }, { ""id"": ""123f456a-12b2-9c51-345d-8b2604adbada7"", ""project_id"": ""da3a1ab32-1c62-22cb-bf04-660bd33cd74d"", ""state"": ""available"", ""update_timestamp"": ""2016-01-18T06:14:38.123456+00:00"", ""category"": ""alarm"", ""type"": ""OUT_OF_MEMORY"", ""name"": ""out of memory"", ""severity"": ""critical"" } ] } ",,806,11
openstack%2Fcinder~master~I0a969b184054f287cef463bbcb980bfb4a0a6803,openstack/cinder,master,I0a969b184054f287cef463bbcb980bfb4a0a6803,hacking: Fix false positive in C302 check,MERGED,2016-02-09 14:00:06.000000000,2016-02-14 13:04:45.000000000,2016-02-09 20:25:02.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16880}, {'_account_id': 16941}, {'_account_id': 17852}]","[{'number': 1, 'created': '2016-02-09 14:00:06.000000000', 'files': ['cinder/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/917d476180552ba83e9675268d8b479504ed29a1', 'message': 'hacking: Fix false positive in C302 check\n\nUse a regular expression to search for ""unicode("" instead of a static\nstring to not complain to ""exception_to_unicode(error)"".\n\nChange-Id: I0a969b184054f287cef463bbcb980bfb4a0a6803\n'}]",0,277841,917d476180552ba83e9675268d8b479504ed29a1,41,18,1,9107,,,0,"hacking: Fix false positive in C302 check

Use a regular expression to search for ""unicode("" instead of a static
string to not complain to ""exception_to_unicode(error)"".

Change-Id: I0a969b184054f287cef463bbcb980bfb4a0a6803
",git fetch https://review.opendev.org/openstack/cinder refs/changes/41/277841/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/hacking/checks.py'],1,917d476180552ba83e9675268d8b479504ed29a1,bp/cinder-python3,_UNICODE_USAGE_REGEX = re.compile(r'\bunicode *\(') if _UNICODE_USAGE_REGEX.search(logical_line):, if 'unicode(' in logical_line:,4,1
openstack%2Fsahara-image-elements~master~Icea77f6fda6d60c4f67dab633347c245a4bd7a9a,openstack/sahara-image-elements,master,Icea77f6fda6d60c4f67dab633347c245a4bd7a9a,gate-sahara-buildimages-ambari (>= 2.1.2) job fix,MERGED,2016-02-03 14:46:19.000000000,2016-02-14 12:54:50.000000000,2016-02-14 12:54:50.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 12038}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-02-03 14:46:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/a38403ffb368b9508723ee9547d7b661452690fa', 'message': ""gate-sahara-buildimages-ambari (>= 2.1.2) job fix\n\nAmbari has started to support Ubuntu since Ambari version 2.1.2.\nFor Ubuntu such packages as\n    ambari-metrics-monitor,\n    ambari-metrics-hadoop-sink,\n    ambari-metrics-collector\nare implemented in ambari-metrics-assembly package.\nThere is no some standalone ambari-log4j package for Ubuntu\nAlso Ubuntu doesn't require of extra installation of 'which' package\n\nChange-Id: Icea77f6fda6d60c4f67dab633347c245a4bd7a9a\n""}, {'number': 2, 'created': '2016-02-03 14:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/7a1fd7d07579bea383ab7493e53cb7d9de1ead3b', 'message': ""gate-sahara-buildimages-ambari (>= 2.1.2) job fix\n\nAmbari has started to support Ubuntu since Ambari version 2.1.2.\nFor Ubuntu such packages as\n    ambari-metrics-monitor,\n    ambari-metrics-hadoop-sink,\n    ambari-metrics-collector\nare implemented in ambari-metrics-assembly package.\nThere is no some standalone ambari-log4j package for Ubuntu\nAlso Ubuntu doesn't require of extra installation of 'which' package\n\nChange-Id: Icea77f6fda6d60c4f67dab633347c245a4bd7a9a\nCloses-bug: #1541410\n""}, {'number': 3, 'created': '2016-02-04 11:24:40.000000000', 'files': ['elements/ambari/element-deps', 'diskimage-create/diskimage-create.sh', 'elements/ambari/pkg-map'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/fc1283ae14bb222b06fc48d18a03546465828cc4', 'message': ""gate-sahara-buildimages-ambari (>= 2.1.2) job fix\n\nAmbari has started to support Ubuntu since Ambari version 2.1.2.\nFor Ubuntu such packages as\n    ambari-metrics-monitor,\n    ambari-metrics-hadoop-sink,\n    ambari-metrics-collector\nare implemented in ambari-metrics-assembly package.\nThere is no some standalone ambari-log4j package for Ubuntu.\nAlso canceled 'disable-firewall' installation for Ubuntu.\n\nChange-Id: Icea77f6fda6d60c4f67dab633347c245a4bd7a9a\nCloses-bug: #1541410\n""}]",1,275728,fc1283ae14bb222b06fc48d18a03546465828cc4,20,5,3,19372,,,0,"gate-sahara-buildimages-ambari (>= 2.1.2) job fix

Ambari has started to support Ubuntu since Ambari version 2.1.2.
For Ubuntu such packages as
    ambari-metrics-monitor,
    ambari-metrics-hadoop-sink,
    ambari-metrics-collector
are implemented in ambari-metrics-assembly package.
There is no some standalone ambari-log4j package for Ubuntu.
Also canceled 'disable-firewall' installation for Ubuntu.

Change-Id: Icea77f6fda6d60c4f67dab633347c245a4bd7a9a
Closes-bug: #1541410
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/28/275728/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/disable-firewall/pkg-map', 'elements/ambari/pkg-map']",2,a38403ffb368b9508723ee9547d7b661452690fa,gate_sahara_buildimages_ambari-2.1.2," ""fuse-libs"": ""fuse"", ""ambari-metrics-monitor"": ""ambari-metrics-assembly"", ""ambari-metrics-collector"": ""ambari-metrics-assembly"", ""ambari-metrics-hadoop-sink"": ""ambari-metrics-assembly"", ""ambari-log4j"": """""," ""fuse-libs"": ""fuse""",12,1
openstack%2Fsahara-specs~master~I9dbc40cde6be077162e7a621866b567783cafecc,openstack/sahara-specs,master,I9dbc40cde6be077162e7a621866b567783cafecc,SPI Method to Validate Images,MERGED,2015-12-08 21:06:36.000000000,2016-02-14 12:52:35.000000000,2016-02-14 12:52:35.000000000,"[{'_account_id': 3}, {'_account_id': 8090}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12320}, {'_account_id': 13953}, {'_account_id': 18777}]","[{'number': 1, 'created': '2015-12-08 21:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/9e1a7f3fe3b145d5afc678f3d0fa2d845be22978', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}, {'number': 2, 'created': '2015-12-08 21:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/a86951dfba1493d9d0be0f8f4c675d885bfcf21e', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}, {'number': 3, 'created': '2015-12-09 16:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/9429a6315b7c26ce991c30a6724dc32cdb4a9997', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}, {'number': 4, 'created': '2015-12-10 17:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/eeccec1beecb1f72db67ae34859a9d978f701151', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}, {'number': 5, 'created': '2015-12-11 19:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/f540a93ebe06b711a20a9796fb22305d24ed8317', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}, {'number': 6, 'created': '2016-01-18 15:40:52.000000000', 'files': ['specs/mitaka/validate-image-spi.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/bfd8790bdedece30746629c2056bb57aed4b394a', 'message': 'SPI Method to Validate Images\n\nThis specification details the addition of a method to the Sahara plugin SPI\nto validate that a chosen image is up to the specification that the plugin\nrequires. While it is not expected that plugin writers will be able to test\nthe image deeply enough to ensure that a given arbitrary image will succeed\nin cluster generation and be functional in all contexts, it is hoped that by\nimplementing this method well, plugin authors can provide a well-defined,\nmachine-actionable contract which will be versioned with the plugin itself.\n\nDescribes: blueprint validate-image-spi\n\nChange-Id: I9dbc40cde6be077162e7a621866b567783cafecc\n'}]",34,254956,bfd8790bdedece30746629c2056bb57aed4b394a,37,7,6,13953,,,0,"SPI Method to Validate Images

This specification details the addition of a method to the Sahara plugin SPI
to validate that a chosen image is up to the specification that the plugin
requires. While it is not expected that plugin writers will be able to test
the image deeply enough to ensure that a given arbitrary image will succeed
in cluster generation and be functional in all contexts, it is hoped that by
implementing this method well, plugin authors can provide a well-defined,
machine-actionable contract which will be versioned with the plugin itself.

Describes: blueprint validate-image-spi

Change-Id: I9dbc40cde6be077162e7a621866b567783cafecc
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/56/254956/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/validate-image-spi.rst'],1,9e1a7f3fe3b145d5afc678f3d0fa2d845be22978,bp/validate-image-spi,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ SPI Method to Validate Image ============================ https://blueprints.launchpad.net/sahara/+spec/validate-image-spi This specification details the addition of a method to the Sahara plugin SPI to validate that a chosen image is up to the specification that the plugin requires. While it is not expected that plugin writers will be able to test the image deeply enough to ensure that a given arbitrary image will succeed in cluster generation and be functional in all contexts, it is hoped that by implementing this method well, plugin authors can provide a well-defined, machine-actionable contract which will be versioned with the plugin itself. Problem description =================== At present, Sahara's image generation and cluster provisioning features are almost entirely decoupled: sahara-image-elements generates an image, and this image is taken by the server and assumed to be valid. This introduces the possibility of version incompatibility between sahara-image-elements and sahara itself, and failure (complete or partial, immediate or silent) in the case of the addition or modification of features on either side. Larger problem description ========================== This is not a traditional specification section, but I am adding it to address the larger context of this feature. This issue is only one part of a larger problem, which will not be wholly addressed in this spec, but for which this spec is an incremental step toward a solution. At present, the processes involved in image generation and use are: 1) Image packing (pre-cluster spawn) 2) Clean image provisioning (building a cluster from an OS-only base image) 3) Image validation (ensuring that a previously packed image really is ok to use for the plugin, at least for the rules we can easily check) The first, image-packing, is currently only possible via a command line script. The ideal user experience would allow generation of images either outside of OpenStack, via a command-line script, or with OpenStack, via a sahara API method. At present, this is not possible. The second, in our present architecture, requires essentially rewriting the logic required to generate an image via the command line process in the plugin code, leading to duplicate logic and multiple maintenance points wherever cluster provisioning from clean images is allowed. However, it should be noted that in the clean image generation case, this logic is in its right place from an encapsulation perspective (it is maintained and versioned with the plugin code, allowing for easy separation, rather than maintained in a monolithic cross-cutting library which serves all plugins.) The third is not formally undertaken as a separate step at all; it will be implemented by the feature this specification describes. Within the context of this larger problem, this feature can be seen as the first incremental step toward a unified solution for image validation, unification of clean and packed image generation logic, and facilitation of image packing via an API. Once this SPI method is stable, functional, and expresses a complete set of tests for all maintained plugins, the validation specification can then be reused as a series of idempotent state descriptions for image packing, which can then be exposed via an API for any plugins which support it. Proposed change =============== A new method will be added to the plugin SPI in Sahara: :: validate_images(self, cluster, reconcile=True) This method will be called after cluster provisioning (as this will be necessary for machine access) and before cluster configuration. This method will receive the cluster definition as an argument, as well as a boolean flag. If this method is not implemented by a plugin, provisioning will proceed as normal; as this is purely a safety feature, full backward compatibility with previous plugin versions is acceptable. The contract of this method is that on being called, the plugin will take any steps it sees fit to validate that any utilized images are fit for their purposes. It is expected that all tests that are run will be necessary for the cluster to succeed, but not that the whole set of tests will be absolutely sufficient for the cluster to succeed (as this would essentially be disproving a universal negative, and would require such in-depth testing as to become ludicrous.) If the reconcile flag is set to True (this will be set by default, then the plugin will also take any steps it is prepared to take to bring the instances of the cluster into line with its expectations (that is, to reconcile minor differences with the image or to spawn from a clean image.) Plugins are not required to provide this functionality, just as they are not required to implement validate_image; if they wish to fail immediately in the case of an imperfect image, that is their choice. However, if a plugin does not support reconciliation, and reconcile is set to True, it must raise an error; likewise, if a plugin receives reconcile=False but it is not able to avoid reconciliation (if, for instance, its implementation uses Puppet and will by definition make changes if needed,) it must raise as well. The sahara base service will provide a set of utilities to help plugin authors to validate their images. These will be found in sahara.plugins.images. It is noted that this module could be immediately written to allow a great deal of deep functionality in terms of matching image validations to services, allowing custom images to be used for specific nodegroups and service sets. However, as no plugins are currently implementing such a feature set, a more basic first iteration is reasonable, and the methods described below will allow a plugin author to perform such specific validations if it is desired. The images module will provide several public members: the definitions of the most notable (if not all) are given below: :: def validate_instance(instance, validators, reconcile=True) """"""Runs all validators against the specified instance."""""" def validate_instances(instances, validators, reconcile=True) """"""Runs all validators against the specified instances, using a parallel approach and using the same batch processing strategy as will be used in the configuration step, if any."""""" class ImageValidator(object): """"""Validates the image spawned to an instance via a set of rules."""""" @abstractmethod validate(self, remote, cluster, reconcile=True) class SaharaImageValidator(ImageValidator): """"""Still-abstract base class for Sahara's native image validation, which provides instantiation of subclasses from a yaml file."""""" @staticmethod from_yaml(yaml_path, validator_map, resource_root) """"""Constructs and returns a validator from the provided yaml file. :param yaml: The path to a yaml file. :param validator_map: A map of validator name to class. Each class is expected to descend from SaharaImageValidator. This method will use the static map of validator name to class provided in the sahara.plugins.images module, updated with this map, to parse the appropriate classes to be used. :resource_root: The root from which relative paths to resources (scripts and such) will be referenced."""""" Additionally an ImageValidationError class will be added to sahara.plugins.exceptions. It is entirely possible for a plugin author, in this framework, to use idempotent state enforcement toolsets, such as Ansible, Puppet, Chef, and the like, to validate and reconcile images. However, in order that Sahara need not absolutely depend on these tools, we will provide the SaharaImageValidator class. This validator will provide a classmethod which allows it to build its validations from a .yaml file. The first iteration of this validator will be very limited, and as such will provide only a few abstract validation types. An example .yaml file showing the full revision-one featureset follows. Note that these are not intended to be realistic, sahara-ready definitions, merely examples taken from our experience: :: os_case: redhat: package: nfs-utils debian: package: nfs-common any: package: java-1.8.0-openjdk-devel package: java-1.7.0-openjdk-devel >= 1.7.0.79-2.5.5.0 script: file: java/setup-java-home env: JDK_HOME: general:java64_home package: - hadoop - hadoop-libhdfs - hadoop-native - hadoop-pipes - hadoop-sbin - hadoop-lzo - lzo - lzo-devel - hadoop-lzo-native :: These resource declarations will be used to instantiate the following basic validator types: :: # The following validator types are subtypes of SaharaImageValidator. SAHARA_VALIDATOR_TYPE_MAP = { ""package"": SaharaPackageValidator, # Verifies that the package (if constructed with a string) or packages # (if given a list) are installed. In the reconcile=True case, ensures # that local package managers are queried before resorting to # networked tools: # `dpkg -s $package || apt-get -y install $package` or # `rpm -q $package || yum install -y $package`) ""script"": SaharaScriptValidator, # Runs the script specified at the relative path from the resource # root. Can optionally be provided an an ""env"" argument, which will # pass values from the cluster_configs into the script with the # environment variable name specified in the key. As per the # example above, nested dictionary keys will be prepended using a # colon as a separator (both dots and underscores are heavily used # in our variable names.) # # These scripts are always provided the env var $SIV_DISTRO, which # specifies the linux distribution per DIB standard naming # conventions, and the env var $SIV_RECONCILE, which is set to 0 if # only validation should occur and 1 if corrective action should be # taken. # # NOTE THAT ALL SCRIPTS REVIEWED BY THE SAHARA TEAM MUST BE WRITTEN # TO BE IDEMPOTENT. If they are to take non-reproducible action, they # must test to see if that action has already been taken. This is # critical to the success of this feature in the long term. ""any"": SaharaAnyValidator, # Verifies that at least one of the validators it contains succeeds. # Even in reconcile mode, runs all validators before attempting to # enforce any. In reconcile mode, if no validators succeed on the # first pass (without change), attempts to enforce each in turn until # one succeeds. ""all"": SaharaAllValidator, # Verifies that all of the validators it contains succeed. This class # will be instantiated by the yaml factory method noted above, and # will contain all sub-validations. ""os_case"": SaharaOSCaseValidator, # Switches on the distro of the instance being validated. Recognizes # the OS family names redhat and debian, as per DIB. } Plugin authors may write their own validator types by extending the SaharaImageValidator type, implementing the interface, and passing the key and class into the constructor. It should be noted that current ""clean"" image generation scripts should be moved into this layer as part of the initial effort to implement this method for any given plugin, even if they are represented as a monolithic script resource. Otherwise clean images will very likely fail validation. Note also that the list above are certain to be needed, but as the implementer works, it may become useful to create additional validators (such as file, directory, user, etc.) As such, the list above is not necessarily complete; I hesitate, however, to list all possible validator types I can conceive of for fear of driving over-engineering from the spec. Alternatives ------------ We have many alternatives here. First, to the problem of merging our validation, packing, and clean image provisioning logic, we could opt to merge our current image generation code with our service layer. However, this poses real difficulties in testing, as our image generation layer, while functional, lacks the stability of our service layer, and merging it as-is could slow forward progress on the project as we wrestle with CI. Assuming that we do not wish to merge our current image generation layer, we could begin immediately to implement a new image generation layer in the service side. However, this sort of truly revolutionary step frequently ends in apathy, conflict, or both. Providing an image validation layer, with the possibility of growing into a clean image generation API and, later, an image packing API, is an incremental step which can provide real value in the short term, and which is needed regardless. Assuming that we are, in fact, building an image validation API, we could wholly separate it from any image preparation logic (including clean image provisioning.) There is a certain purist argument for separation of duties here, but the practical argument that resource testing and enforcement are frequently the same steps suggests that we should merge the two for efficiency. Assuming that we are allowing reconciliation of the image with the validation layer, we could, instead of building our own lightweight validation layer, demand that plugin authors immediately adopt one of Ansible, Puppet, Chef, Salt, etc. However, three factors lead me not to embrace this option. First, these tools are heavily network-dependent; in our context, we do not want to call to yum or apt unless absolutely necessary, as our instances may not be network-enabled. While it is possible to use them offline, it requires some subversion of their normal operation, which might be offputting for newcomers to Sahara who are versed in these tools. Second, Sahara should not be that opinionated about toolchains, either within our team or to our userbase. Facilitating the usage of devops toolchains by providing a clear, well- encapsulated API point is a good goal, but it is not Sahara's job to pick a winner in that market. Third, such a framework is a significant dependency for the sahara core, and such massive dependencies are always to be regarded with suspicion. As such, providing a very lightweight framework for validations is worthwhile, so that we do not need to depend absolutely on any such framework, even in the short term before plugins are abstracted out of the service repo. Assuming that we do not wish to immediately adopt such a framework, we could instead decide to immediately build a full-featured idempotent resource description language, building many more validators with many more options. While I may well have missed required, basic options, and welcome feedback, I strongly suggest that we start with a minimal framework and build upon it, instead of trying to build the moon from the outset. I have aimed in this spec for extensibility over completeness (and as such have left some explicit wiggle room in the set of validators to be implemented in the first pass.) Data model impact ----------------- None. REST API impact --------------- None; this change is SPI only. Other end user impact --------------------- For plugins using SaharaImageValidators, end-users will be able to modify the .yaml files to add packages or run validation or modification scripts against their images on spawn. Deployer impact --------------- None. Developer impact ---------------- This SPI method is optional; plugins may, if they're feeling a bit cowboy about things today, continue to spawn from any provided image without testing it. As such, there is no strictly required developer impact with this spec. Sahara-image-elements impact ---------------------------- None. Sahara-image-elements can keep doing its thing if this is adopted. Future dependent specs may drive changes in how we expect images to be packed (hopefully via an OpenStack API,) but this is not that spec, and can be approved wholly independently. Sahara-dashboard / Horizon impact --------------------------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: egafford Other contributors: ptoscano Work Items ---------- * Add SPI method and call in provisioning flow; wrap to ensure that if absent, no error is raised. * Build sahara.plugins.images as specified above, and all listed validators. * Write .yaml files for CDH and Ambari plugins using this mechanism (other plugins may adopt over time, as the SPI method is optional.) * Add unit tests. Dependencies ============ No new dependencies. Testing ======= The image validation mechanism itself does not need extensive new testing; the positive case will be covered by existing tests. Idempotence testing requires whitebox access to the server, and is not possible in the scenario framework; if this system ever is adopted for image generation, at that point we will have the blackbox hooks to test idempotence by rerunning against a pre-packed image (which should result in no change and a still-valid image.) Documentation Impact ==================== We will need to document the SPI method, the SaharaImageValidator classes, and the .yaml structure that describes them. References ========== None. ",,407,0
openstack%2Fdragonflow~master~I5618163bcc29fb6459284f5b95f46e07e61397ac,openstack/dragonflow,master,I5618163bcc29fb6459284f5b95f46e07e61397ac,Add new test objects destructor method,MERGED,2016-02-04 15:19:23.000000000,2016-02-14 12:46:53.000000000,2016-02-14 12:46:53.000000000,"[{'_account_id': 3}, {'_account_id': 2023}, {'_account_id': 11343}, {'_account_id': 12257}, {'_account_id': 13070}, {'_account_id': 18903}, {'_account_id': 20229}]","[{'number': 1, 'created': '2016-02-04 15:19:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/08a212fb004e00c5fbe4b605269dcb23007ec17e', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 2, 'created': '2016-02-07 13:54:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/f3027f7e82121485daf89a6eef64f28f4cd550a0', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 3, 'created': '2016-02-09 07:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a96e481e0031e63ed4e90bf5c2c8c8dea92b7a57', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 4, 'created': '2016-02-09 10:23:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/82a50c2c4f4e1040b339964d5819ef6112d4c2cd', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 5, 'created': '2016-02-09 10:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/bbd7cb7ac297d274a34256047a271b5c9662caa8', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 6, 'created': '2016-02-09 13:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/e7de74b9db097e7d5ddee11382883764fe55838b', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}, {'number': 7, 'created': '2016-02-14 08:39:50.000000000', 'files': ['dragonflow/tests/fullstack/test_neutron_api.py', 'dragonflow/tests/fullstack/test_objects.py', 'dragonflow/tests/fullstack/test_dhcp_flows.py', 'dragonflow/tests/fullstack/test_base.py', 'dragonflow/tests/fullstack/test_l2_responder.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/da58a31374cc795d5f9630b17e7a6704b309a850', 'message': 'Add new test objects destructor method\n\nChange-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac\n'}]",5,276291,da58a31374cc795d5f9630b17e7a6704b309a850,35,7,7,18903,,,0,"Add new test objects destructor method

Change-Id: I5618163bcc29fb6459284f5b95f46e07e61397ac
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/91/276291/7 && git format-patch -1 --stdout FETCH_HEAD,"['dragonflow/tests/fullstack/test_neutron_api.py', 'dragonflow/tests/fullstack/test_objects.py', 'dragonflow/tests/fullstack/test_dhcp_flows.py', 'dragonflow/tests/fullstack/test_base.py', 'dragonflow/tests/fullstack/test_l2_responder.py']",5,08a212fb004e00c5fbe4b605269dcb23007ec17e,destructor," ovs_flows_parser = OvsFlowsParser() flows_before = ovs_flows_parser.dump() flows_before = [flow for flow in flows_before if flow['table'] == str(const.ARP_TABLE) + ','] vm = self.store(objects.VMTestWrapper(self)) vm.create() ip = self._get_first_ipv4(vm.server.networks['private']) self.assertIsNotNone(ip) flows_middle = ovs_flows_parser.dump() flows_middle = [flow for flow in flows_middle if flow['table'] == str(const.ARP_TABLE) + ','] vm.server.stop() vm.delete() flows_delta = [flow for flow in flows_middle if flow not in flows_before] self.assertIsNotNone( self._find_arp_responder_flow_by_ip(flows_delta, ip) ) self.assertTrue(self._wait_for_flow_removal(flows_before, 30))"," try: ovs_flows_parser = OvsFlowsParser() flows_before = ovs_flows_parser.dump() flows_before = [flow for flow in flows_before if flow['table'] == str(const.ARP_TABLE) + ','] vm = objects.VMTestWrapper(self) vm.create() ip = self._get_first_ipv4(vm.server.networks['private']) self.assertIsNotNone(ip) flows_middle = ovs_flows_parser.dump() flows_middle = [flow for flow in flows_middle if flow['table'] == str(const.ARP_TABLE) + ','] vm.server.stop() vm.delete() vm = None flows_delta = [flow for flow in flows_middle if flow not in flows_before] self.assertIsNotNone( self._find_arp_responder_flow_by_ip(flows_delta, ip) ) self.assertTrue(self._wait_for_flow_removal(flows_before, 30)) finally: try: vm.delete() except Exception: pass # Ignore",67,64
openstack%2Fsenlin-dashboard~master~I384219ab989b91f2fee0245b9eb24780171f29f3,openstack/senlin-dashboard,master,I384219ab989b91f2fee0245b9eb24780171f29f3,Cleanup requirements.txt,MERGED,2016-01-21 06:12:41.000000000,2016-02-14 12:40:53.000000000,2016-02-14 12:40:53.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 14107}]","[{'number': 1, 'created': '2016-01-21 06:12:41.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/10f1febd0476b5130751c089a102c3ee309e5ac9', 'message': 'Cleanup requirements.txt\n\nBecause the dashboard is build on Horizon, so remove the\nlibraries which Horizon already have involved.\n\nChange-Id: I384219ab989b91f2fee0245b9eb24780171f29f3\n'}]",0,270614,10f1febd0476b5130751c089a102c3ee309e5ac9,9,5,1,6763,,,0,"Cleanup requirements.txt

Because the dashboard is build on Horizon, so remove the
libraries which Horizon already have involved.

Change-Id: I384219ab989b91f2fee0245b9eb24780171f29f3
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/14/270614/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,10f1febd0476b5130751c089a102c3ee309e5ac9,cleanup_requirements,,"# Horizon Core Requirements Babel>=1.3 Django<1.9,>=1.8 django-compressor>=1.4 django-openstack-auth>=2.0.0 iso8601>=0.1.9",0,6
openstack%2Fsahara~master~I8e8465332c58ed657f22b64016c40e041bd3a54e,openstack/sahara,master,I8e8465332c58ed657f22b64016c40e041bd3a54e,Add regex matching for node_group_templates_list(),MERGED,2016-01-29 22:15:14.000000000,2016-02-14 11:59:07.000000000,2016-02-14 11:59:07.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}, {'_account_id': 18777}]","[{'number': 1, 'created': '2016-01-29 22:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/a3e8de65860da9685aa4f2eff93ffeb98521e28f', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 2, 'created': '2016-02-02 18:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/de9bebee94f8f4342c029f0d3a3ce8cfe66e7450', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 3, 'created': '2016-02-02 18:48:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d91c32508eeeecae78f8eca9057a9bcab862148c', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 4, 'created': '2016-02-02 18:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c7158c11bc0a516d954204b4abe375949da43c67', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 5, 'created': '2016-02-09 20:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/2d88f9e4dd826fd7e9d21a06007bf8f8b6cc2f32', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 6, 'created': '2016-02-09 21:33:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b3169669a19cbd25586339c56e478fe02c6acb3e', 'message': 'Add substring matching for node_group_templates_list()\n\nThis change implements substring matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 7, 'created': '2016-02-09 21:37:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/93b9c4e72e197fe81c42060928727f493ef2b87a', 'message': 'Add regex matching for node_group_templates_list()\n\nThis change implements regex matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}, {'number': 8, 'created': '2016-02-10 20:46:36.000000000', 'files': ['sahara/service/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_templates.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/85d463df98739cdf0e7efefd734af2fa051d703c', 'message': 'Add regex matching for node_group_templates_list()\n\nThis change implements regex matching for filters on string\nvalues passed to node_group_templates_list() in the REST api.\nNo existing internal calls that use node_group_templates_get_all()\nare affected.\n\nPartial-bug: #1503345\nChange-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e\n'}]",4,274273,85d463df98739cdf0e7efefd734af2fa051d703c,39,8,8,8091,,,0,"Add regex matching for node_group_templates_list()

This change implements regex matching for filters on string
values passed to node_group_templates_list() in the REST api.
No existing internal calls that use node_group_templates_get_all()
are affected.

Partial-bug: #1503345
Change-Id: I8e8465332c58ed657f22b64016c40e041bd3a54e
",git fetch https://review.opendev.org/openstack/sahara refs/changes/73/274273/8 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_templates.py', 'sahara/conductor/manager.py']",6,a3e8de65860da9685aa4f2eff93ffeb98521e28f,bug/1503345," def node_group_template_get_all(self, context, substr_search=False, **kwargs): return self.db.node_group_template_get_all(context, substr_search, **kwargs)"," def node_group_template_get_all(self, context, **kwargs): return self.db.node_group_template_get_all(context, **kwargs)",83,8
openstack%2Fmurano~master~I26c91c54a53a585cdcfa9d55515869882ca446e1,openstack/murano,master,I26c91c54a53a585cdcfa9d55515869882ca446e1,Add test for update environment with invalid name,MERGED,2016-02-13 23:48:16.000000000,2016-02-14 11:57:07.000000000,2016-02-14 11:57:07.000000000,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2016-02-13 23:48:16.000000000', 'files': ['murano/tests/unit/api/v1/test_environments.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/4318fb9e17d79df51c173d62df5a8793e4fe5503', 'message': 'Add test for update environment with invalid name\n\n1.fix a typo in comment\n2.Add test for update environment with invalid name\n\nChange-Id: I26c91c54a53a585cdcfa9d55515869882ca446e1\n'}]",0,279901,4318fb9e17d79df51c173d62df5a8793e4fe5503,9,4,1,14107,,,0,"Add test for update environment with invalid name

1.fix a typo in comment
2.Add test for update environment with invalid name

Change-Id: I26c91c54a53a585cdcfa9d55515869882ca446e1
",git fetch https://review.opendev.org/openstack/murano refs/changes/01/279901/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/tests/unit/api/v1/test_environments.py'],1,4318fb9e17d79df51c173d62df5a8793e4fe5503,add_test_invalid_env," """"""Check that a too long env name results in an HTTPBadResquest."""""" def test_update_environment_with_invalid_name(self): """"""Check that update an invalid env name results in an HTTPBadResquest. """""" self._set_policy_rules( {'update_environment': '@'} ) self._create_fake_environment('env1', '111') self.expect_policy_check('update_environment', {'environment_id': '111'}) body = { 'name': ' ' } req = self._put('/environments/111', json.dumps(body)) result = req.get_response(self.api) self.assertEqual(400, result.status_code) result_msg = result.text.replace('\n', '') msg = ('Environment name must contain at least one ' 'non-white space symbol') self.assertIn(msg, result_msg) "," """"""Check that an too long env name results in an HTTPBadResquest.""""""",25,1
openstack%2Fcinder~master~I7554699760f2173655cb4fae434bd4933be77c9c,openstack/cinder,master,I7554699760f2173655cb4fae434bd4933be77c9c,Wrap the method to calculate virtual free capacity,MERGED,2015-12-15 00:07:55.000000000,2016-02-14 11:54:33.000000000,2016-02-10 22:11:59.000000000,"[{'_account_id': 3}, {'_account_id': 8846}, {'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14274}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16708}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-12-15 00:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/211baee890128b3db7dc6cb7c61d4fbc05f6988b', 'message': 'Wrap the method to calculate virtual free capacity\n\nThere is a logic already there to calculate virtual\nfree capacity in cinder/scheduler/weights/capacity.py.\nThis patch is just to wrap the same logic into a\nmethod in case to avoid the inconsistency when there\nare some other code paths to use the the same logic\nseperately. The reason for the patch is that:\nthe patch for blueprint capacity-headroom has the\nsame code path, and some reviewers prefer to use a\nsingle method to call them in the same way.\n\nPartial-Implements: blueprint capacity-headroom\nChange-Id: I7554699760f2173655cb4fae434bd4933be77c9c\n'}, {'number': 2, 'created': '2015-12-18 20:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1369cb4acd029fd229f4b1a95623a23554fb0de8', 'message': 'Wrap the method to calculate virtual free capacity\n\nThere is a logic already there to calculate virtual\nfree capacity in cinder/scheduler/weights/capacity.py.\nThis patch is just to wrap the same logic into a\nmethod in case to avoid the inconsistency when there\nare some other code paths to use the the same logic\nseperately. The reason for the patch is that:\nthe patch for blueprint capacity-headroom has the\nsame code path, and some reviewers prefer to use a\nsingle method to call them in the same way.\n\nPartial-Implements: blueprint capacity-headroom\nChange-Id: I7554699760f2173655cb4fae434bd4933be77c9c\n'}, {'number': 3, 'created': '2015-12-23 03:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a249f5d4d66b171d029254d60e5e460a40549948', 'message': 'Wrap the method to calculate virtual free capacity\n\nThere is a logic already there to calculate virtual\nfree capacity in cinder/scheduler/weights/capacity.py.\nThis patch is just to wrap the same logic into a\nmethod in case to avoid the inconsistency when there\nare some other code paths to use the the same logic\nseperately. The reason for the patch is that:\nthe patch for blueprint capacity-headroom has the\nsame code path, and some reviewers prefer to use a\nsingle method to call them in the same way.\n\nPartial-Implements: blueprint capacity-headroom\nChange-Id: I7554699760f2173655cb4fae434bd4933be77c9c\n'}, {'number': 4, 'created': '2015-12-24 07:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a00c80de024309dcf939fc2ec09d20c95c601328', 'message': 'Wrap the method to calculate virtual free capacity\n\nThere is a logic already there to calculate virtual\nfree capacity in cinder/scheduler/weights/capacity.py.\nThis patch is just to wrap the same logic into a\nmethod in case to avoid the inconsistency when there\nare some other code paths to use the the same logic\nseperately. The reason for the patch is that:\nthe patch for blueprint capacity-headroom has the\nsame code path, and some reviewers prefer to use a\nsingle method to call them in the same way.\n\nPartial-Implements: blueprint capacity-headroom\nChange-Id: I7554699760f2173655cb4fae434bd4933be77c9c\n'}, {'number': 5, 'created': '2016-01-21 03:20:52.000000000', 'files': ['cinder/scheduler/weights/capacity.py', 'cinder/tests/unit/test_utils.py', 'cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/81fcf8f5ea4283647d0b23dd6115ed8714625917', 'message': 'Wrap the method to calculate virtual free capacity\n\nThere is a logic already there to calculate virtual\nfree capacity in cinder/scheduler/weights/capacity.py.\nThis patch is just to wrap the same logic into a\nmethod in case to avoid the inconsistency when there\nare some other code paths to use the the same logic\nseperately. The reason for the patch is that:\nthe patch for blueprint capacity-headroom has the\nsame code path, and some reviewers prefer to use a\nsingle method to call them in the same way.\n\nPartial-Implements: blueprint capacity-headroom\nChange-Id: I7554699760f2173655cb4fae434bd4933be77c9c\n'}]",11,257620,81fcf8f5ea4283647d0b23dd6115ed8714625917,199,48,5,14274,,,0,"Wrap the method to calculate virtual free capacity

There is a logic already there to calculate virtual
free capacity in cinder/scheduler/weights/capacity.py.
This patch is just to wrap the same logic into a
method in case to avoid the inconsistency when there
are some other code paths to use the the same logic
seperately. The reason for the patch is that:
the patch for blueprint capacity-headroom has the
same code path, and some reviewers prefer to use a
single method to call them in the same way.

Partial-Implements: blueprint capacity-headroom
Change-Id: I7554699760f2173655cb4fae434bd4933be77c9c
",git fetch https://review.opendev.org/openstack/cinder refs/changes/20/257620/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/scheduler/weights/capacity.py', 'cinder/tests/unit/test_utils.py', 'cinder/utils.py']",3,211baee890128b3db7dc6cb7c61d4fbc05f6988b,bp/capacity-headroom,"import math def calculate_virtual_free_capacity(total_capacity, free_capacity, provisioned_capacity, thin_provisioning_support, max_over_subscription_ratio, reserved_percentage): """"""Calculate the virtual free capacity based on thin provisioning support. The logic is already there. Now just to Wrap the logic in a function to make consistency when there are more than one code path to use it. """""" total = float(total_capacity) reserved = float(reserved_percentage) / 100 if thin_provisioning_support: free = (total * max_over_subscription_ratio - provisioned_capacity - math.floor(total * reserved)) else: # Calculate how much free space is left after taking into # account the reserved space. free = free_capacity - math.floor(total * reserved) return free",,73,11
openstack%2Fkuryr~master~I7486eb1ffbf05f39abf7125a37435278aebc79ee,openstack/kuryr,master,I7486eb1ffbf05f39abf7125a37435278aebc79ee,Wrap public strings with i18n,MERGED,2016-01-12 01:29:38.000000000,2016-02-14 11:45:31.000000000,2016-02-14 11:45:31.000000000,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 8279}, {'_account_id': 9820}, {'_account_id': 11208}, {'_account_id': 11343}, {'_account_id': 12069}, {'_account_id': 14352}, {'_account_id': 15967}, {'_account_id': 16352}, {'_account_id': 17104}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-01-12 01:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/8a3e6061c2ab522849a6f3bc868f8474e9758fb9', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to thier i18n version.\n\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 2, 'created': '2016-01-12 23:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/0585286d7fa267c56f9c3ad0d3e53a7a1bf0e0a4', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 3, 'created': '2016-01-15 05:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/1b0d2246b92341b345d64e9235fc77482f470021', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 4, 'created': '2016-01-21 06:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/37742baddc6b00b224b6335cdbe1cbb09636db1a', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nDepends-On: I550ae919494c520ce0ea971cc8b71834a46e0781\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 5, 'created': '2016-02-09 05:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/852325fe49837a388b79ff92a067bfaa93f7cc18', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nDepends-On: I550ae919494c520ce0ea971cc8b71834a46e0781\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 7, 'created': '2016-02-11 00:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/c5acaf7e8c96d6be13ca30039f25f4986ce1551d', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nDepends-On: I550ae919494c520ce0ea971cc8b71834a46e0781\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 8, 'created': '2016-02-11 00:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/4ccbf0e1944d520e4464a34669ab54a7bd0160b3', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}, {'number': 9, 'created': '2016-02-12 01:05:25.000000000', 'files': ['kuryr/_i18n.py', 'kuryr/utils.py', 'kuryr/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/a35f137a58c41e9d344ad11589af5047ee634c8a', 'message': 'Wrap public strings with i18n\n\nCurrently the public error messages/logs are plain ASCII strings.\nThis patch converts them to their i18n version.\n\nChange-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee\nCloses-Bug: #1525053\n'}]",20,266092,a35f137a58c41e9d344ad11589af5047ee634c8a,46,13,8,17776,,,0,"Wrap public strings with i18n

Currently the public error messages/logs are plain ASCII strings.
This patch converts them to their i18n version.

Change-Id: I7486eb1ffbf05f39abf7125a37435278aebc79ee
Closes-Bug: #1525053
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/92/266092/9 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr/utils.py', 'kuryr/controllers.py']",2,8a3e6061c2ab522849a6f3bc868f8474e9758fb9,(detached,"from i18n import _ app.logger.error(_(""Error happened during retrieving the default "" ""subnet pools."").format(ex)) app.logger.error(_(""Error happend during creating a "" ""Neutron port: {0}"").format(ex)) app.logger.error(_(""Error happend during creating a "" ""Neutron port: {0}"").format(ex)) app.logger.debug(_(""Received JSON data {0} for"" "" /NetworkDriver.CreateNetwork"").format(json_data)) app.logger.info(_(""Created a new network with name {0}"" "" successfully: {1}"") app.logger.debug(_(""Received JSON data {0} for"" "" /NetworkDriver.DeleteNetwork"") app.logger.error(_(""Error happened during listing "" ""Neutron networks: {0}"").format(ex)) app.logger.error(_(""Subnet, {0}, is in use. "" ""Network cant be deleted."").format(subnet['id'])) app.logger.error(_(""Error happened during deleting a "" ""Neutron subnets: {0}"").format(ex)) app.logger.error(_(""Error happened during deleting a "" ""Neutron network: {0}"").format(ex)) app.logger.info(_(""Deleted the network with ID {0} successfully"") app.logger.debug(_(""Received JSON data {0} for "" ""/NetworkDriver.CreateEndpoint"") app.logger.debug(_(""Received JSON data {0} for"" "" /NetworkDriver.DeleteEndpoint"") app.logger.debug(_(""Received JSON data {0} for /NetworkDriver.Join"") app.logger.error(_('Preparing the veth pair was failed: {0}.') app.logger.error(_( 'Could not bind the Neutron port to the veth endpoint.')) app.logger.debug(_(""Received JSON data {0} for"" "" /NetworkDriver.DeleteEndpoint"") app.logger.error(_( 'endpoint.')) app.logger.error(_('Cleaning the veth pair up was failed.')) app.logger.debug(_(""Received /IpamDriver.GetDefaultAddressSpaces"")) app.logger.debug(_(""Received JSON data {0} for /IpamDriver.RequestPool"") app.logger.info(_(""Creating subnetpool with the given pool CIDR"")) app.logger.warning(_(""More than one prefixes present. "" ""Picking first one."")) app.logger.error(_(""Default neutron pools not found."")) app.logger.debug(_(""Received JSON data {0} for /IpamDriver.RequestAddress"") app.logger.warning(_(""More than one prefixes present. Picking "" ""first one."")) app.logger.error(_(""Error happend during ip allocation on"" ""Neutron side: {0}"").format(ex)) app.logger.debug(_(""Received JSON data {0} for /IpamDriver.ReleasePool"") app.logger.info(_(""The subnetpool with ID {0} is still in use."" "" It can't be deleted for now."").format(pool_id)) except n_exceptions.NeutronClientException as ex: app.logger.error(_(""Error happend during deleting a "" ""Neutron subnetpool: {0}"").format(ex)) app.logger.debug(_(""Received JSON data {0} for /IpamDriver.ReleaseAddress"") app.logger.error(_(""Error happend while fetching and deleting port, "" ""{0}"").format(ex))"," app.logger.error(""Error happened during retrieving the default "" ""subnet pools."".format(ex)) app.logger.error(""Error happend during creating a "" ""Neutron port: {0}"".format(ex)) app.logger.error(""Error happend during creating a "" ""Neutron port: {0}"".format(ex)) app.logger.debug(""Received JSON data {0} for /NetworkDriver.CreateNetwork"" .format(json_data)) app.logger.info(""Created a new network with name {0} successfully: {1}"" app.logger.debug(""Received JSON data {0} for /NetworkDriver.DeleteNetwork"" app.logger.error(""Error happened during listing "" ""Neutron networks: {0}"".format(ex)) app.logger.error(""Subnet, {0}, is in use. "" ""Network cant be deleted."".format(subnet['id'])) app.logger.error(""Error happened during deleting a "" ""Neutron subnets: {0}"".format(ex)) app.logger.error(""Error happened during deleting a "" ""Neutron network: {0}"".format(ex)) app.logger.info(""Deleted the network with ID {0} successfully"" app.logger.debug(""Received JSON data {0} for /NetworkDriver.CreateEndpoint"" app.logger.debug(""Received JSON data {0} for /NetworkDriver.DeleteEndpoint"" app.logger.debug(""Received JSON data {0} for /NetworkDriver.Join"" app.logger.error('Preparing the veth pair was failed: {0}.' app.logger.error( 'Could not bind the Neutron port to the veth endpoint.') app.logger.debug(""Received JSON data {0} for /NetworkDriver.DeleteEndpoint"" app.logger.error( 'endpoint.') app.logger.error('Cleaning the veth pair up was failed.') app.logger.debug(""Received /IpamDriver.GetDefaultAddressSpaces"") app.logger.debug(""Received JSON data {0} for /IpamDriver.RequestPool"" app.logger.info(""Creating subnetpool with the given pool CIDR"") app.logger.warning(""More than one prefixes present. "" ""Picking first one."") app.logger.error(""Default neutron pools not found"") app.logger.debug(""Received JSON data {0} for /IpamDriver.RequestAddress"" app.logger.warning(""More than one prefixes present. Picking "" ""first one."") app.logger.error(""Error happend during ip allocation on"" ""Neutron side: {0}"".format(ex)) app.logger.debug(""Received JSON data {0} for /IpamDriver.ReleasePool"" app.logger.info(""The subnetpool with ID {0} is still in use."" "" It can't be deleted for now."".format(pool_id)) except n_exceptions.NeutronClientException as ex: app.logger.error(""Error happend during deleting a "" ""Neutron subnetpool: {0}"".format(ex)) app.logger.debug(""Received JSON data {0} for /IpamDriver.ReleaseAddress"" app.logger.error(""Error happend while fetching and deleting port, "" ""{0}"".format(ex))",57,49
openstack%2Fnova~master~I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa,openstack/nova,master,I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa,Replace eventlet-based raw socket client with requests,MERGED,2016-02-09 21:15:13.000000000,2016-02-14 11:31:46.000000000,2016-02-09 23:25:12.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 17714}]","[{'number': 1, 'created': '2016-02-09 21:15:13.000000000', 'files': ['nova/tests/unit/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d754a830861fb55b047e7b4d43ba7f485fc120dd', 'message': ""Replace eventlet-based raw socket client with requests\n\nThere's no discernable reason why we need to use a raw\neventlet-based client TestWSGIServerWithSSL to confirm that a\nwsgi server is listening correctly and returning the expected\nresponse, especially since using eventlet leads to unreliable\ni/o on the socket unless there is an explicit yield before\nasserting the value of the response.\n\nSo requests is used to query the servers and verify the response.\n\nChange-Id: I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa\nCloses-Bug: #1543766\n""}]",0,278089,d754a830861fb55b047e7b4d43ba7f485fc120dd,14,8,1,11564,,,0,"Replace eventlet-based raw socket client with requests

There's no discernable reason why we need to use a raw
eventlet-based client TestWSGIServerWithSSL to confirm that a
wsgi server is listening correctly and returning the expected
response, especially since using eventlet leads to unreliable
i/o on the socket unless there is an explicit yield before
asserting the value of the response.

So requests is used to query the servers and verify the response.

Change-Id: I00c1c1e93eb7c66c3370434db4e3e6c00087f8aa
Closes-Bug: #1543766
",git fetch https://review.opendev.org/openstack/nova refs/changes/89/278089/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_wsgi.py'],1,d754a830861fb55b047e7b4d43ba7f485fc120dd,bug/1543766," response = requests.post( 'https://127.0.0.1:%s/' % fake_ssl_server.port, verify=os.path.join(SSL_CERT_DIR, 'ca.crt'), data='PING') self.assertEqual(response.text, 'PONG') response = requests.post( 'https://127.0.0.1:%s/' % fake_ssl_server.port, verify=os.path.join(SSL_CERT_DIR, 'ca.crt'), data='PING') self.assertEqual(response.text, 'PONG') response = requests.post('http://127.0.0.1:%s/' % fake_server.port, data='PING') self.assertEqual(response.text, 'PONG') fake_server.stop() fake_server.wait()"," cli = eventlet.connect((""localhost"", fake_ssl_server.port)) cli = eventlet.wrap_ssl(cli, ca_certs=os.path.join(SSL_CERT_DIR, 'ca.crt')) cli.write('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") cli = eventlet.connect((""localhost"", fake_ssl_server.port)) cli = eventlet.wrap_ssl(cli, ca_certs=os.path.join(SSL_CERT_DIR, 'ca.crt')) cli.write('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.read(8192) self.assertEqual(response[-4:], ""PONG"") cli = eventlet.connect((""localhost"", fake_server.port)) cli.sendall('POST / HTTP/1.1\r\nHost: localhost\r\n' 'Connection: close\r\nContent-length:4\r\n\r\nPING') response = cli.recv(8192) self.assertEqual(response[-4:], ""PONG"")",13,22
openstack%2Fnetworking-midonet~master~Ib8a79e347b6149f05c0f3835ab033986d5189ed9,openstack/networking-midonet,master,Ib8a79e347b6149f05c0f3835ab033986d5189ed9,ml2: Use SubnetContext.network,MERGED,2016-02-01 05:39:07.000000000,2016-02-14 11:11:54.000000000,2016-02-14 11:11:53.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6598}]","[{'number': 1, 'created': '2016-02-01 05:39:07.000000000', 'files': ['midonet/neutron/ml2/util.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/2f4de1098d8847f0846382c0f1deb0cd0549fe7f', 'message': 'ml2: Use SubnetContext.network\n\nWe don\'t need to make a query by ourselves anymore as\nML2 SubnetContext has obtained the ""network"" attribute while ago. [1]\n\n[1] I718c80512af0f2a43855efb16c2c0da69ef6b741\n\nChange-Id: Ib8a79e347b6149f05c0f3835ab033986d5189ed9\n'}]",0,274507,2f4de1098d8847f0846382c0f1deb0cd0549fe7f,9,3,1,6854,,,0,"ml2: Use SubnetContext.network

We don't need to make a query by ourselves anymore as
ML2 SubnetContext has obtained the ""network"" attribute while ago. [1]

[1] I718c80512af0f2a43855efb16c2c0da69ef6b741

Change-Id: Ib8a79e347b6149f05c0f3835ab033986d5189ed9
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/07/274507/1 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/ml2/util.py'],1,2f4de1098d8847f0846382c0f1deb0cd0549fe7f,ml2-subnet-network, net = context.network.current," # REVISIT(joe): implement this filtering using upstream neutron info # after the subnet context has the network information net = context._plugin.get_network(context._plugin_context, context.current['network_id'])",1,4
openstack%2Fironic~master~If98cfea3e1235f6ffcdb1f47d6c64e65d094168f,openstack/ironic,master,If98cfea3e1235f6ffcdb1f47d6c64e65d094168f,Comment out test options that already exists on tempest's tree,MERGED,2016-02-03 15:27:41.000000000,2016-02-14 11:08:25.000000000,2016-02-14 11:08:25.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 5174}, {'_account_id': 6610}, {'_account_id': 6773}, {'_account_id': 10343}, {'_account_id': 11929}, {'_account_id': 12356}, {'_account_id': 14629}]","[{'number': 1, 'created': '2016-02-03 15:27:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/cdc6d1f61b457ad5b29e6efc441f6390337975e7', 'message': ""Comment out test options that already exists on tempest's tree\n\nSince we can't remove ironic's  tests and options from tempest's tree\nuntil liberty-eol (to tests stable branches) we can't have such options\non our tree, except of course new options like deploywait_timeout.\n\nChange-Id: If98cfea3e1235f6ffcdb1f47d6c64e65d094168f\n""}, {'number': 2, 'created': '2016-02-03 19:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/98622177ced816e37fb9ca582039b3a92b97fa92', 'message': ""Comment out test options that already exists on tempest's tree\n\nSince we can't remove ironic's  tests and options from tempest's tree\nuntil liberty-eol (to tests stable branches) we can't have such options\non our tree, except of course new options like deploywait_timeout.\n\nChange-Id: If98cfea3e1235f6ffcdb1f47d6c64e65d094168f\n""}, {'number': 3, 'created': '2016-02-05 18:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2f91c7d6d15b419aa1d0ff52f44853df55a73739', 'message': ""Comment out test options that already exists on tempest's tree\n\nSince we can't remove ironic's  tests and options from tempest's tree\nuntil liberty-eol (to tests stable branches) we can't have such options\non our tree, except of course new options like deploywait_timeout.\n\nChange-Id: If98cfea3e1235f6ffcdb1f47d6c64e65d094168f\n""}, {'number': 4, 'created': '2016-02-10 17:23:32.000000000', 'files': ['ironic_tempest_plugin/config.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bf6de0040f1b81fca469d16e3e43cee0ec401257', 'message': ""Comment out test options that already exists on tempest's tree\n\nSince we can't remove ironic's  tests and options from tempest's tree\nuntil liberty-eol (to tests stable branches) we can't have such options\non our tree, except of course new options like deploywait_timeout.\n\nChange-Id: If98cfea3e1235f6ffcdb1f47d6c64e65d094168f\n""}]",2,275757,bf6de0040f1b81fca469d16e3e43cee0ec401257,42,9,4,5174,,,0,"Comment out test options that already exists on tempest's tree

Since we can't remove ironic's  tests and options from tempest's tree
until liberty-eol (to tests stable branches) we can't have such options
on our tree, except of course new options like deploywait_timeout.

Change-Id: If98cfea3e1235f6ffcdb1f47d6c64e65d094168f
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/275757/4 && git format-patch -1 --stdout FETCH_HEAD,['ironic_tempest_plugin/config.py'],1,cdc6d1f61b457ad5b29e6efc441f6390337975e7,remove-duplicated-options,"# NOTE(maurosr): Until liberty-eol we need to keep config options and tests # on tempest's tree to test stable branches and thus we have to comment the # options bellow to avoid duplication. Only new options should live here.# cfg.StrOpt('catalog_type', # default='baremetal', # help=""Catalog type of the baremetal provisioning service""), # cfg.BoolOpt('driver_enabled', # default=True, # help=""Whether the Ironic nova-compute driver is enabled""), # cfg.StrOpt('driver', # default='fake', # help=""Driver name which Ironic uses""), # cfg.StrOpt('endpoint_type', # default='publicURL', # choices=['public', 'admin', 'internal', # 'publicURL', 'adminURL', 'internalURL'], # help=""The endpoint type to use for the baremetal provisioning "" # ""service""),# cfg.IntOpt('active_timeout', # default=300, # help=""Timeout for Ironic node to completely provision""), # cfg.IntOpt('association_timeout', # default=30, # help=""Timeout for association of Nova instance and Ironic "" # ""node""), # cfg.IntOpt('power_timeout', # default=60, # help=""Timeout for Ironic power transitions.""), # cfg.IntOpt('unprovision_timeout', # default=300, # help=""Timeout for unprovisioning an Ironic node. "" # ""Takes longer since Kilo as Ironic performs an extra "" # ""step in Node cleaning."")"," cfg.StrOpt('catalog_type', default='baremetal', help=""Catalog type of the baremetal provisioning service""), cfg.BoolOpt('driver_enabled', default=True, help=""Whether the Ironic nova-compute driver is enabled""), cfg.StrOpt('driver', default='fake', help=""Driver name which Ironic uses""), cfg.StrOpt('endpoint_type', default='publicURL', choices=['public', 'admin', 'internal', 'publicURL', 'adminURL', 'internalURL'], help=""The endpoint type to use for the baremetal provisioning "" ""service""), cfg.IntOpt('active_timeout', default=300, help=""Timeout for Ironic node to completely provision""), cfg.IntOpt('association_timeout', default=30, help=""Timeout for association of Nova instance and Ironic "" ""node""), cfg.IntOpt('power_timeout', default=60, help=""Timeout for Ironic power transitions.""), cfg.IntOpt('unprovision_timeout', default=300, help=""Timeout for unprovisioning an Ironic node. "" ""Takes longer since Kilo as Ironic performs an extra "" ""step in Node cleaning."")",33,30
openstack%2Fironic~stable%2Fliberty~Ie2498bcb095535a25e46cea78365c2bfa4562d66,openstack/ironic,stable/liberty,Ie2498bcb095535a25e46cea78365c2bfa4562d66,cautiously fail on unhandled heartbeat exception,MERGED,2016-02-05 15:32:26.000000000,2016-02-14 10:48:56.000000000,2016-02-14 10:48:56.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 6610}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 11680}]","[{'number': 1, 'created': '2016-02-05 15:32:26.000000000', 'files': ['ironic/drivers/modules/agent_base_vendor.py', 'ironic/tests/drivers/test_agent_base_vendor.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5b7dff955b0ecac13706483507bd56c1796aecb0', 'message': ""cautiously fail on unhandled heartbeat exception\n\nCurrently, BaseAgentVendor.hearbeat handles uncaught exceptions by\nadvancing FSM with the 'failed' event no matter the state. Having\nencountered an error, some drivers may both advance FSM themselves and\nraise an exception. This leads to advancing the FSM with the 'fail' event\nwhile already in the DEPLOYFAIL state.\n\nSuggested patch purpose is to advance the FSM only if either in DEPLOYWAIT\nor DEPLOYING state.\n\nChange-Id: Ie2498bcb095535a25e46cea78365c2bfa4562d66\nCloses-Bug: #1506376\n(cherry picked from commit c6c885858a658b0a2d11be200133a3f530f1b6a1)\n""}]",0,276785,5b7dff955b0ecac13706483507bd56c1796aecb0,26,7,1,5805,,,0,"cautiously fail on unhandled heartbeat exception

Currently, BaseAgentVendor.hearbeat handles uncaught exceptions by
advancing FSM with the 'failed' event no matter the state. Having
encountered an error, some drivers may both advance FSM themselves and
raise an exception. This leads to advancing the FSM with the 'fail' event
while already in the DEPLOYFAIL state.

Suggested patch purpose is to advance the FSM only if either in DEPLOYWAIT
or DEPLOYING state.

Change-Id: Ie2498bcb095535a25e46cea78365c2bfa4562d66
Closes-Bug: #1506376
(cherry picked from commit c6c885858a658b0a2d11be200133a3f530f1b6a1)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/85/276785/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/agent_base_vendor.py', 'ironic/tests/drivers/test_agent_base_vendor.py']",2,5b7dff955b0ecac13706483507bd56c1796aecb0,bug/1506376," @mock.patch.object(agent_base_vendor.BaseAgentVendor, 'deploy_has_started', autospec=True) @mock.patch.object(deploy_utils, 'set_failed_state', autospec=True) @mock.patch.object(agent_base_vendor.BaseAgentVendor, 'deploy_is_done', autospec=True) @mock.patch.object(agent_base_vendor.LOG, 'exception', autospec=True) def test_heartbeat_deploy_done_raises_with_event(self, log_mock, done_mock, failed_mock, deploy_started_mock): deploy_started_mock.return_value = True kwargs = { 'agent_url': 'http://127.0.0.1:9999/bar' } with task_manager.acquire( self.context, self.node['uuid'], shared=True) as task: def driver_failure(*args, **kwargs): # simulate driver failure that both advances the FSM # and raises an exception task.node.provision_state = states.DEPLOYFAIL raise Exception('LlamaException') task.node.provision_state = states.DEPLOYWAIT task.node.target_provision_state = states.ACTIVE done_mock.side_effect = driver_failure self.passthru.heartbeat(task, **kwargs) # task.node.provision_state being set to DEPLOYFAIL # within the driver_failue, hearbeat should not call # deploy_utils.set_failed_state anymore self.assertFalse(failed_mock.called) log_mock.assert_called_once_with( 'Asynchronous exception for node ' '1be26c0b-03f2-4d2e-ae87-c02d7f33c123: Failed checking if deploy ' 'is done. exception: LlamaException') ",,36,1
openstack%2Fmanila~master~I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b,openstack/manila,master,I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b,[DEBUG] do not merge,ABANDONED,2016-02-13 16:28:26.000000000,2016-02-14 10:46:48.000000000,,"[{'_account_id': 3}, {'_account_id': 8851}]","[{'number': 1, 'created': '2016-02-13 16:28:26.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/fc0cb16628af5708a917c0aeefe695b57dad6ce4', 'message': '[DEBUG] do not merge\n\nChange-Id: I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b\n'}]",0,279889,fc0cb16628af5708a917c0aeefe695b57dad6ce4,9,2,1,8851,,,0,"[DEBUG] do not merge

Change-Id: I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b
",git fetch https://review.opendev.org/openstack/manila refs/changes/89/279889/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,fc0cb16628af5708a917c0aeefe695b57dad6ce4,," if is_ubuntu; then sudo apt-get install -y nfs-kernel-server nfs-common samba # NOTE(vponomaryov): following installation is valid for Ubuntu 'trusty'. sudo apt-get install -y software-properties-common sudo apt-add-repository --yes ppa:zfs-native/stable sudo apt-get -y -q update && sudo apt-get -y -q upgrade sudo apt-get install -y linux-headers-generic sudo apt-get install -y build-essential sudo apt-get install -y ubuntu-zfs sudo modprobe zfs else echo ""Manila Devstack plugin does not support installation ""\ ""of ZFS packages for non-'Ubuntu-trusty' distros. ""\ ""Please, install it first by other means or add its support ""\ ""for distro that is used by you to Manila project."" exit 1"," sudo apt-get install -y nfs-kernel-server nfs-common samba if [[ ! $(which zfs) ]]; then if is_ubuntu; then # NOTE(vponomaryov): following installation is valid for Ubuntu 'trusty'. sudo apt-get install -y software-properties-common sudo apt-add-repository --yes ppa:zfs-native/stable sudo apt-get -y -q update && sudo apt-get -y -q upgrade sudo apt-get install -y linux-headers-generic sudo apt-get install -y build-essential sudo apt-get install -y ubuntu-zfs sudo modprobe zfs else echo ""Manila Devstack plugin does not support installation ""\ ""of ZFS packages for non-'Ubuntu-trusty' distros. ""\ ""Please, install it first by other means or add its support ""\ ""for distro that is used by you to Manila project."" exit 1 fi",16,18
openstack%2Fmanila~master~I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b,openstack/manila,master,I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b,[DEBUG] do not merge,ABANDONED,2016-02-13 16:22:42.000000000,2016-02-14 10:46:44.000000000,,"[{'_account_id': 3}, {'_account_id': 8851}]","[{'number': 1, 'created': '2016-02-13 16:22:42.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/manila/commit/760cef842ee9eae1faa5bcb8df0b658268212971', 'message': '[DEBUG] do not merge\n\nChange-Id: I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b\n'}]",0,279888,760cef842ee9eae1faa5bcb8df0b658268212971,9,2,1,8851,,,0,"[DEBUG] do not merge

Change-Id: I8100f25f77de0bf7bd4dba637b4608dd0c0b3a5b
",git fetch https://review.opendev.org/openstack/manila refs/changes/88/279888/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,760cef842ee9eae1faa5bcb8df0b658268212971,zfs," if is_ubuntu; then sudo apt-get install -y nfs-kernel-server nfs-common samba # NOTE(vponomaryov): following installation is valid for Ubuntu 'trusty'. sudo apt-get install -y software-properties-common sudo apt-add-repository --yes ppa:zfs-native/stable sudo apt-get -y -q update && sudo apt-get -y -q upgrade sudo apt-get install -y linux-headers-generic sudo apt-get install -y build-essential sudo apt-get install -y ubuntu-zfs sudo modprobe zfs else echo ""Manila Devstack plugin does not support installation ""\ ""of ZFS packages for non-'Ubuntu-trusty' distros. ""\ ""Please, install it first by other means or add its support ""\ ""for distro that is used by you to Manila project."" exit 1"," sudo apt-get install -y nfs-kernel-server nfs-common samba if [[ ! $(which zfs) ]]; then if is_ubuntu; then # NOTE(vponomaryov): following installation is valid for Ubuntu 'trusty'. sudo apt-get install -y software-properties-common sudo apt-add-repository --yes ppa:zfs-native/stable sudo apt-get -y -q update && sudo apt-get -y -q upgrade sudo apt-get install -y linux-headers-generic sudo apt-get install -y build-essential sudo apt-get install -y ubuntu-zfs sudo modprobe zfs else echo ""Manila Devstack plugin does not support installation ""\ ""of ZFS packages for non-'Ubuntu-trusty' distros. ""\ ""Please, install it first by other means or add its support ""\ ""for distro that is used by you to Manila project."" exit 1 fi",16,18
openstack%2Fneutron~master~I3d793ba924dc3fd229d8588f4be1e943614f22bb,openstack/neutron,master,I3d793ba924dc3fd229d8588f4be1e943614f22bb,fullstack: Gracefully stop neutron-server process,MERGED,2016-02-10 16:38:39.000000000,2016-02-14 10:32:26.000000000,2016-02-12 17:12:56.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 12444}, {'_account_id': 12999}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2016-02-10 16:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a21ee50d6c644c88de3cbcf1bcfd93633352e717', 'message': ""[WIP] fullstack: Gracefully stop neutron-server process\n\nThere is possible scenario that neutron-server loses connection to AMQP\nbus and that can cause timeouts when hanging on rpc calls. On the other\nhand, we should be able to stop service gracefully even if AMQP server\nisn't running.\n\nChange-Id: I3d793ba924dc3fd229d8588f4be1e943614f22bb\nRelated-bug: 1494363\n""}, {'number': 2, 'created': '2016-02-11 16:33:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6de5b22409929a05cc4ce7a6146d9b80734c097c', 'message': ""fullstack: Gracefully stop neutron-server process\n\nThere is possible scenario that neutron-server loses connection to AMQP\nbus and that can cause timeouts when hanging on rpc calls. On the other\nhand, we should be able to stop service gracefully even if AMQP server\nisn't running.\n\nNote that this change applies only for neutron-server because previous\ninvestigations showed agents using oslo service can hang on rpc causing\nother failures. Next step should be making sure rabbitmq is stopped as\nlast or decrease rpc timeouts in agents.\n\nChange-Id: I3d793ba924dc3fd229d8588f4be1e943614f22bb\nRelated-bug: 1494363\nCloses-bug: 1541742\n""}, {'number': 3, 'created': '2016-02-11 16:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3c53db0de5aca38d93a4c412a6eeaf59e6eaa6f9', 'message': ""fullstack: Gracefully stop neutron-server process\n\nThere is possible scenario that neutron-server loses connection to AMQP\nbus and that can cause timeouts when hanging on rpc calls. On the other\nhand, we should be able to stop service gracefully even if AMQP server\nisn't running.\n\nDuring teardown there were still neutron-server orphaned api workers\nprocesses running that had open connection to database which caused\nunexpected failures.\n\nNote that this change applies only for neutron-server because previous\ninvestigations showed agents using oslo service can hang on rpc causing\nother failures. Next step should be making sure rabbitmq is stopped as\nlast or decrease rpc timeouts in agents.\n\nChange-Id: I3d793ba924dc3fd229d8588f4be1e943614f22bb\nRelated-bug: 1494363\nCloses-bug: 1541742\n""}, {'number': 4, 'created': '2016-02-11 17:13:50.000000000', 'files': ['neutron/tests/fullstack/resources/process.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5a7b892df46f5d48840f600f03e7be2db999a1d', 'message': ""fullstack: Gracefully stop neutron-server process\n\nThere is possible scenario that neutron-server loses connection to AMQP\nbus and that can cause timeouts when hanging on rpc calls. On the other\nhand, we should be able to stop service gracefully even if AMQP server\nisn't running.\n\nDuring teardown there were still neutron-server orphaned api workers\nprocesses running that had open connection to database which caused\nunexpected failures.\n\nNote that this change applies only for neutron-server because previous\ninvestigations showed agents using oslo service can hang on rpc causing\nother failures. Next step should be making sure rabbitmq is stopped as\nlast or decrease rpc timeouts in agents.\n\nChange-Id: I3d793ba924dc3fd229d8588f4be1e943614f22bb\nRelated-bug: 1494363\nCloses-bug: 1541742\n""}]",2,278501,a5a7b892df46f5d48840f600f03e7be2db999a1d,67,15,4,8655,,,0,"fullstack: Gracefully stop neutron-server process

There is possible scenario that neutron-server loses connection to AMQP
bus and that can cause timeouts when hanging on rpc calls. On the other
hand, we should be able to stop service gracefully even if AMQP server
isn't running.

During teardown there were still neutron-server orphaned api workers
processes running that had open connection to database which caused
unexpected failures.

Note that this change applies only for neutron-server because previous
investigations showed agents using oslo service can hang on rpc causing
other failures. Next step should be making sure rabbitmq is stopped as
last or decrease rpc timeouts in agents.

Change-Id: I3d793ba924dc3fd229d8588f4be1e943614f22bb
Related-bug: 1494363
Closes-bug: 1541742
",git fetch https://review.opendev.org/openstack/neutron refs/changes/01/278501/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/fullstack/resources/process.py'],1,a21ee50d6c644c88de3cbcf1bcfd93633352e717,bug/1494363,"import signal self.kill_signal = signal.SIGKILL self.process.stop(block=True, kill_signal=self.kill_signal) self.process_fixture.kill_signal = signal.SIGTERM", self.process.stop(block=True),4,1
openstack%2Frally~master~I0400d5451585ca3c1a82450a58b33125a2488b42,openstack/rally,master,I0400d5451585ca3c1a82450a58b33125a2488b42,[Verify] Don't create new image when image already exists,MERGED,2016-01-31 03:30:20.000000000,2016-02-14 10:17:31.000000000,2016-02-14 10:17:31.000000000,"[{'_account_id': 3}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 7428}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-01-31 03:30:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2b5a12173151bc8399ff26bdc5d070a23bb4079d', 'message': ""[Verify] Don't create new image when cirros image already exists\n\nIf there is a cirros image in the cloud, Tempest resources context\nwill not create a new image and will use the existing one for tests.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 2, 'created': '2016-01-31 03:34:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/71a472fd4f30e1aed5e80dbbbb41a6b0104fe362', 'message': ""[Verify] Don't create new image when cirros image already exists\n\nIf there is a cirros image in the cloud, Tempest resources context\nwill not create a new image and will use the existing one for tests.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 3, 'created': '2016-01-31 19:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/148a59e3483ee854fae9b5ae0e13e33c82faabb7', 'message': ""[Verify] Don't create new image when cirros image already exists\n\nIf there is a cirros image in the cloud, Tempest resources context\nwill not create a new image and will use the existing one for tests.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 4, 'created': '2016-02-01 01:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ef524c23c18a6abdf58e874bc46191479fe6b806', 'message': ""[Verify] Don't create new image when cirros image already exists\n\nIf there is a cirros image in the cloud, Tempest resources context\nwill not create a new image and will use the existing one for tests.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 5, 'created': '2016-02-02 20:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a105e706ab246bed48c2533a4bcfa1fb56865b8e', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover-resources\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 6, 'created': '2016-02-02 20:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/830137c65f4575127f3e70b446af9c1cec569af5', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover-resources\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 7, 'created': '2016-02-04 15:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8ebedaff512df602712946dc623923c61b57d062', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover-resources\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 8, 'created': '2016-02-04 15:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/db9cd5d19edf60be9f0272a1e5e310ce751aeb3d', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 9, 'created': '2016-02-05 15:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a2e62a8705827ba5a1339e85888fe9bd988fbbe5', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 10, 'created': '2016-02-05 16:38:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6ff53d687258d6d3be8e1c98372e4517bf504ed9', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 11, 'created': '2016-02-05 20:57:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f95e13b2bc0238f6781dda4838ca73e975aa6e47', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 12, 'created': '2016-02-05 21:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a9ecf611b019ae6f6a08b9ca7fab1efd96b5261e', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nThe etc/rally/rally.conf.sample file has a lot of changes because\ncommand `tox -e genconfig` was executed before submmiting the changes.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 13, 'created': '2016-02-10 17:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a4182182f9f2a3ebc4298228a70a68c2055fd0c3', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nThe etc/rally/rally.conf.sample file has a lot of changes because\ncommand `tox -e genconfig` was executed before submmiting the changes.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 14, 'created': '2016-02-10 17:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2e4033b06e204490ad81e224ea6c8620ba8d46fd', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 15, 'created': '2016-02-11 17:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fb60e4783767d667e16fec400dc7592e3c021a24', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 16, 'created': '2016-02-11 17:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e973c963582878f16e08df1f3f8e08c2b5efc14e', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 17, 'created': '2016-02-11 18:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2d5b8f09402124cd9b97972203a9945f6880c398', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 18, 'created': '2016-02-13 06:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f9b77dd4a1f916051599e760746b60377ef4ec93', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}, {'number': 19, 'created': '2016-02-13 18:15:20.000000000', 'files': ['etc/rally/rally.conf.sample', 'rally/verification/tempest/config.py', 'rally/verification/tempest/tempest.py', 'tests/unit/verification/test_config.py', 'etc/rally.bash_completion'], 'web_link': 'https://opendev.org/openstack/rally/commit/b5e81f217ca73215e4b019c1c060bd6e8bd834ad', 'message': ""[Verify] Don't create new image when image already exists\n\nThe current Tempest resources context creates an image in the cloud every\ntime when we run the tests and even when we run only one test. It is not\noptimal. In order to avoid creating the image every time a new option for\n`rally verify start` was added. So if we want to run tests, but we want\nto use some existing image, we should execute the following command:\n\n    $ rally verify start --discover\n\nThis option will tell Rally to search for the image with name that is\nconfigured in the rally.conf file and the discovered image will be used\nfor the tests.\n\nThe next step will be to add the same functionality for flavors.\n\nChange-Id: I0400d5451585ca3c1a82450a58b33125a2488b42\n""}]",22,274397,b5e81f217ca73215e4b019c1c060bd6e8bd834ad,82,9,19,7428,,,0,"[Verify] Don't create new image when image already exists

The current Tempest resources context creates an image in the cloud every
time when we run the tests and even when we run only one test. It is not
optimal. In order to avoid creating the image every time a new option for
`rally verify start` was added. So if we want to run tests, but we want
to use some existing image, we should execute the following command:

    $ rally verify start --discover

This option will tell Rally to search for the image with name that is
configured in the rally.conf file and the discovered image will be used
for the tests.

The next step will be to add the same functionality for flavors.

Change-Id: I0400d5451585ca3c1a82450a58b33125a2488b42
",git fetch https://review.opendev.org/openstack/rally refs/changes/97/274397/17 && git format-patch -1 --stdout FETCH_HEAD,"['rally/verification/tempest/config.py', 'tests/unit/verification/test_config.py']",2,2b5a12173151bc8399ff26bdc5d070a23bb4079d,(HEAD," def test__create_image_when_image_exists(self): client = self.context.clients.glance() client.images.list.return_value = [fakes.FakeImage(name=""CirrOS"")] image = self.context._create_image() self.assertEqual(""CirrOS"", image.name) ",,23,1
openstack%2Fcinder~stable%2Fliberty~I753af89aa5aae5ad20abe48441df3dbd02b8e05e,openstack/cinder,stable/liberty,I753af89aa5aae5ad20abe48441df3dbd02b8e05e,Fix for showing default quotas to non-admin user,MERGED,2016-01-15 15:41:06.000000000,2016-02-14 10:00:54.000000000,2016-02-10 21:00:38.000000000,"[{'_account_id': 3}, {'_account_id': 7198}, {'_account_id': 9535}, {'_account_id': 11224}, {'_account_id': 11904}, {'_account_id': 13144}, {'_account_id': 16269}, {'_account_id': 16660}]","[{'number': 1, 'created': '2016-01-15 15:41:06.000000000', 'files': ['cinder/api/contrib/quotas.py', 'cinder/tests/unit/api/contrib/test_quotas.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/740e9e8ead2aee96f7a9415e96497cf506d6898c', 'message': 'Fix for showing default quotas to non-admin user\n\nEarlier, when non-admin user wanted to get quotas for his own\nprojects, if there were no custom quota values set, the API\nused to return zero values.\n\nChange-Id: I753af89aa5aae5ad20abe48441df3dbd02b8e05e\nCloses-Bug: 1523928\n(cherry picked from commit ef0bfc288d6513a868e0e25b1f7effd13fccb754)\n'}]",0,268201,740e9e8ead2aee96f7a9415e96497cf506d6898c,59,8,1,8912,,,0,"Fix for showing default quotas to non-admin user

Earlier, when non-admin user wanted to get quotas for his own
projects, if there were no custom quota values set, the API
used to return zero values.

Change-Id: I753af89aa5aae5ad20abe48441df3dbd02b8e05e
Closes-Bug: 1523928
(cherry picked from commit ef0bfc288d6513a868e0e25b1f7effd13fccb754)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/01/268201/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/api/contrib/quotas.py', 'cinder/tests/unit/api/contrib/test_quotas.py']",2,740e9e8ead2aee96f7a9415e96497cf506d6898c,bug/1523928,"from keystoneclient import exceptions def test_show_non_admin_user(self): self.controller._get_project = mock.Mock() self.controller._get_project.side_effect = exceptions.Forbidden self.controller._get_quotas = mock.Mock(side_effect= self.controller._get_quotas) result = self.controller.show(self.req, 'foo') self.assertDictMatch(make_body(), result) self.controller._get_quotas.assert_called_with( self.req.environ['cinder.context'], 'foo', False, parent_project_id=None) ",,13,1
openstack%2Fsahara~master~I268c439ab83587375dbff7e125e23f07c9381d83,openstack/sahara,master,I268c439ab83587375dbff7e125e23f07c9381d83,Add regex matching for job_binary_internal_list(),MERGED,2016-02-11 17:17:10.000000000,2016-02-14 09:33:13.000000000,2016-02-14 09:33:13.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 10670}, {'_account_id': 12038}]","[{'number': 1, 'created': '2016-02-11 17:17:10.000000000', 'files': ['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/conductor/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/7811036c6a945439a056efcb6f3b2629f9465a8f', 'message': 'Add regex matching for job_binary_internal_list()\n\nThis change implements regex matching for filters on string\nvalues passed to job_binary_internal_list() in the REST api.\nNo existing internal calls that use job_binary_internal_get_all()\nare affected.\n\nPartial-bug: #1503345\n\nChange-Id: I268c439ab83587375dbff7e125e23f07c9381d83\n'}]",2,279196,7811036c6a945439a056efcb6f3b2629f9465a8f,15,4,1,8091,,,0,"Add regex matching for job_binary_internal_list()

This change implements regex matching for filters on string
values passed to job_binary_internal_list() in the REST api.
No existing internal calls that use job_binary_internal_get_all()
are affected.

Partial-bug: #1503345

Change-Id: I268c439ab83587375dbff7e125e23f07c9381d83
",git fetch https://review.opendev.org/openstack/sahara refs/changes/96/279196/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/edp/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_edp.py', 'sahara/conductor/manager.py']",6,7811036c6a945439a056efcb6f3b2629f9465a8f,bug/1503345," def job_binary_internal_get_all(self, context, regex_search=False, **kwargs): :param context: The context, and associated authentication, to use with this operation :param regex_search: If True, enable regex matching for filter values. See the user guide for more information on how regex matching is handled. If False, no regex matching is done. :param kwargs: Specifies values for named fields by which to constrain the search return self.db.job_binary_internal_get_all(context, regex_search, **kwargs)"," def job_binary_internal_get_all(self, context, **kwargs): e.g. cluster_get_all(name='wordcount.jar') return self.db.job_binary_internal_get_all(context, **kwargs)",86,18
openstack%2Fsahara~master~Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab,openstack/sahara,master,Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab,Add regex matching for clusters_list(),MERGED,2016-02-02 21:46:35.000000000,2016-02-14 09:33:06.000000000,2016-02-14 09:33:06.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13919}]","[{'number': 1, 'created': '2016-02-02 21:46:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7f32372f214976c71f05e8607398d99085565b15', 'message': 'Add substring matching for clusters_list()\n\nThis change implements substring matching for filters\non string values passed to clusters_list() in the REST api.\nNo existing internal calls that use cluster_get_all()\nare affected.\n\nChange-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab\nPartial-bug: #1503345\n'}, {'number': 2, 'created': '2016-02-02 21:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/eadfee4b80023506bd7f36c0e671e3aecdde4a9d', 'message': 'Add substring matching for clusters_list()\n\nThis change implements substring matching for filters\non string values passed to clusters_list() in the REST api.\nNo existing internal calls that use cluster_get_all()\nare affected.\n\nChange-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab\nPartial-bug: #1503345\n'}, {'number': 3, 'created': '2016-02-03 15:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7e2006fb9f4e470fbbfe96446b3ed90d6c76ddc1', 'message': 'Add substring matching for clusters_list()\n\nThis change implements substring matching for filters\non string values passed to clusters_list() in the REST api.\nNo existing internal calls that use cluster_get_all()\nare affected.\n\nChange-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab\nPartial-bug: #1503345\n'}, {'number': 4, 'created': '2016-02-10 20:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/21ca1627147c7ad12cf8950b8cd51834fc469d26', 'message': 'Add substring matching for clusters_list()\n\nThis change implements substring matching for filters\non string values passed to clusters_list() in the REST api.\nNo existing internal calls that use cluster_get_all()\nare affected.\n\nChange-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab\nPartial-bug: #1503345\n'}, {'number': 5, 'created': '2016-02-10 20:41:06.000000000', 'files': ['sahara/service/api.py', 'sahara/db/sqlalchemy/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_clusters.py', 'sahara/conductor/api.py', 'sahara/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/de518b1b15f034feb13ddf2866baf93e2c8800e5', 'message': 'Add regex matching for clusters_list()\n\nThis change implements regex matching for filters\non string values passed to clusters_list() in the REST api.\nNo existing internal calls that use cluster_get_all()\nare affected.\n\nChange-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab\nPartial-bug: #1503345\n'}]",0,275421,de518b1b15f034feb13ddf2866baf93e2c8800e5,20,7,5,8091,,,0,"Add regex matching for clusters_list()

This change implements regex matching for filters
on string values passed to clusters_list() in the REST api.
No existing internal calls that use cluster_get_all()
are affected.

Change-Id: Ifac63bef69cdf8c94132bfb5f14b646ae587b9ab
Partial-bug: #1503345
",git fetch https://review.opendev.org/openstack/sahara refs/changes/21/275421/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/db/sqlalchemy/api.py', 'sahara/conductor/api.py', 'sahara/db/api.py', 'sahara/tests/unit/conductor/manager/test_clusters.py', 'sahara/conductor/manager.py']",5,7f32372f214976c71f05e8607398d99085565b15,bug/1503345," def cluster_get_all(self, context, substr_search=False, **kwargs): :param context: The context, and associated authentication, to use with this operation :param substr_search: If True, enable substring matching for filter values. See the user guide for more information on how substring matching is handled. If False, no substring matching is done. :param kwargs: Specifies values for named fields by which to constrain the search return self.db.cluster_get_all(context, substr_search, **kwargs)"," def cluster_get_all(self, context, **kwargs): e.g. cluster_get_all(plugin_name='vanilla', hadoop_version='1.1') return self.db.cluster_get_all(context, **kwargs)",117,14
openstack%2Fsahara~master~I081db3ba1637c0c619c0b7a25c34e73674394cac,openstack/sahara,master,I081db3ba1637c0c619c0b7a25c34e73674394cac,Allow 'is_public' to be set on protected resources,MERGED,2016-01-25 20:41:28.000000000,2016-02-14 09:33:02.000000000,2016-02-14 09:33:01.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8932}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-01-25 20:41:28.000000000', 'files': ['sahara/service/validations/acl.py', 'sahara/tests/unit/service/validation/test_protected_validation.py', 'sahara/tests/unit/service/validation/edp/test_job_executor.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/52ce8fd8e4578d9efaf82fa64e8a8085d497874b', 'message': ""Allow 'is_public' to be set on protected resources\n\nThis change allows the meta-data value 'is_public' to\nbe set on protected resources without having to first\nset 'is_protected' to False as long as 'is_public' is\nthe only value that is changing.\n\nChange-Id: I081db3ba1637c0c619c0b7a25c34e73674394cac\nImplements: blueprint allow-public-on-protected\n""}]",0,272260,52ce8fd8e4578d9efaf82fa64e8a8085d497874b,15,9,1,8091,,,0,"Allow 'is_public' to be set on protected resources

This change allows the meta-data value 'is_public' to
be set on protected resources without having to first
set 'is_protected' to False as long as 'is_public' is
the only value that is changing.

Change-Id: I081db3ba1637c0c619c0b7a25c34e73674394cac
Implements: blueprint allow-public-on-protected
",git fetch https://review.opendev.org/openstack/sahara refs/changes/60/272260/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/service/validations/acl.py', 'sahara/tests/unit/service/validation/test_protected_validation.py', 'sahara/tests/unit/service/validation/edp/test_job_executor.py']",3,52ce8fd8e4578d9efaf82fa64e8a8085d497874b,bp/allow-public-on-protected," je.check_job_execution_update(job_exec, {'job_configs': {}}) job_exec, {'is_protected': False, 'job_configs': {}})"," je.check_job_execution_update(job_exec, {'is_public': True}) job_exec, {'is_protected': False, 'is_public': True})",67,2
openstack%2Fsahara~master~I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463,openstack/sahara,master,I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463,Move notifications options into oslo_messaging_notifications,MERGED,2016-01-20 08:39:32.000000000,2016-02-14 09:23:46.000000000,2016-02-14 09:23:46.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 15424}]","[{'number': 1, 'created': '2016-01-20 08:39:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9382dba50de209c7917cce3d571d3ef0216ef674', 'message': 'Move notifications options into oslo_messaging_notifications group\n\nIn order to make the notifications configuration clearer, let\'s put\nits options into ""oslo_messaging_notifications"" group just like what\noslo_messaging did.\n\nChange-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463\nCloses-Bug: #1536034\n'}, {'number': 2, 'created': '2016-01-20 08:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5d6c58b84ed2bbed01570d6689ebad1960eaaed7', 'message': 'Move notifications options into oslo_messaging_notifications\n\nIn order to make the notifications configuration clearer, let\'s put\nits options into ""oslo_messaging_notifications"" group just like what\noslo_messaging did.\n\nChange-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463\nCloses-Bug: #1536034\n'}, {'number': 3, 'created': '2016-01-21 12:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ee92a7a25be23711f1b95920d4899afe8282965a', 'message': 'Move notifications options into oslo_messaging_notifications\n\nIn order to make the notifications configuration clearer, let\'s put\nits options into ""oslo_messaging_notifications"" group just like what\noslo_messaging did.\n\nCloses-Bug: #1536034\nDepends-On: I4c9f4de73e7732cb90cb742c94daddf8d2d5e398\nChange-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463\n'}, {'number': 4, 'created': '2016-01-22 03:37:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/79ba1d4cc43e8f52e03b63dceeaee1f8cb40b24d', 'message': 'Move notifications options into oslo_messaging_notifications\n\nIn order to make the notifications configuration clearer, let\'s put\nits options into ""oslo_messaging_notifications"" group just like what\noslo_messaging did.\n\nCloses-Bug: #1536034\nDepends-On: I4c9f4de73e7732cb90cb742c94daddf8d2d5e398\nChange-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463\n'}, {'number': 5, 'created': '2016-01-27 07:13:07.000000000', 'files': ['doc/source/userdoc/configuration.guide.rst', 'sahara/utils/notification/sender.py', 'sahara/config.py', 'sahara/utils/rpc.py', 'releasenotes/notes/options-to-oslo_messaging_notifications-cee206fc4f74c217.yaml', 'sahara/tests/unit/utils/test_rpc.py', 'devstack/plugin.sh', 'sahara/main.py', 'sahara/tests/unit/utils/notification/test_sender.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/24be6c081dd4ca2c3435a464dd7b228b9888a349', 'message': 'Move notifications options into oslo_messaging_notifications\n\nIn order to make the notifications configuration clearer, let\'s put\nits options into ""oslo_messaging_notifications"" group just like what\noslo_messaging did.\n\nCloses-Bug: #1536034\nDepends-On: I4c9f4de73e7732cb90cb742c94daddf8d2d5e398\nChange-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463\n'}]",2,270055,24be6c081dd4ca2c3435a464dd7b228b9888a349,40,6,5,15424,,,0,"Move notifications options into oslo_messaging_notifications

In order to make the notifications configuration clearer, let's put
its options into ""oslo_messaging_notifications"" group just like what
oslo_messaging did.

Closes-Bug: #1536034
Depends-On: I4c9f4de73e7732cb90cb742c94daddf8d2d5e398
Change-Id: I0ba6348ecbc1852e24c9eb7b5f0fa9f3e5922463
",git fetch https://review.opendev.org/openstack/sahara refs/changes/55/270055/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/userdoc/configuration.guide.rst', 'sahara/utils/notification/sender.py', 'sahara/config.py', 'sahara/utils/rpc.py', 'sahara/tests/unit/utils/test_rpc.py', 'devstack/plugin.sh', 'sahara/main.py', 'sahara/tests/unit/utils/notification/test_sender.py']",8,9382dba50de209c7917cce3d571d3ef0216ef674,bug/1536034," self.override_config(""enable"", True, group='oslo_messaging_notifications')"," self.override_config(""enable_notifications"", True)",30,17
openstack%2Fsahara~master~Ibbb6d5c3218f62aafac4881d2a44d57c3b342fe7,openstack/sahara,master,Ibbb6d5c3218f62aafac4881d2a44d57c3b342fe7,notification_driver from group DEFAULT is deprecated,MERGED,2016-01-19 11:43:06.000000000,2016-02-14 09:19:51.000000000,2016-02-14 09:19:51.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8932}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 15424}]","[{'number': 1, 'created': '2016-01-19 11:43:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3319d04934c00f3bb809919f99cc4fdbfe2b9f34', 'message': 'notification_driver from group DEFAULT is deprecated\n\nOption ""notification_driver"" from group ""DEFAULT"" is deprecated, let\'s\nuse option ""driver"" from group ""oslo_messaging_notifications"" instead.\n\nReference link:\n[1] https://github.com/openstack/oslo.messaging/blob/master/oslo_messaging/notify/notifier.py#L34\n\nChange-Id: Ibbb6d5c3218f62aafac4881d2a44d57c3b342fe7\n'}, {'number': 2, 'created': '2016-01-21 12:51:33.000000000', 'files': ['doc/source/userdoc/configuration.guide.rst', 'devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/sahara/commit/3a1cd0f6b5b1b4c9d52ae7fa6dfa290cfb086409', 'message': 'notification_driver from group DEFAULT is deprecated\n\nOption ""notification_driver"" from group ""DEFAULT"" is deprecated, let\'s\nuse option ""driver"" from group ""oslo_messaging_notifications"" instead.\n\nReference link:\n[1] https://github.com/openstack/oslo.messaging/blob/master/oslo_messaging/notify/notifier.py#L34\n\nChange-Id: Ibbb6d5c3218f62aafac4881d2a44d57c3b342fe7\nDepends-On:  I4c9f4de73e7732cb90cb742c94daddf8d2d5e398\n'}]",0,269574,3a1cd0f6b5b1b4c9d52ae7fa6dfa290cfb086409,40,10,2,15424,,,0,"notification_driver from group DEFAULT is deprecated

Option ""notification_driver"" from group ""DEFAULT"" is deprecated, let's
use option ""driver"" from group ""oslo_messaging_notifications"" instead.

Reference link:
[1] https://github.com/openstack/oslo.messaging/blob/master/oslo_messaging/notify/notifier.py#L34

Change-Id: Ibbb6d5c3218f62aafac4881d2a44d57c3b342fe7
Depends-On:  I4c9f4de73e7732cb90cb742c94daddf8d2d5e398
",git fetch https://review.opendev.org/openstack/sahara refs/changes/74/269574/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/userdoc/configuration.guide.rst', 'devstack/plugin.sh']",2,3319d04934c00f3bb809919f99cc4fdbfe2b9f34,bug/1536034," iniset $SAHARA_CONF_FILE oslo_messaging_notifications driver ""messaging"""," iniset $SAHARA_CONF_FILE DEFAULT notification_driver ""messaging""",10,2
openstack%2Fsahara~master~I89d379aebd1f3bb8e619c314bb9085b44459e623,openstack/sahara,master,I89d379aebd1f3bb8e619c314bb9085b44459e623,Use the oslo.utils.reflection to extract class name,MERGED,2016-02-11 15:10:14.000000000,2016-02-14 09:11:35.000000000,2016-02-14 09:11:35.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 8091}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 15424}, {'_account_id': 19372}]","[{'number': 1, 'created': '2016-02-11 15:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d5e07a42e51d017c29929a522c49a74e7943af5a', 'message': 'Use the oslo.utils.reflection to extract class name\n\nThe oslo.utils reflection module/code handles more variations\nof where a class name may come from (on) python 2 and python 3,\nits usage allows getting more accurate class names, so we might\nas well use it.\n\nChange-Id: I89d379aebd1f3bb8e619c314bb9085b44459e623\n'}, {'number': 2, 'created': '2016-02-12 05:31:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5281e03fcbc72a4d0a1235c2bbace2da8fa6a0a0', 'message': 'Use the oslo.utils.reflection to extract class name\n\nThe oslo.utils reflection module/code handles more variations\nof where a class name may come from (on) python 2 and python 3,\nits usage allows getting more accurate class names, so we might\nas well use it.\n\nChange-Id: I89d379aebd1f3bb8e619c314bb9085b44459e623\n'}, {'number': 3, 'created': '2016-02-12 13:32:04.000000000', 'files': ['sahara/plugins/cdh/client/types.py', 'sahara/service/validation.py', 'sahara/cli/sahara_subprocess.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/915ad55d03f06c248af612a4ba7ff062078a9443', 'message': 'Use the oslo.utils.reflection to extract class name\n\nThe oslo.utils reflection module/code handles more variations\nof where a class name may come from (on) python 2 and python 3,\nits usage allows getting more accurate class names, so we might\nas well use it.\n\nChange-Id: I89d379aebd1f3bb8e619c314bb9085b44459e623\n'}]",0,279125,915ad55d03f06c248af612a4ba7ff062078a9443,23,7,3,15424,,,0,"Use the oslo.utils.reflection to extract class name

The oslo.utils reflection module/code handles more variations
of where a class name may come from (on) python 2 and python 3,
its usage allows getting more accurate class names, so we might
as well use it.

Change-Id: I89d379aebd1f3bb8e619c314bb9085b44459e623
",git fetch https://review.opendev.org/openstack/sahara refs/changes/25/279125/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/client/types.py', 'sahara/service/validation.py', 'sahara/cli/sahara_subprocess.py']",3,d5e07a42e51d017c29929a522c49a74e7943af5a,reflection-class-name,"from oslo_utils import reflection cls_name = reflection.get_class_name(e, fully_qualified=False) result['exception'] = cls_name + ': ' + str(e)", result['exception'] = e.__class__.__name__ + ': ' + str(e),13,5
openstack%2Fneutron~master~I1d99f5b1d3599301ca2324b9f96165e8a3316b98,openstack/neutron,master,I1d99f5b1d3599301ca2324b9f96165e8a3316b98,Remove VPN installation plumbing,MERGED,2016-02-10 20:55:39.000000000,2016-02-14 08:56:29.000000000,2016-02-14 08:56:29.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10184}, {'_account_id': 11347}, {'_account_id': 11682}, {'_account_id': 12403}, {'_account_id': 13995}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15752}, {'_account_id': 17211}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-10 20:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/58e3ef3d42feca7347991461bf350deba56df048', 'message': 'Remove VPN installation plumbing\n\nNow that tests are being removed, this no longer belongs\nhere. It should be cohesive with the vpnaas devstack plugin.\n\nChange-Id: I1d99f5b1d3599301ca2324b9f96165e8a3316b98\n'}, {'number': 2, 'created': '2016-02-11 00:13:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d56f26394801c203dda3afcddee68c560a4c8cc', 'message': 'Remove VPN installation plumbing\n\nNow that tests are being removed, this no longer belongs\nhere. It should be cohesive with the vpnaas devstack plugin.\n\nChange-Id: I1d99f5b1d3599301ca2324b9f96165e8a3316b98\n'}, {'number': 3, 'created': '2016-02-11 14:37:47.000000000', 'files': ['neutron/tests/contrib/gate_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/652e121f8fe60f24bdd734a0282a237722291d7d', 'message': 'Remove VPN installation plumbing\n\nNow that tests are being removed, this no longer belongs\nhere. It should be cohesive with the vpnaas devstack plugin.\n\nChange-Id: I1d99f5b1d3599301ca2324b9f96165e8a3316b98\n'}]",0,278626,652e121f8fe60f24bdd734a0282a237722291d7d,47,23,3,748,,,0,"Remove VPN installation plumbing

Now that tests are being removed, this no longer belongs
here. It should be cohesive with the vpnaas devstack plugin.

Change-Id: I1d99f5b1d3599301ca2324b9f96165e8a3316b98
",git fetch https://review.opendev.org/openstack/neutron refs/changes/26/278626/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/contrib/gate_hook.sh'],1,58e3ef3d42feca7347991461bf350deba56df048,remove-vpnaas-plumbing,," cat > $DEVSTACK_PATH/local.conf <<EOF [[post-config|/etc/neutron/neutron_vpnaas.conf]] [service_providers] service_provider=VPN:openswan:neutron_vpnaas.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default EOF export DEVSTACK_LOCAL_CONFIG+="" enable_plugin neutron-vpnaas git://git.openstack.org/openstack/neutron-vpnaas enable_plugin neutron git://git.openstack.org/openstack/neutron enable_service q-qos "" ",0,14
openstack%2Fopenstack-manuals~master~I6513019e03ac132f97d67d3b44c501e33770bf6d,openstack/openstack-manuals,master,I6513019e03ac132f97d67d3b44c501e33770bf6d,[common] Cleanup description about mailing lists,ABANDONED,2016-02-12 08:01:07.000000000,2016-02-14 08:41:20.000000000,,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-12 08:01:07.000000000', 'files': ['doc/common/app_support.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6823a23b36a3093b706e1d66dc37edaaba56297a', 'message': '[common] Cleanup description about mailing lists\n\nChange-Id: I6513019e03ac132f97d67d3b44c501e33770bf6d\n'}]",0,279411,6823a23b36a3093b706e1d66dc37edaaba56297a,4,2,1,10497,,,0,"[common] Cleanup description about mailing lists

Change-Id: I6513019e03ac132f97d67d3b44c501e33770bf6d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/11/279411/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/app_support.rst'],1,6823a23b36a3093b706e1d66dc37edaaba56297a,cleanup,"and help others who might have similar issues. To subscribe or view the archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack. You might be interested in the other mailing lists for specific projects or development, which you can find the all mailing lists and thier descriptions at https://wiki.openstack.org/wiki/Mailing_Lists.","and help others who might have similar issues. To subscribe or view the archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/openstack. You might be interested in the other mailing lists for specific projects or development, which you can find `on the wiki <https://wiki.openstack.org/wiki/MailingLists>`__. A description of all mailing lists is available at https://wiki.openstack.org/wiki/MailingLists.",6,7
openstack%2Fmagnum~master~I5a73488d0c7529ea2e1416a9e41b4893f220a25a,openstack/magnum,master,I5a73488d0c7529ea2e1416a9e41b4893f220a25a,API: Move validate_properties to REST API layer,MERGED,2016-02-04 03:52:51.000000000,2016-02-14 08:40:42.000000000,2016-02-14 08:40:42.000000000,"[{'_account_id': 3}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12175}, {'_account_id': 12385}, {'_account_id': 18498}]","[{'number': 1, 'created': '2016-02-04 03:52:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d4bb0ca1da3b84cb0144d2a1638bc4bdf8f24d33', 'message': 'API: Move validate_properties to REST API layer\n\nWe restrict that only node_count can be modified, this can be moved into\nREST API layer before we send request to conductor though rpc.\n\nBesides, remove some bad test case in REST API layer\nChange-Id: I5a73488d0c7529ea2e1416a9e41b4893f220a25a\n'}, {'number': 2, 'created': '2016-02-04 11:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/419b145d78d6f9b21c236b4eb69f28a58b5d9978', 'message': 'API: Move validate_properties to REST API layer\n\nWe restrict that only node_count can be modified, this can be moved into\nREST API layer before we send request to conductor though rpc.\n\nBesides, remove some bad test case in REST API layer\nChange-Id: I5a73488d0c7529ea2e1416a9e41b4893f220a25a\n'}, {'number': 3, 'created': '2016-02-05 08:57:42.000000000', 'files': ['magnum/tests/unit/api/controllers/v1/test_bay.py', 'magnum/tests/unit/conductor/handlers/test_bay_conductor.py', 'magnum/tests/unit/api/test_validation.py', 'magnum/api/controllers/v1/bay.py', 'magnum/api/validation.py', 'magnum/conductor/handlers/bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/f9a087e9122acc2913147a8b5a72dd81cc965e62', 'message': 'API: Move validate_properties to REST API layer\n\nWe restrict that only node_count can be modified, this can be moved into\nREST API layer before we send request to conductor though rpc.\n\nBesides, remove some bad test case in REST API layer\nChange-Id: I5a73488d0c7529ea2e1416a9e41b4893f220a25a\n'}]",14,276028,f9a087e9122acc2913147a8b5a72dd81cc965e62,24,6,3,12175,,,0,"API: Move validate_properties to REST API layer

We restrict that only node_count can be modified, this can be moved into
REST API layer before we send request to conductor though rpc.

Besides, remove some bad test case in REST API layer
Change-Id: I5a73488d0c7529ea2e1416a9e41b4893f220a25a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/28/276028/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/controllers/v1/test_bay.py', 'magnum/api/controllers/v1/bay.py', 'magnum/conductor/handlers/bay_conductor.py']",3,d4bb0ca1da3b84cb0144d2a1638bc4bdf8f24d33,remove_bay_update_name_from_func,," _update_allowed_properties = set(['node_count']) def _validate_properties(self, delta): update_disallowed_properties = delta - self._update_allowed_properties if update_disallowed_properties: err = (_(""cannot change bay property(ies) %s."") % "", "".join(update_disallowed_properties)) raise exception.InvalidParameterValue(err=err) self._validate_properties(delta) ",31,47
openstack%2Fcinder~master~I13796bc880cd2f71dcce934274b810027cbb39b6,openstack/cinder,master,I13796bc880cd2f71dcce934274b810027cbb39b6,Remove old client version checks from 3PAR driver,MERGED,2016-01-15 21:56:06.000000000,2016-02-14 08:07:14.000000000,2016-02-10 23:16:08.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13689}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16880}, {'_account_id': 16898}, {'_account_id': 16917}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18120}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19852}]","[{'number': 1, 'created': '2016-01-15 21:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/12675b20396a585805b9bc1f8d76b0c72c228349', 'message': 'Remove old client version checks from 3PAR driver\n\nThe minimum required 3PAR client version has been bumped from 4.0.0 to\n4.1.0. There are a few checks that look for a version between these\nthat can be removed.\n\nDocImpact\nChange-Id: I13796bc880cd2f71dcce934274b810027cbb39b6\n'}, {'number': 2, 'created': '2016-02-04 16:57:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4b6d7cd86440dcfd20428f88440b5c77289a4de1', 'message': 'Remove old client version checks from 3PAR driver\n\nThe minimum required 3PAR client version has been bumped from 4.0.0 to\n4.1.0. There are a few checks that look for a version between these\nthat can be removed.\n\nDocImpact\nChange-Id: I13796bc880cd2f71dcce934274b810027cbb39b6\n'}, {'number': 3, 'created': '2016-02-08 18:30:41.000000000', 'files': ['cinder/volume/drivers/hpe/hpe_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/839a32ee04345da1b832ad5659ad2df330f7aca0', 'message': 'Remove old client version checks from 3PAR driver\n\nThe minimum required 3PAR client version has been bumped from 4.0.0 to\n4.1.0. There are a few checks that look for a version between these\nthat can be removed.\n\nDocImpact\nChange-Id: I13796bc880cd2f71dcce934274b810027cbb39b6\n'}]",0,268346,839a32ee04345da1b832ad5659ad2df330f7aca0,146,46,3,16917,,,0,"Remove old client version checks from 3PAR driver

The minimum required 3PAR client version has been bumped from 4.0.0 to
4.1.0. There are a few checks that look for a version between these
that can be removed.

DocImpact
Change-Id: I13796bc880cd2f71dcce934274b810027cbb39b6
",git fetch https://review.opendev.org/openstack/cinder refs/changes/46/268346/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/hpe/hpe_3par_common.py'],1,12675b20396a585805b9bc1f8d76b0c72c228349,remove-client-version-checks," 3.0.12 - Remove client version checks for replication VERSION = ""3.0.12"" cl = client.HPE3ParClient(hpe3par_api_url, timeout=timeout) self._do_replication_setup() if remotecopy_support: self._do_replication_setup()","MIN_REP_CLIENT_VERSION = '4.0.2' VERSION = ""3.0.11"" # Timeout is only supported in version 4.0.2 and greater of the # python-3parclient. if hpe3parclient.version >= MIN_REP_CLIENT_VERSION: cl = client.HPE3ParClient(hpe3par_api_url, timeout=timeout) else: cl = client.HPE3ParClient(hpe3par_api_url) if hpe3parclient.version >= MIN_REP_CLIENT_VERSION: self._do_replication_setup() if (hpe3parclient.version >= MIN_REP_CLIENT_VERSION and remotecopy_support): if hpe3parclient.version >= MIN_REP_CLIENT_VERSION: self._do_replication_setup()",6,14
openstack%2Fsenlin~master~Idfe9816d06f12bb1d5cf4e1b088985ab4ccc24dc,openstack/senlin,master,Idfe9816d06f12bb1d5cf4e1b088985ab4ccc24dc,Rework unit tests for node service requests,MERGED,2016-02-14 07:05:31.000000000,2016-02-14 08:01:01.000000000,2016-02-14 08:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 8246}]","[{'number': 1, 'created': '2016-02-14 07:05:31.000000000', 'files': ['senlin/engine/service.py', 'senlin/engine/node.py', 'senlin/tests/unit/engine/service/test_nodes.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/a1c410322946dde86cbaf750b0b54a9ae81d7662', 'message': 'Rework unit tests for node service requests\n\nThis patch reworks the unit tests for node operations in service module.\nThe intent is to make unit tests just unit tests. We are avoiding too\nmuch real object creation in unit tests.\n\nChange-Id: Idfe9816d06f12bb1d5cf4e1b088985ab4ccc24dc\n'}]",0,279928,a1c410322946dde86cbaf750b0b54a9ae81d7662,6,2,1,8246,,,0,"Rework unit tests for node service requests

This patch reworks the unit tests for node operations in service module.
The intent is to make unit tests just unit tests. We are avoiding too
much real object creation in unit tests.

Change-Id: Idfe9816d06f12bb1d5cf4e1b088985ab4ccc24dc
",git fetch https://review.opendev.org/openstack/senlin refs/changes/28/279928/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/service.py', 'senlin/engine/node.py', 'senlin/tests/unit/engine/service/test_nodes.py']",3,a1c410322946dde86cbaf750b0b54a9ae81d7662,ut-nodes,"from oslo_utils import uuidutilsfrom senlin.common import consts from senlin.common import exception as excfrom senlin.db.sqlalchemy import api as db_api @mock.patch.object(db_api, 'node_get') def test_node_find_by_uuid(self, mock_get): x_node = mock.Mock() mock_get.return_value = x_node aid = uuidutils.generate_uuid() result = self.eng.node_find(self.ctx, aid) self.assertEqual(x_node, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'node_get_by_name') @mock.patch.object(db_api, 'node_get') def test_node_find_by_short_id(self, mock_get, mock_name): mock_get.return_value = None x_node = mock.Mock() mock_name.return_value = x_node aid = uuidutils.generate_uuid() result = self.eng.node_find(self.ctx, aid) self.assertEqual(x_node, result) mock_get.assert_called_once_with(self.ctx, aid, project_safe=True) mock_name.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'node_get_by_short_id') def test_node_find_by_short_id_directly(self, mock_shortid): x_node = mock.Mock() mock_shortid.return_value = x_node aid = 'abcdef' result = self.eng.node_find(self.ctx, aid) self.assertEqual(x_node, result) mock_shortid.assert_called_once_with(self.ctx, aid, project_safe=True) @mock.patch.object(db_api, 'node_get_by_short_id') def test_node_find_not_found(self, mock_shortid): mock_shortid.return_value = None ex = self.assertRaises(exc.NodeNotFound, self.eng.node_find, self.ctx, 'BOGUS') self.assertEqual(""The node (BOGUS) could not be found."", six.text_type(ex)) mock_shortid.assert_called_once_with(self.ctx, 'BOGUS', project_safe=True) @mock.patch.object(node_mod.Node, 'load_all') def test_node_list(self, mock_load): obj_1 = mock.Mock() obj_1.to_dict.return_value = {'k': 'v1'} obj_2 = mock.Mock() obj_2.to_dict.return_value = {'k': 'v2'} mock_load.return_value = [obj_1, obj_2] result = self.eng.node_list(self.ctx) self.assertEqual([{'k': 'v1'}, {'k': 'v2'}], result) mock_load.assert_called_once_with( self.ctx, cluster_id=None, filters=None, sort=None, limit=None, marker=None, project_safe=True) @mock.patch.object(service.EngineService, 'cluster_find') @mock.patch.object(node_mod.Node, 'load_all') def test_node_list_with_cluster_id(self, mock_load, mock_find): obj_1 = mock.Mock() obj_1.to_dict.return_value = {'k': 'v1'} obj_2 = mock.Mock() obj_2.to_dict.return_value = {'k': 'v2'} mock_load.return_value = [obj_1, obj_2] mock_find.return_value = mock.Mock(id='FAKE_CLUSTER') result = self.eng.node_list(self.ctx, cluster_id='MY_CLUSTER', filters={'K': 'V'}, sort='SSS', limit=123, marker='MMM', project_safe=False) self.assertEqual([{'k': 'v1'}, {'k': 'v2'}], result) mock_find.assert_called_once_with(self.ctx, 'MY_CLUSTER') mock_load.assert_called_once_with(self.ctx, cluster_id='FAKE_CLUSTER', filters={'K': 'V'}, sort='SSS', limit=123, marker='MMM', project_safe=False) @mock.patch.object(node_mod.Node, 'load_all') def test_node_list_with_params(self, mock_load): obj_1 = mock.Mock() obj_1.to_dict.return_value = {'k': 'v1'} obj_2 = mock.Mock() obj_2.to_dict.return_value = {'k': 'v2'} mock_load.return_value = [obj_1, obj_2] result = self.eng.node_list(self.ctx, cluster_id=None, filters='FFF', sort='SSS', limit=123, marker='MMM', project_safe=False) self.assertEqual([{'k': 'v1'}, {'k': 'v2'}], result) mock_load.assert_called_once_with(self.ctx, cluster_id=None, filters='FFF', sort='SSS', limit=123, marker='MMM', project_safe=False) def test_node_list_bad_limit(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, limit='MANY') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'MANY' specified for 'limit'"", six.text_type(ex.exc_info[1])) def test_node_list_bad_project_safe(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, project_safe='yes') self.assertEqual(exc.InvalidParameter, ex.exc_info[0]) self.assertEqual(""Invalid value 'yes' specified for 'project_safe'"", six.text_type(ex.exc_info[1])) @mock.patch.object(service.EngineService, 'cluster_find') def test_node_list_cluster_not_found(self, mock_find): mock_find.side_effect = exc.ClusterNotFound(cluster='BOGUS') ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, cluster_id='BOGUS') self.assertEqual(exc.ClusterNotFound, ex.exc_info[0]) self.assertEqual(""The cluster (BOGUS) could not be found."", six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'BOGUS') @mock.patch.object(node_mod.Node, 'load_all') def test_node_list_empty(self, mock_load): mock_load.return_value = [] result = self.eng.node_list(self.ctx) self.assertEqual([], result) mock_load.assert_called_once_with(self.ctx, cluster_id=None, filters=None, sort=None, limit=None, marker=None, project_safe=True) @mock.patch('senlin.engine.actions.base.Action') @mock.patch('senlin.engine.node.Node') @mock.patch.object(service.EngineService, 'profile_find') def test_node_create(self, notify, mock_profile, mock_node, mock_action): mock_profile.return_value = mock.Mock(id='PROFILE_ID') x_node = mock.Mock(id='NODE_ID') x_node.to_dict.return_value = {'foo': 'bar'} mock_node.return_value = x_node x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_create(self.ctx, 'NODE1', 'FAKE_PROFILE') self.assertEqual({'foo': 'bar', 'action': 'ACTION_ID'}, result) mock_profile.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_node.assert_called_once_with( 'NODE1', 'PROFILE_ID', '', self.ctx, index=-1, role=None, metadata={}, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) x_node.store.assert_called_once_with(self.ctx) mock_action.assert_called_once_with( 'NODE_ID', consts.NODE_CREATE, name='node_create_NODE_ID', cause=action_mod.CAUSE_RPC, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) notify.assert_called_once_with(action_id='ACTION_ID') @mock.patch('senlin.engine.actions.base.Action') @mock.patch('senlin.engine.node.Node') @mock.patch.object(db_api, 'cluster_next_index') @mock.patch.object(service.EngineService, 'cluster_find') @mock.patch.object(service.EngineService, 'profile_find') @mock.patch.object(dispatcher, 'start_action') def test_node_create_same_profile(self, notify, mock_profile, mock_cluster, mock_index, mock_node, mock_action): mock_profile.return_value = mock.Mock(id='PROFILE_ID', type='PROFILE_TYPE') x_cluster = mock.Mock(id='CLUSTER_ID', profile_id='PROFILE_ID') mock_cluster.return_value = x_cluster mock_index.return_value = 12345 x_node = mock.Mock(id='NODE_ID') x_node.to_dict.return_value = {'foo': 'bar'} mock_node.return_value = x_node x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_create(self.ctx, 'NODE1', 'FAKE_PROFILE', cluster_id='FAKE_CLUSTER') self.assertEqual({'foo': 'bar', 'action': 'ACTION_ID'}, result) mock_cluster.assert_called_once_with(self.ctx, 'FAKE_CLUSTER') mock_profile.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_index.assert_called_once_with(self.ctx, 'CLUSTER_ID') mock_node.assert_called_once_with( 'NODE1', 'PROFILE_ID', 'CLUSTER_ID', self.ctx, index=12345, role=None, metadata={}, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) x_node.store.assert_called_once_with(self.ctx) mock_action.assert_called_once_with( 'NODE_ID', consts.NODE_CREATE, name='node_create_NODE_ID', cause=action_mod.CAUSE_RPC, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) notify.assert_called_once_with(action_id='ACTION_ID') @mock.patch('senlin.engine.actions.base.Action') @mock.patch('senlin.engine.node.Node') @mock.patch.object(db_api, 'cluster_next_index') @mock.patch.object(service.EngineService, 'cluster_find') @mock.patch.object(service.EngineService, 'profile_find') @mock.patch.object(dispatcher, 'start_action') def test_node_create_same_profile_type(self, notify, mock_profile, mock_cluster, mock_index, mock_node, mock_action): mock_profile.side_effect = [ mock.Mock(id='NODE_PROFILE_ID', type='PROFILE_TYPE'), mock.Mock(id='CLUSTER_PROFILE_ID', type='PROFILE_TYPE'), ] x_cluster = mock.Mock(id='CLUSTER_ID', profile_id='CLUSTER_PROFILE_ID') mock_cluster.return_value = x_cluster mock_index.return_value = 12345 x_node = mock.Mock(id='NODE_ID') x_node.to_dict.return_value = {'foo': 'bar'} mock_node.return_value = x_node x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_create(self.ctx, 'NODE1', 'FAKE_PROFILE', cluster_id='FAKE_CLUSTER') self.assertEqual({'foo': 'bar', 'action': 'ACTION_ID'}, result) mock_cluster.assert_called_once_with(self.ctx, 'FAKE_CLUSTER') mock_profile.assert_has_calls([ mock.call(self.ctx, 'FAKE_PROFILE'), # for node mock.call(self.ctx, 'CLUSTER_PROFILE_ID'), # for cluster ]) mock_index.assert_called_once_with(self.ctx, 'CLUSTER_ID') mock_node.assert_called_once_with( 'NODE1', 'NODE_PROFILE_ID', 'CLUSTER_ID', self.ctx, index=12345, role=None, metadata={}, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) x_node.store.assert_called_once_with(self.ctx) mock_action.assert_called_once_with( 'NODE_ID', consts.NODE_CREATE, name='node_create_NODE_ID', cause=action_mod.CAUSE_RPC, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) notify.assert_called_once_with(action_id='ACTION_ID') @mock.patch.object(db_api, 'node_get_by_name') def test_node_create_name_conflict(self, mock_get): cfg.CONF.set_override('name_unique', True, enforce_type=True) mock_get.return_value = mock.Mock() ex = self.assertRaises(rpc.ExpectedException, self.eng.node_create, self.ctx, 'node-1', 'FAKE_PROFILE') self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(_(""The request is malformed: The node named "" ""(node-1) already exists.""), six.text_type(ex.exc_info[1])) @mock.patch.object(service.EngineService, 'profile_find') def test_node_create_profile_not_found(self, mock_profile): mock_profile.side_effect = exc.ProfileNotFound(profile='Bogus') self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) mock_profile.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(service.EngineService, 'cluster_find') @mock.patch.object(service.EngineService, 'profile_find') def test_node_create_cluster_not_found(self, mock_profile, mock_cluster): mock_profile.return_value = mock.Mock() mock_cluster.side_effect = exc.ClusterNotFound(cluster='Bogus') self.ctx, 'node-1', 'FAKE_PROFILE', self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) mock_profile.assert_called_once_with(self.ctx, 'FAKE_PROFILE') mock_cluster.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(service.EngineService, 'cluster_find') @mock.patch.object(service.EngineService, 'profile_find') def test_node_create_profile_type_not_match(self, mock_profile, mock_cluster): mock_profile.side_effect = [ mock.Mock(id='NODE_PROFILE_ID', type='TYPE-A'), mock.Mock(id='CLUSTER_PROFILE_ID', type='TYPE-B'), ] mock_cluster.return_value = mock.Mock(id='CLUSTER_ID', profile_id='CLUSTER_PROFILE_ID') self.ctx, 'node-1', 'NODE_PROFILE', cluster_id='FAKE_CLUSTER') self.assertEqual(exc.ProfileTypeNotMatch, ex.exc_info[0]) mock_profile.assert_has_calls([ mock.call(self.ctx, 'NODE_PROFILE'), mock.call(self.ctx, 'CLUSTER_PROFILE_ID'), ]) mock_cluster.assert_called_once_with(self.ctx, 'FAKE_CLUSTER') @mock.patch.object(service.EngineService, 'node_find') def test_node_get(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_node = mock.Mock(physical_id='PHYSICAL_ID') x_node.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_node result = self.eng.node_get(self.ctx, 'FAKE_NODE') self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_load.assert_called_once_with(self.ctx, node=x_obj) x_node.to_dict.assert_called_once_with() @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_get_with_details(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_node = mock.Mock(physical_id='PHYSICAL_ID') x_node.to_dict.return_value = {'foo': 'bar'} x_node.get_details.return_value = {'info': 'blahblah'} mock_load.return_value = x_node result = self.eng.node_get(self.ctx, 'FAKE_NODE', show_details=True) self.assertEqual({'foo': 'bar', 'details': {'info': 'blahblah'}}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_load.assert_called_once_with(self.ctx, node=x_obj) x_node.to_dict.assert_called_once_with() x_node.get_details.assert_called_once_with(self.ctx) @mock.patch.object(service.EngineService, 'node_find') def test_node_get_node_not_found(self, mock_find): mock_find.side_effect = exc.NodeNotFound(node='Bogus') ex = self.assertRaises(rpc.ExpectedException, self.eng.node_get, self.ctx, 'Bogus') self.assertEqual(exc.NodeNotFound, ex.exc_info[0]) self.assertEqual(""The node (Bogus) could not be found."", six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_get_node_not_created(self, mock_find, mock_load): x_obj = mock.Mock() mock_find.return_value = x_obj x_node = mock.Mock(physical_id=None) x_node.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_node result = self.eng.node_get(self.ctx, 'FAKE_NODE', show_details=True) self.assertEqual({'foo': 'bar'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_load.assert_called_once_with(self.ctx, node=x_obj) x_node.to_dict.assert_called_once_with() self.assertEqual(0, x_node.get_details.call_count) @mock.patch('senlin.engine.actions.base.Action') @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_update(self, mock_find, mock_load, mock_action, mock_start): x_obj = mock.Mock(id='FAKE_NODE_ID', name='NODE1', role='ROLE1', metadata={'KEY': 'VALUE'}) mock_find.return_value = x_obj x_node = mock.Mock() x_node.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_node x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action # all properties changed except profile id result = self.eng.node_update(self.ctx, 'FAKE_NODE', name='NODE2', role='NEW_ROLE', metadata={'KEY': 'V1'}) self.assertEqual({'foo': 'bar', 'action': 'ACTION_ID'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_action.assert_called_once_with( 'FAKE_NODE_ID', consts.NODE_UPDATE, name='node_update_FAKE_NOD', cause=action_mod.CAUSE_RPC, inputs={ 'name': 'NODE2', 'role': 'NEW_ROLE', 'metadata': { 'KEY': 'V1', } }, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) mock_start.assert_called_once_with(action_id='ACTION_ID') mock_load.assert_called_once_with(self.ctx, node=x_obj) @mock.patch.object(dispatcher, 'start_action') @mock.patch('senlin.engine.actions.base.Action') @mock.patch.object(service.EngineService, 'profile_find') @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_update_new_profile(self, mock_find, mock_load, mock_profile, mock_action, mock_start): x_obj = mock.Mock(id='FAKE_NODE_ID', role='ROLE1', metadata={'KEY': 'VALUE'}, profile_id='OLD_PROFILE_ID') x_obj.name = 'NODE1' mock_find.return_value = x_obj # Same profile type mock_profile.side_effect = [ mock.Mock(id='NEW_PROFILE_ID', type='PROFILE_TYPE'), mock.Mock(id='OLD_PROFILE_ID', type='PROFILE_TYPE'), ] x_node = mock.Mock() x_node.to_dict.return_value = {'foo': 'bar'} mock_load.return_value = x_node x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action # all properties are filtered out except for profile_id result = self.eng.node_update(self.ctx, 'FAKE_NODE', name='NODE1', role='ROLE1', metadata={'KEY': 'VALUE'}, profile_id='NEW_PROFILE') self.assertEqual({'foo': 'bar', 'action': 'ACTION_ID'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_profile.assert_has_calls([ mock.call(self.ctx, 'NEW_PROFILE'), mock.call(self.ctx, 'OLD_PROFILE_ID'), ]) mock_action.assert_called_once_with( 'FAKE_NODE_ID', consts.NODE_UPDATE, name='node_update_FAKE_NOD', cause=action_mod.CAUSE_RPC, inputs={ 'new_profile_id': 'NEW_PROFILE_ID', }, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) mock_start.assert_called_once_with(action_id='ACTION_ID') mock_load.assert_called_once_with(self.ctx, node=x_obj) @mock.patch.object(service.EngineService, 'node_find') def test_node_update_node_not_found(self, mock_find): mock_find.side_effect = exc.NodeNotFound(node='Bogus') self.assertEqual(exc.NodeNotFound, ex.exc_info[0]) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(service.EngineService, 'profile_find') @mock.patch.object(service.EngineService, 'node_find') def test_node_update_profile_not_found(self, mock_find, mock_profile): mock_find.return_value = mock.Mock() mock_profile.side_effect = exc.ProfileNotFound(profile='Bogus') self.ctx, 'FAKE_NODE', profile_id='Bogus') self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: The specified profile ' '(Bogus) is not found.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_profile.assert_called_once_with(self.ctx, 'Bogus') @mock.patch.object(service.EngineService, 'profile_find') @mock.patch.object(service.EngineService, 'node_find') def test_node_update_diff_profile_type(self, mock_find, mock_profile): mock_find.return_value = mock.Mock(profile_id='OLD_PROFILE_ID') mock_profile.side_effect = [ mock.Mock(id='NEW_PROFILE_ID', type='NEW_PROFILE_TYPE'), mock.Mock(id='OLD_PROFILE_ID', type='OLD_PROFILE_TYPE'), ] ex = self.assertRaises(rpc.ExpectedException, self.eng.node_update, self.ctx, 'FAKE_NODE', profile_id='NEW_PROFILE') self.assertEqual(exc.ProfileTypeNotMatch, ex.exc_info[0]) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_profile.assert_has_calls([ mock.call(self.ctx, 'NEW_PROFILE'), mock.call(self.ctx, 'OLD_PROFILE_ID'), ]) @mock.patch.object(service.EngineService, 'node_find') def test_node_update_no_property_for_update(self, mock_find): x_obj = mock.Mock(id='FAKE_NODE_ID', name='NODE1', role='ROLE1', metadata={'KEY': 'VALUE'}) mock_find.return_value = x_obj # no property has been specified for update ex = self.assertRaises(rpc.ExpectedException, self.eng.node_update, self.ctx, 'FAKE_NODE') self.assertEqual(exc.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: No property needs an ' 'update.', six.text_type(ex.exc_info[1])) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') @mock.patch(""senlin.engine.actions.base.Action"") @mock.patch.object(service.EngineService, 'node_find') def test_node_delete(self, mock_find, mock_action, mock_start): mock_find.return_value = mock.Mock(id='12345678AB') x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_delete(self.ctx, 'FAKE_NODE') self.assertEqual({'action': 'ACTION_ID'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_action.assert_called_once_with( '12345678AB', consts.NODE_DELETE, name='node_delete_12345678', cause=action_mod.CAUSE_RPC, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) mock_start.assert_called_once_with(action_id='ACTION_ID') @mock.patch.object(service.EngineService, 'node_find') def test_node_delete_node_not_found(self, mock_find): mock_find.side_effect = exc.NodeNotFound(node='Bogus') self.assertEqual(exc.NodeNotFound, ex.exc_info[0]) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch('senlin.engine.actions.base.Action') @mock.patch.object(service.EngineService, 'node_find') def test_node_check(self, mock_find, mock_action, mock_start): mock_find.return_value = mock.Mock(id='12345678AB') x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_check(self.ctx, 'FAKE_NODE') self.assertEqual({'action': 'ACTION_ID'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_action.assert_called_once_with( '12345678AB', consts.NODE_CHECK, name='node_check_12345678', cause=action_mod.CAUSE_RPC, inputs={}, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) mock_start.assert_called_once_with(action_id='ACTION_ID') @mock.patch.object(service.EngineService, 'node_find') def test_node_check_not_found(self, mock_find): mock_find.side_effect = exc.NodeNotFound(node='Bogus') self.eng.node_check, self.ctx, 'Bogus') self.assertEqual(exc.NodeNotFound, ex.exc_info[0]) mock_find.assert_called_once_with(self.ctx, 'Bogus') @mock.patch('senlin.engine.actions.base.Action') @mock.patch.object(service.EngineService, 'node_find') def test_node_recover(self, mock_find, mock_action, mock_start): mock_find.return_value = mock.Mock(id='12345678AB') x_action = mock.Mock(id='ACTION_ID') mock_action.return_value = x_action result = self.eng.node_recover(self.ctx, 'FAKE_NODE') self.assertEqual({'action': 'ACTION_ID'}, result) mock_find.assert_called_once_with(self.ctx, 'FAKE_NODE') mock_action.assert_called_once_with( '12345678AB', consts.NODE_RECOVER, name='node_recover_12345678', cause=action_mod.CAUSE_RPC, inputs={}, user=self.ctx.user, project=self.ctx.project, domain=self.ctx.domain) self.assertEqual(x_action.READY, x_action.status) x_action.store.assert_called_once_with(self.ctx) mock_start.assert_called_once_with(action_id='ACTION_ID') @mock.patch.object(service.EngineService, 'node_find') def test_node_recover_not_found(self, mock_find): mock_find.side_effect = exc.NodeNotFound(node='Bogus') self.eng.node_recover, self.ctx, 'Bogus') self.assertEqual(exc.NodeNotFound, ex.exc_info[0]) mock_find.assert_called_once_with(self.ctx, 'Bogus')","from senlin.common import exceptionfrom senlin.engine import environmentfrom senlin.tests.unit import fakes self.eng.init_tgm() self.eng.dispatcher = mock.Mock() env = environment.global_env() env.register_profile('TestProfile-1.0', fakes.TestProfile) self.spec = { 'type': 'TestProfile', 'version': '1.0', 'properties': { 'INT': 10, 'STR': 'string' } } self.profile = self.eng.profile_create(self.ctx, 'p-test', self.spec) def _verify_action(self, obj, action, name, target, cause, inputs=None): if inputs is None: inputs = {} self.assertEqual(action, obj['action']) self.assertEqual(name, obj['name']) self.assertEqual(target, obj['target']) self.assertEqual(cause, obj['cause']) self.assertEqual(inputs, obj['inputs']) def test_node_create_default(self, notify): node = self.eng.node_create(self.ctx, 'n-1', self.profile['id']) self.assertIsNotNone(node) self.assertEqual('n-1', node['name']) self.assertEqual(-1, node['index']) self.assertEqual(self.profile['id'], node['profile_id']) self.assertEqual('', node['cluster_id']) self.assertIsNone(node['role']) self.assertEqual({}, node['metadata']) def test_node_create_profile_not_found(self): self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) @mock.patch.object(dispatcher, 'start_action') def test_node_create_with_role_and_metadata(self, notify): node = self.eng.node_create(self.ctx, 'n-1', self.profile['id'], role='master', metadata={'k': 'v'}) self.assertIsNotNone(node) self.assertEqual('n-1', node['name']) self.assertEqual('master', node['role']) self.assertEqual({'k': 'v'}, node['metadata']) @mock.patch.object(dispatcher, 'start_action') def test_node_create_with_profile_name_or_short_id(self, notify): node = self.eng.node_create(self.ctx, 'n-1', self.profile['id'][:8]) self.assertIsNotNone(node) self.assertEqual(self.profile['id'], node['profile_id']) node = self.eng.node_create(self.ctx, 'n-2', self.profile['name']) self.assertIsNotNone(node) self.assertEqual(self.profile['id'], node['profile_id']) @mock.patch.object(dispatcher, 'start_action') def test_node_create_already_exists(self, notify): cfg.CONF.set_override('name_unique', True, enforce_type=True) node = self.eng.node_create(self.ctx, 'n-1', self.profile['id']) self.assertIsNotNone(node) self.ctx, 'n-1', self.profile['id']) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(_(""The request is malformed: The node (n-1) "" ""already exists.""), six.text_type(ex.exc_info[1])) def test_node_create_with_cluster_id_not_found(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.node_create, self.ctx, 'n-1', self.profile['id'], self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) @mock.patch.object(dispatcher, 'start_action') def test_node_create_project_not_match(self, notify): cluster = self.eng.cluster_create(self.ctx, 'c-1', 0, self.profile['id']) ctx_node = utils.dummy_context(project='a-different-project') profile_node = self.eng.profile_create(ctx_node, 'p-test', self.spec) ex = self.assertRaises(rpc.ExpectedException, self.eng.node_create, ctx_node, 'n-1', profile_node['id'], cluster_id=cluster['id']) self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) self.assertEqual(""The request is malformed: The specified cluster "" ""(%s) is not found."" """" % cluster['id'], six.text_type(ex.exc_info[1])) @mock.patch.object(dispatcher, 'start_action') def test_node_create_profile_type_not_match(self, notify): env = environment.global_env() env.register_profile('SecondProfile-1.0', fakes.TestProfile) new_spec = { 'type': 'SecondProfile', 'version': '1.0', 'properties': {'INT': 20, 'STR': 'string'} } cluster_profile = self.eng.profile_create(self.ctx, 'cp', new_spec) cluster = self.eng.cluster_create(self.ctx, 'c-1', 0, cluster_profile['id']) self.ctx, 'n-1', self.profile['id'], cluster_id=cluster['id']) self.assertEqual(exception.ProfileTypeNotMatch, ex.exc_info[0]) @mock.patch.object(dispatcher, 'start_action') def test_node_get(self, notify): node = self.eng.node_create(self.ctx, 'n-1', self.profile['id']) for identity in [node['id'], node['id'][:6], 'n-1']: result = self.eng.node_get(self.ctx, identity) self.assertIsInstance(result, dict) self.assertEqual(node['id'], result['id']) ex = self.assertRaises(rpc.ExpectedException, self.eng.node_get, self.ctx, 'Bogus') self.assertEqual(exception.NodeNotFound, ex.exc_info[0]) @mock.patch.object(dispatcher, 'start_action') def test_node_list(self, notify): node1 = self.eng.node_create(self.ctx, 'n1', self.profile['id']) node2 = self.eng.node_create(self.ctx, 'n2', self.profile['id']) result = self.eng.node_list(self.ctx) self.assertIsInstance(result, list) names = [n['name'] for n in result] ids = [n['id'] for n in result] self.assertEqual(node1['name'], names[0]) self.assertEqual(node2['name'], names[1]) self.assertEqual(node1['id'], ids[0]) self.assertEqual(node2['id'], ids[1]) @mock.patch.object(dispatcher, 'start_action') def test_node_list_with_limit_marker(self, notify): node1 = self.eng.node_create(self.ctx, 'n1', self.profile['id']) node2 = self.eng.node_create(self.ctx, 'n2', self.profile['id']) result = self.eng.node_list(self.ctx, limit=0) self.assertEqual(0, len(result)) result = self.eng.node_list(self.ctx, limit=1) self.assertEqual(1, len(result)) result = self.eng.node_list(self.ctx, limit=2) self.assertEqual(2, len(result)) result = self.eng.node_list(self.ctx, limit=3) self.assertEqual(2, len(result)) result = self.eng.node_list(self.ctx, marker=node1['id']) self.assertEqual(1, len(result)) result = self.eng.node_list(self.ctx, marker=node2['id']) self.assertEqual(0, len(result)) self.eng.node_create(self.ctx, 'n3', self.profile['id']) result = self.eng.node_list(self.ctx, limit=1, marker=node1['id']) self.assertEqual(1, len(result)) result = self.eng.node_list(self.ctx, limit=2, marker=node1['id']) self.assertEqual(2, len(result)) @mock.patch.object(dispatcher, 'start_action') def test_node_list_with_sort_keys(self, notify): node1 = self.eng.node_create(self.ctx, 'CC', self.profile['id']) node2 = self.eng.node_create(self.ctx, 'BB', self.profile['id']) # default by created_time result = self.eng.node_list(self.ctx) self.assertEqual(node1['id'], result[0]['id']) self.assertEqual(node2['id'], result[1]['id']) # use name for sorting result = self.eng.node_list(self.ctx, sort='name') self.assertEqual(node2['id'], result[0]['id']) self.assertEqual(node1['id'], result[1]['id']) # unknown keys will be ignored result = self.eng.node_list(self.ctx, sort='duang') self.assertIsNotNone(result) @mock.patch.object(dispatcher, 'start_action') def test_node_list_with_sort_dir(self, notify): node1 = self.eng.node_create(self.ctx, 'BB', self.profile['id']) node2 = self.eng.node_create(self.ctx, 'AA', self.profile['id']) node3 = self.eng.node_create(self.ctx, 'CC', self.profile['id']) # default by init_at, ascending result = self.eng.node_list(self.ctx) self.assertEqual(node1['id'], result[0]['id']) self.assertEqual(node2['id'], result[1]['id']) # sort by init_at, descending result = self.eng.node_list(self.ctx, sort='init_at:desc') self.assertEqual(node3['id'], result[0]['id']) self.assertEqual(node2['id'], result[1]['id']) # use name for sorting, descending result = self.eng.node_list(self.ctx, sort='name:desc') self.assertEqual(node3['id'], result[0]['id']) self.assertEqual(node1['id'], result[1]['id']) @mock.patch.object(dispatcher, 'start_action') def test_node_list_project_safe(self, notify): new_ctx = utils.dummy_context(project='a_diff_project') spec = { 'type': 'TestProfile', 'version': '1.0', 'properties': {'INT': 10, 'STR': 'string'}, } p1 = self.eng.profile_create(self.ctx, 'p-test-1', spec) p2 = self.eng.profile_create(new_ctx, 'p-test-2', spec) node1 = self.eng.node_create(self.ctx, 'n1', p1['id']) node2 = self.eng.node_create(new_ctx, 'n2', p2['id']) # default is project_safe result = self.eng.node_list(self.ctx) self.assertIsInstance(result, list) self.assertEqual(1, len(result)) self.assertEqual(node1['id'], result[0]['id']) result = self.eng.node_list(new_ctx) self.assertIsInstance(result, list) self.assertEqual(1, len(result)) self.assertEqual(node2['id'], result[0]['id']) # try project_safe set to False result = self.eng.node_list(self.ctx, project_safe=False) self.assertIsInstance(result, list) self.assertEqual(2, len(result)) self.assertEqual(node1['id'], result[0]['id']) self.assertEqual(node2['id'], result[1]['id']) @mock.patch.object(dispatcher, 'start_action') def test_node_list_with_cluster_id(self, notify): c = self.eng.cluster_create(self.ctx, 'c-1', 0, self.profile['id']) node = self.eng.node_create(self.ctx, 'n1', self.profile['id'], cluster_id=c['id']) result = self.eng.node_list(self.ctx, cluster_id=c['id']) self.assertEqual(1, len(result)) self.assertEqual(node['id'], result[0]['id']) ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, cluster_id='Bogus') self.assertEqual(exception.ClusterNotFound, ex.exc_info[0]) self.assertEqual('The cluster (Bogus) could not be found.', six.text_type(ex.exc_info[1])) @mock.patch.object(dispatcher, 'start_action') def test_node_list_with_filters(self, notify): self.eng.node_create(self.ctx, 'BB', self.profile['id']) self.eng.node_create(self.ctx, 'AA', self.profile['id']) self.eng.node_create(self.ctx, 'CC', self.profile['id']) result = self.eng.node_list(self.ctx, filters={'name': 'BB'}) self.assertEqual(1, len(result)) self.assertEqual('BB', result[0]['name']) result = self.eng.node_list(self.ctx, filters={'name': 'DD'}) self.assertEqual(0, len(result)) def test_node_list_bad_param(self): ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, limit='no') self.assertEqual(exception.InvalidParameter, ex.exc_info[0]) ex = self.assertRaises(rpc.ExpectedException, self.eng.node_list, self.ctx, project_safe='no') self.assertEqual(exception.InvalidParameter, ex.exc_info[0]) def test_node_list_empty(self): result = self.eng.node_list(self.ctx) self.assertIsInstance(result, list) self.assertEqual(0, len(result)) @mock.patch.object(dispatcher, 'start_action') def test_node_find(self, notify): node = self.eng.node_create(self.ctx, 'n1', self.profile['id']) nodeid = node['id'] result = self.eng.node_find(self.ctx, nodeid) self.assertIsNotNone(result) # short id result = self.eng.node_find(self.ctx, nodeid[:5]) self.assertIsNotNone(result) # name result = self.eng.node_find(self.ctx, 'n1') self.assertIsNotNone(result) # others self.assertRaises(exception.NodeNotFound, self.eng.node_find, self.ctx, 'Bogus') @mock.patch.object(action_mod, 'Action') def test_node_update_simple(self, mock_action, notify, mock_node_load): node = self.eng.node_create(self.ctx, 'node-1', self.profile['id'], role='Master', metadata={'foo': 'bar'}) nodeid = node['id'] node_obj = mock.Mock() node_obj.id = nodeid node_obj.to_dict.return_value = {'id': nodeid} mock_node_load.return_value = node_obj params = { 'user': self.ctx.user, 'project': self.ctx.project, 'domain': self.ctx.domain } # 1. update name mock_action.reset_mock() self.eng.node_update(self.ctx, nodeid, name='node-2') action_name = 'node_update_%s' % nodeid[:8] mock_action.assert_called_once_with(node_obj.id, 'NODE_UPDATE', name=action_name, inputs={ 'new_profile_id': None, 'name': 'node-2' }, cause=action_mod.CAUSE_RPC, **params) # 2. update role mock_action.reset_mock() self.eng.node_update(self.ctx, nodeid, role='worker') mock_action.assert_called_once_with(node_obj.id, 'NODE_UPDATE', name=action_name, inputs={ 'new_profile_id': None, 'role': 'worker' }, cause=action_mod.CAUSE_RPC, **params) # 3. update metadata mock_action.reset_mock() self.eng.node_update(self.ctx, nodeid, metadata={'FOO': 'BAR'}) mock_action.assert_called_once_with(node_obj.id, 'NODE_UPDATE', name=action_name, inputs={ 'new_profile_id': None, 'metadata': {'FOO': 'BAR'}, }, cause=action_mod.CAUSE_RPC, **params) def test_node_update_node_not_found(self): self.assertEqual(exception.NodeNotFound, ex.exc_info[0]) @mock.patch.object(dispatcher, 'start_action') def test_node_update_with_new_profile(self, notify): node = self.eng.node_create(self.ctx, 'node-1', self.profile['id']) notify.reset_mock() new_spec = { 'type': 'TestProfile', 'version': '1.0', 'properties': {'INT': 20}, } new_profile = self.eng.profile_create(self.ctx, 'p-new', new_spec) result = self.eng.node_update(self.ctx, node['id'], profile_id=new_profile['id']) self.assertIsNotNone(result.pop('action')) self.assertEqual(node, result) @mock.patch.object(dispatcher, 'start_action') def test_node_update_profile_not_found(self, notify): node = self.eng.node_create(self.ctx, 'node-1', self.profile['id']) ex = self.assertRaises(rpc.ExpectedException, self.eng.node_update, self.ctx, node['id'], profile_id='Bogus') self.assertEqual(exception.SenlinBadRequest, ex.exc_info[0]) self.assertEqual('The request is malformed: The specified profile ' '(Bogus) is not found.', six.text_type(ex.exc_info[1])) @mock.patch.object(dispatcher, 'start_action') def test_node_update_with_diff_profile_type(self, notify): env = environment.global_env() env.register_profile('NewProfileType-1.0', fakes.TestProfile) new_spec = { 'type': 'NewProfileType', 'version': '1.0', 'properties': {'INT': 20}, } new_profile = self.eng.profile_create(self.ctx, 'p-new', new_spec) node = self.eng.node_create(self.ctx, 'node-1', self.profile['id']) self.ctx, node['id'], profile_id=new_profile['id']) self.assertEqual(exception.ProfileTypeNotMatch, ex.exc_info[0]) def test_node_delete(self, notify): node = self.eng.node_create(self.ctx, 'node-1', self.profile['id']) nodeid = node['id'] result = self.eng.node_delete(self.ctx, nodeid) action_id = result['action'] self.assertIsNotNone(action_id) # verify action is fired expected_call = mock.call(action_id=mock.ANY) # two calls: one for create, the other for delete notify.assert_has_calls([expected_call] * 2) def test_node_delete_not_found(self): self.assertEqual(exception.NodeNotFound, ex.exc_info[0]) @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_check(self, notify, mock_find, mock_load): node = mock.Mock() node.id = 'nid' nodeid = node.id node.to_dict = mock.Mock(return_value={'id': nodeid}) mock_load.return_value = node result = self.eng.node_check(self.ctx, nodeid) self.assertEqual(node.id, result.get('id')) notify.assert_called_once_with(action_id=mock.ANY) @mock.patch.object(node_mod.Node, 'load') def test_node_check_not_found(self, mock_load): nid = 'Bogus' exp = exception.NodeNotFound(node=nid) mock_load.side_effect = exp self.eng.node_check, self.ctx, nid) self.assertEqual(exception.NodeNotFound, ex.exc_info[0]) @mock.patch.object(node_mod.Node, 'load') @mock.patch.object(service.EngineService, 'node_find') def test_node_recover(self, notify, mock_find, mock_load): node = mock.Mock() node.id = 'nid' nodeid = node.id node.to_dict = mock.Mock(return_value={'id': nodeid}) mock_load.return_value = node result = self.eng.node_recover(self.ctx, nodeid) self.assertEqual(node.id, result.get('id')) notify.assert_called_once_with(action_id=mock.ANY) @mock.patch.object(node_mod.Node, 'load') def test_node_recover_not_found(self, mock_load): nid = 'Bogus' exp = exception.NodeNotFound(node=nid) mock_load.side_effect = exp self.eng.node_recover, self.ctx, nid) self.assertEqual(exception.NodeNotFound, ex.exc_info[0])",748,480
openstack%2Fsenlin~master~Ieb0bfebcf9d83584ace3caf25a6ccc88ffafcca7,openstack/senlin,master,Ieb0bfebcf9d83584ace3caf25a6ccc88ffafcca7,Fix some word spellings,MERGED,2016-02-03 08:14:15.000000000,2016-02-14 08:00:55.000000000,2016-02-14 08:00:55.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-02-03 08:14:15.000000000', 'files': ['TODO.rst', 'doc/source/developer/node.rst', 'doc/source/developer/cluster.rst', 'senlin/tests/unit/db/test_node_api.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/3c23fdc63b2e1a8fd06d8906bb79dc422c1f611f', 'message': 'Fix some word spellings\n\nChange-Id: Ieb0bfebcf9d83584ace3caf25a6ccc88ffafcca7\n'}]",0,275552,3c23fdc63b2e1a8fd06d8906bb79dc422c1f611f,7,3,1,16237,,,0,"Fix some word spellings

Change-Id: Ieb0bfebcf9d83584ace3caf25a6ccc88ffafcca7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/52/275552/1 && git format-patch -1 --stdout FETCH_HEAD,"['TODO.rst', 'doc/source/developer/node.rst', 'doc/source/developer/cluster.rst', 'senlin/tests/unit/db/test_node_api.py']",4,3c23fdc63b2e1a8fd06d8906bb79dc422c1f611f,spell-fix, # retrieve orphan nodes, # retreive orphan nodes,4,4
openstack%2Fopenstack-manuals~stable%2Fliberty~I81bba9971d8284a85a5550e996dcc95a2e97ee45,openstack/openstack-manuals,stable/liberty,I81bba9971d8284a85a5550e996dcc95a2e97ee45,Imported Translations from Zanata,MERGED,2016-02-14 06:10:30.000000000,2016-02-14 07:43:50.000000000,2016-02-14 07:43:50.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2016-02-14 06:10:30.000000000', 'files': ['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/970654225aa5f9a4c0dcaea638862579ea0121ef', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I81bba9971d8284a85a5550e996dcc95a2e97ee45\n'}]",0,279925,970654225aa5f9a4c0dcaea638862579ea0121ef,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I81bba9971d8284a85a5550e996dcc95a2e97ee45
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/25/279925/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/fr/LC_MESSAGES/install-guide.po'],1,970654225aa5f9a4c0dcaea638862579ea0121ef,zanata/translations,"""PO-Revision-Date: 2016-02-13 10:54+0000\n""msgid ""Add the ``admin`` role to the ``neutron`` user:"" msgstr ""Ajouter le rôle ``admin`` à l'utilisateur ``neutron``:"" ""Before you configure the OpenStack Networking (neutron) service, you must "" ""create a database, service credentials, and API endpoints."" msgstr """" ""Avant de configurer le service Réseau d'OpenStack (neutron), vous devez "" ""créer une base de données, des credentials de service, et des endpoints API."" msgid """"msgid ""Configure the DHCP agent"" msgstr ""Configurer l'agent DHCP"" msgid ""Configure the layer-3 agent"" msgstr ""Configurer l'agent layer-3"" ""Create and edit the ``/etc/neutron/dnsmasq-neutron.conf`` file to enable the "" ""DHCP MTU option (26) and configure it to 1450 bytes:"" msgstr """" ""Créer et éditer le fichier ``/etc/neutron/dnsmasq-neutron.conf`` pour "" ""activer l'option DHCP MTU (26) et la configurer à 1450 octets:"" msgid """"msgid ""Create the ``neutron`` database:"" msgstr ""Créer la base de données ``neutron``:"" msgid ""Create the ``neutron`` user:"" msgstr ""Créer l'utilisateur ``neutron``:"" msgid """" ""Grant proper access to the ``neutron`` database, replacing "" ""``NEUTRON_DBPASS`` with a suitable password:"" msgstr """" ""Attribuer l'accès à la base de données ``neutron``, en remplaçant "" ""``NEUTRON_DBPASS`` par un mot de passe approprié:"" ""Ideally, you can prevent these problems by enabling :term:`jumbo frames "" ""<jumbo frame>` on the physical network that contains your tenant virtual "" ""networks. Jumbo frames support MTUs up to approximately 9000 bytes which "" ""negates the impact of VXLAN overhead on virtual networks. However, many "" ""network devices lack support for jumbo frames and OpenStack administrators "" ""often lack control over network infrastructure. Given the latter "" ""complications, you can also prevent MTU problems by reducing the instance "" ""MTU to account for VXLAN overhead. Determining the proper MTU value often "" ""takes experimentation, but 1450 bytes works in most environments. You can "" ""configure the DHCP server that assigns IP addresses to your instances to "" ""also adjust the MTU."" msgstr """" ""Idéalement, vous pouvez éviter ces problèmes en activant les :term:`jumbo "" ""frames <jumbo frame>` sur le réseau physique qui contient les réseaux "" ""virtuels de votre tenant. Les jumbo frames supportent des MTUs jusqu'à "" ""approximativement 9000 octets ce qui annule l'impact du surcoût VXLAN sur "" ""les réseaux virtuels. Néanmoins, de nombreux équipements réseau ne "" ""supportent pas les jumbo frames et les administrateurs OpenStack manque "" ""souvent de contrôle sur l'infrastructure réseau. Étant donné cette dernière "" ""complication, vous pouvez aussi éviter les problèmes de MTU en réduisant le "" ""MTU de l'instance pour tenir compte de la surcouche VXLAN. Déterminer la "" ""bonne valeur de MTU passe souvent often par l'experimentation, mais 1450 "" ""octets fonctionne dans la plupart des environnements. Vous pouvez configurer "" ""le serveur DHCP qui attribue les adresses IP à vos instances pour également "" ""paramétrer le MTU."" msgid """"""In the ``[DEFAULT]`` section, configure the Linux bridge interface driver "" ""and external network bridge:"" msgstr """" ""Dans la section ``[DEFAULT]``, configurer le driver d'interface Linux bridge "" ""et le bridge du réseaux externe:"" #, fuzzy msgid """" ""In the ``[DEFAULT]`` section, configure the Linux bridge interface driver, "" ""Dnsmasq DHCP driver, and enable isolated metadata so instances on public "" ""networks can access metadata over the network:"" msgstr """" ""Dans la section ``[DEFAULT]``, configurer le driver d'interface Linux "" ""bridge, le driver DHCP Dnsmasq, et activer les metadata isolées pour que les "" ""instances sur les réseaux public puissent accéder aux metadata à travers le "" ""réseau:"" msgid """"msgid """" ""In the ``[DEFAULT]`` section, enable the :term:`dnsmasq` configuration file:"" msgstr """" ""Dans la section ``[DEFAULT]``, activer le fichier de configuration :term:"" ""`dnsmasq`:"" msgid """" ""In the ``[DEFAULT]`` section, enable the Modular Layer 2 (ML2) plug-in, "" ""router service, and overlapping IP addresses:"" msgstr """" ""Dans la section ``[DEFAULT]``, activer le plugin Modular Layer 2 (ML2), le "" ""service routeur, et la superposition d'adresses IP:"" msgid ""In the ``[ml2]`` section, enable VXLAN project (private) networks:"" msgstr """" ""Dans la section ``[ml2]``, activer les réseaux de projet (privé) VXLAN:"" msgid ""In the ``[ml2]`` section, enable flat, VLAN, and VXLAN networks:"" msgstr ""Dans la section ``[ml2]``, activer les réseaux flat, VLAN, et VXLAN:"" msgid """" ""In the ``[ml2]`` section, enable the Linux bridge and layer-2 population "" ""mechanisms:"" msgstr """" ""Dans la section ``[ml2]``, activer Linux bridge et les mécanismes de "" ""population de niveau-2:"" ""In the ``[ml2_type_flat]`` section, configure the public flat provider "" ""network:"" msgstr """" ""Dans la section ``[ml2_type_flat]``, configurer le réseau plat fournisseur "" ""d'accès public:"" msgid """" ""In the ``[ml2_type_vxlan]`` section, configure the VXLAN network identifier "" ""range for private networks:"" msgstr """" ""Dans la section ``[ml2_type_vxlan]``, configurer la plage d'identifiants de "" ""réseaux VXLAN pour les réseaux privés:"" msgid """"""In the ``[securitygroup]`` section, enable :term:`ipset` to increase "" ""efficiency of security group rules:"" msgstr """" ""Dans la section ``[securitygroup]``, activer :term:`ipset` pour augmenter "" ""l'efficacité des règles des groupes de sécurité:"" msgid """"msgid """" ""Overlay networks such as VXLAN include additional packet headers that "" ""increase overhead and decrease space available for the payload or user data. "" ""Without knowledge of the virtual network infrastructure, instances attempt "" ""to send packets using the default Ethernet :term:`maximum transmission unit "" ""(MTU)` of 1500 bytes. :term:`Internet protocol (IP)` networks contain the :"" ""term:`path MTU discovery (PMTUD)` mechanism to detect end-to-end MTU and "" ""adjust packet size accordingly. However, some operating systems and networks "" ""block or otherwise lack support for PMTUD causing performance degradation or "" ""connectivity failure."" msgstr """" ""Les réseaux superposés, comme VXLAN inclut une entête de paquet "" ""supplémentaire qui augmente le coût et diminue l'espace disponible pour la "" ""charge utile ou les données utilisateur. Sans connaissance de "" ""l'infrastructure de réseau virtuel, les instances tentent d'envoyer les "" ""paquets en utilisant le :term:`maximum transmission unit (MTU)` Ethernet par "" ""défaut de 1500 octets. Les réseaux :term:`Internet protocol (IP)` incluent "" ""le mécanisme de :term:`path MTU discovery (PMTUD)` pour détecter le MTU de "" ""bout-en-bout et ajuster la taille du paquet packet size en conséquence. "" ""Cependant, certains systèmes d'exploitation et équipements réseau ou autre "" ""ne supportent pas PMTUD provoquant ainsi des dégradations de performance ou "" ""des échecs de connexion."" #, fuzzy msgid """" ""Return to :ref:`Networking controller node configuration <neutron-controller-"" ""metadata-agent>`."" msgstr """" ""Retourner à :ref:`Configuration du nœud contrôleur pour le réseau <neutron-"" ""controller-metadata-agent>`."" ""Some cloud images ignore the DHCP MTU option in which case you should "" ""configure it using metadata, a script, or other suitable method."" msgstr """" ""Certaines images cloud ignorent l'option DHCP MTU auquel cas vous devrez le "" ""configurer en utilisant les metadata, un script, ou tout autre méthode "" ""appropriée."" msgid """"msgid ""The :term:`DHCP agent` provides DHCP services for virtual networks."" msgstr ""L':term:`agent DHCP` fournit les services DHCP aux réseaux virtuels."" msgid """" ""The :term:`Layer-3 (L3) agent` provides routing and NAT services for virtual "" ""networks."" msgstr """" ""L':term:`agent Layer-3 (L3)` fournit le routage et les services NAT aux "" ""réseaux virtuels."" msgid ""The Linux bridge agent only supports VXLAN overlay networks."" msgstr """" ""L'agent Linux bridge supporte uniquement la superposition de réseaux VXLAN."" ""You can deploy the Networking service using one of two architectures "" ""represented by options 1 and 2."" msgstr """" ""Vous pouvez déployer le service Réseau en utilisant l'une des deux "" ""architectures représentées par les options 1 et 2."" msgid """"","""PO-Revision-Date: 2016-02-12 04:36+0000\n""",190,1
openstack%2Fsenlin~master~Icc2e5bc8df8c86b9f14b2a198aa416979a451f04,openstack/senlin,master,Icc2e5bc8df8c86b9f14b2a198aa416979a451f04,Using [trust_id] in '_build_conn_params',MERGED,2016-01-02 05:58:51.000000000,2016-02-14 06:54:17.000000000,2016-02-14 06:54:17.000000000,"[{'_account_id': 3}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2016-01-02 05:58:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f1f6c5aaf6d20ffa2fe2835fb65c9b26ceffe148', 'message': ""Fix _build_conn_params of class Policy\n\n'_build_conn_params' method will return a dict with'trust_id' item\nwhich should be a trust id not a list of trust id.\n\nCloses-Bug: 1530504\nChange-Id: Icc2e5bc8df8c86b9f14b2a198aa416979a451f04\n""}, {'number': 2, 'created': '2016-01-21 03:40:45.000000000', 'files': ['senlin/profiles/base.py', 'senlin/tests/unit/profiles/test_profile_base.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/7c8ce15d5550a9267a6449b2d11ad7de5ddc2504', 'message': ""Using [trust_id] in '_build_conn_params'\n\nUnify the using of trust_id in this project, In profile module\nwe use trust_id, while in receiver and policy module we use\n[trust_id].\n\nCloses-Bug: 1530504\nChange-Id: Icc2e5bc8df8c86b9f14b2a198aa416979a451f04\n""}]",0,262941,7c8ce15d5550a9267a6449b2d11ad7de5ddc2504,11,3,2,16910,,,0,"Using [trust_id] in '_build_conn_params'

Unify the using of trust_id in this project, In profile module
we use trust_id, while in receiver and policy module we use
[trust_id].

Closes-Bug: 1530504
Change-Id: Icc2e5bc8df8c86b9f14b2a198aa416979a451f04
",git fetch https://review.opendev.org/openstack/senlin refs/changes/41/262941/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/tests/unit/policies/test_policy.py', 'senlin/policies/base.py']",2,f1f6c5aaf6d20ffa2fe2835fb65c9b26ceffe148,bug/1530504, params['trust_id'] = cred.cred['openstack']['trust'], params['trust_id'] = [cred.cred['openstack']['trust']],2,2
openstack%2Fdragonflow~master~Idc7e3b5579439f6a2791367d7da36addb1d7104b,openstack/dragonflow,master,Idc7e3b5579439f6a2791367d7da36addb1d7104b,Extra check when adding a tunnel to a remote chassis,MERGED,2016-02-10 17:05:49.000000000,2016-02-14 06:42:15.000000000,2016-02-14 06:42:15.000000000,"[{'_account_id': 3}, {'_account_id': 11343}, {'_account_id': 11364}, {'_account_id': 13070}, {'_account_id': 18668}]","[{'number': 1, 'created': '2016-02-10 17:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/211dcb02a0a53748dfc092374b2030046ab7dc39', 'message': 'Extra check when adding a tunnel to a remote chassis\n\nCheck that if it is already exists and check\nthat it is not to myself\n\nChange-Id: Idc7e3b5579439f6a2791367d7da36addb1d7104b\n'}, {'number': 2, 'created': '2016-02-11 08:45:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/1edacd925938d128c106a1b2bec7daa3c633fb46', 'message': 'Extra check when adding a tunnel to a remote chassis\n\nCheck that if it is already exists and check\nthat it is not to myself\n\nChange-Id: Idc7e3b5579439f6a2791367d7da36addb1d7104b\n'}, {'number': 3, 'created': '2016-02-12 08:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/c4f72bbf1f443e0a747402db4dcf60d4517670d9', 'message': 'Extra check when adding a tunnel to a remote chassis\n\nCheck that if it is already exists and check\nthat it is not to myself\n\nChange-Id: Idc7e3b5579439f6a2791367d7da36addb1d7104b\n'}, {'number': 4, 'created': '2016-02-14 06:13:36.000000000', 'files': ['dragonflow/controller/df_local_controller.py'], 'web_link': 'https://opendev.org/openstack/dragonflow/commit/a015adc7be93e7ea98b62c078faaf3c5e2881ae9', 'message': 'Extra check when adding a tunnel to a remote chassis\n\nCheck that if it is already exists and check\nthat it is not to myself\n\nChange-Id: Idc7e3b5579439f6a2791367d7da36addb1d7104b\n'}]",1,278525,a015adc7be93e7ea98b62c078faaf3c5e2881ae9,19,5,4,13070,,,0,"Extra check when adding a tunnel to a remote chassis

Check that if it is already exists and check
that it is not to myself

Change-Id: Idc7e3b5579439f6a2791367d7da36addb1d7104b
",git fetch https://review.opendev.org/openstack/dragonflow refs/changes/25/278525/1 && git format-patch -1 --stdout FETCH_HEAD,['dragonflow/controller/df_local_controller.py'],1,211dcb02a0a53748dfc092374b2030046ab7dc39,pubsub," t_ports = self.vswitch_api.get_tunnel_ports() remote_chassis_name = chassis.get_name() if self.chassis_name == remote_chassis_name: return for t_port in t_ports: if t_port.get_chassis_id() == remote_chassis_name: LOG.info(_LI(""remote Chassis Tunnel already installed = %s"") % chassis.__str__()) return",,9,1
openstack%2Fcinder~master~Ia6306d5d2d24556135505ddc33174f57c86d8555,openstack/cinder,master,Ia6306d5d2d24556135505ddc33174f57c86d8555,HNAS driver: retry on Connection reset fix,MERGED,2016-02-04 17:14:02.000000000,2016-02-14 06:16:44.000000000,2016-02-10 19:41:52.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10058}, {'_account_id': 12778}, {'_account_id': 13144}, {'_account_id': 14865}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16880}, {'_account_id': 16941}, {'_account_id': 19144}]","[{'number': 1, 'created': '2016-02-04 17:14:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b5a453efedbd880edc7ed7893ed6574e1598265', 'message': 'HNAS driver: retry on Connection reset fix\n\nWhen HNAS driver is not using the SSH option and there are lots of exports in\nthe backend, a exception of ""Connection reset"" is eventually raised in the\ndriver initialization.\nThis patch makes the HNAS driver retries when this exception is raised.\n\nChange-Id: Ia6306d5d2d24556135505ddc33174f57c86d8555\nCloses-Bug: 1541941\n'}, {'number': 2, 'created': '2016-02-04 17:56:14.000000000', 'files': ['cinder/volume/drivers/hitachi/hnas_backend.py', 'cinder/tests/unit/test_hitachi_hnas_backend.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/15a2752d512d7f74b9286e780428b559fe6582dd', 'message': 'HNAS driver: retry on Connection reset fix\n\nWhen HNAS driver is not using the SSH option and there are lots of exports in\nthe backend, a exception of ""Connection reset"" is eventually raised in the\ndriver initialization.\nThis patch makes the HNAS driver retries when this exception is raised.\n\nChange-Id: Ia6306d5d2d24556135505ddc33174f57c86d8555\nCloses-Bug: 1541941\n'}]",7,276357,15a2752d512d7f74b9286e780428b559fe6582dd,92,13,2,14865,,,0,"HNAS driver: retry on Connection reset fix

When HNAS driver is not using the SSH option and there are lots of exports in
the backend, a exception of ""Connection reset"" is eventually raised in the
driver initialization.
This patch makes the HNAS driver retries when this exception is raised.

Change-Id: Ia6306d5d2d24556135505ddc33174f57c86d8555
Closes-Bug: 1541941
",git fetch https://review.opendev.org/openstack/cinder refs/changes/57/276357/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/hitachi/hnas_backend.py', 'cinder/tests/unit/test_hitachi_hnas_backend.py']",2,5b5a453efedbd880edc7ed7893ed6574e1598265,bug/1541941,"HNAS_RESULT27 = ""Connection reset"" m_utl.side_effect = putils.ProcessExecutionError(stdout='', stderr=HNAS_RESULT27, exit_code=255) self.hnas_bend.drv_configs['ssh_enabled'] = 'False' self.assertRaises(exception.HNASConnError, self.hnas_bend.run_cmd, 'ssh', '0.0.0.0', 'supervisor', 'supervisor', 'df', '-a') ",,15,1
openstack%2Fnova~master~Ie354b14f592738a882ca261133de4372a3e6507b,openstack/nova,master,Ie354b14f592738a882ca261133de4372a3e6507b,remove the redundant policy check for SecurityGroupsOutputController,MERGED,2015-02-26 08:19:37.000000000,2016-02-14 06:15:29.000000000,2016-02-14 06:15:27.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 7634}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11103}, {'_account_id': 12175}, {'_account_id': 14131}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 17130}]","[{'number': 1, 'created': '2015-02-26 08:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e64d4a2e23a75a6e5f95f39df904777472cd5df', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 2, 'created': '2015-03-13 02:33:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1deff4206445c62c6af9105fdb3dcf4cc493d8f0', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 3, 'created': '2015-04-15 03:55:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cf99d842a8746b58220501629d67cce09ab01fad', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 4, 'created': '2015-04-15 07:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f090c2ee4b410515bfca93d649d512bd47e50dee', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 5, 'created': '2015-04-20 06:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/091a1518ee0e70b847154ece302cffdd5e4d7c0d', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 6, 'created': '2015-08-24 11:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27ba82ceeadb5c97da78441cfea93d01ada7b365', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}, {'number': 7, 'created': '2015-11-03 09:34:11.000000000', 'files': ['nova/api/openstack/compute/security_groups.py', 'nova/tests/unit/api/openstack/compute/test_security_groups.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/64d852879701c0e1623ba34e081cd4cb095826e8', 'message': 'remove the redundant policy check for SecurityGroupsOutputController\n\nThe normal authorize and soft authorize has the same rule.\n\nAll actions of SecurityGroupsOutputController need soft authorize.\n\nIf soft authorize fails, no chance to do normal authorize, also if soft\nauthorize passes, the normal authorize is redundant.\n\nChange-Id: Ie354b14f592738a882ca261133de4372a3e6507b\nCloses-Bug: 1425849\n'}]",18,159369,64d852879701c0e1623ba34e081cd4cb095826e8,99,23,7,14131,,,0,"remove the redundant policy check for SecurityGroupsOutputController

The normal authorize and soft authorize has the same rule.

All actions of SecurityGroupsOutputController need soft authorize.

If soft authorize fails, no chance to do normal authorize, also if soft
authorize passes, the normal authorize is redundant.

Change-Id: Ie354b14f592738a882ca261133de4372a3e6507b
Closes-Bug: 1425849
",git fetch https://review.opendev.org/openstack/nova refs/changes/69/159369/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/plugins/v3/security_groups.py'],1,0e64d4a2e23a75a6e5f95f39df904777472cd5df,bug/1425849, context = req.environ['nova.context'], context = _authorize_context(req),1,1
openstack%2Frally~master~I9daa7e55c51c325b0cbe11b8520f47a917470e74,openstack/rally,master,I9daa7e55c51c325b0cbe11b8520f47a917470e74,Fix quotas to use the supplied context,MERGED,2016-02-12 18:34:58.000000000,2016-02-14 06:10:25.000000000,2016-02-14 06:10:25.000000000,"[{'_account_id': 3}, {'_account_id': 6835}, {'_account_id': 8491}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 14817}]","[{'number': 1, 'created': '2016-02-12 18:34:58.000000000', 'files': ['rally/plugins/openstack/context/quotas/quotas.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/3757998435e45379ca5f9e3b285eb885f0ad982e', 'message': ""Fix quotas to use the supplied context\n\nIf the task specifies api_versions context at present, it doesn't get used\nin context setup and defaults to hard-coded value from osclients.py, this\nfix will pass the config to osclient which constructs correct versioned\nclient\n\nChange-Id: I9daa7e55c51c325b0cbe11b8520f47a917470e74\n""}]",0,279717,3757998435e45379ca5f9e3b285eb885f0ad982e,8,6,1,12637,,,0,"Fix quotas to use the supplied context

If the task specifies api_versions context at present, it doesn't get used
in context setup and defaults to hard-coded value from osclients.py, this
fix will pass the config to osclient which constructs correct versioned
client

Change-Id: I9daa7e55c51c325b0cbe11b8520f47a917470e74
",git fetch https://review.opendev.org/openstack/rally refs/changes/17/279717/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/plugins/openstack/context/quotas/quotas.py'],1,3757998435e45379ca5f9e3b285eb885f0ad982e,quotas," self.clients = osclients.Clients( self.context[""admin""][""credential""], api_info=self.context[""config""].get(""api_versions""))"," self.clients = osclients.Clients(self.context[""admin""][""credential""])",3,1
openstack%2Fpython-openstackclient~master~I253f66f6bc64470e1a18ffea506048eb53f67d5c,openstack/python-openstackclient,master,I253f66f6bc64470e1a18ffea506048eb53f67d5c,"Floating IP: Neutron support for ""ip floating list"" command",MERGED,2016-02-09 07:43:02.000000000,2016-02-14 06:02:09.000000000,2016-02-14 06:02:09.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}, {'_account_id': 17130}, {'_account_id': 17211}, {'_account_id': 17776}]","[{'number': 1, 'created': '2016-02-09 07:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/0b068d05be3117a77b151b2d5b661e3e8632fe3a', 'message': 'Floating IP: Implementation of ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 2, 'created': '2016-02-09 08:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b303d682a32299f07fc303b21d9d41fba1ddcb62', 'message': 'Floating IP: Implementation of ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 3, 'created': '2016-02-09 17:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4cbffcb3c823251dacce087e476f00bc99f2bf7c', 'message': 'Floating IP: Implementation of ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 4, 'created': '2016-02-09 18:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/1400650937b3a67ffdb7c4e49279e093b1ced3c3', 'message': 'Floating IP: Implementation of ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 5, 'created': '2016-02-09 21:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d51d6e9bd470da92b01c3c8657ae85daa03860e3', 'message': 'Floating IP: Implementation of ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 6, 'created': '2016-02-09 21:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/be3a3f066dc0c7b45e644ac14b38604986a4219d', 'message': 'Floating IP: Neutron support for ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 7, 'created': '2016-02-09 21:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/166f915ad8edd88b06085d1f48c48b86b9de889d', 'message': 'Floating IP: Neutron support for ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 8, 'created': '2016-02-14 04:21:09.000000000', 'files': ['openstackclient/tests/network/v2/test_floating_ip.py', 'openstackclient/tests/network/v2/fakes.py', 'openstackclient/network/v2/floating_ip.py', 'openstackclient/compute/v2/floatingip.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d8abec33ada8b2b028d52eb8bfad2640812b9af8', 'message': 'Floating IP: Neutron support for ""ip floating list"" command\n\nChange-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}]",5,277720,d8abec33ada8b2b028d52eb8bfad2640812b9af8,31,10,8,14937,,,0,"Floating IP: Neutron support for ""ip floating list"" command

Change-Id: I253f66f6bc64470e1a18ffea506048eb53f67d5c
partial-Bug: 1519502
Related-to: blueprint neutron-client
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/20/277720/8 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/tests/network/v2/test_floating_ip.py', 'openstackclient/network/v2/floating_ip.py', 'openstackclient/tests/network/v2/fakes.py', 'openstackclient/compute/v2/floatingip.py', 'setup.cfg']",5,0b068d05be3117a77b151b2d5b661e3e8632fe3a,bug/1519502, ip_floating_list = openstackclient.network.v2.floating_ip:ListFloatingIP,,108,17
openstack%2Fcinder~master~I250d7378547df474f3c78024a737a3e2fa9bbaf4,openstack/cinder,master,I250d7378547df474f3c78024a737a3e2fa9bbaf4,Port backup drivers to Python 3,MERGED,2016-02-09 10:53:44.000000000,2016-02-14 05:59:35.000000000,2016-02-09 19:34:38.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 9008}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 15831}, {'_account_id': 16269}, {'_account_id': 16660}, {'_account_id': 16880}, {'_account_id': 16941}]","[{'number': 1, 'created': '2016-02-09 10:53:44.000000000', 'files': ['cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'tests-py3.txt', 'cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/backup/drivers/posix.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fca244f117f9de2d956619482cba0147b0b7afa1', 'message': ""Port backup drivers to Python 3\n\n* PosixBackupDriver: open file in binary mode (to read/write).\n  Update test_backup_posix.py for that.\n* test_backup_nfs: buffer() doesn't exist and is no more needed on\n  Python 3, only use buffer() on Python 2.\n* tests-py3.txt: add cinder.tests.unit.backup\n\nPartial-Implements: blueprint cinder-python3\nChange-Id: I250d7378547df474f3c78024a737a3e2fa9bbaf4\n""}]",0,277778,fca244f117f9de2d956619482cba0147b0b7afa1,42,14,1,9107,,,0,"Port backup drivers to Python 3

* PosixBackupDriver: open file in binary mode (to read/write).
  Update test_backup_posix.py for that.
* test_backup_nfs: buffer() doesn't exist and is no more needed on
  Python 3, only use buffer() on Python 2.
* tests-py3.txt: add cinder.tests.unit.backup

Partial-Implements: blueprint cinder-python3
Change-Id: I250d7378547df474f3c78024a737a3e2fa9bbaf4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/78/277778/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/backup/drivers/test_backup_nfs.py', 'tests-py3.txt', 'cinder/tests/unit/backup/drivers/test_backup_posix.py', 'cinder/backup/drivers/posix.py']",4,fca244f117f9de2d956619482cba0147b0b7afa1,bp/cinder-python3," f = open(path, 'wb') return open(path, 'rb')"," f = open(path, 'w') return open(path, 'r')",21,11
openstack%2Fpython-openstackclient~master~Ie61f0faad65ec90f9d9956ae463412be8d963d05,openstack/python-openstackclient,master,Ie61f0faad65ec90f9d9956ae463412be8d963d05,"Floating IP: Neutron support for ""ip floating delete"" command",MERGED,2015-12-16 14:04:35.000000000,2016-02-14 05:56:53.000000000,2016-02-14 05:56:53.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}]","[{'number': 1, 'created': '2015-12-16 14:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/54382fa96fe7c040170e04144520beb48ba50697', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating.\n\n$ neutron floatingip-list\n+--------------------------------------+------------------+---------------------+---------+\n| id                                   | fixed_ip_address | floating_ip_address | port_id |\n+--------------------------------------+------------------+---------------------+---------+\n| 44642a7c-c53e-40d0-8d02-f34f6182ed6c |                  | 172.24.4.8          |         |\n| d090d0d6-3d68-4347-8f7e-8b81fac63dac |                  | 172.24.4.9          |         |\n| da278b07-7155-490f-853c-f1c8070760be |                  | 172.24.4.7          |         |\n+--------------------------------------+------------------+---------------------+---------+\n$ openstack floatingip delete 44642a7c-c53e-40d0-8d02-f34f6182ed6c\n$\n$ neutron floatingip-list\n+--------------------------------------+------------------+---------------------+---------+\n| id                                   | fixed_ip_address | floating_ip_address | port_id |\n+--------------------------------------+------------------+---------------------+---------+\n| d090d0d6-3d68-4347-8f7e-8b81fac63dac |                  | 172.24.4.9          |         |\n| da278b07-7155-490f-853c-f1c8070760be |                  | 172.24.4.7          |         |\n+--------------------------------------+------------------+---------------------+---------+\n$\n$ openstack floatingip delete d090d0d6-3d68-4347-8f7e-8b81fac63dac da278b07-7155-490f-853c-f1c8070760be\n$\n$ neutron floatingip-list\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nCloses-Bug: 1519502\n'}, {'number': 2, 'created': '2015-12-21 10:48:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c8e896f01a227128f2295f8b47417f9912d987e9', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 3, 'created': '2015-12-22 14:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/79ccdccf262d11a0e9a70914efdc6ce6df51ceab', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating,\nit support nova and neutron networks\nand include a unit test.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 4, 'created': '2015-12-22 14:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3062e11036618ab76dcacbb53136543b12ca761c', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating,\nit support nova and neutron networks\nand include a unit test.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 5, 'created': '2016-01-06 10:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/42c447730c23f200c197070929e0eeb328dac356', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating,\nit support nova and neutron networks\nand include a unit test.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 6, 'created': '2016-02-01 09:17:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/a30c7be24fad319168a96d2112c9c881a02dcd27', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating,\nit support nova and neutron networks\nand include a unit test.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 7, 'created': '2016-02-02 04:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/80f614570f1b702e7ead97a7f10012aa07f20f7a', 'message': 'Implementation for Network Floating IP CRUD\n\nThis patch is for the deleting floating,\nit support nova and neutron networks\nand include a unit test.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\n'}, {'number': 8, 'created': '2016-02-08 10:17:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/2765f9f7130342575b58366f2de04d67b2af0521', 'message': 'Floating IP: Implementation ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 9, 'created': '2016-02-08 11:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/707e90e7fe279f0cd993b0aa58884b3bbe881765', 'message': 'Floating IP: Implementation ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 10, 'created': '2016-02-08 16:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/b52daf3c5a209aa8c70094f24ac1b1adacbd9140', 'message': 'Floating IP: Implementation ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 11, 'created': '2016-02-09 04:25:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4d8c3c2a0979f31cf0d2f9a937b48bc04416f19e', 'message': 'Floating IP: Implementation ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 12, 'created': '2016-02-09 07:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/61cbf7b58ff23cf66eeac6e12a1175e89a1057de', 'message': 'Floating IP: Implementation for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\nDepends-On: Ic21376b86b40cc6d97f360f3760ba5beed154537\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 13, 'created': '2016-02-09 17:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/32781071f7458a108fd70c5c287db1bfe69f0f1e', 'message': 'Floating IP: Implementation for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 14, 'created': '2016-02-09 18:59:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/05471e7ccdbcd86eed6a4b0aa03714830945994c', 'message': 'Floating IP: Implementation for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 15, 'created': '2016-02-09 21:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3d4c376345120d15e54e2d08f967b1e8090048aa', 'message': 'Floating IP: Implementation for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 16, 'created': '2016-02-09 21:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c9e9982bc2bf33e5ee707c7a5ce58b182826061a', 'message': 'Floating IP: Neutron support for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 17, 'created': '2016-02-09 21:28:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/fdcbce26756b567bc628a830074f6c9062718f47', 'message': 'Floating IP: Neutron support for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}, {'number': 18, 'created': '2016-02-14 04:21:00.000000000', 'files': ['openstackclient/tests/network/v2/test_floating_ip.py', 'openstackclient/tests/compute/v2/fakes.py', 'openstackclient/tests/network/v2/fakes.py', 'openstackclient/network/v2/floating_ip.py', 'openstackclient/compute/v2/floatingip.py', 'doc/source/command-objects/ip-floating.rst', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/6109dfcf63a666330e7323d957a37a251dd2b520', 'message': 'Floating IP: Neutron support for ""ip floating delete"" command\n\nThis patch implements ""ip floating delete"" command for\nboth compute and network. Also includes unit tests.\n\nChange-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05\npartial-Bug: 1519502\nRelated-to: blueprint neutron-client\nCo-Authored-By: Tang Chen <chen.tang@easystack.cn>\n'}]",45,258519,6109dfcf63a666330e7323d957a37a251dd2b520,72,7,18,17317,,,0,"Floating IP: Neutron support for ""ip floating delete"" command

This patch implements ""ip floating delete"" command for
both compute and network. Also includes unit tests.

Change-Id: Ie61f0faad65ec90f9d9956ae463412be8d963d05
partial-Bug: 1519502
Related-to: blueprint neutron-client
Co-Authored-By: Tang Chen <chen.tang@easystack.cn>
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/19/258519/18 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'openstackclient/network/v2/floatingip.py']",2,54382fa96fe7c040170e04144520beb48ba50697,bug/1519502,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # """"""Floating IP action implementations"""""" import json import logging from cliff import command from cliff import lister from cliff import show from openstackclient.common import exceptions from openstackclient.common import utils from openstackclient.identity import common as identity_common class DeleteFloatingIP(command.Command): """"""Delete a given floating IP(s)."""""" log = logging.getLogger(__name__ + '.DeleteFloatingIP') def get_parser(self, prog_name): parser = super(DeleteFloatingIP, self).get_parser(prog_name) parser.add_argument( 'floatingip', metavar=""<floatingip>"", nargs=""+"", help=(""Floating IP(s) to delete ID"") ) return parser def take_action(self, parsed_args): self.log.debug('take_action(%s)' % parsed_args) client = self.app.client_manager.network for floatingip in parsed_args.floatingip: client.delete_floatingip(floatingip) return ",,50,0
openstack%2Fnova~master~I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1,openstack/nova,master,I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1,Updated from global requirements,MERGED,2016-02-10 21:57:31.000000000,2016-02-14 05:14:14.000000000,2016-02-12 22:12:21.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8119}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 16376}, {'_account_id': 16898}]","[{'number': 1, 'created': '2016-02-10 21:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/07e5b953b83218a75cfc78da30298a3f40d2e98c', 'message': 'Updated from global requirements\n\nChange-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1\n'}, {'number': 2, 'created': '2016-02-11 07:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f067c61bebdc9b5f5f701f29ffe465eafc9c7444', 'message': 'Updated from global requirements\n\nChange-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1\n'}, {'number': 3, 'created': '2016-02-11 14:49:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a80cf84e5aa785d4da8d6b787a2acac141ac4238', 'message': 'Updated from global requirements\n\nChange-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1\n'}, {'number': 4, 'created': '2016-02-11 15:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/16d4fa1d49ebcb3a60061b2be23d55e7e5eb67d9', 'message': 'Updated from global requirements\n\nChange-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1\n'}, {'number': 5, 'created': '2016-02-12 20:05:03.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/84fdf2dca104413e0ed1460dcdf0be04d0ed7987', 'message': 'Updated from global requirements\n\nChange-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1\n'}]",0,278700,84fdf2dca104413e0ed1460dcdf0be04d0ed7987,64,13,5,11131,,,0,"Updated from global requirements

Change-Id: I24f3dc7739aa1dd8d1a06a5fd5c4a134a8657eb1
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/278700/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,07e5b953b83218a75cfc78da30298a3f40d2e98c,openstack/requirements,mock>=1.2;python_version<'3.3' # BSD,mock>=1.2 # BSD,3,3
openstack%2Fkolla~master~I8d8778be755a4db9e57d6ff7aaee623547c4243e,openstack/kolla,master,I8d8778be755a4db9e57d6ff7aaee623547c4243e,Fix horizon startup failure,MERGED,2016-02-13 19:09:54.000000000,2016-02-14 04:42:38.000000000,2016-02-14 04:42:38.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 14119}]","[{'number': 1, 'created': '2016-02-13 19:09:54.000000000', 'files': ['docker/horizon/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/50b885c260430029e05edb477dcd3b7d0ed6d754', 'message': 'Fix horizon startup failure\n\noriginal extend_start.sh try to write temp files to a non-existent folder (/home/horizon) and cause horizon failed to start. It is fixed by moving the file to /tmp.\n\nPartial-Bug: 1543429\n\nChange-Id: I8d8778be755a4db9e57d6ff7aaee623547c4243e\n'}]",0,279893,50b885c260430029e05edb477dcd3b7d0ed6d754,7,3,1,20539,,,0,"Fix horizon startup failure

original extend_start.sh try to write temp files to a non-existent folder (/home/horizon) and cause horizon failed to start. It is fixed by moving the file to /tmp.

Partial-Bug: 1543429

Change-Id: I8d8778be755a4db9e57d6ff7aaee623547c4243e
",git fetch https://review.opendev.org/openstack/kolla refs/changes/93/279893/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/horizon/extend_start.sh'],1,50b885c260430029e05edb477dcd3b7d0ed6d754,bug/1543429,"MD5SUM_TXT_PATH=""/tmp/.local_settings.md5sum.txt""","MD5SUM_TXT_PATH=""/home/horizon/.local_settings.md5sum.txt""",1,1
openstack%2Fneutron~master~I96af76be216bd124251bb871b2a37ac0d0da8c8c,openstack/neutron,master,I96af76be216bd124251bb871b2a37ac0d0da8c8c,Use correct mocking in test_remove_router_interface(),ABANDONED,2016-02-03 08:09:06.000000000,2016-02-14 04:07:38.000000000,,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 11347}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 20084}]","[{'number': 1, 'created': '2016-02-03 08:09:06.000000000', 'files': ['neutron/tests/functional/services/l3_router/test_l3_dvr_router_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/81fa1730bfc83e8a37a42009300e6d0176173bbb', 'message': 'Use correct mocking in test_remove_router_interface()\n\nl3_plugin.l3_rpc_notifier is mocked but never restored.\nCorrect that mocking.\n\nChange-Id: I96af76be216bd124251bb871b2a37ac0d0da8c8c\n'}]",2,275549,81fa1730bfc83e8a37a42009300e6d0176173bbb,17,13,1,11347,,,0,"Use correct mocking in test_remove_router_interface()

l3_plugin.l3_rpc_notifier is mocked but never restored.
Correct that mocking.

Change-Id: I96af76be216bd124251bb871b2a37ac0d0da8c8c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/49/275549/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/services/l3_router/test_l3_dvr_router_plugin.py'],1,81fa1730bfc83e8a37a42009300e6d0176173bbb,bug/correct_mock," **{portbindings.HOST_ID: HOST1}),\ mock.patch.object(self.l3_plugin, ""_l3_rpc_notifier"") as l3_notifier:", **{portbindings.HOST_ID: HOST1}): l3_notifier = mock.Mock() self.l3_plugin.l3_rpc_notifier = l3_notifier,3,3
openstack%2Ftricircle~master~I953322737aa97b2d1ebd9a15dc479d7aba753678,openstack/tricircle,master,I953322737aa97b2d1ebd9a15dc479d7aba753678,L3 North-South Networking,MERGED,2016-02-01 07:03:23.000000000,2016-02-14 03:47:29.000000000,2016-02-14 03:47:29.000000000,"[{'_account_id': 3}, {'_account_id': 7805}, {'_account_id': 10556}, {'_account_id': 11819}, {'_account_id': 13305}, {'_account_id': 13629}, {'_account_id': 13779}, {'_account_id': 14542}, {'_account_id': 19960}]","[{'number': 1, 'created': '2016-02-01 07:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/f6a947277ab14550f696f582294dde6a8d1a9ac5', 'message': 'L3 North-South Networking\n\nImplement l3 north-south networking functionality. In our current\ndesign, external network is hosted in one of the bottom pod, VMs\nhosted in other bottom pods are connected to this external network\nvia a bridge network, using the same physical network as the east-\nwest networking, but different vlan.\n\nChange-Id: I953322737aa97b2d1ebd9a15dc479d7aba753678\n'}, {'number': 2, 'created': '2016-02-05 07:11:14.000000000', 'files': ['tricircle/xjob/xmanager.py', 'tricircle/common/exceptions.py', 'tricircle/tests/unit/network/test_plugin.py', 'devstack/plugin.sh', 'tricircle/tests/unit/xjob/test_xmanager.py', 'tricircle/tests/base.py', 'tricircle/nova_apigw/controllers/server.py', 'README.md', 'tricircle/db/api.py', 'devstack/local.conf.node_1.sample', 'devstack/local.conf.node_2.sample', 'tricircle/common/constants.py', 'tricircle/common/resource_handle.py', 'tricircle/common/client.py', 'tricircle/network/plugin.py', 'tricircle/tests/unit/network/__init__.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/8dd1b87e260e017f35b8248575e0bce181cca9b3', 'message': 'L3 North-South Networking\n\nImplement l3 north-south networking functionality. In our current\ndesign, external network is hosted in one of the bottom pod, VMs\nhosted in other bottom pods are connected to this external network\nvia a bridge network, using the same physical network as the east-\nwest networking, but different vlan.\n\nChange-Id: I953322737aa97b2d1ebd9a15dc479d7aba753678\n'}]",4,274521,8dd1b87e260e017f35b8248575e0bce181cca9b3,9,9,2,12076,,,0,"L3 North-South Networking

Implement l3 north-south networking functionality. In our current
design, external network is hosted in one of the bottom pod, VMs
hosted in other bottom pods are connected to this external network
via a bridge network, using the same physical network as the east-
west networking, but different vlan.

Change-Id: I953322737aa97b2d1ebd9a15dc479d7aba753678
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/21/274521/1 && git format-patch -1 --stdout FETCH_HEAD,"['tricircle/xjob/xmanager.py', 'tricircle/common/exceptions.py', 'tricircle/tests/unit/network/test_plugin.py', 'devstack/plugin.sh', 'tricircle/tests/unit/xjob/test_xmanager.py', 'tricircle/tests/base.py', 'tricircle/nova_apigw/controllers/server.py', 'README.md', 'tricircle/db/api.py', 'devstack/local.conf.node_1.sample', 'devstack/local.conf.node_2.sample', 'tricircle/common/constants.py', 'tricircle/common/resource_handle.py', 'tricircle/common/client.py', 'tricircle/network/plugin.py', 'tricircle/tests/unit/network/__init__.py']",16,f6a947277ab14550f696f582294dde6a8d1a9ac5,l3-ns-connect,,,1110,114
openstack%2Fdevstack~master~I5d52e4ef47524b649201ec9e9db7f859119454b1,openstack/devstack,master,I5d52e4ef47524b649201ec9e9db7f859119454b1,[WIP] try oslo.messaging from master,ABANDONED,2016-02-12 03:05:17.000000000,2016-02-14 02:31:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2016-02-12 03:05:17.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6ae2b753d5f72176d10c513933333724f6b689b4', 'message': '[WIP] try oslo.messaging from master\n\nChange-Id: I5d52e4ef47524b649201ec9e9db7f859119454b1\n'}]",0,279369,6ae2b753d5f72176d10c513933333724f6b689b4,9,4,1,5638,,,0,"[WIP] try oslo.messaging from master

Change-Id: I5d52e4ef47524b649201ec9e9db7f859119454b1
",git fetch https://review.opendev.org/openstack/devstack refs/changes/69/279369/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,6ae2b753d5f72176d10c513933333724f6b689b4,,LIBS_FROM_GIT=oslo.messaging,,1,1
